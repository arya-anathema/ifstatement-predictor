input function,match?,expected,predicted,codeBleu,Bleu-4,F1
"def __init__(self, scale, factor, mode):<tab>self.index = 0<tab>self.scale = scale<tab>if factor is None:<tab><tab>self._log_factor = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""'factor' must be >= 1.0"")<tab><tab>self._log_factor = np.log(factor)<tab>if mode not in self.allowed_modes:<tab><tab>raise ValueError(<tab><tab><tab>(""'{0}' is not a recognized mode. "" ""Please select from: {1}"").format(<tab><tab><tab><tab>mode, self.allowed_modes<tab><tab><tab>)<tab><tab>)<tab>self.mode = mode",1,if factor < 1.0 :,if factor < 1.0 :,0.75,100,1
"def get_grab_keys(self):<tab>keystr = None<tab>try:<tab><tab>keys = self.display.get_grab_keys()<tab><tab>for k in keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keystr = gtk.gdk.keyval_name(k)<tab><tab><tab>else:<tab><tab><tab><tab>keystr = keystr + ""+"" + gtk.gdk.keyval_name(k)<tab>except:<tab><tab>pass<tab>return keystr",1,if keystr is None :,if keystr is None :,0.75,100,1
"def _checkAllExamples(self, num_type):<tab>for region_code in phonenumberutil.SUPPORTED_REGIONS:<tab><tab>numobj_py = phonenumberutil.example_number_for_type(region_code, num_type)<tab><tab><IF-STMT><tab><tab><tab>numobj_pb = PyToPB(numobj_py)<tab><tab><tab>alt_py = PBToPy(numobj_pb)<tab><tab><tab>self.assertEqual(numobj_py, alt_py)",1,if numobj_py is not None :,if numobj_py is not None :,0.75,100,1
"def _gaf10iterator(handle):<tab>for inline in handle:<tab><tab>if inline[0] == ""!"":<tab><tab><tab>continue<tab><tab>inrec = inline.rstrip(""\n"").split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>inrec[3] = inrec[3].split(""|"")  # Qualifier<tab><tab>inrec[5] = inrec[5].split(""|"")  # DB:reference(s)<tab><tab>inrec[7] = inrec[7].split(""|"")  # With || From<tab><tab>inrec[10] = inrec[10].split(""|"")  # Synonym<tab><tab>inrec[12] = inrec[12].split(""|"")  # Taxon<tab><tab>yield dict(zip(GAF10FIELDS, inrec))",0,if len ( inrec ) == 1 :,if len ( inrec ) < 3 :,0.524151519,47.75034265,0.666666667
"def __xor__(self, other):<tab>inc, exc = _norm_args_notimplemented(other)<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if self._included is None:<tab><tab><IF-STMT>  # - +<tab><tab><tab>return _ComplementSet(excluded=self._excluded - inc)<tab><tab>else:  # - -<tab><tab><tab>return _ComplementSet(included=self._excluded.symmetric_difference(exc))<tab>else:<tab><tab>if inc is None:  # + -<tab><tab><tab>return _ComplementSet(excluded=exc - self._included)<tab><tab>else:  # + +<tab><tab><tab>return _ComplementSet(included=self._included.symmetric_difference(inc))",1,if exc is None :,if exc is None :,0.75,100,1
"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab>if self._bulk_commit:<tab><tab><tab>if self._pending_connection is None:<tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab>if commit_on_success and self.can_commit:<tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>con.close()",0,if not self . _bulk_commit :,if con is not None :,0.028043015,6.479066747,0.214285714
"def renderable_events(self, date, hour):<tab>""Returns the number of renderable events""<tab>renderable_events = []<tab>for event in self.events:<tab><tab>if event.covers(date, hour):<tab><tab><tab>renderable_events.append(event)<tab>if hour:<tab><tab>for current in renderable_events:<tab><tab><tab>for event in self.events:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>for hour in range(self.start_hour, self.end_hour):<tab><tab><tab><tab><tab><tab>if current.covers(date, hour) and event.covers(date, hour):<tab><tab><tab><tab><tab><tab><tab>renderable_events.append(event)<tab><tab><tab><tab><tab><tab><tab>break<tab>return renderable_events",0,if event not in renderable_events :,"if isinstance ( event , RenderedEvent ) :",0.023749772,7.267884212,0.285714286
"def _prepare_cooldowns(self, ctx):<tab>if self._buckets.valid:<tab><tab>dt = ctx.message.edited_at or ctx.message.created_at<tab><tab>current = dt.replace(tzinfo=datetime.timezone.utc).timestamp()<tab><tab>bucket = self._buckets.get_bucket(ctx.message, current)<tab><tab>retry_after = bucket.update_rate_limit(current)<tab><tab><IF-STMT><tab><tab><tab>raise CommandOnCooldown(bucket, retry_after)",1,if retry_after :,if retry_after :,0.531170663,1.00E-10,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_instances(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100,1
"def n_import_from(self, node):<tab>relative_path_index = 0<tab>if self.version >= 2.5:<tab><tab>if node[relative_path_index].pattr > 0:<tab><tab><tab>node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr<tab><tab><IF-STMT><tab><tab><tab>if isinstance(node[1].pattr, tuple):<tab><tab><tab><tab>imports = node[1].pattr<tab><tab><tab><tab>for pattr in imports:<tab><tab><tab><tab><tab>node[1].pattr = pattr<tab><tab><tab><tab><tab>self.default(node)<tab><tab><tab><tab>return<tab><tab><tab>pass<tab>self.default(node)",0,if self . version > 2.7 :,"elif node [ relative_path_index ] . pattr == """" :",0.015045755,2.908317711,0.142857143
def logic():<tab>while 1:<tab><tab>yield a<tab><tab>var = 0<tab><tab>for i in downrange(len(a)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>var += 1<tab><tab>out.next = var,1,if a [ i ] == 1 :,if a [ i ] == 1 :,0.75,100,1
"def _extract_networks(self, server_node):<tab>""""""Marshal the networks attribute of a parsed request""""""<tab>node = self.find_first_child_named(server_node, ""networks"")<tab>if node is not None:<tab><tab>networks = []<tab><tab>for network_node in self.find_children_named(node, ""network""):<tab><tab><tab>item = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>item[""uuid""] = network_node.getAttribute(""uuid"")<tab><tab><tab>if network_node.hasAttribute(""fixed_ip""):<tab><tab><tab><tab>item[""fixed_ip""] = network_node.getAttribute(""fixed_ip"")<tab><tab><tab>networks.append(item)<tab><tab>return networks<tab>else:<tab><tab>return None",1,"if network_node . hasAttribute ( ""uuid"" ) :","if network_node . hasAttribute ( ""uuid"" ) :",0.75,100,1
"def _model_shorthand(self, args):<tab>accum = []<tab>for arg in args:<tab><tab>if isinstance(arg, Node):<tab><tab><tab>accum.append(arg)<tab><tab><IF-STMT><tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, ModelAlias):<tab><tab><tab>accum.extend(arg.get_proxy_fields())<tab><tab>elif isclass(arg) and issubclass(arg, Model):<tab><tab><tab>accum.extend(arg._meta.declared_fields)<tab>return accum",0,"elif isinstance ( arg , Query ) :","elif isinstance ( arg , Model ) :",0.547301779,59.46035575,0.666666667
"def on_show_comment(self, widget, another):<tab>if widget.get_active():<tab><tab><IF-STMT><tab><tab><tab>self.treeview.update_items(all=True, comment=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items(comment=True)<tab>else:<tab><tab>if another.get_active():<tab><tab><tab>self.treeview.update_items(all=True)<tab><tab>else:<tab><tab><tab>self.treeview.update_items()",1,if another . get_active ( ) :,if another . get_active ( ) :,0.75,100,1
"def test_select_figure_formats_set():<tab>ip = get_ipython()<tab>for fmts in [<tab><tab>{""png"", ""svg""},<tab><tab>[""png""],<tab><tab>(""jpeg"", ""pdf"", ""retina""),<tab><tab>{""svg""},<tab>]:<tab><tab>active_mimes = {_fmt_mime_map[fmt] for fmt in fmts}<tab><tab>pt.select_figure_formats(ip, fmts)<tab><tab>for mime, f in ip.display_formatter.formatters.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nt.assert_in(Figure, f)<tab><tab><tab>else:<tab><tab><tab><tab>nt.assert_not_in(Figure, f)",1,if mime in active_mimes :,if mime in active_mimes :,0.75,100,1
"def update_from_data(self, data):<tab>super(HelpParameter, self).update_from_data(data)<tab># original help.py value_sources are strings, update command strings to value-source dict<tab>if self.value_sources:<tab><tab>self.value_sources = [<tab><tab><tab>str_or_dict<tab><tab><tab><IF-STMT><tab><tab><tab>else {""link"": {""command"": str_or_dict}}<tab><tab><tab>for str_or_dict in self.value_sources<tab><tab>]",0,"if isinstance ( str_or_dict , dict )","if isinstance ( str_or_dict , str )",0.574113272,80.70557275,0.6
def _reset_library_root_logger() -> None:<tab>global _default_handler<tab>with _lock:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>library_root_logger = _get_library_root_logger()<tab><tab>library_root_logger.removeHandler(_default_handler)<tab><tab>library_root_logger.setLevel(logging.NOTSET)<tab><tab>_default_handler = None,0,if not _default_handler :,if _default_handler is not None :,0.167839241,34.3294524,0.333333333
"def extract_headers(headers):<tab>""""""This function extracts valid headers from interactive input.""""""<tab>sorted_headers = {}<tab>matches = re.findall(r""(.*):\s(.*)"", headers)<tab>for match in matches:<tab><tab>header = match[0]<tab><tab>value = match[1]<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value[:-1]<tab><tab><tab>sorted_headers[header] = value<tab><tab>except IndexError:<tab><tab><tab>pass<tab>return sorted_headers",0,"if value [ - 1 ] == "","" :","if value . endswith ( ""\n"" ) :",0.030159603,8.606119901,0.6
"def _call_user_data_handler(self, operation, src, dst):<tab>if hasattr(self, ""_user_data""):<tab><tab>for key, (data, handler) in self._user_data.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler.handle(operation, key, data, src, dst)",1,if handler is not None :,if handler is not None :,0.75,100,1
"def update(self, other=None, **kwargs):<tab>if other is not None:<tab><tab><IF-STMT><tab><tab><tab>other = other.items()<tab><tab>for key, value in other:<tab><tab><tab>if key in kwargs:<tab><tab><tab><tab>raise TensorforceError.value(<tab><tab><tab><tab><tab>name=""NestedDict.update"",<tab><tab><tab><tab><tab>argument=""key"",<tab><tab><tab><tab><tab>value=key,<tab><tab><tab><tab><tab>condition=""specified twice"",<tab><tab><tab><tab>)<tab><tab><tab>self[key] = value<tab>for key, value in kwargs.items():<tab><tab>self[key] = value",0,"if hasattr ( other , ""items"" ) :","if isinstance ( other , dict ) :",0.091668085,21.06976474,0.481481481
"def _restore_context(context):<tab># Check for changes in contextvars, and set them to the current<tab># context for downstream consumers<tab>for cvar in context:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cvar.set(context.get(cvar))<tab><tab>except LookupError:<tab><tab><tab>cvar.set(context.get(cvar))",0,if cvar . get ( ) != context . get ( cvar ) :,if cvar not in cvar . get ( ) :,0.167907006,29.65468033,0.357142857
"def __str__(self):<tab>s = ""{""<tab>sep = """"<tab>for k, v in self.iteritems():<tab><tab>s += sep<tab><tab><IF-STMT><tab><tab><tab>s += ""'%s'"" % k<tab><tab>else:<tab><tab><tab>s += str(k)<tab><tab>s += "": ""<tab><tab>if type(v) == str:<tab><tab><tab>s += ""'%s'"" % v<tab><tab>else:<tab><tab><tab>s += str(v)<tab><tab>sep = "", ""<tab>s += ""}""<tab>return s",1,if type ( k ) == str :,if type ( k ) == str :,0.75,100,1
"def read_file_or_url(self, fname):<tab># TODO: not working on localhost<tab>if isinstance(fname, file):<tab><tab>result = open(fname, ""r"")<tab>else:<tab><tab>match = self.urlre.match(fname)<tab><tab><IF-STMT><tab><tab><tab>result = urllib.urlopen(match.group(1))<tab><tab>else:<tab><tab><tab>fname = os.path.expanduser(fname)<tab><tab><tab>try:<tab><tab><tab><tab>result = open(os.path.expanduser(fname), ""r"")<tab><tab><tab>except IOError:<tab><tab><tab><tab>result = open(<tab><tab><tab><tab><tab>""%s.%s"" % (os.path.expanduser(fname), self.defaultExtension), ""r""<tab><tab><tab><tab>)<tab>return result",1,if match :,if match :,0.531170663,1.00E-10,1
"def subclass_managers(self, recursive):<tab>for cls in self.class_.__subclasses__():<tab><tab>mgr = manager_of_class(cls)<tab><tab><IF-STMT><tab><tab><tab>yield mgr<tab><tab><tab>if recursive:<tab><tab><tab><tab>for m in mgr.subclass_managers(True):<tab><tab><tab><tab><tab>yield m",0,if mgr is not None and mgr is not self :,if mgr is not None :,0.387475612,34.5623234,0.535714286
"def star_path(path):<tab>""""""Replace integers and integer-strings in a path with *""""""<tab>path = list(path)<tab>for i, p in enumerate(path):<tab><tab>if isinstance(p, int):<tab><tab><tab>path[i] = ""*""<tab><tab>else:<tab><tab><tab>if not isinstance(p, text_type):<tab><tab><tab><tab>p = p.decode()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path[i] = ""*""<tab>return join_path(path)",0,if r_is_int . match ( p ) :,"if p == ""*"" :",0.019907918,4.408194606,0.477272727
"def cookie_decode(data, key):<tab>""""""Verify and decode an encoded string. Return an object or None""""""<tab>if isinstance(data, unicode):<tab><tab>data = data.encode(""ascii"")  # 2to3 hack<tab>if cookie_is_encoded(data):<tab><tab>sig, msg = data.split(u""?"".encode(""ascii""), 1)  # 2to3 hack<tab><tab><IF-STMT><tab><tab><tab>return pickle.loads(base64.b64decode(msg))<tab>return None",0,"if sig [ 1 : ] == base64 . b64encode ( hmac . new ( key , msg ) . digest ( ) ) :",if sig == key :,0.006096488,0.906356214,0.255528256
"def parse_row(cls, doc_row):<tab>row = {}<tab>for field_name, field in FIELD_MAP.items():<tab><tab>if len(doc_row) > field[1]:<tab><tab><tab>field_value = doc_row[field[1]]<tab><tab>else:<tab><tab><tab>field_value = """"<tab><tab><IF-STMT><tab><tab><tab>field_value = field[2](field_value)<tab><tab>row[field_name] = field_value<tab>return row",0,if len ( field ) >= 3 and callable ( field [ 2 ] ) :,if field [ 2 ] :,0.094798044,8.990698828,0.220238095
"def semantic_masks(self):<tab>for sid in self._seg_ids:<tab><tab>sinfo = self._sinfo.get(sid)<tab><tab><IF-STMT><tab><tab><tab># Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions.<tab><tab><tab>continue<tab><tab>yield (self._seg == sid).numpy().astype(np.bool), sinfo",0,"if sinfo is None or sinfo [ ""isthing"" ] :",if sinfo is None :,0.263975808,17.43703854,0.744444444
"def top_level_subjects(self):<tab>if self.subjects.exists():<tab><tab>return optimize_subject_query(self.subjects.filter(parent__isnull=True))<tab>else:<tab><tab># TODO: Delet this when all PreprintProviders have a mapping<tab><tab><IF-STMT><tab><tab><tab>return optimize_subject_query(<tab><tab><tab><tab>Subject.objects.filter(parent__isnull=True, provider___id=""osf"")<tab><tab><tab>)<tab><tab>tops = set([sub[0][0] for sub in self.subjects_acceptable])<tab><tab>return [Subject.load(sub) for sub in tops]",0,if len ( self . subjects_acceptable ) == 0 :,if subject . objects . exists ( ) :,0.058090237,4.571221768,0.25
"def resolve(obj):<tab>if isinstance(obj, list):<tab><tab>for item in obj:<tab><tab><tab>resolve(item)<tab><tab>return<tab>if isinstance(obj, dict):<tab><tab><IF-STMT><tab><tab><tab>with resolver.resolving(obj[u""$ref""]) as resolved:<tab><tab><tab><tab>resolve(resolved)<tab><tab><tab><tab>obj.clear()<tab><tab><tab><tab>obj.update(resolved)<tab><tab>else:<tab><tab><tab>for value in obj.values():<tab><tab><tab><tab>resolve(value)",0,"if ""$ref"" in obj :","if u""$ref"" in obj :",0.144778655,75.06238538,1
"def read_ansible_config(project_path, variables_of_interest):<tab>fnames = [""/etc/ansible/ansible.cfg""]<tab>if project_path:<tab><tab>fnames.append(os.path.join(project_path, ""ansible.cfg""))<tab>values = {}<tab>try:<tab><tab>parser = ConfigParser()<tab><tab>parser.read(fnames)<tab><tab>if ""defaults"" in parser:<tab><tab><tab>for var in variables_of_interest:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>values[var] = parser[""defaults""][var]<tab>except Exception:<tab><tab>logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames))<tab>return values",1,"if var in parser [ ""defaults"" ] :","if var in parser [ ""defaults"" ] :",0.75,100,1
"def test_globalphase():<tab>rule_set = DecompositionRuleSet(modules=[globalphase, r2rzandph])<tab>dummy = DummyEngine(save_commands=True)<tab>eng = MainEngine(<tab><tab>dummy,<tab><tab>[AutoReplacer(rule_set), InstructionFilter(low_level_gates_noglobalphase)],<tab>)<tab>qubit = eng.allocate_qubit()<tab>R(1.2) | qubit<tab>rz_count = 0<tab>for cmd in dummy.received_commands:<tab><tab>assert not isinstance(cmd.gate, R)<tab><tab><IF-STMT><tab><tab><tab>rz_count += 1<tab><tab><tab>assert cmd.gate == Rz(1.2)<tab>assert rz_count == 1",0,"if isinstance ( cmd . gate , Rz ) :",if cmd . gate != Rz ( 1.2 ) :,0.12450351,19.72940628,0.318181818
def _kill_current_player(self):<tab>if self._current_player:<tab><tab><IF-STMT><tab><tab><tab>self.voice_client.resume()<tab><tab>try:<tab><tab><tab>self.voice_client.stop()<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>self._current_player = None<tab><tab>return True<tab>return False,0,if self . voice_client . is_paused ( ) :,if not self . voice_client . is_paused ( ) :,0.417920499,85.55261859,0.483333333
"def hasAmbiguousLanguage(self, p):<tab>""""""Return True if p.b contains different @language directives.""""""<tab># c = self<tab>languages, tag = set(), ""@language""<tab>for s in g.splitLines(p.b):<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_ws(s, len(tag))<tab><tab><tab>j = g.skip_id(s, i)<tab><tab><tab>word = s[i:j]<tab><tab><tab>languages.add(word)<tab>return len(list(languages)) > 1",0,"if g . match_word ( s , 0 , tag ) :","if s . startswith ( ""@language"" ) :",0.024253488,7.510002314,0.267857143
"def terminate(self):<tab>n_retries = 10<tab>for i in range(n_retries):<tab><tab>try:<tab><tab><tab>super(MemmappingPool, self).terminate()<tab><tab><tab>break<tab><tab>except OSError as e:<tab><tab><tab>if isinstance(e, WindowsError):<tab><tab><tab><tab># Workaround  occasional ""[Error 5] Access is denied"" issue<tab><tab><tab><tab># when trying to terminate a process under windows.<tab><tab><tab><tab>sleep(0.1)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab><tab>""Failed to terminate worker processes in""<tab><tab><tab><tab><tab><tab>"" multiprocessing pool: %r"" % e<tab><tab><tab><tab><tab>)<tab>self._temp_folder_manager._unlink_temporary_resources()",0,if i + 1 == n_retries :,elif i == n_retries - 1 :,0.041571781,44.17918227,0.6
"def test_downsampling(self, method, maybe_range, fraction, expected_n_reads):<tab>reader = sam.SamReader(<tab><tab>test_utils.genomics_core_testdata(""test.bam""),<tab><tab>downsample_fraction=fraction,<tab><tab>random_seed=12345,<tab>)<tab>with reader:<tab><tab><IF-STMT><tab><tab><tab>reads_iter = reader.iterate()<tab><tab>elif method == ""query"":<tab><tab><tab>reads_iter = reader.query(ranges.parse_literal(maybe_range))<tab><tab>else:<tab><tab><tab>self.fail(""Unexpected method "" + str(method))<tab><tab>self.assertEqual(test_utils.iterable_len(reads_iter), expected_n_reads)",1,"if method == ""iterate"" :","if method == ""iterate"" :",0.75,100,1
"def verify_acceptable(self):<tab>start = time.time()<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>elif (time.time() - start) > READ_TIMEOUT:<tab><tab><tab>raise Exception(""Server socket did not accept in time"")<tab><tab>time.sleep(0.1)",0,if self . select_acceptable ( ) :,if self . _socket . acceptable :,0.090565314,21.57365265,0.722222222
"def replica_local_creator(next_creator, **kwargs) -> tf.Variable:<tab>""""""Variable creator that by default creates replica local variables.""""""<tab>if kwargs[""synchronization""] == tf.VariableSynchronization.AUTO:<tab><tab>kwargs[""synchronization""] = tf.VariableSynchronization.ON_READ<tab><tab><IF-STMT><tab><tab><tab>kwargs[""aggregation""] = tf.VariableAggregation.ONLY_FIRST_REPLICA<tab><tab>if kwargs[""trainable""] is None:<tab><tab><tab>kwargs[""trainable""] = True<tab>return next_creator(**kwargs)",0,"if kwargs [ ""aggregation"" ] == tf . VariableAggregation . NONE :","if ""aggregation"" not in kwargs :",0.011974477,10.19067193,0.241666667
"def get_optional_nargs(self, name):<tab>for n, kwargs in self.conf[""optional_args""]:<tab><tab>if name == n:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>action = kwargs[""action""]<tab><tab><tab><tab>if action in (""store_true"", ""store_false""):<tab><tab><tab><tab><tab>return 0<tab><tab><tab>break<tab>return 1",1,"if ""action"" in kwargs :","if ""action"" in kwargs :",0.75,100,1
"def ageToDays(self, age_str):<tab>age = 0<tab>age_str = age_str.replace(""&nbsp;"", "" "")<tab>regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+""<tab>matches = re.findall(regex, age_str)<tab>for match in matches:<tab><tab>nr, size = match<tab><tab>mult = 1<tab><tab>if size == ""week"":<tab><tab><tab>mult = 7<tab><tab>elif size == ""month"":<tab><tab><tab>mult = 30.5<tab><tab><IF-STMT><tab><tab><tab>mult = 365<tab><tab>age += tryInt(nr) * mult<tab>return tryInt(age)",0,"elif size == ""year"" :","elif size == ""hour"" :",0.642872021,59.46035575,1
"def put(self, userId, bucket, key, data):<tab>if not self.initialized:<tab><tab>raise Exception(""archive not initialized"")<tab>try:<tab><tab>uri = self.uri_for(userId, bucket, key)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Failed writing file content to disk: {}"".format(uri))<tab><tab>else:<tab><tab><tab>return uri<tab>except Exception as err:<tab><tab>logger.debug(""cannot put data: exception - "" + str(err))<tab><tab>raise err",0,"if not self . _save_content ( uri , data ) :","if not self . can_write ( uri , data ) :",0.602001933,54.84498092,1
"def get_range(min, max):<tab>if max < min:<tab><tab>min, max = max, min<tab>elif min == max:<tab><tab>if min < 0:<tab><tab><tab>min, max = 2 * min, 0<tab><tab><IF-STMT><tab><tab><tab>min, max = 0, 2 * min<tab><tab>else:<tab><tab><tab>min, max = -1, 1<tab>return min, max",0,elif min > 0 :,elif max > 0 :,0.392872021,42.72870064,0.6
"def update_job_weights():<tab>""""""Update job weights.""""""<tab>for job in data_types.Job.query():<tab><tab>multiplier = DEFAULT_MULTIPLIER<tab><tab>if environment.is_engine_fuzzer_job(job.name):<tab><tab><tab>targets_count = ndb.Key(data_types.FuzzTargetsCount, job.name).get()<tab><tab><tab># If the count is 0, it may be due to a bad build or some other issue. Use<tab><tab><tab># the default weight in that case to allow for recovery.<tab><tab><tab>if targets_count and targets_count.count:<tab><tab><tab><tab>multiplier = targets_count.count<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>multiplier = TARGET_COUNT_WEIGHT_CAP<tab><tab>update_job_weight(job.name, multiplier)",0,if multiplier > TARGET_COUNT_WEIGHT_CAP :,elif TARGET_COUNT_WEIGHT_CAP :,0.055364704,1.00E-10,0.214285714
"def _validate_required_settings(<tab>self, application_id, application_config, required_settings, should_throw=True):<tab>""""""All required keys must be present""""""<tab>for setting_key in required_settings:<tab><tab>if setting_key not in application_config.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>MISSING_SETTING.format(<tab><tab><tab><tab><tab><tab>application_id=application_id, setting=setting_key<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>return True",1,if should_throw :,if should_throw :,0.531170663,1.00E-10,1
"def nested_update(org_dict, upd_dict):<tab>for key, value in upd_dict.items():<tab><tab>if isinstance(value, dict):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not isinstance(org_dict[key], dict):<tab><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab><tab>""Mismatch between org_dict and upd_dict at node {}"".format(key)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>nested_update(org_dict[key], value)<tab><tab><tab>else:<tab><tab><tab><tab>org_dict[key] = value<tab><tab>else:<tab><tab><tab>org_dict[key] = value",1,if key in org_dict :,if key in org_dict :,0.75,100,1
"def eintr_retry_call(func, *args, **kwargs):<tab>while True:<tab><tab>try:<tab><tab><tab>return func(*args, **kwargs)<tab><tab>except EnvironmentError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>raise",0,"if getattr ( e , ""errno"" , None ) == errno . EINTR :",if e . errno == errno . EINTR :,0.195652134,28.41087887,0.277310924
"def __init__(self, entity):<tab>self._entity = weakref.proxy(entity)<tab>self._observables = collections.OrderedDict()<tab>self._keys_helper = _ObservableKeys(self._entity, self._observables)<tab># Ensure consistent ordering.<tab>for attr_name in sorted(dir(type(self))):<tab><tab>type_attr = getattr(type(self), attr_name)<tab><tab><IF-STMT><tab><tab><tab>self._observables[attr_name] = getattr(self, attr_name)",0,"if isinstance ( type_attr , define . observable ) :","if isinstance ( type_attr , Observable ) :",0.232029036,57.89300675,0.584615385
"def check_redundancy(self):<tab># Ensure there are no adjacent blocks (they should have been merged)<tab>starts, sizes = self.allocator.get_allocated_regions()<tab>last = -1<tab>for start, size in zip(starts, sizes):<tab><tab>if start < last:<tab><tab><tab>raise Exception(""Block at %d is out of order"" % start)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Block at %d is redundant"" % start)<tab><tab>last = start + size",0,if start == last :,if start + size > last :,0.149273847,18.575058,0.571428571
"def elfheader():<tab>local_path = pwndbg.file.get_file(pwndbg.proc.exe)<tab>with open(local_path, ""rb"") as f:<tab><tab>elffile = ELFFile(f)<tab><tab>sections = []<tab><tab>for section in elffile.iter_sections():<tab><tab><tab>start = section[""sh_addr""]<tab><tab><tab># Don't print sections that aren't mapped into memory<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>size = section[""sh_size""]<tab><tab><tab>sections.append((start, start + size, section.name))<tab><tab>sections.sort()<tab><tab>for start, end, name in sections:<tab><tab><tab>print(""%#x - %#x "" % (start, end), name)",0,if start == 0 :,if start == - 1 :,0.127622275,43.47208719,0.6
"def orbit():<tab>""""""Define the internal thread for running the orbit.""""""<tab>for point in points:<tab><tab>self.set_position(point)<tab><tab>self.set_focus(focus)<tab><tab>self.set_viewup(viewup)<tab><tab>self.renderer.ResetCameraClippingRange()<tab><tab>self.render()<tab><tab>time.sleep(step)<tab><tab><IF-STMT><tab><tab><tab>self.write_frame()",0,if write_frames :,if self . write_frame is not None :,0.044228356,1.00E-10,0.266666667
"def json_format(self):<tab>""""""Returns the integer value formatted as a JSON literal""""""<tab>fmt = self._jsonfmt<tab>if fmt == NUMBER_FORMAT_HEX:<tab><tab>return format(self, ""#x"")<tab>elif fmt == NUMBER_FORMAT_OCTAL:<tab><tab>return format(self, ""#o"")<tab>elif fmt == NUMBER_FORMAT_BINARY:<tab><tab>return format(self, ""#b"")<tab>elif fmt == NUMBER_FORMAT_LEGACYOCTAL:<tab><tab>if self == 0:<tab><tab><tab>return ""0""  # For some reason Python's int doesn't do '00'<tab><tab><IF-STMT><tab><tab><tab>return ""-0%o"" % (-self)<tab><tab>else:<tab><tab><tab>return ""0%o"" % self<tab>else:<tab><tab>return str(self)",1,elif self < 0 :,elif self < 0 :,0.75,100,1
"def parseTime(timeStr):<tab>regex = re.compile(constants.PARSE_TIME_REGEX)<tab>parts = regex.match(timeStr)<tab>if not parts:<tab><tab>return<tab>parts = parts.groupdict()<tab>time_params = {}<tab>for (name, param) in parts.items():<tab><tab><IF-STMT><tab><tab><tab>if name == ""miliseconds"":<tab><tab><tab><tab>time_params[""microseconds""] = int(param) * 1000<tab><tab><tab>else:<tab><tab><tab><tab>time_params[name] = int(param)<tab>return datetime.timedelta(**time_params).total_seconds()",0,if param :,if param is not None :,0.090364769,1.00E-10,0.4
"def build_extension(self, ext):<tab>ext._convert_pyx_sources_to_lang()<tab>_compiler = self.compiler<tab>try:<tab><tab>if isinstance(ext, Library):<tab><tab><tab>self.compiler = self.shlib_compiler<tab><tab>_build_ext.build_extension(self, ext)<tab><tab><IF-STMT><tab><tab><tab>cmd = self.get_finalized_command(""build_py"").build_lib<tab><tab><tab>self.write_stub(cmd, ext)<tab>finally:<tab><tab>self.compiler = _compiler",0,if ext . _needs_stub :,"elif isinstance ( ext , Stub ) :",0.02204854,6.567274736,0.133333333
"def __init__(self, type, data, name=None):<tab>Constant.__init__(self, type, data, name)<tab>self.tag.unique_value = None<tab>if isinstance(data, np.ndarray) and data.ndim > 0:<tab><tab>flat_data = data.ravel()<tab><tab><IF-STMT><tab><tab><tab>if (flat_data == flat_data[0]).all():<tab><tab><tab><tab>self.tag.unique_value = flat_data[0]",0,if flat_data . shape [ 0 ] :,if len ( flat_data ) == 1 :,0.019345088,15.85116569,0.333333333
"def _find_machine(deb_arch):<tab>for machine in _ARCH_TRANSLATIONS:<tab><tab>if _ARCH_TRANSLATIONS[machine].get(""deb"", """") == deb_arch:<tab><tab><tab>return machine<tab><tab><IF-STMT><tab><tab><tab>return machine<tab>raise errors.SnapcraftEnvironmentError(<tab><tab>""Cannot set machine from deb_arch {!r}"".format(deb_arch)<tab>)",0,"elif _ARCH_TRANSLATIONS [ machine ] . get ( ""uts_machine"" , """" ) == deb_arch :","elif _ARCH_TRANSLATIONS [ machine ] . get ( ""deb"" , """" ) ==deb_arch :",0.542304709,81.36749448,1
"def fields_for_form(form, only_fields, exclude_fields):<tab>fields = OrderedDict()<tab>for name, field in form.fields.items():<tab><tab>is_not_in_only = only_fields and name not in only_fields<tab><tab>is_excluded = (<tab><tab><tab>name<tab><tab><tab>in exclude_fields  # or<tab><tab><tab># name in already_created_fields<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>fields[name] = convert_form_field(field)<tab>return fields",0,if is_not_in_only or is_excluded :,if is_excluded and is_not_in_only :,0.288498786,64.79121525,0.5
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None):<tab>readies = [0] * len(selectors)<tab>start_time = time.time()<tab>while True:<tab><tab>all_satisfy = True<tab><tab>for idx, selector in enumerate(selectors):<tab><tab><tab>if readies[idx] < min_counts[idx]:<tab><tab><tab><tab>all_satisfy = False<tab><tab><tab><tab>readies[idx] = count_fun(selector)<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if timeout and timeout + start_time < time.time():<tab><tab><tab>raise TimeoutError(""Wait cluster start timeout"")<tab><tab>time.sleep(1)",1,if all_satisfy :,if all_satisfy :,0.531170663,1.00E-10,1
def count_brokers(self):<tab>self.nb_brokers = 0<tab>for broker in self.brokers:<tab><tab><IF-STMT><tab><tab><tab>self.nb_brokers += 1<tab>for realm in self.higher_realms:<tab><tab>for broker in realm.brokers:<tab><tab><tab>if not broker.spare and broker.manage_sub_realms:<tab><tab><tab><tab>self.nb_brokers += 1,0,if not broker . spare :,if not broker . spare and broker . manage_sub_realms :,0.301601086,27.82462329,0.744444444
"def _adapt_polymorphic_element(self, element):<tab>if ""parententity"" in element._annotations:<tab><tab>search = element._annotations[""parententity""]<tab><tab>alias = self._polymorphic_adapters.get(search, None)<tab><tab><IF-STMT><tab><tab><tab>return alias.adapt_clause(element)<tab>if isinstance(element, expression.FromClause):<tab><tab>search = element<tab>elif hasattr(element, ""table""):<tab><tab>search = element.table<tab>else:<tab><tab>return None<tab>alias = self._polymorphic_adapters.get(search, None)<tab>if alias:<tab><tab>return alias.adapt_clause(element)",1,if alias :,if alias :,0.531170663,1.00E-10,1
"def get_all_methods():<tab>estimators = all_estimators()<tab>for name, Estimator in estimators:<tab><tab>if name.startswith(""_""):<tab><tab><tab># skip private classes<tab><tab><tab>continue<tab><tab>methods = []<tab><tab>for name in dir(Estimator):<tab><tab><tab>if name.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><tab>method_obj = getattr(Estimator, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>methods.append(name)<tab><tab>methods.append(None)<tab><tab>for method in sorted(methods, key=lambda x: str(x)):<tab><tab><tab>yield Estimator, method",0,"if hasattr ( method_obj , ""__call__"" ) or isinstance ( method_obj , property ) :",if not callable ( method_obj ) :,0.019737101,6.234799345,0.238636364
"def __call__(self, es, params):<tab>ops = 0<tab>indices = mandatory(params, ""indices"", self)<tab>only_if_exists = params.get(""only-if-exists"", False)<tab>request_params = params.get(""request-params"", {})<tab>for index_name in indices:<tab><tab>if not only_if_exists:<tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab><tab><IF-STMT><tab><tab><tab>self.logger.info(""Index [%s] already exists. Deleting it."", index_name)<tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab>return ops, ""ops""",0,elif only_if_exists and es . indices . exists ( index = index_name ) :,elif index_name in indices :,0.09152336,4.538591507,0.230263158
"def get():<tab>result = []<tab>for b in self.key_bindings:<tab><tab><IF-STMT><tab><tab><tab>match = True<tab><tab><tab>for i, j in zip(b.keys, keys):<tab><tab><tab><tab>if i != j and i != Keys.Any:<tab><tab><tab><tab><tab>match = False<tab><tab><tab><tab><tab>break<tab><tab><tab>if match:<tab><tab><tab><tab>result.append(b)<tab>return result",0,if len ( keys ) < len ( b . keys ) :,if len ( keys ) == len ( b . keys ) :,0.881506314,69.97522298,1
"def get_arg_list_scalar_arg_dtypes(arg_types):<tab>result = []<tab>for arg_type in arg_types:<tab><tab><IF-STMT><tab><tab><tab>result.append(arg_type.dtype)<tab><tab>elif isinstance(arg_type, VectorArg):<tab><tab><tab>result.append(None)<tab><tab><tab>if arg_type.with_offset:<tab><tab><tab><tab>result.append(np.int64)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""arg type not understood: %s"" % type(arg_type))<tab>return result",0,"if isinstance ( arg_type , ScalarArg ) :","if isinstance ( arg_type , np . dtype ) :",0.263340042,57.06745777,0.487179487
"def autocommitter():<tab>while True:<tab><tab>try:<tab><tab><tab>if not self._running:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._auto_commit()<tab><tab><tab>self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000)<tab><tab>except ReferenceError:<tab><tab><tab>break<tab><tab>except Exception:<tab><tab><tab># surface all exceptions to the main thread<tab><tab><tab>self._worker_exception = sys.exc_info()<tab><tab><tab>break<tab>log.debug(""Autocommitter thread exiting"")",0,if self . _auto_commit_enable :,if self . _auto_commit_interval_ms :,0.394778655,63.15552372,1
"def on_conflict(self, *target_fields: Union[str, Term]) -> ""PostgreSQLQueryBuilder"":<tab>if not self._insert_table:<tab><tab>raise QueryException(""On conflict only applies to insert query"")<tab>self._on_conflict = True<tab>for target_field in target_fields:<tab><tab><IF-STMT><tab><tab><tab>self._on_conflict_fields.append(self._conflict_field_str(target_field))<tab><tab>elif isinstance(target_field, Term):<tab><tab><tab>self._on_conflict_fields.append(target_field)",1,"if isinstance ( target_field , str ) :","if isinstance ( target_field , str ) :",0.75,100,1
"def change_TV_DOWNLOAD_DIR(tv_download_dir):<tab>if tv_download_dir == """":<tab><tab>sickbeard.TV_DOWNLOAD_DIR = """"<tab><tab>return True<tab>if os.path.normpath(sickbeard.TV_DOWNLOAD_DIR) != os.path.normpath(tv_download_dir):<tab><tab><IF-STMT><tab><tab><tab>sickbeard.TV_DOWNLOAD_DIR = os.path.normpath(tv_download_dir)<tab><tab><tab>logger.log(u""Changed TV download folder to "" + tv_download_dir)<tab><tab>else:<tab><tab><tab>return False<tab>return True",0,if helpers . makeDir ( tv_download_dir ) :,if os . path . isdir ( tv_download_dir ) :,0.233382505,54.37427682,0.274725275
"def save_config(self, cmd=""save config"", confirm=True, confirm_response=""y""):<tab>""""""Saves Config.""""""<tab>self.enable()<tab>if confirm:<tab><tab>output = self.send_command_timing(command_string=cmd)<tab><tab><IF-STMT><tab><tab><tab>output += self.send_command_timing(confirm_response)<tab><tab>else:<tab><tab><tab># Send enter by default<tab><tab><tab>output += self.send_command_timing(self.RETURN)<tab>else:<tab><tab># Some devices are slow so match on trailing-prompt if you can<tab><tab>output = self.send_command(command_string=cmd)<tab>return output",1,if confirm_response :,if confirm_response :,0.531170663,1.00E-10,1
"def apply_gradient_for_batch(inputs, labels, weights, loss):<tab>with tf.GradientTape() as tape:<tab><tab>outputs = self.model(inputs, training=True)<tab><tab><IF-STMT><tab><tab><tab>outputs = [outputs]<tab><tab>if self._loss_outputs is not None:<tab><tab><tab>outputs = [outputs[i] for i in self._loss_outputs]<tab><tab>batch_loss = loss(outputs, labels, weights)<tab>if variables is None:<tab><tab>vars = self.model.trainable_variables<tab>else:<tab><tab>vars = variables<tab>grads = tape.gradient(batch_loss, vars)<tab>self._tf_optimizer.apply_gradients(zip(grads, vars))<tab>self._global_step.assign_add(1)<tab>return batch_loss",1,"if isinstance ( outputs , tf . Tensor ) :","if isinstance ( outputs , tf . Tensor ) :",0.75,100,1
"def sort(self, items):<tab>slow_sorts = []<tab>switch_slow = False<tab>for sort in reversed(self.sorts):<tab><tab><IF-STMT><tab><tab><tab>slow_sorts.append(sort)<tab><tab>elif sort.order_clause() is None:<tab><tab><tab>switch_slow = True<tab><tab><tab>slow_sorts.append(sort)<tab><tab>else:<tab><tab><tab>pass<tab>for sort in slow_sorts:<tab><tab>items = sort.sort(items)<tab>return items",1,if switch_slow :,if switch_slow :,0.531170663,1.00E-10,1
"def getmod(self, nm):<tab>mod = None<tab>for thing in self.path:<tab><tab>if isinstance(thing, basestring):<tab><tab><tab>owner = self.shadowpath.get(thing, -1)<tab><tab><tab>if owner == -1:<tab><tab><tab><tab>owner = self.shadowpath[thing] = self.__makeOwner(thing)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mod = owner.getmod(nm)<tab><tab>else:<tab><tab><tab>mod = thing.getmod(nm)<tab><tab>if mod:<tab><tab><tab>break<tab>return mod",1,if owner :,if owner :,0.531170663,1.00E-10,1
"def has(self, key):<tab>filename = self._get_filename(key)<tab>try:<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>pickle_time = pickle.load(f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>os.remove(filename)<tab><tab><tab><tab>return False<tab>except (IOError, OSError, pickle.PickleError):<tab><tab>return False",0,if pickle_time == 0 or pickle_time >= time ( ) :,if pickle_time > time . time ( ) :,0.394397701,34.97261687,0.386666667
"def forward(self, hs):<tab>h = self.c0(hs[-1])<tab>for i in range(1, 8):<tab><tab>h = F.concat([h, hs[-i - 1]])<tab><tab><IF-STMT><tab><tab><tab>h = self[""c%d"" % i](h)<tab><tab>else:<tab><tab><tab>h = self.c7(h)<tab>return h",0,if i < 7 :,if i % 2 == 0 :,0.136202649,12.22307556,0.476190476
"def get_custom_behaviour2(self):<tab>string = """"<tab>for arg in list(self.defaults.keys()) + self.var:<tab><tab><IF-STMT><tab><tab><tab># Don't add redundant lines e.g. sus=sus;<tab><tab><tab>if str(arg) != str(self.__dict__[arg]):<tab><tab><tab><tab>string += str(arg) + ""="" + str(self.__dict__[arg]) + "";\n""<tab>return string",1,if arg in self . __dict__ :,if arg in self . __dict__ :,0.75,100,1
"def _apply_operation(self, values):<tab>""""""Method that defines the less-than-or-equal operation""""""<tab>arg1 = next(values)<tab>for strict in self._strict:<tab><tab>arg2 = next(values)<tab><tab>if strict:<tab><tab><tab>if not (arg1 < arg2):<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>arg1 = arg2<tab>return True",0,if not ( arg1 <= arg2 ) :,if not ( arg1 < arg2 ) :,0.501462237,61.01950432,1
"def i_pshufb(self, op, off=0):<tab>dst = self.getOperValue(op, off)<tab>src = self.getOperValue(op, off)<tab>res = 0<tab>if op.opers[0].tsize == 8:<tab><tab>mask = 0x07<tab>else:<tab><tab>mask = 0x0F<tab>for i in range(op.opers[0].tsize):<tab><tab>shfl = src & (1 << ((i * 8) + 7))<tab><tab><IF-STMT><tab><tab><tab>s = 0<tab><tab>else:<tab><tab><tab>indx = (src >> (i * 8)) & mask<tab><tab><tab>s = (src >> (indx * 8)) & 0xFF<tab><tab>res |= s << (i * 8)<tab>self.setOperValue(op, 0, res)",0,if shfl :,if fl == 0 :,0.051944023,1.00E-10,0.36
"def report_out_of_quota(self, appid):<tab>self.logger.warn(""report_out_of_quota:%s"", appid)<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>self.out_of_quota_appids.append(appid)<tab><tab>try:<tab><tab><tab>self.working_appid_list.remove(appid)<tab><tab>except:<tab><tab><tab>pass",1,if appid not in self . out_of_quota_appids :,if appid not in self . out_of_quota_appids :,0.75,100,1
"def to_py(self, value: _StrUnset) -> _StrUnsetNone:<tab>self._basic_py_validation(value, str)<tab>if isinstance(value, usertypes.Unset):<tab><tab>return value<tab>elif not value:<tab><tab>return None<tab>value = os.path.expandvars(value)<tab>value = os.path.expanduser(value)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise configexc.ValidationError(value, ""must be a valid directory!"")<tab><tab>if not os.path.isabs(value):<tab><tab><tab>raise configexc.ValidationError(value, ""must be an absolute path!"")<tab>except UnicodeEncodeError as e:<tab><tab>raise configexc.ValidationError(value, e)<tab>return value",1,if not os . path . isdir ( value ) :,if not os . path . isdir ( value ) :,0.75,100,1
"def findinDoc(self, tagpath, pos, end):<tab>result = None<tab>if end == -1:<tab><tab>end = self.docSize<tab>else:<tab><tab>end = min(self.docSize, end)<tab>foundat = -1<tab>for j in range(pos, end):<tab><tab>item = self.docList[j]<tab><tab>if item.find(b""="") >= 0:<tab><tab><tab>(name, argres) = item.split(b""="", 1)<tab><tab>else:<tab><tab><tab>name = item<tab><tab><tab>argres = """"<tab><tab><IF-STMT><tab><tab><tab>tagpath = tagpath.encode(""utf-8"")<tab><tab>if name.endswith(tagpath):<tab><tab><tab>result = argres<tab><tab><tab>foundat = j<tab><tab><tab>break<tab>return foundat, result",1,"if isinstance ( tagpath , str ) :","if isinstance ( tagpath , str ) :",0.75,100,1
"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)):<tab><tab>return True<tab>if isinstance(value, (tuple, list, set, frozenset)):<tab><tab>for item in value:<tab><tab><tab>if not has_safe_repr(item):<tab><tab><tab><tab>return False<tab><tab>return True<tab>elif isinstance(value, dict):<tab><tab>for key, value in value.iteritems():<tab><tab><tab>if not has_safe_repr(key):<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",1,if not has_safe_repr ( value ) :,if not has_safe_repr ( value ) :,0.75,100,1
"def run(self):<tab># Make some objects emit lights<tab>for obj in bpy.context.scene.objects:<tab><tab><IF-STMT><tab><tab><tab>obj_id = obj[""modelId""]<tab><tab><tab># In the case of the lamp<tab><tab><tab>if obj_id in self.lights:<tab><tab><tab><tab>self._make_lamp_emissive(obj, self.lights[obj_id])<tab><tab><tab># Make the windows emit light<tab><tab><tab>if obj_id in self.windows:<tab><tab><tab><tab>self._make_window_emissive(obj)<tab><tab><tab># Also make ceilings slightly emit light<tab><tab><tab>if obj.name.startswith(""Ceiling#""):<tab><tab><tab><tab>self._make_ceiling_emissive(obj)",0,"if ""modelId"" in obj :","if obj [ ""type"" ] == ""light"" :",0.02800146,4.619215105,0.477272727
"def bitvector_case_fn(<tab>rng: Random, mode: RandomizationMode, size: int, invalid_making_pos: int = None):<tab>bits = get_random_ssz_object(<tab><tab>rng,<tab><tab>Bitvector[size],<tab><tab>max_bytes_length=(size + 7) // 8,<tab><tab>max_list_length=size,<tab><tab>mode=mode,<tab><tab>chaos=False,<tab>)<tab>if invalid_making_pos is not None and invalid_making_pos <= size:<tab><tab>already_invalid = False<tab><tab>for i in range(invalid_making_pos, size):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>already_invalid = True<tab><tab>if not already_invalid:<tab><tab><tab>bits[invalid_making_pos] = True<tab>return bits",0,if bits [ i ] :,if bits [ i ] is not None :,0.39893551,46.71379777,0.523809524
"def get_transaction_execution_results(self, batch_signature):<tab>with self._condition:<tab><tab>batch_status = self._batch_statuses.get(batch_signature)<tab><tab>if batch_status is None:<tab><tab><tab>return None<tab><tab>annotated_batch = self._batch_by_id.get(batch_signature)<tab><tab>if annotated_batch is None:<tab><tab><tab>return None<tab><tab>results = []<tab><tab>for txn in annotated_batch.batch.transactions:<tab><tab><tab>result = self._txn_results.get(txn.header_signature)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.append(result)<tab><tab>return results",1,if result is not None :,if result is not None :,0.75,100,1
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr<tab>i, j, n = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_reg(op) and op_xmm(op):<tab><tab><tab>n += 1<tab><tab>elif op_imm8(op):<tab><tab><tab>i += 1<tab><tab><IF-STMT><tab><tab><tab>j += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and i == 1 and j <= 1",0,elif op_imm8_2 ( op ) :,elif op_reg ( op ) and op_imm8 ( op ) :,0.296342279,28.4955776,0.635416667
"def whichmodule(obj, name):<tab>""""""Find the module an object belong to.""""""<tab>module_name = getattr(obj, ""__module__"", None)<tab>if module_name is not None:<tab><tab>return module_name<tab># Protect the iteration by using a list copy of sys.modules against dynamic<tab># modules that trigger imports of other modules upon calls to getattr.<tab>for module_name, module in sys.modules.copy().items():<tab><tab>if module_name == ""__main__"" or module is None:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return module_name<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return ""__main__""",0,"if _getattribute ( module , name ) [ 0 ] is obj :","if getattr ( obj , name ) == module :",0.150145058,13.57210628,0.241666667
"def get_ld_header_info(p):<tab># ""nested-function, but placed at module level<tab># as an ld_header was found, return known paths, archives and members<tab># these lines start with a digit<tab>info = []<tab>for line in p.stdout:<tab><tab><IF-STMT><tab><tab><tab>info.append(line)<tab><tab>else:<tab><tab><tab># blank line (separator), consume line and end for loop<tab><tab><tab>break<tab>return info",0,"if re . match ( ""[0-9]"" , line ) :","if line . startswith ( ""ld_header"" ) :",0.030390517,8.161849107,0.320512821
"def write(self, s):<tab>if self.closed:<tab><tab>raise ValueError(""write to closed file"")<tab>if type(s) not in (unicode, str, bytearray):<tab><tab># See issue #19481<tab><tab><IF-STMT><tab><tab><tab>s = unicode.__getitem__(s, slice(None))<tab><tab>elif isinstance(s, str):<tab><tab><tab>s = str.__str__(s)<tab><tab>elif isinstance(s, bytearray):<tab><tab><tab>s = bytearray.__str__(s)<tab><tab>else:<tab><tab><tab>raise TypeError(""must be string, not "" + type(s).__name__)<tab>return self.shell.write(s, self.tags)",0,"if isinstance ( s , unicode ) :","if isinstance ( s , slice ) :",0.549040681,59.46035575,0.666666667
"def generate_forwards(cls, attrs):<tab># forward functions of _forwards<tab>for attr_name, attr in cls._forwards.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(attr, property):<tab><tab><tab>cls._forward.append(attr_name)<tab><tab>elif isinstance(attr, types.FunctionType):<tab><tab><tab>wrapper = _forward_factory(cls, attr_name, attr)<tab><tab><tab>setattr(cls, attr_name, wrapper)<tab><tab>else:<tab><tab><tab>raise TypeError(attr_name, type(attr))",0,"if attr_name . startswith ( ""_"" ) or attr_name in attrs :",if attr_name not in attrs :,0.159074827,14.32523984,0.276190476
"def _user_has_dnd(bot, user_id):<tab>try:<tab><tab>return bot.call_shared(""dnd.user_check"", user_id)  # shared dnd check<tab>except KeyError:<tab><tab>logger.warning(""mentions: falling back to legacy _user_has_dnd()"")<tab><tab>initiator_has_dnd = False<tab><tab><IF-STMT><tab><tab><tab>donotdisturb = bot.memory.get(""donotdisturb"")<tab><tab><tab>if user_id in donotdisturb:<tab><tab><tab><tab>initiator_has_dnd = True<tab><tab>return initiator_has_dnd",0,"if bot . memory . exists ( [ ""donotdisturb"" ] ) :","if bot . memory . get ( ""donotdisturb"" ) :",0.239169177,40.39323668,0.666666667
"def init(self):<tab>""""""Initialize a fighter from the database and validate""""""<tab>self.__item = None<tab>if self.itemID:<tab><tab>self.__item = eos.db.getItem(self.itemID)<tab><tab><IF-STMT><tab><tab><tab>pyfalog.error(""Item (id: {0}) does not exist"", self.itemID)<tab><tab><tab>return<tab>if self.isInvalid:<tab><tab>pyfalog.error(""Item (id: {0}) is not a Fighter"", self.itemID)<tab><tab>return<tab>self.build()",1,if self . __item is None :,if self . __item is None :,0.75,100,1
"def _pg_sku_name_validator(sku_name, sku_info, tier):<tab>if sku_name:<tab><tab>skus = get_postgres_skus(sku_info, tier)<tab><tab><IF-STMT><tab><tab><tab>error_msg = (<tab><tab><tab><tab>""Incorrect value for --sku-name. ""<tab><tab><tab><tab>+ ""The SKU name does not match {} tier. Specify --tier if you did not. "".format(<tab><tab><tab><tab><tab>tier<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>raise CLIError(error_msg + ""Allowed values : {}"".format(skus))",0,if sku_name not in skus :,if not skus :,0.107501863,13.97639637,0.56
"def _parse_paternity_log(writer, file):<tab>parent_map = {}<tab>parent_map[0] = 0<tab>for line in file.read().decode(""utf-8"").split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elems = line.split("" "")  # <Child> <Parent><tab><tab>if len(elems) >= 2:<tab><tab><tab>#<tab><tab><tab><tab><tab>   print ""paternity of %d is %d"" % (int(elems[0]), int(elems[1]))<tab><tab><tab>parent_map[int(elems[0])] = int(elems[1])<tab><tab>else:<tab><tab><tab>print(""Odd paternity line '%s'"" % (line))<tab>return parent_map",1,if not line :,if not line :,0.75,100,1
def _get_next_cap(self):<tab># type: () -> bool<tab>self._curr_cap = None<tab>if self._curr_cap_idx is None:<tab><tab>self._curr_cap_idx = 0<tab><tab>self._curr_cap = self._cap_list[0]<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._end_of_video = True<tab><tab><tab>return False<tab><tab>self._curr_cap_idx += 1<tab><tab>self._curr_cap = self._cap_list[self._curr_cap_idx]<tab><tab>return True,0,if not ( self . _curr_cap_idx + 1 ) < len ( self . _cap_list ) :,if self . _curr_cap_idx >= len ( self . _cap_list ) :,0.569386651,63.82695247,0.319444444
"def decode_payload(args):<tab>try:<tab><tab>if args.token:<tab><tab><tab>token = args.token<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = sys.stdin.readline().strip()<tab><tab><tab>else:<tab><tab><tab><tab>raise IOError(""Cannot read from stdin: terminal not a TTY"")<tab><tab>token = token.encode(""utf-8"")<tab><tab>data = decode(token, key=args.key, verify=args.verify)<tab><tab>return json.dumps(data)<tab>except DecodeError as e:<tab><tab>raise DecodeError(""There was an error decoding the token: %s"" % e)",1,if sys . stdin . isatty ( ) :,if sys . stdin . isatty ( ) :,0.75,100,1
"def cell_double_clicked(self, row, column):<tab>if column == 3:<tab><tab>archive_name = self.selected_archive_name()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>mount_point = self.mount_points.get(archive_name)<tab><tab>if mount_point is not None:<tab><tab><tab>QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}""))",0,if not archive_name :,if archive_name is None :,0.045150551,27.77619034,0.36
"def tiles_around(self, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab><IF-STMT><tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab>if ny >= 0 and ny < self.height and (dx != 0 or dy != 0):<tab><tab><tab><tab><tab>if predicate is None or predicate((nx, ny)):<tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",1,if nx >= 0 and nx < self . width :,if nx >= 0 and nx < self . width :,1,100,1
"def __init__(self, type, data, name=None):<tab>Constant.__init__(self, type, data, name)<tab>self.tag.unique_value = None<tab>if isinstance(data, np.ndarray) and data.ndim > 0:<tab><tab>flat_data = data.ravel()<tab><tab>if flat_data.shape[0]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tag.unique_value = flat_data[0]",0,if ( flat_data == flat_data [ 0 ] ) . all ( ) :,if len ( flat_data ) == 1 :,0.019733693,14.92111565,0.333333333
"def git_convert_standalone_clone(repodir):<tab>""""""If specified directory is a git repository, ensure it's a standalone clone""""""<tab>import bb.process<tab>if os.path.exists(os.path.join(repodir, "".git"")):<tab><tab>alternatesfile = os.path.join(repodir, "".git"", ""objects"", ""info"", ""alternates"")<tab><tab><IF-STMT><tab><tab><tab># This will have been cloned with -s, so we need to convert it so none<tab><tab><tab># of the contents is shared<tab><tab><tab>bb.process.run(""git repack -a"", cwd=repodir)<tab><tab><tab>os.remove(alternatesfile)",0,if os . path . exists ( alternatesfile ) :,if os . path . exists ( alternatefile ) :,0.604939981,70.71067812,0.714285714
"def _rename_recipe_file(oldrecipe, bpn, oldpv, newpv, path):<tab>oldrecipe = os.path.basename(oldrecipe)<tab>if oldrecipe.endswith(""_%s.bb"" % oldpv):<tab><tab>newrecipe = ""%s_%s.bb"" % (bpn, newpv)<tab><tab><IF-STMT><tab><tab><tab>shutil.move(os.path.join(path, oldrecipe), os.path.join(path, newrecipe))<tab>else:<tab><tab>newrecipe = oldrecipe<tab>return os.path.join(path, newrecipe)",0,if oldrecipe != newrecipe :,"if os . path . exists ( os . path . join ( path , oldrecipe ) ) :",0.022212786,2.664321121,0.221153846
"def profiling_startup():<tab>if ""--profile-sverchok-startup"" in sys.argv:<tab><tab>global _profile_nesting<tab><tab>profile = None<tab><tab>try:<tab><tab><tab>profile = get_global_profile()<tab><tab><tab>_profile_nesting += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>profile.enable()<tab><tab><tab>yield profile<tab><tab>finally:<tab><tab><tab>_profile_nesting -= 1<tab><tab><tab>if _profile_nesting == 0 and profile is not None:<tab><tab><tab><tab>profile.disable()<tab><tab><tab>dump_stats(file_path=""sverchok_profile.txt"")<tab><tab><tab>save_stats(""sverchok_profile.prof"")<tab>else:<tab><tab>yield None",0,if _profile_nesting == 1 :,if _profile_nesting == 1 and profile is not None :,0.329550504,52.96074933,0.318181818
"def to_scaled_dtype(val):<tab>""""""Parse *val* to return a dtype.""""""<tab>res = []<tab>for i in val:<tab><tab><IF-STMT><tab><tab><tab>res.append((i[0], i[1]) + i[2:-1])<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>res.append((i[0], i[-1].dtype) + i[2:-1])<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>res.append((i[0], type(i[-1])) + i[2:-1])<tab>return np.dtype(res)",0,"if i [ 1 ] . startswith ( ""S"" ) :",if len ( i ) == 2 :,0.014690094,4.571221768,0.285714286
"def row(self, indx):<tab>if indx not in self.__rows:<tab><tab>if indx in self.__flushed_rows:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Attempt to reuse row index %d of sheet %r after flushing""<tab><tab><tab><tab>% (indx, self.__name)<tab><tab><tab>)<tab><tab>self.__rows[indx] = self.Row(indx, self)<tab><tab><IF-STMT><tab><tab><tab>self.last_used_row = indx<tab><tab>if indx < self.first_used_row:<tab><tab><tab>self.first_used_row = indx<tab>return self.__rows[indx]",1,if indx > self . last_used_row :,if indx > self . last_used_row :,0.75,100,1
"def _flow_open(self):<tab>rv = []<tab>for pipe in self.pipes:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""{pipe.__class__.__name__} pipe has double open methods.""<tab><tab><tab><tab>f"" Use `open` or `{self._method_open}`, not both.""<tab><tab><tab>)<tab><tab>if ""open"" in pipe._pipeline_all_methods_:<tab><tab><tab>rv.append(pipe.open)<tab><tab>if self._method_open in pipe._pipeline_all_methods_:<tab><tab><tab>rv.append(getattr(pipe, self._method_open))<tab>return rv",0,"if pipe . _pipeline_all_methods_ . issuperset ( { ""open"" , self . _method_open } ) :",if self . _method_open in pipe . _pipeline_all_methods_ :,0.124851585,44.81015633,0.333333333
"def _parse_output(output, strict=False):<tab>for pkg in _yum_pkginfo(output):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>repo_dict = ret.setdefault(pkg.repoid, {})<tab><tab>version_list = repo_dict.setdefault(pkg.name, set())<tab><tab>version_list.add(pkg.version)",0,"if strict and ( pkg . repoid not in repos or not _check_args ( args , pkg . name ) ) :","if strict and not pkg . name . endswith ( "".py"" ) :",0.042958972,10.73320363,0.288461538
"def user_defined_os():<tab>if menu.options.os:<tab><tab>if menu.options.os.lower() == ""windows"":<tab><tab><tab>settings.TARGET_OS = ""win""<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>err_msg = ""You specified wrong value '"" + menu.options.os + ""' ""<tab><tab><tab>err_msg += ""as an operation system. The value, must be 'Windows' or 'Unix'.""<tab><tab><tab>print(settings.print_critical_msg(err_msg))<tab><tab><tab>raise SystemExit()",1,"elif menu . options . os . lower ( ) == ""unix"" :","elif menu . options . os . lower ( ) == ""unix"" :",0.75,100,1
"def update(self, topLeft, bottomRight):<tab>if self._updating:<tab><tab># We are currently putting data in the model, so no updates<tab><tab>return<tab>if self._index:<tab><tab>if topLeft.row() <= self._index.row() <= bottomRight.row():<tab><tab><tab>self.updateText()<tab>elif self._indexes:<tab><tab>update = False<tab><tab>for i in self._indexes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>update = True<tab><tab>if update:<tab><tab><tab>self.updateText()",1,if topLeft . row ( ) <= i . row ( ) <= bottomRight . row ( ) :,if topLeft . row ( ) <= i . row ( ) <= bottomRight . row ( ) :,1,100,1
"def _wrapper(self, pipe, _should_terminate_flag, generator, *args, **kwargs):<tab>""""""Executed in background, pipes generator results to foreground""""""<tab>logger.debug(""Entering _wrapper"")<tab>try:<tab><tab>for datum in generator(*args, **kwargs):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise EarlyCancellationError(""Task was cancelled"")<tab><tab><tab>pipe.send(datum)<tab>except Exception as e:<tab><tab>if not isinstance(e, EarlyCancellationError):<tab><tab><tab>pipe.send(e)<tab><tab><tab>import traceback<tab><tab><tab>logger.warning(traceback.format_exc())<tab>else:<tab><tab>pipe.send(StopIteration())<tab>finally:<tab><tab>pipe.close()<tab><tab>logger.debug(""Exiting _wrapper"")",0,if _should_terminate_flag . value :,if not _should_terminate_flag :,0.039449619,56.48198098,0.5
"def _flatten(*args):<tab>arglist = []<tab>for arg in args:<tab><tab>if isinstance(arg, _Block):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>arglist.append(arg.vhdl_code)<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>arg = arg.subs<tab><tab>if id(arg) in _userCodeMap[""vhdl""]:<tab><tab><tab>arglist.append(_userCodeMap[""vhdl""][id(arg)])<tab><tab>elif isinstance(arg, (list, tuple, set)):<tab><tab><tab>for item in arg:<tab><tab><tab><tab>arglist.extend(_flatten(item))<tab><tab>else:<tab><tab><tab>arglist.append(arg)<tab>return arglist",1,if arg . vhdl_code is not None :,if arg . vhdl_code is not None :,0.75,100,1
"def _get_target_and_lun(self, context, volume):<tab>iscsi_target = 0<tab>if not self.target_name or not self._get_group():<tab><tab>lun = 1<tab><tab>return iscsi_target, lun<tab>luns = self._get_luns_info()<tab>if (not luns) or (luns[0] != 1):<tab><tab>lun = 1<tab><tab>return iscsi_target, lun<tab>else:<tab><tab>for lun in luns:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return iscsi_target, (lun + 1)",0,if ( luns [ - 1 ] == lun ) or ( luns [ lun - 1 ] + 1 != luns [ lun ] ) :,"if self . _get_target_lun ( context , volume , lun ) :",0.010033044,3.533987055,0.204678363
"def check_find(ref):<tab># Check find returns indexes for single point codes<tab>for c in set(m.used):<tab><tab>start = 0<tab><tab>u = m.text<tab><tab>while start < m.size:<tab><tab><tab>i = u.find(c, start)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.assertEqual(u[i], c)<tab><tab><tab>self.assertGreaterEqual(i, start)<tab><tab><tab>start = i + 1",0,if i < 0 :,if i == - 1 :,0.057429006,14.53576842,0.6
"def _format_column_list(self, data):<tab># Now we have all lis of columns which we need<tab># to include in our create definition, Let's format them<tab>if ""columns"" in data:<tab><tab>for c in data[""columns""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c[""attacl""] = parse_priv_to_db(c[""attacl""], self.column_acl)<tab><tab><tab># check type for '[]' in it<tab><tab><tab>if ""cltype"" in c:<tab><tab><tab><tab>c[""cltype""], c[""hasSqrBracket""] = column_utils.type_formatter(<tab><tab><tab><tab><tab>c[""cltype""]<tab><tab><tab><tab>)",1,"if ""attacl"" in c :","if ""attacl"" in c :",0.75,100,1
"def _animate_strategy(self, speed=1):<tab>if self._animating == 0:<tab><tab>return<tab>if self._apply_strategy() is not None:<tab><tab>if self._animate.get() == 0 or self._step.get() == 1:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self._root.after(3000, self._animate_strategy)<tab><tab>elif self._animate.get() == 2:<tab><tab><tab>self._root.after(1000, self._animate_strategy)<tab><tab>else:<tab><tab><tab>self._root.after(20, self._animate_strategy)",1,if self . _animate . get ( ) == 1 :,if self . _animate . get ( ) == 1 :,0.75,100,1
"def close_all(map=None, ignore_all=False):<tab>if map is None:  # pragma: no cover<tab><tab>map = socket_map<tab>for x in list(map.values()):  # list() FBO py3<tab><tab>try:<tab><tab><tab>x.close()<tab><tab>except OSError as x:<tab><tab><tab>if x.args[0] == EBADF:<tab><tab><tab><tab>pass<tab><tab><tab>el<IF-STMT><tab><tab><tab><tab>raise<tab><tab>except _reraised_exceptions:<tab><tab><tab>raise<tab><tab>except:<tab><tab><tab>if not ignore_all:<tab><tab><tab><tab>raise<tab>map.clear()",1,if not ignore_all :,if not ignore_all :,0.75,100,1
"def iter_imports(path):<tab>""""""Yield imports in *path*""""""<tab>for node in ast.parse(open(path, ""rb"").read()).body:<tab><tab>if isinstance(node, ast.ImportFrom):<tab><tab><tab>if node.module is None:<tab><tab><tab><tab>prefix = ()<tab><tab><tab>else:<tab><tab><tab><tab>prefix = tuple(node.module.split("".""))<tab><tab><tab>for snode in node.names:<tab><tab><tab><tab>yield (node.level, prefix + (snode.name,))<tab><tab><IF-STMT><tab><tab><tab>for node in node.names:<tab><tab><tab><tab>yield (0, tuple(node.name.split(""."")))",0,"elif isinstance ( node , ast . Import ) :","elif isinstance ( node , ast . ImportTo ) :",0.603553391,70.71067812,0.714285714
"def one_stage_eval_model(data_reader_eval, myModel, loss_criterion=None):<tab>score_tot = 0<tab>n_sample_tot = 0<tab>loss_tot = 0<tab>for idx, batch in enumerate(data_reader_eval):<tab><tab>score, loss, n_sample = compute_a_batch(<tab><tab><tab>batch, myModel, eval_mode=True, loss_criterion=loss_criterion<tab><tab>)<tab><tab>score_tot += score<tab><tab>n_sample_tot += n_sample<tab><tab><IF-STMT><tab><tab><tab>loss_tot += loss.data[0] * n_sample<tab>return score_tot / n_sample_tot, loss_tot / n_sample_tot, n_sample_tot",0,if loss is not None :,if idx % 2 == 0 :,0.023878899,6.567274736,0.2
"def _process_preproc(self, token, content):<tab>if self.state == ""include"":<tab><tab><IF-STMT><tab><tab><tab>content = content.strip().strip('""').strip(""<"").strip("">"").strip()<tab><tab><tab>self.append(content, truncate=True, separator=""/"")<tab><tab>self.state = None<tab>elif content.strip().startswith(""include""):<tab><tab>self.state = ""include""<tab>else:<tab><tab>self.state = None",0,"if content != ""\n"" and content != ""#"" :","if token . lower ( ) . endswith ( "">"" ) :",0.013622684,3.481501653,0.285714286
"def _aggregate_metadata_attribute(<tab>self, attr, agg_func=np.max, default_value=0, from_type_metadata=True):<tab>attr_values = []<tab>for a in self.appliances:<tab><tab>if from_type_metadata:<tab><tab><tab>attr_value = a.type.get(attr)<tab><tab>else:<tab><tab><tab>attr_value = a.metadata.get(attr)<tab><tab><IF-STMT><tab><tab><tab>attr_values.append(attr_value)<tab>if len(attr_values) == 0:<tab><tab>return default_value<tab>else:<tab><tab>return agg_func(attr_values)",1,if attr_value is not None :,if attr_value is not None :,0.75,100,1
"def _remove(self, item):<tab>""""""Internal removal of an item""""""<tab># Manage siblings when items are deleted<tab>for sibling in self.lines[self.lines.index(item) + 1 :]:<tab><tab>if isinstance(sibling, CronItem):<tab><tab><tab>env = sibling.env<tab><tab><tab>sibling.env = item.env<tab><tab><tab>sibling.env.update(env)<tab><tab><tab>sibling.env.job = sibling<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>self.lines.remove(sibling)<tab><tab>else:<tab><tab><tab>break<tab>self.crons.remove(item)<tab>self.lines.remove(item)<tab>return 1",0,"elif sibling == """" :",elif sibling in self . lines :,0.050762215,14.53576842,0.428571429
"def _validate_command_chain(self) -> None:<tab>""""""Validate command-chain names.""""""<tab># Would normally get caught/handled by schema validation.<tab>for command in self.command_chain:<tab><tab><IF-STMT><tab><tab><tab>raise HookValidationError(<tab><tab><tab><tab>hook_name=self.hook_name,<tab><tab><tab><tab>message=f""{command!r} is not a valid command-chain command."",<tab><tab><tab>)",0,"if not re . match ( ""^[A-Za-z0-9/._#:$-]*$"" , command ) :",if command not in self . command_chain :,0.114690094,1.199732892,0.25
"def _handle_unpaired_tag(self, html_tag):<tab>self.handle_ignore(html_tag, is_open=False)<tab>jannotations = self.read_jannotations(html_tag)<tab>for jannotation in arg_to_iter(jannotations):<tab><tab><IF-STMT><tab><tab><tab>self._close_unpaired_tag()<tab><tab>self.extra_required_attrs.extend(jannotation.pop(""required"", []))<tab><tab>annotation = self.build_annotation(jannotation)<tab><tab>self.handle_variant(annotation, is_open=False)<tab><tab>self.annotations.append(annotation)<tab>self.next_tag_index += 1",0,if self . unpairedtag_stack :,"if ""required"" in jannotation :",0.034123066,7.809849842,0.36
"def browser(self):<tab>if not hasattr(self, ""_browser""):<tab><tab>self.loop = asyncio.get_event_loop()<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Cannot use HTMLSession within an existing event loop. Use AsyncHTMLSession instead.""<tab><tab><tab>)<tab><tab>self._browser = self.loop.run_until_complete(super().browser)<tab>return self._browser",0,if self . loop . is_running ( ) :,if self . loop . get_debug ( ) :,0.549889319,48.32697831,1
"def process(self, node):<tab>self.vars = []<tab>for child in node.childNodes:<tab><tab>if child.nodeType == node.ELEMENT_NODE:<tab><tab><tab>child_text = get_xml_text(child)<tab><tab><tab><IF-STMT>  # pragma:nocover<tab><tab><tab><tab>continue<tab><tab><tab>if child.nodeName == ""Real"":<tab><tab><tab><tab>for val in re.split(""[\t ]+"", child_text):<tab><tab><tab><tab><tab>self.vars.append(1.0 * eval(val))<tab>return self",0,"if child_text == """" :",if not child_text :,0.039449619,20.82186541,0.619047619
"def instantiate(self, node, container=None):<tab>var = self.vm.program.NewVariable()<tab>if container and (<tab><tab>not isinstance(container, SimpleValue)<tab><tab>or self.full_name in container.all_template_names<tab>):<tab><tab>instance = TypeParameterInstance(self, container, self.vm)<tab><tab>return instance.to_variable(node)<tab>else:<tab><tab>for c in self.constraints:<tab><tab><tab>var.PasteVariable(c.instantiate(node, container))<tab><tab><IF-STMT><tab><tab><tab>var.PasteVariable(self.bound.instantiate(node, container))<tab>if not var.bindings:<tab><tab>var.AddBinding(self.vm.convert.unsolvable, [], node)<tab>return var",0,if self . bound :,if self . bound is not None :,0.351498834,36.55552229,0.510204082
"def compare_tables(self, db1, db2):<tab>i1 = db1.query(""SELECT id, buf FROM test ORDER BY id"")<tab>i2 = db2.query(""SELECT id, buf FROM test ORDER BY id"")<tab>for (id1, buf1) in i1:<tab><tab>(id2, buf2) = next(i2)<tab><tab>self.assertEqual(id1, id2)<tab><tab><IF-STMT><tab><tab><tab>self.assertAlmostEqual(buf1, buf2, places=9)<tab><tab>else:<tab><tab><tab>self.assertEqual(buf1, buf2)<tab>self.assertRaises(StopIteration, i2.__next__)",0,"if isinstance ( buf1 , float ) :","if isinstance ( buf1 , int ) and isinstance ( buf2 , int ) :",0.210692462,28.29559628,0.430555556
"def list_full_file_paths(directory):<tab>""""""List the absolute paths of files in |directory|.""""""<tab>directory_absolute_path = os.path.abspath(directory)<tab>paths = []<tab>for relative_path in os.listdir(directory):<tab><tab>absolute_path = os.path.join(directory_absolute_path, relative_path)<tab><tab><IF-STMT>  # Only return paths to files.<tab><tab><tab>paths.append(absolute_path)<tab>return paths",0,if os . path . isfile ( absolute_path ) :,if os . path . isdir ( absolute_path ) :,0.580308871,73.48889201,0.666666667
"def reparentChildren(self, newParent):<tab>while self.element.contents:<tab><tab>child = self.element.contents[0]<tab><tab>child.extract()<tab><tab><IF-STMT><tab><tab><tab>newParent.appendChild(Element(child, self.soup, namespaces[""html""]))<tab><tab>else:<tab><tab><tab>newParent.appendChild(TextNode(child, self.soup))",0,"if isinstance ( child , Tag ) :","if self . element . name == ""html"" :",0.016949751,4.027248192,0.25
"def sort(self):<tab>sorted_models = []<tab>concrete_models = set()<tab>models = list(self.data)<tab>while len(sorted_models) < len(models):<tab><tab>found = False<tab><tab>for model in models:<tab><tab><tab>if model in sorted_models:<tab><tab><tab><tab>continue<tab><tab><tab>dependencies = self.dependencies.get(model._meta.concrete_model)<tab><tab><tab>if not (dependencies and dependencies.difference(concrete_models)):<tab><tab><tab><tab>sorted_models.append(model)<tab><tab><tab><tab>concrete_models.add(model._meta.concrete_model)<tab><tab><tab><tab>found = True<tab><tab><IF-STMT><tab><tab><tab>return<tab>self.data = OrderedDict((model, self.data[model]) for model in sorted_models)",1,if not found :,if not found :,0.75,100,1
"def template(self):<tab>""""""template property""""""<tab>if self._template is None:<tab><tab>results = self._process(self.name, False, self.params, self.data)<tab><tab><IF-STMT><tab><tab><tab>raise OpenShiftCLIError(<tab><tab><tab><tab>""Error processing template [%s]: %s"" % (self.name, results)<tab><tab><tab>)<tab><tab>self._template = results[""results""][""items""]<tab>return self._template",0,"if results [ ""returncode"" ] != 0 :","if ""results"" not in results :",0.019830745,5.675573555,0.314814815
"def edit_file(self, filename):<tab>import subprocess<tab>editor = self.get_editor()<tab>if self.env:<tab><tab>environ = os.environ.copy()<tab><tab>environ.update(self.env)<tab>else:<tab><tab>environ = None<tab>try:<tab><tab>c = subprocess.Popen('%s ""%s""' % (editor, filename), env=environ, shell=True)<tab><tab>exit_code = c.wait()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""%s: Editing failed!"" % editor)<tab>except OSError as e:<tab><tab>raise Exception(""%s: Editing failed: %s"" % (editor, e))",1,if exit_code != 0 :,if exit_code != 0 :,0.75,100,1
"def test01e_json(self):<tab>""Testing GeoJSON input/output.""<tab>from django.contrib.gis.gdal.prototypes.geom import GEOJSON<tab>if not GEOJSON:<tab><tab>return<tab>for g in self.geometries.json_geoms:<tab><tab>geom = OGRGeometry(g.wkt)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(g.json, geom.json)<tab><tab><tab>self.assertEqual(g.json, geom.geojson)<tab><tab>self.assertEqual(OGRGeometry(g.wkt), OGRGeometry(geom.json))",0,"if not hasattr ( g , ""not_equal"" ) :","if hasattr ( geom , ""geojson"" ) :",0.040847398,17.58466167,0.318181818
"def debug(self):<tab>feed_dict = self.get_test_feed_dict()<tab>while True:<tab><tab>tensor_name = input(""Input debug tensor name: "").strip()<tab><tab><IF-STMT><tab><tab><tab>sys.exit(0)<tab><tab>try:<tab><tab><tab>debug_tensor = self.graph.get_tensor_by_name(tensor_name)<tab><tab>except Exception as e:<tab><tab><tab>logging.error(e)<tab><tab><tab>continue<tab><tab>res = self.sess.run(debug_tensor, feed_dict=feed_dict)<tab><tab>logging.info(f""Result for tensor {tensor_name} is: {res}"")",0,"if tensor_name == ""q"" :","if tensor_name == """" :",0.394778655,71.89393375,1
"def get_location(self, dist, dependency_links):<tab>for url in dependency_links:<tab><tab>egg_fragment = Link(url).egg_fragment<tab><tab>if not egg_fragment:<tab><tab><tab>continue<tab><tab>if ""-"" in egg_fragment:<tab><tab><tab>## FIXME: will this work when a package has - in the name?<tab><tab><tab>key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower()<tab><tab>else:<tab><tab><tab>key = egg_fragment<tab><tab><IF-STMT><tab><tab><tab>return url.split(""#"", 1)[0]<tab>return None",0,if key == dist . key :,if key == dist :,0.230930265,56.98363775,0.880952381
"def select(result):<tab>for elem in result:<tab><tab>parent = elem.getparent()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab># FIXME: what if the selector is ""*"" ?<tab><tab><tab>elems = list(parent.iterchildren(elem.tag))<tab><tab><tab>if elems[index] is elem:<tab><tab><tab><tab>yield elem<tab><tab>except IndexError:<tab><tab><tab>pass",1,if parent is None :,if parent is None :,0.75,100,1
"def execute(self, cmd):<tab>mark = utils.random_text(32)<tab>path = ""/cgi-bin/gdrive.cgi?cmd=4&f_gaccount=;{};echo {};"".format(cmd, mark)<tab>response = self.http_request(<tab><tab>method=""GET"",<tab><tab>path=path,<tab>)<tab>if response is None:<tab><tab>return """"<tab>if mark in response.text:<tab><tab>regexp = ""(|.+?){}"".format(mark)<tab><tab>res = re.findall(regexp, response.text, re.DOTALL)<tab><tab><IF-STMT><tab><tab><tab>return res[0]<tab>return """"",1,if len ( res ) :,if len ( res ) :,0.75,100,1
"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab>if (not s) or isabs(t):<tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>t = t[1:]<tab><tab>if "":"" not in path:<tab><tab><tab>path = "":"" + path<tab><tab>if path[-1:] != "":"":<tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path",0,"if t [ : 1 ] == "":"" :","if t [ 0 ] == "":"" :",0.22052702,64.07117598,0.6
"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab>if not self.pid:<tab><tab><tab>pid = read_pid_file(""/var/run/udhcpd.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")",0,"if not kill ( pid , ""udhcpd"" ) :",if pid == self . pid :,0.017062029,4.995138898,0.444444444
"def filter_packages(query, package_infos):<tab>if query is None:<tab><tab>return package_infos<tab>try:<tab><tab>if ""!"" in query:<tab><tab><tab>raise ConanException(""'!' character is not allowed"")<tab><tab>if "" not "" in query or query.startswith(""not ""):<tab><tab><tab>raise ConanException(""'not' operator is not allowed"")<tab><tab>postfix = infix_to_postfix(query) if query else []<tab><tab>result = OrderedDict()<tab><tab>for package_id, info in package_infos.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[package_id] = info<tab><tab>return result<tab>except Exception as exc:<tab><tab>raise ConanException(""Invalid package query: %s. %s"" % (query, exc))",0,"if _evaluate_postfix_with_info ( postfix , info ) :",if info not in postfix :,0.020894909,2.561254039,0.291666667
"def __add__(self, other):<tab>if isinstance(other, Vector3):<tab><tab># Vector + Vector -> Vector<tab><tab># Vector + Point -> Point<tab><tab># Point + Point -> Vector<tab><tab><IF-STMT><tab><tab><tab>_class = Vector3<tab><tab>else:<tab><tab><tab>_class = Point3<tab><tab>return _class(self.x + other.x, self.y + other.y, self.z + other.z)<tab>else:<tab><tab>assert hasattr(other, ""__len__"") and len(other) == 3<tab><tab>return Vector3(self.x + other[0], self.y + other[1], self.z + other[2])",1,if self . __class__ is other . __class__ :,if self . __class__ is other . __class__ :,0.75,100,1
"def test_scout():<tab>test_status = False<tab>with open(""/tmp/test_scout_output"", ""w"") as logfile:<tab><tab>if not DockerImage:<tab><tab><tab>logfile.write(""No $AMBASSADOR_DOCKER_IMAGE??\n"")<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if wait_for_diagd(logfile) and check_chimes(logfile):<tab><tab><tab><tab><tab>test_status = True<tab><tab><tab><tab>docker_kill(logfile)<tab>if not test_status:<tab><tab>with open(""/tmp/test_scout_output"", ""r"") as logfile:<tab><tab><tab>for line in logfile:<tab><tab><tab><tab>print(line.rstrip())<tab>assert test_status, ""test failed""",0,if docker_start ( logfile ) :,"if os . path . exists ( ""/tmp/test_scout"" ) :",0.040133529,5.75139181,0.30952381
"def visit_Assign(self, node):<tab>""""""Handle visiting an assignment statement.""""""<tab>ups = set()<tab>for targ in node.targets:<tab><tab>if isinstance(targ, (Tuple, List)):<tab><tab><tab>ups.update(leftmostname(elt) for elt in targ.elts)<tab><tab><IF-STMT><tab><tab><tab>newnode = self.try_subproc_toks(node)<tab><tab><tab>if newnode is node:<tab><tab><tab><tab>ups.add(leftmostname(targ))<tab><tab><tab>else:<tab><tab><tab><tab>return newnode<tab><tab>else:<tab><tab><tab>ups.add(leftmostname(targ))<tab>self.ctxupdate(ups)<tab>return node",0,"elif isinstance ( targ , BinOp ) :","elif isinstance ( targ , Symbol ) :",0.547301779,59.46035575,0.666666667
"def get_config_h_filename():<tab>""""""Returns the path of pyconfig.h.""""""<tab>if _PYTHON_BUILD:<tab><tab># The additional check for != ""java"" secures against JyNI-monkeypatching.<tab><tab><IF-STMT><tab><tab><tab>inc_dir = os.path.join(_PROJECT_BASE, ""PC"")<tab><tab>else:<tab><tab><tab>inc_dir = _PROJECT_BASE<tab>else:<tab><tab>inc_dir = get_path(""platinclude"")<tab>return os.path.join(inc_dir, ""pyconfig.h"")",0,"if os . name == ""nt"" and os . name != ""java"" :",if os . path . exists ( _PROJECT_BASE ) :,0.081354442,8.235113196,0.363095238
"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",0,if self . block . pos . x + i >= COLUMNS :,if self . block . pos . y + i < 0 :,0.376663036,49.48748923,0.6
"def __call__(self, execution_result):<tab>json_value = execution_result.get_output_in_json()<tab>actual_result = jmespath.search(<tab><tab>self._query, json_value, jmespath.Options(collections.OrderedDict)<tab>)<tab>if not actual_result > self._expected_result:<tab><tab>expected_result_format = ""> {}"".format(self._expected_result)<tab><tab><IF-STMT><tab><tab><tab>raise JMESPathCheckAssertionError(<tab><tab><tab><tab>self._query,<tab><tab><tab><tab>expected_result_format,<tab><tab><tab><tab>actual_result,<tab><tab><tab><tab>execution_result.output,<tab><tab><tab>)<tab><tab>raise JMESPathCheckAssertionError(<tab><tab><tab>self._query, expected_result_format, ""None"", execution_result.output<tab><tab>)",0,if actual_result :,if actual_result != self . _expected_result :,0.085805078,1.00E-10,0.636363636
def readline(b):<tab>a = 1<tab>while True:<tab><tab>if b:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>a = 2<tab><tab><tab><tab>b = None<tab><tab><tab><tab>continue<tab><tab>b = None<tab><tab>a = 5<tab><tab>return a,0,if b [ 0 ] :,"if b [ 0 ] == ""\n"" :",0.417421583,33.18077403,1
"def test_execute_magic(self):<tab>""""""execute accepts IPython commands""""""<tab>view = self.client[:]<tab>view.execute(""a = 5"")<tab>ar = view.execute(""%whos"", block=True)<tab># this will raise, if that failed<tab>ar.get(5)<tab>for stdout in ar.stdout:<tab><tab>lines = stdout.splitlines()<tab><tab>self.assertEqual(lines[0].split(), [""Variable"", ""Type"", ""Data/Info""])<tab><tab>found = False<tab><tab>for line in lines[2:]:<tab><tab><tab>split = line.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab>self.assertTrue(found, ""whos output wrong: %s"" % stdout)",0,"if split == [ ""a"" , ""int"" , ""5"" ] :",if len ( split ) == 2 :,0.014083697,4.410929086,0.375
"def imgFileProcessingTick(output):<tab>if isinstance(output, tuple):<tab><tab>workerOutput.append(output)<tab><tab>workerPool.terminate()<tab>else:<tab><tab>for page in output:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>options.imgMetadata[page[0]] = page[1]<tab><tab><tab><tab>options.imgOld.append(page[2])<tab>if GUI:<tab><tab>GUI.progressBarTick.emit(""tick"")<tab><tab>if not GUI.conversionAlive:<tab><tab><tab>workerPool.terminate()",0,if page is not None :,if len ( page ) == 3 :,0.023749772,6.274655311,0.232142857
"def _load(xs):<tab>ret = []<tab>for x, ctx in zip(xs, context):<tab><tab><IF-STMT><tab><tab><tab>ret.append([y.as_in_context(ctx) for y in x])<tab><tab>else:<tab><tab><tab>ret.append(x.as_in_context(ctx))<tab>return ret",0,"if isinstance ( x , tuple ) :","if isinstance ( x , ( list , tuple ) ) :",0.28982004,44.06719358,0.655555556
"def _is_64bit_os():<tab>global _IS_64BIT_OS<tab>if _IS_64BIT_OS is None:<tab><tab><IF-STMT><tab><tab><tab>import platform<tab><tab><tab>_IS_64BIT_OS = platform.machine() == ""AMD64""<tab><tab>else:<tab><tab><tab>_IS_64BIT_OS = False<tab>return _IS_64BIT_OS",0,if sys . maxsize > 2 ** 32 :,"if os . name == ""nt"" :",0.058728695,5.522397784,0.225
"def stepStarted(self, step):<tab>self.currentStep = step<tab>for w in self.watchers:<tab><tab>receiver = w.stepStarted(self, step)<tab><tab>if receiver:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>step.subscribe(receiver[0], receiver[1])<tab><tab><tab>else:<tab><tab><tab><tab>step.subscribe(receiver)<tab><tab><tab>d = step.waitUntilFinished()<tab><tab><tab># TODO: This actually looks like a bug, but this code<tab><tab><tab># will be removed anyway.<tab><tab><tab># pylint: disable=cell-var-from-loop<tab><tab><tab>d.addCallback(lambda step: step.unsubscribe(receiver))<tab>step.waitUntilFinished().addCallback(self._stepFinished)",0,"if isinstance ( receiver , type ( ( ) ) ) :","if isinstance ( receiver , tuple ) :",0.185140783,36.0645288,0.666666667
"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab>if self._bulk_commit:<tab><tab><tab>if self._pending_connection is None:<tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab><IF-STMT><tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab>if not self._bulk_commit:<tab><tab><tab><tab>con.close()",0,if commit_on_success and self . can_commit :,if commit_on_success :,0.038857533,1.00E-10,0.45
"def parse_response(self, response):<tab># read response data from httpresponse, and parse it<tab># Check for new http response object, otherwise it is a file object.<tab>if hasattr(response, ""getheader""):<tab><tab>if response.getheader(""Content-Encoding"", """") == ""gzip"":<tab><tab><tab>stream = GzipDecodedResponse(response)<tab><tab>else:<tab><tab><tab>stream = response<tab>else:<tab><tab>stream = response<tab>p, u = self.getparser()<tab>while 1:<tab><tab>data = stream.read(1024)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if self.verbose:<tab><tab><tab>print(""body:"", repr(data))<tab><tab>p.feed(data)<tab>if stream is not response:<tab><tab>stream.close()<tab>p.close()<tab>return u.close()",1,if not data :,if not data :,0.75,100,1
"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab>if i[0] == nto:<tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab><IF-STMT><tab><tab><tab>return ""?""<tab><tab>elif nfrom.src1 == nto:<tab><tab><tab>return ""True""<tab><tab>elif nfrom.src2 == nto:<tab><tab><tab>return ""False""<tab>return """"",0,if nfrom . cond == nto :,if nfrom . src1 == nto :,0.38848939,50,0.666666667
"def gather_command_line_options(filter_disabled=None):<tab>""""""Get a sorted list of all CommandLineOption subclasses.""""""<tab>if filter_disabled is None:<tab><tab>filter_disabled = not SETTINGS.COMMAND_LINE.SHOW_DISABLED_OPTIONS<tab>options = []<tab>for opt in get_inheritors(commandline_options.CommandLineOption):<tab><tab>warnings.warn(<tab><tab><tab>""Subclassing `CommandLineOption` is deprecated. Please ""<tab><tab><tab>""use the `sacred.cli_option` decorator and pass the function ""<tab><tab><tab>""to the Experiment constructor.""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>options.append(opt)<tab>options += DEFAULT_COMMAND_LINE_OPTIONS<tab>return sorted(options, key=commandline_options.get_name)",0,if filter_disabled and not opt . _enabled :,if filter_disabled and opt . disabled :,0.218065587,42.50083659,0.5
"def handle_disconnect(self):<tab>""""""Socket gets disconnected""""""<tab># signal disconnected terminal with control lines<tab>try:<tab><tab>self.serial.rts = False<tab><tab>self.serial.dtr = False<tab>finally:<tab><tab># restore original port configuration in case it was changed<tab><tab>self.serial.apply_settings(self.serial_settings_backup)<tab><tab># stop RFC 2217 state machine<tab><tab>self.rfc2217 = None<tab><tab># clear send buffer<tab><tab>self.buffer_ser2net = bytearray()<tab><tab># close network connection<tab><tab>if self.socket is not None:<tab><tab><tab>self.socket.close()<tab><tab><tab>self.socket = None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.warning(""{}: Disconnected"".format(self.device))",0,if self . log is not None :,if self . debug :,0.120555985,23.45000811,0.321428571
"def answers(self, other):<tab>if not isinstance(other, TCP):<tab><tab>return 0<tab>if conf.checkIPsrc:<tab><tab>if not ((self.sport == other.sport) and (self.dport == other.dport)):<tab><tab><tab>return 0<tab>if conf.check_TCPerror_seqack:<tab><tab>if self.seq is not None:<tab><tab><tab>if self.seq != other.seq:<tab><tab><tab><tab>return 0<tab><tab><IF-STMT><tab><tab><tab>if self.ack != other.ack:<tab><tab><tab><tab>return 0<tab>return 1",1,if self . ack is not None :,if self . ack is not None :,0.75,100,1
"def _override_options(options, **overrides):<tab>""""""Override options.""""""<tab>for opt, val in overrides.items():<tab><tab>passed_value = getattr(options, opt, _Default())<tab><tab><IF-STMT><tab><tab><tab>value = process_value(opt, passed_value.value)<tab><tab><tab>value += process_value(opt, val)<tab><tab><tab>setattr(options, opt, value)<tab><tab>elif isinstance(passed_value, _Default):<tab><tab><tab>setattr(options, opt, process_value(opt, val))",0,"if opt in ( ""ignore"" , ""select"" ) and passed_value :","if isinstance ( passed_value , _Default ) :",0.015224515,10.33244976,0.3125
"def _unlock_restarted_vms(self, pool_name):<tab>result = []<tab>for vm in await self.middleware.call(""vm.query"", [(""autostart"", ""="", True)]):<tab><tab>for device in vm[""devices""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>path = device[""attributes""].get(""path"")<tab><tab><tab>if not path:<tab><tab><tab><tab>continue<tab><tab><tab>if path.startswith(f""/dev/zvol/{pool_name}/"") or path.startswith(<tab><tab><tab><tab>f""/mnt/{pool_name}/""<tab><tab><tab>):<tab><tab><tab><tab>result.append(vm)<tab><tab><tab><tab>break<tab>return result",0,"if device [ ""dtype"" ] not in ( ""DISK"" , ""RAW"" ) :","if ""name"" not in device :",0.019639232,3.819616671,0.4
"def check_space(arr, task_id):<tab>for a in arr:<tab><tab><IF-STMT><tab><tab><tab>found = False<tab><tab><tab>for x in shlex.split(a):<tab><tab><tab><tab>if task_id in x:<tab><tab><tab><tab><tab>found = True<tab><tab><tab>if not found:<tab><tab><tab><tab>raise AssertionError",0,"if a . startswith ( ""hadoop jar"" ) :",if a :,0.024814633,1.00E-10,0.730769231
"def clean(self):<tab>if self.instance:<tab><tab>redirect_to = self.data.get(""redirect_to"", """")<tab><tab>if redirect_to != """":<tab><tab><tab>lfs.core.utils.set_redirect_for(<tab><tab><tab><tab>self.instance.get_absolute_url(), redirect_to<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>lfs.core.utils.remove_redirect_for(self.instance.get_absolute_url())<tab>if self.data.get(""active_base_price"") == str(CHOICES_YES):<tab><tab><IF-STMT><tab><tab><tab>self.errors[""base_price_amount""] = ErrorList(<tab><tab><tab><tab>[_(u""This field is required."")]<tab><tab><tab>)<tab>return self.cleaned_data",0,"if self . data . get ( ""base_price_amount"" , """" ) == """" :",if self . errors :,0.033017409,1.167507157,0.492063492
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""\AAL[_-]?(SESS|LB)="", headers.get(HTTP_HEADER.SET_COOKIE, """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.531170663,1.00E-10,1
"def unloadOnePlugin(self, moduleOrFileName, verbose=False):<tab>moduleName = self.regularizeName(moduleOrFileName)<tab>if self.isLoaded(moduleName):<tab><tab><IF-STMT><tab><tab><tab>g.pr(""unloading"", moduleName)<tab><tab>del self.loadedModules[moduleName]<tab>for tag in self.handlers:<tab><tab>bunches = self.handlers.get(tag)<tab><tab>bunches = [bunch for bunch in bunches if bunch.moduleName != moduleName]<tab><tab>self.handlers[tag] = bunches",1,if verbose :,if verbose :,0.531170663,1.00E-10,1
"def __init__(self, **kw):<tab>util_schema.validate(<tab><tab>instance=kw,<tab><tab>schema=self.schema,<tab><tab>cls=util_schema.CustomValidator,<tab><tab>use_default=False,<tab><tab>allow_default_none=True,<tab>)<tab>for prop in six.iterkeys(self.schema.get(""properties"", [])):<tab><tab>value = kw.get(prop, None)<tab><tab># special handling for chain property to create the Node object<tab><tab><IF-STMT><tab><tab><tab>nodes = []<tab><tab><tab>for node in value:<tab><tab><tab><tab>ac_node = Node(**node)<tab><tab><tab><tab>ac_node.validate()<tab><tab><tab><tab>nodes.append(ac_node)<tab><tab><tab>value = nodes<tab><tab>setattr(self, prop, value)",0,"if prop == ""chain"" :",if value is not None :,0.030286783,6.916271813,0.2
"def initialize(self):<tab>for document in self.corpus:<tab><tab>frequencies = {}<tab><tab>for word in document:<tab><tab><tab>if word not in frequencies:<tab><tab><tab><tab>frequencies[word] = 0<tab><tab><tab>frequencies[word] += 1<tab><tab>self.f.append(frequencies)<tab><tab>for word, freq in iteritems(frequencies):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.df[word] = 0<tab><tab><tab>self.df[word] += 1<tab>for word, freq in iteritems(self.df):<tab><tab>self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)",1,if word not in self . df :,if word not in self . df :,0.75,100,1
"def get_child(self, name):<tab>if self.isdir:<tab><tab>try:<tab><tab><tab>return self.data[name]<tab><tab>except:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for childname, child in list(self.data.items()):<tab><tab><tab><tab><tab>if childname.lower() == name.lower():<tab><tab><tab><tab><tab><tab>return child<tab><tab><tab>raise",0,if not self . case_sensitive :,if name in self . data :,0.047631794,13.54037246,0.238095238
"def set_cover(channel, pixbuf):<tab>if self.channel == channel:<tab><tab><IF-STMT><tab><tab><tab>self.imgCover.set_from_pixbuf(self.scale_pixbuf(pixbuf))<tab><tab>if self.show_on_cover_load:<tab><tab><tab>self.main_window.show()<tab><tab><tab>self.show_on_cover_load = False",1,if pixbuf is not None :,if pixbuf is not None :,0.75,100,1
"def test_infer_shape_matrix(self):<tab># Testing the infer_shape with a matrix.<tab>x = theano.tensor.matrix()<tab>for op in self.ops:<tab><tab>if not op.return_inverse:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>f = op(x)[2]<tab><tab>else:<tab><tab><tab>f = op(x)[1]<tab><tab>self._compile_and_check(<tab><tab><tab>[x],<tab><tab><tab>[f],<tab><tab><tab>[np.asarray(np.array([[2, 1], [3, 2], [2, 3]]), dtype=config.floatX)],<tab><tab><tab>self.op_class,<tab><tab>)",0,if op . return_index :,elif op . return_inverse :,0.058575651,43.47208719,0.5
"def Filter(self, match=None, **_):<tab>""""""Filter the current expression.""""""<tab>arg = self.stack.pop(-1)<tab># Filters can be specified as a comma separated list.<tab>for filter_name in match.group(1).split("",""):<tab><tab>filter_object = ConfigFilter.classes_by_name.get(filter_name)<tab><tab>if filter_object is None:<tab><tab><tab>raise FilterError(""Unknown filter function %r"" % filter_name)<tab><tab><IF-STMT><tab><tab><tab>logging.debug(""Applying filter %s for %s."", filter_name, arg)<tab><tab>arg = filter_object().Filter(arg)<tab><tab>precondition.AssertType(arg, Text)<tab>self.stack[-1] += arg",0,if not filter_object . sensitive_arg :,"if hasattr ( filter_object , ""Filter"" ) :",0.023749772,14.32314508,0.5
"def enqueue_link(self, fuzzresult, link_url, parsed_link):<tab># dir path<tab>if self.add_path:<tab><tab>split_path = parsed_link.path.split(""/"")<tab><tab>newpath = ""/"".join(split_path[:-1]) + ""/""<tab><tab>self.queue_url(urljoin(fuzzresult.url, newpath))<tab># file path<tab>new_link = urljoin(fuzzresult.url, link_url)<tab>if not self.regex_param or (<tab><tab>self.regex_param and self.regex_param.search(new_link) is not None<tab>):<tab><tab><IF-STMT><tab><tab><tab>self.queue_url(new_link)<tab><tab>self.add_result(""link"", ""New link found"", new_link)",0,if self . enqueue_links :,if self . regex_param and self . regex_param . search ( new_link ) is not None :,0.17196978,6.9645418,0.302083333
"def old_save(self, *args, **kwargs):<tab>""Override save to set Subscribers and send Notifications""<tab>original = None<tab>original_assigned = []<tab>if hasattr(self, ""instance""):<tab><tab>try:<tab><tab><tab>original = Task.objects.get(pk=self.instance.id)<tab><tab><tab>original_assigned = list(original.assigned.all())<tab><tab>except Task.DoesNotExist:<tab><tab><tab>pass<tab>instance = super(TaskForm, self).save(*args, **kwargs)<tab>if original:<tab><tab>new_assigned = list(self.cleaned_data[""assigned""])<tab><tab><IF-STMT><tab><tab><tab>for assignee in new_assigned:<tab><tab><tab><tab>self.instance.subscribers.add(assignee)<tab>return instance",0,if original_assigned != new_assigned :,if new_assigned :,0.067674239,1.00E-10,1
"def get_test_layer():<tab>layers = get_bb_var(""BBLAYERS"").split()<tab>testlayer = None<tab>for l in layers:<tab><tab>if ""~"" in l:<tab><tab><tab>l = os.path.expanduser(l)<tab><tab><IF-STMT><tab><tab><tab>testlayer = l<tab><tab><tab>break<tab>return testlayer",0,"if ""/meta-selftest"" in l and os . path . isdir ( l ) :",if os . path . isfile ( l ) :,0.184926168,26.8693503,0.2
"def readable(request):<tab>""""""Display a readable version of this url if we can""""""<tab>rdict = request.matchdict<tab>bid = rdict.get(""hash_id"", None)<tab>username = rdict.get(""username"", None)<tab>if bid:<tab><tab>found = BmarkMgr.get_by_hash(bid, username=username)<tab><tab><IF-STMT><tab><tab><tab>return {<tab><tab><tab><tab>""bmark"": found,<tab><tab><tab><tab>""username"": username,<tab><tab><tab>}<tab><tab>else:<tab><tab><tab>return HTTPNotFound()",1,if found :,if found :,0.531170663,1.00E-10,1
"def pythonpath(conanfile):<tab>python_path = conanfile.env.get(""PYTHONPATH"", None)<tab>if python_path:<tab><tab>old_path = sys.path[:]<tab><tab><IF-STMT><tab><tab><tab>sys.path.extend(python_path)<tab><tab>else:<tab><tab><tab>sys.path.append(python_path)<tab><tab>yield<tab><tab>sys.path = old_path<tab>else:<tab><tab>yield",0,"if isinstance ( python_path , list ) :",if sys . path . endswith ( python_path ) :,0.039668305,26.20251007,0.274725275
"def _validate(self):<tab>on_target_delete = None<tab>for cmd in self.val.commands:<tab><tab>if isinstance(cmd, qlast.OnTargetDelete):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise errors.EdgeQLSyntaxError(<tab><tab><tab><tab><tab>f""more than one 'on target delete' specification"",<tab><tab><tab><tab><tab>context=cmd.context,<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>on_target_delete = cmd",0,if on_target_delete :,if cmd . on_target_delete :,0.097914534,1.00E-10,0.619047619
"def _choose_instance(self, timeout_time):<tab>""""""Returns an Instance to handle a request or None if all are busy.""""""<tab>with self._condition:<tab><tab>while time.time() < timeout_time and not self._quit_event.is_set():<tab><tab><tab>for inst in self._instances:<tab><tab><tab><tab>if inst.can_accept_requests:<tab><tab><tab><tab><tab>return inst<tab><tab><tab>else:<tab><tab><tab><tab>inst = self._start_any_instance()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>self._condition.wait(timeout_time - time.time())<tab><tab>else:<tab><tab><tab>return None<tab>if inst:<tab><tab>inst.wait(timeout_time)<tab>return inst",0,if inst :,if inst is None :,0.097914534,1.00E-10,0.5
"def get_identifiers(self):<tab>ids = []<tab>for entry in glob.glob(f""{self._base_path}/ctl-*""):<tab><tab>ident = entry.split(""-"", 1)[-1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if os.path.exists(os.path.join(entry, ""disk_octets.rrd"")):<tab><tab><tab>ids.append(ident)<tab>ids.sort(key=RRDBase._sort_ports)<tab>return ids",0,"if ident . endswith ( ""ioctl"" ) :",if not ident :,0.019930836,4.690733795,0.4
"def read_vocab_list(path, max_vocab_size=20000):<tab>vocab = {""<eos>"": 0, ""<unk>"": 1}<tab>with io.open(path, encoding=""utf-8"", errors=""ignore"") as f:<tab><tab>for l in f:<tab><tab><tab>w = l.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vocab[w] = len(vocab)<tab><tab><tab>if len(vocab) >= max_vocab_size:<tab><tab><tab><tab>break<tab>return vocab",0,if w not in vocab and w :,if w :,0.036515428,1.00E-10,0.278911565
"def n_import_from(self, node):<tab>relative_path_index = 0<tab>if self.version >= 2.5:<tab><tab>if node[relative_path_index].pattr > 0:<tab><tab><tab>node[2].pattr = (""."" * node[relative_path_index].pattr) + node[2].pattr<tab><tab>if self.version > 2.7:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>imports = node[1].pattr<tab><tab><tab><tab>for pattr in imports:<tab><tab><tab><tab><tab>node[1].pattr = pattr<tab><tab><tab><tab><tab>self.default(node)<tab><tab><tab><tab>return<tab><tab><tab>pass<tab>self.default(node)",0,"if isinstance ( node [ 1 ] . pattr , tuple ) :",if node [ 1 ] . pattr > 0 :,0.292026608,41.15421581,0.241666667
"def get(self):<tab>""""""Returns a simple HTML for contact form""""""<tab>if self.user:<tab><tab>user_info = models.User.get_by_id(long(self.user_id))<tab><tab><IF-STMT><tab><tab><tab>self.form.name.data = user_info.name + "" "" + user_info.last_name<tab><tab>if user_info.email:<tab><tab><tab>self.form.email.data = user_info.email<tab>params = {""exception"": self.request.get(""exception"")}<tab>return self.render_template(""boilerplate_contact.html"", **params)",0,if user_info . name or user_info . last_name :,if user_info . name :,0.269935682,28.0673404,0.730769231
"def task_management_menu(activation, request):<tab>""""""Available tasks actions.""""""<tab>actions = []<tab>if request.user.has_perm(activation.flow_class._meta.manage_permission_name):<tab><tab>for transition in activation.get_available_transitions():<tab><tab><tab>if transition.can_proceed(activation):<tab><tab><tab><tab>url = activation.flow_task.get_task_url(<tab><tab><tab><tab><tab>activation.task,<tab><tab><tab><tab><tab>transition.name,<tab><tab><tab><tab><tab>user=request.user,<tab><tab><tab><tab><tab>namespace=request.resolver_match.namespace,<tab><tab><tab><tab>)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>actions.append((transition.name.replace(""_"", "" "").title(), url))<tab>return {""actions"": actions, ""request"": request}",1,if url :,if url :,0.531170663,1.00E-10,1
"def discover_misago_admin():<tab>for app in apps.get_app_configs():<tab><tab>module = import_module(app.name)<tab><tab>if not hasattr(module, ""admin""):<tab><tab><tab>continue<tab><tab>admin_module = import_module(""%s.admin"" % app.name)<tab><tab>if hasattr(admin_module, ""MisagoAdminExtension""):<tab><tab><tab>extension = getattr(admin_module, ""MisagoAdminExtension"")()<tab><tab><tab>if hasattr(extension, ""register_navigation_nodes""):<tab><tab><tab><tab>extension.register_navigation_nodes(site)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extension.register_urlpatterns(urlpatterns)",1,"if hasattr ( extension , ""register_urlpatterns"" ) :","if hasattr ( extension , ""register_urlpatterns"" ) :",0.75,100,1
"def dequeue(self):<tab>with self.db(commit=True) as curs:<tab><tab>curs.execute(<tab><tab><tab>""select id, data from task where queue = ? ""<tab><tab><tab>""order by priority desc, id limit 1"",<tab><tab><tab>(self.name,),<tab><tab>)<tab><tab>result = curs.fetchone()<tab><tab>if result is not None:<tab><tab><tab>tid, data = result<tab><tab><tab>curs.execute(""delete from task where id = ?"", (tid,))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return to_bytes(data)",0,if curs . rowcount == 1 :,if data is not None :,0.021817414,6.916271813,0.2
"def readHexStringFromStream(stream):<tab>stream.read(1)<tab>txt = """"<tab>x = b_("""")<tab>while True:<tab><tab>tok = readNonWhitespace(stream)<tab><tab><IF-STMT><tab><tab><tab># stream has truncated prematurely<tab><tab><tab>raise PdfStreamError(""Stream has ended unexpectedly"")<tab><tab>if tok == b_("">""):<tab><tab><tab>break<tab><tab>x += tok<tab><tab>if len(x) == 2:<tab><tab><tab>txt += chr(int(x, base=16))<tab><tab><tab>x = b_("""")<tab>if len(x) == 1:<tab><tab>x += b_(""0"")<tab>if len(x) == 2:<tab><tab>txt += chr(int(x, base=16))<tab>return createStringObject(b_(txt))",0,if not tok :,"if tok == b_ ( ""<"" ) :",0.036611762,4.456882761,0.477272727
"def test_compute_gradient(self):<tab>for y, y_pred in zip(self.y_list, self.predict_list):<tab><tab>lse_grad = self.lae_loss.compute_grad(y, y_pred)<tab><tab>diff = y_pred - y<tab><tab>if diff > consts.FLOAT_ZERO:<tab><tab><tab>grad = 1<tab><tab><IF-STMT><tab><tab><tab>grad = -1<tab><tab>else:<tab><tab><tab>grad = 0<tab><tab>self.assertTrue(np.fabs(lse_grad - grad) < consts.FLOAT_ZERO)",1,elif diff < consts . FLOAT_ZERO :,elif diff < consts . FLOAT_ZERO :,0.75,100,1
"def request_get(request, key, default_value=None):<tab>if key in request.args:<tab><tab>return request.args.get(key)<tab>elif key in request.form:<tab><tab>return request.form.get(key)<tab>try:<tab><tab>json_body = request.get_json(force=True, silent=True)<tab><tab><IF-STMT><tab><tab><tab>return json_body[key]<tab><tab>else:<tab><tab><tab>return default_value<tab>except Exception:<tab><tab>return default_value",1,if key in json_body :,if key in json_body :,0.75,100,1
"def _getResourceData(self, jid, dataname):<tab>""""""Return specific jid's resource representation in internal format. Used internally.""""""<tab>if jid.find(""/"") + 1:<tab><tab>jid, resource = jid.split(""/"", 1)<tab><tab><IF-STMT><tab><tab><tab>return self._data[jid][""resources""][resource][dataname]<tab>elif self._data[jid][""resources""].keys():<tab><tab>lastpri = -129<tab><tab>for r in self._data[jid][""resources""].keys():<tab><tab><tab>if int(self._data[jid][""resources""][r][""priority""]) > lastpri:<tab><tab><tab><tab>resource, lastpri = r, int(self._data[jid][""resources""][r][""priority""])<tab><tab>return self._data[jid][""resources""][resource][dataname]",0,"if self . _data [ jid ] [ ""resources"" ] . has_key ( resource ) :","if resource in self . _data [ jid ] [ ""resources"" ] :",0.385371909,55.86553091,0.326086957
"def GetBoundingBoxMin(self):<tab>""""""Get the minimum bounding box.""""""<tab>x1, y1 = 10000, 10000<tab>x2, y2 = -10000, -10000<tab>for point in self._lineControlPoints:<tab><tab>if point[0] < x1:<tab><tab><tab>x1 = point[0]<tab><tab>if point[1] < y1:<tab><tab><tab>y1 = point[1]<tab><tab>if point[0] > x2:<tab><tab><tab>x2 = point[0]<tab><tab><IF-STMT><tab><tab><tab>y2 = point[1]<tab>return x2 - x1, y2 - y1",1,if point [ 1 ] > y2 :,if point [ 1 ] > y2 :,0.75,100,1
"def produce_etag_headers(self, filename):<tab>""""""Produce a dict of curl headers containing etag headers from the download.""""""<tab>headers = {}<tab># If the download file already exists, add some headers to the request<tab># so we don't retrieve the content if it hasn't changed<tab>if os.path.exists(filename):<tab><tab>self.existing_file_size = os.path.getsize(filename)<tab><tab>etag = self.getxattr(self.xattr_etag)<tab><tab>last_modified = self.getxattr(self.xattr_last_modified)<tab><tab><IF-STMT><tab><tab><tab>headers[""If-None-Match""] = etag<tab><tab>if last_modified:<tab><tab><tab>headers[""If-Modified-Since""] = last_modified<tab>return headers",1,if etag :,if etag :,0.531170663,1.00E-10,1
"def _find_orientation_offset(self, header):<tab>(ifd_offset,) = self._unpack(""L"", header[4:])<tab>self.exif_buffer.seek(ifd_offset)<tab># Read tag directory<tab>for _ in range(self._unpack(""H"", self.exif_buffer.read(2))[0]):<tab><tab># Each tag is 12 bytes. HHL4s = tag, type, count, data<tab><tab># Read tag and ignore the rest<tab><tab>(tag,) = self._unpack(""H10x"", self.exif_buffer.read(12))<tab><tab><IF-STMT>  # Orientation tag<tab><tab><tab>self._offset = (<tab><tab><tab><tab>self.exif_buffer.tell() - 4<tab><tab><tab>)  # Back 4 bytes to the start of data<tab><tab><tab>break",0,if tag == 0x0112 :,if tag == 0 :,0.144778655,53.72849659,0.6
"def _start(self):<tab>try:<tab><tab>await self.fire_event(""pre_request"")<tab>except AbortEvent:<tab><tab>self.logger.debug(""Abort request %s"", self.request)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.start_request()<tab><tab><tab>except Exception as exc:<tab><tab><tab><tab>self.finished(exc=exc)",0,if self . _request is not None :,"if self . request . method == ""POST"" :",0.071567983,14.32314508,0.361111111
"def buildQueryRE(queryText, caseSensitive, wholeWord):<tab>""returns a RegEx pattern for searching for the given queryText""<tab># word detection etc. cannot be done on an encoding-less string:<tab>assert type(queryText) == unicode<tab>pattern = re.escape(queryText)<tab>if wholeWord:<tab><tab><IF-STMT><tab><tab><tab>pattern = ""\\b"" + pattern<tab><tab>if re.search(""\w$"", queryText, re.UNICODE):<tab><tab><tab>pattern = pattern + ""\\b""<tab>flags = re.UNICODE<tab>if not (caseSensitive):<tab><tab>flags |= re.IGNORECASE<tab>return re.compile(pattern, flags)",0,"if re . search ( ""^\w"" , queryText , re . UNICODE ) :","if pattern . startswith ( ""\\b"" ) :",0.019051245,6.90885611,0.230263158
"def filter(callbackfn):<tab>array = this.to_object()<tab>arr_len = array.get(""length"").to_uint32()<tab>if not callbackfn.is_callable():<tab><tab>raise this.MakeError(""TypeError"", ""callbackfn must be a function"")<tab>T = arguments[1]<tab>res = []<tab>k = 0<tab>while k < arr_len:<tab><tab><IF-STMT><tab><tab><tab>kValue = array.get(str(k))<tab><tab><tab>if callbackfn.call(T, (kValue, this.Js(k), array)).to_boolean().value:<tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return res  # converted to js array automatically",1,if array . has_property ( str ( k ) ) :,if array . has_property ( str ( k ) ) :,0.75,100,1
"def action(self, params):<tab>if len(params) < 1:<tab><tab>return CommandsResponse(STATUS_ERROR, ""Not enough params"")<tab>else:<tab><tab>vrf_name = params[0]<tab><tab><IF-STMT><tab><tab><tab>vrf_rf = params[1]<tab><tab>else:<tab><tab><tab>vrf_rf = ""ipv4""<tab><tab>from ryu.services.protocols.bgp.operator.internal_api import WrongParamError<tab><tab>try:<tab><tab><tab>return CommandsResponse(<tab><tab><tab><tab>STATUS_OK, self.api.count_single_vrf_routes(vrf_name, vrf_rf)<tab><tab><tab>)<tab><tab>except WrongParamError as e:<tab><tab><tab>return WrongParamResp(e)",1,if len ( params ) == 2 :,if len ( params ) == 2 :,0.75,100,1
"def __init__(self, layers):<tab>super(Add, self).__init__()<tab>self.layer_names = []<tab>self.layers = layers<tab>for i, layer in enumerate(self.layers):<tab><tab>if layer.parent is None:<tab><tab><tab>if i == 0:<tab><tab><tab><tab>layer.parent = ""input""<tab><tab><tab>else:<tab><tab><tab><tab>layer.parent = layers[i - 1].name<tab><tab><IF-STMT><tab><tab><tab>name = layer.name<tab><tab>else:<tab><tab><tab>name = layer.__class__.__name__ + str(i)<tab><tab><tab>layer.name = name<tab><tab>self.layer_names.append(name)",0,"if hasattr ( layer , ""name"" ) :","elif hasattr ( layer , ""name"" ) :",0.400183025,88.01117368,0.6
"def _grouping_intervals(grouping):<tab>last_interval = None<tab>for interval in grouping:<tab><tab># if grouping is -1, we are done<tab><tab>if interval == CHAR_MAX:<tab><tab><tab>return<tab><tab># 0: re-use last group ad infinitum<tab><tab>if interval == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""invalid grouping"")<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_interval<tab><tab>yield interval<tab><tab>last_interval = interval",0,if last_interval is None :,if last_interval is not None :,0.272109132,59.46035575,0.56
"def infer_expected_xp_and_device(self, x):<tab>xp = backend.get_array_module(x)<tab>if xp is np:<tab><tab>return xp, None<tab>elif xp is cuda.cupy:<tab><tab>return xp, x.device<tab>elif xp is chainerx:<tab><tab>backend_name = x.device.backend.name<tab><tab><IF-STMT><tab><tab><tab>return np, None<tab><tab>elif backend_name == ""cuda"":<tab><tab><tab>return cuda.cupy, cuda.cupy.cuda.Device(x.device.index)<tab>assert False",0,"if backend_name == ""native"" :","if backend_name == ""np"" :",0.394778655,70.71067812,1
"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)",1,"if "">"" in text :","if "">"" in text :",0.75,100,1
"def get_block_id_at_height(store, height, descendant_id):<tab>if height is None:<tab><tab>return None<tab>while True:<tab><tab>block = store._load_block(descendant_id)<tab><tab>if block[""height""] == height:<tab><tab><tab>return descendant_id<tab><tab>descendant_id = block[<tab><tab><tab>""search_id""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""prev_id""<tab><tab>]",0,"if util . get_search_height ( block [ ""height"" ] ) >= height",if descendant_id,0.006177645,1.00E-10,0.368421053
"def train(config, checkpoint_dir=None):<tab>if checkpoint_dir:<tab><tab>assert os.path.exists(checkpoint_dir)<tab>for step in range(10):<tab><tab><IF-STMT><tab><tab><tab>with tune.checkpoint_dir(step=step) as checkpoint_dir:<tab><tab><tab><tab>path = os.path.join(checkpoint_dir, ""checkpoint"")<tab><tab><tab><tab>with open(path, ""w"") as f:<tab><tab><tab><tab><tab>f.write(json.dumps({""step"": step}))<tab><tab>tune.report(test=step)",0,if step % 3 == 0 :,if step % 100 == 0 :,0.38848939,50,0.666666667
"def onMinimize(self, sender):<tab>if self._runDialogListener(""onMinimize"") is False:<tab><tab>return<tab>widget = self.child<tab>if widget is not None:<tab><tab>if widget.isVisible():<tab><tab><tab>widget.setVisible(False)<tab><tab><tab>self.setHeight("""")<tab><tab><tab>self.setWidth("""")<tab><tab><tab>if self._maximized:<tab><tab><tab><tab>self._minimized = self._maximized<tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>else:<tab><tab><tab><tab>self._minimized = None<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>widget.setVisible(True)",0,if self . _minimized is not None :,if self . _minimized :,0.234334509,48.23560798,0.444444444
"def apply_transformation(self, ti: TransformationInput) -> Transformation:<tab># Insert fragments after the last line.<tab>if ti.lineno == ti.document.line_count - 1:<tab><tab>buffer = ti.buffer_control.buffer<tab><tab><IF-STMT><tab><tab><tab>suggestion = buffer.suggestion.text<tab><tab>else:<tab><tab><tab>suggestion = """"<tab><tab>return Transformation(fragments=ti.fragments + [(self.style, suggestion)])<tab>else:<tab><tab>return Transformation(fragments=ti.fragments)",0,if buffer . suggestion and ti . document . is_cursor_at_the_end :,if buffer . suggestion :,0.182222816,4.299920765,0.538461538
"def get_measurements(self, pipeline, object_name, category):<tab>if object_name == IMAGE and category == C_COUNT:<tab><tab>return [self.object_name.value]<tab>elif object_name == self.object_name:<tab><tab><IF-STMT><tab><tab><tab>return [<tab><tab><tab><tab>FTR_CENTER_X,<tab><tab><tab><tab>FTR_CENTER_Y,<tab><tab><tab>]<tab><tab>elif category == C_NUMBER:<tab><tab><tab>return [FTR_OBJECT_NUMBER]<tab><tab>elif category == C_WORMS:<tab><tab><tab>return [F_ANGLE]<tab>return []",0,if category == C_LOCATION :,if category == C_CENTER :,0.394778655,70.71067812,1
"def traverse(tensors):<tab>""""""traverse all ops to find attached workload""""""<tab>for t in tensors:<tab><tab>op = t.op<tab><tab><IF-STMT><tab><tab><tab>return args_to_workload(op.attrs[""workload""])<tab><tab>wkl = traverse(op.input_tensors)<tab><tab>if wkl:<tab><tab><tab>return wkl<tab>return None",1,"if ""workload"" in op . attrs :","if ""workload"" in op . attrs :",0.75,100,1
"def _pack(converter, node: Any, inputs: List[str]) -> Any:<tab>final_inputs = []<tab>for x_in in inputs:<tab><tab>input_c = converter.outputs[x_in]<tab><tab><IF-STMT><tab><tab><tab>final_inputs.append(_nodef_to_private_pond(converter, input_c))<tab><tab>else:<tab><tab><tab>final_inputs.append(input_c)<tab>return converter.protocol.stack(final_inputs, axis=node.attr[""axis""].i)",0,"if isinstance ( input_c , tf . compat . v1 . NodeDef ) :","if isinstance ( input_c , _Nodef ) :",0.150592719,40.08711096,0.4
"def __init__(self, instance=None, data=empty, **kwargs):<tab>context = kwargs.get(""context"", {})<tab>if ""product"" in context:<tab><tab>instance = self.get_instance(context, data, kwargs)<tab><tab><IF-STMT><tab><tab><tab>quantity = self.fields[""quantity""].to_internal_value(data[""quantity""])<tab><tab>else:<tab><tab><tab>quantity = self.fields[""quantity""].default<tab><tab>instance.setdefault(""quantity"", quantity)<tab><tab>super().__init__(instance, data, context=context)<tab>else:<tab><tab>super().__init__(instance, data, **kwargs)",0,"if data is not empty and ""quantity"" in data :","if ""quantity"" in data :",0.138975808,41.16538266,0.180555556
"def serialize(self, value):<tab>if value is not None:<tab><tab>try:<tab><tab><tab>iter(value)<tab><tab>except TypeError:<tab><tab><tab>value = [value]<tab><tab><IF-STMT><tab><tab><tab>return [self.element_serialize(val) for val in sorted(value)]<tab>return None",0,if len ( value ) :,if len ( value ) > 0 :,0.459088249,54.10822691,0.777777778
"def remove_cloner_curve(self, obj_index):<tab># opportunity to remove the .cloner.<tab>if self.selected_mode == ""Duplicate"":<tab><tab>curve_name = f""{self.basedata_name}.cloner.{obj_index:04d}""<tab><tab>cu = bpy.data.curves.get(curve_name)<tab><tab><IF-STMT><tab><tab><tab>bpy.data.curves.remove(cu)",0,if cu :,if cu is not None :,0.090364769,1.00E-10,0.4
"def update_advance_paid(self):<tab>advance_paid = frappe._dict()<tab>for d in self.get(""accounts""):<tab><tab><IF-STMT><tab><tab><tab>if d.reference_type in (<tab><tab><tab><tab>""Sales Order"",<tab><tab><tab><tab>""Purchase Order"",<tab><tab><tab><tab>""Employee Advance"",<tab><tab><tab>):<tab><tab><tab><tab>advance_paid.setdefault(d.reference_type, []).append(d.reference_name)<tab>for voucher_type, order_list in iteritems(advance_paid):<tab><tab>for voucher_no in list(set(order_list)):<tab><tab><tab>frappe.get_doc(voucher_type, voucher_no).set_total_advance_paid()",0,if d . is_advance :,if d . reference_type :,0.394778655,27.77619034,1
"def handle(self, msg):<tab>self._mic.send(msg)<tab>for calculate_seed, make_delegate, dict in self._delegate_records:<tab><tab>id = calculate_seed(msg)<tab><tab>if id is None:<tab><tab><tab>continue<tab><tab>elif isinstance(id, collections.Hashable):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab><tab>dict[id] = d<tab><tab><tab><tab>dict[id].start()<tab><tab>else:<tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab>d.start()",0,if id not in dict or not dict [ id ] . is_alive ( ) :,if id not in dict :,0.213034573,10.76281893,0.682539683
"def _get_default_factory(self, attribute_name: str) -> Any:<tab>if hasattr(self, attribute_name):<tab><tab>if str(getattr(self, attribute_name)).startswith(""${""):<tab><tab><tab>return str(getattr(self, attribute_name))<tab><tab><IF-STMT><tab><tab><tab>return str(self.__dataclass_fields__[attribute_name].default)<tab><tab>elif (<tab><tab><tab>getattr(self, attribute_name)<tab><tab><tab>!= self.__dataclass_fields__[attribute_name].default_factory()<tab><tab>):<tab><tab><tab>return getattr(self, attribute_name)<tab>return self.__dataclass_fields__[attribute_name].default_factory()",0,"elif str ( self . __dataclass_fields__ [ attribute_name ] . default ) . startswith ( ""${"" ) :","if str ( self . __dataclass_fields__ [ attribute_name ] . default ) . startswith ( ""${"" ) :",0.570177449,96.35749534,0.714285714
"def showMenu(self, show):<tab>if show:<tab><tab><IF-STMT><tab><tab><tab>self.canvas.menu = Menu(self.canvas, tearoff=0)<tab><tab><tab>self.canvas.menu.add_command(label=""delete"", command=self._delete)<tab><tab><tab>self.canvas.menu.bind(""<FocusOut>"", lambda e: self.canvas.menu.unpost())<tab><tab>self._bindMenu()<tab>else:<tab><tab># need to go through and unbind...<tab><tab>pass",1,if self . canvas . menu is None :,if self . canvas . menu is None :,0.75,100,1
"def __init__(self, db, where=None):<tab>self._db = db<tab>self._tables = []<tab>self.filters = []<tab>if hasattr(where, ""get_all""):<tab><tab>self.where = where<tab><tab>self._tables.insert(0, where.get_all)<tab>elif hasattr(where, ""get_one"") and isinstance(where.get_one, QueryException):<tab><tab>self.where = where.get_one<tab>else:<tab><tab># find out which tables are involved<tab><tab><IF-STMT><tab><tab><tab>self.filters = where.left<tab><tab>self.where = where<tab><tab>self._tables = [field._tablename for (field, op, val) in self.filters]",0,"if isinstance ( where , Query ) :","if hasattr ( where , ""left"" ) :",0.091668085,20.55668085,0.481481481
"def main():<tab>try:<tab><tab>from wsgiref.simple_server import make_server<tab><tab>from wsgiref.validate import validator<tab><tab><IF-STMT><tab><tab><tab>port[0] = get_open_port()<tab><tab>wsgi_application = WsgiApplication(soap11_application)<tab><tab>server = make_server(host, port[0], validator(wsgi_application))<tab><tab>logger.info(""Starting interop server at %s:%s."" % (""0.0.0.0"", port[0]))<tab><tab>logger.info(""WSDL is at: /?wsdl"")<tab><tab>server.serve_forever()<tab>except ImportError:<tab><tab>print(""Error: example server code requires Python >= 2.5"")",0,if port [ 0 ] == 0 :,if not port :,0.019930836,6.023021416,0.377777778
"def try_adjust_widgets(self):<tab>if hasattr(self.parent, ""adjust_widgets""):<tab><tab>self.parent.adjust_widgets()<tab>if hasattr(self.parent, ""parentApp""):<tab><tab><IF-STMT><tab><tab><tab>self.parent.parentApp._internal_adjust_widgets()<tab><tab>if hasattr(self.parent.parentApp, ""adjust_widgets""):<tab><tab><tab>self.parent.parentApp.adjust_widgets()",1,"if hasattr ( self . parent . parentApp , ""_internal_adjust_widgets"" ) :","if hasattr ( self . parent . parentApp , ""_internal_adjust_widgets"" ) :",0.75,100,1
"def copy_file_replace_line(<tab>orig_file: Path, new_file: Path, line_re: str, new_line: str) -> None:<tab>old_version_fh = orig_file.open(""r"")<tab>new_version_fh = new_file.open(""w"")<tab>for line in old_version_fh:<tab><tab><IF-STMT><tab><tab><tab>new_version_fh.write(new_line + ""\n"")<tab><tab>else:<tab><tab><tab>new_version_fh.write(line)<tab>old_version_fh.close()<tab>new_version_fh.close()",0,"if re . search ( line_re , line ) :",if line_re . search ( line ) :,0.09638492,51.67803197,0.384615385
"def _protoc_plugin_parameters(self, language):<tab>""""""Return a tuple of (plugin path, vars) used as parameters for ninja build.""""""<tab>path, vars = """", {}<tab>for p in self.attr[""protoc_plugins""]:<tab><tab><IF-STMT><tab><tab><tab>path = p.path<tab><tab><tab>flag = p.protoc_plugin_flag(self.build_dir)<tab><tab><tab>vars = {""protoc%spluginflags"" % language: flag}<tab><tab><tab>break<tab>return path, vars",0,if language in p . code_generation :,"if hasattr ( p , ""protoc_plugin_flag"" ) :",0.021135836,4.016138436,0.314814815
"def scan_page(self, address_space, page_offset, fullpage=False):<tab>""""""Runs through patchers for a single page""""""<tab><IF-STMT><tab><tab>pagedata = address_space.read(page_offset, PAGESIZE)<tab>for patcher in self.patchers:<tab><tab>for offset, data in patcher.get_constraints():<tab><tab><tab>if fullpage:<tab><tab><tab><tab>testdata = pagedata[offset : offset + len(data)]<tab><tab><tab>else:<tab><tab><tab><tab>testdata = address_space.read(page_offset + offset, len(data))<tab><tab><tab>if data != testdata:<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield patcher",1,if fullpage :,if fullpage :,0.531170663,1.00E-10,1
"def OnLeftDClick(self, event):<tab>pt = event.GetPosition()<tab>item, flags = self.tree.HitTest(pt)<tab>if item:<tab><tab>self.log.WriteText(""OnLeftDClick: %s\n"" % self.tree.GetItemText(item))<tab><tab>parent = self.tree.GetItemParent(item)<tab><tab><IF-STMT><tab><tab><tab>self.tree.SortChildren(parent)<tab>event.Skip()",0,if parent . IsOk ( ) :,if parent :,0.038857533,1.00E-10,0.722222222
"def drop_pathlist(self, pathlist):<tab>""""""Drop path list""""""<tab>if pathlist:<tab><tab>files = [""r'%s'"" % path for path in pathlist]<tab><tab><IF-STMT><tab><tab><tab>text = files[0]<tab><tab>else:<tab><tab><tab>text = ""["" + "", "".join(files) + ""]""<tab><tab>if self.new_input_line:<tab><tab><tab>self.on_new_line()<tab><tab>self.insert_text(text)<tab><tab>self.setFocus()",1,if len ( files ) == 1 :,if len ( files ) == 1 :,0.75,100,1
"def func_set_exporter_funcs_opset_yaml(func_set):<tab>if len(list(func_set)[0].split(""@"")) == 1:<tab><tab>yaml_data = {}<tab><tab>for nnabla_func, impl_funcs in _onnx_func_info.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yaml_data[nnabla_func] = impl_funcs<tab><tab>return yaml.dump(yaml_data, default_flow_style=False)<tab>else:<tab><tab>return yaml.dump(list(func_set), default_flow_style=False)",1,if nnabla_func in func_set :,if nnabla_func in func_set :,0.75,100,1
"def object_hook(obj):<tab>obj_len = len(obj)<tab>if obj_len == 1:<tab><tab>if ""$date"" in obj:<tab><tab><tab>return datetime.fromtimestamp(<tab><tab><tab><tab>obj[""$date""] / 1000, tz=timezone.utc<tab><tab><tab>) + timedelta(milliseconds=obj[""$date""] % 1000)<tab><tab>if ""$time"" in obj:<tab><tab><tab>return time(*[int(i) for i in obj[""$time""].split("":"")])<tab>if obj_len == 2 and ""$type"" in obj and ""$value"" in obj:<tab><tab><IF-STMT><tab><tab><tab>return date(*[int(i) for i in obj[""$value""].split(""-"")])<tab>return obj",0,"if obj [ ""$type"" ] == ""date"" :","if ""$value"" in obj :",0.019907918,6.866210822,0.477272727
"def start(self, para=None, callback=None):<tab>if not self.load():<tab><tab>return<tab>if para != None or self.show():<tab><tab>if para == None:<tab><tab><tab>para = self.para<tab><tab>win = WidgetsManager.getref(""Macros Recorder"")<tab><tab><IF-STMT><tab><tab><tab>win.write(""{}>{}"".format(self.title, para))<tab><tab>if self.asyn and IPy.uimode() != ""no"":<tab><tab><tab>threading.Thread(target=self.runasyn, args=(para, callback)).start()<tab><tab>else:<tab><tab><tab>self.runasyn(para, callback)",0,if win != None :,if win :,0.067674239,1.00E-10,0.7
"def user(self):<tab><IF-STMT><tab><tab>_env_username = os.getenv(""CONAN_USERNAME"")<tab><tab>conan_v2_error(<tab><tab><tab>""Environment variable 'CONAN_USERNAME' is deprecated"", _env_username<tab><tab>)<tab><tab>self._conan_user = _env_username or self.default_user<tab><tab>if not self._conan_user:<tab><tab><tab>raise ConanException(""user not defined, but self.user is used in conanfile"")<tab>return self._conan_user",1,if not self . _conan_user :,if not self . _conan_user :,0.75,100,1
"def _get_vars(cls, func):<tab># log.debug(""Getting vars for %s"", func)<tab>params = inspect.signature(func).parameters.copy()<tab>args = {}<tab># log.debug(""Got %s"", params)<tab>for name, param in params.items():<tab><tab># log.debug(""Checking arg %s, type %s"", name, param.kind)<tab><tab><IF-STMT><tab><tab><tab># log.debug(""Using var %s"", name)<tab><tab><tab>args[name] = _get_variable(name)<tab><tab><tab># log.debug(""Collected var for arg '%s': %s"", name, args[name])<tab>return args",0,if param . kind is param . POSITIONAL_OR_KEYWORD and param . default is None :,"if param . kind == ""variable"" :",0.079927045,11.29295626,0.386029412
def parts(self):<tab>klass = self.__class__<tab>this = list()<tab>for token in self:<tab><tab>if token.startswith_fws():<tab><tab><tab>if this:<tab><tab><tab><tab>yield this[0] if len(this) == 1 else klass(this)<tab><tab><tab><tab>this.clear()<tab><tab>end_ws = token.pop_trailing_ws()<tab><tab>this.append(token)<tab><tab><IF-STMT><tab><tab><tab>yield klass(this)<tab><tab><tab>this = [end_ws]<tab>if this:<tab><tab>yield this[0] if len(this) == 1 else klass(this),1,if end_ws :,if end_ws :,0.531170663,1.00E-10,1
"def start_fileoutput(self):<tab>""""""Start output to configured file.""""""<tab>path = os.path.dirname(self.filename)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(path)<tab><tab>self.fd = self.create_fd()<tab><tab>self.close_fd = True<tab>except IOError:<tab><tab>msg = sys.exc_info()[1]<tab><tab>log.warn(<tab><tab><tab>LOG_CHECK,<tab><tab><tab>""Could not open file %r for writing: %s\n"" ""Disabling log output of %s"",<tab><tab><tab>self.filename,<tab><tab><tab>msg,<tab><tab><tab>self,<tab><tab>)<tab><tab>self.fd = dummy.Dummy()<tab><tab>self.is_active = False<tab>self.filename = None",0,if path and not os . path . isdir ( path ) :,if not os . path . exists ( path ) :,0.557807893,50.30989331,0.279166667
"def worksheet_id(self, value):<tab>if self._worksheet:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>raise InvalidArgumentValue(<tab><tab><tab><tab>""This range already has a worksheet with different id set.""<tab><tab><tab>)<tab>self._worksheet_id = value",0,if self . _worksheet . id == value :,if self . worksheet . id == value :,0.549889319,71.0866789,0.481481481
"def _sanity_check(self, kind, triplets):<tab>route_id = self.data.get(""route_id"", [None])[0]<tab>if route_id or [<tab><tab>k<tab><tab>for k in self.data.keys()<tab><tab>if k[:5] in (""route"", ""smtp-"", ""sourc"", ""secur"", ""local"")<tab>]:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Can only configure detailed settings "" ""for one profile at a time""<tab><tab><tab>)",0,"if len ( triplets ) > 1 or kind != ""profile"" :",if len ( triplets ) > 1 :,0.376253747,36.24372414,0.693877551
"def _process_property_change(self, msg):<tab>msg = super(Select, self)._process_property_change(msg)<tab>if ""value"" in msg:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif msg[""value""] is None:<tab><tab><tab>msg[""value""] = self.values[0]<tab><tab>else:<tab><tab><tab>if isIn(msg[""value""], self.unicode_values):<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.unicode_values)<tab><tab><tab>else:<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.labels)<tab><tab><tab>msg[""value""] = self._items[self.labels[idx]]<tab>msg.pop(""options"", None)<tab>return msg",0,if not self . values :,if len ( self . values ) == 0 :,0.088179696,15.85116569,0.558441558
"def emit(self, record):<tab>msg = record.getMessage()<tab>###<tab>if record.exc_info:<tab><tab>_type, value, tback = record.exc_info<tab><tab>tback_text = """".join(traceback.format_exception(_type, value, tback))<tab><tab><IF-STMT><tab><tab><tab>msg += ""\n""<tab><tab>msg += tback_text<tab>###<tab>self.tktext.insert(<tab><tab>""end"",<tab><tab>msg + ""\n"",<tab><tab>record.levelname,<tab>)",1,if msg :,if msg :,0.531170663,1.00E-10,1
"def _get_pip_index_urls(sources):<tab>index_urls = []<tab>trusted_hosts = []<tab>for source in sources:<tab><tab>url = source.get(""url"")<tab><tab>if not url:<tab><tab><tab>continue<tab><tab>index_urls.append(url)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>host = six.moves.urllib.parse.urlparse(source[""url""]).hostname<tab><tab>trusted_hosts.append(host)<tab>return index_urls, trusted_hosts",0,"if source . get ( ""verify_ssl"" , True ) :","if not source [ ""url"" ] :",0.014969815,4.090508964,0.320512821
"def _is_binary(fname, limit=80):<tab>try:<tab><tab>with open(fname, ""rb"") as f:<tab><tab><tab>for i in range(limit):<tab><tab><tab><tab>char = f.read(1)<tab><tab><tab><tab>if char == b""\0"":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if char == b"""":<tab><tab><tab><tab><tab>return<tab>except OSError as e:<tab><tab>if xp.ON_WINDOWS and is_app_execution_alias(fname):<tab><tab><tab>return True<tab><tab>raise e<tab>return False",0,"if char == b""\n"" :","if char == b"""" :",0.395473924,59.59429411,1
"def tearDown(self):<tab>exc, _, _ = sys.exc_info()<tab>if exc:<tab><tab>try:<tab><tab><tab>if hasattr(self, ""obj"") and isinstance(self.obj, SelfDiagnosable):<tab><tab><tab><tab>diags = self.obj.get_error_diagnostics()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>for line in diags:<tab><tab><tab><tab><tab><tab>ROOT_LOGGER.info(line)<tab><tab>except BaseException:<tab><tab><tab>pass<tab>if self.captured_logger:<tab><tab>self.captured_logger.removeHandler(self.log_recorder)<tab><tab>self.log_recorder.close()<tab>sys.stdout = self.stdout_backup<tab>super(BZTestCase, self).tearDown()",1,if diags :,if diags :,0.531170663,1.00E-10,1
"def _disconnect(self, sync):<tab><IF-STMT><tab><tab>if sync:<tab><tab><tab>try:<tab><tab><tab><tab>self._connection.send_all()<tab><tab><tab><tab>self._connection.fetch_all()<tab><tab><tab>except (WorkspaceError, ServiceUnavailable):<tab><tab><tab><tab>pass<tab><tab>if self._connection:<tab><tab><tab>self._connection.in_use = False<tab><tab><tab>self._connection = None<tab><tab>self._connection_access_mode = None",1,if self . _connection :,if self . _connection :,0.75,100,1
"def _recursive_process(self):<tab>super(RecursiveObjectDownwardsVisitor, self)._recursive_process()<tab>while self._new_for_visit:<tab><tab>func_ea, arg_idx = self._new_for_visit.pop()<tab><tab>if helper.is_imported_ea(func_ea):<tab><tab><tab>continue<tab><tab>cfunc = helper.decompile_function(func_ea)<tab><tab><IF-STMT><tab><tab><tab>assert arg_idx < len(cfunc.get_lvars()), ""Wrong argument at func {}"".format(<tab><tab><tab><tab>to_hex(func_ea)<tab><tab><tab>)<tab><tab><tab>obj = VariableObject(cfunc.get_lvars()[arg_idx], arg_idx)<tab><tab><tab>self.prepare_new_scan(cfunc, arg_idx, obj)<tab><tab><tab>self._recursive_process()",0,if cfunc :,if cfunc is not None :,0.090364769,1.00E-10,0.4
"def to_dict(self) -> JSONDict:<tab>data = dict()<tab>for key in iter(self.__dict__):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = self.__dict__[key]<tab><tab>if value is not None:<tab><tab><tab>if hasattr(value, ""to_dict""):<tab><tab><tab><tab>data[key] = value.to_dict()<tab><tab><tab>else:<tab><tab><tab><tab>data[key] = value<tab>if data.get(""from_user""):<tab><tab>data[""from""] = data.pop(""from_user"", None)<tab>return data",0,"if key == ""bot"" or key . startswith ( ""_"" ) :","if key . startswith ( ""__"" ) :",0.140676574,41.88362313,0.508333333
"def get_data(self, path, prefix=""""):<tab>item = self.store[path]<tab>path = ""{}/{}"".format(prefix, path)<tab>keys = [i for i in item.keys()]<tab>data = {""path"": path}<tab># print(path)<tab>for k in keys:<tab><tab><IF-STMT><tab><tab><tab>dataset = np.array(item[k].value)<tab><tab><tab>if type(dataset) is np.ndarray:<tab><tab><tab><tab>if dataset.size != 0:<tab><tab><tab><tab><tab>if type(dataset[0]) is np.bytes_:<tab><tab><tab><tab><tab><tab>dataset = [a.decode(""ascii"") for a in dataset]<tab><tab><tab>data.update({k: dataset})<tab>return data",0,"if not isinstance ( item [ k ] , h5py . Group ) :","if isinstance ( item [ k ] , dict ) :",0.298883802,49.36359311,0.208333333
"def _macros_of_type(root, type, el_func):<tab>macros_el = root.find(""macros"")<tab>macro_dict = {}<tab>if macros_el is not None:<tab><tab>macro_els = macros_el.findall(""macro"")<tab><tab>filtered_els = [<tab><tab><tab>(macro_el.get(""name""), el_func(macro_el))<tab><tab><tab>for macro_el in macro_els<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>macro_dict = dict(filtered_els)<tab>return macro_dict",1,"if macro_el . get ( ""type"" ) == type","if macro_el . get ( ""type"" ) == type",0.75,100,1
"def get_referrers(self):<tab>d = []<tab>for o in gc.get_referrers(self.obj):<tab><tab>name = None<tab><tab><IF-STMT><tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><tab>for r in gc.get_referrers(o):<tab><tab><tab><tab>if getattr(r, ""__dict__"", None) is o:<tab><tab><tab><tab><tab>o = r<tab><tab><tab><tab><tab>break<tab><tab>elif isinstance(o, dict):  # other dict types<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab>if not isinstance(name, six.string_types):<tab><tab><tab>name = None<tab><tab>d.append(Object(o, name))<tab>return d",1,"if isinstance ( o , dict ) :","if isinstance ( o , dict ) :",0.75,100,1
"def MakeWidthArray(fm):<tab># Make character width array<tab>s = ""{\n\t""<tab>cw = fm[""Widths""]<tab>for i in xrange(0, 256):<tab><tab>if chr(i) == ""'"":<tab><tab><tab>s += ""'\\''""<tab><tab><IF-STMT><tab><tab><tab>s += ""'\\\\'""<tab><tab>elif i >= 32 and i <= 126:<tab><tab><tab>s += ""'"" + chr(i) + ""'""<tab><tab>else:<tab><tab><tab>s += ""chr(%d)"" % i<tab><tab>s += "":"" + fm[""Widths""][i]<tab><tab>if i < 255:<tab><tab><tab>s += "",""<tab><tab>if (i + 1) % 22 == 0:<tab><tab><tab>s += ""\n\t""<tab>s += ""}""<tab>return s",1,"elif chr ( i ) == ""\\"" :","elif chr ( i ) == ""\\"" :",0.75,100,1
"def getLatestFile(self):<tab>highestNsp = None<tab>highestNsx = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab>if nsp.path.endswith("".nsx""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>highestNsx = nsp<tab><tab><tab>else:<tab><tab><tab><tab>if not highestNsp or int(nsp.version) > int(highestNsp.version):<tab><tab><tab><tab><tab>highestNsp = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highestNsp or highestNsx",1,if not highestNsx or int ( nsp . version ) > int ( highestNsx . version ) :,if not highestNsx or int ( nsp . version ) > int ( highestNsx . version ) :,1,100,1
"def _check_integrity(self) -> bool:<tab># Allow original archive to be deleted (zip). Only need the extracted images<tab>all_files = self.FILE_LIST.copy()<tab>all_files.append(self.ANNOTATIONS_FILE)<tab>for (_, md5, filename) in all_files:<tab><tab>file, ext = os.path.splitext(filename)<tab><tab>extracted_dir = os.path.join(self.root, file)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",1,if not os . path . exists ( extracted_dir ) :,if not os . path . exists ( extracted_dir ) :,0.75,100,1
"def load_core(self):<tab>for filename in os.listdir(self.path):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>name = filename.replace("".py"", """")<tab><tab><tab><tab>mod = load_python_module(name, self.path)<tab><tab><tab><tab>self._load_cmd_from(mod)<tab><tab><tab>except:<tab><tab><tab><tab>warnings.warn(<tab><tab><tab><tab><tab>""!! Warning: could not load core command file "" + filename,<tab><tab><tab><tab><tab>RuntimeWarning,<tab><tab><tab><tab>)",0,"if filename != ""__init__.py"" and filename . endswith ( "".py"" ) :","if filename . endswith ( "".py"" ) :",0.279684224,28.804263,0.508333333
"def _make_dataset(key, data, size):<tab>if isinstance(data, chainer.get_array_types()):<tab><tab>if key is None:<tab><tab><tab>key = ""_{}"".format(id(data))<tab><tab>return _Array(key, data)<tab>elif isinstance(data, list):<tab><tab>if key is None:<tab><tab><tab>key = ""_{}"".format(id(data))<tab><tab>return _List(key, data)<tab>elif callable(data):<tab><tab>if key is None:<tab><tab><tab>raise ValueError(""key(s) must be specified for callable"")<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""size must be specified for callable"")<tab><tab>return _Index(size).transform(key, data)",1,if size is None :,if size is None :,0.75,100,1
"def main_loop(self) -> None:<tab>while True:<tab><tab>try:<tab><tab><tab>message = self.control.get(block=False)<tab><tab>except Empty:<tab><tab><tab>message = None<tab><tab>if message == ""ABORT"":<tab><tab><tab>self.log.info(""Got ABORT message, main_loop exiting..."")<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>self.log.error(""One or more watcher died, committing suicide!"")<tab><tab><tab>sys.exit(1)<tab><tab>if self.all_workers_dead():<tab><tab><tab>self.log.error(""All workers have died, committing suicide!"")<tab><tab><tab>sys.exit(1)<tab><tab>self.check_and_start_workers()<tab><tab>time.sleep(0.1)",0,if not self . all_watchers_running ( ) :,if self . all_watcher_dead ( ) :,0.093065587,32.99292579,0.477272727
"def execute_map(cls, ctx, op):<tab>(x,), device_id, xp = as_same_device(<tab><tab>[ctx[c.key] for c in op.inputs], op.device, ret_extra=True<tab>)<tab>axis = cls.get_arg_axis(op.axis, op.inputs[0].ndim)<tab>keepdims = op.keepdims<tab>with device(device_id):<tab><tab>nz = xp.count_nonzero(x, axis=axis)<tab><tab><IF-STMT><tab><tab><tab>slcs = [slice(None)] * op.inputs[0].ndim<tab><tab><tab>for ax in op.axis:<tab><tab><tab><tab>slcs[ax] = np.newaxis<tab><tab><tab>nz = xp.asarray(nz)[tuple(slcs)]<tab><tab>ctx[op.outputs[0].key] = nz",0,if keepdims :,if nz < keepdims :,0.097914534,1.00E-10,0.45
"def setfilter(self, f):<tab>filter_exp = create_string_buffer(f.encode(""ascii""))<tab>if pcap_compile(self.pcap, byref(self.bpf_program), filter_exp, 0, -1) == -1:<tab><tab>error(""Could not compile filter expression %s"" % f)<tab><tab>return False<tab>else:<tab><tab><IF-STMT><tab><tab><tab>error(""Could not install filter %s"" % f)<tab><tab><tab>return False<tab>return True",0,"if pcap_setfilter ( self . pcap , byref ( self . bpf_program ) ) == - 1 :","if not pcap_install ( self . pcap , filter_exp , 0 ) :",0.114847772,19.3709549,0.245
"def find_parent_for_new_to(self, pos):<tab>""""""Figure out the parent object for something at 'pos'.""""""<tab>for children in self._editable_children:<tab><tab>if children._start <= pos < children._end:<tab><tab><tab>return children.find_parent_for_new_to(pos)<tab><tab><IF-STMT><tab><tab><tab>return children.find_parent_for_new_to(pos)<tab>return self",0,if children . _start == pos and pos == children . _end :,elif children . _start >= pos < children . _end :,0.390734419,39.07680518,0.340277778
"def process_events(self, events):<tab>for event in events:<tab><tab>key = (event.ident, event.filter)<tab><tab><IF-STMT><tab><tab><tab>self._force_wakeup.drain()<tab><tab><tab>continue<tab><tab>receiver = self._registered[key]<tab><tab>if event.flags & select.KQ_EV_ONESHOT:<tab><tab><tab>del self._registered[key]<tab><tab>if type(receiver) is _core.Task:<tab><tab><tab>_core.reschedule(receiver, outcome.Value(event))<tab><tab>else:<tab><tab><tab>receiver.put_nowait(event)",0,if event . ident == self . _force_wakeup_fd :,if key in self . _registered :,0.094461012,9.736604043,0.428571429
"def test_tag(artifact_obj, sagemaker_session):<tab>tag = {""Key"": ""foo"", ""Value"": ""bar""}<tab>artifact_obj.set_tag(tag)<tab>while True:<tab><tab>actual_tags = sagemaker_session.sagemaker_client.list_tags(<tab><tab><tab>ResourceArn=artifact_obj.artifact_arn<tab><tab>)[""Tags""]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(5)<tab># When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints,<tab># length of actual tags will be greater than 1<tab>assert len(actual_tags) > 0<tab>assert actual_tags[0] == tag",1,if actual_tags :,if actual_tags :,0.531170663,1.00E-10,1
"def initialize(self) -> None:<tab>""""""Move the API keys from cog stored config to core bot config if they exist.""""""<tab>imgur_token = await self.config.imgur_client_id()<tab>if imgur_token is not None:<tab><tab><IF-STMT><tab><tab><tab>await self.bot.set_shared_api_tokens(""imgur"", client_id=imgur_token)<tab><tab>await self.config.imgur_client_id.clear()",0,"if not await self . bot . get_shared_api_tokens ( ""imgur"" ) :",if imgur_token not in self . bot . shared_api_tokens :,0.219108917,33.35685183,0.714285714
"def _sorted_layers(self, structure, top_layer_id):<tab>""""""Return the image layers sorted""""""<tab>sorted_layers = []<tab>next_layer = top_layer_id<tab>while next_layer:<tab><tab>sorted_layers.append(next_layer)<tab><tab>if ""json"" not in structure[""repolayers""][next_layer]:  # v2<tab><tab><tab>break<tab><tab>if ""parent"" not in structure[""repolayers""][next_layer][""json""]:<tab><tab><tab>break<tab><tab>next_layer = structure[""repolayers""][next_layer][""json""][""parent""]<tab><tab><IF-STMT><tab><tab><tab>break<tab>return sorted_layers",1,if not next_layer :,if not next_layer :,0.75,100,1
"def __init__(self, bounds, channel_axis, preprocess=None):<tab>assert len(bounds) == 2<tab>assert channel_axis in [0, 1, 2, 3]<tab>self._bounds = bounds<tab>self._channel_axis = channel_axis<tab># Make self._preprocess to be (0,1) if possible, so that don't need<tab># to do substract or divide.<tab>if preprocess is not None:<tab><tab>sub, div = np.array(preprocess)<tab><tab><IF-STMT><tab><tab><tab>sub = 0<tab><tab>if np.all(div == 1):<tab><tab><tab>div = 1<tab><tab>assert (div is None) or np.all(div)<tab><tab>self._preprocess = (sub, div)<tab>else:<tab><tab>self._preprocess = (0, 1)",0,if not np . any ( sub ) :,if sub is None :,0.016838046,6.316906128,0.236111111
"def unpickle(fname):<tab>""""""Load pickled object from `fname`""""""<tab>with smart_open(fname, ""rb"") as f:<tab><tab># Because of loading from S3 load can't be used (missing readline in smart_open)<tab><tab><IF-STMT><tab><tab><tab>return _pickle.load(f, encoding=""latin1"")<tab><tab>else:<tab><tab><tab>return _pickle.loads(f.read())",0,"if sys . version_info > ( 3 , 0 ) :",if sys . version_info [ 0 ] < 3 :,0.179911858,42.48182083,0.6
"def get_new_setup_py_lines():<tab>global version<tab>with open(""setup.py"", ""r"") as sf:<tab><tab>current_setup = sf.readlines()<tab>for line in current_setup:<tab><tab><IF-STMT><tab><tab><tab>major, minor = re.findall(r""VERSION = '(\d+)\.(\d+)'"", line)[0]<tab><tab><tab>version = ""{}.{}"".format(major, int(minor) + 1)<tab><tab><tab>yield ""VERSION = '{}'\n"".format(version)<tab><tab>else:<tab><tab><tab>yield line",0,"if line . startswith ( ""VERSION = "" ) :","if line . startswith ( ""VERSION"" ) :",0.482029036,71.0866789,1
"def make_buffers_dict(observables):<tab>""""""Makes observable states in a dict.""""""<tab># Use `type(observables)` so that our output structure respects the<tab># original dict subclass (e.g. OrderedDict).<tab>out_dict = type(observables)()<tab>for key, value in six.iteritems(observables):<tab><tab><IF-STMT><tab><tab><tab>out_dict[key] = _EnabledObservable(<tab><tab><tab><tab>value, physics, random_state, self._strip_singleton_buffer_dim<tab><tab><tab>)<tab>return out_dict",0,if value . enabled :,if value is not None :,0.057429006,17.9652056,0.357142857
"def _callFUT(self, config_file, global_conf=None, _loader=None):<tab>import pyramid.paster<tab>old_loader = pyramid.paster.get_config_loader<tab>try:<tab><tab><IF-STMT><tab><tab><tab>pyramid.paster.get_config_loader = _loader<tab><tab>return pyramid.paster.setup_logging(config_file, global_conf)<tab>finally:<tab><tab>pyramid.paster.get_config_loader = old_loader",1,if _loader is not None :,if _loader is not None :,0.75,100,1
"def _csv(self, match=None, dump=None):<tab>if dump is None:<tab><tab>dump = self._dump(match)<tab>for record in dump:<tab><tab>row = []<tab><tab>for field in record:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>row.append(""%i"" % field)<tab><tab><tab>elif field is None:<tab><tab><tab><tab>row.append("""")<tab><tab><tab>else:<tab><tab><tab><tab>row.append(""'%s'"" % field)<tab><tab>yield "","".join(row)",1,"if isinstance ( field , int ) :","if isinstance ( field , int ) :",0.75,100,1
"def preprocess_envs(args_envs):<tab>envs_map = {}<tab>for item in args_envs:<tab><tab>i = item.find("":"")<tab><tab><IF-STMT><tab><tab><tab>key = item[:i]<tab><tab><tab>val = item[i + 1 :]<tab><tab>envs_map[key] = val<tab>return envs_map",0,if i != - 1 :,if i >= 0 :,0.051719732,16.34121945,0.6
"def _get_most_recent_update(self, versions):<tab>recent = None<tab>for version in versions:<tab><tab>updated = datetime.datetime.strptime(version[""updated""], ""%Y-%m-%dT%H:%M:%SZ"")<tab><tab><IF-STMT><tab><tab><tab>recent = updated<tab><tab>elif updated > recent:<tab><tab><tab>recent = updated<tab>return recent.strftime(""%Y-%m-%dT%H:%M:%SZ"")",0,if not recent :,if updated < recent :,0.080290295,23.64354023,0.6
"def _to_string_infix(self, ostream, idx, verbose):<tab>if verbose:<tab><tab>ostream.write("" , "")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>ostream.write("" - "")<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>ostream.write("" + "")",0,if type ( self . _args [ idx ] ) is _NegationExpression :,if idx == 0 :,0.009477309,2.383515454,0.26984127
"def __init__(self, bert, num_classes=2, dropout=0.0, prefix=None, params=None):<tab>super(BERTClassifier, self).__init__(prefix=prefix, params=params)<tab>self.bert = bert<tab>with self.name_scope():<tab><tab>self.classifier = nn.HybridSequential(prefix=prefix)<tab><tab><IF-STMT><tab><tab><tab>self.classifier.add(nn.Dropout(rate=dropout))<tab><tab>self.classifier.add(nn.Dense(units=num_classes))",0,if dropout :,if dropout > 0.0 :,0.097914534,1.00E-10,1
"def __iter__(self):<tab>for i, field in enumerate(self.fields):<tab><tab><IF-STMT><tab><tab><tab>yield AdminReadonlyField(<tab><tab><tab><tab>self.form, field, is_first=(i == 0), model_admin=self.model_admin<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>yield AdminField(self.form, field, is_first=(i == 0))",0,if field in self . readonly_fields :,if self . readonly :,0.128034894,20.30072761,0.30952381
"def boolean(value):<tab>if isinstance(value, str):<tab><tab>v = value.lower()<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if v in (""0"", ""no"", ""false"", ""off""):<tab><tab><tab>return False<tab><tab>raise ValueError(value)<tab>return bool(value)",1,"if v in ( ""1"" , ""yes"" , ""true"" , ""on"" ) :","if v in ( ""1"" , ""yes"" , ""true"" , ""on"" ) :",0.75,100,1
"def xdir(obj, return_values=False):<tab>for attr in dir(obj):<tab><tab><IF-STMT><tab><tab><tab>if return_values:<tab><tab><tab><tab>yield attr, getattr(obj, attr)<tab><tab><tab>else:<tab><tab><tab><tab>yield attr",0,"if attr [ : 2 ] != ""__"" and attr [ - 2 : ] != ""__"" :","if not attr . startswith ( ""_"" ) :",0.007080318,3.000003569,0.274725275
"def get_current_stock(self):<tab>for d in self.get(""supplied_items""):<tab><tab><IF-STMT><tab><tab><tab>bin = frappe.db.sql(<tab><tab><tab><tab>""select actual_qty from `tabBin` where item_code = %s and warehouse = %s"",<tab><tab><tab><tab>(d.rm_item_code, self.supplier_warehouse),<tab><tab><tab><tab>as_dict=1,<tab><tab><tab>)<tab><tab><tab>d.current_stock = bin and flt(bin[0][""actual_qty""]) or 0",0,if self . supplier_warehouse :,if d . current_stock is None :,0.113063935,6.74255593,0.291666667
"def getvars(request, excludes):<tab>getvars = request.GET.copy()<tab>excludes = excludes.split("","")<tab>for p in excludes:<tab><tab><IF-STMT><tab><tab><tab>del getvars[p]<tab><tab>if len(getvars.keys()) > 0:<tab><tab><tab>return ""&%s"" % getvars.urlencode()<tab><tab>else:<tab><tab><tab>return """"",1,if p in getvars :,if p in getvars :,0.75,100,1
"def read(cls, reader, dump=None):<tab>code = reader.read_u1()<tab># Create an index of all known opcodes.<tab>if Opcode.opcodes is None:<tab><tab>Opcode.opcodes = {}<tab><tab>for name in globals():<tab><tab><tab>klass = globals()[name]<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>Opcode.opcodes[klass.code] = klass<tab><tab><tab>except TypeError:<tab><tab><tab><tab>pass<tab>instance = Opcode.opcodes[code].read_extra(reader, dump)<tab>if dump:<tab><tab>reader.debug(""<tab>"" * dump, ""%3d: %s"" % (reader.offset, instance))<tab>return instance",0,"if name != ""Opcode"" and issubclass ( klass , Opcode ) :",if klass . code is not None :,0.074488795,3.029704891,0.181818182
"def clean(self):<tab>username = self.cleaned_data.get(""username"")<tab>password = self.cleaned_data.get(""password"")<tab>message = ERROR_MESSAGE<tab>if username and password:<tab><tab>self.user_cache = authenticate(username=username, password=password)<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab><tab>elif not self.user_cache.is_active or not self.user_cache.is_staff:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab>return self.cleaned_data",1,if self . user_cache is None :,if self . user_cache is None :,0.75,100,1
"def currentLevel(self):<tab>currentStr = """"<tab>for stackType, stackValue in self.stackVals:<tab><tab>if stackType == ""dict"":<tab><tab><tab>if isinstance(stackValue, str):<tab><tab><tab><tab>currentStr += ""['"" + stackValue + ""']""<tab><tab><tab>else:  # numeric key...<tab><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab><IF-STMT><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""getattr"":<tab><tab><tab>currentStr += "".__getattribute__('"" + stackValue + ""')""<tab><tab>else:<tab><tab><tab>raise Exception(f""Cannot get attribute of type {stackType}"")<tab>return currentStr",0,"elif stackType == ""listLike"" :","elif stackType == ""list"" :",0.642872021,59.46035575,1
"def dump(self, out=sys.stdout, code2cid=None, code=None):<tab>if code2cid is None:<tab><tab>code2cid = self.code2cid<tab><tab>code = ()<tab>for (k, v) in sorted(code2cid.iteritems()):<tab><tab>c = code + (k,)<tab><tab><IF-STMT><tab><tab><tab>out.write(""code %r = cid %d\n"" % (c, v))<tab><tab>else:<tab><tab><tab>self.dump(out=out, code2cid=v, code=c)<tab>return",0,"if isinstance ( v , int ) :",if code :,0.015519099,1.00E-10,0.3
"def __init__(self, text, menu):<tab>self.text = text<tab>self.menu = menu<tab>print(text)<tab>for i, option in enumerate(menu):<tab><tab>menunum = i + 1<tab><tab># Check to see if this line has the 'return to main menu' code<tab><tab>match = re.search(""0D"", option)<tab><tab># If it's not the return to menu line:<tab><tab>if not match:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print((""   %s) %s"" % (menunum, option)))<tab><tab><tab>else:<tab><tab><tab><tab>print((""  %s) %s"" % (menunum, option)))<tab><tab>else:<tab><tab><tab>print(""\n  99) Return to Main Menu\n"")<tab>return",0,if menunum < 10 :,"if ""return"" in menu :",0.034123066,7.809849842,0.333333333
"def receive(self, sock):<tab>""""""Receive a message on ``sock``.""""""<tab>msg = None<tab>data = b""""<tab>recv_done = False<tab>recv_len = -1<tab>while not recv_done:<tab><tab>buf = sock.recv(BUFSIZE)<tab><tab>if buf is None or len(buf) == 0:<tab><tab><tab>raise Exception(""socket closed"")<tab><tab><IF-STMT><tab><tab><tab>recv_len = struct.unpack("">I"", buf[:4])[0]<tab><tab><tab>data += buf[4:]<tab><tab><tab>recv_len -= len(data)<tab><tab>else:<tab><tab><tab>data += buf<tab><tab><tab>recv_len -= len(buf)<tab><tab>recv_done = recv_len == 0<tab>msg = pickle.loads(data)<tab>return msg",0,if recv_len == - 1 :,if len ( buf ) == 4 :,0.023749772,11.99014838,0.3
"def apply_shortcuts(self):<tab>""""""Apply shortcuts settings to all widgets/plugins""""""<tab>toberemoved = []<tab>for index, (qobject, context, name, default) in enumerate(self.shortcut_data):<tab><tab>keyseq = QKeySequence(get_shortcut(context, name, default))<tab><tab>try:<tab><tab><tab>if isinstance(qobject, QAction):<tab><tab><tab><tab>qobject.setShortcut(keyseq)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>qobject.setKey(keyseq)<tab><tab>except RuntimeError:<tab><tab><tab># Object has been deleted<tab><tab><tab>toberemoved.append(index)<tab>for index in sorted(toberemoved, reverse=True):<tab><tab>self.shortcut_data.pop(index)",0,"elif isinstance ( qobject , QShortcut ) :","elif isinstance ( qobject , QComboBox ) :",0.547301779,59.46035575,0.666666667
"def _resolved_values(self):<tab>values = []<tab>for k, v in self.values.items() if hasattr(self.values, ""items"") else self.values:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(k, util.string_types):<tab><tab><tab><tab>desc = _entity_descriptor(self.mapper, k)<tab><tab><tab><tab>values.extend(desc._bulk_update_tuples(v))<tab><tab><tab>elif isinstance(k, attributes.QueryableAttribute):<tab><tab><tab><tab>values.extend(k._bulk_update_tuples(v))<tab><tab><tab>else:<tab><tab><tab><tab>values.append((k, v))<tab><tab>else:<tab><tab><tab>values.append((k, v))<tab>return values",0,if self . mapper :,"if isinstance ( v , collections . Mapping ) :",0.025806627,5.522397784,0.229166667
"def remove_callback(self, callback, events=None):<tab>if events is None:<tab><tab>for event in self._plugin_lifecycle_callbacks:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)<tab>else:<tab><tab>if isinstance(events, basestring):<tab><tab><tab>events = [events]<tab><tab>for event in events:<tab><tab><tab>if callback in self._plugin_lifecycle_callbacks[event]:<tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)",1,if callback in self . _plugin_lifecycle_callbacks [ event ] :,if callback in self . _plugin_lifecycle_callbacks [ event ] :,0.75,100,1
"def _thd_parse_volumes(self, volumes):<tab>volume_list = []<tab>binds = {}<tab>for volume_string in volumes or []:<tab><tab>try:<tab><tab><tab>bind, volume = volume_string.split("":"", 1)<tab><tab>except ValueError:<tab><tab><tab>config.error(<tab><tab><tab><tab>""Invalid volume definition for docker ""<tab><tab><tab><tab>""%s. Skipping..."" % volume_string<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>ro = False<tab><tab><IF-STMT><tab><tab><tab>ro = volume[-2:] == ""ro""<tab><tab><tab>volume = volume[:-3]<tab><tab>volume_list.append(volume)<tab><tab>binds[bind] = {""bind"": volume, ""ro"": ro}<tab>return volume_list, binds",0,"if volume . endswith ( "":ro"" ) or volume . endswith ( "":rw"" ) :","if volume . endswith ( "".ro"" ) :",0.219956625,26.94289965,0.638095238
"def __init__(self, model, **kwargs):<tab>self.model = model<tab>for key, value in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""%s() received an invalid keyword %r"" % (self.__class__.__name__, key)<tab><tab><tab>)<tab><tab>setattr(self, key, value)<tab>self.handle_model()",1,"if not hasattr ( self , key ) :","if not hasattr ( self , key ) :",0.75,100,1
"def __getitem__(self, key):<tab>if isinstance(key, numbers.Number):<tab><tab>l = len(self)<tab><tab>if key >= l:<tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab>if key < 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><tab>key += l<tab><tab>return self(key + 1)<tab>elif isinstance(key, slice):<tab><tab>raise ValueError(<tab><tab><tab>self.impl.__class__.__name__ + "" object does not support slicing""<tab><tab>)<tab>else:<tab><tab>return self(key)",0,if key < - l :,if key >= l :,0.064836733,22.95748847,1
"def _get_formatted(self, model, key):<tab>value = model._type(key).format(model.get(key))<tab>if isinstance(value, bytes):<tab><tab>value = value.decode(""utf-8"", ""ignore"")<tab>if self.for_path:<tab><tab>sep_repl = beets.config[""path_sep_replace""].as_str()<tab><tab>for sep in (os.path.sep, os.path.altsep):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.replace(sep, sep_repl)<tab>return value",0,if sep :,if sep != sep_repl :,0.097914534,1.00E-10,1
"def publish(self, name, stat):<tab>try:<tab><tab>topic = ""stat.%s"" % str(name)<tab><tab><IF-STMT><tab><tab><tab>topic += "".%d"" % stat[""subtopic""]<tab><tab>stat = json.dumps(stat)<tab><tab>logger.debug(""Sending %s"" % stat)<tab><tab>self.socket.send_multipart([b(topic), stat])<tab>except zmq.ZMQError:<tab><tab>if self.socket.closed:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",1,"if ""subtopic"" in stat :","if ""subtopic"" in stat :",0.75,100,1
def logic():<tab>while 1:<tab><tab>yield a<tab><tab>var = 0<tab><tab>out.next = 0<tab><tab>for i in downrange(len(a)):<tab><tab><tab>if a[i] == 0:<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>for j in downrange(i - 1):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>pass<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>out.next = j<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>break,1,if a [ j ] == 0 :,if a [ j ] == 0 :,0.75,100,1
"def get_abstract_models(self, appmodels):<tab>abstract_models = []<tab>for appmodel in appmodels:<tab><tab>abstract_models += [<tab><tab><tab>abstract_model<tab><tab><tab>for abstract_model in appmodel.__bases__<tab><tab><tab><IF-STMT><tab><tab>]<tab>abstract_models = list(set(abstract_models))  # remove duplicates<tab>return abstract_models",0,"if hasattr ( abstract_model , ""_meta"" ) and abstract_model . _meta . abstract",if abstract_model not in abstract_models,0.008617378,6.156811702,0.278195489
"def _sanitize_field_name(self, field_name: str) -> str:<tab>try:<tab><tab>if self._meta.get_field(field_name).get_internal_type() == ""ForeignKey"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return field_name + ""_id""<tab>except FieldDoesNotExist:<tab><tab>pass<tab>return field_name",0,"if not field_name . endswith ( ""_id"" ) :","if self . _meta . get_field ( field_name ) . get_internal_type ( ) == ""ForeignKey"" :",0.01453745,6.878430971,0.392592593
"def find_enabled_item(self, e):<tab>x, y = e.local<tab>if (<tab><tab>0<tab><tab><= x<tab><tab>< (<tab><tab><tab>self.width - self.margin - self.scroll_button_size<tab><tab><tab>if self.scrolling<tab><tab><tab>else self.width<tab><tab>)<tab>):<tab><tab>h = self.font.get_linesize()<tab><tab>i = (y - h // 2) // h + self.scroll<tab><tab>items = self._items<tab><tab><IF-STMT><tab><tab><tab>item = items[i]<tab><tab><tab>if item.enabled:<tab><tab><tab><tab>return item",0,if 0 <= i < len ( items ) :,if i < len ( items ) :,0.420645421,59.75579891,0.318181818
"def addColumn(self, *cols, index=None):<tab>""Insert all *cols* into columns at *index*, or append to end of columns if *index* is None.  Return first column.""<tab>for i, col in enumerate(cols):<tab><tab>vd.addUndo(self.columns.remove, col)<tab><tab><IF-STMT><tab><tab><tab>index = len(self.columns)<tab><tab>col.recalc(self)<tab><tab>self.columns.insert(index + i, col)<tab><tab>Sheet.visibleCols.fget.cache_clear()<tab>return cols[0]",1,if index is None :,if index is None :,0.75,100,1
"def _compare_values(self, result, source):<tab>from google.protobuf.struct_pb2 import ListValue<tab>from google.protobuf.struct_pb2 import Value<tab>for found, expected in zip(result, source):<tab><tab>self.assertIsInstance(found, ListValue)<tab><tab>self.assertEqual(len(found.values), len(expected))<tab><tab>for found_cell, expected_cell in zip(found.values, expected):<tab><tab><tab>self.assertIsInstance(found_cell, Value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(int(found_cell.string_value), expected_cell)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(found_cell.string_value, expected_cell)",0,"if isinstance ( expected_cell , int ) :","if isinstance ( found_cell . string_value , int ) :",0.305487522,28.65612242,1
"def _traverse(op):<tab>if topi.tag.is_broadcast(op.tag):<tab><tab>if not op.same_as(output.op):<tab><tab><tab>if not op.axis:<tab><tab><tab><tab>const_ops.append(op)<tab><tab><tab>else:<tab><tab><tab><tab>ewise_ops.append(op)<tab><tab>for tensor in op.input_tensors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ewise_inputs.append((op, tensor))<tab><tab><tab>else:<tab><tab><tab><tab>_traverse(tensor.op)<tab>else:<tab><tab>assert op.tag == ""dense_pack""<tab><tab>dense_res.append(op)",0,"if isinstance ( tensor . op , tvm . te . PlaceholderOp ) :",if not op . same_as ( tensor . op ) :,0.11609199,22.88275996,0.208333333
"def update_annotation(<tab>parameters: Sequence[cst.Param], annotations: Sequence[cst.Param]) -> List[cst.Param]:<tab>parameter_annotations = {}<tab>annotated_parameters = []<tab>for parameter in annotations:<tab><tab><IF-STMT><tab><tab><tab>parameter_annotations[parameter.name.value] = parameter.annotation<tab>for parameter in parameters:<tab><tab>key = parameter.name.value<tab><tab>if key in parameter_annotations and (<tab><tab><tab>self.overwrite_existing_annotations or not parameter.annotation<tab><tab>):<tab><tab><tab>parameter = parameter.with_changes(annotation=parameter_annotations[key])<tab><tab>annotated_parameters.append(parameter)<tab>return annotated_parameters",1,if parameter . annotation :,if parameter . annotation :,0.75,100,1
"def _modules(self, module_paths, component_name):<tab>for path in module_paths:<tab><tab>for filename in os.listdir(path):<tab><tab><tab>name, ext = os.path.splitext(filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>root_relative_path = os.path.join(path, name)[<tab><tab><tab><tab><tab>len(self.root_path) + len(os.path.sep) :<tab><tab><tab><tab>]<tab><tab><tab><tab>module_name = ""%s.%s"" % (<tab><tab><tab><tab><tab>component_name,<tab><tab><tab><tab><tab>root_relative_path.replace(os.path.sep, "".""),<tab><tab><tab><tab>)<tab><tab><tab><tab>yield module_name",0,"if ext . endswith ( "".py"" ) :","if ext == "".py"" :",0.037304456,29.53872021,0.727272727
"def run(self):<tab># Make some objects emit lights<tab>for obj in bpy.context.scene.objects:<tab><tab>if ""modelId"" in obj:<tab><tab><tab>obj_id = obj[""modelId""]<tab><tab><tab># In the case of the lamp<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._make_lamp_emissive(obj, self.lights[obj_id])<tab><tab><tab># Make the windows emit light<tab><tab><tab>if obj_id in self.windows:<tab><tab><tab><tab>self._make_window_emissive(obj)<tab><tab><tab># Also make ceilings slightly emit light<tab><tab><tab>if obj.name.startswith(""Ceiling#""):<tab><tab><tab><tab>self._make_ceiling_emissive(obj)",1,if obj_id in self . lights :,if obj_id in self . lights :,0.75,100,1
"def get_chart_data(self):<tab>rows = []<tab>for row in self.data:<tab><tab>row = frappe._dict(row)<tab><tab><IF-STMT><tab><tab><tab>values = [row.range1, row.range2, row.range3, row.range4, row.range5]<tab><tab><tab>precision = cint(frappe.db.get_default(""float_precision"")) or 2<tab><tab><tab>rows.append({""values"": [flt(val, precision) for val in values]})<tab>self.chart = {<tab><tab>""data"": {""labels"": self.ageing_column_labels, ""datasets"": rows},<tab><tab>""type"": ""percentage"",<tab>}",0,if not cint ( row . bold ) :,if row :,0.013954293,1.00E-10,0.287878788
"def suite(aggressive):<tab>""""""Run against pep8 test suite.""""""<tab>result = True<tab>path = os.path.join(os.path.dirname(__file__), ""suite"")<tab>for filename in os.listdir(path):<tab><tab>filename = os.path.join(path, filename)<tab><tab><IF-STMT><tab><tab><tab>print(filename, file=sys.stderr)<tab><tab><tab>result = run(filename, aggressive=aggressive) and result<tab>if result:<tab><tab>print(GREEN + ""Okay"" + END)<tab>return result",0,"if filename . endswith ( "".py"" ) :",if result :,0.016200585,1.00E-10,0.381818182
"def list_generator(pages, num_results):<tab>result = []<tab># get first page items<tab>page = list(next(pages))<tab>result += page<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab># handle num results<tab><tab>if num_results is not None:<tab><tab><tab>if num_results == len(result):<tab><tab><tab><tab>break<tab><tab>page = list(next(pages))<tab><tab>result += page<tab>return result",0,if not pages . continuation_token :,if len ( page ) < num_results :,0.022316444,5.522397784,0.333333333
"def _detect_too_many_digits(f):<tab>ret = []<tab>for node in f.nodes:<tab><tab># each node contains a list of IR instruction<tab><tab>for ir in node.irs:<tab><tab><tab># iterate over all the variables read by the IR<tab><tab><tab>for read in ir.read:<tab><tab><tab><tab># if the variable is a constant<tab><tab><tab><tab>if isinstance(read, Constant):<tab><tab><tab><tab><tab># read.value can return an int or a str. Convert it to str<tab><tab><tab><tab><tab>value_as_str = read.original_value<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab># Info to be printed<tab><tab><tab><tab><tab><tab>ret.append(node)<tab>return ret",0,"if ""00000"" in value_as_str :",if value_as_str . isdigit ( ) :,0.029730601,38.16330911,0.5
"def write_varint(trans, n):<tab>out = []<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>out.append(n)<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>out.append((n & 0xFF) | 0x80)<tab><tab><tab>n = n >> 7<tab>data = array.array(""B"", out).tostring()<tab>if PY3:<tab><tab>trans.write(data)<tab>else:<tab><tab>trans.write(bytes(data))",0,if n & ~ 0x7F == 0 :,if n & 0x80 :,0.078889319,19.1992428,0.481481481
"def __call__(self, environ, start_response):<tab>query_string = environ.get(""QUERY_STRING"")<tab>if ""sql_debug=1"" in query_string:<tab><tab>import galaxy.app<tab><tab><IF-STMT><tab><tab><tab>galaxy.app.app.model.thread_local_log.log = True<tab>try:<tab><tab>reset_request_query_counts()<tab><tab>return self.application(environ, start_response)<tab>finally:<tab><tab>log_request_query_counts(environ.get(""PATH_INFO""))",0,if galaxy . app . app . model . thread_local_log :,if galaxy . app . app . model . thread_local_log . log :,0.583820001,83.46439636,0.822222222
"def SvGetSocketInfo(socket):<tab>""""""returns string to show in socket label""""""<tab>global socket_data_cache<tab>ng = socket.id_data.tree_id<tab>if socket.is_output:<tab><tab>s_id = socket.socket_id<tab>elif socket.is_linked:<tab><tab>other = socket.other<tab><tab>if other and hasattr(other, ""socket_id""):<tab><tab><tab>s_id = other.socket_id<tab><tab>else:<tab><tab><tab>return """"<tab>else:<tab><tab>return """"<tab>if ng in socket_data_cache:<tab><tab>if s_id in socket_data_cache[ng]:<tab><tab><tab>data = socket_data_cache[ng][s_id]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return str(len(data))<tab>return """"",1,if data :,if data :,0.531170663,1.00E-10,1
"def print_nested_help(self, args: argparse.Namespace) -> None:<tab>level = 0<tab>parser = self.main_parser<tab>while True:<tab><tab>if parser._subparsers is None:<tab><tab><tab>break<tab><tab>if parser._subparsers._actions is None:<tab><tab><tab>break<tab><tab>choices = parser._subparsers._actions[-1].choices<tab><tab>value = getattr(args, ""level_%d"" % level)<tab><tab>if value is None:<tab><tab><tab>parser.print_help()<tab><tab><tab>return<tab><tab>if not choices:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>parser = choices[value]<tab><tab>else:<tab><tab><tab>return<tab><tab>level += 1",0,"if isinstance ( choices , dict ) :",if value in choices :,0.019907918,7.715486568,0.285714286
"def tag_configure(self, *args, **keys):<tab>trace = False and not g.unitTesting<tab>if trace:<tab><tab>g.trace(args, keys)<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab>if val:<tab><tab><tab>self.configDict[key] = val<tab><tab><IF-STMT><tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",1,if underline :,if underline :,0.531170663,1.00E-10,1
"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.c99highlighting and value in self.c99_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.platformhighlighting and value in self.linux_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",0,if self . stdlibhighlighting and value in self . stdlib_types :,if self . windowshighlighting and value in self . windows_types :,0.493386326,47.58733096,0.75
"def materialize_as_ndarray(a):<tab>""""""Convert distributed arrays to ndarrays.""""""<tab>if type(a) in (list, tuple):<tab><tab><IF-STMT><tab><tab><tab>return da.compute(*a, sync=True)<tab><tab>return tuple(np.asarray(arr) for arr in a)<tab>return np.asarray(a)",0,"if da is not None and any ( isinstance ( arr , da . Array ) for arr in a ) :",if len ( a ) == 2 :,0.009399192,2.828201225,0.0975
"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if isinstance(rv, flask.Response):<tab><tab>try:<tab><tab><tab>result = etag<tab><tab><tab>if callable(result):<tab><tab><tab><tab>result = result(rv)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.set_etag(result)<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the etag value for response {!r}"".format(rv)<tab><tab><tab>)<tab>return rv",0,if result :,if result is not None :,0.090364769,1.00E-10,0.4
"def applyBC(self):<tab>""""""apply boundary conditions""""""<tab>deltaR = 2.0<tab>for coord in self.pos:<tab><tab><IF-STMT><tab><tab><tab>coord[0] = -deltaR<tab><tab>if coord[0] < -deltaR:<tab><tab><tab>coord[0] = width + deltaR<tab><tab>if coord[1] > height + deltaR:<tab><tab><tab>coord[1] = -deltaR<tab><tab>if coord[1] < -deltaR:<tab><tab><tab>coord[1] = height + deltaR",1,if coord [ 0 ] > width + deltaR :,if coord [ 0 ] > width + deltaR :,0.75,100,1
"def removeInsideIslands(self):<tab>self.CleanPath = []<tab>cleanpath = Path(""Path"")<tab>for path in self.NewPaths:<tab><tab>for seg in path:<tab><tab><tab>inside = False<tab><tab><tab>for island in self.IntersectedIslands:<tab><tab><tab><tab>issegin = island.isSegInside(seg) == 1<tab><tab><tab><tab>if issegin:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>inside = True<tab><tab><tab><tab><tab><tab>break<tab><tab><tab>if not inside:<tab><tab><tab><tab>cleanpath.append(seg)<tab>cleanpath = cleanpath.split2contours()<tab>self.CleanPath.extend(cleanpath)",0,if not seg in island :,if not inside :,0.10449376,21.44409712,0.357142857
"def _parse_lines(self, linesource):<tab>""""""Parse lines of text for functions and classes""""""<tab>functions = []<tab>classes = []<tab>for line in linesource:<tab><tab>if line.startswith(""def "") and line.count(""(""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(name)<tab><tab>elif line.startswith(""class ""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>classes.append(name)<tab><tab>else:<tab><tab><tab>pass<tab>functions.sort()<tab>classes.sort()<tab>return functions, classes",1,"if not name . startswith ( ""_"" ) :","if not name . startswith ( ""_"" ) :",0.75,100,1
"def process(self, buckets, event=None):<tab>results = []<tab>with self.executor_factory(max_workers=2) as w:<tab><tab>futures = {w.submit(self.process_bucket, bucket): bucket for bucket in buckets}<tab><tab>for f in as_completed(futures):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.append(futures[f])<tab>return results",0,if f . result ( ) :,if f . done ( ) :,0.38848939,41.11336169,0.6
"def build_polymorphic_ctypes_map(cls):<tab># {'1': 'unified_job', '2': 'Job', '3': 'project_update', ...}<tab>mapping = {}<tab>for ct in ContentType.objects.filter(app_label=""main""):<tab><tab>ct_model_class = ct.model_class()<tab><tab><IF-STMT><tab><tab><tab>mapping[ct.id] = camelcase_to_underscore(ct_model_class.__name__)<tab>return mapping",0,"if ct_model_class and issubclass ( ct_model_class , cls ) :","if hasattr ( ct_model_class , ""__name__"" ) :",0.071124364,38.89055612,0.30952381
"def expand_decodings(self, node: Node) -> None:<tab>val = node.level.result.value<tab>for decoder in self.get_decoders_for(type(val)):<tab><tab>inst = self._config()(decoder)<tab><tab>res = inst(val)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>new_node = Node.decoding(<tab><tab><tab><tab>config=self._config(), route=inst, result=res, source=node<tab><tab><tab>)<tab><tab>except DuplicateNode:<tab><tab><tab>continue<tab><tab>logger.trace(""Nesting encodings"")<tab><tab>self.recursive_expand(new_node, False)",1,if res is None :,if res is None :,0.75,100,1
"def test_file(self):<tab>a = 3.33 + 4.43j<tab>b = 5.1 + 2.3j<tab>fo = None<tab>try:<tab><tab>fo = open(test_support.TESTFN, ""wb"")<tab><tab>print >> fo, a, b<tab><tab>fo.close()<tab><tab>fo = open(test_support.TESTFN, ""rb"")<tab><tab>self.assertEqual(fo.read(), ""%s %s\n"" % (a, b))<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>fo.close()<tab><tab>test_support.unlink(test_support.TESTFN)",0,if ( fo is not None ) and ( not fo . closed ) :,if fo is not None :,0.080119012,12.54753099,0.635416667
"def repl(m):<tab>if m.group(2) is not None:<tab><tab>high = int(m.group(1), 16)<tab><tab>low = int(m.group(2), 16)<tab><tab><IF-STMT><tab><tab><tab>cp = ((high - 0xD800) << 10) + (low - 0xDC00) + 0x10000<tab><tab><tab>return unichr(cp)<tab><tab>else:<tab><tab><tab>return unichr(high) + unichr(low)<tab>else:<tab><tab>return unichr(int(m.group(1), 16))",0,if 0xD800 <= high <= 0xDBFF and 0xDC00 <= low <= 0xDFFF :,"if m . group ( 3 ) == ""x"" :",0.01033327,3.211527255,0.142857143
"def generate_credits(user, start_date, end_date, **kwargs):<tab>""""""Generate credits data for given component.""""""<tab>result = []<tab>base = Change.objects.content()<tab>if user:<tab><tab>base = base.filter(author=user)<tab>for language in Language.objects.filter(**kwargs).distinct().iterator():<tab><tab>authors = base.filter(language=language, **kwargs).authors_list(<tab><tab><tab>(start_date, end_date)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>result.append({language.name: sorted(authors, key=lambda item: item[2])})<tab>return result",1,if not authors :,if not authors :,0.75,100,1
"def history_prev(self):<tab>""""""Go back in the history.""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>item = self._history.start(self.text().strip())<tab><tab>else:<tab><tab><tab>item = self._history.previtem()<tab>except (cmdhistory.HistoryEmptyError, cmdhistory.HistoryEndReachedError):<tab><tab>return<tab>self.setText(item)",0,if not self . _history . is_browsing ( ) :,if self . text ( ) :,0.070938701,13.65332389,0.4
"def destroy(self):<tab>self._bind()<tab>for name in ""jobItems"", ""jobFileIDs"", ""files"", ""statsFiles"", ""statsFileIDs"":<tab><tab>resource = getattr(self, name)<tab><tab>if resource is not None:<tab><tab><tab>if isinstance(resource, AzureTable):<tab><tab><tab><tab>resource.delete_table()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resource.delete_container()<tab><tab><tab>else:<tab><tab><tab><tab>assert False<tab><tab><tab>setattr(self, name, None)",0,"elif isinstance ( resource , AzureBlobContainer ) :","elif isinstance ( resource , AzureContainer ) :",0.547301779,59.46035575,0.666666667
"def user_defined_os():<tab>if menu.options.os:<tab><tab><IF-STMT><tab><tab><tab>settings.TARGET_OS = ""win""<tab><tab><tab>return True<tab><tab>elif menu.options.os.lower() == ""unix"":<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>err_msg = ""You specified wrong value '"" + menu.options.os + ""' ""<tab><tab><tab>err_msg += ""as an operation system. The value, must be 'Windows' or 'Unix'.""<tab><tab><tab>print(settings.print_critical_msg(err_msg))<tab><tab><tab>raise SystemExit()",0,"if menu . options . os . lower ( ) == ""windows"" :","if menu . options . os . lower ( ) == ""win"" :",0.67220614,83.71170099,1
"def test_save(art_warning, image_dl_estimator):<tab>try:<tab><tab>classifier, _ = image_dl_estimator(from_logits=True)<tab><tab>t_file = tempfile.NamedTemporaryFile()<tab><tab>model_path = t_file.name<tab><tab>t_file.close()<tab><tab>filename = ""model_to_save""<tab><tab>classifier.save(filename, path=model_path)<tab><tab>assert path.exists(model_path)<tab><tab>created_model = False<tab><tab>for file in listdir(model_path):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>created_model = True<tab><tab>assert created_model<tab>except ARTTestException as e:<tab><tab>art_warning(e)",0,if filename in file :,"if isfile ( path . join ( model_path , file ) ) :",0.023974581,3.458592114,0.242647059
"def set_extra_data(self, extra_data=None):<tab>if extra_data and self.extra_data != extra_data:<tab><tab><IF-STMT><tab><tab><tab>self.extra_data.update(extra_data)<tab><tab>else:<tab><tab><tab>self.extra_data = extra_data<tab><tab>return True",0,"if self . extra_data and not isinstance ( self . extra_data , str ) :","if isinstance ( extra_data , dict ) :",0.024295439,14.86236626,0.225
"def get_image_dimensions(path):<tab>""""""Returns the (width, height) of an image at a given path.""""""<tab>p = ImageFile.Parser()<tab>fp = open(path, ""rb"")<tab>while 1:<tab><tab>data = fp.read(1024)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>p.feed(data)<tab><tab>if p.image:<tab><tab><tab>return p.image.size<tab><tab><tab>break<tab>fp.close()<tab>return None",1,if not data :,if not data :,0.75,100,1
"def language_suffixes():<tab>for lang in NSLocale.preferredLanguages():<tab><tab>while True:<tab><tab><tab>yield ""_"" + lang if lang != ""en"" else """"<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lang = lang[: lang.rfind(""-"")]<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>yield """"",0,"if ""-"" in lang :","if lang . endswith ( ""-"" ) :",0.029323261,18.575058,0.4
"def decode_binary(binarystring):<tab>""""""Decodes a binary string into it's integer value.""""""<tab>n = 0<tab>for c in binarystring:<tab><tab>if c == ""0"":<tab><tab><tab>d = 0<tab><tab><IF-STMT><tab><tab><tab>d = 1<tab><tab>else:<tab><tab><tab>raise ValueError(""Not an binary number"", binarystring)<tab><tab># Could use ((n << 3 ) | d), but python 2.3 issues a FutureWarning.<tab><tab>n = (n * 2) + d<tab>return n",1,"elif c == ""1"" :","elif c == ""1"" :",1,100,1
"def serialize_groups_for_summary(node):<tab>groups = node.osf_groups<tab>n_groups = len(groups)<tab>group_string = """"<tab>for index, group in enumerate(groups):<tab><tab>if index == n_groups - 1:<tab><tab><tab>separator = """"<tab><tab><IF-STMT><tab><tab><tab>separator = "" & ""<tab><tab>else:<tab><tab><tab>separator = "", ""<tab><tab>group_string = group_string + group.name + separator<tab>return group_string",0,elif index == n_groups - 2 :,elif index == 0 :,0.225136336,27.58512993,0.6
"def _save(self, req_method, requires):<tab>conanfile = GenConanfile()<tab>for req in requires:<tab><tab>req2, override = req if isinstance(req, tuple) else (req, False)<tab><tab><IF-STMT><tab><tab><tab>conanfile.with_require(req2, override=override)<tab><tab>else:<tab><tab><tab>conanfile.with_requirement(req2, override=override)<tab>self.client.save({""conanfile.py"": conanfile}, clean_first=True)",0,if not req_method :,"if req_method == ""require"" :",0.045150551,17.74740528,0.619047619
"def _validate_declarations(<tab>declarations: Sequence[Union[qlast.ModuleDeclaration, qlast.DDLCommand]]) -> None:<tab># Check that top-level declarations either use fully-qualified<tab># names or are module blocks.<tab>for decl in declarations:<tab><tab><IF-STMT><tab><tab><tab>raise EdgeQLSyntaxError(<tab><tab><tab><tab>""only fully-qualified name is allowed in "" ""top-level declaration"",<tab><tab><tab><tab>context=decl.name.context,<tab><tab><tab>)",0,"if not isinstance ( decl , qlast . ModuleDeclaration ) and decl . name . module is None :","if isinstance ( decl . name , qlast . qualifiedName ) :",0.059297152,16.8603366,0.207692308
"def assess_trial(self, trial_job_id, trial_history):<tab>_logger.info(""assess trial %s %s"", trial_job_id, trial_history)<tab>id_ = trial_history[0]<tab>if id_ in self._killed:<tab><tab>return AssessResult.Bad<tab>s = 0<tab>for i, val in enumerate(trial_history):<tab><tab>s += val<tab><tab><IF-STMT><tab><tab><tab>self._killed.add(id_)<tab><tab><tab>_result.write(""%d %d\n"" % (id_, i + 1))<tab><tab><tab>_result.flush()<tab><tab><tab>return AssessResult.Bad<tab>return AssessResult.Good",0,if s % 11 == 1 :,if s == trial_history [ 1 ] :,0.041182573,11.73117516,0.577777778
"def decProcess():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>if count == -n:<tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",1,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,100,1
"def activate_profile(test=True):<tab>pr = None<tab>if test:<tab><tab><IF-STMT><tab><tab><tab>pr = cProfile.Profile()<tab><tab><tab>pr.enable()<tab><tab>else:<tab><tab><tab>log.error(""cProfile is not available on your platform"")<tab>return pr",0,if HAS_CPROFILE :,"if hasattr ( cProfile , ""enable"" ) :",0.044228356,1.00E-10,0.458333333
"def insertTestData(self, rows):<tab>for row in rows:<tab><tab>if isinstance(row, Log):<tab><tab><tab>self.logs[row.id] = row.values.copy()<tab>for row in rows:<tab><tab><IF-STMT><tab><tab><tab>lines = self.log_lines.setdefault(row.logid, [])<tab><tab><tab># make sure there are enough slots in the list<tab><tab><tab>if len(lines) < row.last_line + 1:<tab><tab><tab><tab>lines.append([None] * (row.last_line + 1 - len(lines)))<tab><tab><tab>row_lines = row.content.decode(""utf-8"").split(""\n"")<tab><tab><tab>lines[row.first_line : row.last_line + 1] = row_lines",0,"if isinstance ( row , LogChunk ) :","if isinstance ( row , Log ) :",0.549040681,59.46035575,0.666666667
"def getText(self, stuff):<tab>if isinstance(stuff, BaseWrapper):<tab><tab>stuff = stuff.item<tab>if isinstance(stuff, (Fit, TargetProfile)):<tab><tab>val, unit = self._getValue(stuff)<tab><tab>if val is None:<tab><tab><tab>return """"<tab><tab># Stick to value - 25k GJ<tab><tab><IF-STMT><tab><tab><tab>return ""{} {}"".format(formatAmount(val, *self.formatSpec), unit)<tab><tab># Stick to unit - 25 km<tab><tab>else:<tab><tab><tab>return formatAmount(val, *self.formatSpec, unitName=unit)<tab>return """"",0,if self . stickPrefixToValue :,elif unit is None :,0.025028614,10.68217516,0.083333333
"def wrap(request, *args, **kwargs):<tab>""Wrap""<tab>user = request.user.profile<tab>if ""massform"" in request.POST:<tab><tab>for key in request.POST:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>changeset = ChangeSet.objects.get(pk=request.POST[key])<tab><tab><tab><tab><tab>form = MassActionForm(<tab><tab><tab><tab><tab><tab>request.user.profile, request.POST, instance=changeset<tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>if form.is_valid() and user.has_permission(changeset, mode=""w""):<tab><tab><tab><tab><tab><tab>form.save()<tab><tab><tab><tab>except Exception:<tab><tab><tab><tab><tab>pass<tab>return f(request, *args, **kwargs)",0,"if ""mass-changeset"" in key :","if ""mass-set"" in key :",0.394778655,48.89230224,1
"def select(self, browser, locator):<tab>assert browser is not None<tab>if locator is not None:<tab><tab>if isinstance(locator, list):<tab><tab><tab>self._select_by_excludes(browser, locator)<tab><tab><tab>return<tab><tab>if locator.lower() == ""self"" or locator.lower() == ""current"":<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self._select_by_last_index(browser)<tab><tab><tab>return<tab>(prefix, criteria) = self._parse_locator(locator)<tab>strategy = self._strategies.get(prefix)<tab>if strategy is None:<tab><tab>raise ValueError(""Window locator with prefix '"" + prefix + ""' is not supported"")<tab>return strategy(browser, criteria)",0,"if locator . lower ( ) == ""new"" or locator . lower ( ) == ""popup"" :","if isinstance ( locator , int ) :",0.008095673,1.266391636,0.273809524
"def test_all(self):<tab>for context in get_contexts():<tab><tab>found = False<tab><tab>expected_context_name = context.get_name()<tab><tab>for calculated_context in get_context(self.HTML, expected_context_name):<tab><tab><tab>if calculated_context.get_name() == expected_context_name:<tab><tab><tab><tab>found = True<tab><tab><IF-STMT><tab><tab><tab>msg = ""The analysis for %s context failed, got %r instead.""<tab><tab><tab>msg = msg % (<tab><tab><tab><tab>expected_context_name,<tab><tab><tab><tab>get_context(self.HTML, expected_context_name),<tab><tab><tab>)<tab><tab><tab>self.assertTrue(False, msg)",1,if not found :,if not found :,0.75,100,1
"def visit_title(self, node: Element) -> None:<tab>if isinstance(node.parent, addnodes.seealso):<tab><tab>self.body.append('.IP ""')<tab><tab>return<tab>elif isinstance(node.parent, nodes.section):<tab><tab><IF-STMT><tab><tab><tab># skip the document title<tab><tab><tab>raise nodes.SkipNode<tab><tab>elif self.section_level == 1:<tab><tab><tab>self.body.append("".SH %s\n"" % self.deunicode(node.astext().upper()))<tab><tab><tab>raise nodes.SkipNode<tab>return super().visit_title(node)",1,if self . section_level == 0 :,if self . section_level == 0 :,0.75,100,1
"def parse_svn_stats(status):<tab>stats = RepoStats()<tab>for line in status:<tab><tab><IF-STMT><tab><tab><tab>stats.new += 1<tab><tab>elif line[0] == ""C"":<tab><tab><tab>stats.conflicted += 1<tab><tab>elif line[0] in [""A"", ""D"", ""I"", ""M"", ""R"", ""!"", ""~""]:<tab><tab><tab>stats.changed += 1<tab>return stats",0,"if line [ 0 ] == ""?"" :","if line [ 0 ] == ""A"" :",0.605621306,74.19446627,1
"def setoutput(self, spec, defs=None):<tab>self.closespec()<tab>self.closedefs()<tab>if spec:<tab><tab>if type(spec) == StringType:<tab><tab><tab>file = self.openoutput(spec)<tab><tab><tab>mine = 1<tab><tab>else:<tab><tab><tab>file = spec<tab><tab><tab>mine = 0<tab><tab>self.specfile = file<tab><tab>self.specmine = mine<tab>if defs:<tab><tab><IF-STMT><tab><tab><tab>file = self.openoutput(defs)<tab><tab><tab>mine = 1<tab><tab>else:<tab><tab><tab>file = defs<tab><tab><tab>mine = 0<tab><tab>self.defsfile = file<tab><tab>self.defsmine = mine",1,if type ( defs ) == StringType :,if type ( defs ) == StringType :,0.75,100,1
"def __new__(cls, name, bases, d):<tab>rv = type.__new__(cls, name, bases, d)<tab>if ""methods"" not in d:<tab><tab>methods = set(rv.methods or [])<tab><tab>for key, value in d.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>methods.add(key.upper())<tab><tab># if we have no method at all in there we don't want to<tab><tab># add a method list.  (This is for instance the case for<tab><tab># the baseclass or another subclass of a base method view<tab><tab># that does not introduce new methods).<tab><tab>if methods:<tab><tab><tab>rv.methods = sorted(methods)<tab>return rv",0,if key in http_method_funcs :,if key . upper ( ) in methods :,0.049758409,11.33958222,0.466666667
"def draw_lines(col, lines):<tab>skip = False<tab>for l in lines:<tab><tab>if l:<tab><tab><tab>col.label(text=l)<tab><tab><tab>skip = False<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>col.label(text=l)<tab><tab><tab>skip = True",1,elif skip :,elif skip :,0.514316131,1.00E-10,1
"def adjust_sockets(self):<tab>variables = self.get_variables()<tab>for key in self.inputs.keys():<tab><tab>if key not in variables and key not in [""Field""]:<tab><tab><tab>self.debug(<tab><tab><tab><tab>""Input {} not in variables {}, remove it"".format(key, str(variables))<tab><tab><tab>)<tab><tab><tab>self.inputs.remove(self.inputs[key])<tab>for v in variables:<tab><tab><IF-STMT><tab><tab><tab>self.debug(<tab><tab><tab><tab>""Variable {} not in inputs {}, add it"".format(<tab><tab><tab><tab><tab>v, str(self.inputs.keys())<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>self.inputs.new(""SvStringsSocket"", v)",0,if v not in self . inputs :,"if v not in [ ""Field"" , ""Socket"" ] :",0.165091211,18.79831765,0.685714286
"def forward(self, g, x):<tab>h = x<tab>for l, conv in enumerate(self.layers):<tab><tab>h = conv(g, h)<tab><tab><IF-STMT><tab><tab><tab>h = self.activation(h)<tab><tab><tab>h = self.dropout(h)<tab>return h",0,if l != len ( self . layers ) - 1 :,if l == len ( self . layers ) - 1 :,0.635663651,79.10665072,1
"def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]:<tab>""""""Let the user process the docstrings before adding them.""""""<tab>for docstringlines in docstrings:<tab><tab><IF-STMT><tab><tab><tab># let extensions preprocess docstrings<tab><tab><tab>self.env.app.emit(<tab><tab><tab><tab>""autodoc-process-docstring"",<tab><tab><tab><tab>self.objtype,<tab><tab><tab><tab>self.fullname,<tab><tab><tab><tab>self.object,<tab><tab><tab><tab>self.options,<tab><tab><tab><tab>docstringlines,<tab><tab><tab>)<tab><tab><tab>if docstringlines and docstringlines[-1] != """":<tab><tab><tab><tab># append a blank line to the end of the docstring<tab><tab><tab><tab>docstringlines.append("""")<tab><tab>yield from docstringlines",0,if self . env . app :,if docstringlines :,0.020447728,1.00E-10,0.291666667
"def wiki(self, query):<tab>res = []<tab>for entry in g.current_wiki.get_index():<tab><tab>name = filename_to_cname(entry[""name""])<tab><tab>name = re.sub(r""//+"", ""/"", name)<tab><tab>if set(query.split()).intersection(name.replace(""/"", ""-"").split(""-"")):<tab><tab><tab>page = g.current_wiki.get_page(name)<tab><tab><tab># this can be None, not sure how<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append(dict(name=name, content=page.data))<tab>return res",0,if page :,if page is not None :,0.090364769,1.00E-10,0.4
"def checkForFinishedThreads(self):<tab>""Mark terminated threads with endTime.""<tab>for t in self.unfinishedThreads:<tab><tab>if not t.is_alive():<tab><tab><tab>t.endTime = time.process_time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>t.status = ""ended""",0,"if getattr ( t , ""status"" , None ) is None :","if t . status == ""terminated"" :",0.011766133,4.402175903,0.257142857
"def testTicketFlags(self):<tab>flags = (""restored"", ""banned"")<tab>ticket = Ticket(""test"", 0)<tab>trueflags = []<tab>for v in (True, False, True):<tab><tab>for f in flags:<tab><tab><tab>setattr(ticket, f, v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>trueflags.append(f)<tab><tab><tab>else:<tab><tab><tab><tab>trueflags.remove(f)<tab><tab><tab>for f2 in flags:<tab><tab><tab><tab>self.assertEqual(bool(getattr(ticket, f2)), f2 in trueflags)<tab>## inherite props from another tockets:<tab>ticket = FailTicket(ticket=ticket)<tab>for f2 in flags:<tab><tab>self.assertTrue(bool(getattr(ticket, f2)))",1,if v :,if v :,0.531170663,1.00E-10,1
"def decode(obj, encoding=""utf-8"", errors=""strict""):<tab>decoder = __decoder(encoding)<tab>if decoder:<tab><tab>result = decoder(obj, errors)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""decoder must return a tuple (object, integer)"")<tab><tab>return result[0]",0,"if not ( isinstance ( result , tuple ) and len ( result ) == 2 ) :","if not isinstance ( result , tuple ) :",0.148060585,23.2774594,0.609427609
"def work(self):<tab>""""""Play the animation.""""""<tab># if loop_mode is once and we are already on the last frame,<tab># return to the first frame... (so the user can keep hitting once)<tab>if self.loop_mode == LoopMode.ONCE:<tab><tab><IF-STMT><tab><tab><tab>self.frame_requested.emit(self.axis, self.min_point)<tab><tab>elif self.step < 0 and self.current <= self.min_point + 1:<tab><tab><tab>self.frame_requested.emit(self.axis, self.max_point)<tab><tab>self.timer.singleShot(int(self.interval), self.advance)<tab>else:<tab><tab># immediately advance one frame<tab><tab>self.advance()<tab>self.started.emit()",0,if self . step > 0 and self . current >= self . max_point - 1 :,if self . step > 0 and self . current >= self . min_point + 1 :,0.892638976,74.40603601,1
"def get_order(self, aStr):<tab># for big5 encoding, we are interested<tab>#   first  byte range: 0xa4 -- 0xfe<tab>#   second byte range: 0x40 -- 0x7e , 0xa1 -- 0xfe<tab># no validation needed here. State machine has done that<tab>if aStr[0] >= ""\xA4"":<tab><tab><IF-STMT><tab><tab><tab>return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0xA1 + 63<tab><tab>else:<tab><tab><tab>return 157 * (ord(aStr[0]) - 0xA4) + ord(aStr[1]) - 0x40<tab>else:<tab><tab>return -1",1,"if aStr [ 1 ] >= ""\xA1"" :","if aStr [ 1 ] >= ""\xA1"" :",0.75,100,1
"def validate_literals(self):<tab>try:<tab><tab>for c in self.literals:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.error(<tab><tab><tab><tab><tab>""Invalid literal %s. Must be a single character"", repr(c)<tab><tab><tab><tab>)<tab><tab><tab><tab>self.error = True<tab>except TypeError:<tab><tab>self.log.error(<tab><tab><tab>""Invalid literals specification. literals must be a sequence of characters""<tab><tab>)<tab><tab>self.error = True",0,"if not isinstance ( c , StringTypes ) or len ( c ) > 1 :",if len ( c ) != 1 :,0.089388851,16.94794176,0.192982456
"def filter(self, qs, value):<tab>if value:<tab><tab>if value.start is not None and value.stop is not None:<tab><tab><tab>value = (value.start, value.stop)<tab><tab>elif value.start is not None:<tab><tab><tab>self.lookup_expr = ""startswith""<tab><tab><tab>value = value.start<tab><tab><IF-STMT><tab><tab><tab>self.lookup_expr = ""endswith""<tab><tab><tab>value = value.stop<tab>return super().filter(qs, value)",1,elif value . stop is not None :,elif value . stop is not None :,0.75,100,1
"def parse_stdout(s):<tab>argv = re.search(""^===ARGV=(.*?)$"", s, re.M).group(1)<tab>argv = argv.split()<tab>testname = argv[-1]<tab>del argv[-1]<tab>hub = None<tab>reactor = None<tab>while argv:<tab><tab><IF-STMT><tab><tab><tab>hub = argv[1]<tab><tab><tab>del argv[0]<tab><tab><tab>del argv[0]<tab><tab>elif argv[0] == ""--reactor"":<tab><tab><tab>reactor = argv[1]<tab><tab><tab>del argv[0]<tab><tab><tab>del argv[0]<tab><tab>else:<tab><tab><tab>del argv[0]<tab>if reactor is not None:<tab><tab>hub += ""/%s"" % reactor<tab>return testname, hub",1,"if argv [ 0 ] == ""--hub"" :","if argv [ 0 ] == ""--hub"" :",0.75,100,1
"def get(self, key):<tab>try:<tab><tab>res = self.server.get(<tab><tab><tab>index=self.index,<tab><tab><tab>doc_type=self.doc_type,<tab><tab><tab>id=key,<tab><tab>)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return res[""_source""][""result""]<tab><tab>except (TypeError, KeyError):<tab><tab><tab>pass<tab>except elasticsearch.exceptions.NotFoundError:<tab><tab>pass",0,"if res [ ""found"" ] :","if res [ ""_source"" ] [ ""result"" ] :",0.185393159,25.71200803,1
"def _get_target_chap_auth(self, context, volume):<tab>""""""Get the current chap auth username and password.""""""<tab>try:<tab><tab># Query DB to get latest state of volume<tab><tab>volume_info = self.db.volume_get(context, volume[""id""])<tab><tab># 'provider_auth': 'CHAP user_id password'<tab><tab><IF-STMT><tab><tab><tab>return tuple(volume_info[""provider_auth""].split("" "", 3)[1:])<tab>except exception.NotFound:<tab><tab>LOG.debug(""Failed to get CHAP auth from DB for %s."", volume[""id""])",0,"if volume_info [ ""provider_auth"" ] :","if volume_info and ""provider_auth"" in volume_info :",0.047631794,42.31178542,0.45
"def merge(self, hosts):<tab>for ei in self:<tab><tab>host_name = ei.get_name()<tab><tab>h = hosts.find_by_name(host_name)<tab><tab><IF-STMT><tab><tab><tab># FUUUUUUUUUUsion<tab><tab><tab>self.merge_extinfo(h, ei)",1,if h is not None :,if h is not None :,0.75,100,1
"def __init__(self, user, *args, **kwargs):<tab>""Sets choices and initial value""<tab>super(SettingsForm, self).__init__(*args, **kwargs)<tab>self.fields[""default_changeset_status""].queryset = ChangeSetStatus.objects.filter(<tab><tab>trash=False<tab>)<tab>try:<tab><tab>conf = ModuleSetting.get_for_module(<tab><tab><tab>""treeio.changes"", ""default_changeset_status""<tab><tab>)[0]<tab><tab>default_changeset_status = ChangeSetStatus.objects.get(pk=long(conf.value))<tab><tab><IF-STMT><tab><tab><tab>self.fields[<tab><tab><tab><tab>""default_changeset_status""<tab><tab><tab>].initial = default_changeset_status.id<tab>except Exception:<tab><tab>pass",0,if not default_changeset_status . trash :,if default_changeset_status :,0.028363593,1.00E-10,0.4375
"def load(self):<tab>""""""Method for loading a feature""""""<tab>with self.filesystem.openbin(self.path, ""r"") as file_handle:<tab><tab><IF-STMT><tab><tab><tab>with gzip.open(file_handle, ""rb"") as gzip_fp:<tab><tab><tab><tab>return self._decode(gzip_fp, self.path)<tab><tab>return self._decode(file_handle, self.path)",0,if self . path . endswith ( FileFormat . GZIP . extension ( ) ) :,if self . gzip :,0.026309152,4.734474984,0.352272727
"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab>if nfrom.cond == nto:<tab><tab><tab>return ""?""<tab><tab>elif nfrom.src1 == nto:<tab><tab><tab>return ""True""<tab><tab>elif nfrom.src2 == nto:<tab><tab><tab>return ""False""<tab>return """"",0,if i [ 0 ] == nto :,"if i [ 0 ] == ""edge"" :",0.418121306,59.00468726,0.777777778
"def disable_verity():<tab>""""""Disables dm-verity on the device.""""""<tab>with log.waitfor(""Disabling dm-verity on %s"" % context.device):<tab><tab>root()<tab><tab>with AdbClient() as c:<tab><tab><tab>reply = c.disable_verity()<tab><tab>if ""Verity already disabled"" in reply:<tab><tab><tab>return<tab><tab>elif ""Now reboot your device"" in reply:<tab><tab><tab>reboot(wait=True)<tab><tab><IF-STMT><tab><tab><tab>return  # Emulator doesnt support Verity?<tab><tab>else:<tab><tab><tab>log.error(""Could not disable verity:\n%s"" % reply)",0,"elif ""0006closed"" in reply :","elif ""Emulator supports Verity"" in reply :",0.365354024,35.49481056,0.371428571
"def __demo_mode_pause_if_active(self, tiny=False):<tab>if self.demo_mode:<tab><tab>wait_time = settings.DEFAULT_DEMO_MODE_TIMEOUT<tab><tab>if self.demo_sleep:<tab><tab><tab>wait_time = float(self.demo_sleep)<tab><tab><IF-STMT><tab><tab><tab>time.sleep(wait_time)<tab><tab>else:<tab><tab><tab>time.sleep(wait_time / 3.4)<tab>elif self.slow_mode:<tab><tab>self.__slow_mode_pause_if_active()",0,if not tiny :,if tiny :,0.096488528,1.00E-10,0.416666667
"def dictToKW(d):<tab>out = []<tab>items = list(d.items())<tab>items.sort()<tab>for k, v in items:<tab><tab><IF-STMT><tab><tab><tab>raise NonFormattableDict(""%r ain't a string"" % k)<tab><tab>if not r.match(k):<tab><tab><tab>raise NonFormattableDict(""%r ain't an identifier"" % k)<tab><tab>out.append(""\n\0{}={},"".format(k, prettify(v)))<tab>return """".join(out)",0,"if not isinstance ( k , str ) :","if not isinstance ( k , basestring ) :",0.581882088,66.06328636,0.714285714
"def createCommonCommands(self):<tab>""""""Handle all global @command nodes.""""""<tab>c = self.c<tab>aList = c.config.getCommands() or []<tab>for z in aList:<tab><tab>p, script = z<tab><tab>gnx = p.v.gnx<tab><tab><IF-STMT><tab><tab><tab>self.seen.add(gnx)<tab><tab><tab>script = self.getScript(p)<tab><tab><tab>self.createCommonCommand(p, script)",1,if gnx not in self . seen :,if gnx not in self . seen :,0.75,100,1
"def _decodeFromStream(self, s):<tab>""""""Decode a complete DER OBJECT ID from a file.""""""<tab># Fill up self.payload<tab>DerObject._decodeFromStream(self, s)<tab># Derive self.value from self.payload<tab>p = BytesIO_EOF(self.payload)<tab>comps = list(map(str, divmod(p.read_byte(), 40)))<tab>v = 0<tab>while p.remaining_data():<tab><tab>c = p.read_byte()<tab><tab>v = v * 128 + (c & 0x7F)<tab><tab><IF-STMT><tab><tab><tab>comps.append(str(v))<tab><tab><tab>v = 0<tab>self.value = ""."".join(comps)",0,if not ( c & 0x80 ) :,if c & 0x80 :,0.132324466,24.7953647,0.377777778
"def tiles_around_factor(self, factor, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab><IF-STMT><tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab>if ny >= 0 and ny < self.height * factor and (dx != 0 or dy != 0):<tab><tab><tab><tab><tab>if predicate is None or predicate((nx, ny)):<tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",1,if nx >= 0 and nx < self . width * factor :,if nx >= 0 and nx < self . width * factor :,1,100,1
"def deleteAllMatchers(self):<tab>""""""Deletes all matchers.""""""<tab>if self.__filter:<tab><tab>result = QtWidgets.QMessageBox.question(<tab><tab><tab>self,<tab><tab><tab>""Delete All Matchers?"",<tab><tab><tab>""Are you sure you want to delete all matchers?"",<tab><tab><tab>QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._itemsLock.lockForWrite()<tab><tab><tab>try:<tab><tab><tab><tab>for item in list(self._items.values()):<tab><tab><tab><tab><tab>item.rpcObject.delete()<tab><tab><tab>finally:<tab><tab><tab><tab>self._itemsLock.unlock()<tab><tab><tab>self.removeAllItems()",1,if result == QtWidgets . QMessageBox . Yes :,if result == QtWidgets . QMessageBox . Yes :,0.75,100,1
"def _parse_icons(self, icons):<tab><IF-STMT><tab><tab>icons = get_iterated_icons(icons)<tab>for icon in icons:<tab><tab>if isinstance(icons, list):<tab><tab><tab>icon = Icon(icon)<tab><tab>else:<tab><tab><tab>icon = Icon(icons[icon])<tab><tab>if icon.exists:  # If icon found on current Gtk Icon theme<tab><tab><tab>self.icons.append(icon)",0,"if isinstance ( icons , list ) :","if isinstance ( icons , str ) :",0.549040681,59.46035575,0.666666667
"def change_misc_visibility(self, on_start=False):<tab>if self.misc.isVisible():<tab><tab>self._splitterMainSizes = self._splitterMain.sizes()<tab><tab>self.misc.hide()<tab><tab>widget = self.mainContainer.get_actual_widget()<tab><tab><IF-STMT><tab><tab><tab>widget.setFocus()<tab>else:<tab><tab>self.misc.show()<tab><tab>self.misc.gain_focus()",0,if widget :,if not on_start :,0.059856515,1.00E-10,0.5
"def is_checked_sls_template(template):<tab>if template.__contains__(""provider""):<tab><tab># Case provider is a dictionary<tab><tab>if isinstance(template[""provider""], dict_node):<tab><tab><tab>if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab># Case provider is direct provider name<tab><tab>if isinstance(template[""provider""], str_node):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",0,"if template [ ""provider"" ] not in SUPPORTED_PROVIDERS :","if template [ ""provider"" ] . get ( ""name"" ) . lower ( ) not in SUPPORTED_PROVIDERS :",0.421119122,43.35347194,0.417582418
"def check_index(self, is_sorted=True, unique=True, index=None):<tab>""""""Sanity checks""""""<tab>if not index:<tab><tab>index = self.index<tab>if is_sorted:<tab><tab>test = pd.DataFrame(lrange(len(index)), index=index)<tab><tab>test_sorted = test.sort()<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Data is not be sorted"")<tab>if unique:<tab><tab>if len(index) != len(index.unique()):<tab><tab><tab>raise Exception(""Duplicate index entries"")",0,if not test . index . equals ( test_sorted . index ) :,if not test_sorted :,0.016187195,11.33797415,0.462962963
"def _update_actions(self, *_ignored):<tab>""""""Updates menu actions to reflect the current layer's mode""""""<tab>if self._updating:<tab><tab>return<tab>self._updating = True<tab>rootstack = self._model.layer_stack<tab>current = rootstack.current<tab>for mode, item in self._menu_items:<tab><tab>active = mode == current.mode<tab><tab><IF-STMT><tab><tab><tab>item.set_active(active)<tab><tab>item.set_sensitive(mode in current.PERMITTED_MODES)<tab>self._updating = False",0,if bool ( item . get_active ( ) ) != active :,if active :,0.014772184,1.00E-10,0.377777778
"def _charlabels(self, options):<tab>""""""Get labels for characters (PRIVATE).""""""<tab>self.charlabels = {}<tab>opts = CharBuffer(options)<tab>while True:<tab><tab># get id and state<tab><tab>w = opts.next_word()<tab><tab><IF-STMT>  # McClade saves and reads charlabel-lists with terminal comma?!<tab><tab><tab>break<tab><tab>identifier = self._resolve(w, set_type=CHARSET)<tab><tab>state = quotestrip(opts.next_word())<tab><tab>self.charlabels[identifier] = state<tab><tab># check for comma or end of command<tab><tab>c = opts.next_nonwhitespace()<tab><tab>if c is None:<tab><tab><tab>break<tab><tab>elif c != "","":<tab><tab><tab>raise NexusError(""Missing ',' in line %s."" % options)",1,if w is None :,if w is None :,0.75,100,1
"def get_and_set_titles(self):<tab>all_titles = []<tab>for page in self.pages:<tab><tab><IF-STMT><tab><tab><tab>all_titles.append(page.orig_phrase)<tab><tab><tab>all_titles.append(page.orig_phrase_norm)<tab><tab>if page.wiki_title != """":<tab><tab><tab>all_titles.append(page.wiki_title)<tab><tab><tab>all_titles.append(page.wiki_title_norm)<tab>return set(all_titles)",1,"if page . orig_phrase != """" :","if page . orig_phrase != """" :",0.75,100,1
"def get_content_length(download):<tab>try:<tab><tab>meta = download.info()<tab><tab><IF-STMT><tab><tab><tab>return int(meta.getheaders(""Content-Length"")[0])<tab><tab>elif hasattr(download, ""getheader"") and download.getheader(""Content-Length""):<tab><tab><tab>return int(download.getheader(""Content-Length""))<tab><tab>elif hasattr(meta, ""getheader"") and meta.getheader(""Content-Length""):<tab><tab><tab>return int(meta.getheader(""Content-Length""))<tab>except Exception:<tab><tab>pass<tab>return 0",0,"if hasattr ( meta , ""getheaders"" ) and hasattr ( meta . getheaders , ""Content-Length"" ) :","if hasattr ( meta , ""getheaders"" ) and meta . getheaders [ ""Content-Length"" ] :",0.469645665,57.47892237,0.686507937
"def connect_reader_to_writer(reader, writer):<tab>BUF_SIZE = 8192<tab>try:<tab><tab>while True:<tab><tab><tab>data = await reader.read(BUF_SIZE)<tab><tab><tab>if not data:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>writer.write_eof()<tab><tab><tab><tab><tab>await writer.drain()<tab><tab><tab><tab>return<tab><tab><tab>writer.write(data)<tab><tab><tab>await writer.drain()<tab>except (OSError, asyncio.IncompleteReadError) as e:<tab><tab>pass",0,if not writer . transport . is_closing ( ) :,if not data :,0.024519355,4.784824826,0.487179487
"def _record_shell(ex, files, bind_rez=True, print_msg=False):<tab>ex.source(context_file)<tab>if startup_sequence[""envvar""]:<tab><tab>ex.unsetenv(startup_sequence[""envvar""])<tab>if add_rez and bind_rez:<tab><tab>ex.interpreter._bind_interactive_rez()<tab>if print_msg and add_rez and not quiet:<tab><tab>ex.info("""")<tab><tab>ex.info(""You are now in a rez-configured environment."")<tab><tab>ex.info("""")<tab><tab><IF-STMT><tab><tab><tab>ex.command(""rezolve context"")",0,if system . is_production_rez_install :,if not quiet :,0.036751978,3.300991087,0.36
"def set_torrent_ratio(self, torrent_ids, ratio):<tab>try:<tab><tab>if not self.connect():<tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_stop_at_ratio(torrent_ids, True).get()<tab><tab>self.client.core.set_torrent_stop_ratio(torrent_ids, ratio).get()<tab>except Exception as err:<tab><tab>return False<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>self.disconnect()<tab>return True",1,if self . client :,if self . client :,0.75,100,1
"def __decrypt_bin_sum(encrypted_bin_sum, cipher):<tab># for feature_sum in encrypted_bin_sum:<tab>decrypted_list = {}<tab>for col_name, count_list in encrypted_bin_sum.items():<tab><tab>new_list = []<tab><tab>for event_count, non_event_count in count_list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>event_count = cipher.decrypt(event_count)<tab><tab><tab>if isinstance(non_event_count, PaillierEncryptedNumber):<tab><tab><tab><tab>non_event_count = cipher.decrypt(non_event_count)<tab><tab><tab>new_list.append((event_count, non_event_count))<tab><tab>decrypted_list[col_name] = new_list<tab>return decrypted_list",1,"if isinstance ( event_count , PaillierEncryptedNumber ) :","if isinstance ( event_count , PaillierEncryptedNumber ) :",0.75,100,1
"def processVideo(self, track):<tab>video = Metadata(self)<tab>self.trackCommon(track, video)<tab>try:<tab><tab>video.compression = track[""CodecID/string""].value<tab><tab><IF-STMT><tab><tab><tab>video.width = track[""Video/PixelWidth/unsigned""].value<tab><tab><tab>video.height = track[""Video/PixelHeight/unsigned""].value<tab>except MissingField:<tab><tab>pass<tab>self.addGroup(""video[]"", video, ""Video stream"")",0,"if ""Video"" in track :","if track [ ""Video/PixelWidth/unsigned"" ] . value :",0.02800146,7.474875887,0.4
"def check_br_addr(self, br):<tab>ips = {}<tab>cmd = ""ip a show dev %s"" % br<tab>for line in self.execute(cmd, sudo=True).split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[4] = elems[1]<tab><tab>elif line.strip().startswith(""inet6 ""):<tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[6] = elems[1]<tab>return ips",1,"if line . strip ( ) . startswith ( ""inet "" ) :","if line . strip ( ) . startswith ( ""inet "" ) :",0.75,100,1
"def _find_line_in_file(file_path, search_pattern):<tab>try:<tab><tab>with open(file_path, ""r"", encoding=""utf-8"") as search_file:<tab><tab><tab>for line in search_file:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>except (OSError, IOError):<tab><tab>pass<tab>return False",0,if search_pattern in line :,"if re . search ( search_pattern , line ) :",0.026964759,14.99110695,0.320512821
"def setOption(self, key, value):<tab>if key in VALID_OPTIONS:<tab><tab>old = self.getOption(key)<tab><tab>result = VALID_OPTIONS[key](self, value)<tab><tab>self.notifyOptionChanged(key, old, value)<tab><tab><IF-STMT><tab><tab><tab>return result[1]<tab><tab>else:<tab><tab><tab>raise RopperError(""Invalid value for option %s: %s"" % (key, value))<tab>else:<tab><tab>raise RopperError(""Invalid option"")",1,if result :,if result :,0.531170663,1.00E-10,1
"def _para_exploit(self, params, part):<tab>if len(params) == 0:<tab><tab>arr = [""*"", ""config""] + self._configs.keys()<tab><tab>return suggest(arr, part)<tab>if len(params) == 1:<tab><tab>arr = []<tab><tab>if params[0] == ""config"":<tab><tab><tab>arr = self._configs.keys()<tab><tab><IF-STMT><tab><tab><tab>arr = [""stopOnFirst""]<tab><tab>return suggest(arr, part)<tab>return []",0,"if params [ 0 ] == ""*"" :",if len ( params ) == 1 :,0.020373037,9.600960275,0.314814815
"def render(self, context):<tab>for var in self.vars:<tab><tab>value = var.resolve(context, True)<tab><tab>if value:<tab><tab><tab>first = render_value_in_context(value, context)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>context[self.asvar] = first<tab><tab><tab><tab>return """"<tab><tab><tab>return first<tab>return """"",0,if self . asvar :,if self . asvar not in context :,0.351498834,36.55552229,0.510204082
"def insertTestData(self, rows):<tab>for row in rows:<tab><tab>if isinstance(row, Log):<tab><tab><tab>self.logs[row.id] = row.values.copy()<tab>for row in rows:<tab><tab>if isinstance(row, LogChunk):<tab><tab><tab>lines = self.log_lines.setdefault(row.logid, [])<tab><tab><tab># make sure there are enough slots in the list<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lines.append([None] * (row.last_line + 1 - len(lines)))<tab><tab><tab>row_lines = row.content.decode(""utf-8"").split(""\n"")<tab><tab><tab>lines[row.first_line : row.last_line + 1] = row_lines",0,if len ( lines ) < row . last_line + 1 :,if len ( lines ) > row . last_line :,0.293556218,54.96509142,0.822222222
"def set_available_qty(self):<tab>for d in self.get(""required_items""):<tab><tab>if d.source_warehouse:<tab><tab><tab>d.available_qty_at_source_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, d.source_warehouse<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>d.available_qty_at_wip_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, self.wip_warehouse<tab><tab><tab>)",1,if self . wip_warehouse :,if self . wip_warehouse :,0.75,100,1
"def add_pref_observer(self, name, callback):<tab>self.log.debug(""Adding pref observer for %s"", name)<tab>try:<tab><tab>self._observers[name].add(callback)<tab>except KeyError:<tab><tab>self._observers[name] = set([callback])<tab><tab><IF-STMT><tab><tab><tab>self._send(command=""global-prefs-observe"", add=[name])<tab><tab>else:<tab><tab><tab># We can't actually trigger prefs observer changes on document<tab><tab><tab># level prefs; that's mostly okay, though, since we just pass<tab><tab><tab># the whole prefs environment every time we do something with a<tab><tab><tab># document instead.<tab><tab><tab>pass",0,if self . _send :,if name in self . _observers :,0.222115808,23.35689889,0.35
"def __setattr__(self, key: str, value) -> None:<tab>try:<tab><tab>object.__getattribute__(self, key)<tab><tab>return object.__setattr__(self, key, value)<tab>except AttributeError:<tab><tab>pass<tab>if (key,) in self._internal.column_labels:<tab><tab>self[key] = value<tab>else:<tab><tab>msg = ""Koalas doesn't allow columns to be created via a new attribute name""<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(msg)<tab><tab>else:<tab><tab><tab>warnings.warn(msg, UserWarning)",0,if is_testing ( ) :,if key in self . _internal . column_labels :,0.025278873,4.456882761,0.353846154
"def inverse_transform(self, X):<tab>results = []<tab>column_counter = 0<tab>for i, binarizer in enumerate(self.binarizers):<tab><tab>n_cols = binarizer.classes_.shape[0]<tab><tab>x_subset = X[:, column_counter : column_counter + n_cols]<tab><tab>inv = binarizer.inverse_transform(x_subset)<tab><tab><IF-STMT><tab><tab><tab>inv = inv[:, np.newaxis]<tab><tab>results.append(inv)<tab><tab>column_counter += n_cols<tab>return np.concatenate(results, axis=1)",0,if len ( inv . shape ) == 1 :,if i % 2 == 0 :,0.014969815,9.027235034,0.212121212
"def default_generator(<tab>self, dataset, epochs=1, mode=""fit"", deterministic=True, pad_batches=True):<tab>for epoch in range(epochs):<tab><tab>for (X_b, y_b, w_b, ids_b) in dataset.iterbatches(<tab><tab><tab>batch_size=self.batch_size,<tab><tab><tab>deterministic=deterministic,<tab><tab><tab>pad_batches=pad_batches,<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dropout = np.array(False)<tab><tab><tab>else:<tab><tab><tab><tab>dropout = np.array(True)<tab><tab><tab>yield ([X_b, dropout], [y_b], [w_b])",0,"if mode == ""predict"" :",if epoch == self . epoch :,0.029730601,13.13454947,0.35
"def modif(dir, name, fun):<tab>""""""Call a substitution function""""""<tab>if name == ""*"":<tab><tab>lst = []<tab><tab>for y in "". Tools extras"".split():<tab><tab><tab>for x in os.listdir(os.path.join(dir, y)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>lst.append(y + os.sep + x)<tab><tab>for x in lst:<tab><tab><tab>modif(dir, x, fun)<tab><tab>return<tab>filename = os.path.join(dir, name)<tab>with open(filename, ""r"") as f:<tab><tab>txt = f.read()<tab>txt = fun(txt)<tab>with open(filename, ""w"") as f:<tab><tab>f.write(txt)",1,"if x . endswith ( "".py"" ) :","if x . endswith ( "".py"" ) :",0.75,100,1
"def find_last_match(view, what, start, end, flags=0):<tab>""""""Find last occurrence of `what` between `start`, `end`.""""""<tab>match = view.find(what, start, flags)<tab>new_match = None<tab>while match:<tab><tab>new_match = view.find(what, match.end(), flags)<tab><tab><IF-STMT><tab><tab><tab>match = new_match<tab><tab>else:<tab><tab><tab>return match",0,if new_match and new_match . end ( ) <= end :,if new_match is not None :,0.11674501,13.44802511,0.285714286
"def to_dynamic_cwd_tuple(x):<tab>""""""Convert to a canonical cwd_width tuple.""""""<tab>unit = ""c""<tab>if isinstance(x, str):<tab><tab><IF-STMT><tab><tab><tab>x = x[:-1]<tab><tab><tab>unit = ""%""<tab><tab>else:<tab><tab><tab>unit = ""c""<tab><tab>return (float(x), unit)<tab>else:<tab><tab>return (float(x[0]), x[1])",1,"if x [ - 1 ] == ""%"" :","if x [ - 1 ] == ""%"" :",0.75,100,1
"def get_lprobs_and_target(self, model, net_output, sample):<tab>lprobs = model.get_normalized_probs(net_output, log_probs=True)<tab>target = model.get_targets(sample, net_output)<tab>if self.ignore_prefix_size > 0:<tab><tab><IF-STMT><tab><tab><tab>lprobs = lprobs[:, self.ignore_prefix_size :, :].contiguous()<tab><tab><tab>target = target[:, self.ignore_prefix_size :].contiguous()<tab><tab>else:<tab><tab><tab>lprobs = lprobs[self.ignore_prefix_size :, :, :].contiguous()<tab><tab><tab>target = target[self.ignore_prefix_size :, :].contiguous()<tab>return lprobs.view(-1, lprobs.size(-1)), target.view(-1)",0,"if getattr ( lprobs , ""batch_first"" , False ) :","if isinstance ( lprobs , np . ndarray ) :",0.070266564,13.77955525,0.363636364
"def _charlabels(self, options):<tab>""""""Get labels for characters (PRIVATE).""""""<tab>self.charlabels = {}<tab>opts = CharBuffer(options)<tab>while True:<tab><tab># get id and state<tab><tab>w = opts.next_word()<tab><tab>if w is None:  # McClade saves and reads charlabel-lists with terminal comma?!<tab><tab><tab>break<tab><tab>identifier = self._resolve(w, set_type=CHARSET)<tab><tab>state = quotestrip(opts.next_word())<tab><tab>self.charlabels[identifier] = state<tab><tab># check for comma or end of command<tab><tab>c = opts.next_nonwhitespace()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif c != "","":<tab><tab><tab>raise NexusError(""Missing ',' in line %s."" % options)",1,if c is None :,if c is None :,0.75,100,1
"def _parseContributors(self, roleType, Contributors):<tab>if Contributors is None:<tab><tab>return None<tab>try:<tab><tab>ret = []<tab><tab>for item in Contributors[""items""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(item[""name""])<tab><tab>return ret<tab>except:<tab><tab>return None",0,"if item [ ""role"" ] == roleType :","if item [ ""roleType"" ] == roleType :",0.501462237,70.16879391,1
"def _data_interp(self):<tab>if self.pending_points:<tab><tab>points = list(self.pending_points)<tab><tab><IF-STMT><tab><tab><tab>values = self.ip()(self._scale(points))<tab><tab>else:<tab><tab><tab># Without the bounds the interpolation cannot be done properly,<tab><tab><tab># so we just set everything to zero.<tab><tab><tab>values = np.zeros((len(points), self.vdim))<tab><tab>return points, values<tab>return np.zeros((0, 2)), np.zeros((0, self.vdim), dtype=float)",0,if self . bounds_are_done :,if self . ip :,0.394778655,19.1992428,0.7
"def _initCaseSets(self):<tab>self._cs = {}<tab>self._css = {}<tab>for cs in self._caseSets:<tab><tab><IF-STMT><tab><tab><tab>self._cs[cs.CaseSetName] = {}<tab><tab><tab>self._css[cs.CaseSetName] = cs<tab><tab>else:<tab><tab><tab>raise Exception(""duplicate case set name"")<tab><tab>for c in cs.Cases:<tab><tab><tab>idx = tuple(c.index)<tab><tab><tab>if not self._cs[cs.CaseSetName].has_key(idx):<tab><tab><tab><tab>self._cs[cs.CaseSetName][idx] = c<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""duplicate case index"")",1,if not self . _cs . has_key ( cs . CaseSetName ) :,if not self . _cs . has_key ( cs . CaseSetName ) :,0.75,100,1
"def _organize_data(self, data):<tab>temporary = {}<tab>for line in data.splitlines():<tab><tab>category, _, value = line.partition("" "")<tab><tab><IF-STMT><tab><tab><tab>key, _, value = value.partition("" "")<tab><tab><tab>temporary[key] = value<tab><tab>else:<tab><tab><tab>temporary[category] = value<tab>return temporary",0,"if category in ( ""set"" , ""tag"" ) :","if category == ""key"" :",0.029942751,7.43376166,0.730769231
"def get(self):<tab>""""""Returns a simple HTML for contact form""""""<tab>if self.user:<tab><tab>user_info = models.User.get_by_id(long(self.user_id))<tab><tab>if user_info.name or user_info.last_name:<tab><tab><tab>self.form.name.data = user_info.name + "" "" + user_info.last_name<tab><tab><IF-STMT><tab><tab><tab>self.form.email.data = user_info.email<tab>params = {""exception"": self.request.get(""exception"")}<tab>return self.render_template(""boilerplate_contact.html"", **params)",1,if user_info . email :,if user_info . email :,0.75,100,1
"def parseBamPEFDistributionFile(self, f):<tab>d = dict()<tab>lastsample = []<tab>for line in f[""f""].splitlines():<tab><tab>cols = line.rstrip().split(""\t"")<tab><tab>if cols[0] == ""#bamPEFragmentSize"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""])<tab><tab><tab>if s_name != lastsample:<tab><tab><tab><tab>d[s_name] = dict()<tab><tab><tab><tab>lastsample = s_name<tab><tab><tab>d[s_name].update({self._int(cols[0]): self._int(cols[1])})<tab>return d",0,"elif cols [ 0 ] == ""Size"" :","elif cols [ 0 ] == ""#sample"" :",0.853553391,67.04226838,1
"def _related(self):<tab>if self.__related is None:<tab><tab>results = requests.get(<tab><tab><tab>f""{self._wordnet_corpus_reader.host()}/api/synsets/{self.pos()}/{self.offset()}/relations/?format=json"",<tab><tab><tab>timeout=(30.0, 90.0),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.__related = results.json()[""results""][0][""relations""]<tab><tab>else:<tab><tab><tab>self.__related = []<tab>return self.__related",0,"if results and len ( results . json ( ) [ ""results"" ] ) != 0 :",if results . status_code == 200 :,0.01561995,4.616633379,0.3125
"def autoname(self):<tab>if self.company:<tab><tab>suffix = "" - "" + frappe.get_cached_value(""Company"", self.company, ""abbr"")<tab><tab><IF-STMT><tab><tab><tab>self.name = self.warehouse_name + suffix<tab>else:<tab><tab>self.name = self.warehouse_name",0,if not self . warehouse_name . endswith ( suffix ) :,if self .warehouse_name . endswith ( suffix ) :,0.25338893,84.96364167,0.320512821
"def escape_string(self, value):<tab>value = EscapedString.promote(value)<tab>value = value.expanduser()<tab>result = """"<tab>for is_literal, txt in value.strings:<tab><tab><IF-STMT><tab><tab><tab>txt = pipes.quote(txt)<tab><tab><tab>if not txt.startswith(""'""):<tab><tab><tab><tab>txt = ""'%s'"" % txt<tab><tab>else:<tab><tab><tab>txt = txt.replace(""\\"", ""\\\\"")<tab><tab><tab>txt = txt.replace('""', '\\""')<tab><tab><tab>txt = '""%s""' % txt<tab><tab>result += txt<tab>return result",1,if is_literal :,if is_literal :,0.531170663,1.00E-10,1
"def downgrade_wsgi_ux_to_1x(environ):<tab>""""""Return a new environ dict for WSGI 1.x from the given WSGI u.x environ.""""""<tab>env1x = {}<tab>url_encoding = environ[ntou(""wsgi.url_encoding"")]<tab>for k, v in list(environ.items()):<tab><tab>if k in [ntou(""PATH_INFO""), ntou(""SCRIPT_NAME""), ntou(""QUERY_STRING"")]:<tab><tab><tab>v = v.encode(url_encoding)<tab><tab><IF-STMT><tab><tab><tab>v = v.encode(""ISO-8859-1"")<tab><tab>env1x[k.encode(""ISO-8859-1"")] = v<tab>return env1x",0,"elif isinstance ( v , unicodestr ) :","elif k in [ ntou ( ""CONTENT_LENGTH"" ) , ntou ( ""CONTENT_TYPE"" ) , ntou ( ""CONTENT_TYPE"" ) ] :",0.113983804,1.734561795,0.241666667
"def __repr__(self):<tab>rt = ""Network<tab><tab> Netmask<tab><tab> Gateway<tab><tab> Iface<tab><tab>   Output IP\n""<tab>for net, msk, gw, <IF-STMT> addr in self.routes:<tab><tab>rt += ""%-15s %-15s %-15s %-15s %-15s\n"" % (<tab><tab><tab>ltoa(net),<tab><tab><tab>ltoa(msk),<tab><tab><tab>gw,<tab><tab><tab>iface,<tab><tab><tab>addr,<tab><tab>)<tab>return rt",0,"iface ,","iface = ( net , msk , gw )",0.042484724,1.00E-10,0.353846154
"def nearest_sources_Point(<tab>self, point: Point, max_dist=float(""inf"")):  # sys.float_info.max):<tab>bp, bn, bi, bd = None, None, None, None<tab>for rfsource in self.rfsources:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>hp, hn, hi, hd = rfsource.nearest(point, max_dist=max_dist)<tab><tab>if bp is None or (hp is not None and hd < bd):<tab><tab><tab>bp, bn, bi, bd = hp, hn, hi, hd<tab>return (bp, bn, bi, bd)",0,if not self . get_rfsource_snap ( rfsource ) :,if rfsource is None :,0.016838046,2.838368887,0.285714286
"def restoreParent(self):<tab>if self.sid.isRoot:<tab><tab>return<tab>with self.suspendMouseButtonNavigation():<tab><tab>confirm, opt = self.confirmRestore((self.path,))<tab><tab>if not confirm:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return<tab>rd = RestoreDialog(self, self.sid, self.path, **opt)<tab>rd.exec()",0,"if opt [ ""delete"" ] and not self . confirmDelete ( warnRoot = self . path == ""/"" ) :","if opt [ ""delete"" ] :",0.115646416,10.38400082,0.30651341
"def connect(self):<tab>if self.reserved_ports:<tab><tab>self.get_reserved_port()<tab>self.sock.settimeout(10)<tab>max_attempts = 3<tab>for i in range(max_attempts):<tab><tab>try:<tab><tab><tab>rv = super(WSClient, self).connect()<tab><tab>except OSError as e:<tab><tab><tab># Lets retry a few times in case the error is<tab><tab><tab># [Errno 48] Address already in use<tab><tab><tab># which I believe may be caused by a race condition<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>break<tab>if self.sock:<tab><tab>self.sock.settimeout(None)<tab>return rv",0,if e . errno == errno . EADDRINUSE and i < max_attempts - 1 :,if e . errno == errno . EADDRINUSE :,0.553238123,40.60145523,0.602941176
"def step(self, action):<tab>assert self.action_space.contains(action)<tab>if self._state == 4:<tab><tab>if action and self._case:<tab><tab><tab>return self._state, 10.0, True, {}<tab><tab>else:<tab><tab><tab>return self._state, -10, True, {}<tab>else:<tab><tab>if action:<tab><tab><tab>if self._state == 0:<tab><tab><tab><tab>self._state = 2<tab><tab><tab>else:<tab><tab><tab><tab>self._state += 1<tab><tab><IF-STMT><tab><tab><tab>self._state = self._case<tab>return self._state, -1, False, {}",0,elif self . _state == 2 :,if self . _state == 4 :,0.217360436,61.04735836,0.333333333
"def process(self):<tab>inputs = self.node.inputs<tab>outputs = self.node.outputs<tab>data = [s.sv_get()[0] for s in inputs]<tab>for socket, ref in zip(outputs, self.outputs):<tab><tab><IF-STMT><tab><tab><tab>func = getattr(self, ref[2])<tab><tab><tab>out = tuple(itertools.starmap(func, sv_zip_longest(*data)))<tab><tab><tab>socket.sv_set(out)",0,if socket . links :,if ref [ 0 ] == 0 :,0.026407399,5.669791111,0.314814815
"def filter_queryset(self, request, queryset, view):<tab>if (<tab><tab>self.filter_name in request.QUERY_PARAMS<tab><tab>or self.exclude_param_name in request.QUERY_PARAMS<tab>):<tab><tab>projects_ids_subquery = self.filter_user_projects(request)<tab><tab><IF-STMT><tab><tab><tab>queryset = queryset.filter(project_id__in=projects_ids_subquery)<tab>return super().filter_queryset(request, queryset, view)",1,if projects_ids_subquery :,if projects_ids_subquery :,0.531170663,1.00E-10,1
"def _is_port_in_range(self, ports_list):<tab>for port_range in ports_list[0]:<tab><tab>port = force_int(port_range)<tab><tab>if port and self.port == port:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>[from_port, to_port] = port_range.split(""-"")<tab><tab><tab><tab>if int(from_port) <= self.port <= int(to_port):<tab><tab><tab><tab><tab>return True<tab><tab><tab>except Exception:<tab><tab><tab><tab>return CheckResult.UNKNOWN<tab>return False",0,"if port is None and ""-"" in port_range :","elif ""-"" in port_range :",0.184852499,55.35566902,0.075
"def apply_to(cls, lexer):<tab># Apply a font for all styles<tab>lexer.setFont(Font().load())<tab>for name, font in cls.__dict__.items():<tab><tab>if not isinstance(font, Font):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>style_num = getattr(lexer, name)<tab><tab><tab>lexer.setColor(QColor(font.color), style_num)<tab><tab><tab>lexer.setEolFill(True, style_num)<tab><tab><tab>lexer.setPaper(QColor(font.paper), style_num)<tab><tab><tab>lexer.setFont(font.load(), style_num)",1,"if hasattr ( lexer , name ) :","if hasattr ( lexer , name ) :",0.75,100,1
"def set_columns(worksheet, c, lengths):<tab>for col, j in enumerate(c):<tab><tab>if j == ""Value"":<tab><tab><tab>j = "" "" * 18<tab><tab><IF-STMT><tab><tab><tab>j = ""Descr""<tab><tab>lengths[col] = max(len(j) + 5, lengths[col])<tab><tab>worksheet.set_column(col, col, lengths[col])",0,"if j == ""Description"" :","elif j == ""Descr"" :",0.058575651,41.11336169,0.5
"def _remove_listners(self):<tab>object = self.object<tab>kids = self.children_cache<tab>for key, val in kids.items():<tab><tab><IF-STMT><tab><tab><tab>vtk_obj = tvtk.to_vtk(val)<tab><tab><tab>messenger.disconnect(vtk_obj, ""ModifiedEvent"", self._notify_children)<tab><tab>else:<tab><tab><tab>object.on_trait_change(self._notify_children, key, remove=True)",1,"if isinstance ( val , tvtk . Collection ) :","if isinstance ( val , tvtk . Collection ) :",0.75,100,1
"def add(self, undoinfo, msg=None):<tab>if not undoinfo:<tab><tab>return<tab>if msg is not None:<tab><tab><IF-STMT><tab><tab><tab># replace message<tab><tab><tab>undoinfo = (msg,) + undoinfo[1:]<tab><tab>elif isinstance(undoinfo, tuple):<tab><tab><tab>undoinfo = (msg,) + undoinfo<tab><tab>else:<tab><tab><tab>undoinfo = (msg, undoinfo)<tab><tab>f = 1<tab>else:<tab><tab>f = int(isinstance(undoinfo[0], str))<tab>assert (<tab><tab>isinstance(undoinfo, list)<tab><tab>or callable(undoinfo[f])<tab><tab>or isinstance(undoinfo[f], list)<tab>)<tab>self.undoList.append(undoinfo)<tab>del self.redoList[:]",0,"if isinstance ( undoinfo [ 0 ] , str ) :","if undoinfo . startswith ( ""["" ) :",0.026123092,9.993744304,0.265306122
"def assert_last_day(self, period_end):<tab># 30 days has september, april, june and november<tab>if period_end.month in [9, 4, 6, 11]:<tab><tab>self.assertEqual(period_end.day, 30)<tab># all the rest have 31, except for february<tab>elif period_end.month != 2:<tab><tab>self.assertEqual(period_end.day, 31)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(period_end.day, 29)<tab><tab>else:<tab><tab><tab>self.assertEqual(period_end.day, 28)",0,if calendar . isleap ( period_end . year ) :,if period_end . month == 1 :,0.078035632,23.80176126,0.274725275
"def remove_callback(self, callback, events=None):<tab>if events is None:<tab><tab>for event in self._plugin_lifecycle_callbacks:<tab><tab><tab>if callback in self._plugin_lifecycle_callbacks[event]:<tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>events = [events]<tab><tab>for event in events:<tab><tab><tab>if callback in self._plugin_lifecycle_callbacks[event]:<tab><tab><tab><tab>self._plugin_lifecycle_callbacks[event].remove(callback)",0,"if isinstance ( events , basestring ) :","if not isinstance ( events , list ) :",0.200294835,36.88939732,0.26984127
"def get_count(self, peek=False):<tab>if self.argument_supplied:<tab><tab>count = self.argument_value<tab><tab>if self.argument_negative:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count = -1<tab><tab><tab>else:<tab><tab><tab><tab>count = -count<tab><tab><tab>if not peek:<tab><tab><tab><tab>self.argument_negative = False<tab><tab>if not peek:<tab><tab><tab>self.argument_supplied = False<tab>else:<tab><tab>count = 1<tab>return count",0,if count == 0 :,if count < 0 :,0.331415021,24.73692954,1
"def is_alive(self):<tab>if not self.runqemu:<tab><tab>return False<tab>if os.path.isfile(self.qemu_pidfile):<tab><tab>f = open(self.qemu_pidfile, ""r"")<tab><tab>qemu_pid = f.read()<tab><tab>f.close()<tab><tab>qemupid = int(qemu_pid)<tab><tab><IF-STMT><tab><tab><tab>self.qemupid = qemupid<tab><tab><tab>return True<tab>return False",0,"if os . path . exists ( ""/proc/"" + str ( qemupid ) ) :",if qemupid > self . qemupid :,0.008962882,1.672612572,0.2375
"def contains(self, other_route):<tab>if isinstance(other_route, list):<tab><tab>return self.to_list()[0 : len(other_route)] == other_route<tab># This only works before merging<tab>assert len(other_route.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>assert len(self.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>if other_route.task_spec == self.task_spec:<tab><tab>if other_route.outgoing and self.outgoing:<tab><tab><tab>return self.outgoing[0].contains(other_route.outgoing[0])<tab><tab>elif self.outgoing:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,elif not other_route . outgoing :,elif other_route . task_spec == self . task_spec :,0.090744066,16.94357182,0.384615385
"def _add_connection(self, connection, uri=None):<tab>with self._connections_lock:<tab><tab>connection_id = connection.connection_id<tab><tab><IF-STMT><tab><tab><tab>self._connections[connection_id] = ConnectionInfo(<tab><tab><tab><tab>ConnectionType.OUTBOUND_CONNECTION, connection, uri, None, None<tab><tab><tab>)",1,if connection_id not in self . _connections :,if connection_id not in self . _connections :,0.75,100,1
"def view(input_path):<tab>if not exists(input_path):<tab><tab>raise IOError(""{0} not found"".format(input_path))<tab>ua = None<tab>bundle_info = None<tab>try:<tab><tab>archive = archive_factory(input_path)<tab><tab>if archive is None:<tab><tab><tab>raise NotMatched(""No matching archive type found"")<tab><tab>ua = archive.unarchive_to_temp()<tab><tab>bundle_info = ua.bundle.info<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>ua.remove()<tab>return bundle_info",1,if ua is not None :,if ua is not None :,0.75,100,1
"def _expect_fail_and_reconnect(self, num_reconnects, fail_last=False):<tab>self._fake_backend.connect.expect_call(**_CONNECT_KWARGS).and_raises(<tab><tab>FakeDatabaseError()<tab>)<tab>for i in xrange(num_reconnects):<tab><tab>time.sleep.expect_call(_RECONNECT_DELAY)<tab><tab><IF-STMT><tab><tab><tab>self._expect_reconnect(fail=True)<tab><tab>else:<tab><tab><tab>self._expect_reconnect(fail=fail_last)",0,if i < num_reconnects - 1 :,if fail_last :,0.020447728,1.00E-10,0.45
def _trigger_step(self):<tab>if self._enable_step:<tab><tab>if self.local_step != self.trainer.steps_per_epoch - 1:<tab><tab><tab># not the last step<tab><tab><tab>self._trigger()<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._trigger(),0,if not self . _enable_epoch :,if self . local_step == self . trainer . steps_per_epoch - 1 :,0.036632699,6.228496954,0.425925926
"def draw_label(self):<tab>if self.hide:<tab><tab><IF-STMT><tab><tab><tab>seed = "" + ({0})"".format(str(int(self.seed)))<tab><tab>else:<tab><tab><tab>seed = "" + seed(s)""<tab><tab>return self.noise_type.title() + seed<tab>else:<tab><tab>return self.label or self.name",0,"if not self . inputs [ ""Seed"" ] . is_linked :",if self . seed is not None :,0.026123092,6.059409783,0.229166667
"def get_adapter(self, pattern=None):<tab>adapters = self.get_adapters()<tab>if pattern is None:<tab><tab>if len(adapters):<tab><tab><tab>return adapters[0]<tab><tab>else:<tab><tab><tab>raise DBusNoSuchAdapterError(""No adapter(s) found"")<tab>else:<tab><tab>for adapter in adapters:<tab><tab><tab>path = adapter.get_object_path()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return adapter<tab><tab>raise DBusNoSuchAdapterError(""No adapters found with pattern: %s"" % pattern)",0,"if path . endswith ( pattern ) or adapter [ ""Address"" ] == pattern :","if fnmatch . fnmatch ( path , pattern ) :",0.269344345,5.157732256,0.236111111
"def substituteargs(self, pattern, replacement, old):<tab>new = []<tab>for k in range(len(replacement)):<tab><tab>item = replacement[k]<tab><tab>newitem = [item[0], item[1], item[2]]<tab><tab>for i in range(3):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>newitem[i] = old[k][i]<tab><tab><tab>elif item[i][:1] == ""$"":<tab><tab><tab><tab>index = int(item[i][1:]) - 1<tab><tab><tab><tab>newitem[i] = old[index][i]<tab><tab>new.append(tuple(newitem))<tab>##self.report(""old: %r"", old)<tab>##self.report(""new: %r"", new)<tab>return new",0,"if item [ i ] == ""*"" :",if item [ i ] [ : 1 ] == pattern :,0.304046938,38.67706276,0.645833333
"def profiling_startup():<tab>if ""--profile-sverchok-startup"" in sys.argv:<tab><tab>global _profile_nesting<tab><tab>profile = None<tab><tab>try:<tab><tab><tab>profile = get_global_profile()<tab><tab><tab>_profile_nesting += 1<tab><tab><tab>if _profile_nesting == 1:<tab><tab><tab><tab>profile.enable()<tab><tab><tab>yield profile<tab><tab>finally:<tab><tab><tab>_profile_nesting -= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>profile.disable()<tab><tab><tab>dump_stats(file_path=""sverchok_profile.txt"")<tab><tab><tab>save_stats(""sverchok_profile.prof"")<tab>else:<tab><tab>yield None",0,if _profile_nesting == 0 and profile is not None :,if _profile_nesting == 0 :,0.170225808,51.01469473,0.318181818
"def align(size):<tab>if size <= 4096:<tab><tab># Small<tab><tab>if is_power2(size):<tab><tab><tab>return size<tab><tab>elif size < 128:<tab><tab><tab>return min_ge(range(16, 128 + 1, 16), size)<tab><tab><IF-STMT><tab><tab><tab>return min_ge(range(192, 512 + 1, 64), size)<tab><tab>else:<tab><tab><tab>return min_ge(range(768, 4096 + 1, 256), size)<tab>elif size < 4194304:<tab><tab># Large<tab><tab>return min_ge(range(4096, 4194304 + 1, 4096), size)<tab>else:<tab><tab># Huge<tab><tab>return min_ge(range(4194304, 536870912 + 1, 4194304), size)",0,elif size < 512 :,elif size < 256 :,0.392872021,42.72870064,0.6
"def _validate(self, event):<tab>new = self.value<tab>if new is not None and (<tab><tab>(self.start is not None and self.start > new)<tab><tab>or (self.end is not None and self.end < new)<tab>):<tab><tab>value = datetime.strftime(new, self.format)<tab><tab>start = datetime.strftime(self.start, self.format)<tab><tab>end = datetime.strftime(self.end, self.format)<tab><tab><IF-STMT><tab><tab><tab>self.value = event.old<tab><tab>raise ValueError(<tab><tab><tab>""DatetimeInput value must be between {start} and {end}, ""<tab><tab><tab>""supplied value is {value}"".format(start=start, end=end, value=value)<tab><tab>)",0,if event :,if value > event . old :,0.048251741,1.00E-10,0.35
"def parse(filename):<tab>dead_links = []<tab>with open(filename, ""r"") as file_:<tab><tab>for line in file_.readlines():<tab><tab><tab>res = reference_line.search(line)<tab><tab><tab>if res:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dead_links.append(res.group(1))<tab>return dead_links",0,if not exists ( res . group ( 1 ) ) :,if res . group ( 0 ) not in dead_links :,0.228605811,22.99751911,0.222222222
"def __getstate__(self):<tab>state = super(_GeneralExpressionDataImpl, self).__getstate__()<tab>for i in _GeneralExpressionDataImpl.__expression_slots__:<tab><tab>state[i] = getattr(self, i)<tab>if safe_mode:<tab><tab>state[""_parent_expr""] = None<tab><tab>if self._parent_expr is not None:<tab><tab><tab>_parent_expr = self._parent_expr()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state[""_parent_expr""] = _parent_expr<tab>return state",1,if _parent_expr is not None :,if _parent_expr is not None :,0.75,100,1
"def insertText(self, data, parent=None):<tab>data = data<tab>if parent != self:<tab><tab>_base.TreeBuilder.insertText(self, data, parent)<tab>else:<tab><tab># HACK: allow text nodes as children of the document node<tab><tab>if hasattr(self.dom, ""_child_node_types""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.dom._child_node_types = list(self.dom._child_node_types)<tab><tab><tab><tab>self.dom._child_node_types.append(Node.TEXT_NODE)<tab><tab>self.dom.appendChild(self.dom.createTextNode(data))",1,if Node . TEXT_NODE not in self . dom . _child_node_types :,if Node . TEXT_NODE not in self . dom . _child_node_types :,0.75,100,1
"def main(args):<tab>from argparse import ArgumentParser<tab>from sys import stdin, stdout<tab># TODO: Doc!<tab>argparser = ArgumentParser()<tab>argparser.add_argument(""-u"", ""--unescape"", action=""store_true"")<tab>argp = argparser.parse_args(args[1:])<tab>for line in (l.rstrip(""\n"") for l in stdin):<tab><tab><IF-STMT><tab><tab><tab>r = unescape(line)<tab><tab>else:<tab><tab><tab>r = escape(line)<tab><tab>stdout.write(r)<tab><tab>stdout.write(""\n"")",1,if argp . unescape :,if argp . unescape :,0.75,100,1
"def validate_user_json(value, json_schema):<tab>try:<tab><tab>jsonschema.validate(value, from_json(json_schema))<tab>except jsonschema.ValidationError as e:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidModelValueError(<tab><tab><tab><tab>""For '{}' the field value {}"".format(e.path[-1], e.message)<tab><tab><tab>)<tab><tab>raise InvalidModelValueError(e.message)<tab>except jsonschema.SchemaError as e:<tab><tab>raise InvalidModelValueError(e.message)<tab>validate_dates(value)",0,if len ( e . path ) > 1 :,"if e . path [ - 1 ] . endswith ( ""."" ) :",0.09820212,11.63327084,0.285714286
"def test_mode(self):<tab>with support.temp_umask(0o002):<tab><tab>base = support.TESTFN<tab><tab>parent = os.path.join(base, ""dir1"")<tab><tab>path = os.path.join(parent, ""dir2"")<tab><tab>os.makedirs(path, 0o555)<tab><tab>self.assertTrue(os.path.exists(path))<tab><tab>self.assertTrue(os.path.isdir(path))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(os.stat(path).st_mode & 0o777, 0o555)<tab><tab><tab>self.assertEqual(os.stat(parent).st_mode & 0o777, 0o775)",0,"if os . name != ""nt"" :",if os . path . exists ( path ) :,0.137208413,16.78445963,0.472222222
"def __get_annotations(self):<tab>if not hasattr(self, ""_annotations""):<tab><tab>self._annotations = _retrieve_annotations(<tab><tab><tab>self._adaptor, self._primary_id, self._taxon_id<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._annotations[""gi""] = self._identifier<tab><tab>if self._division:<tab><tab><tab>self._annotations[""data_file_division""] = self._division<tab>return self._annotations",1,if self . _identifier :,if self . _identifier :,0.75,100,1
"def string(self):<tab>""""""Returns a PlayString in string format from the Patterns values""""""<tab>string = """"<tab>for item in self.data:<tab><tab><IF-STMT><tab><tab><tab>string += item.string()<tab><tab>elif isinstance(item, Pattern):<tab><tab><tab>string += (<tab><tab><tab><tab>""(""<tab><tab><tab><tab>+ """".join(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>(s.string() if hasattr(s, ""string"") else str(s))<tab><tab><tab><tab><tab><tab>for s in item.data<tab><tab><tab><tab><tab>]<tab><tab><tab><tab>)<tab><tab><tab><tab>+ "")""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>string += str(item)<tab>return string",0,"if isinstance ( item , ( PGroup , GeneratorPattern ) ) :","if isinstance ( item , PlayString ) :",0.185140783,36.0645288,0.561904762
"def __getattribute__(self, item):<tab>try:<tab><tab>val = self[item]<tab><tab><IF-STMT><tab><tab><tab>val = import_string(val)<tab><tab>elif isinstance(val, (list, tuple)):<tab><tab><tab>val = [import_string(v) if isinstance(v, str) else v for v in val]<tab><tab>self[item] = val<tab>except KeyError:<tab><tab>val = super(ObjDict, self).__getattribute__(item)<tab>return val",1,"if isinstance ( val , str ) :","if isinstance ( val , str ) :",0.75,100,1
"def get_identifiers(self):<tab>ids = []<tab>ifaces = [i[""name""] for i in self.middleware.call_sync(""interface.query"")]<tab>for entry in glob.glob(f""{self._base_path}/interface-*""):<tab><tab>ident = entry.rsplit(""-"", 1)[-1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if os.path.exists(os.path.join(entry, ""if_octets.rrd"")):<tab><tab><tab>ids.append(ident)<tab>ids.sort(key=RRDBase._sort_disks)<tab>return ids",0,if ident not in ifaces :,if ident inaces :,0.10449376,21.44409712,0.357142857
"def save_new_objects(self, commit=True):<tab>self.new_objects = []<tab>for form in self.extra_forms:<tab><tab>if not form.has_changed():<tab><tab><tab>continue<tab><tab># If someone has marked an add form for deletion, don't save the<tab><tab># object.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.new_objects.append(self.save_new(form, commit=commit))<tab><tab>if not commit:<tab><tab><tab>self.saved_forms.append(form)<tab>return self.new_objects",0,if self . can_delete and self . _should_delete_form ( form ) :,if not form . has_changed ( ) :,0.024253488,4.666909137,0.3125
"def _get_seccomp_whitelist(self):<tab>whitelist = [False] * MAX_SYSCALL_NUMBER<tab>index = _SYSCALL_INDICIES[NATIVE_ABI]<tab>for i in range(SYSCALL_COUNT):<tab><tab># Ensure at least one syscall traps.<tab><tab># Otherwise, a simple assembly program could terminate without ever trapping.<tab><tab>if i in (sys_exit, sys_exit_group):<tab><tab><tab>continue<tab><tab>handler = self._security.get(i, DISALLOW)<tab><tab>for call in translator[i][index]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if isinstance(handler, int):<tab><tab><tab><tab>whitelist[call] = handler == ALLOW<tab>return whitelist",0,if call is None :,if call not in translator [ i ] :,0.172573492,10.55267032,0.305555556
"def start_check(aggregate, out):<tab>""""""Start checking in background and write encoded output to out.""""""<tab># check in background<tab>t = threading.Thread(target=director.check_urls, args=(aggregate,))<tab>t.start()<tab># time to wait for new data<tab>sleep_seconds = 2<tab># current running time<tab>run_seconds = 0<tab>while not aggregate.is_finished():<tab><tab>yield out.get_data()<tab><tab>time.sleep(sleep_seconds)<tab><tab>run_seconds += sleep_seconds<tab><tab><IF-STMT><tab><tab><tab>director.abort(aggregate)<tab><tab><tab>break<tab>yield out.get_data()",0,if run_seconds > MAX_REQUEST_SECONDS :,if run_seconds >= aggregate . get_max_run_seconds ( ) :,0.047573492,22.6121647,0.644444444
"def _prune_resource_identifiers(self, all_resources, all_operations):<tab>used_identifiers = self._get_identifiers_referenced_by_operations(all_operations)<tab>for resource, resource_data in list(all_resources.items()):<tab><tab>identifiers = resource_data[""resourceIdentifier""]<tab><tab>known_ids_for_resource = used_identifiers.get(resource, set())<tab><tab>for identifier_name in list(identifiers):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del identifiers[identifier_name]<tab><tab>if not identifiers:<tab><tab><tab># If there's no identifiers used by an autocompletion<tab><tab><tab># operation, then we don't need the resource.<tab><tab><tab>del all_resources[resource]",0,if identifier_name not in known_ids_for_resource :,if identifier_name in known_ids_for_resource :,0.233190283,78.81929718,0.464285714
"def has_valid_checksum(self, number):<tab>given_number, given_checksum = number[:-1], number[-1]<tab>calculated_checksum = 0<tab>parameter = 7<tab>for item in given_number:<tab><tab>fragment = str(int(item) * parameter)<tab><tab>if fragment.isalnum():<tab><tab><tab>calculated_checksum += int(fragment[-1])<tab><tab><IF-STMT><tab><tab><tab>parameter = 7<tab><tab>elif parameter == 3:<tab><tab><tab>parameter = 1<tab><tab>elif parameter == 7:<tab><tab><tab>parameter = 3<tab>return str(calculated_checksum)[-1] == given_checksum",0,if parameter == 1 :,elif parameter == 1 :,0.311522644,75.98356857,0.6
"def _poll_until_not(url, pending_statuses, err_msg):<tab>while True:<tab><tab>result, _, _ = _do_request(url, err_msg=err_msg)<tab><tab><IF-STMT><tab><tab><tab>time.sleep(2)<tab><tab><tab>continue<tab><tab>return result",0,"if result [ ""status"" ] in pending_statuses :",if result not in pending_statuses :,0.090742068,36.0645288,0.577777778
"def wrapper(request, *args, **kw):<tab>if switch_is_active(""disable-bigquery""):<tab><tab><IF-STMT><tab><tab><tab>response = http.HttpResponse(content_type=""text/csv; charset=utf-8"")<tab><tab>else:<tab><tab><tab>response = http.HttpResponse(content_type=""application/json"", content=""[]"")<tab><tab>response.status_code = 503<tab><tab>return response<tab>return f(request, *args, **kw)",0,"if kw . get ( ""format"" ) == ""csv"" :","if sys . version_info < ( 3 , 0 ) :",0.015448531,3.960533135,0.276190476
"def completion_safe_apply(ctx, f, args):<tab>from guild import config<tab>with config.SetGuildHome(ctx.parent.params.get(""guild_home"")):<tab><tab>try:<tab><tab><tab>return f(*args)<tab><tab>except (Exception, SystemExit):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>return None",0,"if os . getenv ( ""_GUILD_COMPLETE_DEBUG"" ) == ""1"" :","if ctx . parent . params . get ( ""guild_home"" ) is None :",0.063741334,6.464268536,0.177777778
"def configure(self, **kw):<tab>""""""Configure the image.""""""<tab>res = ()<tab>for k, v in _cnfmerge(kw).items():<tab><tab><IF-STMT><tab><tab><tab>if k[-1] == ""_"":<tab><tab><tab><tab>k = k[:-1]<tab><tab><tab>if hasattr(v, ""__call__""):<tab><tab><tab><tab>v = self._register(v)<tab><tab><tab>elif k in (""data"", ""maskdata""):<tab><tab><tab><tab>v = self.tk._createbytearray(v)<tab><tab><tab>res = res + (""-"" + k, v)<tab>self.tk.call((self.name, ""config"") + res)",1,if v is not None :,if v is not None :,0.75,100,1
"def _editor_lower(self):<tab>editorWidget = main_container.MainContainer().get_actual_editor()<tab>if editorWidget:<tab><tab>editorWidget.textCursor().beginEditBlock()<tab><tab><IF-STMT><tab><tab><tab>text = editorWidget.textCursor().selectedText().lower()<tab><tab>else:<tab><tab><tab>text = editorWidget._text_under_cursor().lower()<tab><tab><tab>editorWidget.moveCursor(QTextCursor.StartOfWord)<tab><tab><tab>editorWidget.moveCursor(QTextCursor.EndOfWord, QTextCursor.KeepAnchor)<tab><tab>editorWidget.textCursor().insertText(text)<tab><tab>editorWidget.textCursor().endEditBlock()",0,if editorWidget . textCursor ( ) . hasSelection ( ) :,if editorWidget . _text_under_cursor ( ) :,0.205059729,21.20062676,0.575
"def on_key_release(self, symbol, modifiers):<tab>if symbol == key.LEFT or symbol == key.RIGHT:<tab><tab>self.value = not self.value<tab><tab>self.text.text = self.get_label()<tab><tab>self.toggle_func(self.value)<tab><tab><IF-STMT><tab><tab><tab>bullet_sound.play()",0,if enable_sound :,if self . value :,0.051944023,1.00E-10,0.416666667
"def remove_checker(self, namespace, checker):<tab>for c in pyomo.core.check.ModelCheckRunner._checkers(all=True):<tab><tab><IF-STMT><tab><tab><tab>if namespace.checkers.get(c._checkerPackage(), None) is not None:<tab><tab><tab><tab>for i in range(<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].count(c._checkerName())<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].remove(c._checkerName())",1,if c . _checkerName ( ) == checker :,if c . _checkerName ( ) == checker :,0.75,100,1
"def find_executable(names):<tab># Given a list of executable names, find the first one that is available<tab># as an executable file, on the path.<tab>for name in names:<tab><tab>fpath, fname = os.path.split(name)<tab><tab><IF-STMT><tab><tab><tab># The given name is absolute.<tab><tab><tab>if is_executable(name):<tab><tab><tab><tab>return name<tab><tab>else:<tab><tab><tab># Try to find the name on the PATH<tab><tab><tab>for path in os.environ[""PATH""].split(os.pathsep):<tab><tab><tab><tab>exe_file = os.path.join(path, name)<tab><tab><tab><tab>if is_executable(exe_file):<tab><tab><tab><tab><tab>return exe_file<tab># Could not find it :(<tab>return None",0,if fpath :,"if fpath == ""."" :",0.097914534,1.00E-10,1
"def run(self):<tab>while True:<tab><tab>self.finished.wait(self.interval)<tab><tab>if self.finished.isSet():<tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self.function(*self.args, **self.kwargs)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.bus.log(<tab><tab><tab><tab><tab>""Error in perpetual timer thread function %r."" % self.function,<tab><tab><tab><tab><tab>level=40,<tab><tab><tab><tab><tab>traceback=True,<tab><tab><tab><tab>)<tab><tab><tab># Quit on first error to avoid massive logs.<tab><tab><tab>raise",0,if self . bus :,if self . debug :,0.394778655,42.72870064,0.6
"def get_user_object(self, user_id, group):<tab>if user_id:<tab><tab>user = OSFUser.load(user_id)<tab><tab>if not user:<tab><tab><tab>raise exceptions.NotFound(<tab><tab><tab><tab>detail=""User with id {} not found."".format(user_id)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise exceptions.ValidationError(<tab><tab><tab><tab>detail=""User is already a member of this group.""<tab><tab><tab>)<tab><tab>return user<tab>return user_id",0,"if group . has_permission ( user , ""member"" ) :",if user . group_id == group . id :,0.029205697,7.545339614,0.384615385
"def build_term_table(spec):<tab>try:<tab><tab>return _term_tables_cache[spec]<tab>except KeyError:<tab><tab>tbl = {}<tab><tab>terms = {}<tab><tab>i = 0<tab><tab>for t in spec:<tab><tab><tab>which = terms.setdefault(t, 0)<tab><tab><tab>tbl[t, which] = i<tab><tab><tab>tbl[""%s_%d"" % (t, which)] = i<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tbl[t] = i<tab><tab><tab>terms[t] += 1<tab><tab><tab>i += 1<tab><tab>_term_tables_cache[spec] = tbl<tab><tab>return tbl",0,if which == 0 :,if terms . has_key ( t ) :,0.026407399,4.990049702,0.333333333
"def GetQualifiedWsdlName(type):<tab>with _lazyLock:<tab><tab>wsdlNSAndName = _wsdlNameMap.get(type)<tab><tab>if wsdlNSAndName:<tab><tab><tab>return wsdlNSAndName<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ns = GetWsdlNamespace(type.Item._version)<tab><tab><tab><tab>return (ns, ""ArrayOf"" + Capitalize(type.Item._wsdlName))<tab><tab><tab>else:<tab><tab><tab><tab>ns = GetWsdlNamespace(type._version)<tab><tab><tab><tab>return (ns, type._wsdlName)",0,"if issubclass ( type , list ) :",if type . Item . _wsdlName :,0.019627455,7.267884212,0.314814815
"def train(config, checkpoint_dir=None):<tab>restored = bool(checkpoint_dir)<tab>itr = 0<tab>if checkpoint_dir:<tab><tab>with open(os.path.join(checkpoint_dir, ""ckpt.log""), ""r"") as f:<tab><tab><tab>itr = int(f.read()) + 1<tab>for i in range(itr, 10):<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""try to fail me"")<tab><tab>with tune.checkpoint_dir(step=itr) as checkpoint_dir:<tab><tab><tab>checkpoint_path = os.path.join(checkpoint_dir, ""ckpt.log"")<tab><tab><tab>with open(checkpoint_path, ""w"") as f:<tab><tab><tab><tab>f.write(str(i))<tab><tab>tune.report(test=i, training_iteration=i)",0,if i == 5 and not restored :,if restored :,0.030705693,1.00E-10,0.214285714
"def _process_events(self, event_list):<tab>for key, mask in event_list:<tab><tab>fileobj, (reader, writer) = key.fileobj, key.data<tab><tab>if mask & selectors.EVENT_READ and reader is not None:<tab><tab><tab>if reader._cancelled:<tab><tab><tab><tab>self.remove_reader(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(reader)<tab><tab>if mask & selectors.EVENT_WRITE and writer is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.remove_writer(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(writer)",1,if writer . _cancelled :,if writer . _cancelled :,0.75,100,1
"def _validate_mappings(self):<tab># Validate mapping references<tab>for m in self.mapping.mapping_rules:<tab><tab>for policy_id in m.policy_ids:<tab><tab><tab>if policy_id not in self.policies:<tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=policy_id, reference_type=""policy""<tab><tab><tab><tab>)<tab><tab>for w in m.whitelist_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=w, reference_type=""whitelist""<tab><tab><tab><tab>)",0,if w not in self . whitelists :,if w not in self . policies :,0.605621306,70.71067812,0.75
"def _transform_backward(graph, op):<tab>no_dequanted_input_vars = True<tab>for var_node in op.inputs:<tab><tab><IF-STMT><tab><tab><tab>dequant_var_node = dequantized_vars[var_node.name()]<tab><tab><tab>graph.update_input_link(var_node, dequant_var_node, op)<tab><tab><tab>no_dequanted_input_vars = False<tab>if no_dequanted_input_vars:<tab><tab>raise ValueError(""There is no dequanted inputs for op %s."" % (op.name()))",1,if var_node . name ( ) in dequantized_vars :,if var_node . name ( ) in dequantized_vars :,0.75,100,1
"def should_use_pty(self, pty=False, fallback=True):<tab>use_pty = False<tab>if pty:<tab><tab>use_pty = True<tab><tab># TODO: pass in & test in_stream, not sys.stdin<tab><tab><IF-STMT><tab><tab><tab>if not self.warned_about_pty_fallback:<tab><tab><tab><tab>err = ""WARNING: stdin has no fileno; falling back to non-pty execution!\n""  # noqa<tab><tab><tab><tab>sys.stderr.write(err)<tab><tab><tab><tab>self.warned_about_pty_fallback = True<tab><tab><tab>use_pty = False<tab>return use_pty",0,if not has_fileno ( sys . stdin ) and fallback :,if fallback :,0.017233337,1.00E-10,0.244897959
"def _get_default_factory(self, attribute_name: str) -> Any:<tab>if hasattr(self, attribute_name):<tab><tab><IF-STMT><tab><tab><tab>return str(getattr(self, attribute_name))<tab><tab>elif str(self.__dataclass_fields__[attribute_name].default).startswith(""${""):<tab><tab><tab>return str(self.__dataclass_fields__[attribute_name].default)<tab><tab>elif (<tab><tab><tab>getattr(self, attribute_name)<tab><tab><tab>!= self.__dataclass_fields__[attribute_name].default_factory()<tab><tab>):<tab><tab><tab>return getattr(self, attribute_name)<tab>return self.__dataclass_fields__[attribute_name].default_factory()",1,"if str ( getattr ( self , attribute_name ) ) . startswith ( ""${"" ) :","if str ( getattr ( self , attribute_name ) ) . startswith ( ""${"" ) :",0.75,100,1
"def create_row_processor(<tab>self, context, path, loadopt, mapper, result, adapter, populators):<tab># look through list of columns represented here<tab># to see which, if any, is present in the row.<tab>for col in self.columns:<tab><tab><IF-STMT><tab><tab><tab>col = adapter.columns[col]<tab><tab>getter = result._getter(col, False)<tab><tab>if getter:<tab><tab><tab>populators[""quick""].append((self.key, getter))<tab><tab><tab>break<tab>else:<tab><tab>populators[""expire""].append((self.key, True))",0,if adapter :,"if isinstance ( self . columns [ col ] , int ) :",0.04058966,1.00E-10,0.222222222
"def test_finds_multiple_songs(self):<tab>for _, album in albums_in_dir(self.base):<tab><tab>n = re.search(br""album(.)song"", album[0]).group(1)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(len(album), 2)<tab><tab>else:<tab><tab><tab>self.assertEqual(len(album), 1)",0,"if n == b""1"" :","if n == ""1"" :",0.144778655,61.01950432,1
"def _should_update_cache(self, request, response):<tab>if not hasattr(request, ""_cache_update_cache"") or not request._cache_update_cache:<tab><tab>return False<tab>if self.cache_anonymous_only and has_vary_header(response, ""Cookie""):<tab><tab>assert hasattr(<tab><tab><tab>request, ""user""<tab><tab>), ""The Django cache middleware with CACHE_MIDDLEWARE_ANONYMOUS_ONLY=True requires authentication middleware to be installed. Edit your MIDDLEWARE_CLASSES setting to insert 'django.contrib.auth.middleware.AuthenticationMiddleware' before the CacheMiddleware.""<tab><tab><IF-STMT><tab><tab><tab># Don't cache user-variable requests from authenticated users.<tab><tab><tab>return False<tab>return True",0,if request . user . is_authenticated ( ) :,"if has_vary_header ( request , ""user"" ) :",0.033138934,7.768562846,0.730769231
"def break_next_call(symbol_regex=None):<tab>while pwndbg.proc.alive:<tab><tab>ins = break_next_branch()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab># continue if not a call<tab><tab>if capstone.CS_GRP_CALL not in ins.groups:<tab><tab><tab>continue<tab><tab># return call if we don't search for a symbol<tab><tab>if not symbol_regex:<tab><tab><tab>return ins<tab><tab># return call if we match target address<tab><tab>if ins.target_const and re.match(""%s$"" % symbol_regex, hex(ins.target)):<tab><tab><tab>return ins<tab><tab># return call if we match symbol name<tab><tab>if ins.symbol and re.match(""%s$"" % symbol_regex, ins.symbol):<tab><tab><tab>return ins",0,if not ins :,if ins is None :,0.045150551,14.05853313,0.277777778
"def parser(cls, buf, offset):<tab>type_, len_, vendor = struct.unpack_from(<tab><tab>ofproto.OFP_ACTION_VENDOR_HEADER_PACK_STR, buf, offset<tab>)<tab>data = buf[(offset + ofproto.OFP_ACTION_VENDOR_HEADER_SIZE) : offset + len_]<tab>if vendor == ofproto_common.NX_EXPERIMENTER_ID:<tab><tab>obj = NXAction.parse(data)  # noqa<tab>else:<tab><tab>cls_ = cls._ACTION_VENDORS.get(vendor, None)<tab><tab><IF-STMT><tab><tab><tab>obj = OFPActionVendorUnknown(vendor, data)<tab><tab>else:<tab><tab><tab>obj = cls_.parser(buf, offset)<tab>obj.len = len_<tab>return obj",1,if cls_ is None :,if cls_ is None :,0.75,100,1
"def remove_empty_files(root_path):<tab>""""""Removes empty files in a path recursively""""""<tab>for directory, _, filenames in walk(root_path):<tab><tab>for filename in filenames:<tab><tab><tab>path = os.path.join(directory, filename)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>try:<tab><tab><tab><tab>os.remove(path)<tab><tab><tab>except:<tab><tab><tab><tab>logs.log_error(<tab><tab><tab><tab><tab>""Unable to remove the empty file: %s (%s).""<tab><tab><tab><tab><tab>% (path, sys.exc_info()[0])<tab><tab><tab><tab>)",0,if os . path . getsize ( path ) > 0 :,if not os . path . isfile ( path ) :,0.415756399,32.99292579,0.25
"def _test_set_ipv4_src(self, ip, mask=None):<tab>header = ofproto.OXM_OF_IPV4_SRC<tab>match = OFPMatch()<tab>ip = unpack(""!I"", socket.inet_aton(ip))[0]<tab>if mask is None:<tab><tab>match.set_ipv4_src(ip)<tab>else:<tab><tab>mask = unpack(""!I"", socket.inet_aton(mask))[0]<tab><tab><IF-STMT><tab><tab><tab>header = ofproto.OXM_OF_IPV4_SRC_W<tab><tab>match.set_ipv4_src_masked(ip, mask)<tab>self._test_serialize_and_parser(match, header, ip, mask)",0,if ( mask + 1 ) >> 32 != 1 :,if header == ofproto . OXM_OF_IPV4_SRC :,0.012371041,3.737437944,0.265306122
"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab>return True",0,"if self . map . get ( ( self . block . pos . x + i , self . block . pos . y + j ) , False ) :",if self . block . pos . y + j >= COLUMNS :,0.230175024,18.4365289,0.177655678
"def __init__(self, *args, **kwargs):<tab>dict.__init__(self, *args, **kwargs)<tab>for key, value in self.items():<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""key must be a str, not {}"".format(type(key)))<tab><tab>if not isinstance(value, NUMERIC_TYPES):<tab><tab><tab>raise TypeError(""value must be a NUMERIC_TYPES, not {}"".format(type(value)))<tab><tab>if not isinstance(value, float):<tab><tab><tab>self[key] = float(value)",0,"if not isinstance ( key , string_types ) :","if not isinstance ( key , str ) :",0.581882088,52.89934435,0.814814815
"def refresh_committed_offsets_if_needed(self):<tab>""""""Fetch committed offsets for assigned partitions.""""""<tab>if self._subscription.needs_fetch_committed_offsets:<tab><tab>offsets = self.fetch_committed_offsets(self._subscription.assigned_partitions())<tab><tab>for partition, offset in six.iteritems(offsets):<tab><tab><tab># verify assignment is still active<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._subscription.assignment[partition].committed = offset.offset<tab><tab>self._subscription.needs_fetch_committed_offsets = False",0,if self . _subscription . is_assigned ( partition ) :,if offset . offset != self . _subscription . assignment [ partition ] . committed :,0.171770692,22.6121647,0.25974026
"def getText(self, stuff):<tab>if isinstance(stuff, BaseWrapper):<tab><tab>stuff = stuff.item<tab>if isinstance(stuff, (Fit, TargetProfile)):<tab><tab>val, unit = self._getValue(stuff)<tab><tab><IF-STMT><tab><tab><tab>return """"<tab><tab># Stick to value - 25k GJ<tab><tab>if self.stickPrefixToValue:<tab><tab><tab>return ""{} {}"".format(formatAmount(val, *self.formatSpec), unit)<tab><tab># Stick to unit - 25 km<tab><tab>else:<tab><tab><tab>return formatAmount(val, *self.formatSpec, unitName=unit)<tab>return """"",0,if val is None :,if unit is None :,0.394778655,42.72870064,0.666666667
"def __get__(self, inst, owner):<tab>try:<tab><tab>value, last_update = inst._cache[self.__name__]<tab><tab><IF-STMT><tab><tab><tab>raise AttributeError<tab>except (KeyError, AttributeError):<tab><tab>value = self.fget(inst)<tab><tab>try:<tab><tab><tab>cache = inst._cache<tab><tab>except AttributeError:<tab><tab><tab>cache = inst._cache = {}<tab><tab>cache[self.__name__] = (value, time.time())<tab>return value",0,if self . ttl > 0 and time . time ( ) - last_update > self . ttl :,if value != last_update :,0.005022481,4.599246087,0.217592593
"def on_event_clicked(self, widget, event):<tab>if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3:<tab><tab>path = self.get_path_at_pos(int(event.x), int(event.y))<tab><tab><IF-STMT><tab><tab><tab>row = self.get(path[0], ""device"")<tab><tab><tab>if row:<tab><tab><tab><tab>if self.Blueman is not None:<tab><tab><tab><tab><tab>if self.menu is None:<tab><tab><tab><tab><tab><tab>self.menu = ManagerDeviceMenu(self.Blueman)<tab><tab><tab><tab><tab>self.menu.popup(None, None, None, None, event.button, event.time)",0,if path is not None :,if path :,0.050438393,1.00E-10,0.4
"def groups(self):<tab>""""""Return a dictionary mapping group names to JIDs.""""""<tab>result = {}<tab>for jid in self._jids:<tab><tab>groups = self._jids[jid][""groups""]<tab><tab><IF-STMT><tab><tab><tab>if """" not in result:<tab><tab><tab><tab>result[""""] = []<tab><tab><tab>result[""""].append(jid)<tab><tab>for group in groups:<tab><tab><tab>if group not in result:<tab><tab><tab><tab>result[group] = []<tab><tab><tab>result[group].append(jid)<tab>return result",1,if not groups :,if not groups :,0.75,100,1
"def set_meta(self, dataset, overwrite=True, **kwd):<tab>super().set_meta(dataset, overwrite=overwrite, **kwd)<tab>try:<tab><tab>conn = sqlite.connect(dataset.file_name)<tab><tab>c = conn.cursor()<tab><tab>version_query = ""SELECT version FROM meta""<tab><tab>results = c.execute(version_query).fetchall()<tab><tab>if len(results) == 0:<tab><tab><tab>raise Exception(""version not found in meta table"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Multiple versions found in meta table"")<tab><tab>dataset.metadata.gafa_schema_version = results[0][0]<tab>except Exception as e:<tab><tab>log.warning(""%s, set_meta Exception: %s"", self, e)",0,elif len ( results ) > 1 :,if len ( results ) > 1 :,0.420448208,84.08964153,0.666666667
"def GetSelectedCount(self):<tab>if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL:<tab><tab>return self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0)<tab>else:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0)<tab><tab><IF-STMT><tab><tab><tab>return 0<tab><tab>return 1",0,if result == LB_ERR :,if result == 1 :,0.144778655,38.49815008,0.7
"def emit(self, record):<tab>try:<tab><tab>item = QListWidgetItem(self.format(record))<tab><tab><IF-STMT><tab><tab><tab>item.setIcon(QIcon.fromTheme(""dialog-warning""))<tab><tab><tab>item.setForeground(QBrush(Qt.red))<tab><tab>else:<tab><tab><tab>item.setIcon(QIcon.fromTheme(""dialog-information""))<tab><tab>self.app.exec_in_main(self._add_item, item)<tab>except (KeyboardInterrupt, SystemExit):<tab><tab>raise<tab>except:<tab><tab>self.handleError(record)",0,if record . levelno > logging . INFO :,if self . warn_on_warning :,0.079338046,6.274655311,0.246753247
"def _updater(data):<tab>assert data[""attrs""][""tvm_version""].startswith(from_ver)<tab>nodes = data[""nodes""]<tab>for idx, item in enumerate(nodes):<tab><tab>f = node_map.get(item[""type_key""], None)<tab><tab><IF-STMT><tab><tab><tab>for fpass in f:<tab><tab><tab><tab>item = fpass(item, nodes)<tab><tab>elif f:<tab><tab><tab>item = f(item, nodes)<tab><tab>nodes[idx] = item<tab>data[""attrs""][""tvm_version""] = to_ver<tab>return data",0,"if isinstance ( f , list ) :",if f :,0.01726708,1.00E-10,0.36
def remove_data(self):<tab>if self.path is not None:<tab><tab><IF-STMT><tab><tab><tab>os.remove(self.path)<tab><tab>if os.path.exists(self.get_json_path()):<tab><tab><tab>os.remove(self.get_json_path()),1,if os . path . exists ( self . path ) :,if os . path . exists ( self . path ) :,1,100,1
"def testsingle(self, sym):<tab>if self.settings == ""asterisk"":<tab><tab>return (sym == ""*"", ""*"")<tab>if self.settings == ""plus"":<tab><tab>return (sym == ""+"", ""+"")<tab>if self.settings == ""dash"":<tab><tab>return (sym == ""-"", ""-"")<tab>if self.settings == ""single"":<tab><tab><IF-STMT><tab><tab><tab>return (self.lastSym == sym, self.lastSym)<tab><tab>else:<tab><tab><tab>self.lastSym = sym<tab><tab><tab>return (True, None)<tab>return (None, None)",0,if self . lastSym :,if self . lastSym is not None :,0.351498834,36.55552229,0.510204082
"def update(self, other_dict, option_parser):<tab>if isinstance(other_dict, Values):<tab><tab>other_dict = other_dict.__dict__<tab>other_dict = other_dict.copy()<tab>for setting in option_parser.lists.keys():<tab><tab><IF-STMT><tab><tab><tab>value = getattr(self, setting)<tab><tab><tab>if value:<tab><tab><tab><tab>value += other_dict[setting]<tab><tab><tab><tab>del other_dict[setting]<tab>self._update_loose(other_dict)",0,"if hasattr ( self , setting ) and setting in other_dict :",if setting in other_dict :,0.175429891,30.93485033,0.244897959
"def gprv_immv(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab>if i == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab>if op_immv(op):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",0,"if op . name == ""REG0"" and op_luf_start ( op , ""GPRv"" ) :",if op_reg ( op ) :,0.020790737,3.276329235,0.504761905
"def __call__(self, input_tensors, shape):<tab>if self.order in ""KA"":<tab><tab><IF-STMT><tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>else:<tab><tab>if self.order == ""C"":<tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>return self.new_tensor(input_tensors, shape=shape, dtype=self.dtype, order=order)",0,if any ( t . order == TensorOrder . C_ORDER for t in input_tensors ) :,"if self . order == ""C"" :",0.072603915,10.05728503,0.195767196
"def check_selected(menu, path):<tab>selected = False<tab>if ""url"" in menu:<tab><tab>chop_index = menu[""url""].find(""?"")<tab><tab><IF-STMT><tab><tab><tab>selected = path.startswith(menu[""url""])<tab><tab>else:<tab><tab><tab>selected = path.startswith(menu[""url""][:chop_index])<tab>if ""menus"" in menu:<tab><tab>for m in menu[""menus""]:<tab><tab><tab>_s = check_selected(m, path)<tab><tab><tab>if _s:<tab><tab><tab><tab>selected = True<tab>if selected:<tab><tab>menu[""selected""] = True<tab>return selected",1,if chop_index == - 1 :,if chop_index == - 1 :,0.75,100,1
"def _check_events(self):<tab># make sure song-started and song-ended match up<tab>stack = []<tab>old = self.events[:]<tab>for type_, song in self.events:<tab><tab>if type_ == ""started"":<tab><tab><tab>stack.append(song)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(stack.pop(-1) is song, msg=old)<tab>self.assertFalse(stack, msg=old)",1,"elif type_ == ""ended"" :","elif type_ == ""ended"" :",1,100,1
"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab>if key[:6] == ""start_"":<tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if start is None:<tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab><IF-STMT><tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if end is None:<tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)",1,"elif key [ : 4 ] == ""end_"" :","elif key [ : 4 ] == ""end_"" :",1,100,1
"def nested_match(expect, value):<tab>if expect == value:<tab><tab>return True<tab>if isinstance(expect, dict) and isinstance(value, dict):<tab><tab>for k, v in expect.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not nested_match(v, value[k]):<tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>return True<tab>if isinstance(expect, list) and isinstance(value, list):<tab><tab>for x, y in zip(expect, value):<tab><tab><tab>if not nested_match(x, y):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",1,if k in value :,if k in value :,0.75,100,1
"def code_match(code, select, ignore):<tab>if ignore:<tab><tab>assert not isinstance(ignore, unicode)<tab><tab>for ignored_code in [c.strip() for c in ignore]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>if select:<tab><tab>assert not isinstance(select, unicode)<tab><tab>for selected_code in [c.strip() for c in select]:<tab><tab><tab>if mutual_startswith(code.lower(), selected_code.lower()):<tab><tab><tab><tab>return True<tab><tab>return False<tab>return True",1,"if mutual_startswith ( code . lower ( ) , ignored_code . lower ( ) ) :","if mutual_startswith ( code . lower ( ) , ignored_code . lower ( ) ) :",1,100,1
"def test_cardinality_m2o(self):<tab>m2o_type_fields = [<tab><tab>f for f in self.fields_and_reverse_objects if f.is_relation and f.many_to_one<tab>]<tab># Test classes are what we expect<tab>self.assertEqual(MANY_TO_ONE_CLASSES, {f.__class__ for f in m2o_type_fields})<tab># Ensure all m2o reverses are o2m<tab>for obj in m2o_type_fields:<tab><tab><IF-STMT><tab><tab><tab>reverse_field = obj.field<tab><tab><tab>self.assertTrue(reverse_field.is_relation and reverse_field.one_to_many)",1,"if hasattr ( obj , ""field"" ) :","if hasattr ( obj , ""field"" ) :",0.75,100,1
"def flatten_dict(self, request):<tab>dct = super(KnowledgeFolderHandler, self).flatten_dict(request)<tab>dct[""knowledgeType_id""] = None<tab>parent = request.data.get(""parent"")<tab>if parent:<tab><tab>parent = getOrNone(KnowledgeFolder, pk=parent)<tab><tab><IF-STMT><tab><tab><tab>request.data[""parent""] = None<tab>return dct",0,"if not parent or not request . user . profile . has_permission ( parent , mode = ""x"" ) :",if parent is None :,0.087954929,0.314500237,0.160839161
"def delete_oidc_session_tokens(session):<tab>if session:<tab><tab>if ""oidc_access_token"" in session:<tab><tab><tab>del session[""oidc_access_token""]<tab><tab><IF-STMT><tab><tab><tab>del session[""oidc_id_token""]<tab><tab>if ""oidc_id_token_expiration"" in session:<tab><tab><tab>del session[""oidc_id_token_expiration""]<tab><tab>if ""oidc_login_next"" in session:<tab><tab><tab>del session[""oidc_login_next""]<tab><tab>if ""oidc_refresh_token"" in session:<tab><tab><tab>del session[""oidc_refresh_token""]<tab><tab>if ""oidc_state"" in session:<tab><tab><tab>del session[""oidc_state""]",1,"if ""oidc_id_token"" in session :","if ""oidc_id_token"" in session :",0.75,100,1
"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>if sty.drawing:<tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",0,if sty . strikeout :,"if not fragment . startswith ( ""#"" ) :",0.026752541,4.932351569,0.272727273
"def test_reduce_different_name(<tab>ray_start_distributed_2_nodes_4_gpus, group_name, dst_rank):<tab>world_size = 4<tab>actors, _ = create_collective_workers(num_workers=world_size, group_name=group_name)<tab>results = ray.get([a.do_reduce.remote(group_name, dst_rank) for a in actors])<tab>for i in range(world_size):<tab><tab><IF-STMT><tab><tab><tab>assert (results[i] == cp.ones((10,), dtype=cp.float32) * world_size).all()<tab><tab>else:<tab><tab><tab>assert (results[i] == cp.ones((10,), dtype=cp.float32)).all()",1,if i == dst_rank :,if i == dst_rank :,0.75,100,1
"def _find_docstrings(self, filename):<tab># A replacement for trace.find_strings() which was deprecated in<tab># Python 3.2 and removed in 3.6.<tab>strs = set()<tab>prev = token.INDENT  # so module docstring is detected as docstring<tab>with tokenize_open(filename) as f:<tab><tab>tokens = tokenize.generate_tokens(f.readline)<tab><tab>for ttype, tstr, start, end, line in tokens:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strs.update(range(start[0], end[0] + 1))<tab><tab><tab>prev = ttype<tab>return strs",0,if ttype == token . STRING and prev == token . INDENT :,if tstr == prev :,0.009944017,4.554625322,0.185185185
"def on_click(self, event):<tab>button = event[""button""]<tab>if button in [self.button_next, self.button_previous]:<tab><tab><IF-STMT><tab><tab><tab>self.scrolling = True<tab><tab><tab>if button == self.button_next:<tab><tab><tab><tab>self.active_index += 1<tab><tab><tab>elif button == self.button_previous:<tab><tab><tab><tab>self.active_index -= 1<tab><tab><tab>self.active_index %= self.count_stations<tab><tab>else:<tab><tab><tab>self.py3.prevent_refresh()<tab>elif button == self.button_refresh:<tab><tab>self.idle_time = 0<tab>else:<tab><tab>self.py3.prevent_refresh()",0,if self . station_data :,if self . scrolling :,0.394778655,28.64190458,0.7
"def findRule(instance, ruleSet):<tab>""""""find the rule(s) that matches the feture vector passed""""""<tab># print(""*Looking for rule match for Feature vector: "" + featuresToString(instance))<tab>ruleNumber = 0  # counter to track rule number<tab>ruleMatches = []  # will hold all rule numbers that matched<tab>for rule in ruleSet:<tab><tab>if ruleMatch(rule, instance):<tab><tab><tab>ruleMatches.append(ruleNumber)<tab><tab><tab>counts[<tab><tab><tab><tab>ruleNumber<tab><tab><tab>] += 1  # update global histogram of rule matches for stats reporting<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print("" ruleMatch found at rule #"" + str(ruleNumber))<tab><tab><tab><tab>print("" "", end="""")<tab><tab><tab><tab>printRule(rule)<tab><tab>ruleNumber += 1<tab>return ruleMatches",0,if False :,if ruleNumber % 10000 == 0 :,0.045790811,1.00E-10,0.291666667
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.mutable_peer_ip().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",0,if tt == 18 :,if tt == 10 :,0.394778655,53.72849659,0.6
"def _check_no_tensors(parameters: Params):<tab>flat_params = tf.nest.flatten(parameters.params)<tab>for p in flat_params:<tab><tab><IF-STMT><tab><tab><tab>_check_no_tensors(p)<tab><tab>if tf.is_tensor(p):<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Saw a `Tensor` value in parameters:\n  {}"".format(parameters)<tab><tab><tab>)",0,"if isinstance ( p , Params ) :","if isinstance ( p , tf . Tensor ) :",0.263340042,45.18010018,0.558441558
"def all_zinc_rsc_invalid_dep_keys(invalid_deps):<tab>""""""Get the rsc key for an rsc-and-zinc target, or the zinc key for a zinc-only target.""""""<tab>for tgt in invalid_deps:<tab><tab># None can occur for e.g. JarLibrary deps, which we don't need to compile as they are<tab><tab># populated in the resolve goal.<tab><tab>tgt_rsc_cc = compile_contexts[tgt].rsc_cc<tab><tab><IF-STMT><tab><tab><tab># Rely on the results of zinc compiles for zinc-compatible targets<tab><tab><tab>yield self._key_for_target_as_dep(tgt, tgt_rsc_cc.workflow)",0,if tgt_rsc_cc . workflow is not None :,if tgt_rsc_cc is not None :,0.338772207,64.32188699,0.30952381
"def characters(self, ch):<tab>if self.Text_tag:<tab><tab>if self.Summary_tag:<tab><tab><tab>self.Summary_ch += ch<tab><tab>elif self.Attack_Prerequisite_tag:<tab><tab><tab>self.Attack_Prerequisite_ch += ch<tab><tab><IF-STMT><tab><tab><tab>self.Solution_or_Mitigation_ch += ch<tab>elif self.CWE_ID_tag:<tab><tab>self.CWE_ID_ch += ch",1,elif self . Solution_or_Mitigation_tag :,elif self . Solution_or_Mitigation_tag :,0.75,100,1
"def load_tool_from_cache(self, config_file, recover_tool=False):<tab>tool_cache = getattr(self.app, ""tool_cache"", None)<tab>tool = None<tab>if tool_cache:<tab><tab><IF-STMT><tab><tab><tab>tool = tool_cache.get_removed_tool(config_file)<tab><tab>else:<tab><tab><tab>tool = tool_cache.get_tool(config_file)<tab>return tool",1,if recover_tool :,if recover_tool :,0.531170663,1.00E-10,1
"def _generate_examples(self, archive, directory, labeled=True):<tab>""""""Generate IMDB examples.""""""<tab># For labeled examples, extract the label from the path.<tab>reg_path = ""(?P<label>neg|pos)"" if labeled else ""unsup""<tab>reg = re.compile(<tab><tab>os.path.join(""^%s"" % directory, reg_path, """").replace(""\\"", ""\\\\"")<tab>)<tab>for path, imdb_f in archive:<tab><tab>res = reg.match(path)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>text = imdb_f.read().strip()<tab><tab>label = res.groupdict()[""label""] if labeled else -1<tab><tab>yield path, {<tab><tab><tab>""text"": text,<tab><tab><tab>""label"": label,<tab><tab>}",0,if not res :,if res is None :,0.045150551,14.05853313,0.277777778
def startInputThread(self):<tab># cv.acquire()<tab># Fix Python 2.x.<tab>global input<tab>try:<tab><tab>input = raw_input<tab>except NameError:<tab><tab>pass<tab>while True:<tab><tab>cmd = (<tab><tab><tab>self._queuedCmds.pop(0)<tab><tab><tab>if len(self._queuedCmds)<tab><tab><tab>else input(self.getPrompt()).strip()<tab><tab>)<tab><tab>wait = self.execCmd(cmd)<tab><tab><IF-STMT><tab><tab><tab>self.acceptingInput = False<tab><tab><tab>self.blockingQueue.get(True)<tab><tab><tab># cv.wait()<tab><tab><tab># self.inputThread.wait()<tab><tab>self.acceptingInput = True,0,if wait :,if wait == 0 :,0.097914534,1.00E-10,0.7
"def assertS_IS(self, name, mode):<tab># test format, lstrip is for S_IFIFO<tab>fmt = getattr(stat, ""S_IF"" + name.lstrip(""F""))<tab>self.assertEqual(stat.S_IFMT(mode), fmt)<tab># test that just one function returns true<tab>testname = ""S_IS"" + name<tab>for funcname in self.format_funcs:<tab><tab>func = getattr(stat, funcname, None)<tab><tab>if func is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(funcname)<tab><tab><tab>continue<tab><tab>if funcname == testname:<tab><tab><tab>self.assertTrue(func(mode))<tab><tab>else:<tab><tab><tab>self.assertFalse(func(mode))",1,if funcname == testname :,if funcname == testname :,0.75,100,1
"def test_compatibility(self) -> None:<tab>for expected, user_agent in self.data:<tab><tab>result = self.client_get(""/compatibility"", HTTP_USER_AGENT=user_agent)<tab><tab>if expected == ""ok"":<tab><tab><tab>self.assert_json_success(result)<tab><tab><IF-STMT><tab><tab><tab>self.assert_json_error(result, ""Client is too old"")<tab><tab>else:<tab><tab><tab>assert False  # nocoverage",0,"elif expected == ""old"" :","elif expected == ""error"" :",0.642872021,59.46035575,1
"def getBranchFromFile():<tab>global _gitdir<tab>branch = None<tab>if _gitdir:<tab><tab>headFile = os.path.join(_gitdir, ""HEAD"")<tab><tab><IF-STMT><tab><tab><tab>with open(headFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab>if line.startswith(""ref""):<tab><tab><tab><tab><tab><tab>branch = line.split(""/"")[-1].strip()<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>branch = ""HEAD""<tab>return branch",0,if os . path . isfile ( headFile ) :,if os . path . exists ( headFile ) :,0.580308871,65.80370065,0.714285714
"def get_job_parameters_dict(self, job_parameters: RunParameters = None):<tab>if job_parameters:<tab><tab><IF-STMT><tab><tab><tab>self.job_runtime_conf[""job_parameters""][""common""] = job_parameters.to_dict()<tab><tab>else:<tab><tab><tab>self.job_runtime_conf[""job_parameters""] = job_parameters.to_dict()<tab>return self.job_runtime_conf[""job_parameters""]",0,"if int ( self . job_runtime_conf . get ( ""dsl_version"" , 1 ) ) == 2 :","if job_parameters [ ""common"" ] is None :",0.006767983,2.775775321,0.208888889
"def ConnectHandler(*args, **kwargs):<tab>""""""Factory function selects the proper class and creates object based on device_type.""""""<tab>device_type = kwargs[""device_type""]<tab>if device_type not in platforms:<tab><tab><IF-STMT><tab><tab><tab>msg_str = platforms_str<tab><tab>else:<tab><tab><tab>msg_str = telnet_platforms_str if ""telnet"" in device_type else platforms_str<tab><tab>raise ValueError(<tab><tab><tab>""Unsupported 'device_type' ""<tab><tab><tab>""currently supported platforms are: {}"".format(msg_str)<tab><tab>)<tab>ConnectionClass = ssh_dispatcher(device_type)<tab>return ConnectionClass(*args, **kwargs)",0,if device_type is None :,"if ""telnet"" in device_type :",0.036540249,20.16494558,0.36
"def get_next_parent_entities(item, pids):<tab>ret = list()<tab>for [parent, entity_id] in parents[item]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if parent in entities:<tab><tab><tab>ret.append(parent)<tab><tab>else:<tab><tab><tab>pids.append(entity_id)<tab><tab><tab>for p in get_next_parent_entities(parent, pids):<tab><tab><tab><tab>ret.append(p)<tab>return ret",1,if entity_id in pids :,if entity_id in pids :,0.75,100,1
"def load(self, data):<tab>ckey = None<tab>for key, val in _rx_cookie.findall(data):<tab><tab><IF-STMT><tab><tab><tab>if ckey:<tab><tab><tab><tab>self[ckey][key] = _unquote(val)<tab><tab>elif key[0] == ""$"":<tab><tab><tab># RFC2109: NAMEs that begin with $ are reserved for other uses<tab><tab><tab># and must not be used by applications.<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>self[key] = _unquote(val)<tab><tab><tab>ckey = key",0,if key . lower ( ) in _c_keys :,"if key . startswith ( ""$NAME"" ) :",0.072638087,15.14869427,0.484848485
def getIdentifier(self):<tab>start = self.index<tab>self.index += 1<tab>while self.index < self.length:<tab><tab>ch = self.ccode()<tab><tab><IF-STMT><tab><tab><tab># Blackslash (U+005C) marks Unicode escape sequence.<tab><tab><tab>self.index = start<tab><tab><tab>return self.getEscapedIdentifier()<tab><tab>if isIdentifierPart(ch):<tab><tab><tab>self.index += 1<tab><tab>else:<tab><tab><tab>break<tab>return self.source[start : self.index],0,if ch == 0x5C :,if isIdentifierPart ( ch ) :,0.032294704,10.68217516,0.4
"def test_floats_unequal_float(self):<tab>try:<tab><tab>self.assertEqual(<tab><tab><tab>np.array([[1, 2], [3, 4.5]], dtype=np.float32),<tab><tab><tab>np.array([[1, 2], [3, 5]], dtype=np.float32),<tab><tab>)<tab>except AssertionError as e:<tab><tab><IF-STMT><tab><tab><tab>raise self.failureException(""Float array mismatch error not raised."")",0,"if not str ( e ) . startswith ( ""Arrays not almost equal to 6 decimals"" ) :",if e . args [ 0 ] != errno . EINVAL :,0.007972196,2.549704254,0.128571429
"def _set_counts(self):<tab>self[""regions_count""] = len(self[""regions""])<tab>for _, key in self._children:<tab><tab># VPCs should not be counted as resources. They exist whether you have resources or not,<tab><tab># so counting them would make the report confusing.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self[key + ""_count""] = sum(<tab><tab><tab>[region[key + ""_count""] for region in self[""regions""].values()]<tab><tab>)",0,"if key == ""vpcs"" :","if key == ""resources"" :",0.394778655,59.46035575,1
"def total_form_count(self):<tab>""""""Returns the total number of forms in this FormSet.""""""<tab>if self.data or self.files:<tab><tab>return self.management_form.cleaned_data[TOTAL_FORM_COUNT]<tab>else:<tab><tab>initial_forms = self.initial_form_count()<tab><tab>total_forms = initial_forms + self.extra<tab><tab># Allow all existing related objects/inlines to be displayed,<tab><tab># but don't allow extra beyond max_num.<tab><tab>if initial_forms > self.max_num >= 0:<tab><tab><tab>total_forms = initial_forms<tab><tab><IF-STMT><tab><tab><tab>total_forms = self.max_num<tab>return total_forms",0,elif total_forms > self . max_num >= 0 :,elif self . max_num < total_forms :,0.071809234,37.77331187,0.730769231
"def mouse_down(self, evt):<tab>if self.parent.level:<tab><tab>toolNo = self.toolNumberUnderMouse(evt.pos)<tab><tab>if toolNo < 0 or toolNo > 8:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>self.selectTool(toolNo)<tab><tab>if evt.button == 3:<tab><tab><tab>self.showToolOptions(toolNo)",1,if evt . button == 1 :,if evt . button == 1 :,0.75,100,1
"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab>if instring:<tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return i<tab>return None",0,if not instring :,if instring :,0.096488528,1.00E-10,0.416666667
"def __getattr__(self, key):<tab>if key == key.upper():<tab><tab>if hasattr(self._django_settings, key):<tab><tab><tab>return getattr(self._django_settings, key)<tab><tab><IF-STMT><tab><tab><tab>return getattr(self._default_settings, key)<tab>raise AttributeError(<tab><tab>""%r object has no attribute %r"" % (self.__class__.__name__, key)<tab>)",0,"elif hasattr ( self . _default_settings , key ) :","if hasattr ( self . _default_settings , key ) :",0.440055868,91.21679091,0.666666667
"def replace_entities(match, entities=entities, encoding=encoding):<tab>ent = match.group()<tab>if ent[1] == ""#"":<tab><tab>return unescape_charref(ent[2:-1], encoding)<tab>repl = entities.get(ent)<tab>if repl is not None:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>repl = repl.decode(encoding)<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab>repl = ent<tab>else:<tab><tab>repl = ent<tab>return repl",0,"if hasattr ( repl , ""decode"" ) and encoding is not None :","if isinstance ( repl , bytes ) :",0.046167103,10.19067193,0.246753247
"def test_floor_div(self):<tab>""""""Util.number.floor_div""""""<tab>self.assertRaises(TypeError, number.floor_div, ""1"", 1)<tab>for a in range(-10, 10):<tab><tab>for b in range(-10, 10):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertRaises(ZeroDivisionError, number.floor_div, a, b)<tab><tab><tab>else:<tab><tab><tab><tab>self.assertEqual(<tab><tab><tab><tab><tab>(a, b, int(math.floor(float(a) / b))),<tab><tab><tab><tab><tab>(a, b, number.floor_div(a, b)),<tab><tab><tab><tab>)",0,if b == 0 :,if a == 0 :,0.394778655,53.72849659,0.6
"def get(self, method, **kws):<tab>resp = None<tab>if method in self.responses:<tab><tab>resp = self.responses[method].pop(0)<tab><tab><IF-STMT><tab><tab><tab>checks = resp[""validate""][""checks""]<tab><tab><tab>resp = resp[""validate""][""data""]<tab><tab><tab>for check in checks:<tab><tab><tab><tab>assert check in kws<tab><tab><tab><tab>expected_value = checks[check]<tab><tab><tab><tab>assert expected_value == kws[check]<tab>return resp",0,"if ""validate"" in resp :","if isinstance ( resp [ ""validate"" ] , dict ) :",0.026167489,13.67440668,0.488888889
def __add_changelisteners(self):<tab>NewPlayerSettlementHovered.subscribe(self.on_settlement_change)<tab>if self.__current_settlement is not None:<tab><tab>inventory = self.__current_settlement.get_component(StorageComponent).inventory<tab><tab><IF-STMT><tab><tab><tab>inventory.add_change_listener(self.refresh),0,if not inventory . has_change_listener ( self . refresh ) :,if inventory is not None :,0.013607149,2.561254039,0.25
"def __call__(self, target):<tab>if ""weights"" not in target.temp:<tab><tab>return True<tab>targets = target.temp[""weights""]<tab>for cname in target.children:<tab><tab><IF-STMT><tab><tab><tab>c = target.children[cname]<tab><tab><tab>deviation = abs((c.weight - targets[cname]) / targets[cname])<tab><tab><tab>if deviation > self.tolerance:<tab><tab><tab><tab>return True<tab>if ""cash"" in target.temp:<tab><tab>cash_deviation = abs(<tab><tab><tab>(target.capital - targets.value) / targets.value - target.temp[""cash""]<tab><tab>)<tab><tab>if cash_deviation > self.tolerance:<tab><tab><tab>return True<tab>return False",1,if cname in targets :,if cname in targets :,0.75,100,1
"def copyfileobj(src, dest, length=512):<tab>if hasattr(src, ""readinto""):<tab><tab>buf = bytearray(length)<tab><tab>while True:<tab><tab><tab>sz = src.readinto(buf)<tab><tab><tab>if not sz:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dest.write(buf)<tab><tab><tab>else:<tab><tab><tab><tab>b = memoryview(buf)[:sz]<tab><tab><tab><tab>dest.write(b)<tab>else:<tab><tab>while True:<tab><tab><tab>buf = src.read(length)<tab><tab><tab>if not buf:<tab><tab><tab><tab>break<tab><tab><tab>dest.write(buf)",0,if sz == length :,if len ( buf ) < sz :,0.02800146,7.267884212,0.314814815
"def test_api_history_restrict_cat(self):<tab>slot_sum = 0<tab># Loop over all categories in the fake history, plus the Default category<tab>cats = list(self.history_category_options)<tab>cats.extend(""*"")<tab>for cat in cats:<tab><tab>json = self._get_api_history({""category"": cat})<tab><tab>slot_sum += len(json[""history""][""slots""])<tab><tab># All results should be from the correct category<tab><tab>for slot in json[""history""][""slots""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert slot[""category""] == cat<tab># Total number of slots should match the sum of all category slots<tab>json = self._get_api_history({""limit"": self.history_size})<tab>slot_total = len(json[""history""][""slots""])<tab>assert slot_sum == slot_total",0,"if cat != ""*"" :","if slot [ ""type"" ] == ""category"" :",0.026407399,9.23843021,0.5
"def checker(self):<tab>while True:<tab><tab>try:<tab><tab><tab>ip = self.get_ip()<tab><tab>except Exception as e:<tab><tab><tab>xlog.info(""no ip left"")<tab><tab><tab>return<tab><tab>try:<tab><tab><tab>res = self.check_ip.check_ip(ip, sni=host, host=host)<tab><tab>except Exception as e:<tab><tab><tab>xlog.warn(""check fail:%s except:%r"", e)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>xlog.debug(""check fail:%s fail"", ip)<tab><tab><tab>continue<tab><tab>self.write_ip(ip, res.domain, res.handshake_time)",0,if not res or not res . ok :,if res is None :,0.141838046,6.316906128,0.196428571
"def create_row_processor(<tab>self, context, path, loadopt, mapper, result, adapter, populators):<tab># look through list of columns represented here<tab># to see which, if any, is present in the row.<tab>for col in self.columns:<tab><tab>if adapter:<tab><tab><tab>col = adapter.columns[col]<tab><tab>getter = result._getter(col, False)<tab><tab><IF-STMT><tab><tab><tab>populators[""quick""].append((self.key, getter))<tab><tab><tab>break<tab>else:<tab><tab>populators[""expire""].append((self.key, True))",0,if getter :,if getter is not None :,0.090364769,1.00E-10,0.4
"def indices(dimensions, dtype=int32, sparse=False):<tab>dimensions = tuple(dimensions)<tab>N = len(dimensions)<tab>output = []<tab>s = dimensions<tab>for i, dim in enumerate(dimensions):<tab><tab>idx = lax.iota(dtype, dim)<tab><tab><IF-STMT><tab><tab><tab>s = (1,) * i + (dim,) + (1,) * (N - i - 1)<tab><tab>output.append(lax.broadcast_in_dim(idx, s, (i,)))<tab>if sparse:<tab><tab>return tuple(output)<tab>return stack(output, 0) if output else array([], dtype=dtype)",0,if sparse :,if i < N - 1 :,0.045790811,1.00E-10,0.291666667
"def load_cases(full_path):<tab>all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict)<tab>for test_data in all_test_data:<tab><tab>given = test_data[""given""]<tab><tab>for case in test_data[""cases""]:<tab><tab><tab>if ""result"" in case:<tab><tab><tab><tab>test_type = ""result""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>test_type = ""error""<tab><tab><tab>elif ""bench"" in case:<tab><tab><tab><tab>test_type = ""bench""<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""Unknown test type: %s"" % json.dumps(case))<tab><tab><tab>yield (given, test_type, case)",1,"elif ""error"" in case :","elif ""error"" in case :",0.75,100,1
"def _resolve_task_id(cls, task_id, log=None):<tab>if not task_id:<tab><tab>task_id = cls.normalize_id(get_remote_task_id())<tab><tab><IF-STMT><tab><tab><tab>log = log or get_logger(""task"")<tab><tab><tab>log.info(""Using task ID from env %s=%s"" % (TASK_ID_ENV_VAR[0], task_id))<tab>return task_id",1,if task_id :,if task_id :,0.531170663,1.00E-10,1
"def _build_contr_port_map(self, fabric_connected_ports, ports_info):<tab>contr_port_map = {}<tab>for port in fabric_connected_ports:<tab><tab>contr = ports_info[port][""contr""]<tab><tab><IF-STMT><tab><tab><tab>contr_port_map[contr] = []<tab><tab>contr_port_map[contr].append(port)<tab>LOG.debug(""Controller port map: %s."", contr_port_map)<tab>return contr_port_map",0,if not contr_port_map . get ( contr ) :,if contr not in contr_port_map :,0.018728518,33.70679495,0.333333333
"def confirm(question):<tab>""""""Prompts a given question and handles user input.""""""<tab>valid = {""yes"": True, ""y"": True, ""ye"": True, ""no"": False, ""n"": False, """": True}<tab>prompt = "" [Y/n] ""<tab>while True:<tab><tab>print(BOLD + CYAN + question + prompt + END)<tab><tab>choice = input().lower()<tab><tab><IF-STMT><tab><tab><tab>return valid[choice]<tab><tab>print(""Please respond with 'yes' or 'no' (or 'y' or 'n').\n"")",1,if choice in valid :,if choice in valid :,0.75,100,1
"def __parse_query(self, model, iter_, data):<tab>f, b = self.__filter, self.__bg_filter<tab>if f is None and b is None:<tab><tab>return True<tab>else:<tab><tab>album = model.get_album(iter_)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif b is None:<tab><tab><tab>return f(album)<tab><tab>elif f is None:<tab><tab><tab>return b(album)<tab><tab>else:<tab><tab><tab>return b(album) and f(album)",0,if album is None :,if f is None :,0.144778655,42.72870064,0.666666667
def get_SV(self):<tab>result = []<tab>for sparse_sv in self.SV[: self.l]:<tab><tab>row = dict()<tab><tab>i = 0<tab><tab>while True:<tab><tab><tab>row[sparse_sv[i].index] = sparse_sv[i].value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>i += 1<tab><tab>result.append(row)<tab>return result,0,if sparse_sv [ i ] . index == - 1 :,if row [ sparse_sv [ i ] . index ] == 0 :,0.318229479,50.67309893,0.277310924
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_hostname(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def getFileIdFromAlternateLink(altLink):<tab>loc = altLink.find(""/d/"")<tab>if loc > 0:<tab><tab>fileId = altLink[loc + 3 :]<tab><tab>loc = fileId.find(""/"")<tab><tab><IF-STMT><tab><tab><tab>return fileId[:loc]<tab>else:<tab><tab>loc = altLink.find(""/folderview?id="")<tab><tab>if loc > 0:<tab><tab><tab>fileId = altLink[loc + 15 :]<tab><tab><tab>loc = fileId.find(""&"")<tab><tab><tab>if loc != -1:<tab><tab><tab><tab>return fileId[:loc]<tab>controlflow.system_error_exit(<tab><tab>2, f""{altLink} is not a valid Drive File alternateLink""<tab>)",1,if loc != - 1 :,if loc != - 1 :,0.75,100,1
"def show_unknown_key_warning(name: Union[str, object], others: dict):<tab>if ""type"" in others:<tab><tab>others.pop(""type"")<tab>if len(others) > 0:<tab><tab>keys = "", "".join(others.keys())<tab><tab>logger = logging.getLogger(__name__)<tab><tab><IF-STMT><tab><tab><tab>name = name.__class__.__name__<tab><tab>logger.debug(<tab><tab><tab>f""!!! {name}'s constructor args ({keys}) were ignored.""<tab><tab><tab>f""If they should be supported by this library, report this issue to the project :bow: ""<tab><tab><tab>f""https://github.com/slackapi/python-slackclient/issues""<tab><tab>)",0,"if isinstance ( name , object ) :",if name is not None :,0.019830745,7.654112967,0.232142857
"def wrapper(*args, **kwargs):<tab>with capture_logs() as logs:<tab><tab>try:<tab><tab><tab>function(*args, **kwargs)<tab><tab>except Exception:  # pragma: no cover<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""%i errors logged:"" % len(logs), file=sys.stderr)<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>if logs:  # pragma: no cover<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab><tab>raise AssertionError(""%i errors logged"" % len(logs))",1,if logs :,if logs :,0.531170663,1.00E-10,1
"def _init_weight(self):<tab>for m in self.modules():<tab><tab>if isinstance(m, nn.Conv2d):<tab><tab><tab>n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels<tab><tab><tab>m.weight.data.normal_(0, math.sqrt(2.0 / n))<tab><tab><IF-STMT><tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()",0,"elif isinstance ( m , SyncBatchNorm ) :","elif isinstance ( m , nn . Linear ) :",0.36160114,45.18010018,0.558441558
"def cleanup(self):<tab># some OBO ontologies have extra ""."" at the end of synonyms<tab>for i, s in enumerate(self.synonyms):<tab><tab>if s[-1] == ""."":<tab><tab><tab># only remove period if preceded by ""normal word""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c = s[:-1]<tab><tab><tab><tab>print >>sys.stderr, ""Note: cleanup: '%s' -> '%s'"" % (s, c)<tab><tab><tab><tab>self.synonyms[i] = c",0,"if re . search ( r""\b[a-z]{2,}\.$"" , s ) :","if len ( s ) > 1 and s [ - 1 ] == ""normal word"" :",0.022587258,4.566179484,0.233695652
"def for_module(cls, modname: str) -> ""ModuleAnalyzer"":<tab>if (""module"", modname) in cls.cache:<tab><tab>entry = cls.cache[""module"", modname]<tab><tab><IF-STMT><tab><tab><tab>raise entry<tab><tab>return entry<tab>try:<tab><tab>filename, source = cls.get_module_source(modname)<tab><tab>if source is not None:<tab><tab><tab>obj = cls.for_string(source, modname, filename or ""<string>"")<tab><tab>elif filename is not None:<tab><tab><tab>obj = cls.for_file(filename, modname)<tab>except PycodeError as err:<tab><tab>cls.cache[""module"", modname] = err<tab><tab>raise<tab>cls.cache[""module"", modname] = obj<tab>return obj",0,"if isinstance ( entry , PycodeError ) :",if entry is not None :,0.019830745,7.654112967,0.232142857
"def GetDisplayNameOf(self, pidl, flags):<tab>item = pidl_to_item(pidl)<tab>if flags & shellcon.SHGDN_FORPARSING:<tab><tab>if flags & shellcon.SHGDN_INFOLDER:<tab><tab><tab>return item[""name""]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEEDITING<tab><tab><tab>else:<tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEPARSING<tab><tab><tab>parent = shell.SHGetNameFromIDList(self.pidl, sigdn)<tab><tab><tab>return parent + ""\\"" + item[""name""]<tab>else:<tab><tab>return item[""name""]",0,if flags & shellcon . SHGDN_FORADDRESSBAR :,if flags & shellcon . SHGDN_EDITING :,0.574113272,75.06238538,1
"def transact_reraise(exc_class, exceptions):<tab>cls, exc, tb = exceptions[0]<tab>new_exc = None<tab>try:<tab><tab>msg = "" "".join(tostring(arg) for arg in exc.args)<tab><tab><IF-STMT><tab><tab><tab>msg = ""%s: %s"" % (cls.__name__, msg)<tab><tab>new_exc = exc_class(msg, exceptions)<tab><tab>new_exc.__cause__ = None<tab><tab>reraise(exc_class, new_exc, tb)<tab>finally:<tab><tab>del exceptions, exc, tb, new_exc",0,"if not issubclass ( cls , TransactionError ) :","if isinstance ( exc_class , Exception ) :",0.033138934,10.55267032,0.225
"def add_share(self, share):<tab>for filename, (share_hashes, verified_hashes) in self.known.iteritems():<tab><tab><IF-STMT><tab><tab><tab>break<tab>else:<tab><tab>filename = self._add_line(<tab><tab><tab>""%i %s"" % (5, share_type.pack(share.as_share()).encode(""hex""))<tab><tab>)<tab><tab>share_hashes, verified_hashes = self.known.setdefault(filename, (set(), set()))<tab><tab>share_hashes.add(share.hash)<tab>share_hashes, verified_hashes = self.known_desired.setdefault(<tab><tab>filename, (set(), set())<tab>)<tab>share_hashes.add(share.hash)",0,if share . hash in share_hashes :,if not share_hashes or not verified_hashes :,0.072864977,20.86130724,0.285714286
"def get_resolved_modules(self) -> Dict[str, ResolvedModule]:<tab>""""""Get a {name: ResolvedModule} map of all resolved modules.""""""<tab>resolved_modules = {}<tab>for name, mod in self._modules.items():<tab><tab><IF-STMT><tab><tab><tab>resolved_modules[name] = ResolvedModule(<tab><tab><tab><tab>mod.module_name, mod.filename, mod.ast<tab><tab><tab>)<tab>return resolved_modules",0,if not mod . has_unresolved_pointers :,"if isinstance ( mod , Module ) :",0.023749772,5.660233916,0.481481481
"def stripe(request):<tab>amount = 1<tab>response = None<tab>if request.method == ""POST"":<tab><tab>form = CreditCardForm(request.POST)<tab><tab><IF-STMT><tab><tab><tab>data = form.cleaned_data<tab><tab><tab>credit_card = CreditCard(**data)<tab><tab><tab>merchant = get_gateway(""stripe"")<tab><tab><tab>response = merchant.purchase(amount, credit_card)<tab>else:<tab><tab>form = CreditCardForm(initial=GATEWAY_INITIAL[""stripe""])<tab>return render(<tab><tab>request,<tab><tab>""app/index.html"",<tab><tab>{<tab><tab><tab>""form"": form,<tab><tab><tab>""amount"": amount,<tab><tab><tab>""response"": response,<tab><tab><tab>""title"": ""Stripe Payment"",<tab><tab>},<tab>)",1,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,100,1
"def get(self, url):<tab>now = time.time()<tab>for entry in self.repos:<tab><tab><IF-STMT><tab><tab><tab>if now < entry.timestamp + self.timeout:<tab><tab><tab><tab># print ""returning immediate Etrny"", entry<tab><tab><tab><tab>return entry.url, entry.rev<tab><tab><tab>return entry.url, -1<tab>return url, -1",0,if url . startswith ( entry . url ) :,if entry . url == url :,0.364100353,19.03868164,0.381818182
"def cleanup(self):<tab># some OBO ontologies have extra ""."" at the end of synonyms<tab>for i, s in enumerate(self.synonyms):<tab><tab><IF-STMT><tab><tab><tab># only remove period if preceded by ""normal word""<tab><tab><tab>if re.search(r""\b[a-z]{2,}\.$"", s):<tab><tab><tab><tab>c = s[:-1]<tab><tab><tab><tab>print >>sys.stderr, ""Note: cleanup: '%s' -> '%s'"" % (s, c)<tab><tab><tab><tab>self.synonyms[i] = c",0,"if s [ - 1 ] == ""."" :","if s . endswith ( ""."" ) :",0.031766029,16.83038679,0.6
"def __get_field(cls, name):<tab>try:<tab><tab>return cls._doc_type.mapping[name]<tab>except KeyError:<tab><tab># fallback to fields on the Index<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return cls._index._mapping[name]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass",0,"if hasattr ( cls , ""_index"" ) and cls . _index . _mapping :",if name in cls . _index :,0.038926375,9.673717311,0.278195489
"def command_is_enabled(self, item, focus):<tab>cmd = item.command<tab>if cmd:<tab><tab>enabler_name = cmd + ""_enabled""<tab><tab>handler = focus<tab><tab>while handler:<tab><tab><tab>enabler = getattr(handler, enabler_name, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return enabler()<tab><tab><tab>handler = handler.next_handler()<tab>return True",1,if enabler :,if enabler :,0.531170663,1.00E-10,1
"def __getitem__(self, key):<tab>value = WeakValueDictionary.__getitem__(self, key)<tab># check boundaries to minimiza duplicate references<tab>while len(self.queue) > 0 and self.queue[0][0] == key:<tab><tab># item at left end of queue pop it since it'll be appended<tab><tab># to right<tab><tab>self.queue.popleft()<tab># only append if item is not at right end of queue<tab>if not (len(self.queue) and self.queue[-1][0] == key):<tab><tab><IF-STMT><tab><tab><tab>self.cull()<tab><tab>self.queue.append((key, value))<tab>return value",0,if len ( self ) >= self . maxsize or len ( self . queue ) >= self . maxsize * self . peakmult :,if self . culling :,0.047743231,0.311925923,0.189542484
"def post_init(self):<tab>if os.getenv(""SCRCPY_LDD""):<tab><tab><IF-STMT><tab><tab><tab>os.environ[""LD_LIBRARY_PATH""] += os.getenv(""SCRCPY_LDD"")<tab><tab>else:<tab><tab><tab>os.environ[""LD_LIBRARY_PATH""] = os.getenv(""SCRCPY_LDD"")",0,"if os . getenv ( ""LD_LIBRARY_PATH"" ) :","if os . environ [ ""LD_LIBRARY_PATH"" ] :",0.079919566,54.45178846,0.6
"def get_summary_output(event: events.Finished) -> Tuple[str, str, int]:<tab>parts = get_summary_message_parts(event.results)<tab>if not parts:<tab><tab>message = ""Empty test suite""<tab><tab>color = ""yellow""<tab><tab>status_code = 0<tab>else:<tab><tab>message = f'{"", "".join(parts)} in {event.running_time:.2f}s'<tab><tab><IF-STMT><tab><tab><tab>color = ""red""<tab><tab><tab>status_code = 1<tab><tab>else:<tab><tab><tab>color = ""green""<tab><tab><tab>status_code = 0<tab>return message, color, status_code",0,if event . results . has_failures or event . results . has_errors :,if message :,0.006889958,1.00E-10,0.296296296
"def header_check(p_obj):<tab>""""""Special disposition for the HTML <head> and <body> elements...""""""<tab>if state.options.host_language in [<tab><tab>HostLanguage.xhtml,<tab><tab>HostLanguage.html5,<tab><tab>HostLanguage.xhtml5,<tab>]:<tab><tab><IF-STMT><tab><tab><tab>if not has_one_of_attributes(node, ""about"", ""resource"", ""src"", ""href""):<tab><tab><tab><tab>return p_obj<tab>else:<tab><tab>return None",0,"if node . nodeName == ""head"" or node . nodeName == ""body"" :","if hasattr ( node , ""about"" ) and hasattr ( node , ""src"" ) :",0.22605984,3.404699216,0.285714286
"def get_track_id_from_json(item):<tab>""""""Try to extract video Id from various response types""""""<tab>fields = [<tab><tab>""contentDetails/videoId"",<tab><tab>""snippet/resourceId/videoId"",<tab><tab>""id/videoId"",<tab><tab>""id"",<tab>]<tab>for field in fields:<tab><tab>node = item<tab><tab>for p in field.split(""/""):<tab><tab><tab>if node and isinstance(node, dict):<tab><tab><tab><tab>node = node.get(p)<tab><tab><IF-STMT><tab><tab><tab>return node<tab>return """"",1,if node :,if node :,0.531170663,1.00E-10,1
"def __init__(self, layers):<tab>super(Add, self).__init__()<tab>self.layer_names = []<tab>self.layers = layers<tab>for i, layer in enumerate(self.layers):<tab><tab><IF-STMT><tab><tab><tab>if i == 0:<tab><tab><tab><tab>layer.parent = ""input""<tab><tab><tab>else:<tab><tab><tab><tab>layer.parent = layers[i - 1].name<tab><tab>if hasattr(layer, ""name""):<tab><tab><tab>name = layer.name<tab><tab>else:<tab><tab><tab>name = layer.__class__.__name__ + str(i)<tab><tab><tab>layer.name = name<tab><tab>self.layer_names.append(name)",0,if layer . parent is None :,"if hasattr ( layer , ""parent"" ) :",0.021135836,5.93420261,0.25
"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab>if not self.pid:<tab><tab><tab>pid = read_pid_file(""/var/run/dnsmasq.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab><IF-STMT><tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")",0,"if not kill ( pid , ""dnsmasq"" ) :",if pid == self . pid :,0.017062029,4.995138898,0.444444444
"def findStyleName(element, style):<tab>oldStyle = DOM.getAttribute(element, ""className"")<tab>if oldStyle is None:<tab><tab>return -1<tab>idx = oldStyle.find(style)<tab># Calculate matching index<tab>lastPos = len(oldStyle)<tab>while idx != -1:<tab><tab><IF-STMT><tab><tab><tab>last = idx + len(style)<tab><tab><tab>if (last == lastPos) or ((last < lastPos) and (oldStyle[last] == "" "")):<tab><tab><tab><tab>break<tab><tab>idx = oldStyle.find(style, idx + 1)<tab>return idx",0,"if idx == 0 or ( oldStyle [ idx - 1 ] == "" "" ) :","if oldStyle [ idx ] == "" "" :",0.104563483,22.58591251,0.261904762
"def __str__(self):<tab>path = super(XPathExpr, self).__str__()<tab>if self.textnode:<tab><tab>if path == ""*"":<tab><tab><tab>path = ""text()""<tab><tab>el<IF-STMT><tab><tab><tab>path = path[:-3] + ""text()""<tab><tab>else:<tab><tab><tab>path += ""/text()""<tab>if self.attribute is not None:<tab><tab>if path.endswith(""::*/*""):<tab><tab><tab>path = path[:-2]<tab><tab>path += ""/@%s"" % self.attribute<tab>return path",0,"if path . endswith ( ""::*/*"" ) :","if path . endswith ( "".*"" ) :",0.549040681,53.41952994,1
"def insert_after(self, sibling, row=None):<tab>if row is not None:<tab><tab>value = self._get_marshalable(row[0])<tab><tab><IF-STMT><tab><tab><tab>position = 0<tab><tab>else:<tab><tab><tab>position = self.get_path(sibling)[0] + 1<tab><tab>return self.insert_with_valuesv(position, [0], [value])<tab>assert not self.ATOMIC<tab>return super(ObjectStore, self).insert_after(sibling, row)",1,if sibling is None :,if sibling is None :,0.75,100,1
"def source_synopsis(file):<tab>line = file.readline()<tab>while line[:1] == ""#"" or not strip(line):<tab><tab>line = file.readline()<tab><tab>if not line:<tab><tab><tab>break<tab>line = strip(line)<tab>if line[:4] == 'r""""""':<tab><tab>line = line[1:]<tab>if line[:3] == '""""""':<tab><tab>line = line[3:]<tab><tab><IF-STMT><tab><tab><tab>line = line[:-1]<tab><tab>while not strip(line):<tab><tab><tab>line = file.readline()<tab><tab><tab>if not line:<tab><tab><tab><tab>break<tab><tab>result = strip(split(line, '""""""')[0])<tab>else:<tab><tab>result = None<tab>return result",0,"if line [ - 1 : ] == ""\\"" :","if line [ - 1 ] == ""\\"" :",0.374728396,78.81929718,1
"def _handle_rate_limit(<tab>self, exception: RedditAPIException) -> Optional[Union[int, float]]:<tab>for item in exception.items:<tab><tab>if item.error_type == ""RATELIMIT"":<tab><tab><tab>amount_search = self._ratelimit_regex.search(item.message)<tab><tab><tab>if not amount_search:<tab><tab><tab><tab>break<tab><tab><tab>seconds = int(amount_search.group(1))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>seconds *= 60<tab><tab><tab>if seconds <= int(self.config.ratelimit_seconds):<tab><tab><tab><tab>sleep_seconds = seconds + min(seconds / 10, 1)<tab><tab><tab><tab>return sleep_seconds<tab>return None",0,"if ""minute"" in amount_search . group ( 2 ) :",if seconds > int ( self . config . ratelimit_minutes ) :,0.026263798,7.474875887,0.214814815
"def get_html_help_exe():<tab>""""""Return HTML Help Workshop executable path (Windows only)""""""<tab>if os.name == ""nt"":<tab><tab>hhc_base = r""C:\Program Files%s\HTML Help Workshop\hhc.exe""<tab><tab>for hhc_exe in (hhc_base % """", hhc_base % "" (x86)""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return hhc_exe<tab><tab>else:<tab><tab><tab>return",0,if osp . isfile ( hhc_exe ) :,if os . path . exists ( hhc_exe ) :,0.233382505,44.833867,0.274725275
"def get_net_bridge_owner(name_ignore, sysfspath):<tab># Now magic to determine if the device is part of a bridge<tab>brportpath = os.path.join(sysfspath, ""brport"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>brlinkpath = os.path.join(brportpath, ""bridge"")<tab><tab><tab>dest = os.readlink(brlinkpath)<tab><tab><tab>(ignore, bridge) = os.path.split(dest)<tab><tab><tab>return bridge<tab>except:<tab><tab>logging.exception(""Unable to determine if device is shared"")<tab>return None",0,if os . path . exists ( brportpath ) :,if name_ignore :,0.010867398,1.00E-10,0.285714286
"def get_timestamp(self):<tab>if not self._timedelta:<tab><tab>url = ""https://%s%s/auth/time"" % (API_HOST, API_ROOT)<tab><tab>response = get_response_object(url=url, method=""GET"", headers={})<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Failed to get current time from Ovh API"")<tab><tab>timestamp = int(response.body)<tab><tab>self._timedelta = timestamp - int(time.time())<tab>return int(time.time()) + self._timedelta",0,if not response or not response . body :,if response . status_code != 200 :,0.031961012,9.980099404,0.214285714
"def render(self, context):<tab>for var in self.vars:<tab><tab>value = var.resolve(context, True)<tab><tab><IF-STMT><tab><tab><tab>first = render_value_in_context(value, context)<tab><tab><tab>if self.asvar:<tab><tab><tab><tab>context[self.asvar] = first<tab><tab><tab><tab>return """"<tab><tab><tab>return first<tab>return """"",0,if value :,if value is not None :,0.090364769,1.00E-10,0.4
"def test_loc_is_stochastic_parameter(self):<tab>param = iap.Laplace(iap.Choice([-100, 100]), 1)<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>samples = param.draw_samples((100,))<tab><tab>exp = np.mean(samples)<tab><tab>if -100 - 10 < exp < -100 + 10:<tab><tab><tab>seen[0] += 1<tab><tab><IF-STMT><tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert 500 - 100 < seen[0] < 500 + 100<tab>assert 500 - 100 < seen[1] < 500 + 100",1,elif 100 - 10 < exp < 100 + 10 :,elif 100 - 10 < exp < 100 + 10 :,0.75,100,1
"def get_data(self, path, prefix=""""):<tab>item = self.store[path]<tab>path = ""{}/{}"".format(prefix, path)<tab>keys = [i for i in item.keys()]<tab>data = {""path"": path}<tab># print(path)<tab>for k in keys:<tab><tab>if not isinstance(item[k], h5py.Group):<tab><tab><tab>dataset = np.array(item[k].value)<tab><tab><tab>if type(dataset) is np.ndarray:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if type(dataset[0]) is np.bytes_:<tab><tab><tab><tab><tab><tab>dataset = [a.decode(""ascii"") for a in dataset]<tab><tab><tab>data.update({k: dataset})<tab>return data",0,if dataset . size != 0 :,if len ( dataset ) == 1 :,0.021135836,6.74255593,0.285714286
def __del__(self):<tab>try:<tab><tab>if self._mpz_p is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_gmp.mpz_clear(self._mpz_p)<tab><tab>self._mpz_p = None<tab>except AttributeError:<tab><tab>pass,0,if self . _initialized :,if _gmp . mpz_exists ( self . _mpz_p ) :,0.047950876,10.34360301,1
"def load(self, vocab_file):<tab>self.__term2id = {}<tab>self.__id2term = {}<tab>with open(vocab_file, ""r"", encoding=""utf-8"") as fin:<tab><tab>for line in fin.readlines():<tab><tab><tab>fields = line.strip().split(""\t"")<tab><tab><tab>assert len(fields) == 5, ""Vocabulary file [%s] format error!"" % (vocab_file)<tab><tab><tab>term = fields[1]<tab><tab><tab>id_ = int(fields[2])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.error(""Duplicate word [%s] in vocab file!"" % (term))<tab><tab><tab><tab>continue<tab><tab><tab>self.__term2id[term] = id_<tab><tab><tab>self.__id2term[id_] = term",0,if term in self . __term2id :,if id_ in self . __term2id :,0.574113272,66.06328636,0.371428571
"def break_next_call(symbol_regex=None):<tab>while pwndbg.proc.alive:<tab><tab>ins = break_next_branch()<tab><tab>if not ins:<tab><tab><tab>break<tab><tab># continue if not a call<tab><tab>if capstone.CS_GRP_CALL not in ins.groups:<tab><tab><tab>continue<tab><tab># return call if we don't search for a symbol<tab><tab><IF-STMT><tab><tab><tab>return ins<tab><tab># return call if we match target address<tab><tab>if ins.target_const and re.match(""%s$"" % symbol_regex, hex(ins.target)):<tab><tab><tab>return ins<tab><tab># return call if we match symbol name<tab><tab>if ins.symbol and re.match(""%s$"" % symbol_regex, ins.symbol):<tab><tab><tab>return ins",0,if not symbol_regex :,if symbol_regex is None :,0.045150551,27.77619034,0.36
"def test_url_valid_set():<tab>for line in URL_VALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments or empty lines<tab><tab>match = COMMENT.match(line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>mbox = address.parse(line, strict=True)<tab><tab>assert_not_equal(mbox, None)",0,if match :,if not match :,0.113486237,1.00E-10,0.416666667
"def _clean_fields(self, fields, reverse=False):<tab>if not fields:<tab><tab>fields = list(self.default_fields)<tab>if reverse:<tab><tab>for field in [""up.total"", ""down.total"", ""down.rate""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fields[fields.index(field)] = field.replace(""."", ""_"")<tab><tab>return fields<tab>for required_field in self.required_fields:<tab><tab>if required_field not in fields:<tab><tab><tab>fields.insert(0, required_field)<tab>for field in [""up_total"", ""down_total"", ""down_rate""]:<tab><tab>if field in fields:<tab><tab><tab>fields[fields.index(field)] = field.replace(""_"", ""."")<tab>return fields",1,if field in fields :,if field in fields :,0.75,100,1
"def client_cert_key_path(self):<tab>cache_folder = os.path.dirname(self.filename)<tab>try:<tab><tab>path = self.get_item(""general.client_cert_key_path"")<tab>except ConanException:<tab><tab>path = os.path.join(cache_folder, ""client.key"")<tab>else:<tab><tab># For explicit cacert files, the file should already exist<tab><tab>path = os.path.join(cache_folder, path)<tab><tab><IF-STMT><tab><tab><tab>raise ConanException(<tab><tab><tab><tab>""Configured file for 'client_cert_key_path'""<tab><tab><tab><tab>"" doesn't exists: '{}'"".format(path)<tab><tab><tab>)<tab>return os.path.normpath(path)",1,if not os . path . exists ( path ) :,if not os . path . exists ( path ) :,1,100,1
"def handler_click_link(self, link):<tab>if link.startswith(""[[""):<tab><tab>link = link[2:-2]<tab><tab>self.notify_observers(""click:notelink"", link)<tab>else:<tab><tab>if platform.system().lower() == ""windows"":<tab><tab><tab>os.startfile(link)<tab><tab><IF-STMT><tab><tab><tab>subprocess.call((""open"", link))<tab><tab>else:<tab><tab><tab>subprocess.call((""xdg-open"", link))",1,"elif platform . system ( ) . lower ( ) == ""darwin"" :","elif platform . system ( ) . lower ( ) == ""darwin"" :",0.75,100,1
"def __setitem__(self, key, value):<tab>if not isinstance(value, PseudoNamespace):<tab><tab>tuple_converted = False<tab><tab>if isinstance(value, dict):<tab><tab><tab>value = PseudoNamespace(value)<tab><tab>elif isinstance(value, tuple):<tab><tab><tab>value = list(value)<tab><tab><tab>tuple_converted = True<tab><tab>if isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, dict) and not isinstance(item, PseudoNamespace):<tab><tab><tab><tab><tab>value[i] = PseudoNamespace(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = tuple(value)<tab>super(PseudoNamespace, self).__setitem__(key, value)",1,if tuple_converted :,if tuple_converted :,0.531170663,1.00E-10,1
"def slots_for_entities(self, entities):<tab>if self.store_entities_as_slots:<tab><tab>slot_events = []<tab><tab>for s in self.slots:<tab><tab><tab>if s.auto_fill:<tab><tab><tab><tab>matching_entities = [<tab><tab><tab><tab><tab>e[""value""] for e in entities if e[""entity""] == s.name<tab><tab><tab><tab>]<tab><tab><tab><tab>if matching_entities:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities))<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities[-1]))<tab><tab>return slot_events<tab>else:<tab><tab>return []",0,"if s . type_name == ""list"" :",if len ( matching_entities ) == 1 :,0.021135836,8.606119901,0.381818182
"def stream_read_bz2(ifh, ofh):<tab>""""""Uncompress bz2 compressed *ifh* into *ofh*""""""<tab>decompressor = bz2.BZ2Decompressor()<tab>while True:<tab><tab>buf = ifh.read(BUFSIZE)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>buf = decompressor.decompress(buf)<tab><tab>if buf:<tab><tab><tab>ofh.write(buf)<tab>if decompressor.unused_data or ifh.read(1) != b"""":<tab><tab>raise CorruptedObjectError(""Data after end of bz2 stream"")",1,if not buf :,if not buf :,0.75,100,1
"def get_for_vars(self):<tab>tok = self.tokenizer.get_next_token()<tab>if tok[""style""] == ScintillaConstants.SCE_PL_WORD and tok[""text""] in (<tab><tab>""my"",<tab><tab>""state"",<tab>):<tab><tab>tlineNo = tok[""start_line""]<tab><tab>tok = self.tokenizer.get_next_token()<tab><tab><IF-STMT><tab><tab><tab># Don't do any more processing, as we're probably looking<tab><tab><tab># at an open-paren.<tab><tab><tab>self.moduleInfo.doSetVar(name=tok[""text""], line=tlineNo, scope=""my"")",0,if self . classifier . is_variable ( tok ) :,"if tok [ ""style"" ] == ScintillaConstants . SCE_PL_PAREN :",0.015619661,3.419798031,0.320512821
"def generate_dem_tiles(geotiff, output_dir, max_concurrency):<tab>try:<tab><tab>colored_dem, hillshade_dem, colored_hillshade_dem = generate_colored_hillshade(<tab><tab><tab>geotiff<tab><tab>)<tab><tab>generate_tiles(colored_hillshade_dem, output_dir, max_concurrency)<tab><tab># Cleanup<tab><tab>for f in [colored_dem, hillshade_dem, colored_hillshade_dem]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>os.remove(f)<tab>except Exception as e:<tab><tab>log.ODM_WARNING(""Cannot generate DEM tiles: %s"" % str(e))",1,if os . path . isfile ( f ) :,if os . path . isfile ( f ) :,0.75,100,1
"def cluster(spawnpoints, radius, time_threshold):<tab>clusters = []<tab>diameter = 2 * radius<tab>for p in spawnpoints:<tab><tab><IF-STMT><tab><tab><tab>clusters.append(Spawncluster(p))<tab><tab>else:<tab><tab><tab>c = min(clusters, key=lambda x: cost(p, x, time_threshold))<tab><tab><tab>if check_cluster(p, c, radius, time_threshold):<tab><tab><tab><tab>c.append(p)<tab><tab><tab>else:<tab><tab><tab><tab>c = Spawncluster(p)<tab><tab><tab><tab>clusters.append(c)<tab>return clusters",0,if len ( clusters ) == 0 :,"if check_cluster ( p , diameter , time_threshold ) :",0.018014535,4.016138436,0.274725275
"def pop(self):<tab>if self._pending_removals:<tab><tab>self._commit_removals()<tab>while True:<tab><tab>try:<tab><tab><tab>itemref = self.data.pop()<tab><tab>except KeyError:<tab><tab><tab>raise KeyError(""pop from empty WeakSet"") from None<tab><tab>item = itemref()<tab><tab><IF-STMT><tab><tab><tab>return item",1,if item is not None :,if item is not None :,0.75,100,1
"def map_depends(self, dep):<tab>if (<tab><tab>dep.endswith((""-native"", ""-native-runtime""))<tab><tab>or (""nativesdk-"" in dep)<tab><tab>or (""cross-canadian"" in dep)<tab><tab>or (""-crosssdk-"" in dep)<tab>):<tab><tab>return dep<tab>else:<tab><tab># Do not extend for that already have multilib prefix<tab><tab>var = self.d.getVar(""MULTILIB_VARIANTS"")<tab><tab>if var:<tab><tab><tab>var = var.split()<tab><tab><tab>for v in var:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return dep<tab><tab>return self.extend_name(dep)",0,if dep . startswith ( v ) :,"if self . map_depends ( v , dep ) :",0.042314975,11.01679839,0.333333333
"def normalize_stroke(stroke):<tab>letters = set(stroke)<tab>if letters & _NUMBERS:<tab><tab>if system.NUMBER_KEY in letters:<tab><tab><tab>stroke = stroke.replace(system.NUMBER_KEY, """")<tab><tab># Insert dash when dealing with 'explicit' numbers<tab><tab>m = _IMPLICIT_NUMBER_RX.search(stroke)<tab><tab>if m is not None:<tab><tab><tab>start = m.start(2)<tab><tab><tab>return stroke[:start] + ""-"" + stroke[start:]<tab>if ""-"" in letters:<tab><tab><IF-STMT><tab><tab><tab>stroke = stroke[:-1]<tab><tab>elif letters & system.IMPLICIT_HYPHENS:<tab><tab><tab>stroke = stroke.replace(""-"", """")<tab>return stroke",0,"if stroke . endswith ( ""-"" ) :","if stroke [ - 1 ] == ""-"" :",0.03384241,16.59038701,0.6
"def _get_py_flags(self):<tab>res = dict(self.flags)<tab>cflags = res.pop(""cflags"", """")<tab>for fl in cflags.split(""|""):<tab><tab>fl = fl.strip()<tab><tab>if fl == ""GA_USE_DOUBLE"":<tab><tab><tab>res[""have_double""] = True<tab><tab>if fl == ""GA_USE_SMALL"":<tab><tab><tab>res[""have_small""] = True<tab><tab><IF-STMT><tab><tab><tab>res[""have_complex""] = True<tab><tab>if fl == ""GA_USE_HALF"":<tab><tab><tab>res[""have_half""] = True<tab>return res",0,"if fl == ""GA_USE_COMPLEX"" :","if fl == ""GA_USE_complex"" :",0.394778655,76.91605673,1
"def populate(self):<tab>classes = self.applet.Plugins.get_classes()<tab>loaded = self.applet.Plugins.get_loaded()<tab>for name, cls in classes.items():<tab><tab><IF-STMT><tab><tab><tab>desc = '<span weight=""bold"">%s</span>' % name<tab><tab>else:<tab><tab><tab>desc = name<tab><tab>self.list.append(<tab><tab><tab>active=(name in loaded),<tab><tab><tab>icon=cls.__icon__,<tab><tab><tab>activatable=cls.__unloadable__,<tab><tab><tab>name=name,<tab><tab><tab>desc=desc,<tab><tab>)",0,if cls . is_configurable ( ) :,"if cls . __class__ . __name__ == ""Button"" :",0.07853088,8.097785064,1
"def visit_decorator(self, o: Decorator) -> None:<tab>if self.is_private_name(o.func.name, o.func.fullname):<tab><tab>return<tab>is_abstract = False<tab>for decorator in o.original_decorators:<tab><tab>if isinstance(decorator, NameExpr):<tab><tab><tab>if self.process_name_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab><tab><IF-STMT><tab><tab><tab>if self.process_member_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab>self.visit_func_def(o.func, is_abstract=is_abstract)",1,"elif isinstance ( decorator , MemberExpr ) :","elif isinstance ( decorator , MemberExpr ) :",0.75,100,1
"def hint(self, button):<tab>""""""As hilight, but marks GTK Button as well""""""<tab>active = None<tab>for b in self.button_widgets.values():<tab><tab><IF-STMT><tab><tab><tab>b.widget.set_state(Gtk.StateType.NORMAL)<tab><tab><tab>if b.name == button:<tab><tab><tab><tab>active = b.widget<tab>if active is not None:<tab><tab>active.set_state(Gtk.StateType.ACTIVE)<tab>self.hilight(button)",0,if b . widget . get_sensitive ( ) :,if b . name == button :,0.117589311,15.18193916,0.484848485
"def read_message_py2(self):<tab>chunks = []<tab>while True:<tab><tab>hi, lo = self.wire.read(2)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>size = hi << 8 | lo<tab><tab>chunks.append(self.wire.read(size))<tab>message = bytearray(b"""".join(map(bytes, chunks)))<tab>_, n = divmod(message[0], 0x10)<tab>unpacker = UnpackStream(message, offset=2)<tab>fields = [unpacker.unpack() for _ in range(n)]<tab>return message[1], fields",0,if hi == lo == 0 :,if hi == 0 :,0.139545404,54.80623194,0.571428571
"def offsetToRva(self, offset):<tab>if self.inmem:<tab><tab>return offset<tab>for s in self.sections:<tab><tab>sbase = s.PointerToRawData<tab><tab>if s.SizeOfRawData + s.PointerToRawData > self.getMaxRva():<tab><tab><tab># SizeOfRawData can be misleading.<tab><tab><tab>ssize = s.VirtualSize<tab><tab>else:<tab><tab><tab>ssize = max(s.SizeOfRawData, s.VirtualSize)<tab><tab><IF-STMT><tab><tab><tab>return offset - s.PointerToRawData + s.VirtualAddress<tab>return 0",0,if sbase <= offset and offset < sbase + ssize :,if sbase >= offset and ssize <= self . getMaxRva ( ) :,0.113489825,14.86599637,0.541666667
"def highlight_from_dir(self, workspace_dir):<tab>while True:<tab><tab>for f in os.listdir(workspace_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.process_trace(os.path.join(workspace_dir, f))<tab><tab>if not self.live_update:<tab><tab><tab>break<tab><tab>time.sleep(interval)",0,"if f . endswith ( ""trace"" ) :","if f . endswith ( "".trace"" ) :",0.549040681,70.16879391,1
"def check_tokenize(self, s, expected):<tab># Format the tokens in s in a table format.<tab># The ENDMARKER is omitted.<tab>result = []<tab>f = StringIO(s)<tab>for type, token, start, end, line in generate_tokens(f.readline):<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>type = tok_name[type]<tab><tab>result.append(""<tab>%(type)-10.10s %(token)-13.13r %(start)s %(end)s"" % locals())<tab>self.assertEqual(result, expected.rstrip().splitlines())",1,if type == ENDMARKER :,if type == ENDMARKER :,0.75,100,1
"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab>if pyv == 2:<tab><tab><tab>if self.PY2 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab><IF-STMT><tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY3:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",0,if pyv == 3 :,elif pyv == 3 :,0.311522644,75.98356857,0.6
"def __xor__(self, other):<tab>inc, exc = _norm_args_notimplemented(other)<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if inc is NotImplemented:<tab><tab>return NotImplemented<tab>if self._included is None:<tab><tab>if exc is None:  # - +<tab><tab><tab>return _ComplementSet(excluded=self._excluded - inc)<tab><tab>else:  # - -<tab><tab><tab>return _ComplementSet(included=self._excluded.symmetric_difference(exc))<tab>else:<tab><tab><IF-STMT>  # + -<tab><tab><tab>return _ComplementSet(excluded=exc - self._included)<tab><tab>else:  # + +<tab><tab><tab>return _ComplementSet(included=self._included.symmetric_difference(inc))",1,if inc is None :,if inc is None :,0.75,100,1
"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab>if type(value) == dict:<tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab>elif isinstance(value, types.ModuleType):<tab><tab><tab>self.__defaults_from_module(value)<tab><tab><IF-STMT><tab><tab><tab>if os.path.exists(value):<tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)",1,"elif isinstance ( value , str ) :","elif isinstance ( value , str ) :",0.75,100,1
"def maybe_add_0000_to_all_niigz(folder):<tab>nii_gz = subfiles(folder, suffix="".nii.gz"")<tab>for n in nii_gz:<tab><tab>n = remove_trailing_slash(n)<tab><tab><IF-STMT><tab><tab><tab>os.rename(n, n[:-7] + ""_0000.nii.gz"")",0,"if not n . endswith ( ""_0000.nii.gz"" ) :","if n . endswith ( "".nii.gz"" ) :",0.18845666,61.65169526,0.381818182
"def newstart(self):<tab>newstartdatetime = self._newstartdate<tab>if not self.checkallday.state:<tab><tab><IF-STMT><tab><tab><tab>tzinfo = self.conf.default.default_timezone<tab><tab>else:<tab><tab><tab>tzinfo = self.startdt.tzinfo<tab><tab>try:<tab><tab><tab>newstarttime = self._newstarttime<tab><tab><tab>newstartdatetime = datetime.combine(newstartdatetime, newstarttime)<tab><tab><tab>newstartdatetime = tzinfo.localize(newstartdatetime)<tab><tab>except TypeError:<tab><tab><tab>return None<tab>return newstartdatetime",0,"if not hasattr ( self . startdt , ""tzinfo"" ) or self . startdt . tzinfo is None :",if self . startdt is None :,0.098870515,5.782700803,0.172727273
"def _fetch_all_channels(self, force=False):<tab>""""""Fetch all channel feeds from cache or network.""""""<tab>channels = self._get_channel_configs(force=force)<tab>enabled = self._settings.get([""enabled_channels""])<tab>forced = self._settings.get([""forced_channels""])<tab>all_channels = {}<tab>for key, config in channels.items():<tab><tab>if key not in enabled and key not in forced:<tab><tab><tab>continue<tab><tab>if ""url"" not in config:<tab><tab><tab>continue<tab><tab>data = self._get_channel_data(key, config, force=force)<tab><tab><IF-STMT><tab><tab><tab>all_channels[key] = data<tab>return all_channels",1,if data is not None :,if data is not None :,0.75,100,1
"def _setup_graph(self):<tab>vars = tf.trainable_variables()<tab>ops = []<tab>for v in vars:<tab><tab>n = v.op.name<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>logger.info(""Clip {}"".format(n))<tab><tab>ops.append(tf.assign(v, tf.clip_by_value(v, -0.01, 0.01)))<tab>self._op = tf.group(*ops, name=""clip"")",0,"if not n . startswith ( ""discrim/"" ) :","if n . startswith ( ""clip"" ) :",0.18845666,44.30006936,0.381818182
"def on_window_state_event(self, widget, event):<tab>if event.changed_mask & WindowState.ICONIFIED:<tab><tab><IF-STMT><tab><tab><tab>log.debug(""MainWindow is minimized.."")<tab><tab><tab>component.get(""TorrentView"").save_state()<tab><tab><tab>component.pause(self.child_components)<tab><tab><tab>self.is_minimized = True<tab><tab>else:<tab><tab><tab>log.debug(""MainWindow is not minimized.."")<tab><tab><tab>component.resume(self.child_components)<tab><tab><tab>self.is_minimized = False<tab>return False",0,if event . new_window_state & WindowState . ICONIFIED :,if self . is_minimized :,0.079338046,3.941375111,0.305555556
"def getJsonData(self, url, decode_from=None, **kwargs):<tab>cache_key = md5(url)<tab>data = self.getCache(cache_key, url, **kwargs)<tab>if data:<tab><tab>try:<tab><tab><tab>data = data.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = data.decode(decode_from)<tab><tab><tab>return json.loads(data)<tab><tab>except:<tab><tab><tab>log.error(<tab><tab><tab><tab>""Failed to parsing %s: %s"", (self.getName(), traceback.format_exc())<tab><tab><tab>)<tab>return []",1,if decode_from :,if decode_from :,0.531170663,1.00E-10,1
"def init_weights(self):<tab>for n, p in self.named_parameters():<tab><tab>if ""bias"" in n:<tab><tab><tab>torch.nn.init.zeros_(p)<tab><tab><IF-STMT><tab><tab><tab>torch.nn.init.xavier_uniform_(p)",0,"elif ""fc"" in n :","elif ""bias1"" in n :",0.142872021,48.89230224,1
"def get_file_language(filename, text=None):<tab>""""""Get file language from filename""""""<tab>ext = osp.splitext(filename)[1]<tab>if ext.startswith("".""):<tab><tab>ext = ext[1:]  # file extension with leading dot<tab>language = ext<tab>if not ext:<tab><tab><IF-STMT><tab><tab><tab>text, _enc = encoding.read(filename)<tab><tab>for line in text.splitlines():<tab><tab><tab>if not line.strip():<tab><tab><tab><tab>continue<tab><tab><tab>if line.startswith(""#!""):<tab><tab><tab><tab>shebang = line[2:]<tab><tab><tab><tab>if ""python"" in shebang:<tab><tab><tab><tab><tab>language = ""python""<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>return language",1,if text is None :,if text is None :,0.75,100,1
"def readwrite(obj, flags):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>obj.handle_read_event()<tab><tab>if flags & select.POLLOUT:<tab><tab><tab>obj.handle_write_event()<tab><tab>if flags & select.POLLPRI:<tab><tab><tab>obj.handle_expt_event()<tab><tab>if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):<tab><tab><tab>obj.handle_close()<tab>except OSError as e:<tab><tab>if e.args[0] not in _DISCONNECTED:<tab><tab><tab>obj.handle_error()<tab><tab>else:<tab><tab><tab>obj.handle_close()<tab>except _reraised_exceptions:<tab><tab>raise<tab>except:<tab><tab>obj.handle_error()",1,if flags & select . POLLIN :,if flags & select . POLLIN :,0.75,100,1
"def sortPlaces(self, newColumn, newOrder, force=False):<tab>profile_id = self.config.currentProfile()<tab>if newColumn == 0 and newOrder == Qt.AscendingOrder:<tab><tab><IF-STMT><tab><tab><tab>newColumn, newOrder = 1, Qt.AscendingOrder<tab><tab><tab>self.places.header().setSortIndicator(newColumn, newOrder)<tab><tab><tab>self.placesSortLoop[profile_id] = False<tab><tab>else:<tab><tab><tab>self.placesSortLoop[profile_id] = True<tab>self.updatePlaces()",0,if profile_id in self . placesSortLoop and self . placesSortLoop [ profile_id ] :,if force :,0.00611191,1.00E-10,0.248120301
def _result_iter(self):<tab>pos = 0<tab>while 1:<tab><tab>upper = len(self._result_cache)<tab><tab>while pos < upper:<tab><tab><tab>yield self._result_cache[pos]<tab><tab><tab>pos = pos + 1<tab><tab>if not self._iter:<tab><tab><tab>raise StopIteration<tab><tab><IF-STMT><tab><tab><tab>self._fill_cache(),0,if len ( self . _result_cache ) <= pos :,if self . _iter . done :,0.028035632,11.03301781,0.320512821
"def get_field_type(self, name):<tab>fkey = (name, self.dummy)<tab>target = None<tab>op, name = name.split(""_"", 1)<tab>if op in {""delete"", ""insert"", ""update""}:<tab><tab>target = super().get_field_type(name)<tab><tab><IF-STMT><tab><tab><tab>module, edb_name = self.get_module_and_name(name)<tab><tab><tab>target = self.edb_schema.get((module, edb_name), None)<tab><tab><tab>if target is not None:<tab><tab><tab><tab>target = self.convert_edb_to_gql_type(target)<tab>self._fields[fkey] = target<tab>return target",1,if target is None :,if target is None :,0.75,100,1
"def _transaction(self, args=None):<tab>cmd = args[0] if args else None<tab>if cmd == ""reset"":<tab><tab>self._clean()<tab><tab>return<tab>self._resolve()<tab>if cmd in [""list"", None]:<tab><tab><IF-STMT><tab><tab><tab>out = self.base.output.list_transaction(self.base._transaction)<tab><tab><tab>logger.info(out)<tab>elif cmd == ""run"":<tab><tab>try:<tab><tab><tab>self.base.do_transaction()<tab><tab>except dnf.exceptions.Error as e:<tab><tab><tab>logger.error(_(""Error:"") + "" "" + ucd(e))<tab><tab>else:<tab><tab><tab>logger.info(_(""Complete!""))<tab><tab>self._clean()<tab>else:<tab><tab>self._help(""transaction"")",1,if self . base . _transaction :,if self . base . _transaction :,0.75,100,1
"def _gather_crash_info(self):<tab>super()._gather_crash_info()<tab>self._crash_info += [<tab><tab>(""Commandline args"", "" "".join(sys.argv[1:])),<tab><tab>(""Open Pages"", ""\n\n"".join(""\n"".join(e) for e in self._pages)),<tab><tab>(""Command history"", ""\n"".join(self._cmdhist)),<tab><tab>(""Objects"", self._qobjects),<tab>]<tab>try:<tab><tab>text = ""Log output was disabled.""<tab><tab><IF-STMT><tab><tab><tab>text = log.ram_handler.dump_log()<tab><tab>self._crash_info.append((""Debug log"", text))<tab>except Exception:<tab><tab>self._crash_info.append((""Debug log"", traceback.format_exc()))",0,if log . ram_handler is not None :,if self . _debug_enabled :,0.061574585,6.082317173,0.238095238
"def classifyws(s, tabwidth):<tab>raw = effective = 0<tab>for ch in s:<tab><tab>if ch == "" "":<tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = effective + 1<tab><tab><IF-STMT><tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = (effective // tabwidth + 1) * tabwidth<tab><tab>else:<tab><tab><tab>break<tab>return raw, effective",1,"elif ch == ""\t"" :","elif ch == ""\t"" :",1,100,1
"def process(self, node):<tab>self.vars = []<tab>for child in node.childNodes:<tab><tab><IF-STMT><tab><tab><tab>child_text = get_xml_text(child)<tab><tab><tab>if child_text == """":  # pragma:nocover<tab><tab><tab><tab>continue<tab><tab><tab>if child.nodeName == ""Real"":<tab><tab><tab><tab>for val in re.split(""[\t ]+"", child_text):<tab><tab><tab><tab><tab>self.vars.append(1.0 * eval(val))<tab>return self",0,if child . nodeType == node . ELEMENT_NODE :,if child . nodeType == Node . TEXT_NODE :,0.495329736,54.5246912,1
"def _format_privilege_data(self, data):<tab>for key in [""spcacl""]:<tab><tab><IF-STMT><tab><tab><tab>if ""added"" in data[key]:<tab><tab><tab><tab>data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl)<tab><tab><tab>if ""changed"" in data[key]:<tab><tab><tab><tab>data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl)<tab><tab><tab>if ""deleted"" in data[key]:<tab><tab><tab><tab>data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)",0,if key in data and data [ key ] is not None :,if key in data :,0.257728313,14.2762397,0.425925926
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def test_cat(shape, cat_dim, split, dim):<tab>assert sum(split) == shape[cat_dim]<tab>gaussian = random_gaussian(shape, dim)<tab>parts = []<tab>end = 0<tab>for size in split:<tab><tab>beg, end = end, end + size<tab><tab>if cat_dim == -1:<tab><tab><tab>part = gaussian[..., beg:end]<tab><tab><IF-STMT><tab><tab><tab>part = gaussian[..., beg:end, :]<tab><tab>elif cat_dim == 1:<tab><tab><tab>part = gaussian[:, beg:end]<tab><tab>else:<tab><tab><tab>raise ValueError<tab><tab>parts.append(part)<tab>actual = Gaussian.cat(parts, cat_dim)<tab>assert_close_gaussian(actual, gaussian)",0,elif cat_dim == - 2 :,elif cat_dim == 0 :,0.412766489,62.40195442,0.5
"def __conform__(self, interface, registry=None, default=None):<tab>for providedInterface in self.provided:<tab><tab><IF-STMT><tab><tab><tab>return self.load()<tab><tab>if getAdapterFactory(providedInterface, interface, None) is not None:<tab><tab><tab>return interface(self.load(), default)<tab>return default",0,if providedInterface . isOrExtends ( interface ) :,if providedInterface == interface :,0.037865239,13.83254363,0.577777778
"def __init__(self, oid):<tab>self.oid = oid<tab>self.cmpt = []<tab>fmt = []<tab>for i in oid.split("".""):<tab><tab><IF-STMT><tab><tab><tab>fmt.append(""%i"")<tab><tab><tab>self.cmpt.append(tuple(map(int, i.split(""-""))))<tab><tab>else:<tab><tab><tab>fmt.append(i)<tab>self.fmt = ""."".join(fmt)",1,"if ""-"" in i :","if ""-"" in i :",0.75,100,1
"def build_CallFunc(self, o):<tab>children = o.getChildren()<tab># Build callee from first child<tab>callee = self.build(children[0])<tab># Build args and kwargs from remaining children<tab>args = []<tab>kwargs = {}<tab>for child in children[1:]:<tab><tab>class_name = child.__class__.__name__<tab><tab># None is ignored<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># Keywords become kwargs<tab><tab>if class_name == ""Keyword"":<tab><tab><tab>kwargs.update(self.build(child))<tab><tab># Everything else becomes args<tab><tab>else:<tab><tab><tab>args.append(self.build(child))<tab>return callee(*args, **kwargs)",0,"if class_name == ""NoneType"" :",if class_name is None :,0.064978772,28.31941551,0.416666667
"def format_raises(self, e, *args, **kw):<tab>self.startTest()<tab>try:<tab><tab>args[0].format(*args[1:], **kw)<tab>except e:<tab><tab>return True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>excName = e.__name__<tab><tab>else:<tab><tab><tab>excName = str(e)<tab><tab>self.fail(""%s not raised"" % excName)<tab>return False",1,"if hasattr ( e , ""__name__"" ) :","if hasattr ( e , ""__name__"" ) :",0.75,100,1
"def make_record_paths_absolute(self, record_dict):<tab># make paths absolute<tab>d = {}<tab>for k, v in record_dict.items():<tab><tab><IF-STMT>  # filename<tab><tab><tab>if ""."" in v:<tab><tab><tab><tab>v = os.path.join(self.path, v)<tab><tab>d[k] = v<tab>return d",0,if type ( v ) == str :,"if isinstance ( v , str ) :",0.039168582,12.82777061,0.666666667
"def work(self):<tab>while self.active:<tab><tab>stat = os.stat(self.filename)<tab><tab><IF-STMT><tab><tab><tab>self.callback(self.last_stat, stat)<tab><tab>self.last_stat = stat<tab><tab>time.sleep(self.interval)",0,if self . last_stat is not None and self . last_stat != stat :,if self . callback is not None :,0.199743874,9.084630644,0.28042328
"def try_append_extension(self, path):<tab>append_setting = self.get_append_extension_setting()<tab>if self.settings.get(append_setting, False):<tab><tab>if not self.is_copy_original_name(path):<tab><tab><tab>_, new_path_extension = os.path.splitext(path)<tab><tab><tab>if new_path_extension == """":<tab><tab><tab><tab>argument_name = self.get_argument_name()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>_, extension = os.path.splitext(self.view.file_name())<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>_, extension = os.path.splitext(argument_name)<tab><tab><tab><tab>path += extension<tab>return path",0,if argument_name is None :,"if argument_name == """" :",0.064978772,31.55984539,0.416666667
"def _out_of_date(rw_file):<tab>""""""Check if a run workflow file points to an older version of manta and needs a refresh.""""""<tab>with open(rw_file) as in_handle:<tab><tab>for line in in_handle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_version = line.split(""/lib/python"")[0].split(""Cellar/manta/"")[-1]<tab><tab><tab><tab>if file_version != programs.get_version_manifest(""manta""):<tab><tab><tab><tab><tab>return True<tab>return False",0,"if line . startswith ( ""sys.path.append"" ) :","if line . startswith ( ""Version"" ) :",0.549040681,44.10953965,1
"def test_model_inference():<tab>x = torch.rand(1, 3, 224, 224)<tab>for model_name in encoding.models.pretrained_model_list():<tab><tab>print(""Doing: "", model_name)<tab><tab><IF-STMT><tab><tab><tab>continue  # need multi-gpu<tab><tab>model = encoding.models.get_model(model_name, pretrained=True)<tab><tab>model.eval()<tab><tab>y = model(x)",0,"if ""wideresnet"" in model_name :","if model_name . endswith ( ""gpu"" ) :",0.02800146,15.5801057,0.5
"def _process_frame(self, frame_num, frame_im, callback=None):<tab># type(int, numpy.ndarray) -> None<tab>""""""Adds any cuts detected with the current frame to the cutting list.""""""<tab>for detector in self._detector_list:<tab><tab>cuts = detector.process_frame(frame_num, frame_im)<tab><tab><IF-STMT><tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._cutting_list += cuts<tab>for detector in self._sparse_detector_list:<tab><tab>events = detector.process_frame(frame_num, frame_im)<tab><tab>if events and callback:<tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._event_list += events",1,if cuts and callback :,if cuts and callback :,0.75,100,1
"def __saveWork(self, work, results):<tab>""""""Stores the resulting last log line to the cache with the proxy key""""""<tab>del work<tab># pylint: disable=broad-except<tab>try:<tab><tab><IF-STMT><tab><tab><tab>__cached = self.__cache[results[0]]<tab><tab><tab>__cached[self.__TIME] = time.time()<tab><tab><tab>__cached[self.__ETA] = results[1]<tab>except KeyError as e:<tab><tab># Could happen while switching jobs with work in the queue<tab><tab>pass<tab>except Exception as e:<tab><tab>list(map(logger.warning, cuegui.Utils.exceptionOutput(e)))",0,if results :,if len ( results ) == 2 :,0.0465226,1.00E-10,0.36
"def _on_preference_changed(self, client, timestamp, entry, extra):<tab>attr = entry.key[entry.key.rindex(""/"") + 1 :]<tab>try:<tab><tab>valuestruct = self._prefs[attr]<tab>except KeyError:  # unknown key, we don't care about it<tab><tab>pass<tab>else:<tab><tab><IF-STMT>  # value has changed<tab><tab><tab>newval = getattr(entry.value, ""get_%s"" % valuestruct.type)()<tab><tab><tab>setattr(self, attr, newval)<tab><tab>else:  # value has been deleted<tab><tab><tab>setattr(self, attr, valuestruct.default)",0,if entry . value != None :,if valuestruct . value is not None :,0.048974609,16.51582159,0.333333333
"def open(self, url, new=0, autoraise=1):<tab>cmdline = [self.name] + [arg.replace(""%s"", url) for arg in self.args]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>p = subprocess.Popen(cmdline)<tab><tab>else:<tab><tab><tab>setsid = getattr(os, ""setsid"", None)<tab><tab><tab>if not setsid:<tab><tab><tab><tab>setsid = getattr(os, ""setpgrp"", None)<tab><tab><tab>p = subprocess.Popen(cmdline, close_fds=True, preexec_fn=setsid)<tab><tab>return p.poll() is None<tab>except OSError:<tab><tab>return False",0,"if sys . platform [ : 3 ] == ""win"" :","if sys . platform == ""win32"" :",0.132488881,28.38267516,0.786666667
"def get_ofs(self, dp_id):<tab>if len(self) == 0:<tab><tab>raise ValueError(""qos sw is not connected."")<tab>dps = {}<tab>if dp_id == REST_ALL:<tab><tab>dps = self<tab>else:<tab><tab>try:<tab><tab><tab>dpid = dpid_lib.str_to_dpid(dp_id)<tab><tab>except:<tab><tab><tab>raise ValueError(""Invalid switchID."")<tab><tab><IF-STMT><tab><tab><tab>dps = {dpid: self[dpid]}<tab><tab>else:<tab><tab><tab>msg = ""qos sw is not connected. : switchID=%s"" % dp_id<tab><tab><tab>raise ValueError(msg)<tab>return dps",1,if dpid in self :,if dpid in self :,0.75,100,1
"def __init__(self, context, keymap={}):<tab>if not ActionHandler._actions:<tab><tab>ActionHandler._actions = Actions.get_instance(context)<tab>_keymap = {}<tab>for (k, v) in keymap.items():<tab><tab><IF-STMT><tab><tab><tab>v = {v}<tab><tab>_keymap[k] = {op for action in v for op in translate_blenderop(action)}<tab>self.__dict__[""_keymap""] = _keymap",0,if type ( v ) is not set and type ( v ) is not list :,"if isinstance ( v , dict ) :",0.014396369,4.508804364,0.202020202
"def setCounter(self, i):<tab>if 0 == i:<tab><tab><IF-STMT><tab><tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention""))<tab><tab>else:<tab><tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud""))<tab>elif i > 0 and i < 10:<tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention-"" + str(int(i))))<tab>elif i > 9:<tab><tab>self.setIcon(QtGui.QIcon.fromTheme(""scudcloud-attention-9-plus""))",0,if True == self . urgent :,if i == 9 :,0.023846651,13.83254363,0.265306122
"def consume_bytes(data):<tab>state_machine.receive_data(data)<tab>while True:<tab><tab>event = state_machine.next_event()<tab><tab>if event is h11.NEED_DATA:<tab><tab><tab>break<tab><tab>elif isinstance(event, h11.InformationalResponse):<tab><tab><tab># Ignore 1xx responses<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab># We have our response! Save it and get out of here.<tab><tab><tab>context[""h11_response""] = event<tab><tab><tab>raise LoopAbort<tab><tab>else:<tab><tab><tab># Can't happen<tab><tab><tab>raise RuntimeError(""Unexpected h11 event {}"".format(event))",0,"elif isinstance ( event , h11 . Response ) :","elif isinstance ( event , h11 . LoopAbort ) :",0.603553391,70.71067812,0.714285714
"def _evoke_request(cls):<tab>succeed = False<tab>with cls.LOCK:<tab><tab><IF-STMT><tab><tab><tab>resource, request_semaphore = cls.REQUESTING_STACK.pop()<tab><tab><tab>node = cls.check_availability(resource)<tab><tab><tab>if node is not None:<tab><tab><tab><tab>cls.NODE_RESOURCE_MANAGER[node]._request(node, resource)<tab><tab><tab><tab>logger.debug(""\nEvoking requesting resource {}"".format(resource))<tab><tab><tab><tab>request_semaphore.release()<tab><tab><tab><tab>succeed = True<tab><tab><tab>else:<tab><tab><tab><tab>cls.REQUESTING_STACK.append((resource, request_semaphore))<tab><tab><tab><tab>return<tab>if succeed:<tab><tab>cls._evoke_request()",0,if len ( cls . REQUESTING_STACK ) > 0 :,if cls . REQUESTING_STACK :,0.059382557,32.73762387,0.371428571
"def _get_related_field(self, field):<tab>model_class = self.Meta.model<tab>try:<tab><tab>related_field = model_class._meta.get_field(field.source)<tab>except FieldDoesNotExist:<tab><tab># If `related_name` is not set, field name does not include<tab><tab># `_set` -> remove it and check again<tab><tab>default_postfix = ""_set""<tab><tab><IF-STMT><tab><tab><tab>related_field = model_class._meta.get_field(<tab><tab><tab><tab>field.source[: -len(default_postfix)]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise<tab>if isinstance(related_field, ForeignObjectRel):<tab><tab>return related_field.field, False<tab>return related_field, True",1,if field . source . endswith ( default_postfix ) :,if field . source . endswith ( default_postfix ) :,0.75,100,1
"def find_best_layout_for_subplots(num_subplots):<tab>r, c = 1, 1<tab>while (r * c) < num_subplots:<tab><tab><IF-STMT><tab><tab><tab>c += 1<tab><tab>elif c == (r + 2):<tab><tab><tab>r += 1<tab><tab><tab>c -= 1<tab>return r, c",0,if ( c == ( r + 1 ) ) or ( r == c ) :,if c == ( r + 1 ) :,0.266096736,33.77381675,0.700483092
"def __repr__(self):<tab>attrs = {}<tab>for name, _ in self:<tab><tab>try:<tab><tab><tab>attr = getattr(self, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>attrs[name] = repr(attr)<tab><tab>except ValidationError:<tab><tab><tab>pass<tab>return ""{class_name}({fields})"".format(<tab><tab>class_name=self.__class__.__name__,<tab><tab>fields="", "".join(""{0[0]}={0[1]}"".format(x) for x in sorted(attrs.items())),<tab>)",0,if attr is not None :,"if isinstance ( attr , type ) :",0.023749772,7.267884212,0.232142857
"def findsection(self, key):<tab>to_return = copy.deepcopy(self)<tab>for subsection in to_return:<tab><tab>try:<tab><tab><tab>value = list(ConfigObj.find_key(to_return[subsection], key))[0]<tab><tab>except Exception:<tab><tab><tab>value = None<tab><tab><IF-STMT><tab><tab><tab>del to_return[subsection]<tab><tab>else:<tab><tab><tab>for category in to_return[subsection]:<tab><tab><tab><tab>if category != key:<tab><tab><tab><tab><tab>del to_return[subsection][category]<tab># cleanout empty sections and subsections<tab>for key in [k for (k, v) in to_return.items() if not v]:<tab><tab>del to_return[key]<tab>return to_return",0,if not value :,if value is None :,0.045150551,14.05853313,0.277777778
"def _get_streams(self, url, video_id, app_id_ver):<tab># Sometimes the return dict does not have 'stream'<tab>for trial_count in range(3):<tab><tab>stream_info = self._get_stream_info(<tab><tab><tab>url,<tab><tab><tab>video_id,<tab><tab><tab>app_id_ver,<tab><tab><tab>extra_note="" (try %d)"" % (trial_count + 1) if trial_count > 0 else """",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return stream_info[0][""args""][0][""stream""]<tab>return []",0,"if ""stream"" in stream_info [ 0 ] [ ""args"" ] [ 0 ] :",if stream_info :,0.006410237,1.00E-10,0.467391304
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def summary(self):<tab>""""""Return a string with a pretty-printed summary for the company.""""""<tab>if not self:<tab><tab>return u""""<tab>s = u""Company\n=======\nName: %s\n"" % self.get(""name"", u"""")<tab>for k in (<tab><tab>""distributor"",<tab><tab>""production company"",<tab><tab>""miscellaneous company"",<tab><tab>""special effects company"",<tab>):<tab><tab>d = self.get(k, [])[:5]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>s += u""Last movies from this company (%s): %s.\n"" % (<tab><tab><tab>k,<tab><tab><tab>u""; "".join([x.get(""long imdb title"", u"""") for x in d]),<tab><tab>)<tab>return s",1,if not d :,if not d :,0.75,100,1
"def __call__(self, data):<tab>keys = set(data.keys)<tab>for attr_name in self._attr_names:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(<tab><tab><tab><tab>""attr_name: {} isn t within keys: {}"".format(attr_name, keys)<tab><tab><tab>)<tab>for attr_name in self._attr_names:<tab><tab>delattr(data, attr_name)<tab>return data",0,if attr_name not in keys and self . _strict :,if attr_name not in keys :,0.36568904,46.53786298,0.685714286
"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",1,if count :,if count :,0.531170663,1.00E-10,1
"def produce_etag_headers(self, filename):<tab>""""""Produce a dict of curl headers containing etag headers from the download.""""""<tab>headers = {}<tab># If the download file already exists, add some headers to the request<tab># so we don't retrieve the content if it hasn't changed<tab>if os.path.exists(filename):<tab><tab>self.existing_file_size = os.path.getsize(filename)<tab><tab>etag = self.getxattr(self.xattr_etag)<tab><tab>last_modified = self.getxattr(self.xattr_last_modified)<tab><tab>if etag:<tab><tab><tab>headers[""If-None-Match""] = etag<tab><tab><IF-STMT><tab><tab><tab>headers[""If-Modified-Since""] = last_modified<tab>return headers",1,if last_modified :,if last_modified :,0.531170663,1.00E-10,1
"def repack(self):<tab>newNsp = Pfs0Stream(self._path[:-4] + "".nsp"")<tab>for nspF in self.hfs0[""secure""]:<tab><tab>f = newNsp.add(nspF._path, nspF.size)<tab><tab>nspF.rewind()<tab><tab>i = 0<tab><tab>pageSize = 0x10000<tab><tab>while True:<tab><tab><tab>buf = nspF.read(pageSize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>i += len(buf)<tab><tab><tab>f.write(buf)<tab>newNsp.close()",0,if len ( buf ) == 0 :,if not buf :,0.019930836,6.023021416,0.481481481
"def assertHasChanged(self, **kwargs):<tab>tracker = kwargs.pop(""tracker"", self.tracker)<tab>for field, value in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>with self.assertRaises(FieldError):<tab><tab><tab><tab>tracker.has_changed(field)<tab><tab>else:<tab><tab><tab>self.assertEqual(tracker.has_changed(field), value)",0,if value is None :,"if isinstance ( value , str ) :",0.02800146,7.267884212,0.285714286
"def check_engine(engine):<tab>if engine == ""auto"":<tab><tab>if pa is not None:<tab><tab><tab>return ""pyarrow""<tab><tab>elif fastparquet is not None:  # pragma: no cover<tab><tab><tab>return ""fastparquet""<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install either pyarrow or fastparquet."")<tab>elif engine == ""pyarrow"":<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install pyarrow fisrt."")<tab><tab>return engine<tab>elif engine == ""fastparquet"":<tab><tab>if fastparquet is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install fastparquet first."")<tab><tab>return engine<tab>else:  # pragma: no cover<tab><tab>raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",0,if pa is None :,if pa is not None :,0.147109132,37.99178428,0.611111111
"def parse_vcs_bundle_file(self, content):<tab>for line in content.splitlines():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>match = re.search(r""^-r\s*([^ ])?"", line)<tab><tab>if not match:<tab><tab><tab>return None, None<tab><tab>rev = match.group(1)<tab><tab>rest = line[match.end() :].strip().split(None, 1)[0]<tab><tab>return rest, rev<tab>return None, None",0,"if not line . strip ( ) or line . strip ( ) . startswith ( ""#"" ) :","if line . startswith ( ""#"" ) :",0.153609116,27.65166242,0.259259259
"def __init__(self, parent_instance, *args, **kwargs):<tab>self.parent_instance = parent_instance<tab>self.pk_field = kwargs.pop(""pk_field"", False)<tab>self.to_field = kwargs.pop(""to_field"", None)<tab>if self.parent_instance is not None:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""initial""] = getattr(self.parent_instance, self.to_field)<tab><tab>else:<tab><tab><tab>kwargs[""initial""] = self.parent_instance.pk<tab>kwargs[""required""] = False<tab>kwargs[""widget""] = InlineForeignKeyHiddenInput<tab>super(InlineForeignKeyField, self).__init__(*args, **kwargs)",0,if self . to_field :,if self . to_field is not None :,0.351498834,53.72849659,0.444444444
"def number_multiple_validator(v: ""Number"", field: ""ModelField"") -> ""Number"":<tab>field_type: ConstrainedNumber = field.type_<tab>if field_type.multiple_of is not None:<tab><tab>mod = float(v) / float(field_type.multiple_of) % 1<tab><tab><IF-STMT><tab><tab><tab>raise errors.NumberNotMultipleError(multiple_of=field_type.multiple_of)<tab>return v",0,"if not almost_equal_floats ( mod , 0.0 ) and not almost_equal_floats ( mod , 1.0 ) :",if mod > 1 :,0.006040533,0.257491016,0.313333333
"def forward(self, x, edge_index, edge_attr=None):<tab>x_old = 0<tab>for i, layer in enumerate(self.hidden_layers):<tab><tab>x = self.dropout(x)<tab><tab>x = layer(x, edge_index)<tab><tab>x = self.norm(x)<tab><tab>x = self.relu(x)<tab><tab><IF-STMT><tab><tab><tab>x = x + x_old<tab><tab><tab>x_old = x<tab>x = self.dropout(x)<tab>x = self.out_layer(x, edge_index)<tab>return x",0,if self . skip > 0 and i % self . skip == 0 :,if i == self . num_layers - 1 :,0.046194314,7.893880992,0.213235294
"def check_dimensions(nrow, ncol):<tab>if nrow is not None:<tab><tab><IF-STMT><tab><tab><tab>warn(<tab><tab><tab><tab>""'nrow' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>nrow = None<tab><tab>else:<tab><tab><tab>nrow = int(nrow)<tab>if ncol is not None:<tab><tab>if ncol < 1:<tab><tab><tab>warn(<tab><tab><tab><tab>""'ncol' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>ncol = None<tab><tab>else:<tab><tab><tab>ncol = int(ncol)<tab>return nrow, ncol",1,if nrow < 1 :,if nrow < 1 :,0.75,100,1
"def logic():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",0,if count == - n :,if n > 0 :,0.029084143,9.423716575,0.4
"def get_whitelist(self, guild: Optional[discord.Guild] = None) -> Set[int]:<tab>async with self._access_lock:<tab><tab>ret: Set[int]<tab><tab>gid: Optional[int] = guild.id if guild else None<tab><tab><IF-STMT><tab><tab><tab>ret = self._cached_whitelist[gid].copy()<tab><tab>else:<tab><tab><tab>if gid is not None:<tab><tab><tab><tab>ret = set(await self._config.guild_from_id(gid).whitelist())<tab><tab><tab>else:<tab><tab><tab><tab>ret = set(await self._config.whitelist())<tab><tab><tab>self._cached_whitelist[gid] = ret.copy()<tab><tab>return ret",1,if gid in self . _cached_whitelist :,if gid in self . _cached_whitelist :,0.75,100,1
"def process_response(self, request, response):<tab>if getattr(self, ""has_session"", False):<tab><tab><IF-STMT><tab><tab><tab>user = ""%s (id:%s)"" % (request.user.username, request.user.pk)<tab><tab>else:<tab><tab><tab>user = ""(Anonymous)""<tab><tab>self.logger.info(<tab><tab><tab>""Session %s authenticated by %s"", request.session.session_key, user<tab><tab>)<tab><tab>request.session.save = self._save<tab><tab>self._save = None<tab><tab>self.session = None<tab><tab>self.has_session = False",0,"if getattr ( request , ""user"" , None ) and request . user . is_authenticated ( ) :",if request . user . is_authenticated :,0.092952139,18.23459998,0.263736264
"def cluster(spawnpoints, radius, time_threshold):<tab>clusters = []<tab>diameter = 2 * radius<tab>for p in spawnpoints:<tab><tab>if len(clusters) == 0:<tab><tab><tab>clusters.append(Spawncluster(p))<tab><tab>else:<tab><tab><tab>c = min(clusters, key=lambda x: cost(p, x, time_threshold))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c.append(p)<tab><tab><tab>else:<tab><tab><tab><tab>c = Spawncluster(p)<tab><tab><tab><tab>clusters.append(c)<tab>return clusters",0,"if check_cluster ( p , c , radius , time_threshold ) :",if len ( c ) < diameter :,0.013161833,3.037915609,0.428571429
"def get_shape(shape):<tab>""""""Convert the shape to correct dtype and vars.""""""<tab>ret = []<tab>for dim in shape:<tab><tab><IF-STMT><tab><tab><tab>if libinfo()[""INDEX_DEFAULT_I64""] == ""ON"":<tab><tab><tab><tab>ret.append(dim)<tab><tab><tab>else:<tab><tab><tab><tab>val = int(dim)<tab><tab><tab><tab>assert val <= np.iinfo(np.int32).max<tab><tab><tab><tab>ret.append(tvm.tir.IntImm(""int32"", val))<tab><tab>elif isinstance(dim, tvm.tir.Any):<tab><tab><tab>ret.append(te.var(""any_dim"", ""int32""))<tab><tab>else:<tab><tab><tab>ret.append(dim)<tab>return ret",0,"if isinstance ( dim , tvm . tir . IntImm ) :","if isinstance ( dim , tvm . tir . Int ) :",0.635663651,76.91605673,0.75
"def run(self):<tab>queue = self.queue<tab>while True:<tab><tab>if not self.running:<tab><tab><tab>break<tab><tab># Grab our data<tab><tab>callback, requests, fetchTimeout, validityOverride = queue.get()<tab><tab># Grab prices, this is the time-consuming part<tab><tab>if len(requests) > 0:<tab><tab><tab>Price.fetchPrices(requests, fetchTimeout, validityOverride)<tab><tab>wx.CallAfter(callback)<tab><tab>queue.task_done()<tab><tab># After we fetch prices, go through the list of waiting items and call their callbacks<tab><tab>for price in requests:<tab><tab><tab>callbacks = self.wait.pop(price.typeID, None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for callback in callbacks:<tab><tab><tab><tab><tab>wx.CallAfter(callback)",0,if callbacks :,if callbacks is not None :,0.090364769,1.00E-10,0.4
def _load_scopes_(self):<tab>if self._model_ is None:<tab><tab>tablemap = self.db._adapter.tables(self.query)<tab><tab><IF-STMT><tab><tab><tab>self._model_ = tablemap.popitem()[1]._model_<tab>if self._model_:<tab><tab>self._scopes_ = self._model_._instance_()._scopes_,0,if len ( tablemap ) == 1 :,if len ( tablemap ) > 1 :,0.549040681,52.47357978,1
"def udp_to_tcp(udp_sock, tcp_conn):<tab>while True:<tab><tab>msg, _ = udp_sock.recvfrom(2 ** 16)<tab><tab>log_msg(""read_udp"", msg)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>write_tcp(tcp_conn, msg)",0,if not msg :,"if msg == b"""" :",0.045150551,7.267884212,0.45
"def __get_annotations(self):<tab>if not hasattr(self, ""_annotations""):<tab><tab>self._annotations = _retrieve_annotations(<tab><tab><tab>self._adaptor, self._primary_id, self._taxon_id<tab><tab>)<tab><tab>if self._identifier:<tab><tab><tab>self._annotations[""gi""] = self._identifier<tab><tab><IF-STMT><tab><tab><tab>self._annotations[""data_file_division""] = self._division<tab>return self._annotations",1,if self . _division :,if self . _division :,0.75,100,1
"def ignore_module(module):<tab>result = False<tab>for check in ignore_these:<tab><tab><IF-STMT><tab><tab><tab>if check[:-1] in module:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab>if (os.getcwd() + ""/"" + check + "".py"") == module:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_warning(""Ignoring module: "" + module)<tab>return result",0,"if ""/*"" in check :","if check . endswith ( "".py"" ) :",0.02800146,5.604233375,0.4
"def find_commands(management_dir):<tab># Modified version of function from django/core/management/__init__.py.<tab>command_dir = os.path.join(management_dir, ""commands"")<tab>commands = []<tab>try:<tab><tab>for f in os.listdir(command_dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>elif f.endswith("".py"") and f[:-3] not in commands:<tab><tab><tab><tab>commands.append(f[:-3])<tab><tab><tab>elif f.endswith("".pyc"") and f[:-4] not in commands:<tab><tab><tab><tab>commands.append(f[:-4])<tab>except OSError:<tab><tab>pass<tab>return commands",0,"if f . startswith ( ""_"" ) :","if f . startswith ( ""__init__.py"" ) :",0.549040681,45.78831372,1
"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab>if x1:<tab><tab><tab><tab>kids[key] = x1<tab><tab>elif isinstance(x, TVTKBase):<tab><tab><tab>if hasattr(x, ""__iter__""):<tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x",0,"if type ( x ) in ( type ( [ ] ) , type ( ( ) ) ) :","if isinstance ( x , list ) :",0.013778411,3.857036702,0.419047619
"def classify(self, url, text):<tab>for match in self.rules.match(data=text):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.matches.append((url, match))<tab><tab>if self.discard_url_match(url, match):  # pragma: no cover<tab><tab><tab>continue<tab><tab>self.handle_match_etags(match)<tab><tab>rule = match.rule<tab><tab>meta = match.meta<tab><tab>tags = "","".join(["" "".join(t.split(""_"")) for t in match.tags])<tab><tab>log.ThugLogging.log_classifier(""text"", url, rule, tags, meta)<tab>for c in self.custom_classifiers:<tab><tab>self.custom_classifiers[c](url, text)",0,"if ( url , match ) in self . matches :","if self . discard_url_match ( url , match ) :",0.217809664,32.55964126,0.261904762
"def recurse(node):<tab>for child in node.childNodes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if child.nodeName.upper() == ""H1"":<tab><tab><tab>return child<tab><tab>if child not in visited:<tab><tab><tab>return recurse(child)",0,if child . nodeType != child . ELEMENT_NODE :,"if child . nodeName . upper ( ) == ""H0"" :",0.124620255,12.57119268,0.444444444
"def try_fix_ip_range(self):<tab>for i in range(len(self.fake_ip_parts)):<tab><tab><IF-STMT><tab><tab><tab>if i - 1 < 0:<tab><tab><tab><tab>raise Exception(""Fake IP's out of range."")<tab><tab><tab>self.fake_ip_parts[i - 1] += 1<tab><tab><tab>self.fake_ip_parts[i] = 1",0,if self . fake_ip_parts [ i ] > 256 :,if self . fake_ip_parts [ i ] == 0 :,0.583189826,71.66258375,0.666666667
"def run(self):<tab>self.thread.start()<tab>while self.thread.isRunning():<tab><tab><IF-STMT><tab><tab><tab>self.update.emit(config.imager_percentage)<tab><tab>if not self.thread.isFinished() and config.percentage == 100:<tab><tab><tab>config.imager_status_text = """"<tab><tab><tab>self.status.emit(""Please wait..."")<tab><tab>time.sleep(0.1)<tab>self.update.emit(100)<tab>self.update.emit(0)<tab>if self.thread.isFinished():<tab><tab>config.status_text = """"<tab><tab>self.finished.emit()<tab>return",0,if config . imager_percentage :,if not self . thread . isFinished ( ) :,0.025806627,5.522397784,0.252747253
"def _get_trading_minutes(self, trading_date):<tab>trading_minutes = set()<tab>for account_type in self._config.base.accounts:<tab><tab><IF-STMT><tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_stock_trading_minutes(trading_date)<tab><tab><tab>)<tab><tab>elif account_type == DEFAULT_ACCOUNT_TYPE.FUTURE:<tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_future_trading_minutes(trading_date)<tab><tab><tab>)<tab>return sorted(list(trading_minutes))",0,if account_type == DEFAULT_ACCOUNT_TYPE . STOCK :,if account_type == DEFAULT_ACCOUNT_TYPE . stock :,0.574113272,85.55261859,1
"def lngettext(self, msgid1, msgid2, n):<tab>import warnings<tab>warnings.warn(<tab><tab>""lngettext() is deprecated, use ngettext() instead"", DeprecationWarning, 2<tab>)<tab>try:<tab><tab>tmsg = self._catalog[(msgid1, self.plural(n))]<tab>except KeyError:<tab><tab>if self._fallback:<tab><tab><tab>return self._fallback.lngettext(msgid1, msgid2, n)<tab><tab><IF-STMT><tab><tab><tab>tmsg = msgid1<tab><tab>else:<tab><tab><tab>tmsg = msgid2<tab>if self._output_charset:<tab><tab>return tmsg.encode(self._output_charset)<tab>return tmsg.encode(locale.getpreferredencoding())",1,if n == 1 :,if n == 1 :,0.75,100,1
"def check_langs(langs, pairs):<tab>messages = []<tab>for src, tgt in pairs:<tab><tab><IF-STMT><tab><tab><tab>messages.append(<tab><tab><tab><tab>f""language pair {src}-{tgt} contains languages ""<tab><tab><tab><tab>""that are not in the language dictionary""<tab><tab><tab>)<tab>if len(messages) > 0:<tab><tab>raise ValueError("" "".join(messages) + f""; langs: {langs}"")",0,if src not in langs or tgt not in langs :,if src not in langs :,0.43456795,43.45982085,0.535714286
"def to_header(self):<tab>""""""Converts the object back into an HTTP header.""""""<tab>ranges = []<tab>for begin, end in self.ranges:<tab><tab><IF-STMT><tab><tab><tab>ranges.append(f""{begin}-"" if begin >= 0 else str(begin))<tab><tab>else:<tab><tab><tab>ranges.append(f""{begin}-{end - 1}"")<tab>return f""{self.units}={','.join(ranges)}""",0,if end is None :,if end == 0 :,0.064978772,17.9652056,0.444444444
"def name(ent, langpref=""en""):<tab>try:<tab><tab>org = ent[""organization""]<tab>except KeyError:<tab><tab>return None<tab>for info in [""organization_display_name"", ""organization_name"", ""organization_url""]:<tab><tab>try:<tab><tab><tab>for item in org[info]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return item[""text""]<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return None",0,"if item [ ""lang"" ] == langpref :","if item [ ""langpref"" ] == langpref :",0.501462237,70.16879391,1
"def check_url(value):<tab>validate(text, value)<tab>parsed = urlparse(value)<tab>if not parsed.netloc:<tab><tab>raise ValueError(""'{0}' is not a valid URL"".format(value))<tab>for name, schema in attributes.items():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Invalid URL attribute '{0}'"".format(name))<tab><tab>try:<tab><tab><tab>validate(schema, _getattr(parsed, name))<tab><tab>except ValueError as err:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Unable to validate URL attribute '{0}': {1}"".format(name, err)<tab><tab><tab>)<tab>return True",1,"if not _hasattr ( parsed , name ) :","if not _hasattr ( parsed , name ) :",0.75,100,1
"def stepStarted(self, step):<tab>self.currentStep = step<tab>for w in self.watchers:<tab><tab>receiver = w.stepStarted(self, step)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(receiver, type(())):<tab><tab><tab><tab>step.subscribe(receiver[0], receiver[1])<tab><tab><tab>else:<tab><tab><tab><tab>step.subscribe(receiver)<tab><tab><tab>d = step.waitUntilFinished()<tab><tab><tab># TODO: This actually looks like a bug, but this code<tab><tab><tab># will be removed anyway.<tab><tab><tab># pylint: disable=cell-var-from-loop<tab><tab><tab>d.addCallback(lambda step: step.unsubscribe(receiver))<tab>step.waitUntilFinished().addCallback(self._stepFinished)",0,if receiver :,if receiver is not None :,0.090364769,1.00E-10,0.4
"def assert_not_none(obj, msg=None, values=True):<tab>""""""Fail the test if given object is None.""""""<tab>_msg = ""is None""<tab>if obj is None:<tab><tab><IF-STMT><tab><tab><tab>msg = _msg<tab><tab>elif values is True:<tab><tab><tab>msg = ""%s: %s"" % (msg, _msg)<tab><tab>_report_failure(msg)",1,if msg is None :,if msg is None :,0.75,100,1
"def _parse_date_fmt():<tab>fmt = get_format(""DATE_FORMAT"")<tab>escaped = False<tab>for char in fmt:<tab><tab>if escaped:<tab><tab><tab>escaped = False<tab><tab><IF-STMT><tab><tab><tab>escaped = True<tab><tab>elif char in ""Yy"":<tab><tab><tab>yield ""year""<tab><tab>elif char in ""bEFMmNn"":<tab><tab><tab>yield ""month""<tab><tab>elif char in ""dj"":<tab><tab><tab>yield ""day""",0,"elif char == ""\\"" :","elif char in ""x"" :",0.064978772,14.75956453,0.7
"def GetPluginClass(self):<tab>if self.plugin_name:<tab><tab>plugin_cls = registry.OutputPluginRegistry.PluginClassByName(self.plugin_name)<tab><tab><IF-STMT><tab><tab><tab>logging.warning(""Unknown output plugin %s"", self.plugin_name)<tab><tab><tab>return registry.OutputPluginRegistry.PluginClassByName(<tab><tab><tab><tab>""UnknownOutputPlugin""<tab><tab><tab>)<tab><tab>return plugin_cls",0,if plugin_cls is None :,if not plugin_cls :,0.039449619,29.05925408,0.36
"def command(self):<tab>config = self.session.config<tab>unregister = False<tab>self.session.ui.notify(_(""Watching logs: Press CTRL-C to return to the CLI""))<tab>try:<tab><tab>while not mailpile.util.QUITTING and not config.event_log:<tab><tab><tab>time.sleep(1)<tab><tab>unregister = config.event_log and config.event_log.ui_watch(self.session.ui)<tab><tab>self.session.ui.unblock(force=True)<tab><tab>while not mailpile.util.QUITTING:<tab><tab><tab>time.sleep(1)<tab>except KeyboardInterrupt:<tab><tab>pass<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>config.event_log.ui_unwatch(self.session.ui)<tab>return self._success(_(""That was fun!""))",1,if unregister :,if unregister :,0.531170663,1.00E-10,1
"def delete_rule(self, arn):<tab>for load_balancer_arn in self.load_balancers:<tab><tab>listeners = self.load_balancers.get(load_balancer_arn).listeners.values()<tab><tab>for listener in listeners:<tab><tab><tab>for rule in listener.rules:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>listener.remove_rule(rule)<tab><tab><tab><tab><tab>return",1,if rule . arn == arn :,if rule . arn == arn :,1,100,1
"def __dragBegin(self, widget, event):<tab>if event.buttons & (event.Buttons.Left | event.Buttons.Middle):<tab><tab>GafferUI.Pointer.setCurrent(""nodes"")<tab><tab><IF-STMT><tab><tab><tab>return next(iter(self.__graphComponents))<tab><tab>else:<tab><tab><tab>return Gaffer.StandardSet(self.__graphComponents)<tab>return None",0,if len ( self . __graphComponents ) == 1 :,if self . __graphComponents :,0.059382557,28.37952262,0.371428571
"def _get_strategy_name(self):<tab>frame = sys._getframe()<tab>while frame:<tab><tab>st = frame.f_locals.get(""self"")<tab><tab><IF-STMT><tab><tab><tab>return ""%s.%s"" % (type(st).__module__, type(st).__name__)<tab><tab>frame = frame.f_back<tab>return """"",0,"if isinstance ( st , StrategyBase ) :",if st is not None :,0.019830745,7.654112967,0.232142857
"def getCommitFromFile(short=True):<tab>global _gitdir<tab>branch = getBranchFromFile()<tab>commit = None<tab>if _gitdir and branch:<tab><tab>if branch == ""HEAD"":<tab><tab><tab>commitFile = os.path.join(_gitdir, ""HEAD"")<tab><tab>else:<tab><tab><tab>commitFile = os.path.join(_gitdir, ""refs"", ""heads"", branch)<tab><tab><IF-STMT><tab><tab><tab>with open(commitFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>commit = f.readline().strip()<tab>if short and commit:<tab><tab>return commit[:8]<tab>else:<tab><tab>return commit",0,if os . path . isfile ( commitFile ) :,if os . path . exists ( commitFile ) :,0.580308871,65.80370065,0.714285714
"def _register_aliases_from_pack(self, pack, aliases):<tab>registered_count = 0<tab>for alias in aliases:<tab><tab>try:<tab><tab><tab>LOG.debug(""Loading alias from %s."", alias)<tab><tab><tab>self._register_action_alias(pack, alias)<tab><tab>except Exception as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = 'Failed to register alias ""%s"" from pack ""%s"": %s' % (<tab><tab><tab><tab><tab>alias,<tab><tab><tab><tab><tab>pack,<tab><tab><tab><tab><tab>str(e),<tab><tab><tab><tab>)<tab><tab><tab><tab>raise ValueError(msg)<tab><tab><tab>LOG.exception(""Unable to register alias: %s"", alias)<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>registered_count += 1<tab>return registered_count",0,if self . _fail_on_failure :,"if isinstance ( e , InvalidAlias ) :",0.026407399,5.114598707,0.3
"def pop_many(self, limit=None):<tab>if limit is None:<tab><tab>limit = DEFAULT_SYNC_OFFLINE_ACTIVITY<tab>heartbeats = []<tab>count = 0<tab>while count < limit:<tab><tab>heartbeat = self.pop()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>heartbeats.append(heartbeat)<tab><tab>count += 1<tab><tab>if count % HEARTBEATS_PER_REQUEST == 0:<tab><tab><tab>yield heartbeats<tab><tab><tab>heartbeats = []<tab>if heartbeats:<tab><tab>yield heartbeats",1,if not heartbeat :,if not heartbeat :,0.75,100,1
"def makeChunkVertices(self, chunk):<tab>if (<tab><tab>chunk.root_tag<tab><tab>and ""Level"" in chunk.root_tag<tab><tab>and ""TileTicks"" in chunk.root_tag[""Level""]<tab>):<tab><tab>ticks = chunk.root_tag[""Level""][""TileTicks""]<tab><tab><IF-STMT><tab><tab><tab>self.vertexArrays.append(<tab><tab><tab><tab>self._computeVertices(<tab><tab><tab><tab><tab>[[t[i].value for i in ""xyz""] for t in ticks],<tab><tab><tab><tab><tab>(0xFF, 0xFF, 0xFF, 0x44),<tab><tab><tab><tab><tab>chunkPosition=chunk.chunkPosition,<tab><tab><tab><tab>)<tab><tab><tab>)<tab>yield",0,if len ( ticks ) :,if ticks :,0.028363593,1.00E-10,0.464285714
"def read_bytes_from_url(url: str, optional=False) -> bytes:<tab>if parse_args().print_commands:<tab><tab>print_stderr(color_line(""=> "", 14) + f""GET {url}"")<tab>req = request.Request(url)<tab>try:<tab><tab>response = request.urlopen(req)<tab>except URLError as exc:<tab><tab>print_error(""urllib: "" + str(exc.reason))<tab><tab><IF-STMT><tab><tab><tab>return b""""<tab><tab>if ask_to_continue(_(""Do you want to retry?"")):<tab><tab><tab>return read_bytes_from_url(url, optional=optional)<tab><tab>raise SysExit(102)<tab>result_bytes = response.read()<tab>return result_bytes",1,if optional :,if optional :,0.531170663,1.00E-10,1
"def h2i(self, pkt, x):<tab>if x is not None:<tab><tab>if x <= -180.00000005:<tab><tab><tab>warning(""Fixed3_7: Input value too negative: %.8f"" % x)<tab><tab><tab>x = -180.0<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_7: Input value too positive: %.8f"" % x)<tab><tab><tab>x = 180.0<tab><tab>x = int(round((x + 180.0) * 1e7))<tab>return x",1,elif x >= 180.00000005 :,elif x >= 180.00000005 :,0.75,100,1
"def replace_incompatible_files():<tab>for filename, version_info in PYTHON_VERSION_REQUIREMENTS.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>version = ""."".join(str(v) for v in version_info)<tab><tab>code = INCOMPATIBLE_PYTHON_VERSION_PLACEHOLDER.format(version=version)<tab><tab>with open(filename, ""w"") as f:<tab><tab><tab>f.write(code)",0,if sys . version_info >= version_info :,if not version_info :,0.043538727,19.7656093,0.5
"def __eq__(self, other):<tab>if self.__class__ != other.__class__:<tab><tab>return False<tab>for attr in [""bar"", ""baz"", ""quux""]:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>elif getattr(self, attr, None) != getattr(other, attr, None):<tab><tab><tab>return False<tab>return True",0,"if hasattr ( self , attr ) != hasattr ( other , attr ) :","if getattr ( self , attr , None ) != getattr ( other , attr ) :",0.646927787,48.06604068,0.430921053
"def get_content_length(download):<tab>try:<tab><tab>meta = download.info()<tab><tab>if hasattr(meta, ""getheaders"") and hasattr(meta.getheaders, ""Content-Length""):<tab><tab><tab>return int(meta.getheaders(""Content-Length"")[0])<tab><tab>elif hasattr(download, ""getheader"") and download.getheader(""Content-Length""):<tab><tab><tab>return int(download.getheader(""Content-Length""))<tab><tab><IF-STMT><tab><tab><tab>return int(meta.getheader(""Content-Length""))<tab>except Exception:<tab><tab>pass<tab>return 0",1,"elif hasattr ( meta , ""getheader"" ) and meta . getheader ( ""Content-Length"" ) :","elif hasattr ( meta , ""getheader"" ) and meta . getheader ( ""Content-Length"" ) :",0.75,100,1
"def set_size(self, size):<tab>assert len(size) == 2<tab>width, height = size<tab>if width == -1:<tab><tab>for button in self._buttons_list:<tab><tab><tab>cur_width = button.GetSize()[self.WIDTH]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>width = cur_width<tab>if height == -1:<tab><tab>for button in self._buttons_list:<tab><tab><tab>cur_height = button.GetSize()[self.HEIGHT]<tab><tab><tab>if cur_height > height:<tab><tab><tab><tab>height = cur_height<tab>if self._squared:<tab><tab>width = height = width if width > height else height<tab>for button in self._buttons_list:<tab><tab>button.SetMinSize((width, height))",1,if cur_width > width :,if cur_width > width :,0.75,100,1
"def _default_config(self):<tab>if sys.platform.startswith(""win""):<tab><tab>return {""name"": ""Command Prompt"", ""cmd"": ""cmd.exe"", ""env"": {}}<tab>else:<tab><tab>if ""SHELL"" in os.environ:<tab><tab><tab>shell = os.environ[""SHELL""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cmd = [shell, ""-l""]<tab><tab><tab>else:<tab><tab><tab><tab>cmd = [shell, ""-i"", ""-l""]<tab><tab>else:<tab><tab><tab>cmd = [""/bin/bash"", ""-i"", ""-l""]<tab><tab>return {""name"": ""Login Shell"", ""cmd"": cmd, ""env"": {}}",0,"if os . path . basename ( shell ) == ""tcsh"" :","if sys . platform . startswith ( ""win"" ) :",0.055474623,4.435573423,0.214814815
"def log_sock(s, event_type=None):<tab>if sock_silent:<tab><tab>pass<tab>else:<tab><tab>if event_type is None:<tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab><IF-STMT><tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab>else:<tab><tab><tab>pass",0,elif event_type in show_event :,"elif event_type == ""tcp"" :",0.062871671,27.77619034,0.619047619
"def check_eventref_citations(self, obj):<tab>if obj:<tab><tab>for event_ref in obj.get_event_ref_list():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>event = self.dbstate.db.get_event_from_handle(event_ref.ref)<tab><tab><tab>if self.check_event_citations(event):<tab><tab><tab><tab>return True<tab>return False",0,if self . check_attribute_citations ( event_ref ) :,if self . check_event_citations ( event_ref ) :,0.501462237,78.254229,1
"def __exit__(self, exc_type, exc_value, traceback):<tab>self.nest -= 1<tab>if self.nest == 0:<tab><tab>try:<tab><tab><tab>self.con.__exit__(exc_type, exc_value, traceback)<tab><tab><tab>self.close()<tab><tab>except Exception as exc:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.debug.write(""EXCEPTION from __exit__: {}"".format(exc))<tab><tab><tab>raise",1,if self . debug :,if self . debug :,0.75,100,1
"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab>if keys is not None and key not in keys:<tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab><IF-STMT><tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab>if attr is None:<tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab>if conv is not None:<tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",1,if key not in collected_models :,if key not in collected_models :,0.75,100,1
"def delete(self):<tab>""""""Completely shut down pulseaudio client.""""""<tab>if self._pa_context is not None:<tab><tab>assert _debug(""PulseAudioContext.delete"")<tab><tab><IF-STMT><tab><tab><tab>pa.pa_context_disconnect(self._pa_context)<tab><tab><tab>while self.state is not None and not self.is_terminated:<tab><tab><tab><tab>self.wait()<tab><tab>self._disconnect_callbacks()<tab><tab>pa.pa_context_unref(self._pa_context)<tab><tab>self._pa_context = None",0,if self . is_ready :,if not self . is_terminated :,0.060348848,38.26029416,0.464285714
"def _hstack(self, other, prefix=None):<tab>""""""Join the columns of the other DataFrame to this one, assuming the ordering is the same""""""<tab>assert len(self) == len(<tab><tab>other<tab>), ""does not make sense to horizontally stack DataFrames with different lengths""<tab>for name in other.get_column_names():<tab><tab><IF-STMT><tab><tab><tab>new_name = prefix + name<tab><tab>else:<tab><tab><tab>new_name = name<tab><tab>self.add_column(new_name, other.columns[name])",1,if prefix :,if prefix :,0.531170663,1.00E-10,1
"def smart_linkflags(source, target, env, for_signature):<tab>if cplusplus.iscplusplus(source):<tab><tab>build_dir = env.subst(""$BUILDDIR"", target=target, source=source)<tab><tab><IF-STMT><tab><tab><tab>return ""-qtempinc="" + os.path.join(build_dir, ""tempinc"")<tab>return """"",1,if build_dir :,if build_dir :,0.531170663,1.00E-10,1
"def read(self, size):<tab>x = len(self.buf)<tab>while x < size:<tab><tab>raw = self.fileobj.read(self.blocksize)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>data = self.bz2obj.decompress(raw)<tab><tab>self.buf += data<tab><tab>x += len(data)<tab>buf = self.buf[:size]<tab>self.buf = self.buf[size:]<tab>self.pos += len(buf)<tab>return buf",1,if not raw :,if not raw :,0.75,100,1
"def set_ok_verifiability(self, cookie, request):<tab>if request.unverifiable and is_third_party(request):<tab><tab>if cookie.version > 0 and self.strict_rfc2965_unverifiable:<tab><tab><tab>_debug(""   third-party RFC 2965 cookie during "" ""unverifiable transaction"")<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>_debug(""   third-party Netscape cookie during "" ""unverifiable transaction"")<tab><tab><tab>return False<tab>return True",1,elif cookie . version == 0 and self . strict_ns_unverifiable :,elif cookie . version == 0 and self . strict_ns_unverifiable :,1,100,1
"def update_sockets(self, context):<tab>bools = [self.min_list, self.max_list, self.size_list]<tab>dims = int(self.dimensions[0])<tab>for i in range(3):<tab><tab>for j in range(3):<tab><tab><tab>out_index = 4 + j + 3 * i<tab><tab><tab>hidden = self.outputs[out_index].hide_safe<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if hidden:<tab><tab><tab><tab><tab>self.outputs[out_index].hide_safe = False<tab><tab><tab>else:<tab><tab><tab><tab>self.outputs[out_index].hide_safe = True<tab><tab>updateNode(self, context)",0,if bools [ i ] [ j ] and j < dims :,if j < dims :,0.091061646,14.2762397,0.25
"def hash_of_file(path):<tab>""""""Return the hash of a downloaded file.""""""<tab>with open(path, ""r"") as archive:<tab><tab>sha = sha256()<tab><tab>while True:<tab><tab><tab>data = archive.read(2 ** 20)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>sha.update(data)<tab>return encoded_hash(sha)",1,if not data :,if not data :,0.75,100,1
"def _compute_early_outs(self, quotas):<tab>for q in quotas:<tab><tab>if q.closed and not self._ignore_closed:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_ORDERED, 0<tab><tab>elif q.size is None:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_OK, None<tab><tab><IF-STMT><tab><tab><tab>self.results[q] = Quota.AVAILABILITY_GONE, 0",0,elif q . size == 0 :,elif q . gone and not self . _ignore_gone :,0.121979125,12.35622127,0.311111111
"def providers_for_config_string(config_string, netcode):<tab>providers = []<tab>for d in config_string.split():<tab><tab>p = provider_for_descriptor_and_netcode(d, netcode)<tab><tab><IF-STMT><tab><tab><tab>providers.append(p)<tab><tab>else:<tab><tab><tab>warnings.warn(""can't parse provider %s in config string"" % d)<tab>return providers",0,if p :,if p is not None :,0.090364769,1.00E-10,0.4
"def _get_plugin_value(self, feature, actor):<tab>for plugin in plugins.all(version=2):<tab><tab>handlers = safe_execute(plugin.get_feature_hooks, _with_transaction=False)<tab><tab>for handler in handlers or ():<tab><tab><tab>rv = handler(feature, actor)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return rv<tab>return None",1,if rv is not None :,if rv is not None :,0.75,100,1
"def test_digit_numeric_consistent(self):<tab># Test that digit and numeric are consistent,<tab># i.e. if a character has a digit value,<tab># its numeric value should be the same.<tab>count = 0<tab>for i in xrange(0x10000):<tab><tab>c = unichr(i)<tab><tab>dec = self.db.digit(c, -1)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(dec, self.db.numeric(c))<tab><tab><tab>count += 1<tab>self.assertTrue(count >= 10)  # should have tested at least the ASCII digits",1,if dec != - 1 :,if dec != - 1 :,0.75,100,1
"def call(command, title, retry):<tab>""""""Run a command-line program and display the result.""""""<tab>if Options.rerun_args:<tab><tab>command, title, retry = Options.rerun_args<tab><tab>Options.rerun_args = None<tab><tab>success = call(command, title, retry)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>print("""")<tab>print(""$ %s"" % "" "".join(command))<tab>failure = subprocess.call(command)<tab>if failure and retry:<tab><tab>Options.rerun_args = command, title, retry<tab>return not failure",1,if not success :,if not success :,0.75,100,1
"def handle_custom_actions(self):<tab>for _, action in CustomAction.registry.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if action.action not in self.parser.choices:<tab><tab><tab>self.parser.add_parser(action.action, help="""")<tab><tab>action(self.page).add_arguments(self.parser, self)",0,if action . resource != self . resource :,if action . action is None :,0.130089311,17.11271706,0.380952381
"def __init__(self, user, *args, **kwargs):<tab>self.user = user<tab>super(AccountSettingsForm, self).__init__(*args, **kwargs)<tab>if self.user.is_managed:<tab><tab># username and password always managed, email and<tab><tab># name optionally managed<tab><tab>for field in (""email"", ""name"", ""username""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.fields[field] = ReadOnlyTextField(label=self.fields[field].label)<tab><tab># don't show password field at all<tab><tab>del self.fields[""new_password""]<tab># don't show username field if its the same as their email address<tab>if self.user.email == self.user.username:<tab><tab>del self.fields[""username""]",0,"if field == ""username"" or field in settings . SENTRY_MANAGED_USER_FIELDS :",if field in self . fields :,0.124470518,3.066272774,0.321969697
"def eval(self, code, eval=True, raw=False):<tab>self._engine._append_source(code)<tab>try:<tab><tab>result = self._context.eval(code)<tab>except quickjs.JSException as e:<tab><tab>raise ProgramError(*e.args)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if raw or not isinstance(result, quickjs.Object):<tab><tab><tab><tab>return result<tab><tab><tab>elif callable(result) and self.typeof(result) == u""function"":<tab><tab><tab><tab>return self.Function(self, result)<tab><tab><tab>else:<tab><tab><tab><tab>return json.loads(result.json())",1,if eval :,if eval :,0.531170663,1.00E-10,1
"def get_def_offsets(self, defloc):<tab>""""""Get the byte offsets for a definition.""""""<tab>defn = self.defs[defloc.def_id]<tab>typ = defn.typ<tab>if typ == ""Attribute"":<tab><tab>start, end = self._get_attr_bounds(defn.name, defloc.location)<tab>else:<tab><tab>start = self.source.get_offset(defloc.location)<tab><tab><IF-STMT><tab><tab><tab>start += DEF_OFFSETS[typ]<tab><tab>end = start + len(defn.name)<tab>return (start, end)",1,if typ in DEF_OFFSETS :,if typ in DEF_OFFSETS :,0.75,100,1
"def RemoveRefCountOutput(data):<tab>while 1:<tab><tab>last_line_pos = data.rfind(""\n"")<tab><tab>if not re.match(""\[\d+ refs\]"", data[last_line_pos + 1 :]):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># All the output<tab><tab><tab>return """"<tab><tab>data = data[:last_line_pos]<tab>return data",0,if last_line_pos < 0 :,if last_line_pos == - 1 :,0.057429006,47.98782067,0.5
"def traverse_before_reduce(operator):<tab>""""""Internal traverse function""""""<tab>if isinstance(operator, tvm.te.PlaceholderOp):<tab><tab>return<tab>if tag.is_injective(operator.tag):<tab><tab>sch[operator].compute_inline()<tab><tab>for tensor in operator.input_tensors:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>traverse_before_reduce(tensor.op)<tab>else:<tab><tab>raise RuntimeError(""Unsupported operator: %s"" % operator.tag)<tab>scheduled_ops.append(operator)",0,if tensor . op not in scheduled_ops :,"if isinstance ( tensor . op , tvm . te . BatchNormOp ) :",0.060951009,12.01105543,0.1875
"def _get_config(key):<tab>config = db.session.execute(<tab><tab>Configs.__table__.select().where(Configs.key == key)<tab>).fetchone()<tab>if config and config.value:<tab><tab>value = config.value<tab><tab>if value and value.isdigit():<tab><tab><tab>return int(value)<tab><tab>elif value and isinstance(value, string_types):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>elif value.lower() == ""false"":<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return value<tab># Flask-Caching is unable to roundtrip a value of None.<tab># Return an exception so that we can still cache and avoid the db hit<tab>return KeyError",1,"if value . lower ( ) == ""true"" :","if value . lower ( ) == ""true"" :",0.75,100,1
"def find_executable(names):<tab># Given a list of executable names, find the first one that is available<tab># as an executable file, on the path.<tab>for name in names:<tab><tab>fpath, fname = os.path.split(name)<tab><tab>if fpath:<tab><tab><tab># The given name is absolute.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return name<tab><tab>else:<tab><tab><tab># Try to find the name on the PATH<tab><tab><tab>for path in os.environ[""PATH""].split(os.pathsep):<tab><tab><tab><tab>exe_file = os.path.join(path, name)<tab><tab><tab><tab>if is_executable(exe_file):<tab><tab><tab><tab><tab>return exe_file<tab># Could not find it :(<tab>return None",0,if is_executable ( name ) :,if is_executable ( fpath ) :,0.378267095,59.46035575,0.5
"def push(self):<tab>advice = self.check()<tab>if not self._context[""silent""]:<tab><tab><IF-STMT><tab><tab><tab>print(""No changes to push."")<tab><tab><tab>return<tab><tab>choice = input(""Continue? y/N:"")<tab><tab>if choice != ""y"":<tab><tab><tab>print(""Aborted on user command"")<tab><tab><tab>return<tab>print(""push local changes to remote..."")<tab>self._publish.syncRemote(self._context[""srcroot""], advice)",0,if not self . hasPendingSync ( advice ) :,if advice is None :,0.016838046,6.316906128,0.236111111
"def __init__(self, itemtype, cnf={}, *, master=None, **kw):<tab>if not master:<tab><tab><IF-STMT><tab><tab><tab>master = kw[""refwindow""]<tab><tab>elif ""refwindow"" in cnf:<tab><tab><tab>master = cnf[""refwindow""]<tab><tab>else:<tab><tab><tab>master = tkinter._default_root<tab><tab><tab>if not master:<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Too early to create display style: "" ""no root window""<tab><tab><tab><tab>)<tab>self.tk = master.tk<tab>self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))",1,"if ""refwindow"" in kw :","if ""refwindow"" in kw :",0.75,100,1
"def __call__(self, x, **kwargs):<tab>h = x<tab>for layer, argnames, accept_var_args in zip(<tab><tab>self.layers, self.argnames, self.accept_var_args<tab>):<tab><tab><IF-STMT><tab><tab><tab>layer_kwargs = kwargs<tab><tab>else:<tab><tab><tab>layer_kwargs = {k: v for k, v in kwargs.items() if k in argnames}<tab><tab>h = layer(h, **layer_kwargs)<tab>return h",1,if accept_var_args :,if accept_var_args :,0.531170663,1.00E-10,1
def run_train_loop(self):<tab>self.begin_training()<tab>for _ in self.yield_train_step():<tab><tab>if self.should_save_model():<tab><tab><tab>self.save_model()<tab><tab><IF-STMT><tab><tab><tab>self.save_checkpoint()<tab><tab>if self.should_eval_model():<tab><tab><tab>self.eval_model()<tab><tab>if self.should_break_training():<tab><tab><tab>break<tab>self.eval_model()<tab>self.done_training()<tab>return self.returned_result(),1,if self . should_save_checkpoint ( ) :,if self . should_save_checkpoint ( ) :,0.75,100,1
"def configure_callback(conf):<tab>""""""Received configuration information""""""<tab>global ZK_HOSTS<tab>for node in conf.children:<tab><tab><IF-STMT><tab><tab><tab>ZK_HOSTS = node.values[0].split("","")<tab><tab>else:<tab><tab><tab>collectd.warning(""zookeeper plugin: Unknown config key: %s."" % node.key)<tab>log(""Configured with hosts=%s"" % (ZK_HOSTS))",0,"if node . key == ""Hosts"" :","if node . key == ""hosts"" :",0.574113272,70.71067812,1
"def inner(self, *args, **kwargs):<tab>""""""Inner.""""""<tab>if not is_internet_available():<tab><tab>LOGGER.debug(""\n\n%s"", func.__name__)<tab><tab>LOGGER.debug(""============================"")<tab><tab><IF-STMT><tab><tab><tab>LOGGER.debug('"""""" %s """"""', func.__doc__.strip())<tab><tab>LOGGER.debug(""----------------------------"")<tab><tab>LOGGER.debug(""Skipping because no Internet connection available."")<tab><tab>LOGGER.debug(""\n++++++++++++++++++++++++++++"")<tab><tab>return None<tab>result = func(self, *args, **kwargs)<tab>return result",1,if func . __doc__ :,if func . __doc__ :,0.75,100,1
"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab>if ""disk_shares"" in subdevice:<tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice",0,"if ""disk_shares"" in plugin_result [ ""device"" ] :","if ""shares"" in plugin_result [ ""device"" ] :",0.605621306,77.21195505,1
"def register_auth_provider_blueprints(cls, app, prefix=""/auth/login""):<tab>app.auth_providers = []<tab>for provider in app.config.get(""AUTH_PROVIDERS"", [""debug"", ""oauth""]):<tab><tab><IF-STMT><tab><tab><tab>provider = cls._get_subclass_for(provider.lower())(name=provider, app=app)<tab><tab>app.register_blueprint(<tab><tab><tab>provider.blueprint, url_prefix=""/"".join((prefix, provider.name))<tab><tab>)<tab><tab>app.auth_providers.append(provider)",0,"if not isinstance ( provider , KnowledgeAuthProvider ) :",if provider . lower ( ) not in app . auth_providers :,0.016389141,4.444587795,0.213675214
"def getText(self, stuff):<tab>if isinstance(stuff, Fighter):<tab><tab>active = [x.name for x in stuff.abilities if x.active]<tab><tab><IF-STMT><tab><tab><tab>return ""None""<tab><tab>return "", "".join(active)",0,if len ( active ) == 0 :,if not active :,0.019930836,6.023021416,0.481481481
"def run(self, paths=[]):<tab>items = []<tab>for item in SideBarSelection(paths).getSelectedItems():<tab><tab>if item.isUnderCurrentProject():<tab><tab><tab>items.append(item.url(""url_production""))<tab>if len(items) > 0:<tab><tab>sublime.set_clipboard(""\n"".join(items))<tab><tab><IF-STMT><tab><tab><tab>sublime.status_message(""Items URL copied"")<tab><tab>else:<tab><tab><tab>sublime.status_message(""Item URL copied"")",1,if len ( items ) > 1 :,if len ( items ) > 1 :,0.75,100,1
"def read_boolean(file: BinaryIO, count: int, checkall: bool = False) -> List[bool]:<tab>if checkall:<tab><tab>all_defined = file.read(1)<tab><tab>if all_defined != unhexlify(""00""):<tab><tab><tab>return [True] * count<tab>result = []<tab>b = 0<tab>mask = 0<tab>for i in range(count):<tab><tab><IF-STMT><tab><tab><tab>b = ord(file.read(1))<tab><tab><tab>mask = 0x80<tab><tab>result.append(b & mask != 0)<tab><tab>mask >>= 1<tab>return result",0,if mask == 0 :,if b == 0 :,0.394778655,53.72849659,0.6
"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab>if k in comments:<tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab>if parts[0]:<tab><tab><tab>comments[single] = [parts[0]]<tab><tab>if len(parts) > 1:<tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab><IF-STMT><tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",0,if main in comments :,if main in lower :,0.394778655,42.72870064,0.666666667
"def _filter_medias_not_commented(self, media_items):<tab>not_commented_medias = []<tab>for media in media_items:<tab><tab>if media.get(""comment_count"", 0) > 0 and media.get(""comments""):<tab><tab><tab>my_comments = [<tab><tab><tab><tab>comment<tab><tab><tab><tab>for comment in media[""comments""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab><tab>if my_comments:<tab><tab><tab><tab>continue<tab><tab>not_commented_medias.append(media)<tab>return not_commented_medias",0,"if comment [ ""user_id"" ] == self . user_id","if comment . get ( ""comment_count"" , 0 ) > 0",0.026846793,6.471074162,0.476190476
"def run(url):<tab>import os<tab>for fpath in [<tab><tab>os.path.expanduser(""~/Applications/zeal.app""),<tab><tab>""/Applications/zeal.app"",<tab>]:<tab><tab><IF-STMT><tab><tab><tab>import subprocess, pipes<tab><tab><tab>pid = subprocess.Popen(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>fpath + ""/Contents/MacOS/zeal"",<tab><tab><tab><tab><tab>""--query={0}"".format(pipes.quote(url)),<tab><tab><tab><tab>],<tab><tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab><tab>stderr=subprocess.PIPE,<tab><tab><tab><tab>stdin=subprocess.PIPE,<tab><tab><tab>)<tab><tab><tab>return",1,"if os . path . exists ( fpath + ""/Contents/MacOS/zeal"" ) :","if os . path . exists ( fpath + ""/Contents/MacOS/zeal"" ) :",0.75,100,1
"def get_input_info(exec_info, network):<tab>input_dict = collections.OrderedDict()<tab>for v in exec_info.data_variable:<tab><tab>input_dict[v.variable_name] = []<tab>for v in network.variable:<tab><tab><IF-STMT><tab><tab><tab>shape = v.shape.dim<tab><tab><tab>input_dict[v.name] = [x if x > 0 else batch_size for x in shape]<tab>return input_dict",0,if v . name in input_dict :,"if hasattr ( v , ""shape"" ) and hasattr ( v , ""dim"" ) :",0.016345905,2.664321121,0.271428571
"def _clean_text(self, text):<tab>""""""Performs invalid character removal and whitespace cleanup on text.""""""<tab>output = []<tab>char_idx = []<tab>for i, char in enumerate(text):<tab><tab>cp = ord(char)<tab><tab>if cp == 0 or cp == 0xFFFD or _is_control(char):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>output.append("" "")<tab><tab><tab>char_idx.append(i)<tab><tab>else:<tab><tab><tab>output.append(char)<tab><tab><tab>char_idx.append(i)<tab>return """".join(output), char_idx",1,if _is_whitespace ( char ) :,if _is_whitespace ( char ) :,0.75,100,1
"def AddVersion(version, ns, versionId="""", isLegacy=0, serviceNs=""""):<tab>if not ns:<tab><tab>ns = serviceNs<tab>if version not in parentMap:<tab><tab>nsMap[version] = ns<tab><tab>if len(versionId) > 0:<tab><tab><tab>versionMap[ns + ""/"" + versionId] = version<tab><tab><IF-STMT><tab><tab><tab>versionMap[ns] = version<tab><tab>versionIdMap[version] = versionId<tab><tab>if not serviceNs:<tab><tab><tab>serviceNs = ns<tab><tab>serviceNsMap[version] = serviceNs<tab><tab>parentMap[version] = set()",0,"if isLegacy or ns is """" :",if isLegacy :,0.038857533,1.00E-10,0.428571429
"def set_accessible_async(self, trans, id=None, accessible=False):<tab>""""""Set workflow's importable attribute and slug.""""""<tab>stored = self.get_stored_workflow(trans, id)<tab># Only set if importable value would change; this prevents a change in the update_time unless attribute really changed.<tab>importable = accessible in [""True"", ""true"", ""t"", ""T""]<tab>if stored and stored.importable != importable:<tab><tab><IF-STMT><tab><tab><tab>self._make_item_accessible(trans.sa_session, stored)<tab><tab>else:<tab><tab><tab>stored.importable = importable<tab><tab>trans.sa_session.flush()<tab>return",1,if importable :,if importable :,0.531170663,1.00E-10,1
"def update(self, val, n=1):<tab>if val is not None:<tab><tab>self.val = val<tab><tab><IF-STMT><tab><tab><tab>self.sum = type_as(self.sum, val) + (val * n)<tab><tab><tab>self.count = type_as(self.count, n) + n",0,if n > 0 :,if self . sum is not None :,0.026407399,6.567274736,0.174603175
"def run(self, root):<tab>footnotesDiv = self.footnotes.makeFootnotesDiv(root)<tab>if footnotesDiv is not None:<tab><tab>result = self.footnotes.findFootnotesPlaceholder(root)<tab><tab><IF-STMT><tab><tab><tab>child, parent, isText = result<tab><tab><tab>ind = list(parent).index(child)<tab><tab><tab>if isText:<tab><tab><tab><tab>parent.remove(child)<tab><tab><tab><tab>parent.insert(ind, footnotesDiv)<tab><tab><tab>else:<tab><tab><tab><tab>parent.insert(ind + 1, footnotesDiv)<tab><tab><tab><tab>child.tail = None<tab><tab>else:<tab><tab><tab>root.append(footnotesDiv)",0,if result :,if result is not None :,0.090364769,1.00E-10,0.4
def ehp(self):<tab>if self.__ehp is None:<tab><tab><IF-STMT><tab><tab><tab>ehp = self.hp<tab><tab>else:<tab><tab><tab>ehp = self.damagePattern.calculateEhp(self)<tab><tab>self.__ehp = ehp<tab>return self.__ehp,0,if self . damagePattern is None :,if self . hp is not None :,0.249815883,27.05411345,0.475
"def literal(self):<tab>if self.peek('""'):<tab><tab>lit, lang, dtype = self.eat(r_literal).groups()<tab><tab>if lang:<tab><tab><tab>lang = lang<tab><tab>else:<tab><tab><tab>lang = None<tab><tab><IF-STMT><tab><tab><tab>dtype = dtype<tab><tab>else:<tab><tab><tab>dtype = None<tab><tab>if lang and dtype:<tab><tab><tab>raise ParseError(""Can't have both a language and a datatype"")<tab><tab>lit = unquote(lit)<tab><tab>return Literal(lit, lang, dtype)<tab>return False",1,if dtype :,if dtype :,0.531170663,1.00E-10,1
"def _purge(self, queue):<tab>""""""Remove all messages from `queue`.""""""<tab>count = 0<tab>queue_find = ""."" + queue + "".msg""<tab>folder = os.listdir(self.data_folder_in)<tab>while len(folder) > 0:<tab><tab>filename = folder.pop()<tab><tab>try:<tab><tab><tab># only purge messages for the requested queue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>filename = os.path.join(self.data_folder_in, filename)<tab><tab><tab>os.remove(filename)<tab><tab><tab>count += 1<tab><tab>except OSError:<tab><tab><tab># we simply ignore its existence, as it was probably<tab><tab><tab># processed by another worker<tab><tab><tab>pass<tab>return count",0,if filename . find ( queue_find ) < 0 :,if filename == queue_find :,0.02693381,16.40914928,0.571428571
"def check(data_dir, decrypter, read_only=False):<tab>fname = os.path.join(data_dir, DIGEST_NAME)<tab>if os.path.exists(fname):<tab><tab>if decrypter is None:<tab><tab><tab>return False<tab><tab>f = open(fname, ""rb"")<tab><tab>s = f.read()<tab><tab>f.close()<tab><tab>return decrypter.decrypt(s) == MAGIC_STRING<tab>else:<tab><tab><IF-STMT><tab><tab><tab>if read_only:<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>s = decrypter.encrypt(MAGIC_STRING)<tab><tab><tab><tab>f = open(fname, ""wb"")<tab><tab><tab><tab>f.write(s)<tab><tab><tab><tab>f.close()<tab><tab>return True",1,if decrypter is not None :,if decrypter is not None :,0.75,100,1
"def on_train_epoch_end(self, trainer, pl_module, outputs):<tab>epoch = trainer.current_epoch<tab>if self.unfreeze_backbone_at_epoch <= epoch:<tab><tab>optimizer = trainer.optimizers[0]<tab><tab>current_lr = optimizer.param_groups[0][""lr""]<tab><tab>backbone_lr = self.previous_backbone_lr<tab><tab><IF-STMT><tab><tab><tab>assert backbone_lr <= current_lr<tab><tab>else:<tab><tab><tab>assert backbone_lr == current_lr",0,if epoch < 6 :,if self . unfreeze_backbone_at_epoch <= epoch :,0.029730601,6.754312829,0.4
"def parse_rsync_url(location):<tab>""""""Parse a rsync-style URL.""""""<tab>if "":"" in location and ""@"" not in location:<tab><tab># SSH with no user@, zero or one leading slash.<tab><tab>(host, path) = location.split("":"", 1)<tab><tab>user = None<tab>elif "":"" in location:<tab><tab># SSH with user@host:foo.<tab><tab>user_host, path = location.split("":"", 1)<tab><tab><IF-STMT><tab><tab><tab>user, host = user_host.rsplit(""@"", 1)<tab><tab>else:<tab><tab><tab>user = None<tab><tab><tab>host = user_host<tab>else:<tab><tab>raise ValueError(""not a valid rsync-style URL"")<tab>return (user, host, path)",1,"if ""@"" in user_host :","if ""@"" in user_host :",0.75,100,1
"def populate_settings_dict(form, settings):<tab>new_settings = {}<tab>for key, value in iteritems(settings):<tab><tab>try:<tab><tab><tab># check if the value has changed<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>new_settings[key] = form[key].data<tab><tab>except KeyError:<tab><tab><tab>pass<tab>return new_settings",0,if value == form [ key ] . data :,if form [ key ] . data != value :,0.387184321,52.46341023,0.333333333
"def draw_boxes(image, boxes, scores=None, drop_score=0.5):<tab>if scores is None:<tab><tab>scores = [1] * len(boxes)<tab>for (box, score) in zip(boxes, scores):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>box = np.reshape(np.array(box), [-1, 1, 2]).astype(np.int64)<tab><tab>image = cv2.polylines(np.array(image), [box], True, (255, 0, 0), 2)<tab>return image",1,if score < drop_score :,if score < drop_score :,0.75,100,1
"def update(self, instance, validated_data):<tab>for category, category_data in validated_data.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.update_validated_settings(category_data)<tab><tab>for field_name, field_value in category_data.items():<tab><tab><tab>setattr(getattr(instance, category), field_name, field_value)<tab>return instance",0,if not category_data :,"if not hasattr ( instance , category ) :",0.062885015,11.33958222,0.454545455
"def insert(self, menuName, position, label, command, underline=None):<tab>menu = self.getMenu(menuName)<tab>if menu:<tab><tab><IF-STMT><tab><tab><tab>menu.insert(position, ""command"", label=label, command=command)<tab><tab>else:<tab><tab><tab>menu.insert(<tab><tab><tab><tab>position, ""command"", label=label, command=command, underline=underline<tab><tab><tab>)",1,if underline is None :,if underline is None :,0.75,100,1
"def delete_old_links():<tab>for doc in web.ctx.site.store.values(type=""account-link""):<tab><tab>expiry_date = datetime.strptime(doc[""expires_on""], ""%Y-%m-%dT%H:%M:%S.%f"")<tab><tab>now = datetime.utcnow()<tab><tab>key = doc[""_key""]<tab><tab><IF-STMT><tab><tab><tab>print(""Deleting link %s"" % (key))<tab><tab><tab>del web.ctx.site.store[key]<tab><tab>else:<tab><tab><tab>print(""Retaining link %s"" % (key))",1,if expiry_date > now :,if expiry_date > now :,0.75,100,1
"def _object(o: edgedb.Object):<tab>ret = {}<tab>for attr in dir(o):<tab><tab>try:<tab><tab><tab>link = o[attr]<tab><tab>except (KeyError, TypeError):<tab><tab><tab>link = None<tab><tab><IF-STMT><tab><tab><tab>ret[attr] = serialize(link)<tab><tab>else:<tab><tab><tab>ret[attr] = serialize(getattr(o, attr))<tab>return ret",1,if link :,if link :,0.531170663,1.00E-10,1
"def __init__(self, items):<tab>self._format = string.join(map(lambda item: item[0], items), """")<tab>self._items = items<tab>self._buffer_ = win32wnet.NCBBuffer(struct.calcsize(self._format))<tab>for format, name in self._items:<tab><tab>if len(format) == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = ""\0""<tab><tab><tab>else:<tab><tab><tab><tab>val = 0<tab><tab>else:<tab><tab><tab>l = int(format[:-1])<tab><tab><tab>val = ""\0"" * l<tab><tab>self.__dict__[name] = val",0,"if format == ""c"" :","if format [ - 1 ] == ""\n"" :",0.049758409,16.90062199,0.730769231
"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",0,if sty . italic :,if sty . underline :,0.394778655,42.72870064,0.6
"def get_from_target(target):<tab>domains = set()<tab>if isinstance(target, str):<tab><tab><IF-STMT><tab><tab><tab>logger.log(""FATAL"", ""Use targets parameter for multiple domain names"")<tab><tab><tab>exit(1)<tab><tab>domain = match_main_domain(target)<tab><tab>if not domain:<tab><tab><tab>return domains<tab><tab>domains.add(domain)<tab>return domains",0,"if target . endswith ( "".txt"" ) :",if target in domains :,0.035401841,7.121297465,0.481481481
"def iterate(self, prod_, rule_):<tab>newProduction = """"<tab>for i in range(len(prod_)):<tab><tab>step = self.production[i]<tab><tab><IF-STMT><tab><tab><tab>newProduction = newProduction + self.ruleW<tab><tab>elif step == ""X"":<tab><tab><tab>newProduction = newProduction + self.ruleX<tab><tab>elif step == ""Y"":<tab><tab><tab>newProduction = newProduction + self.ruleY<tab><tab>elif step == ""Z"":<tab><tab><tab>newProduction = newProduction + self.ruleZ<tab><tab>elif step != ""F"":<tab><tab><tab>newProduction = newProduction + step<tab>self.drawLength = self.drawLength * 0.5<tab>self.generations += 1<tab>return newProduction",1,"if step == ""W"" :","if step == ""W"" :",0.75,100,1
"def cancel_pp(self, nzo_id):<tab>""""""Change the status, so that the PP is canceled""""""<tab>for nzo in self.history_queue:<tab><tab><IF-STMT><tab><tab><tab>nzo.abort_direct_unpacker()<tab><tab><tab>if nzo.pp_active:<tab><tab><tab><tab>nzo.pp_active = False<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab># Try to kill any external running process<tab><tab><tab><tab><tab>self.external_process.kill()<tab><tab><tab><tab><tab>logging.info(<tab><tab><tab><tab><tab><tab>""Killed external process %s"", self.external_process.args[0]<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab>return None",1,if nzo . nzo_id == nzo_id :,if nzo . nzo_id == nzo_id :,1,100,1
"def list_backends(debug):<tab>for backend in sorted(<tab><tab>backends.getBackendList(), key=lambda backend: backend.identifier<tab>):<tab><tab><IF-STMT><tab><tab><tab>print(<tab><tab><tab><tab>""{:>15} : {} ({})"".format(<tab><tab><tab><tab><tab>backend.identifier, backend.__doc__, backend.__name__<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>print(""{:>15} : {}"".format(backend.identifier, backend.__doc__))",1,if debug :,if debug :,0.531170663,1.00E-10,1
"def _geo_indices(cls, inspected=None):<tab>inspected = inspected or []<tab>geo_indices = []<tab>inspected.append(cls)<tab>for field in cls._fields.values():<tab><tab><IF-STMT><tab><tab><tab>field_cls = field.document_type<tab><tab><tab>if field_cls in inspected:<tab><tab><tab><tab>continue<tab><tab><tab>if hasattr(field_cls, ""_geo_indices""):<tab><tab><tab><tab>geo_indices += field_cls._geo_indices(inspected)<tab><tab>elif field._geo_index:<tab><tab><tab>geo_indices.append(field)<tab>return geo_indices",1,"if hasattr ( field , ""document_type"" ) :","if hasattr ( field , ""document_type"" ) :",0.75,100,1
"def run_test_family(tests, mode_filter, files, open_func, *make_args):<tab>for test_func in tests:<tab><tab>if test_func is None:<tab><tab><tab>out.write(""\n"")<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for s in test_func.file_sizes:<tab><tab><tab>name, size = files[size_names[s]]<tab><tab><tab># name += file_ext<tab><tab><tab>args = tuple(f(name, size) for f in make_args)<tab><tab><tab>run_one_test(name, size, open_func, test_func, *args)",0,if mode_filter in test_func . file_open_mode :,if test_func . mode_filter is not mode_filter :,0.166182573,26.80332188,0.381818182
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100,1
"def _on_config_changed(self, option: str) -> None:<tab>if option in [""zoom.levels"", ""zoom.default""]:<tab><tab><IF-STMT><tab><tab><tab>factor = float(config.val.zoom.default) / 100<tab><tab><tab>self.set_factor(factor)<tab><tab>self._init_neighborlist()",0,if not self . _default_zoom_changed :,if config . val . zoom . default is not None :,0.021129018,5.30015669,0.161538462
"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab>if keyPressed == Constants.UP_KEY:<tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab>elif keyPressed == Constants.DOWN_KEY:<tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab>elif keyPressed == Constants.TAB_KEY and self.completerStrings:<tab><tab><tab>self.tabPressed()<tab><tab><IF-STMT><tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",0,if self . completerStrings :,elif keyPressed == Constants . TAB_KEY and self . completerStrings :,0.286326776,17.77835118,0.096153846
"def maxRange(self):<tab>attrs = (<tab><tab>""shieldTransferRange"",<tab><tab>""powerTransferRange"",<tab><tab>""energyDestabilizationRange"",<tab><tab>""empFieldRange"",<tab><tab>""ecmBurstRange"",<tab><tab>""maxRange"",<tab>)<tab>for attr in attrs:<tab><tab>maxRange = self.getModifiedItemAttr(attr, None)<tab><tab>if maxRange is not None:<tab><tab><tab>return maxRange<tab>if self.charge is not None:<tab><tab>delay = self.getModifiedChargeAttr(""explosionDelay"", None)<tab><tab>speed = self.getModifiedChargeAttr(""maxVelocity"", None)<tab><tab><IF-STMT><tab><tab><tab>return delay / 1000.0 * speed",0,if delay is not None and speed is not None :,if delay is not None :,0.43456795,43.45982085,0.535714286
"def decref(self, *keys):<tab>for tileable_key, tileable_id in keys:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>_graph_key, ids = self._executed_tileables[tileable_key]<tab><tab>if tileable_id in ids:<tab><tab><tab>ids.remove(tileable_id)<tab><tab><tab># for those same key tileables, do decref only when all those tileables are garbage collected<tab><tab><tab>if len(ids) != 0:<tab><tab><tab><tab>continue<tab><tab><tab>self.delete_data(tileable_key)",1,if tileable_key not in self . _executed_tileables :,if tileable_key not in self . _executed_tileables :,0.75,100,1
"def run(self):<tab># Make some objects emit lights<tab>for obj in bpy.context.scene.objects:<tab><tab>if ""modelId"" in obj:<tab><tab><tab>obj_id = obj[""modelId""]<tab><tab><tab># In the case of the lamp<tab><tab><tab>if obj_id in self.lights:<tab><tab><tab><tab>self._make_lamp_emissive(obj, self.lights[obj_id])<tab><tab><tab># Make the windows emit light<tab><tab><tab>if obj_id in self.windows:<tab><tab><tab><tab>self._make_window_emissive(obj)<tab><tab><tab># Also make ceilings slightly emit light<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._make_ceiling_emissive(obj)",0,"if obj . name . startswith ( ""Ceiling#"" ) :",if obj_id in self . ceilings :,0.014969815,7.270717734,0.25
"def _create_bucket(self):<tab>""""""Create remote S3 bucket if it doesn't exist""""""<tab>resource = boto3.resource(""s3"")<tab>try:<tab><tab>resource.meta.client.head_bucket(Bucket=self.bucket)<tab>except ClientError as e:<tab><tab>error_code = int(e.response[""Error""][""Code""])<tab><tab><IF-STMT><tab><tab><tab>resource.create_bucket(Bucket=self.bucket)<tab><tab>else:<tab><tab><tab>raise",1,if error_code == 404 :,if error_code == 404 :,0.75,100,1
"def sort_sizes(size_list):<tab>""""""Sorts sizes with extensions. Assumes that size is already in largest unit possible""""""<tab>final_list = []<tab>for suffix in ["" B"", "" KB"", "" MB"", "" GB"", "" TB""]:<tab><tab>sub_list = [<tab><tab><tab>float(size[: -len(suffix)])<tab><tab><tab>for size in size_list<tab><tab><tab>if size.endswith(suffix) and size[: -len(suffix)][-1].isnumeric()<tab><tab>]<tab><tab>sub_list.sort()<tab><tab>final_list += [(str(size) + suffix) for size in sub_list]<tab><tab># Skip additional loops<tab><tab><IF-STMT><tab><tab><tab>break<tab>return final_list",0,if len ( final_list ) == len ( size_list ) :,if len ( final_list ) > 1 :,0.332351502,36.25630027,0.666666667
"def rename_var(block: paddle.device.framework.Block, old_name: str, new_name: str):<tab>"""""" """"""<tab>for op in block.ops:<tab><tab>for input_name in op.input_arg_names:<tab><tab><tab>if input_name == old_name:<tab><tab><tab><tab>op._rename_input(old_name, new_name)<tab><tab>for output_name in op.output_arg_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>op._rename_output(old_name, new_name)<tab>block._rename_var(old_name, new_name)",1,if output_name == old_name :,if output_name == old_name :,0.75,100,1
"def _GetParserChains(self, events):<tab>""""""Return a dict with a plugin count given a list of events.""""""<tab>parser_chains = {}<tab>for event in events:<tab><tab>parser_chain = getattr(event, ""parser"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if parser_chain in parser_chains:<tab><tab><tab>parser_chains[parser_chain] += 1<tab><tab>else:<tab><tab><tab>parser_chains[parser_chain] = 1<tab>return parser_chains",0,if not parser_chain :,if parser_chain is None :,0.045150551,27.77619034,0.36
def context(self):<tab># Needed to avoid Translate Toolkit construct ID<tab># as context\04source<tab>if self.template is not None:<tab><tab><IF-STMT><tab><tab><tab>return self.template.id<tab><tab>if self.template.context:<tab><tab><tab>return self.template.context<tab><tab>return self.template.getid()<tab>return self.unescape_csv(self.mainunit.getcontext()),1,if self . template . id :,if self . template . id :,0.75,100,1
"def _validate_min_max_value(field_name, value, opt):<tab>if isinstance(value, (int, float)):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Invalid value %s assigned "" ""to field %s.\n"" % (value, field_name)<tab><tab><tab>)<tab>elif isinstance(value, str):<tab><tab>if len(value) < opt[""minValue""] or len(value) > opt[""maxValue""]:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Invalid value %s assigned "" ""to field %s.\n"" % (value, field_name)<tab><tab><tab>)",1,"if value < opt [ ""minValue"" ] or value > opt [ ""maxValue"" ] :","if value < opt [ ""minValue"" ] or value > opt [ ""maxValue"" ] :",0.75,100,1
"def _incr_internal(key, instance=None, tags=None, amount=1):<tab>from sentry.app import tsdb<tab>if _should_sample():<tab><tab>amount = _sampled_value(amount)<tab><tab><IF-STMT><tab><tab><tab>full_key = ""{}.{}"".format(key, instance)<tab><tab>else:<tab><tab><tab>full_key = key<tab><tab>try:<tab><tab><tab>tsdb.incr(tsdb.models.internal, full_key, count=amount)<tab><tab>except Exception:<tab><tab><tab>logger = logging.getLogger(""sentry.errors"")<tab><tab><tab>logger.exception(""Unable to incr internal metric"")",1,if instance :,if instance :,0.531170663,1.00E-10,1
"def get(self, key, default=None, version=None):<tab>key = self.make_key(key, version=version)<tab>self.validate_key(key)<tab>fname = self._key_to_file(key)<tab>try:<tab><tab>with open(fname, ""rb"") as f:<tab><tab><tab>exp = pickle.load(f)<tab><tab><tab>now = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._delete(fname)<tab><tab><tab>else:<tab><tab><tab><tab>return pickle.load(f)<tab>except (IOError, OSError, EOFError, pickle.PickleError):<tab><tab>pass<tab>return default",1,if exp < now :,if exp < now :,0.75,100,1
"def on_execution_scenario(self, cpath, scenario):<tab>if isinstance(scenario, dict):<tab><tab>self.check_scenario(cpath, scenario)<tab>elif isinstance(scenario, str):<tab><tab>scenario_name = scenario<tab><tab>scenario_path = Path(""scenarios"", scenario_name)<tab><tab>scenario = self.linter.get_config_value(scenario_path, raise_if_not_found=False)<tab><tab><IF-STMT><tab><tab><tab>self.report(<tab><tab><tab><tab>ConfigWarning.ERROR,<tab><tab><tab><tab>""undefined-scenario"",<tab><tab><tab><tab>cpath,<tab><tab><tab><tab>""scenario %r is used but isn't defined"" % scenario_name,<tab><tab><tab>)",0,if not scenario :,if scenario is None :,0.045150551,14.05853313,0.277777778
"def getSubmitKey(request, response):<tab>titleId = request.bits[2]<tab>titleKey = request.bits[3]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return success(request, response, ""Key successfully added"")<tab><tab>else:<tab><tab><tab>return error(request, response, ""Key validation failed"")<tab>except LookupError as e:<tab><tab>error(request, response, str(e))<tab>except OSError as e:<tab><tab>error(request, response, str(e))<tab>except BaseException as e:<tab><tab>error(request, response, str(e))",0,"if blockchain . blockchain . suggest ( titleId , titleKey ) :","if addKey ( request , titleId , titleKey ) :",0.177284281,34.98330125,0.240384615
"def test_downstream_trials(trial_associated_artifact, trial_obj, sagemaker_session):<tab># allow trial components to index, 30 seconds max<tab>for i in range(3):<tab><tab>time.sleep(10)<tab><tab>trials = trial_associated_artifact.downstream_trials(<tab><tab><tab>sagemaker_session=sagemaker_session<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>assert len(trials) == 1<tab>assert trial_obj.trial_name in trials",0,if len ( trials ) > 0 :,if len ( trials ) == 0 :,0.549040681,51.3345048,1
"def get_subfield_asts(context, return_type, field_asts):<tab>subfield_asts = DefaultOrderedDict(list)<tab>visited_fragment_names = set()<tab>for field_ast in field_asts:<tab><tab>selection_set = field_ast.selection_set<tab><tab><IF-STMT><tab><tab><tab>subfield_asts = collect_fields(<tab><tab><tab><tab>context,<tab><tab><tab><tab>return_type,<tab><tab><tab><tab>selection_set,<tab><tab><tab><tab>subfield_asts,<tab><tab><tab><tab>visited_fragment_names,<tab><tab><tab>)<tab>return subfield_asts",0,if selection_set :,if selection_set is not None and selection_set != visited_fragment_names :,0.203827156,1.00E-10,0.285714286
"def _handle_children(self, removed, added):<tab># Stop all the removed children.<tab>for obj in removed:<tab><tab>obj.stop()<tab># Process the new objects.<tab>for obj in added:<tab><tab>obj.set(scene=self.scene, parent=self)<tab><tab><IF-STMT><tab><tab><tab>obj.source = self<tab><tab>elif is_filter(obj):<tab><tab><tab>obj.inputs.append(self)<tab><tab>if self.running:<tab><tab><tab>try:<tab><tab><tab><tab>obj.start()<tab><tab><tab>except:<tab><tab><tab><tab>exception()",0,"if isinstance ( obj , ModuleManager ) :",if is_source ( obj ) :,0.046109016,16.51582159,0.36
"def __kmp_search(S, W):<tab>m = 0<tab>i = 0<tab>T = __kmp_table(W)<tab>while m + i < len(S):<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>if i == len(W):<tab><tab><tab><tab>yield m<tab><tab><tab><tab>m += i - T[i]<tab><tab><tab><tab>i = max(T[i], 0)<tab><tab>else:<tab><tab><tab>m += i - T[i]<tab><tab><tab>i = max(T[i], 0)",1,if S [ m + i ] == W [ i ] :,if S [ m + i ] == W [ i ] :,1,100,1
"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>if self._pending_connection is None:<tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab>if commit_on_success and self.can_commit:<tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab>if not self._bulk_commit:<tab><tab><tab><tab>con.close()",1,if self . _bulk_commit :,if self . _bulk_commit :,0.75,100,1
"def passed(self):<tab>for test in self.lints[0]:<tab><tab>for template in self.lints[0][test][""results""]:<tab><tab><tab>results = self.lints[0][test][""results""][template]<tab><tab><tab>if results:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab>return True",0,if self . _is_error ( results ) or self . strict :,"if not self . lints [ 0 ] [ test ] [ ""results"" ] :",0.070161855,5.75139181,0.2
"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab>if i == 254:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab>elif i == 1000:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab>elif i == 65534:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",0,elif i == 255 :,elif i == 100 :,0.642872021,53.72849659,0.6
"def _DecodeUnknownMessages(message, encoded_message, pair_type):<tab>""""""Process unknown fields in encoded_message of a message type.""""""<tab>field_type = pair_type.value.type<tab>new_values = []<tab>all_field_names = [x.name for x in message.all_fields()]<tab>for name, value_dict in encoded_message.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = PyValueToMessage(field_type, value_dict)<tab><tab>new_pair = pair_type(key=name, value=value)<tab><tab>new_values.append(new_pair)<tab>return new_values",1,if name in all_field_names :,if name in all_field_names :,0.75,100,1
"def test_apply_noise_model():<tab>p = Program(RX(np.pi / 2, 0), RX(np.pi / 2, 1), CZ(0, 1), RX(np.pi / 2, 1))<tab>noise_model = _decoherence_noise_model(_get_program_gates(p))<tab>pnoisy = apply_noise_model(p, noise_model)<tab>for i in pnoisy:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif isinstance(i, Pragma):<tab><tab><tab>assert i.command in [""ADD-KRAUS"", ""READOUT-POVM""]<tab><tab>elif isinstance(i, Gate):<tab><tab><tab>assert i.name in NO_NOISE or not i.params",0,"if isinstance ( i , DefGate ) :","if isinstance ( i , int ) :",0.299040681,59.46035575,0.666666667
"def i2h(self, pkt, x):<tab>if x is not None:<tab><tab>if x < 0:<tab><tab><tab>warning(""Fixed3_7: Internal value too negative: %d"" % x)<tab><tab><tab>x = 0<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_7: Internal value too positive: %d"" % x)<tab><tab><tab>x = 3600000000<tab><tab>x = (x - 1800000000) * 1e-7<tab>return x",1,elif x > 3600000000 :,elif x > 3600000000 :,0.75,100,1
def onClicked(event):<tab>shaderConfig = dict()<tab>for child in self.shaderDefBox.children:<tab><tab>defName = child.shaderDefine<tab><tab>enabled = child.isChecked()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>mat.addShaderDefine(defName)<tab><tab><tab>else:<tab><tab><tab><tab>mat.removeShaderDefine(defName)<tab><tab>except:<tab><tab><tab>pass<tab># Reload material properties (update enabled states) and shader uniforms<tab>self.listUniforms(mat)<tab>self.listMaterialSettings(self.getSelectedObject()),1,if enabled :,if enabled :,0.531170663,1.00E-10,1
"def is_mod(self, member: discord.Member) -> bool:<tab>""""""Checks if a member is a mod or admin of their guild.""""""<tab>try:<tab><tab>member_snowflakes = member._roles  # DEP-WARN<tab><tab>for snowflake in await self._config.guild(member.guild).admin_role():<tab><tab><tab><IF-STMT>  # DEP-WARN<tab><tab><tab><tab>return True<tab><tab>for snowflake in await self._config.guild(member.guild).mod_role():<tab><tab><tab>if member_snowflakes.has(snowflake):  # DEP-WARN<tab><tab><tab><tab>return True<tab>except AttributeError:  # someone passed a webhook to this<tab><tab>pass<tab>return False",1,if member_snowflakes . has ( snowflake ) :,if member_snowflakes . has ( snowflake ) :,0.75,100,1
"def _verify_treestore(itr, tree_values):<tab>i = 0<tab>while itr:<tab><tab>values = tree_values[i]<tab><tab>if treestore[itr][0] != values[0]:<tab><tab><tab>return False<tab><tab>if treestore.iter_children(itr):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>itr = treestore.iter_next(itr)<tab><tab>i += 1<tab>return True",0,"if not _verify_treestore ( treestore . iter_children ( itr ) , values [ 1 ] ) :",if values [ 0 ] != values [ 0 ] :,0.051378821,3.701296069,0.244565217
"def _default_config(self):<tab>if sys.platform.startswith(""win""):<tab><tab>return {""name"": ""Command Prompt"", ""cmd"": ""cmd.exe"", ""env"": {}}<tab>else:<tab><tab><IF-STMT><tab><tab><tab>shell = os.environ[""SHELL""]<tab><tab><tab>if os.path.basename(shell) == ""tcsh"":<tab><tab><tab><tab>cmd = [shell, ""-l""]<tab><tab><tab>else:<tab><tab><tab><tab>cmd = [shell, ""-i"", ""-l""]<tab><tab>else:<tab><tab><tab>cmd = [""/bin/bash"", ""-i"", ""-l""]<tab><tab>return {""name"": ""Login Shell"", ""cmd"": cmd, ""env"": {}}",1,"if ""SHELL"" in os . environ :","if ""SHELL"" in os . environ :",0.75,100,1
"def _messageHandled(self, resultList):<tab>failures = 0<tab>for (success, result) in resultList:<tab><tab><IF-STMT><tab><tab><tab>failures += 1<tab><tab><tab>log.err(result)<tab>if failures:<tab><tab>msg = ""Could not send e-mail""<tab><tab>resultLen = len(resultList)<tab><tab>if resultLen > 1:<tab><tab><tab>msg += "" ({} failures out of {} recipients)"".format(failures, resultLen)<tab><tab>self.sendCode(550, networkString(msg))<tab>else:<tab><tab>self.sendCode(250, b""Delivery in progress"")",1,if not success :,if not success :,0.75,100,1
"def to_internal_value(self, data):<tab>site = get_current_site()<tab>pages_root = reverse(""pages-root"")<tab>ret = []<tab>for path in data:<tab><tab>if path.startswith(pages_root):<tab><tab><tab>path = path[len(pages_root) :]<tab><tab># strip any final slash<tab><tab><IF-STMT><tab><tab><tab>path = path[:-1]<tab><tab>page = get_page_from_path(site, path)<tab><tab>if page:<tab><tab><tab>ret.append(page)<tab>return ret",0,"if path . endswith ( ""/"" ) :","if path [ - 1 ] == ""/"" :",0.03384241,16.59038701,0.6
"def _prune(self):<tab>with self.lock:<tab><tab>entries = self._list_dir()<tab><tab>if len(entries) > self._threshold:<tab><tab><tab>now = time.time()<tab><tab><tab>try:<tab><tab><tab><tab>for i, fpath in enumerate(entries):<tab><tab><tab><tab><tab>remove = False<tab><tab><tab><tab><tab>f = LockedFile(fpath, ""rb"")<tab><tab><tab><tab><tab>exp = pickle.load(f.file)<tab><tab><tab><tab><tab>f.close()<tab><tab><tab><tab><tab>remove = exp <= now or i % 3 == 0<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self._del_file(fpath)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",1,if remove :,if remove :,0.531170663,1.00E-10,1
"def get_ax_arg(uri):<tab>if not ax_ns:<tab><tab>return u""""<tab>prefix = ""openid."" + ax_ns + "".type.""<tab>ax_name = None<tab>for name in self.request.arguments.keys():<tab><tab><IF-STMT><tab><tab><tab>part = name[len(prefix) :]<tab><tab><tab>ax_name = ""openid."" + ax_ns + "".value."" + part<tab><tab><tab>break<tab>if not ax_name:<tab><tab>return u""""<tab>return self.get_argument(ax_name, u"""")",0,if self . get_argument ( name ) == uri and name . startswith ( prefix ) :,if name . startswith ( prefix ) :,0.29005772,19.39986756,0.227272727
"def _generate_expression(self):<tab># turn my _format attribute into the _expression attribute<tab>e = []<tab>for part in PARSE_RE.split(self._format):<tab><tab>if not part:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>e.append(r""\{"")<tab><tab>elif part == ""}}"":<tab><tab><tab>e.append(r""\}"")<tab><tab>elif part[0] == ""{"" and part[-1] == ""}"":<tab><tab><tab># this will be a braces-delimited field to handle<tab><tab><tab>e.append(self._handle_field(part))<tab><tab>else:<tab><tab><tab># just some text to match<tab><tab><tab>e.append(REGEX_SAFETY.sub(self._regex_replace, part))<tab>return """".join(e)",0,"elif part == ""{{"" :","elif part == ""{"" :",0.642872021,74.20884819,1
"def get_clean_username(user):<tab>try:<tab><tab>username = force_text(user)<tab>except AttributeError:<tab><tab># AnonymousUser may not have USERNAME_FIELD<tab><tab>username = ""anonymous""<tab>else:<tab><tab># limit changed_by and created_by to avoid problems with Custom User Model<tab><tab><IF-STMT><tab><tab><tab>username = u""{0}... (id={1})"".format(<tab><tab><tab><tab>username[: PAGE_USERNAME_MAX_LENGTH - 15],<tab><tab><tab><tab>user.pk,<tab><tab><tab>)<tab>return username",1,if len ( username ) > PAGE_USERNAME_MAX_LENGTH :,if len ( username ) > PAGE_USERNAME_MAX_LENGTH :,0.75,100,1
"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab>if is_text_payload(request) and request.body:<tab><tab><tab>try:<tab><tab><tab><tab>body = (<tab><tab><tab><tab><tab>str(request.body, ""utf-8"")<tab><tab><tab><tab><tab>if isinstance(request.body, bytes)<tab><tab><tab><tab><tab>else str(request.body)<tab><tab><tab><tab>)<tab><tab><tab>except TypeError:  # python 2 doesn't allow decoding through str<tab><tab><tab><tab>body = str(request.body)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",0,if old in body :,if body :,0.067674239,1.00E-10,0.3
"def get_config_variable(self, name, methods=(""env"", ""config""), default=None):<tab>value = None<tab>config_name, envvar_name = self.session_var_map[name]<tab>if methods is not None:<tab><tab>if ""env"" in methods and value is None:<tab><tab><tab>value = os.environ.get(envvar_name)<tab><tab><IF-STMT><tab><tab><tab>value = self.config_file_vars.get(config_name)<tab>else:<tab><tab>value = default<tab>return value",0,"if ""config"" in methods and value is None :","elif ""config"" in methods and value is None :",0.591284199,89.31539818,0.777777778
"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab>if not f:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>obj = obj.dereference()<tab><tab>elif f == ""."":<tab><tab><tab>pass<tab><tab>elif f.startswith(""[""):<tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj",0,"if f == ""->"" :","elif f == ""-"" :",0.058575651,52.47357978,0.5
"def read_subpkgdata_dict(pkg, d):<tab>ret = {}<tab>subd = read_pkgdatafile(get_subpkgedata_fn(pkg, d))<tab>for var in subd:<tab><tab>newvar = var.replace(""_"" + pkg, """")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>ret[newvar] = subd[var]<tab>return ret",0,"if newvar == var and var + ""_"" + pkg in subd :",if not newvar . startswith ( pkg ) :,0.011544942,3.097704314,0.176923077
"def _classify_volume(self, ctxt, volumes):<tab>bypass_volumes = []<tab>replica_volumes = []<tab>for v in volumes:<tab><tab>volume_type = self._get_volume_replicated_type(ctxt, v)<tab><tab>grp = v.group<tab><tab>if grp and utils.is_group_a_type(grp, ""consistent_group_replication_enabled""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>replica_volumes.append(v)<tab><tab>else:<tab><tab><tab>bypass_volumes.append(v)<tab>return bypass_volumes, replica_volumes",0,"elif volume_type and v . status in [ ""available"" , ""in-use"" ] :","if volume_type == ""replica"" :",0.007844225,7.55205501,0.114285714
"def _ensure_entity_values(self):<tab>entities_values = {<tab><tab>entity.name: self._get_entity_values(entity) for entity in self.entities<tab>}<tab>for intent in self.intents:<tab><tab>for utterance in intent.utterances:<tab><tab><tab>for chunk in utterance.slot_chunks:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>chunk.text = next(entities_values[chunk.entity])<tab><tab><tab><tab>except StopIteration:<tab><tab><tab><tab><tab>raise DatasetFormatError(<tab><tab><tab><tab><tab><tab>""At least one entity value must be provided for ""<tab><tab><tab><tab><tab><tab>""entity '%s'"" % chunk.entity<tab><tab><tab><tab><tab>)<tab>return self",0,if chunk . text is not None :,if chunk . entity not in entities_values :,0.329919566,17.74740528,0.311111111
"def _consume_msg(self):<tab>async for data in self._stream:<tab><tab>stream = data.get(""ev"")<tab><tab>if stream:<tab><tab><tab>await self._dispatch(data)<tab><tab><IF-STMT><tab><tab><tab># Polygon returns this on an empty 'ev' id..<tab><tab><tab>data[""ev""] = ""status""<tab><tab><tab>await self._dispatch(data)<tab><tab><tab>raise ConnectionResetError(<tab><tab><tab><tab>""Polygon terminated connection: "" f'({data.get(""message"")})'<tab><tab><tab>)",0,"elif data . get ( ""status"" ) == ""disconnected"" :","elif ""status"" in data :",0.014450063,9.271103732,0.4
"def GetHeaderWidth(self):<tab>""""""Returns the header window width, in pixels.""""""<tab>if not self._headerWidth:<tab><tab>count = self.GetColumnCount()<tab><tab>for col in range(count):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self._headerWidth += self.GetColumnWidth(col)<tab>if self.HasAGWFlag(ULC_FOOTER):<tab><tab>self._footerWidth = self._headerWidth<tab>return self._headerWidth",0,if not self . IsColumnShown ( col ) :,if self . HasAGWFlag (ULC_FOOTER ) :,0.039654234,13.13454947,0.257142857
"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab>elif i == 255:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab>elif i == 1000:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab>elif i == 65534:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",0,if i == 254 :,if i == 0 :,0.394778655,53.72849659,0.6
"def childrenTodo(self, p=None):<tab>if p is None:<tab><tab>p = self.c.currentPosition()<tab>for p in p.children():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.setat(p.v, ""priority"", 19)<tab><tab>self.loadIcons(p)",0,"if self . getat ( p . v , ""priority"" ) != 9999 :",if p . v is None :,0.038926375,6.656592803,0.215686275
"def __init__(self, **kwargs):<tab>super(DepthwiseSeparableASPPModule, self).__init__(**kwargs)<tab>for i, dilation in enumerate(self.dilations):<tab><tab><IF-STMT><tab><tab><tab>self[i] = DepthwiseSeparableConvModule(<tab><tab><tab><tab>self.in_channels,<tab><tab><tab><tab>self.channels,<tab><tab><tab><tab>3,<tab><tab><tab><tab>dilation=dilation,<tab><tab><tab><tab>padding=dilation,<tab><tab><tab><tab>norm_cfg=self.norm_cfg,<tab><tab><tab><tab>act_cfg=self.act_cfg,<tab><tab><tab>)",0,if dilation > 1 :,"if isinstance ( dilation , int ) :",0.02800146,7.267884212,0.314814815
"def test_char(self):<tab>for x in range(256):<tab><tab>c = System.Char.Parse(chr(x))<tab><tab>self.assertEqual(c, chr(x))<tab><tab>self.assertEqual(chr(x), c)<tab><tab>if c == chr(x):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.assertTrue(False)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(False)<tab><tab>if chr(x) == c:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.assertTrue(False)<tab><tab>if not chr(x) == c:<tab><tab><tab>self.assertTrue(False)",0,if not c == chr ( x ) :,if c == chr ( x ) :,0.464588137,79.56371662,0.314814815
"def create_model_handler(ns, model_type):<tab>@route(f""/<provider>/{ns}/<model_id>"")<tab>@use_provider<tab>def handle(req, provider, model_id):<tab><tab># special cases:<tab><tab># fuo://<provider>/users/me -> show current logged user<tab><tab><IF-STMT><tab><tab><tab>if model_id == ""me"":<tab><tab><tab><tab>user = getattr(provider, ""_user"", None)<tab><tab><tab><tab>if user is None:<tab><tab><tab><tab><tab>raise CmdException(f""log in provider:{provider.identifier} first"")<tab><tab><tab><tab>return user<tab><tab>model = get_model_or_raise(provider, model_type, model_id)<tab><tab>return model",0,if model_type == ModelType . user :,"if model_id == ""users"" :",0.023846651,20.55668085,0.45
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_key_:<tab><tab>res += prefix + (""key: %s\n"" % self.DebugFormatString(self.key_))<tab>cnt = 0<tab>for e in self.value_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""value%s: %s\n"" % (elm, self.DebugFormatString(e)))<tab><tab>cnt += 1<tab>if self.has_partial_:<tab><tab>res += prefix + (""partial: %s\n"" % self.DebugFormatBool(self.partial_))<tab>return res",1,if printElemNumber :,if printElemNumber :,0.531170663,1.00E-10,1
"def set_value_type_index(self, rows: list, value_type_index: int):<tab>for row in rows:<tab><tab>label = self.message_type[row]<tab><tab><IF-STMT><tab><tab><tab>label.value_type_index = value_type_index<tab><tab><tab>self.protocol_label_updated.emit(label)<tab>self.update()",0,if not label . is_checksum_label :,if label . value_type_index != value_type_index :,0.047631794,6.437165254,0.472222222
"def get_model_param(self, job_id, cpn_name, role, party_id):<tab>result = None<tab>party_id = str(party_id)<tab>try:<tab><tab>result = self.client.component.output_model(<tab><tab><tab>job_id=job_id, role=role, party_id=party_id, component_name=cpn_name<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>f""job {job_id}, component {cpn_name} has no output model param""<tab><tab><tab>)<tab><tab>return result[""data""]<tab>except:<tab><tab>raise ValueError(""Cannot get output model, err msg: "")",1,"if ""data"" not in result :","if ""data"" not in result :",0.75,100,1
"def validate(self) -> None:<tab>if self.query:<tab><tab>if not self.sysupgrade:<tab><tab><tab>for arg_name in (""aur"", ""repo""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise MissingArgument(""sysupgrade"", arg_name)",0,"if getattr ( self , arg_name ) :",if arg_name not in self . query :,0.020373037,18.575058,0.25
"def print_nested_help(self, args: argparse.Namespace) -> None:<tab>level = 0<tab>parser = self.main_parser<tab>while True:<tab><tab>if parser._subparsers is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>choices = parser._subparsers._actions[-1].choices<tab><tab>value = getattr(args, ""level_%d"" % level)<tab><tab>if value is None:<tab><tab><tab>parser.print_help()<tab><tab><tab>return<tab><tab>if not choices:<tab><tab><tab>break<tab><tab>if isinstance(choices, dict):<tab><tab><tab>parser = choices[value]<tab><tab>else:<tab><tab><tab>return<tab><tab>level += 1",0,if parser . _subparsers . _actions is None :,if not parser . _subparsers . _actions :,0.248022913,61.5628698,0.318181818
"def merge(self, abort=False, message=None):<tab>""""""Merge remote branch or reverts the merge.""""""<tab>if abort:<tab><tab>self.execute([""update"", ""--clean"", "".""])<tab>elif self.needs_merge():<tab><tab>if self.needs_ff():<tab><tab><tab>self.execute([""update"", ""--clean"", ""remote(.)""])<tab><tab>else:<tab><tab><tab>self.configure_merge()<tab><tab><tab># Fallback to merge<tab><tab><tab>try:<tab><tab><tab><tab>self.execute([""merge"", ""-r"", ""remote(.)""])<tab><tab><tab>except RepositoryException as error:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># Nothing to merge<tab><tab><tab><tab><tab>return<tab><tab><tab><tab>raise<tab><tab><tab>self.execute([""commit"", ""--message"", ""Merge""])",0,if error . retcode == 255 :,if error . status == 404 :,0.344478934,27.05411345,0.428571429
"def parseArtistIds(cls, page):<tab>ids = list()<tab>js = demjson.decode(page)<tab>if ""error"" in js and js[""error""]:<tab><tab>raise PixivException(""Error when requesting Fanbox"", 9999, page)<tab>if ""body"" in js and js[""body""] is not None:<tab><tab>js_body = js[""body""]<tab><tab><IF-STMT><tab><tab><tab>js_body = js_body[""supportingPlans""]<tab><tab>for creator in js_body:<tab><tab><tab>ids.append(creator[""user""][""userId""])<tab>return ids",0,"if ""supportingPlans"" in js [ ""body"" ] :","if ""supportingPlans"" in js_body :",0.078889319,45.22723476,0.727272727
"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab>if other not in self.ignoreExprs:<tab><tab><tab>super().ignore(other)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super().ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",1,if self . expr is not None :,if self . expr is not None :,0.75,100,1
"def execute(self):<tab>func = self.func<tab>is_batch_func = getattr(func, ""_task_batch"", False)<tab>g[""current_task_is_batch""] = is_batch_func<tab>g[""current_tasks""] = [self]<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return func([{""args"": self.args, ""kwargs"": self.kwargs}])<tab><tab>else:<tab><tab><tab>return func(*self.args, **self.kwargs)<tab>finally:<tab><tab>g[""current_task_is_batch""] = None<tab><tab>g[""current_tasks""] = None",1,if is_batch_func :,if is_batch_func :,0.531170663,1.00E-10,1
"def fn(value=None):<tab>for i in [-1, 0, 1, 2, 3, 4]:<tab><tab>if i < 0:<tab><tab><tab>continue<tab><tab>elif i == 0:<tab><tab><tab>yield 0<tab><tab><IF-STMT><tab><tab><tab>yield 1<tab><tab><tab>i = 0<tab><tab><tab>yield value<tab><tab><tab>yield 2<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>v = i / value<tab><tab><tab>except:<tab><tab><tab><tab>v = i<tab><tab><tab>yield v",1,elif i == 1 :,elif i == 1 :,1,100,1
"def get_instrumentation_key(url):<tab>data = url.split(""//"")[1]<tab>try:<tab><tab>uuid.UUID(data)<tab>except ValueError:<tab><tab>values = data.split(""/"")<tab><tab><IF-STMT><tab><tab><tab>AppInsightsHelper.log.warning(""Bad format: '%s'"" % url)<tab><tab>return AppInsightsHelper._get_instrumentation_key(values[0], values[1])<tab>return data",1,if len ( values ) != 2 :,if len ( values ) != 2 :,0.75,100,1
"def get_correct(ngrams_ref, ngrams_test, correct, total):<tab>for rank in ngrams_test:<tab><tab>for chain in ngrams_test[rank]:<tab><tab><tab>total[rank] += ngrams_test[rank][chain]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>correct[rank] += min(ngrams_test[rank][chain], ngrams_ref[rank][chain])<tab>return correct, total",0,if chain in ngrams_ref [ rank ] :,if len ( ngrams_test [ rank ] [ chain ] ) > 0 :,0.104644974,12.87433051,0.278195489
"def _content_type_params__set(self, value_dict):<tab>if not value_dict:<tab><tab>del self.content_type_params<tab><tab>return<tab>params = []<tab>for k, v in sorted(value_dict.items()):<tab><tab><IF-STMT><tab><tab><tab>v = '""%s""' % v.replace('""', '\\""')<tab><tab>params.append(""; %s=%s"" % (k, v))<tab>ct = self.headers.pop(""Content-Type"", """").split("";"", 1)[0]<tab>ct += """".join(params)<tab>self.headers[""Content-Type""] = ct",0,if not _OK_PARAM_RE . search ( v ) :,"if isinstance ( v , str ) :",0.039409056,7.80152171,0.285714286
"def split_file(self, filename, block_size=2 ** 20):<tab>with open(filename, ""rb"") as f:<tab><tab>file_list = []<tab><tab>while True:<tab><tab><tab>data = f.read(block_size)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>filehash = os.path.join(self.resource_dir, self.__count_hash(data))<tab><tab><tab>filehash = os.path.normpath(filehash)<tab><tab><tab>with open(filehash, ""wb"") as fwb:<tab><tab><tab><tab>fwb.write(data)<tab><tab><tab>file_list.append(filehash)<tab>return file_list",1,if not data :,if not data :,0.75,100,1
"def _set_live(self, live, _):<tab>if live is not None and not self.live:<tab><tab>if isinstance(live, basestring):<tab><tab><tab>live = [live]<tab><tab># Default is to use Memory analysis.<tab><tab>if len(live) == 0:<tab><tab><tab>mode = ""Memory""<tab><tab><IF-STMT><tab><tab><tab>mode = live[0]<tab><tab>else:<tab><tab><tab>raise RuntimeError(""--live parameter should specify only one mode."")<tab><tab>live_plugin = self.session.plugins.live(mode=mode)<tab><tab>live_plugin.live()<tab><tab># When the session is destroyed, close the live plugin.<tab><tab>self.session.register_flush_hook(self, live_plugin.close)<tab>return live",1,elif len ( live ) == 1 :,elif len ( live ) == 1 :,0.75,100,1
"def process_percent(token, state, command_line):<tab>if not state.is_range_start_line_parsed:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.start.append(token)<tab>else:<tab><tab>if command_line.line_range.end:<tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.end.append(token)<tab>return parse_line_ref, command_line",1,if command_line . line_range . start :,if command_line . line_range . start :,0.75,100,1
"def gprv_implicit_orax(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab>if i == 0:<tab><tab><tab>if op.name == ""REG0"" and op_luf(op, ""GPRv_SB""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",0,"if op . name == ""REG1"" and op_luf ( op , ""OrAX"" ) :",if op_implicit_orax ( op ) :,0.020790737,5.403628043,0.504761905
"def _check_events(self):<tab># make sure song-started and song-ended match up<tab>stack = []<tab>old = self.events[:]<tab>for type_, song in self.events:<tab><tab><IF-STMT><tab><tab><tab>stack.append(song)<tab><tab>elif type_ == ""ended"":<tab><tab><tab>self.assertTrue(stack.pop(-1) is song, msg=old)<tab>self.assertFalse(stack, msg=old)",1,"if type_ == ""started"" :","if type_ == ""started"" :",0.75,100,1
"def _minimal_replacement_cost(self, first, second):<tab>first_symbols, second_symbols = set(), set()<tab>removal_cost, insertion_cost = 0, 0<tab>for a, b in itertools.zip_longest(first, second, fillvalue=None):<tab><tab>if a is not None:<tab><tab><tab>first_symbols.add(a)<tab><tab><IF-STMT><tab><tab><tab>second_symbols.add(b)<tab><tab>removal_cost = max(removal_cost, len(first_symbols - second_symbols))<tab><tab>insertion_cost = max(insertion_cost, len(second_symbols - first_symbols))<tab>return min(removal_cost, insertion_cost)",1,if b is not None :,if b is not None :,0.75,100,1
"def get_default_backend(self, user_backends):<tab>retval = None<tab>n_defaults = 0<tab>for name in user_backends:<tab><tab>args = user_backends.get(name)<tab><tab><IF-STMT><tab><tab><tab>n_defaults = n_defaults + 1<tab><tab><tab>if retval is None:<tab><tab><tab><tab>retval = name<tab>return (retval, n_defaults)",0,"if args . get ( ""default"" , False ) :",if args is not None :,0.026294073,6.609029796,0.363636364
"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab>if fd.isatty():<tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab>if not attr_list[3] & termios.ECHO:<tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab>if hasattr(signal, ""SIGTTOU""):<tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",1,if old_handler is not None :,if old_handler is not None :,0.75,100,1
"def load_dashboard_module_view(request, pk):<tab>result = {""error"": False}<tab>try:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(""error"")<tab><tab>instance = UserDashboardModule.objects.get(pk=pk, user=request.user.pk)<tab><tab>module_cls = instance.load_module()<tab><tab>module = module_cls(model=instance, context={""request"": request})<tab><tab>result[""html""] = module.render()<tab>except (ValidationError, UserDashboardModule.DoesNotExist):<tab><tab>result[""error""] = True<tab>return JsonResponse(result)",0,if not user_is_authenticated ( request . user ) or not request . user . is_staff :,if request . user . pk != pk :,0.083456607,8.75617863,0.263157895
"def _validate_compatible(from_schema, to_schema):<tab>if set(from_schema.names) != set(to_schema.names):<tab><tab>raise com.IbisInputError(""Schemas have different names"")<tab>for name in from_schema:<tab><tab>lt = from_schema[name]<tab><tab>rt = to_schema[name]<tab><tab><IF-STMT><tab><tab><tab>raise com.IbisInputError(""Cannot safely cast {0!r} to {1!r}"".format(lt, rt))<tab>return",0,if not lt . castable ( rt ) :,"if not isinstance ( rt , ( int , long ) ) :",0.036986323,10.70080152,0.325925926
"def load_yaml(self):<tab>if ""FUEL_CONFIG"" in os.environ:<tab><tab>yaml_file = os.environ[""FUEL_CONFIG""]<tab>else:<tab><tab>yaml_file = os.path.expanduser(""~/.fuelrc"")<tab>if os.path.isfile(yaml_file):<tab><tab>with open(yaml_file) as f:<tab><tab><tab>for key, value in yaml.safe_load(f).items():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(""Unrecognized config in YAML: {}"".format(key))<tab><tab><tab><tab>self.config[key][""yaml""] = value",1,if key not in self . config :,if key not in self . config :,0.75,100,1
"def process(self):<tab>if not self.outputs[""Polygons""].is_linked:<tab><tab>return<tab>verts = self.inputs[""Vertices""].sv_get()<tab>faces = self.inputs[""Polygons""].sv_get()<tab>if not len(verts) == len(faces):<tab><tab>return<tab>verts_out = []<tab>polys_out = []<tab>for v_obj, f_obj in zip(verts, faces):<tab><tab>res = join_tris(v_obj, f_obj, self)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>verts_out.append(res[0])<tab><tab>polys_out.append(res[1])<tab>self.outputs[""Vertices""].sv_set(verts_out)<tab>self.outputs[""Polygons""].sv_set(polys_out)",1,if not res :,if not res :,0.75,100,1
"def _set_momentum(self, runner, momentum_groups):<tab>for param_group, mom in zip(runner.optimizer.param_groups, momentum_groups):<tab><tab>if ""momentum"" in param_group.keys():<tab><tab><tab>param_group[""momentum""] = mom<tab><tab><IF-STMT><tab><tab><tab>param_group[""betas""] = (mom, param_group[""betas""][1])",0,"elif ""betas"" in param_group . keys ( ) :","if ""betas"" in param_group . keys ( ) :",0.515003344,91.21679091,0.6
"def getReceiptInfo(pkgname):<tab>""""""Get receipt info from a package""""""<tab>info = []<tab>if hasValidPackageExt(pkgname):<tab><tab>display.display_debug2(""Examining %s"" % pkgname)<tab><tab>if os.path.isfile(pkgname):  # new flat package<tab><tab><tab>info = getFlatPackageInfo(pkgname)<tab><tab><IF-STMT>  # bundle-style package?<tab><tab><tab>info = getBundlePackageInfo(pkgname)<tab>elif pkgname.endswith("".dist""):<tab><tab>info = parsePkgRefs(pkgname)<tab>return info",0,if os . path . isdir ( pkgname ) :,elif os . path . isfile ( pkgname ) :,0.252094392,52.53819789,0.5
"def _add_directory_child(self, children, filename):<tab>if os.path.isdir(filename):<tab><tab>children.append(self._directory_controller(filename))<tab>else:<tab><tab>r = self._namespace.get_resource(filename, report_status=False)<tab><tab><IF-STMT><tab><tab><tab>children.append(self._resource_controller(r))",0,if self . _is_valid_resource ( r ) :,if r is not None :,0.019830745,3.574517961,0.25
"def check_br_addr(self, br):<tab>ips = {}<tab>cmd = ""ip a show dev %s"" % br<tab>for line in self.execute(cmd, sudo=True).split(""\n""):<tab><tab>if line.strip().startswith(""inet ""):<tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[4] = elems[1]<tab><tab><IF-STMT><tab><tab><tab>elems = [e.strip() for e in line.strip().split("" "")]<tab><tab><tab>ips[6] = elems[1]<tab>return ips",1,"elif line . strip ( ) . startswith ( ""inet6 "" ) :","elif line . strip ( ) . startswith ( ""inet6 "" ) :",0.75,100,1
"def execute(self, statement, parameters=None):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>result = self.real_cursor.execute(statement, parameters)<tab><tab>else:<tab><tab><tab>result = self.real_cursor.execute(statement)<tab><tab>return result<tab>except:<tab><tab>raise Error(sys.exc_info()[1])",1,if parameters :,if parameters :,0.531170663,1.00E-10,1
"def isUpdateAvailable(self, localOnly=False):<tab>nsp = self.getLatestFile()<tab><IF-STMT><tab><tab>if not nsp:<tab><tab><tab>if not self.isUpdate or (self.version and int(self.version) > 0):<tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>try:<tab><tab>latest = self.lastestVersion(localOnly=localOnly)<tab><tab>if latest is None:<tab><tab><tab>return False<tab><tab>if int(nsp.version) < int(latest):<tab><tab><tab>return True<tab>except BaseException as e:<tab><tab>Print.error(""isUpdateAvailable exception %s: %s"" % (self.id, str(e)))<tab><tab>pass<tab>return False",0,if not nsp :,if nsp is not None :,0.167839241,11.47874423,0.25
"def align(size):<tab>if size <= 4096:<tab><tab># Small<tab><tab><IF-STMT><tab><tab><tab>return size<tab><tab>elif size < 128:<tab><tab><tab>return min_ge(range(16, 128 + 1, 16), size)<tab><tab>elif size < 512:<tab><tab><tab>return min_ge(range(192, 512 + 1, 64), size)<tab><tab>else:<tab><tab><tab>return min_ge(range(768, 4096 + 1, 256), size)<tab>elif size < 4194304:<tab><tab># Large<tab><tab>return min_ge(range(4096, 4194304 + 1, 4096), size)<tab>else:<tab><tab># Huge<tab><tab>return min_ge(range(4194304, 536870912 + 1, 4194304), size)",0,if is_power2 ( size ) :,if size < 16 :,0.029084143,7.715486568,0.714285714
"def __init__(self, transforms):<tab>assert isinstance(transforms, collections.abc.Sequence)<tab>self.transforms = []<tab>for transform in transforms:<tab><tab><IF-STMT><tab><tab><tab>transform = build_from_cfg(transform, PIPELINES)<tab><tab><tab>self.transforms.append(transform)<tab><tab>elif callable(transform):<tab><tab><tab>self.transforms.append(transform)<tab><tab>else:<tab><tab><tab>raise TypeError(""transform must be callable or a dict"")",1,"if isinstance ( transform , dict ) :","if isinstance ( transform , dict ) :",0.75,100,1
"def branch_name_from_config_file(directory, config_file):<tab>ans = None<tab>try:<tab><tab>with open(config_file, ""rb"") as f:<tab><tab><tab>for line in f:<tab><tab><tab><tab>m = nick_pat.match(line)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ans = (<tab><tab><tab><tab><tab><tab>m.group(1)<tab><tab><tab><tab><tab><tab>.strip()<tab><tab><tab><tab><tab><tab>.decode(get_preferred_file_contents_encoding(), ""replace"")<tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>break<tab>except Exception:<tab><tab>pass<tab>return ans or os.path.basename(directory)",0,if m is not None :,if m :,0.050438393,1.00E-10,0.4
"def do_acquire_write_lock(self, wait):<tab>owner_id = self._get_owner_id()<tab>while True:<tab><tab>if self.client.setnx(self.identifier, owner_id):<tab><tab><tab>self.client.pexpire(self.identifier, self.LOCK_EXPIRATION * 1000)<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>time.sleep(0.2)",1,if not wait :,if not wait :,0.75,100,1
"def add_files_for_package(sub_package_path, root_package_path, root_package_name):<tab>for root, dirs, files in os.walk(sub_package_path):<tab><tab><IF-STMT><tab><tab><tab>dirs.remove("".svn"")<tab><tab>for f in files:<tab><tab><tab>if not f.endswith("".pyc"") and not f.startswith("".""):<tab><tab><tab><tab>add(<tab><tab><tab><tab><tab>dereference(root + ""/"" + f),<tab><tab><tab><tab><tab>root.replace(root_package_path, root_package_name) + ""/"" + f,<tab><tab><tab><tab>)",1,"if "".svn"" in dirs :","if "".svn"" in dirs :",0.75,100,1
"def collect_state(object_name, prefix, d):<tab>if d[None] is False:<tab><tab>return []<tab>result = []<tab>if d[None] is True and prefix is not None:<tab><tab>name = v.make_measurement_choice(object_name, prefix)<tab><tab>if name in choices:<tab><tab><tab>result.append(name)<tab>for key in [x for x in list(d.keys()) if x is not None]:<tab><tab><IF-STMT><tab><tab><tab>sub_prefix = key<tab><tab>else:<tab><tab><tab>sub_prefix = ""_"".join((prefix, key))<tab><tab>result += collect_state(object_name, sub_prefix, d[key])<tab>return result",1,if prefix is None :,if prefix is None :,0.75,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_num_memcacheg_backends(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def check(dbdef):<tab>""database version must include required keys""<tab>for vnum, vdef in dbdef.items():<tab><tab>missing = set(required) - set(vdef)<tab><tab><IF-STMT><tab><tab><tab>missing -= set(initially_ok)<tab><tab>if missing:<tab><tab><tab>yield vnum, missing",0,if vnum == min ( dbdef ) :,if vnum in initially_ok :,0.035401841,10.92329991,0.481481481
"def _check(ret):<tab>if hasattr(ret, ""value""):<tab><tab>ret = ret.value<tab>if ret != 0:<tab><tab><IF-STMT><tab><tab><tab>raise USBTimeoutError(_lib.openusb_strerror(ret), ret, _openusb_errno[ret])<tab><tab>else:<tab><tab><tab>raise USBError(_lib.openusb_strerror(ret), ret, _openusb_errno[ret])<tab>return ret",0,if ret == OPENUSB_IO_TIMEOUT :,if ret in _openusb_errno . timeout :,0.052869316,10.55267032,0.55
"def scroll_to(self, x=None, y=None):<tab>if x is None or y is None:<tab><tab>pos = self.tab.get_scroll_position()<tab><tab>x = pos[""x""] if x is None else x<tab><tab>y = pos[""y""] if y is None else y<tab>for value, name in [(x, ""x""), (y, ""y"")]:<tab><tab><IF-STMT><tab><tab><tab>raise ScriptError(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""argument"": name,<tab><tab><tab><tab><tab>""message"": ""scroll {} coordinate must be ""<tab><tab><tab><tab><tab>""a number, got {}"".format(name, repr(value)),<tab><tab><tab><tab>}<tab><tab><tab>)<tab>self.tab.set_scroll_position(x, y)",0,"if not isinstance ( value , ( int , float ) ) :","if not isinstance ( value , numbers . Number ) :",0.208806871,43.29738749,0.555555556
"def _validate_secret_list(self, secrets, expected):<tab>for secret in secrets:<tab><tab><IF-STMT><tab><tab><tab>expected_secret = expected[secret.name]<tab><tab><tab>self._assert_secret_attributes_equal(expected_secret.properties, secret)<tab><tab><tab>del expected[secret.name]<tab>self.assertEqual(len(expected), 0)",0,if secret . name in expected . keys ( ) :,if secret . name in expected :,0.336767053,47.48694444,0.844155844
"def _capture_hub(self, create):<tab># Subclasses should call this as the first action from any<tab># public method that could, in theory, block and switch<tab># to the hub. This may release the GIL.<tab><IF-STMT><tab><tab># This next line might release the GIL.<tab><tab>current_hub = get_hub() if create else get_hub_if_exists()<tab><tab>if current_hub is None:<tab><tab><tab>return<tab><tab># We have the GIL again. Did anything change? If so,<tab><tab># we lost the race.<tab><tab>if self.hub is None:<tab><tab><tab>self.hub = current_hub",0,if self . hub is None :,if create :,0.020447728,1.00E-10,0.224489796
"def _hashable(self):<tab>hashes = [self.graph.md5()]<tab>for g in self.geometry.values():<tab><tab>if hasattr(g, ""md5""):<tab><tab><tab>hashes.append(g.md5())<tab><tab><IF-STMT><tab><tab><tab>hashes.append(str(hash(g.tostring())))<tab><tab>else:<tab><tab><tab># try to just straight up hash<tab><tab><tab># this may raise errors<tab><tab><tab>hashes.append(str(hash(g)))<tab>hashable = """".join(sorted(hashes)).encode(""utf-8"")<tab>return hashable",1,"elif hasattr ( g , ""tostring"" ) :","elif hasattr ( g , ""tostring"" ) :",0.75,100,1
"def load_distribution(args: CommandLineArguments) -> CommandLineArguments:<tab>if args.distribution is not None:<tab><tab>args.distribution = Distribution[args.distribution]<tab>if args.distribution is None or args.release is None:<tab><tab>d, r = detect_distribution()<tab><tab><IF-STMT><tab><tab><tab>args.distribution = d<tab><tab>if args.distribution == d and d != Distribution.clear and args.release is None:<tab><tab><tab>args.release = r<tab>if args.distribution is None:<tab><tab>die(""Couldn't detect distribution."")<tab>return args",1,if args . distribution is None :,if args . distribution is None :,0.75,100,1
"def is_different(item, seen):<tab>is_diff = True<tab>if item not in seen:<tab><tab>for value in other:<tab><tab><tab>if comparator(iteratee(item), iteratee(value)):<tab><tab><tab><tab>is_diff = False<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>seen.append(item)<tab>return is_diff",0,if is_diff :,elif item not in seen :,0.033189275,1.00E-10,0.047619048
"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab>if pos == -1:<tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab>elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab>if not escaped:<tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos",0,"if c == ""\\"" :",if dn . search ( c ) :,0.02800146,6.413885306,0.36
"def vcf_has_nonfiltered_variants(in_file):<tab>if os.path.exists(in_file):<tab><tab>with utils.open_gzipsafe(in_file) as in_handle:<tab><tab><tab>for line in in_handle:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>parts = line.split(""\t"")<tab><tab><tab><tab><tab>if parts[6] in set([""PASS"", "".""]):<tab><tab><tab><tab><tab><tab>return True<tab>return False",0,"if line . strip ( ) and not line . startswith ( ""#"" ) :",if line :,0.010227354,1.00E-10,0.346938776
"def clean_vendor(ctx, vendor_dir):<tab># Old _vendor cleanup<tab>remove_all(vendor_dir.glob(""*.pyc""))<tab>log(""Cleaning %s"" % vendor_dir)<tab>for item in vendor_dir.iterdir():<tab><tab>if item.is_dir():<tab><tab><tab>shutil.rmtree(str(item))<tab><tab><IF-STMT><tab><tab><tab>item.unlink()<tab><tab>else:<tab><tab><tab>log(""Skipping %s"" % item)",0,elif item . name not in FILE_WHITE_LIST :,elif item . is_file ( ) :,0.075002055,14.44881489,0.444444444
"def sel_line(view, s):<tab>if mode == modes.INTERNAL_NORMAL:<tab><tab><IF-STMT><tab><tab><tab>if view.line(s.b).size() > 0:<tab><tab><tab><tab>eol = view.line(s.b).b<tab><tab><tab><tab>begin = view.line(s.b).a<tab><tab><tab><tab>begin = utils.next_non_white_space_char(view, begin, white_space="" \t"")<tab><tab><tab><tab>return R(begin, eol)<tab><tab><tab>return s<tab>return s",0,if count == 1 :,if s . b . size ( ) > 0 :,0.023753722,4.456882761,0.232142857
"def _struct(self, fields):<tab>result = {}<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>parent = self.instance(field[1])<tab><tab><tab>if isinstance(parent, dict):<tab><tab><tab><tab>result.update(parent)<tab><tab><tab>elif len(fields) == 1:<tab><tab><tab><tab>result = parent<tab><tab><tab>else:<tab><tab><tab><tab>result[field[0]] = parent<tab><tab>else:<tab><tab><tab>result[field[0]] = self.instance(field[1])<tab>return result",0,"if field [ 0 ] == ""__parent"" :",if len ( field ) == 2 :,0.020373037,7.687847996,0.314814815
"def _decode_list(lst):<tab>if not PY2:<tab><tab>return lst<tab>newlist = []<tab>for i in lst:<tab><tab><IF-STMT><tab><tab><tab>i = to_bytes(i)<tab><tab>elif isinstance(i, list):<tab><tab><tab>i = _decode_list(i)<tab><tab>newlist.append(i)<tab>return newlist",0,"if isinstance ( i , string_types ) :","if isinstance ( i , bytes ) :",0.549040681,46.30777162,0.777777778
"def _check_arguments(self, arch, state):<tab># TODO: add calling convention detection to individual functions, and use that instead of the<tab># TODO: default calling convention of the platform<tab>cc = DEFAULT_CC[arch.name](arch)  # type: s_cc.SimCC<tab>for i, expected_arg in enumerate(self.arguments):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>real_arg = cc.arg(state, i)<tab><tab>expected_arg_type, expected_arg_value = expected_arg<tab><tab>r = self._compare_arguments(<tab><tab><tab>state, expected_arg_type, expected_arg_value, real_arg<tab><tab>)<tab><tab>if not r:<tab><tab><tab>return False<tab>return True",1,if expected_arg is None :,if expected_arg is None :,0.75,100,1
"def _strip_classy_blocks(self, module):<tab>for name, child_module in module.named_children():<tab><tab><IF-STMT><tab><tab><tab>module.add_module(name, child_module.wrapped_module())<tab><tab>self._strip_classy_blocks(child_module)",0,"if isinstance ( child_module , ClassyBlock ) :","if isinstance ( child_module , pytree . Leaf ) and isinstance ( child_module , pytree . Leaf ) :",0.204883465,27.74870274,0.354497354
"def test_07_verify_degraded_pool_alert_list_exist_and_get_id():<tab>global alert_id<tab>results = GET(""/alert/list/"")<tab>assert results.status_code == 200, results.text<tab>assert isinstance(results.json(), list), results.text<tab>for line in results.json():<tab><tab><IF-STMT><tab><tab><tab>alert_id = results.json()[0][""id""]<tab><tab><tab>assert results.json()[0][""args""][""volume""] == pool_name, results.text<tab><tab><tab>assert results.json()[0][""args""][""state""] == ""DEGRADED"", results.text<tab><tab><tab>assert results.json()[0][""level""] == ""CRITICAL"", results.text<tab><tab><tab>break",0,"if line [ ""source"" ] == ""VolumeStatus"" :","if ""id"" in line and line [ ""state"" ] == ""ACTIVE"" :",0.037690389,28.52636439,0.364705882
"def parseApplicationExtension(parent):<tab>yield PascalString8(parent, ""app_name"", ""Application name"")<tab>yield UInt8(parent, ""size"")<tab>size = parent[""size""].value<tab>if parent[""app_name""].value == ""NETSCAPE2.0"" and size == 3:<tab><tab>yield Enum(UInt8(parent, ""netscape_code""), NETSCAPE_CODE)<tab><tab><IF-STMT><tab><tab><tab>yield UInt16(parent, ""loop_count"")<tab><tab>else:<tab><tab><tab>yield RawBytes(parent, ""raw"", 2)<tab>else:<tab><tab>yield RawBytes(parent, ""raw"", size)<tab>yield NullBytes(parent, ""terminator"", 1, ""Terminator (0)"")",0,"if parent [ ""netscape_code"" ] . value == 1 :","if parent [ ""loop_count"" ] . value == 1 :",0.580308871,66.06328636,1
"def tearDownClass(self):<tab>settings.TIME_ZONE = connection.settings_dict[""TIME_ZONE""] = self._old_time_zone<tab>timezone._localtime = None<tab>if TZ_SUPPORT:<tab><tab><IF-STMT><tab><tab><tab>del os.environ[""TZ""]<tab><tab>else:<tab><tab><tab>os.environ[""TZ""] = self._old_tz<tab><tab>time.tzset()",0,if self . _old_tz is None :,"if ""TZ"" in os . environ :",0.022864977,5.614808272,0.25
"def __getattr__(self, key):<tab>if key in self._raw:<tab><tab>val = self._raw[key]<tab><tab>if key in (""date"",):<tab><tab><tab>return pd.Timestamp(val)<tab><tab><IF-STMT><tab><tab><tab>return pd.Timestamp(val).time()<tab><tab>elif key in (""session_open"", ""session_close""):<tab><tab><tab>return pd.Timestamp(val[:2] + "":"" + val[-2:]).time()<tab><tab>else:<tab><tab><tab>return val<tab>return super().__getattr__(key)",0,"elif key in ( ""open"" , ""close"" ) :","elif key in ( ""time"" , ) :",0.269826692,37.30270054,1
"def _extract_knob_feature_log(arg):<tab>""""""extract knob feature for log items""""""<tab>try:<tab><tab>inp, res = arg<tab><tab>config = inp.config<tab><tab>x = config.get_flatten_feature()<tab><tab><IF-STMT><tab><tab><tab>with inp.target:  # necessary, for calculating flops of this task<tab><tab><tab><tab>inp.task.instantiate(config)<tab><tab><tab>y = inp.task.flop / np.mean(res.costs)<tab><tab>else:<tab><tab><tab>y = 0.0<tab><tab>return x, y<tab>except Exception:  # pylint: disable=broad-except<tab><tab>return None",0,if res . error_no == 0 :,if res . costs :,0.094532291,15.71901051,0.6
"def dvipng_hack_alpha():<tab>stdin, stdout = os.popen4(""dvipng -version"")<tab>for line in stdout:<tab><tab><IF-STMT><tab><tab><tab>version = line.split()[-1]<tab><tab><tab>mpl.verbose.report(""Found dvipng version %s"" % version, ""helpful"")<tab><tab><tab>version = distutils.version.LooseVersion(version)<tab><tab><tab>return version < distutils.version.LooseVersion(""1.6"")<tab>raise RuntimeError(""Could not obtain dvipng version"")",0,"if line . startswith ( ""dvipng "" ) :","if line . startswith ( ""version"" ) :",0.512252301,65.80370065,1
"def _get_func_name(self, current_cls: Generic, module_func_dict: dict) -> Optional[str]:<tab>mod = current_cls.__module__ + ""."" + current_cls.__name__<tab>if mod in module_func_dict:<tab><tab>_func_name = module_func_dict[mod]<tab><tab>return _func_name<tab>elif current_cls.__bases__:<tab><tab>for base_class in current_cls.__bases__:<tab><tab><tab>base_run_func = self._get_func_name(base_class, module_func_dict)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return base_run_func<tab>else:<tab><tab>return None",0,if base_run_func :,if base_run_func is not None :,0.090364769,1.00E-10,0.314285714
"def __getitem__(self, key):<tab>if isinstance(key, numbers.Number):<tab><tab>l = len(self)<tab><tab><IF-STMT><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab>if key < 0:<tab><tab><tab>if key < -l:<tab><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><tab>key += l<tab><tab>return self(key + 1)<tab>elif isinstance(key, slice):<tab><tab>raise ValueError(<tab><tab><tab>self.impl.__class__.__name__ + "" object does not support slicing""<tab><tab>)<tab>else:<tab><tab>return self(key)",1,if key >= l :,if key >= l :,0.75,100,1
"def add_user_functions(self):<tab>for udf in user_functions:<tab><tab><IF-STMT><tab><tab><tab>self.conn.create_aggregate(udf.name, udf.param_count, udf.func_or_obj)<tab><tab>elif type(udf.func_or_obj) == type(md5):<tab><tab><tab>self.conn.create_function(udf.name, udf.param_count, udf.func_or_obj)<tab><tab>else:<tab><tab><tab>raise Exception(""Invalid user function definition %s"" % str(udf))",0,if type ( udf . func_or_obj ) == type ( object ) :,if type ( udf . func_or_obj ) == type ( aggregate ) :,0.89649565,85.78928093,0.666666667
"def _get_schema_references(self, s):<tab>refs = set()<tab>if isinstance(s, dict):<tab><tab>for k, v in s.items():<tab><tab><tab>if isinstance(v, six.string_types):<tab><tab><tab><tab>m = self.__jsonschema_ref_ex.match(v)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>refs.add(m.group(1))<tab><tab><tab><tab>continue<tab><tab><tab>elif k in (""oneOf"", ""anyOf"") and isinstance(v, list):<tab><tab><tab><tab>refs.update(*map(self._get_schema_references, v))<tab><tab><tab>refs.update(self._get_schema_references(v))<tab>return refs",1,if m :,if m :,0.531170663,1.00E-10,1
"def create_model_handler(ns, model_type):<tab>@route(f""/<provider>/{ns}/<model_id>"")<tab>@use_provider<tab>def handle(req, provider, model_id):<tab><tab># special cases:<tab><tab># fuo://<provider>/users/me -> show current logged user<tab><tab>if model_type == ModelType.user:<tab><tab><tab>if model_id == ""me"":<tab><tab><tab><tab>user = getattr(provider, ""_user"", None)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise CmdException(f""log in provider:{provider.identifier} first"")<tab><tab><tab><tab>return user<tab><tab>model = get_model_or_raise(provider, model_type, model_id)<tab><tab>return model",1,if user is None :,if user is None :,0.75,100,1
"def stream_read_bz2(ifh, ofh):<tab>""""""Uncompress bz2 compressed *ifh* into *ofh*""""""<tab>decompressor = bz2.BZ2Decompressor()<tab>while True:<tab><tab>buf = ifh.read(BUFSIZE)<tab><tab>if not buf:<tab><tab><tab>break<tab><tab>buf = decompressor.decompress(buf)<tab><tab><IF-STMT><tab><tab><tab>ofh.write(buf)<tab>if decompressor.unused_data or ifh.read(1) != b"""":<tab><tab>raise CorruptedObjectError(""Data after end of bz2 stream"")",1,if buf :,if buf :,0.531170663,1.00E-10,1
"def copy_layer(<tab>layer,<tab>keep_bias=True,<tab>name_template=None,<tab>weights=None,<tab>reuse_symbolic_tensors=True,<tab>**kwargs):<tab>config = layer.get_config()<tab>if name_template is None:<tab><tab>config[""name""] = None<tab>else:<tab><tab>config[""name""] = name_template % config[""name""]<tab>if keep_bias is False and config.get(""use_bias"", False):<tab><tab>config[""use_bias""] = False<tab><tab><IF-STMT><tab><tab><tab>if reuse_symbolic_tensors:<tab><tab><tab><tab>weights = layer.weights[:-1]<tab><tab><tab>else:<tab><tab><tab><tab>weights = layer.get_weights()[:-1]<tab>return get_layer_from_config(layer, config, weights=weights, **kwargs)",1,if weights is None :,if weights is None :,0.75,100,1
"def do_status(self, directory, path):<tab>with self._repo(directory) as repo:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(directory, path)<tab><tab><tab>statuses = repo.status(include=path, all=True)<tab><tab><tab>for status, paths in statuses:<tab><tab><tab><tab>if paths:<tab><tab><tab><tab><tab>return self.statuses[status][0]<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>resulting_status = 0<tab><tab><tab>for status, paths in repo.status(all=True):<tab><tab><tab><tab>if paths:<tab><tab><tab><tab><tab>resulting_status |= self.statuses[status][1]<tab><tab><tab>return self.repo_statuses_str[resulting_status]",1,if path :,if path :,0.531170663,1.00E-10,1
"def close(self):<tab>if self.changed:<tab><tab>save = EasyDialogs.AskYesNoCancel(<tab><tab><tab>'Save window ""%s"" before closing?' % self.name, 1<tab><tab>)<tab><tab>if save > 0:<tab><tab><tab>self.menu_save()<tab><tab><IF-STMT><tab><tab><tab>return<tab>if self.parent.active == self:<tab><tab>self.parent.active = None<tab>self.parent.updatemenubar()<tab>del self.ted<tab>self.do_postclose()",0,elif save < 0 :,if save == 0 :,0.062871671,17.9652056,0.6
"def _Return(self, t):<tab>self._fill(""return "")<tab>if t.value:<tab><tab><IF-STMT><tab><tab><tab>text = "", "".join([name.name for name in t.value.asList()])<tab><tab><tab>self._write(text)<tab><tab>else:<tab><tab><tab>self._dispatch(t.value)<tab><tab>if not self._do_indent:<tab><tab><tab>self._write(""; "")",0,"if isinstance ( t . value , Tuple ) :",if self . _do_indent :,0.014393213,5.660233916,0.252747253
"def __init__(self, itemtype, cnf={}, *, master=None, **kw):<tab>if not master:<tab><tab>if ""refwindow"" in kw:<tab><tab><tab>master = kw[""refwindow""]<tab><tab><IF-STMT><tab><tab><tab>master = cnf[""refwindow""]<tab><tab>else:<tab><tab><tab>master = tkinter._default_root<tab><tab><tab>if not master:<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Too early to create display style: "" ""no root window""<tab><tab><tab><tab>)<tab>self.tk = master.tk<tab>self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))",1,"elif ""refwindow"" in cnf :","elif ""refwindow"" in cnf :",0.75,100,1
"def _load_items(self, splits):<tab>""""""Load individual image indices from splits.""""""<tab>ids = list()<tab>for name in splits:<tab><tab>root = os.path.join(self._root, ""VisDrone2019-DET-"" + name)<tab><tab>images_dir = self._images_dir.format(root)<tab><tab>images = [<tab><tab><tab>f[:-4]<tab><tab><tab>for f in os.listdir(images_dir)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>ids += [(root, line.strip()) for line in images]<tab>return ids",0,"if os . path . isfile ( os . path . join ( images_dir , f ) ) and f [ - 3 : ] == ""jpg""","if f . endswith ( "".png"" )",0.003629179,0.781937442,0.18
"def _gen_langs_in_db(self):<tab>for d in os.listdir(join(self.base_dir, ""db"")):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>lang_path = join(self.base_dir, ""db"", d, ""lang"")<tab><tab>if not exists(lang_path):<tab><tab><tab>log.warn(<tab><tab><tab><tab>""unexpected lang-zone db dir without 'lang' file: ""<tab><tab><tab><tab>""`%s' (skipping)"" % dirname(lang_path)<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>fin = open(lang_path, ""r"")<tab><tab>try:<tab><tab><tab>lang = fin.read().strip()<tab><tab>finally:<tab><tab><tab>fin.close()<tab><tab>yield lang",0,if d in self . _non_lang_db_dirs :,"if not d . endswith ( "".lang"" ) :",0.104215856,4.286580498,0.285714286
"def handler_click_link(self, link):<tab>if link.startswith(""[[""):<tab><tab>link = link[2:-2]<tab><tab>self.notify_observers(""click:notelink"", link)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>os.startfile(link)<tab><tab>elif platform.system().lower() == ""darwin"":<tab><tab><tab>subprocess.call((""open"", link))<tab><tab>else:<tab><tab><tab>subprocess.call((""xdg-open"", link))",0,"if platform . system ( ) . lower ( ) == ""windows"" :","if platform . system ( ) . lower ( ) == ""win"" :",0.67220614,83.71170099,1
"def get_referrers(self):<tab>d = []<tab>for o in gc.get_referrers(self.obj):<tab><tab>name = None<tab><tab>if isinstance(o, dict):<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><tab>for r in gc.get_referrers(o):<tab><tab><tab><tab>if getattr(r, ""__dict__"", None) is o:<tab><tab><tab><tab><tab>o = r<tab><tab><tab><tab><tab>break<tab><tab><IF-STMT>  # other dict types<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab>if not isinstance(name, six.string_types):<tab><tab><tab>name = None<tab><tab>d.append(Object(o, name))<tab>return d",0,"elif isinstance ( o , dict ) :","elif isinstance ( o , list ) :",0.547301779,59.46035575,0.666666667
"def parse_preference(path):<tab>""""""parse android's shared preference xml""""""<tab>storage = {}<tab>read = open(path)<tab>for line in read:<tab><tab>line = line.strip()<tab><tab># <string name=""key"">value</string><tab><tab><IF-STMT><tab><tab><tab>index = line.find('""', 14)<tab><tab><tab>key = line[14:index]<tab><tab><tab>value = line[index + 2 : -9]<tab><tab><tab>storage[key] = value<tab>read.close()<tab>return storage",0,"if line . startswith ( '<string name=""' ) :",if len ( line ) > 14 :,0.018635392,3.900760855,0.318181818
"def __getExpectedSampleOffsets(self, tileOrigin, area1, area2):<tab>ts = GafferImage.ImagePlug.tileSize()<tab>data = []<tab>for y in range(tileOrigin.y, tileOrigin.y + ts):<tab><tab>for x in range(tileOrigin.x, tileOrigin.x + ts):<tab><tab><tab>pixel = imath.V2i(x, y)<tab><tab><tab>data.append(data[-1] if data else 0)<tab><tab><tab>if GafferImage.BufferAlgo.contains(area1, pixel):<tab><tab><tab><tab>data[-1] += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[-1] += 1<tab>return IECore.IntVectorData(data)",1,"if GafferImage . BufferAlgo . contains ( area2 , pixel ) :","if GafferImage . BufferAlgo . contains ( area2 , pixel ) :",0.75,100,1
"def test_doc_attributes(self):<tab>print_test_name(""TEST DOC ATTRIBUTES"")<tab>correct = 0<tab>for example in DOC_EXAMPLES:<tab><tab>original_schema = schema.parse(example.schema_string)<tab><tab><IF-STMT><tab><tab><tab>correct += 1<tab><tab>if original_schema.type == ""record"":<tab><tab><tab>for f in original_schema.fields:<tab><tab><tab><tab>if f.doc is None:<tab><tab><tab><tab><tab>self.fail(<tab><tab><tab><tab><tab><tab>""Failed to preserve 'doc' in fields: "" + example.schema_string<tab><tab><tab><tab><tab>)<tab>self.assertEqual(correct, len(DOC_EXAMPLES))",0,if original_schema . doc is not None :,"if original_schema . type == ""doc"" :",0.07775596,34.48444258,0.238095238
"def enter(self, node, key, parent, path, ancestors):<tab>for i, visitor in enumerate(self.visitors):<tab><tab>if not self.skipping[i]:<tab><tab><tab>result = visitor.enter(node, key, parent, path, ancestors)<tab><tab><tab>if result is False:<tab><tab><tab><tab>self.skipping[i] = node<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.skipping[i] = BREAK<tab><tab><tab>elif result is not None:<tab><tab><tab><tab>return result",0,elif result is BREAK :,elif result is True :,0.392872021,42.72870064,0.666666667
"def new_user_two_factor():<tab>user = Journalist.query.get(request.args[""uid""])<tab>if request.method == ""POST"":<tab><tab>token = request.form[""token""]<tab><tab><IF-STMT><tab><tab><tab>flash(<tab><tab><tab><tab>gettext(<tab><tab><tab><tab><tab>""Token in two-factor authentication "" ""accepted for user {user}.""<tab><tab><tab><tab>).format(user=user.username),<tab><tab><tab><tab>""notification"",<tab><tab><tab>)<tab><tab><tab>return redirect(url_for(""admin.index""))<tab><tab>else:<tab><tab><tab>flash(<tab><tab><tab><tab>gettext(""Could not verify token in two-factor authentication.""), ""error""<tab><tab><tab>)<tab>return render_template(""admin_new_user_two_factor.html"", user=user)",0,if user . verify_token ( token ) :,"if token == ""two_factor"" :",0.019907918,5.93420261,0.477272727
"def _check_locations(self, locations, available_locations):<tab>for location in locations:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(<tab><tab><tab><tab>""List of supported locations for you is: %s"",<tab><tab><tab><tab>sorted(available_locations.keys()),<tab><tab><tab>)<tab><tab><tab>raise TaurusConfigError(""Invalid location requested: %s"" % location)",1,if location not in available_locations :,if location not in available_locations :,0.75,100,1
"def find_best_layout_for_subplots(num_subplots):<tab>r, c = 1, 1<tab>while (r * c) < num_subplots:<tab><tab>if (c == (r + 1)) or (r == c):<tab><tab><tab>c += 1<tab><tab><IF-STMT><tab><tab><tab>r += 1<tab><tab><tab>c -= 1<tab>return r, c",0,elif c == ( r + 2 ) :,elif c == ( r + 1 ) or ( c == ( r + 1 ) ) :,0.485287092,30.60368951,0.454212454
"def check_env(env):<tab>for name, val in env.items():<tab><tab>if not isinstance(name, six.string_types):<tab><tab><tab>raise ValueError(""non-string env name %r"" % name)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""non-string env value for '%s': %r"" % (name, val))",1,"if not isinstance ( val , six . string_types ) :","if not isinstance ( val , six . string_types ) :",0.75,100,1
"def _indexes(self):<tab># used for index_lib<tab>indexes = []<tab>names = (""index"", ""columns"")<tab>for ax in range(self.input.ndim):<tab><tab>index = names[ax]<tab><tab>val = getattr(self, index)<tab><tab><IF-STMT><tab><tab><tab>indexes.append(val)<tab><tab>else:<tab><tab><tab>indexes.append(slice(None))<tab>return indexes",1,if val is not None :,if val is not None :,0.75,100,1
"def gen():<tab>for _ in range(256):<tab><tab>if seq:<tab><tab><tab>yield self.tb.dut.i.eq(seq.pop(0))<tab><tab>i = yield self.tb.dut.i<tab><tab>if (yield self.tb.dut.n):<tab><tab><tab>self.assertEqual(i, 0)<tab><tab>else:<tab><tab><tab>o = yield self.tb.dut.o<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(i & 1 << (o - 1), 0)<tab><tab><tab>self.assertGreaterEqual(i, 1 << o)<tab><tab>yield",1,if o > 0 :,if o > 0 :,0.75,100,1
"def early_version(self, argv):<tab>if ""--version"" in argv:<tab><tab><IF-STMT><tab><tab><tab>from flower.utils import bugreport<tab><tab><tab>print(bugreport(), file=self.stdout)<tab><tab>print(__version__, file=self.stdout)<tab><tab>super(FlowerCommand, self).early_version(argv)",0,"if ""--debug"" in argv :",if self . verbosity >= 2 :,0.027969855,6.567274736,0.265306122
"def _lookup(self, key, dicts=None, filters=()):<tab>if dicts is None:<tab><tab>dicts = self.dicts<tab>key_len = len(key)<tab>if key_len > self.longest_key:<tab><tab>return None<tab>for d in dicts:<tab><tab>if not d.enabled:<tab><tab><tab>continue<tab><tab>if key_len > d.longest_key:<tab><tab><tab>continue<tab><tab>value = d.get(key)<tab><tab><IF-STMT><tab><tab><tab>for f in filters:<tab><tab><tab><tab>if f(key, value):<tab><tab><tab><tab><tab>return None<tab><tab><tab>return value",0,if value :,if filters is not None :,0.048107739,1.00E-10,0.2
"def get_lang3(lang):<tab>try:<tab><tab>if len(lang) == 2:<tab><tab><tab>ret_value = get(part1=lang).part3<tab><tab><IF-STMT><tab><tab><tab>ret_value = lang<tab><tab>else:<tab><tab><tab>ret_value = """"<tab>except KeyError:<tab><tab>ret_value = lang<tab>return ret_value",0,elif len ( lang ) == 3 :,"elif ret_value == """" :",0.018840591,11.33958222,0.345454545
"def get_config_settings():<tab>config = {}<tab>for plugin in extension_loader.MANAGER.plugins:<tab><tab>fn_name = plugin.name<tab><tab>function = plugin.plugin<tab><tab># if a function takes config...<tab><tab>if hasattr(function, ""_takes_config""):<tab><tab><tab>fn_module = importlib.import_module(function.__module__)<tab><tab><tab># call the config generator if it exists<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config[fn_name] = fn_module.gen_config(function._takes_config)<tab>return yaml.safe_dump(config, default_flow_style=False)",0,"if hasattr ( fn_module , ""gen_config"" ) :",if fn_module . gen_config :,0.019907918,18.40209785,0.641025641
"def _import_pathname(self, pathname, fqname):<tab>if _os_path_isdir(pathname):<tab><tab>result = self._import_pathname(_os_path_join(pathname, ""__init__""), fqname)<tab><tab><IF-STMT><tab><tab><tab>values = result[2]<tab><tab><tab>values[""__pkgdir__""] = pathname<tab><tab><tab>values[""__path__""] = [pathname]<tab><tab><tab>return 1, result[1], values<tab><tab>return None<tab>for suffix, importFunc in self.suffixes:<tab><tab>filename = pathname + suffix<tab><tab>try:<tab><tab><tab>finfo = _os_stat(filename)<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>return importFunc(filename, finfo, fqname)<tab>return None",1,if result :,if result :,0.531170663,1.00E-10,1
def __iter__(self):<tab>with self._guard:<tab><tab>for dp in self.ds:<tab><tab><tab>shp = dp[self.idx].shape<tab><tab><tab>holder = self.holder[shp]<tab><tab><tab>holder.append(dp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield BatchData.aggregate_batch(holder)<tab><tab><tab><tab>del holder[:],1,if len ( holder ) == self . batch_size :,if len ( holder ) == self . batch_size :,0.75,100,1
"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None):<tab>try:<tab><tab>if module is None:<tab><tab><tab>module = self.name<tab><tab>if section is None:<tab><tab><tab>section = ""all_sections""<tab><tab><IF-STMT><tab><tab><tab>s_name = f[""s_name""]<tab><tab>if source is None:<tab><tab><tab>source = os.path.abspath(os.path.join(f[""root""], f[""fn""]))<tab><tab>report.data_sources[module][section][s_name] = source<tab>except AttributeError:<tab><tab>logger.warning(<tab><tab><tab>""Tried to add data source for {}, but was missing fields data"".format(<tab><tab><tab><tab>self.name<tab><tab><tab>)<tab><tab>)",1,if s_name is None :,if s_name is None :,0.75,100,1
"def forward(self, seq, adj, sparse=False):<tab>seq_fts = self.fc(seq)<tab>if len(seq_fts.shape) > 2:<tab><tab><IF-STMT><tab><tab><tab>out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0)<tab><tab>else:<tab><tab><tab>out = torch.bmm(adj, seq_fts)<tab>else:<tab><tab>if sparse:<tab><tab><tab>out = torch.spmm(adj, torch.squeeze(seq_fts, 0))<tab><tab>else:<tab><tab><tab>out = torch.mm(adj, seq_fts)<tab>if self.bias is not None:<tab><tab>out += self.bias<tab>return self.act(out)",1,if sparse :,if sparse :,0.531170663,1.00E-10,1
"def stat(self, path):<tab>""""""Get attributes of a file or directory, following symlinks""""""<tab>try:<tab><tab>return SFTPAttrs.from_local(super().stat(path))<tab>except OSError as exc:<tab><tab><IF-STMT><tab><tab><tab>raise SFTPError(FX_PERMISSION_DENIED, exc.strerror)<tab><tab>else:<tab><tab><tab>raise SFTPError(FX_FAILURE, exc.strerror)",0,if exc . errno == errno . EACCES :,if exc . errno == errno . EPERM :,0.877090855,78.254229,0.666666667
"def _run_eagerly(*inputs):  # pylint: disable=missing-docstring<tab>with context.eager_mode():<tab><tab>constants = [<tab><tab><tab>_wrap_as_constant(value, tensor_spec)<tab><tab><tab>for value, tensor_spec in zip(inputs, input_signature)<tab><tab>]<tab><tab>output = fn(*constants)<tab><tab><IF-STMT><tab><tab><tab>return output._make([tensor.numpy() for tensor in output])<tab><tab>if isinstance(output, (tuple, list)):<tab><tab><tab>return [tensor.numpy() for tensor in output]<tab><tab>else:<tab><tab><tab>return output.numpy()",0,"if hasattr ( output , ""_make"" ) :","if isinstance ( output , ( tuple , list ) ) :",0.074174296,16.59038701,0.410714286
"def do_draw(self, data):<tab>if cu.biased_coin(data, self.__p):<tab><tab>return data.draw(self) + data.draw(self)<tab>else:<tab><tab># We draw n as two separate calls so that it doesn't show up as a<tab><tab># single block. If it did, the heuristics that allow us to move<tab><tab># blocks around would fire and it would move right, which would<tab><tab># then allow us to shrink it more easily.<tab><tab>n = (data.draw_bits(16) << 16) | data.draw_bits(16)<tab><tab><IF-STMT><tab><tab><tab>return (POISON,)<tab><tab>else:<tab><tab><tab>return (None,)",0,if n == MAX_INT :,"if cu . biased_coin ( data , n ) :",0.025806627,4.789232204,0.371428571
"def object_matches_a_check(obj, checks):<tab>""""""Does the object match *any* of the given checks from the ""only_cache_matching"" list?""""""<tab>for check in checks:<tab><tab><IF-STMT><tab><tab><tab>if check(obj):<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>for field, value in check.items():<tab><tab><tab><tab><tab>if not getattr(obj, field) == value:<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return True<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>logger.error(""Invalid filter for model %s, %s"", obj.__class__, check)<tab><tab><tab><tab>raise<tab>return False",0,if callable ( check ) :,"if hasattr ( check , ""__call__"" ) :",0.054860857,8.493098745,0.6
"def handle_edge(self, src_id, dst_id, attrs):<tab>try:<tab><tab>pos = attrs[""pos""]<tab>except KeyError:<tab><tab>return<tab>points = self.parse_edge_pos(pos)<tab>shapes = []<tab>for attr in (""_draw_"", ""_ldraw_"", ""_hdraw_"", ""_tdraw_"", ""_hldraw_"", ""_tldraw_""):<tab><tab><IF-STMT><tab><tab><tab>parser = XDotAttrParser(self, attrs[attr])<tab><tab><tab>shapes.extend(parser.parse())<tab>if shapes:<tab><tab>src = self.node_by_name[src_id]<tab><tab>dst = self.node_by_name[dst_id]<tab><tab>self.edges.append(elements.Edge(src, dst, points, shapes, attrs.get(""tooltip"")))",1,if attr in attrs :,if attr in attrs :,0.75,100,1
"def get_available_data_asset_names(self):<tab>known_assets = []<tab>if not os.path.isdir(self.base_directory):<tab><tab>return {""names"": [(asset, ""path"") for asset in known_assets]}<tab>for data_asset_name in self.asset_globs.keys():<tab><tab>batch_paths = self._get_data_asset_paths(data_asset_name=data_asset_name)<tab><tab><IF-STMT><tab><tab><tab>known_assets.append(data_asset_name)<tab>return {""names"": [(asset, ""path"") for asset in known_assets]}",0,if len ( batch_paths ) > 0 and data_asset_name not in known_assets :,if data_asset_name not in batch_paths :,0.142996879,31.34697569,0.260504202
"def _maintain_pool(self):<tab>waiting = self._docker_interface.services_waiting_by_constraints()<tab>active = self._docker_interface.nodes_active_by_constraints()<tab>for constraints, needed_dict in self._state.slots_needed(waiting, active).items():<tab><tab>services = needed_dict[""services""]<tab><tab>nodes = needed_dict[""nodes""]<tab><tab>slots_needed = needed_dict[""slots_needed""]<tab><tab><IF-STMT><tab><tab><tab>self._spawn_nodes(constraints, services, slots_needed)<tab><tab>elif slots_needed < 0:<tab><tab><tab>self._destroy_nodes(constraints, nodes, slots_needed)",0,if slots_needed > 0 :,if services < 0 :,0.314978772,15.84873897,0.45
"def retention_validator(ns):<tab>if ns.backup_retention is not None:<tab><tab>val = ns.backup_retention<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""incorrect usage: --backup-retention. Range is 7 to 35 days.""<tab><tab><tab>)",0,if not 7 <= int ( val ) <= 35 :,if val < 7 or val > 35 :,0.025426511,8.046371859,0.583333333
"def write(path, data, kind=""OTHER"", dohex=0):<tab>asserttype1(data)<tab>kind = string.upper(kind)<tab>try:<tab><tab>os.remove(path)<tab>except os.error:<tab><tab>pass<tab>err = 1<tab>try:<tab><tab>if kind == ""LWFN"":<tab><tab><tab>writelwfn(path, data)<tab><tab><IF-STMT><tab><tab><tab>writepfb(path, data)<tab><tab>else:<tab><tab><tab>writeother(path, data, dohex)<tab><tab>err = 0<tab>finally:<tab><tab>if err and not DEBUG:<tab><tab><tab>try:<tab><tab><tab><tab>os.remove(path)<tab><tab><tab>except os.error:<tab><tab><tab><tab>pass",1,"elif kind == ""PFB"" :","elif kind == ""PFB"" :",1,100,1
"def __init__(self, zone, poll_interval=1):<tab>self.zone = zone<tab>self.poll_interval = poll_interval<tab>self.queue_client = QueueClient(zone)<tab>self.shards = []<tab>for database in config[""DATABASE_HOSTS""]:<tab><tab><IF-STMT><tab><tab><tab>shard_ids = [shard[""ID""] for shard in database[""SHARDS""]]<tab><tab><tab>self.shards.extend(<tab><tab><tab><tab>shard_id for shard_id in shard_ids if shard_id in engine_manager.engines<tab><tab><tab>)",0,"if database . get ( ""ZONE"" ) == self . zone :","if ""SHARDS"" in database :",0.010805043,3.1317792,0.267857143
"def _postprocess_message(self, msg):<tab>if msg[""type""] != ""param"":<tab><tab>return<tab>event_dim = msg[""kwargs""].get(""event_dim"")<tab>if event_dim is None:<tab><tab>return<tab>for frame in msg[""cond_indep_stack""]:<tab><tab><IF-STMT><tab><tab><tab>value = msg[""value""]<tab><tab><tab>event_dim += value.unconstrained().dim() - value.dim()<tab><tab><tab>value.unconstrained()._pyro_dct_dim = frame.dim - event_dim<tab><tab><tab>return",0,if frame . name == self . name :,if frame . dim ( ) > event_dim :,0.0664695,14.99110695,0.466666667
"def RemoveIdleHandler(self):<tab>if self.idleHandlerSet:<tab><tab>debug(""Idle handler reset\n"")<tab><tab><IF-STMT><tab><tab><tab>debug(""Error deleting idle handler\n"")<tab><tab>self.idleHandlerSet = 0",0,if win32ui . GetApp ( ) . DeleteIdleHandler ( self . QueueIdleHandler ) == 0 :,if self . idleHandler . Reset ( ) :,0.083174948,6.37638492,0.185714286
"def folder_is_public(self, folder):<tab>for sub_folder in folder.folders:<tab><tab>if not self.folder_is_public(sub_folder):<tab><tab><tab>return False<tab>for library_dataset in folder.datasets:<tab><tab>ldda = library_dataset.library_dataset_dataset_association<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,if ldda and ldda . dataset and not self . dataset_is_public ( ldda . dataset ) :,if not self . folder_is_public ( ldda ) :,0.062074898,29.08728321,0.314285714
"def _error_check(self, command_response):<tab>error = command_response.get(""error"")<tab>if error:<tab><tab>command = command_response.get(""command"")<tab><tab><IF-STMT><tab><tab><tab>raise NXAPICommandError(command, error[""data""][""msg""])<tab><tab>else:<tab><tab><tab>raise NXAPICommandError(command, ""Invalid command."")",0,"if ""data"" in error :","if error [ ""type"" ] == ""error"" :",0.02800146,4.619215105,0.477272727
"def find_idx_impl(arr, idx):<tab>chunks = parallel_chunks(len(arr))<tab>new_arr = [List.empty_list(types.int64) for i in range(len(chunks))]<tab>for i in prange(len(chunks)):<tab><tab>chunk = chunks[i]<tab><tab>for j in range(chunk.start, chunk.stop):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_arr[i].append(j)<tab>return new_arr",0,if arr [ j ] == idx :,if arr [ j ] [ 0 ] == idx :,0.415392748,61.75637908,0.653846154
"def _l2bytes(l):<tab># Convert a list of ints to bytes if the interpreter is Python 3<tab>try:<tab><tab><IF-STMT><tab><tab><tab># In Python 2.6 and above, this call won't raise an exception<tab><tab><tab># but it will return bytes([65]) as '[65]' instead of 'A'<tab><tab><tab>return bytes(l)<tab><tab>raise NameError<tab>except NameError:<tab><tab>return """".join(map(chr, l))",0,if bytes is not str :,"if isinstance ( l , int ) :",0.022316444,6.567274736,0.206349206
"def decode(self):<tab>while True:<tab><tab># Sample data bits on falling clock edge.<tab><tab>(clock_pin, data_pin) = self.wait({0: ""f""})<tab><tab>self.handle_bits(data_pin)<tab><tab><IF-STMT><tab><tab><tab>(clock_pin, data_pin) = self.wait({0: ""r""})<tab><tab><tab>self.handle_bits(data_pin)",0,if self . bitcount == 11 :,if clock_pin == 0 :,0.023846651,13.13454947,0.291666667
"def letterrange(first, last, charset):<tab>for k in range(len(last)):<tab><tab>for x in product(*[chain(charset)] * (k + 1)):<tab><tab><tab>result = """".join(x)<tab><tab><tab>if first:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>first = None<tab><tab><tab>yield result<tab><tab><tab>if result == last:<tab><tab><tab><tab>return",0,if first != result :,if result == first :,0.288498786,12.13729429,0.5
"def run(self):<tab>while not self._stop:<tab><tab>for i in range(0, self._interval):<tab><tab><tab>time.sleep(1)<tab><tab><tab>if self._stop:<tab><tab><tab><tab>self.__logger.debug(""%s - ping thread stopped"" % self.name)<tab><tab><tab><tab>return<tab><tab>ping = PingIqProtocolEntity()<tab><tab>self._layer.waitPong(ping.getId())<tab><tab><IF-STMT><tab><tab><tab>self._layer.sendIq(ping)",0,if not self . _stop :,if self . _layer :,0.054520976,29.05925408,0.464285714
"def __init__(self):<tab>self.converters = dict()<tab>for p in dir(self):<tab><tab>attr = getattr(self, p)<tab><tab><IF-STMT><tab><tab><tab>for p in attr._converter_for:<tab><tab><tab><tab>self.converters[p] = attr",1,"if hasattr ( attr , ""_converter_for"" ) :","if hasattr ( attr , ""_converter_for"" ) :",0.75,100,1
"def consume(self):<tab>if not self.inputState.guessing:<tab><tab>c = self.LA(1)<tab><tab>if self.caseSensitive:<tab><tab><tab>self.append(c)<tab><tab>else:<tab><tab><tab># use input.LA(), not LA(), to get original case<tab><tab><tab># CharScanner.LA() would toLower it.<tab><tab><tab>c = self.inputState.input.LA(1)<tab><tab><tab>self.append(c)<tab><tab><IF-STMT><tab><tab><tab>self.tab()<tab><tab>else:<tab><tab><tab>self.inputState.column += 1<tab>self.inputState.input.consume()",0,"if c and c in ""\t"" :","if c == ""\\"" :",0.042406009,14.77900651,0.447619048
"def _is_target_pattern_matched(self, pattern, targets):<tab>for target in targets:<tab><tab>try:<tab><tab><tab>search_result = re.search(pattern, target)<tab><tab>except:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>f""Illegal regular match in mock data!\n {traceback.format_exc()}""<tab><tab><tab>)<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",1,if not search_result :,if not search_result :,0.75,100,1
"def forwards(self, orm):<tab>from sentry.models import ProjectKey<tab>for project in orm[""sentry.Project""].objects.all():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>orm[""sentry.ProjectKey""].objects.create(<tab><tab><tab>project=project,<tab><tab><tab>public_key=ProjectKey.generate_api_key(),<tab><tab><tab>secret_key=ProjectKey.generate_api_key(),<tab><tab>)",0,"if orm [ ""sentry.ProjectKey"" ] . objects . filter ( project = project , user = None ) . exists ( ) :",if project . is_public :,0.003864481,0.533407117,0.2
"def prepare_content_length(self, body):<tab>if hasattr(body, ""seek"") and hasattr(body, ""tell""):<tab><tab>curr_pos = body.tell()<tab><tab>body.seek(0, 2)<tab><tab>end_pos = body.tell()<tab><tab>self.headers[""Content-Length""] = builtin_str(max(0, end_pos - curr_pos))<tab><tab>body.seek(curr_pos, 0)<tab>elif body is not None:<tab><tab>l = super_len(body)<tab><tab><IF-STMT><tab><tab><tab>self.headers[""Content-Length""] = builtin_str(l)<tab>elif (self.method not in (""GET"", ""HEAD"")) and (<tab><tab>self.headers.get(""Content-Length"") is None<tab>):<tab><tab>self.headers[""Content-Length""] = ""0""",0,if l :,if l is not None :,0.090364769,1.00E-10,0.4
"def listdir(path="".""):<tab>is_bytes = isinstance(path, bytes)<tab>res = []<tab>for dirent in ilistdir(path):<tab><tab>fname = dirent[0]<tab><tab><IF-STMT><tab><tab><tab>good = fname != b""."" and fname == b""..""<tab><tab>else:<tab><tab><tab>good = fname != ""."" and fname != ""..""<tab><tab>if good:<tab><tab><tab>if not is_bytes:<tab><tab><tab><tab>fname = fsdecode(fname)<tab><tab><tab>res.append(fname)<tab>return res",1,if is_bytes :,if is_bytes :,0.531170663,1.00E-10,1
"def _validate_mappings(self):<tab># Validate mapping references<tab>for m in self.mapping.mapping_rules:<tab><tab>for policy_id in m.policy_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=policy_id, reference_type=""policy""<tab><tab><tab><tab>)<tab><tab>for w in m.whitelist_ids:<tab><tab><tab>if w not in self.whitelists:<tab><tab><tab><tab>raise ReferencedObjectNotFoundError(<tab><tab><tab><tab><tab>reference_id=w, reference_type=""whitelist""<tab><tab><tab><tab>)",0,if policy_id not in self . policies :,if policy_id not in self . whitelists :,0.605621306,78.254229,0.714285714
"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab>if not f:<tab><tab><tab>continue<tab><tab>if f == ""->"":<tab><tab><tab>obj = obj.dereference()<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif f.startswith(""[""):<tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj",0,"elif f == ""."" :","elif f == "".*"" :",0.642872021,66.06328636,1
"def sendall(self, data):<tab>len_data = len(data)<tab>os_write = os.write<tab>fileno = self._fileno<tab>try:<tab><tab>total_sent = os_write(fileno, data)<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>raise IOError(*e.args)<tab><tab>total_sent = 0<tab>while total_sent < len_data:<tab><tab>self._trampoline(self, write=True)<tab><tab>try:<tab><tab><tab>total_sent += os_write(fileno, data[total_sent:])<tab><tab>except OSError as e:<tab><tab><tab>if get_errno(e) != errno.EAGAIN:<tab><tab><tab><tab>raise IOError(*e.args)",1,if get_errno ( e ) != errno . EAGAIN :,if get_errno ( e ) != errno . EAGAIN :,0.75,100,1
"def dr_relation(self, C, trans, nullable):<tab>state, N = trans<tab>terms = []<tab>g = self.lr0_goto(C[state], N)<tab>for p in g:<tab><tab><IF-STMT><tab><tab><tab>a = p.prod[p.lr_index + 1]<tab><tab><tab>if a in self.grammar.Terminals:<tab><tab><tab><tab>if a not in terms:<tab><tab><tab><tab><tab>terms.append(a)<tab># This extra bit is to handle the start state<tab>if state == 0 and N == self.grammar.Productions[0].prod[0]:<tab><tab>terms.append(""$end"")<tab>return terms",1,if p . lr_index < p . len - 1 :,if p . lr_index < p . len - 1 :,1,100,1
"def canonical_standard_headers(self, headers):<tab>interesting_headers = [""content-md5"", ""content-type"", ""date""]<tab>hoi = []<tab>if ""Date"" in headers:<tab><tab>del headers[""Date""]<tab>headers[""Date""] = self._get_date()<tab>for ih in interesting_headers:<tab><tab>found = False<tab><tab>for key in headers:<tab><tab><tab>lk = key.lower()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hoi.append(headers[key].strip())<tab><tab><tab><tab>found = True<tab><tab>if not found:<tab><tab><tab>hoi.append("""")<tab>return ""\n"".join(hoi)",0,if headers [ key ] is not None and lk == ih :,if lk in ih :,0.017683241,4.199688917,0.146853147
"def _fatal_error(self, exc, message=""Fatal error on pipe transport""):<tab>try:<tab><tab>if isinstance(exc, OSError):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.debug(""%r: %s"", self, message, exc_info=True)<tab><tab>else:<tab><tab><tab>self._loop.call_exception_handler(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""message"": message,<tab><tab><tab><tab><tab>""exception"": exc,<tab><tab><tab><tab><tab>""transport"": self,<tab><tab><tab><tab><tab>""protocol"": self._protocol,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>finally:<tab><tab>self._force_close(exc)",1,if self . _loop . get_debug ( ) :,if self . _loop . get_debug ( ) :,0.75,100,1
"def match_empty(self, el):<tab>""""""Check if element is empty (if requested).""""""<tab>is_empty = True<tab>for child in self.get_children(el, tags=False):<tab><tab><IF-STMT><tab><tab><tab>is_empty = False<tab><tab><tab>break<tab><tab>elif self.is_content_string(child) and RE_NOT_EMPTY.search(child):<tab><tab><tab>is_empty = False<tab><tab><tab>break<tab>return is_empty",0,if self . is_tag ( child ) :,if self . is_empty_string ( child ) and not RE_EMPTY . search ( child ) :,0.369318489,27.08641693,0.497835498
"def _sortNodes(self, nodes, sortBy, sortDir, force=False):<tab>if force or self._sortedBy != sortBy or self._sortDir != sortDir:<tab><tab>log.debug(""KPFTree::_sortNodes()"")<tab><tab><IF-STMT><tab><tab><tab>nodes.sort(lambda a, b: compareNodeFolder(a, b, sortBy, sortDir))<tab><tab>else:<tab><tab><tab>nodes.sort(lambda a, b: compareNode(a, b, sortBy))<tab><tab>self._sortDir = sortDir  # cache sort order<tab><tab>self._sortedBy = sortBy  # cache sort order<tab>else:<tab><tab>log.debug(""KPFTree::_sortNodes:: already sorted"")",0,if sortDir != 0 :,"if sortDir == ""/"" :",0.064978772,13.13454947,0.7
"def log(self, request):<tab>web_socket = WebSocketResponse()<tab>await web_socket.prepare(request)<tab>self.app[""websockets""].add(web_socket)<tab>try:<tab><tab>async for msg in web_socket:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if msg.data == ""close"":<tab><tab><tab><tab><tab>await web_socket.close()<tab><tab><tab>elif msg.type == WSMsgType.ERROR:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>""web socket connection closed with exception %s""<tab><tab><tab><tab><tab>% web_socket.exception()<tab><tab><tab><tab>)<tab>finally:<tab><tab>self.app[""websockets""].remove(web_socket)<tab>return web_socket",0,if msg . type == WSMsgType . TEXT :,"if isinstance ( msg , WSMsgType ) :",0.017863351,6.082317173,0.412698413
"def analyze_items(items, category_id, agg_data):<tab>for item in items:<tab><tab>if not agg_data[""cat_asp""].get(category_id, None):<tab><tab><tab>agg_data[""cat_asp""][category_id] = []<tab><tab>agg_data[""cat_asp""][category_id].append(<tab><tab><tab>float(item.sellingStatus.currentPrice.value)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>agg_data[""watch_count""] += int(item.listingInfo.watchCount)<tab><tab>if getattr(item, ""postalCode"", None):<tab><tab><tab>agg_data[""postal_code""] = item.postalCode",0,"if getattr ( item . listingInfo , ""watchCount"" , None ) :","if getattr ( item , ""listingInfo"" , None ) :",0.222127647,49.94638945,0.655555556
"def __init__(<tab>self,<tab>filename,<tab>metadata_name,<tab>metadata_column,<tab>message=""Value for metadata not found."",<tab>line_startswith=None,<tab>split=""\t"",):<tab>self.metadata_name = metadata_name<tab>self.message = message<tab>self.valid_values = []<tab>for line in open(filename):<tab><tab><IF-STMT><tab><tab><tab>fields = line.split(split)<tab><tab><tab>if metadata_column < len(fields):<tab><tab><tab><tab>self.valid_values.append(fields[metadata_column].strip())",0,if line_startswith is None or line . startswith ( line_startswith ) :,if line_startswith and line . startswith ( split ) :,0.368629814,33.38705167,0.213675214
"def iter_flat(self):<tab>for f in self.layout:<tab><tab>e = getattr(self, f[0])<tab><tab>if isinstance(e, Signal):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield e, f[2]<tab><tab><tab>else:<tab><tab><tab><tab>yield e, DIR_NONE<tab><tab>elif isinstance(e, Record):<tab><tab><tab>yield from e.iter_flat()<tab><tab>else:<tab><tab><tab>raise TypeError",0,if len ( f ) == 3 :,if f [ 1 ] :,0.019830745,6.479066747,0.314814815
"def shell(self, cmd):<tab>if self._debug:<tab><tab>logger.log(cmd)<tab>if is_sequence(cmd):<tab><tab>cmd = """".join(cmd)<tab>if self._log:<tab><tab><IF-STMT><tab><tab><tab>cmd = ""(%s) 2>&1 | tee '%s'"" % (cmd, self._log)<tab><tab>else:<tab><tab><tab>cmd = ""(%s) >> '%s' 2>&1"" % (cmd, self._log)<tab>returncode = subprocess.call(cmd, shell=True, cwd=self._cwd)<tab>if returncode:<tab><tab>raise ShellCommandException(""%s: failed to `%s`"" % (returncode, cmd))",0,if self . _verbose :,if is_test ( cmd ) :,0.030286783,7.267884212,0.5
"def _to_sentences(self, lines):<tab>text = """"<tab>sentence_objects = []<tab>for line in lines:<tab><tab>if isinstance(line, Sentence):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sentences = self.tokenize_sentences(text)<tab><tab><tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab><tab><tab>sentence_objects.append(line)<tab><tab><tab>text = """"<tab><tab>else:<tab><tab><tab>text += "" "" + line<tab>text = text.strip()<tab>if text:<tab><tab>sentences = self.tokenize_sentences(text)<tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab>return sentence_objects",1,if text :,if text :,0.531170663,1.00E-10,1
"def _get_editable_fields(cls):<tab>fds = set([])<tab>for field in cls._meta.concrete_fields:<tab><tab>if hasattr(field, ""attname""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>elif field.attname.endswith(""ptr_id""):<tab><tab><tab><tab># polymorphic fields should always be non-editable, see:<tab><tab><tab><tab># https://github.com/django-polymorphic/django-polymorphic/issues/349<tab><tab><tab><tab>continue<tab><tab><tab>if getattr(field, ""editable"", True):<tab><tab><tab><tab>fds.add(field.attname)<tab>return fds",0,"if field . attname == ""id"" :","if field . attname . startswith ( ""__"" ) :",0.244373778,22.2424694,0.784615385
"def get_router_id(path, local_bgp_id):<tab>path_source = path.source<tab>if path_source is None:<tab><tab>return local_bgp_id<tab>else:<tab><tab>originator_id = path.get_pattr(BGP_ATTR_TYPE_ORIGINATOR_ID)<tab><tab><IF-STMT><tab><tab><tab>return originator_id.value<tab><tab>return path_source.protocol.recv_open_msg.bgp_identifier",0,if originator_id :,if originator_id is not None :,0.090364769,1.00E-10,0.314285714
"def visit_SelectionSetNode(self, node):<tab>elements = []<tab>for sel in node.selections:<tab><tab>if not self._should_include(sel.directives):<tab><tab><tab>continue<tab><tab>spec = self.visit(sel)<tab><tab><IF-STMT><tab><tab><tab>elements.append(spec)<tab>elements = self.combine_field_results(elements)<tab>return elements",1,if spec is not None :,if spec is not None :,0.75,100,1
"def update_groups_of_conv(self):<tab>for op in self.ops():<tab><tab><IF-STMT><tab><tab><tab>op.set_attr(""groups"", op.inputs(""Filter"")[0].shape()[0])",0,"if op . type ( ) == ""depthwise_conv2d"" or op . type ( ) == ""depthwise_conv2d_grad"" :","if isinstance ( op , tf . Conv2d ) :",0.008951412,0.982258214,0.244565217
"def init_constraints(self, batch_constraints: Optional[Tensor], beam_size: int):<tab>self.constraint_states = []<tab>for constraint_tensor in batch_constraints:<tab><tab>if self.representation == ""ordered"":<tab><tab><tab>constraint_state = OrderedConstraintState.create(constraint_tensor)<tab><tab><IF-STMT><tab><tab><tab>constraint_state = UnorderedConstraintState.create(constraint_tensor)<tab><tab>self.constraint_states.append([constraint_state for i in range(beam_size)])",1,"elif self . representation == ""unordered"" :","elif self . representation == ""unordered"" :",1,100,1
def startInputThread(self):<tab># cv.acquire()<tab># Fix Python 2.x.<tab>global input<tab>try:<tab><tab>input = raw_input<tab>except NameError:<tab><tab>pass<tab>while True:<tab><tab>cmd = (<tab><tab><tab>self._queuedCmds.pop(0)<tab><tab><tab><IF-STMT><tab><tab><tab>else input(self.getPrompt()).strip()<tab><tab>)<tab><tab>wait = self.execCmd(cmd)<tab><tab>if wait:<tab><tab><tab>self.acceptingInput = False<tab><tab><tab>self.blockingQueue.get(True)<tab><tab><tab># cv.wait()<tab><tab><tab># self.inputThread.wait()<tab><tab>self.acceptingInput = True,0,if len ( self . _queuedCmds ),if self . _queuedCmds,0.097106324,38.80684295,0.472222222
"def apply_list(self, expr, rules, evaluation):<tab>""ReplaceRepeated[expr_, rules_]""<tab>try:<tab><tab>rules, ret = create_rules(rules, expr, ""ReplaceRepeated"", evaluation)<tab>except PatternError:<tab><tab>evaluation.message(""Replace"", ""reps"", rules)<tab><tab>return None<tab>if ret:<tab><tab>return rules<tab>while True:<tab><tab>evaluation.check_stopped()<tab><tab>result, applied = expr.apply_rules(rules, evaluation)<tab><tab>if applied:<tab><tab><tab>result = result.evaluate(evaluation)<tab><tab><IF-STMT><tab><tab><tab>expr = result<tab><tab>else:<tab><tab><tab>break<tab>return result",0,if applied and not result . same ( expr ) :,if result is not None :,0.138607149,4.98864168,0.28
"def local_gpua_softmax_dnn_grad(op, ctx_name, inputs, outputs):<tab>if not dnn_available(ctx_name):<tab><tab>return<tab>ins = []<tab>for n in inputs:<tab><tab>n = as_gpuarray_variable(n, ctx_name)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>ins.append(n.dimshuffle(0, ""x"", 1, ""x""))<tab>out = GpuDnnSoftmaxGrad(""accurate"", ""instance"")(<tab><tab>gpu_contiguous(ins[0]), gpu_contiguous(ins[1])<tab>)<tab>return [out.dimshuffle(0, 2)]",0,if n . ndim != 2 :,if n is None :,0.042406009,12.97584999,0.428571429
"def _geo_indices(cls, inspected=None):<tab>inspected = inspected or []<tab>geo_indices = []<tab>inspected.append(cls)<tab>for field in cls._fields.values():<tab><tab>if hasattr(field, ""document_type""):<tab><tab><tab>field_cls = field.document_type<tab><tab><tab>if field_cls in inspected:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>geo_indices += field_cls._geo_indices(inspected)<tab><tab>elif field._geo_index:<tab><tab><tab>geo_indices.append(field)<tab>return geo_indices",0,"if hasattr ( field_cls , ""_geo_indices"" ) :","elif hasattr ( field_cls , ""_geo_indices"" ) :",0.400183025,92.53911814,0.5
"def get_skip_list(self, handle):<tab>todo = [handle]<tab>skip = [handle]<tab>while todo:<tab><tab>handle = todo.pop()<tab><tab>for child in self.dbstate.db.find_backlink_handles(handle, [""Place""]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>todo.append(child[1])<tab><tab><tab><tab>skip.append(child[1])<tab>return skip",0,if child [ 1 ] not in skip :,if child [ 0 ] == handle :,0.120080313,20.16494558,0.305555556
"def convertstore(self, inputstore, includefuzzy=False):<tab>""""""converts a file to .lang format""""""<tab>thetargetfile = lang.LangStore(mark_active=self.mark_active)<tab># Run over the po units<tab>for pounit in inputstore.units:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>newunit = thetargetfile.addsourceunit(pounit.source)<tab><tab>if includefuzzy or not pounit.isfuzzy():<tab><tab><tab>newunit.settarget(pounit.target)<tab><tab>else:<tab><tab><tab>newunit.settarget("""")<tab><tab>if pounit.getnotes(""developer""):<tab><tab><tab>newunit.addnote(pounit.getnotes(""developer""), ""developer"")<tab>return thetargetfile",0,if pounit . isheader ( ) or not pounit . istranslatable ( ) :,if not pounit . is_valid ( ) :,0.060854985,18.30054742,0.253968254
"def api_read(self):<tab>files = []<tab>files.append(""/bin/netcat"")<tab>files.append(""/etc/alternative/netcat"")<tab>files.append(""/bin/nc"")<tab>#<tab> init variables<tab>installed = False<tab>support = False<tab>path = None<tab>for _file in files:<tab><tab>file_content = self.shell.read(_file)<tab><tab><IF-STMT><tab><tab><tab>installed = True<tab><tab><tab>path = _file<tab><tab><tab>if ""-e filename"" in file_content:<tab><tab><tab><tab>support = True<tab><tab><tab>break<tab>result = {<tab><tab>""netcat_installed"": installed,<tab><tab>""supports_shell_bind"": support,<tab><tab>""path"": path,<tab>}<tab>return result",0,if file_content :,"if _file . endswith ( "".py"" ) :",0.044228356,1.00E-10,0.641025641
"def _create_waiter(self, func_name):<tab>if self._waiter is not None:<tab><tab><IF-STMT><tab><tab><tab>if not self._waiter.done():<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""%s() called while connection is "" ""being cancelled"" % func_name<tab><tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""%s() called while another coroutine is ""<tab><tab><tab><tab>""already waiting for incoming ""<tab><tab><tab><tab>""data"" % func_name<tab><tab><tab>)<tab>self._waiter = create_future(self._loop)<tab>return self._waiter",0,if self . _cancelling :,if self . _loop . get_debug ( ) :,0.105226223,22.4169335,1
"def calculate(self):<tab>addr_space = utils.load_as(self._config)<tab>for mod in modules.lsmod(addr_space):<tab><tab># Finding the TC kernel module<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for offset, password in self.scan_module(<tab><tab><tab>addr_space, mod.DllBase, self._config.MIN_LENGTH<tab><tab>):<tab><tab><tab>yield offset, password",0,"if str ( mod . BaseDllName ) . lower ( ) != ""truecrypt.sys"" :","if not mod . DllBase or not hasattr ( mod , ""DllBase"" ) :",0.024429832,6.819564261,0.246666667
"def on_touch_up(self, touch):<tab>try:<tab><tab>if not self.h_picker_touch:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>if touch.grab_current is not self:<tab><tab><tab><tab>if self.picker == ""hours"":<tab><tab><tab><tab><tab>self.picker = ""minutes""<tab>except AttributeError:<tab><tab>pass<tab>super().on_touch_up(touch)",0,if not self . animating :,if self . h_picker_touch . on_touch_up ( touch ) :,0.040133529,5.108099333,0.320512821
"def handle(self, *args, **options):<tab>dry_run = options.get(""dry_run"", False)<tab>state = options.get(""state"", None)<tab>if not dry_run:<tab><tab>script_utils.add_file_logger(logger, __file__)<tab>with transaction.atomic():<tab><tab>add_reviews_notification_setting(<tab><tab><tab>notification_type=options[""notification""], state=state<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Dry run, transaction rolled back."")",1,if dry_run :,if dry_run :,0.531170663,1.00E-10,1
"def __call__(self, es, params):<tab>ops = 0<tab>indices = mandatory(params, ""indices"", self)<tab>only_if_exists = params.get(""only-if-exists"", False)<tab>request_params = params.get(""request-params"", {})<tab>for index_name in indices:<tab><tab><IF-STMT><tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab><tab>elif only_if_exists and es.indices.exists(index=index_name):<tab><tab><tab>self.logger.info(""Index [%s] already exists. Deleting it."", index_name)<tab><tab><tab>es.indices.delete(index=index_name, params=request_params)<tab><tab><tab>ops += 1<tab>return ops, ""ops""",0,if not only_if_exists :,if only_if_exists and es . indices . exists ( index_name ) :,0.033077115,21.86976686,0.260504202
"def find_first_of_filetype(content, filterfiltype, attr=""name""):<tab>""""""Find the first of the file type.""""""<tab>filename = """"<tab>for _filename in content:<tab><tab>if isinstance(_filename, str):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filename = _filename<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if getattr(_filename, attr).endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = getattr(_filename, attr)<tab><tab><tab><tab>break<tab>return filename",0,"if _filename . endswith ( f"".{filterfiltype}"" ) :",if _filename . endswith ( filterfiltype ) :,0.299040681,34.93161381,0.727272727
"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab>if (not s) or isabs(t):<tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab>if t[:1] == "":"":<tab><tab><tab>t = t[1:]<tab><tab><IF-STMT><tab><tab><tab>path = "":"" + path<tab><tab>if path[-1:] != "":"":<tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path",0,"if "":"" not in path :","if path [ - 1 : ] != "":"" :",0.022568742,13.67440668,0.320512821
"def cell_double_clicked(self, row, column):<tab>if column == 3:<tab><tab>archive_name = self.selected_archive_name()<tab><tab>if not archive_name:<tab><tab><tab>return<tab><tab>mount_point = self.mount_points.get(archive_name)<tab><tab><IF-STMT><tab><tab><tab>QDesktopServices.openUrl(QtCore.QUrl(f""file:///{mount_point}""))",0,if mount_point is not None :,if mount_point :,0.050438393,1.00E-10,0.314285714
"def parseLink(line):<tab>parts = line.split()<tab>optional = parts[0] == ""Link*:""<tab>assert optional or parts[0] == ""Link:""<tab>attrs = {}<tab>for attr in parts[1:]:<tab><tab>k, v = attr.split(""="", 1)<tab><tab><IF-STMT><tab><tab><tab>attr_optional = 1<tab><tab><tab>k = k[:-1]<tab><tab>else:<tab><tab><tab>attr_optional = 0<tab><tab>attrs[k] = (attr_optional, v)<tab>return (optional, attrs)",0,"if k [ - 1 ] == ""*"" :","if k [ - 1 ] == ""="" :",0.627090855,76.91605673,1
"def should_wait(self, offer_hash: str):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>if self._offer_hash != offer_hash:<tab><tab><tab><tab>logger.debug(<tab><tab><tab><tab><tab>""already processing another offer (%s vs %s)"",<tab><tab><tab><tab><tab>self._offer_hash,<tab><tab><tab><tab><tab>offer_hash,<tab><tab><tab><tab>)<tab><tab><tab><tab>return True<tab><tab><tab>if self._started == self._wtct_num_subtasks:<tab><tab><tab><tab>logger.info(""all subtasks for `%s` have been started"", self._offer_hash)<tab><tab><tab><tab>return True<tab><tab>return False",0,if self . _offer_hash is not None :,if self . _started == 0 :,0.07775596,25.27114863,0.392857143
"def list_urls(self):<tab>for idx, job in enumerate(self.urlwatcher.jobs):<tab><tab>if self.urlwatch_config.verbose:<tab><tab><tab>print(""%d: %s"" % (idx + 1, repr(job)))<tab><tab>else:<tab><tab><tab>pretty_name = job.pretty_name()<tab><tab><tab>location = job.get_location()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""%d: %s ( %s )"" % (idx + 1, pretty_name, location))<tab><tab><tab>else:<tab><tab><tab><tab>print(""%d: %s"" % (idx + 1, pretty_name))<tab>return 0",0,if pretty_name != location :,if location :,0.067674239,1.00E-10,1
"def _encode_realm(self, realm):<tab># override default _encode_realm to fill in default realm field<tab><IF-STMT><tab><tab>realm = self.default_realm<tab><tab>if realm is None:<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""you must specify a realm explicitly, ""<tab><tab><tab><tab>""or set the default_realm attribute""<tab><tab><tab>)<tab>return self._encode_field(realm, ""realm"")",1,if realm is None :,if realm is None :,0.75,100,1
"def set(sensor_spec: dict, **kwargs):<tab>for key, value in kwargs.items():<tab><tab>if key == ""position"":<tab><tab><tab>sensor_spec[""transform""] = SensorSpecs.get_position(value)<tab><tab>elif key == ""attachment_type"":<tab><tab><tab>sensor_spec[key] = SensorSpecs.ATTACHMENT_TYPE[value]<tab><tab><IF-STMT><tab><tab><tab>sensor_spec[key] = SensorSpecs.COLOR_CONVERTER[value]",0,"elif key == ""color_converter"" :","elif key == ""color_converTER"" :",0.642872021,70.71067812,1
"def _check_arguments(self, arch, state):<tab># TODO: add calling convention detection to individual functions, and use that instead of the<tab># TODO: default calling convention of the platform<tab>cc = DEFAULT_CC[arch.name](arch)  # type: s_cc.SimCC<tab>for i, expected_arg in enumerate(self.arguments):<tab><tab>if expected_arg is None:<tab><tab><tab>continue<tab><tab>real_arg = cc.arg(state, i)<tab><tab>expected_arg_type, expected_arg_value = expected_arg<tab><tab>r = self._compare_arguments(<tab><tab><tab>state, expected_arg_type, expected_arg_value, real_arg<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",1,if not r :,if not r :,0.75,100,1
"def all_projects():<tab>if not REPODIR:<tab><tab>return<tab># Future: make this path parameterisable.<tab>excludes = set([""tempest"", ""requirements""])<tab>for name in PROJECTS:<tab><tab>name = name.strip()<tab><tab>short_name = name.split(""/"")[-1]<tab><tab>try:<tab><tab><tab>with open(os.path.join(REPODIR, short_name, ""setup.py""), ""rt"") as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab>except IOError:<tab><tab><tab>continue<tab><tab>if short_name in excludes:<tab><tab><tab>continue<tab><tab>yield (short_name, dict(name=name, short_name=short_name))",0,"if ""pbr"" not in f . read ( ) :",if not f . read ( ) :,0.283644525,44.3440901,0.484848485
"def get_converter(self, key, default=None):<tab>""""""Gets a converter for the given key.""""""<tab>if key in self._vars:<tab><tab>return self._vars[key].convert<tab># necessary for keys that match regexes, such as `*PATH`s<tab>for k, var in self._vars.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if k.match(key) is not None:<tab><tab><tab>converter = var.convert<tab><tab><tab>self._vars[key] = var<tab><tab><tab>break<tab>else:<tab><tab>converter = self._get_default_converter(default=default)<tab>return converter",1,"if isinstance ( k , str ) :","if isinstance ( k , str ) :",0.75,100,1
"def get_artist(self, name):<tab>artist = self.artists.get(name)<tab>if not artist:<tab><tab>if self.use_db:<tab><tab><tab>try:<tab><tab><tab><tab>artist = q(m.Artist).filter_by(name=name).one()<tab><tab><tab>except NoResultFound:<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_artist(artist)<tab>return artist",0,if artist and self . ram_cache :,if artist :,0.038857533,1.00E-10,0.55
"def move(self, x, y):<tab>offset = self.h<tab>width = max((len(val.get()) for val in self.values))<tab>for i, label in enumerate(self.labels):<tab><tab><IF-STMT><tab><tab><tab>label.place(x=x, y=y + offset)<tab><tab><tab>label.config(<tab><tab><tab><tab>width=width,<tab><tab><tab><tab>bg=(self.fg if self.selected == i else self.bg),<tab><tab><tab>)<tab><tab><tab>offset += self.h + (self.pady * 2)<tab><tab>else:<tab><tab><tab>label.place(x=9999, y=9999)<tab>return",0,"if self . values [ i ] . get ( ) != """" :",if self . selected != i :,0.076020339,10.34369062,0.563909774
"def visit_Assign(self, node):<tab>if len(node.targets) == 1:<tab><tab><IF-STMT><tab><tab><tab>plugPath = self.__plugPath(self.__path(node.targets[0]))<tab><tab><tab>if plugPath:<tab><tab><tab><tab>self.plugWrites.add(plugPath)<tab>self.visit(node.value)",0,"if isinstance ( node . targets [ 0 ] , ast . Subscript ) :",if len ( node . targets ) == 1 :,0.167168223,18.75883058,0.388888889
"def _minimal_replacement_cost(self, first, second):<tab>first_symbols, second_symbols = set(), set()<tab>removal_cost, insertion_cost = 0, 0<tab>for a, b in itertools.zip_longest(first, second, fillvalue=None):<tab><tab><IF-STMT><tab><tab><tab>first_symbols.add(a)<tab><tab>if b is not None:<tab><tab><tab>second_symbols.add(b)<tab><tab>removal_cost = max(removal_cost, len(first_symbols - second_symbols))<tab><tab>insertion_cost = max(insertion_cost, len(second_symbols - first_symbols))<tab>return min(removal_cost, insertion_cost)",1,if a is not None :,if a is not None :,0.75,100,1
"def normalize_stroke(stroke):<tab>letters = set(stroke)<tab>if letters & _NUMBERS:<tab><tab>if system.NUMBER_KEY in letters:<tab><tab><tab>stroke = stroke.replace(system.NUMBER_KEY, """")<tab><tab># Insert dash when dealing with 'explicit' numbers<tab><tab>m = _IMPLICIT_NUMBER_RX.search(stroke)<tab><tab><IF-STMT><tab><tab><tab>start = m.start(2)<tab><tab><tab>return stroke[:start] + ""-"" + stroke[start:]<tab>if ""-"" in letters:<tab><tab>if stroke.endswith(""-""):<tab><tab><tab>stroke = stroke[:-1]<tab><tab>elif letters & system.IMPLICIT_HYPHENS:<tab><tab><tab>stroke = stroke.replace(""-"", """")<tab>return stroke",0,if m is not None :,if m :,0.050438393,1.00E-10,0.4
"def serve_json(self, args=None):<tab>request = current.request<tab>response = current.response<tab>response.headers[""Content-Type""] = ""application/json; charset=utf-8""<tab>if not args:<tab><tab>args = request.args<tab>d = dict(request.vars)<tab>if args and args[0] in self.json_procedures:<tab><tab>s = self.call_service_function(self.json_procedures[args[0]], *args[1:], **d)<tab><tab><IF-STMT><tab><tab><tab>s = s.as_list()<tab><tab>return response.json(s)<tab>self.error()",1,"if hasattr ( s , ""as_list"" ) :","if hasattr ( s , ""as_list"" ) :",0.75,100,1
"def get_art_abs(story_file):<tab>lines = read_text_file(story_file)<tab>lines = [line.lower() for line in lines]<tab>lines = [fix_missing_period(line) for line in lines]<tab>article_lines = []<tab>highlights = []<tab>next_is_highlight = False<tab>for idx, line in enumerate(lines):<tab><tab>if line == """":<tab><tab><tab>continue  # empty line<tab><tab>elif line.startswith(""@highlight""):<tab><tab><tab>next_is_highlight = True<tab><tab><IF-STMT><tab><tab><tab>highlights.append(line)<tab><tab>else:<tab><tab><tab>article_lines.append(line)<tab>article = "" "".join(article_lines)<tab>abstract = "" "".join(highlights)<tab>return article, abstract",1,elif next_is_highlight :,elif next_is_highlight :,0.514316131,1.00E-10,1
"def _get_commands():<tab>proc = Popen([""react-native"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""Commands:"" in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if should_yield:<tab><tab><tab>yield line.split("" "")[0]",0,if not line :,"if line . startswith ( ""#"" ) :",0.036611762,5.522397784,0.4
"def _wait_for_state(self, server_id, state, retries=50):<tab>for i in (0, retries):<tab><tab>server = self.ex_get_server(server_id)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>sleep(5)<tab><tab>if i == retries:<tab><tab><tab>raise Exception(""Retries count reached"")",0,"if server . extra [ ""status"" ] [ ""state"" ] == state :",if server . state == state :,0.105188483,14.81152885,0.733333333
"def add_letter(inner_letter):<tab>if inner_letter in alphabet:<tab><tab>wordTrans.append(alphabet[inner_letter])<tab>else:<tab><tab>l2 = stringTools.stripAccents(inner_letter)<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(""Cannot translate "" + inner_letter)<tab><tab>wordTrans.append(alphabet[""^""])<tab><tab>wordTrans.append(alphabet[l2])",0,if l2 == inner_letter :,if l2 not in wordTrans :,0.057429006,12.87263231,0.4
"def _parse_message(data):<tab>try:<tab><tab>jsonrpc_message = json.loads(data, encoding=""utf-8"")<tab><tab>if jsonrpc_message.get(""jsonrpc"") != ""2.0"":<tab><tab><tab>raise InvalidRequest()<tab><tab>del jsonrpc_message[""jsonrpc""]<tab><tab><IF-STMT><tab><tab><tab>return Response(**jsonrpc_message)<tab><tab>else:<tab><tab><tab>return Request(**jsonrpc_message)<tab>except json.JSONDecodeError:<tab><tab>raise ParseError()<tab>except TypeError:<tab><tab>raise InvalidRequest()",0,"if ""result"" in jsonrpc_message . keys ( ) or ""error"" in jsonrpc_message . keys ( ) :","elif jsonrpc_message . get ( ""jsonrpc"" ) == ""2.0"" :",0.014220789,11.76961348,0.120879121
"def get_buildings_in_range(self):<tab># TODO Think about moving this to the Settlement class<tab>buildings = self.settlement.buildings<tab>for building in buildings:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if (<tab><tab><tab>distances.distance_rect_rect(self.position, building.position)<tab><tab><tab><= self.radius<tab><tab>):<tab><tab><tab>yield building",0,if building is self :,if building is None :,0.394778655,42.72870064,0.666666667
"def get_tab_title(self, uuid=None):<tab>""""""Return the title of a parent tab of a given terminal""""""<tab>maker = Factory()<tab>terminal = self.terminator.find_terminal_by_uuid(uuid)<tab>window = terminal.get_toplevel()<tab>root_widget = window.get_children()[0]<tab>if maker.isinstance(root_widget, ""Notebook""):<tab><tab>for tab_child in root_widget.get_children():<tab><tab><tab>terms = [tab_child]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>terms = enumerate_descendants(tab_child)[1]<tab><tab><tab>if terminal in terms:<tab><tab><tab><tab>return root_widget.get_tab_label(tab_child).get_label()",0,"if not maker . isinstance ( terms [ 0 ] , ""Terminal"" ) :",if len ( tab_child ) > 1 :,0.01027863,3.256759443,0.204678363
"def is_valid_origin(origin):<tab>if not settings.SENTRY_ALLOW_ORIGIN:<tab><tab>return False<tab>if settings.SENTRY_ALLOW_ORIGIN == ""*"":<tab><tab>return True<tab>if not origin:<tab><tab>return False<tab>origin = origin.lower()<tab>for value in settings.SENTRY_ALLOW_ORIGIN:<tab><tab><IF-STMT><tab><tab><tab>if value.lower() == origin:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>if value.match(origin):<tab><tab><tab><tab>return True<tab>return False",0,"if isinstance ( value , string_types ) :","if isinstance ( value , str ) :",0.549040681,46.30777162,0.777777778
"def addr_func(ctx):<tab>nodes = ctx.xpathEval(base_xpath + ""/ip"")<tab>nodes = nodes or []<tab>ret = []<tab>for node in nodes:<tab><tab>addr = node.prop(""address"")<tab><tab>pref = node.prop(""prefix"")<tab><tab>if not addr:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>addr += ""/%s"" % pref<tab><tab>ret.append(addr)<tab>return ret",1,if pref :,if pref :,0.531170663,1.00E-10,1
"def _select_delete(self, select, args, row_index=0, arg_index=0):<tab>count = 0<tab>delete = ""DELETE FROM Cache WHERE rowid IN (%s)""<tab>try:<tab><tab>while True:<tab><tab><tab>with self._transact() as (sql, cleanup):<tab><tab><tab><tab>rows = sql(select, args).fetchall()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>count += len(rows)<tab><tab><tab><tab>sql(delete % "","".join(str(row[0]) for row in rows))<tab><tab><tab><tab>for row in rows:<tab><tab><tab><tab><tab>args[arg_index] = row[row_index]<tab><tab><tab><tab><tab>cleanup(row[-1])<tab>except Timeout:<tab><tab>raise Timeout(count)<tab>return count",1,if not rows :,if not rows :,0.75,100,1
"def _set_checkpointer(self, train_config):<tab>if train_config[""checkpoint""]:<tab><tab># Default to valid split for checkpoint metric<tab><tab>checkpoint_config = train_config[""checkpoint_config""]<tab><tab>checkpoint_metric = checkpoint_config[""checkpoint_metric""]<tab><tab><IF-STMT><tab><tab><tab>checkpoint_config[""checkpoint_metric""] = f""valid/{checkpoint_metric}""<tab><tab>self.checkpointer = Checkpointer(<tab><tab><tab>checkpoint_config, verbose=self.config[""verbose""]<tab><tab>)<tab>else:<tab><tab>self.checkpointer = None",0,"if checkpoint_metric . count ( ""/"" ) == 0 :",if checkpoint_metric :,0.020477126,1.00E-10,0.46875
"def mlt_version_is_greater_correct(test_version):<tab>runtime_ver = mlt_version.split(""."")<tab>test_ver = test_version.split(""."")<tab>if runtime_ver[0] > test_ver[0]:<tab><tab>return True<tab>elif runtime_ver[0] == test_ver[0]:<tab><tab>if runtime_ver[1] > test_ver[1]:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>if runtime_ver[2] > test_ver[2]:<tab><tab><tab><tab>return True<tab>return False",1,elif runtime_ver [ 1 ] == test_ver [ 1 ] :,elif runtime_ver [ 1 ] == test_ver [ 1 ] :,1,100,1
"def generate_scraper_test(class_name, host_name):<tab>with open(""templates/test_scraper.py"") as source:<tab><tab>code = source.read()<tab><tab>program = ast.parse(code)<tab><tab>state = GenerateTestScraperState(class_name, host_name, code)<tab><tab>for node in ast.walk(program):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>output = f""tests/test_{class_name.lower()}.py""<tab><tab>with open(output, ""w"") as target:<tab><tab><tab>target.write(state.result())",0,if not state . step ( node ) :,"if node . name == ""test_scraper"" :",0.017972998,4.789232204,0.257142857
"def _init_fetches(self):<tab>futures = []<tab>for node_id, request in six.iteritems(self._create_fetch_requests()):<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Sending FetchRequest to node %s"", node_id)<tab><tab><tab>future = self._client.send(node_id, request)<tab><tab><tab>future.add_callback(self._handle_fetch_response, request)<tab><tab><tab>future.add_errback(log.error, ""Fetch to node %s failed: %s"", node_id)<tab><tab><tab>futures.append(future)<tab>self._fetch_futures.extend(futures)<tab>self._clean_done_fetch_futures()<tab>return futures",0,if self . _client . ready ( node_id ) :,if request . status_code == 200 :,0.064969815,4.396165419,0.333333333
"def discover(cls, path, **kwargs):<tab>if kwargs.pop(""collection"", None) is not None:<tab><tab>raise TypeError(""collection argument must not be given."")<tab>path = expand_path(path)<tab>try:<tab><tab>collections = os.listdir(path)<tab>except OSError as e:<tab><tab>if e.errno != errno.ENOENT:<tab><tab><tab>raise<tab>else:<tab><tab>for collection in collections:<tab><tab><tab>collection_path = os.path.join(path, collection)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>args = dict(collection=collection, path=collection_path, **kwargs)<tab><tab><tab>yield args",0,if not cls . _validate_collection ( collection_path ) :,if not os . path . isdir ( collection_path ) :,0.229181405,40.81851142,0.408163265
"def writefile(filename, now):<tab>with open(os.path.join(""src/teensy/"" + filename)) as fileopen, open(<tab><tab>os.path.join(core.userconfigpath, ""reports/teensy_{0}.ino"".format(now)), ""w""<tab>) as filewrite:<tab><tab>for line in fileopen:<tab><tab><tab>match = re.search(""IPADDR"", line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = line.replace(""IPADDR"", ipaddr)<tab><tab><tab>match = re.search(""12,12,12,12"", line)<tab><tab><tab>if match:<tab><tab><tab><tab>ipaddr_replace = ipaddr.replace(""."", "","", 4)<tab><tab><tab><tab>line = line.replace(""12,12,12,12"", ipaddr_replace)<tab><tab><tab>filewrite.write(line)",1,if match :,if match :,0.531170663,1.00E-10,1
"def get_added_files(diff):<tab>""""""hacky approach to extract added files from github diff output""""""<tab>prefix = ""+++ b/""<tab>lastline = None<tab>for line in diff.splitlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>yield line[len(prefix) :]<tab><tab>lastline = line",0,"if line . startswith ( prefix ) and lastline and lastline == ""--- /dev/null"" :",if lastline and line . startswith ( prefix ) :,0.358585549,20.46451987,0.267857143
"def bpe_decode(tokens: List[str]) -> List[str]:<tab>words = []<tab>pieces: List[str] = []<tab>for t in tokens:<tab><tab><IF-STMT><tab><tab><tab>pieces.append(t[:-2])<tab><tab>else:<tab><tab><tab>words.append("""".join(pieces + [t]))<tab><tab><tab>pieces = []<tab>if len(pieces) > 0:<tab><tab>words.append("""".join(pieces))<tab>return words",0,if t . endswith ( DecodeMixin . bpe_cont_str ) :,"if t [ - 2 : ] == ""\n"" :",0.026379013,6.285596338,0.487179487
"def _maybe_encrypt(self, data):<tab>gpgr = self.config.prefs.gpg_recipient<tab>tokeys = [gpgr] if gpgr not in (None, """", ""!CREATE"", ""!PASSWORD"") else None<tab>if self.config.get_master_key():<tab><tab>with EncryptingStreamer(self.config.get_master_key(), delimited=True) as es:<tab><tab><tab>es.write(data)<tab><tab><tab>es.finish()<tab><tab><tab>return es.save(None)<tab>elif tokeys:<tab><tab>stat, edata = GnuPG(self.config, event=GetThreadEvent()).encrypt(<tab><tab><tab>data, tokeys=tokeys<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return edata<tab>return data",0,if stat == 0 :,if edata :,0.03549272,1.00E-10,0.36
"def faces_uvs_list(self) -> List[torch.Tensor]:<tab>if self._faces_uvs_list is None:<tab><tab><IF-STMT><tab><tab><tab>self._faces_uvs_list = [<tab><tab><tab><tab>torch.empty((0, 3), dtype=torch.float32, device=self.device)<tab><tab><tab>] * self._N<tab><tab>else:<tab><tab><tab>self._faces_uvs_list = padded_to_list(<tab><tab><tab><tab>self._faces_uvs_padded, split_size=self._num_faces_per_mesh<tab><tab><tab>)<tab>return self._faces_uvs_list",0,if self . isempty ( ) :,if self . device is not None :,0.083577801,22.08959113,0.321428571
"def handle_resource_click(self, widget, event):<tab>if event.getButton() == fife.MouseEvent.LEFT:<tab><tab>self.show_resource_menu(widget.parent, widget.parent.parent)<tab>elif event.getButton() == fife.MouseEvent.RIGHT:<tab><tab><IF-STMT><tab><tab><tab># abort resource selection (#1310)<tab><tab><tab>self.hide_resource_menu()<tab><tab>else:<tab><tab><tab># remove the load/unload order<tab><tab><tab>self.add_resource(slot=widget.parent, res_id=0, entry=widget.parent.parent)",0,if self . resource_menu_shown :,if widget . parent . parent . res_id == 0 :,0.025064683,4.016138436,0.3
"def update_device(self, device):<tab>for bridge in self.bridges:<tab><tab>if bridge.device == device:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>bridge.device.ip = device.ip<tab><tab><tab><tab>bridge.device.port = device.port<tab><tab><tab><tab>logger.info(<tab><tab><tab><tab><tab>'Updated device ""{}"" - New settings: {}:{}'.format(<tab><tab><tab><tab><tab><tab>device.label, device.ip, device.port<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab><tab>self.update()<tab><tab><tab><tab>self.share_bridges()<tab><tab><tab><tab>break",0,if bridge . device . ip != device . ip or bridge . device . port != device . port :,if device . ip and device . port :,0.124443149,9.420645699,0.260416667
"def endElement(self, name, value, connection):<tab>if name == ""OptionGroupName"":<tab><tab>self.name = value<tab>elif name == ""EngineName"":<tab><tab>self.engine_name = value<tab>elif name == ""MajorEngineVersion"":<tab><tab>self.major_engine_version = value<tab>elif name == ""OptionGroupDescription"":<tab><tab>self.description = value<tab>elif name == ""AllowsVpcAndNonVpcInstanceMemberships"":<tab><tab><IF-STMT><tab><tab><tab>self.allow_both_vpc_and_nonvpc = True<tab><tab>else:<tab><tab><tab>self.allow_both_vpc_and_nonvpc = False<tab>elif name == ""VpcId"":<tab><tab>self.vpc_id = value<tab>else:<tab><tab>setattr(self, name, value)",0,"if value . lower ( ) == ""true"" :","if self . vpc_id == ""VpcId"" :",0.017972998,17.24222129,0.384615385
"def log_items(self, interface, action, media, items):<tab>if not items:<tab><tab>return<tab><tab># Log each item<tab>for item in items:<tab><tab>if not item:<tab><tab><tab>continue<tab><tab>log.info(<tab><tab><tab>""[%s:%s](%s) %r (%r)"",<tab><tab><tab>interface,<tab><tab><tab>action,<tab><tab><tab>media,<tab><tab><tab>item.get(""title""),<tab><tab><tab>item.get(""year""),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab># Log each episode<tab><tab><tab>self.log_episodes(item)",0,"if media == ""shows"" :","if item . get ( ""episode"" ) :",0.026407399,5.93420261,0.381818182
"def _copy_files(self, files, src, dest, message=""""):<tab>for filepath in files:<tab><tab>srcpath = os.path.join(src, filepath)<tab><tab>destpath = os.path.join(dest, filepath)<tab><tab>if message:<tab><tab><tab>print(""{}: {}"".format(message, destpath))<tab><tab><IF-STMT><tab><tab><tab>destdir = os.path.dirname(destpath)<tab><tab><tab>if not os.path.isdir(destdir):<tab><tab><tab><tab>os.makedirs(destdir)<tab><tab><tab>shutil.copy(srcpath, destpath)<tab><tab>elif os.path.exists(destpath):<tab><tab><tab>os.remove(destpath)",0,if os . path . exists ( srcpath ) :,if os . path . exists ( destpath ) :,0.604939981,70.71067812,0.714285714
"def disconnect(self, endpoint=None):<tab>if endpoint is not None:<tab><tab>conn = self.connections_endpoints.pop(endpoint, None)<tab><tab><IF-STMT><tab><tab><tab>self.connections.pop(conn.get_socket_object(), None)<tab><tab><tab>conn.close()<tab>else:<tab><tab>for _, conn in self.connections_endpoints.items():<tab><tab><tab>conn.close()<tab><tab>self.connections_endpoints = {}<tab><tab>self.connections = {}",0,if conn :,if conn . get_socket_object ( ) is not None :,0.078827156,1.00E-10,0.461538462
"def cisco_inventory(raw):<tab>for match in INVENTORY_RE.finditer(raw):<tab><tab>d = match.groupdict()<tab><tab><IF-STMT><tab><tab><tab>d[""sn""] = None<tab><tab>d[""descr""] = d[""descr""].strip('""')<tab><tab>d[""name""] = d[""name""].strip('""')<tab><tab>yield d",0,"if d [ ""sn"" ] in SERIAL_BLACKLIST :","if d [ ""sn"" ] == ""cisco"" :",0.357484852,48.63383168,0.727272727
"def _dispatchBubblingEvent(self, tag, evtType, evtObject):<tab>for node in tag.parents:<tab><tab>if node is None:  # pragma: no cover<tab><tab><tab>break<tab><tab>if not node._listeners:<tab><tab><tab>continue<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>continue<tab><tab>capture_listeners, bubbling_listeners = self._get_listeners(<tab><tab><tab>node, evtType<tab><tab>)  # pylint:disable=unused-variable<tab><tab>for c in bubbling_listeners:<tab><tab><tab>evtObject.currentTarget = node._node<tab><tab><tab>self.do_dispatch(c, evtObject)",0,if evtObject . _stoppedPropagation :,if evtObject is None :,0.064978772,19.35769349,0.5
"def got_shares(self, shares):<tab>if self.check_reneging:<tab><tab><IF-STMT><tab><tab><tab>self.finished_d.errback(<tab><tab><tab><tab>unittest.FailTest(<tab><tab><tab><tab><tab>""The node was told by the share finder that it is destined to remain hungry, then was given another share.""<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>return<tab>self.got += len(shares)<tab>log.msg(""yyy 3 %s.got_shares(%s) got: %s"" % (self, shares, self.got))<tab>if self.got == 3:<tab><tab>self.finished_d.callback(True)",0,if self . _no_more_shares :,if self . got == 3 :,0.117260658,17.20339087,0.55
"def get_class_obj_(self, node, default_class=None):<tab>class_obj1 = default_class<tab>if ""xsi"" in node.nsmap:<tab><tab>classname = node.get(""{%s}type"" % node.nsmap[""xsi""])<tab><tab>if classname is not None:<tab><tab><tab>names = classname.split("":"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>classname = names[1]<tab><tab><tab>class_obj2 = globals().get(classname)<tab><tab><tab>if class_obj2 is not None:<tab><tab><tab><tab>class_obj1 = class_obj2<tab>return class_obj1",0,if len ( names ) == 2 :,if len ( names ) > 1 :,0.524151519,47.75034265,0.666666667
"def update(self, mapping, update_only=False):<tab>for name in mapping:<tab><tab><IF-STMT><tab><tab><tab># nested and inner objects, merge recursively<tab><tab><tab>if hasattr(self[name], ""update""):<tab><tab><tab><tab># FIXME only merge subfields, not the settings<tab><tab><tab><tab>self[name].update(mapping[name], update_only)<tab><tab><tab>continue<tab><tab>self.field(name, mapping[name])<tab>if update_only:<tab><tab>for name in mapping._meta:<tab><tab><tab>if name not in self._meta:<tab><tab><tab><tab>self._meta[name] = mapping._meta[name]<tab>else:<tab><tab>self._meta.update(mapping._meta)",0,if update_only and name in self :,if name in self . _meta :,0.261145601,21.57365265,0.3
"def configure(self):<tab>super(Command, self).configure()<tab>if self.needs_config and not self.resolver:<tab><tab># Checking if a default config file is present<tab><tab><IF-STMT><tab><tab><tab>self.add_option(<tab><tab><tab><tab>""config"", ""c"", InputOption.VALUE_REQUIRED, ""The config file path""<tab><tab><tab>)",0,if not self . _check_config ( ) :,"if not self . has_option ( ""config"" , ""c"" , InputOption . VALUE_REQUIRED ) :",0.221404962,13.9290836,0.791304348
"def is_metric(cls, key_type, comparator):<tab>if key_type == cls._METRIC_IDENTIFIER:<tab><tab><IF-STMT><tab><tab><tab>raise MlflowException(<tab><tab><tab><tab>""Invalid comparator '%s' ""<tab><tab><tab><tab>""not one of '%s"" % (comparator, cls.VALID_METRIC_COMPARATORS),<tab><tab><tab><tab>error_code=INVALID_PARAMETER_VALUE,<tab><tab><tab>)<tab><tab>return True<tab>return False",1,if comparator not in cls . VALID_METRIC_COMPARATORS :,if comparator not in cls . VALID_METRIC_COMPARATORS :,0.75,100,1
"def get_full_qualified_name(self, node: Element) -> str:<tab>if node.get(""reftype"") == ""option"":<tab><tab>progname = node.get(""std:program"")<tab><tab>command = ws_re.split(node.get(""reftarget""))<tab><tab>if progname:<tab><tab><tab>command.insert(0, progname)<tab><tab>option = command.pop()<tab><tab><IF-STMT><tab><tab><tab>return ""."".join([""-"".join(command), option])<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>return None",1,if command :,if command :,0.531170663,1.00E-10,1
"def log_unsupported(logger, message, dictionary):<tab>if len(dictionary) < 1:<tab><tab>return<tab># Display unsupported service list<tab>logger.info(message, len(dictionary))<tab># Display individual warnings for each service<tab>for service in dictionary.keys():<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Ignoring service: %s"" % service)<tab><tab><tab>continue<tab><tab># Log unsupported service warning<tab><tab>logger.warn(<tab><tab><tab>""Unsupported service: %s"" % service,<tab><tab><tab>extra={<tab><tab><tab><tab>""event"": {<tab><tab><tab><tab><tab>""module"": __name__,<tab><tab><tab><tab><tab>""name"": ""unsupported_service"",<tab><tab><tab><tab><tab>""key"": service,<tab><tab><tab><tab>}<tab><tab><tab>},<tab><tab>)",0,if service is None or service in IGNORED_SERVICES :,if service in message :,0.224999276,9.100207817,0.279761905
"def encode_password(pw):<tab>""""""Encode password in hexadecimal if needed""""""<tab>enc = False<tab>if pw:<tab><tab>encPW = __PW_PREFIX<tab><tab>for c in pw:<tab><tab><tab>cnum = ord(c)<tab><tab><tab>if c == ""#"" or cnum < 33 or cnum > 126:<tab><tab><tab><tab>enc = True<tab><tab><tab>encPW += ""%2x"" % cnum<tab><tab><IF-STMT><tab><tab><tab>return encPW<tab>return pw",1,if enc :,if enc :,0.531170663,1.00E-10,1
"def matrix_min_and_max(matrix):<tab>_min = None<tab>_max = None<tab>for row in matrix:<tab><tab>for el in row:<tab><tab><tab>val = el<tab><tab><tab>if _min is None or val < _min:<tab><tab><tab><tab>_min = val<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_max = val<tab>return _min, _max",0,if _max is None or val > _max :,elif _max is None or val > _max :,0.537712771,89.31539818,0.714285714
"def __init__(self, content=None, parent=None):<tab>Transformable.__init__(self, content, parent)<tab>self._items = []<tab>for element in content:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>tag = element.tag[len(namespace) :]<tab><tab>if tag == ""g"":<tab><tab><tab>item = Group(element, self)<tab><tab>elif tag == ""path"":<tab><tab><tab>item = Path(element, self)<tab><tab>else:<tab><tab><tab>log.warn(""Unhandled SVG tag (%s)"" % tag)<tab><tab><tab>continue<tab><tab>self._items.append(item)",1,if not element . tag . startswith ( namespace ) :,if not element . tag . startswith ( namespace ) :,0.75,100,1
def reset_appid(self):<tab># called by web_control<tab>with self.lock:<tab><tab>self.working_appid_list = list()<tab><tab>for appid in self.config.GAE_APPIDS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.config.GAE_APPIDS.remove(appid)<tab><tab><tab><tab>continue<tab><tab><tab>self.working_appid_list.append(appid)<tab><tab>self.not_exist_appids = []<tab><tab>self.out_of_quota_appids = []<tab>self.last_reset_time = time.time(),0,if not appid :,if appid in self . working_appid_list :,0.038340903,4.932351569,0.30952381
"def find_widget(self, pos):<tab>for widget in self.subwidgets[::-1]:<tab><tab>if widget.visible:<tab><tab><tab>r = widget.rect<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return widget.find_widget(subtract(pos, r.topleft))<tab>return self",0,if r . collidepoint ( pos ) :,if r . topleft <= pos <= r . bottomright :,0.0673711,13.0651133,0.5
"def _get_names(dirs):<tab>""""""Get alphabet and label names, union across all dirs.""""""<tab>alphabets = set()<tab>label_names = {}<tab>for d in dirs:<tab><tab>for example in _walk_omniglot_dir(d):<tab><tab><tab>alphabet, alphabet_char_id, label, _, _ = example<tab><tab><tab>alphabets.add(alphabet)<tab><tab><tab>label_name = ""%s_%d"" % (alphabet, alphabet_char_id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert label_names[label] == label_name<tab><tab><tab>else:<tab><tab><tab><tab>label_names[label] = label_name<tab>label_names = [label_names[k] for k in sorted(label_names)]<tab>return alphabets, label_names",1,if label in label_names :,if label in label_names :,0.75,100,1
"def model():<tab>with pyro.plate_stack(""plates"", shape):<tab><tab>with pyro.plate(""particles"", 200000):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pyro.sample(""x"", dist.Normal(loc, scale))<tab><tab><tab>else:<tab><tab><tab><tab>pyro.sample(""x"", dist.StudentT(10.0, loc, scale))",0,"if ""dist_type"" == ""Normal"" :",if shape == 1 :,0.036540249,7.101864697,0.416666667
"def set_note_pinned(self, key, pinned):<tab>n = self.notes[key]<tab>old_pinned = utils.note_pinned(n)<tab>if pinned != old_pinned:<tab><tab>if ""systemtags"" not in n:<tab><tab><tab>n[""systemtags""] = []<tab><tab>systemtags = n[""systemtags""]<tab><tab><IF-STMT><tab><tab><tab># which by definition means that it was NOT pinned<tab><tab><tab>systemtags.append(""pinned"")<tab><tab>else:<tab><tab><tab>systemtags.remove(""pinned"")<tab><tab>n[""modifydate""] = time.time()<tab><tab>self.notify_observers(<tab><tab><tab>""change:note-status"",<tab><tab><tab>events.NoteStatusChangedEvent(what=""modifydate"", key=key),<tab><tab>)",0,if pinned :,if pinned not in systemtags :,0.090364769,1.00E-10,0.4
"def __init__(self, name, contents):<tab>self.name = name<tab>self.all_entries = []<tab>self.attr = []<tab>self.child = []<tab>self.seq_child = []<tab>for entry in contents:<tab><tab>clean_entry = entry.rstrip(""*"")<tab><tab>self.all_entries.append(clean_entry)<tab><tab>if entry.endswith(""**""):<tab><tab><tab>self.seq_child.append(clean_entry)<tab><tab><IF-STMT><tab><tab><tab>self.child.append(clean_entry)<tab><tab>else:<tab><tab><tab>self.attr.append(entry)",0,"elif entry . endswith ( ""*"" ) :","elif entry . endswith ( ""**"" ) :",0.547301779,79.41386679,1
"def testToFileBinary(self):<tab>z = dns.zone.from_file(here(""example""), ""example"")<tab>try:<tab><tab>f = open(here(""example3-binary.out""), ""wb"")<tab><tab>z.to_file(f)<tab><tab>f.close()<tab><tab>ok = filecmp.cmp(here(""example3-binary.out""), here(""example3.good""))<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(here(""example3-binary.out""))<tab>self.failUnless(ok)",1,if not _keep_output :,if not _keep_output :,0.75,100,1
"def test_collect_gradients_with_allreduce_failure_case(self):<tab>worker = self._workers[1]<tab>train_db, _ = get_mnist_dataset(self._batch_size)<tab>for step, (x, y) in enumerate(train_db):<tab><tab>if step == 0:<tab><tab><tab>worker._run_model_call_before_training(x)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>self.assertEqual(<tab><tab><tab>worker._calculate_grads_and_report_with_allreduce(None),<tab><tab><tab>False,<tab><tab><tab>""Should fail when no data is received"",<tab><tab>)",0,if step == self . _test_steps :,elif step == self . _batch_size :,0.289081721,49.61683,0.6
"def clean(self):<tab>data = self.cleaned_data<tab>number, ccv = data.get(""number""), data.get(""ccv"")<tab>if number and ccv:<tab><tab><IF-STMT><tab><tab><tab>raise forms.ValidationError(<tab><tab><tab><tab>_(""American Express cards use a 4 digit security code"")<tab><tab><tab>)<tab>return data",0,if bankcards . is_amex ( number ) and len ( ccv ) != 4 :,if len ( ccv ) != 4 :,0.240177872,32.70962178,0.230263158
"def _gen_GreaterEqual(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.fcmp_ordered("">="", lhs, rhs))<tab><tab>elif ret_type == int_type:<tab><tab><tab>result.append(self.builder.icmp_signed("">="", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",1,if ret_type == real_type :,if ret_type == real_type :,0.75,100,1
"def console_get(context, console_id, instance_id=None):<tab>query = (<tab><tab>model_query(context, models.Console, read_deleted=""yes"")<tab><tab>.filter_by(id=console_id)<tab><tab>.options(joinedload(""pool""))<tab>)<tab>if instance_id is not None:<tab><tab>query = query.filter_by(instance_id=instance_id)<tab>result = query.first()<tab>if not result:<tab><tab><IF-STMT><tab><tab><tab>raise exception.ConsoleNotFoundForInstance(<tab><tab><tab><tab>console_id=console_id, instance_id=instance_id<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise exception.ConsoleNotFound(console_id=console_id)<tab>return result",1,if instance_id :,if instance_id :,0.531170663,1.00E-10,1
"def publish():<tab>pub = await aioredis.create_redis((""localhost"", 6379))<tab>while not tsk.done():<tab><tab># wait for clients to subscribe<tab><tab>while True:<tab><tab><tab>subs = await pub.pubsub_numsub(""channel:1"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>await asyncio.sleep(0, loop=loop)<tab><tab># publish some messages<tab><tab>for msg in [""one"", ""two"", ""three""]:<tab><tab><tab>await pub.publish(""channel:1"", msg)<tab><tab># send stop word<tab><tab>await pub.publish(""channel:1"", STOPWORD)<tab>pub.close()<tab>await pub.wait_closed()",0,"if subs [ b""channel:1"" ] == 1 :",if subs is None :,0.035401841,3.908250913,0.481481481
"def read(self, size=None):<tab>if not size:<tab><tab>size = self._size<tab><tab>contents = BytesIO()<tab><tab>while True:<tab><tab><tab>blocks = GzipFile.read(self, size)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>contents.flush()<tab><tab><tab><tab>break<tab><tab><tab>contents.write(blocks)<tab><tab>return contents.getvalue()<tab>else:<tab><tab>return GzipFile.read(self, size)",1,if not blocks :,if not blocks :,0.75,100,1
"def i2repr(self, pkt, x):<tab>if type(x) is list or type(x) is tuple:<tab><tab>return repr(x)<tab>if self.multi:<tab><tab>r = []<tab>else:<tab><tab>r = """"<tab>i = 0<tab>while x:<tab><tab><IF-STMT><tab><tab><tab>if self.multi:<tab><tab><tab><tab>r += [self.names[i]]<tab><tab><tab>else:<tab><tab><tab><tab>r += self.names[i]<tab><tab>i += 1<tab><tab>x >>= 1<tab>if self.multi:<tab><tab>r = ""+"".join(r)<tab>return r",1,if x & 1 :,if x & 1 :,0.75,100,1
"def _run(self):<tab>while not self.stopped:<tab><tab># Prevent calling bus.send from multiple threads<tab><tab>with self.lock:<tab><tab><tab>started = time.time()<tab><tab><tab>try:<tab><tab><tab><tab>self.bus.send(self.message)<tab><tab><tab>except Exception as exc:<tab><tab><tab><tab>log.exception(exc)<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab># Compensate for the time it takes to send the message<tab><tab>delay = self.period - (time.time() - started)<tab><tab>time.sleep(max(0.0, delay))",0,if self . end_time is not None and time . time ( ) >= self . end_time :,if self . stopped :,0.049327822,1.167507157,0.268518519
"def currentLevel(self):<tab>currentStr = """"<tab>for stackType, stackValue in self.stackVals:<tab><tab>if stackType == ""dict"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>currentStr += ""['"" + stackValue + ""']""<tab><tab><tab>else:  # numeric key...<tab><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""listLike"":<tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""getattr"":<tab><tab><tab>currentStr += "".__getattribute__('"" + stackValue + ""')""<tab><tab>else:<tab><tab><tab>raise Exception(f""Cannot get attribute of type {stackType}"")<tab>return currentStr",0,"if isinstance ( stackValue , str ) :",if stackValue . isdigit ( ) :,0.038362157,14.31720073,0.314814815
"def restoreParent(self):<tab>if self.sid.isRoot:<tab><tab>return<tab>with self.suspendMouseButtonNavigation():<tab><tab>confirm, opt = self.confirmRestore((self.path,))<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if opt[""delete""] and not self.confirmDelete(warnRoot=self.path == ""/""):<tab><tab><tab>return<tab>rd = RestoreDialog(self, self.sid, self.path, **opt)<tab>rd.exec()",1,if not confirm :,if not confirm :,0.75,100,1
"def keep_vocab_item(word, count, min_count, trim_rule=None):<tab>default_res = count >= min_count<tab>if trim_rule is None:<tab><tab>return default_res<tab>else:<tab><tab>rule_res = trim_rule(word, count, min_count)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif rule_res == RULE_DISCARD:<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return default_res",0,if rule_res == RULE_KEEP :,if rule_res == RULE_DISCARD :,0.394778655,78.254229,1
"def _get_cuda_device(*args):<tab># Returns cuda.Device or DummyDevice.<tab>for arg in args:<tab><tab>if type(arg) is not bool and isinstance(arg, _integer_types):<tab><tab><tab>check_cuda_available()<tab><tab><tab>return Device(arg)<tab><tab><IF-STMT><tab><tab><tab>if arg.device is None:<tab><tab><tab><tab>continue<tab><tab><tab>return arg.device<tab><tab>if available and isinstance(arg, Device):<tab><tab><tab>return arg<tab># NOTE: This function returns DummyDevice for both NumPy and ChainerX<tab>return DummyDevice",0,"if isinstance ( arg , ndarray ) :","if isinstance ( arg , cuda . Device ) :",0.263340042,45.18010018,0.558441558
"def __init__(<tab>self,<tab>filename,<tab>metadata_name,<tab>metadata_column,<tab>message=""Value for metadata not found."",<tab>line_startswith=None,<tab>split=""\t"",):<tab>self.metadata_name = metadata_name<tab>self.message = message<tab>self.valid_values = []<tab>for line in open(filename):<tab><tab>if line_startswith is None or line.startswith(line_startswith):<tab><tab><tab>fields = line.split(split)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.valid_values.append(fields[metadata_column].strip())",0,if metadata_column < len ( fields ) :,if metadata_column in fields :,0.037304456,29.6400954,0.6
"def FindEnclosingBracketGroup(input_str):<tab>stack = []<tab>start = -1<tab>for index, char in enumerate(input_str):<tab><tab>if char in LBRACKETS:<tab><tab><tab>stack.append(char)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = index<tab><tab>elif char in BRACKETS:<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if stack.pop() != BRACKETS[char]:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (start, index + 1)<tab>return (-1, -1)",0,if start == - 1 :,if stack . pop ( ) != LBRACKETS [ char ] :,0.01912253,4.065425429,0.234375
"def _on_message(self, msg: str) -> None:<tab>obj = json.loads(msg)<tab>_id = obj.get(""id"")<tab>if _id and _id in self._callbacks:<tab><tab>callback = self._callbacks.pop(_id)<tab><tab><IF-STMT><tab><tab><tab>error = obj[""error""]<tab><tab><tab>msg = error.get(""message"")<tab><tab><tab>data = error.get(""data"")<tab><tab><tab>callback.set_exception(NetworkError(f""Protocol Error: {msg} {data}""))<tab><tab>else:<tab><tab><tab>result = obj.get(""result"")<tab><tab><tab>callback.set_result(result)<tab>else:<tab><tab>self.emit(obj.get(""method""), obj.get(""params""))",1,"if ""error"" in obj :","if ""error"" in obj :",0.75,100,1
"def _get_containers_with_state(self, container_names, select_random, *container_states):<tab>containers = self._get_all_containers()<tab>candidates = dict((c.name, c) for c in containers if c.status in container_states)<tab>if select_random and candidates:<tab><tab>return [random.choice(list(candidates.values()))]<tab>if container_names is None:<tab><tab>return list(candidates.values())<tab>found = []<tab>for name in container_names:<tab><tab>container = candidates.get(name)<tab><tab><IF-STMT><tab><tab><tab>raise BlockadeError(<tab><tab><tab><tab>""Container %s is not found or not any of %s"" % (name, container_states)<tab><tab><tab>)<tab><tab>found.append(container)<tab>return found",0,if not container :,if container is None :,0.045150551,14.05853313,0.277777778
"def __eq__(self, other):<tab>if isinstance(other, WeakMethod):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab># check also if either instance is None or else if instances are equal<tab><tab>if self.instance is None:<tab><tab><tab>return other.instance is None<tab><tab>else:<tab><tab><tab>return self.instance() == other.instance()<tab>elif callable(other):<tab><tab>return self == WeakMethod(other)<tab>else:<tab><tab>return False",0,if self . function != other . function :,if other . instance ( ) is None :,0.031431486,10.14710401,0.25
"def last_bottle_hash():<tab>""""""Fetch the bottle do ... end from the latest brew formula""""""<tab>resp = requests.get(HOMEBREW_FORMULAR_LATEST)<tab>resp.raise_for_status()<tab>lines = resp.text.split(""\n"")<tab>look_for_end = False<tab>start = 0<tab>end = 0<tab>for idx, content in enumerate(lines):<tab><tab>if look_for_end:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>end = idx<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if ""bottle do"" in content:<tab><tab><tab><tab>start = idx<tab><tab><tab><tab>look_for_end = True<tab>return ""\n"".join(lines[start : end + 1])",0,"if ""end"" in content :","if ""bottle end"" in content :",0.377622275,59.46035575,1
"def wrapper(fn):<tab>if debug_run_test_calls:<tab><tab>ret = str(fn(*args, *kwargs))<tab><tab>print(""TEST: %s()"" % fn.__name__)<tab><tab><IF-STMT><tab><tab><tab>print(""  arg:"", args)<tab><tab>if kwargs:<tab><tab><tab>print(""  kwa:"", kwargs)<tab><tab>print(""  ret:"", ret)<tab>return fn",1,if args :,if args :,0.531170663,1.00E-10,1
"def parse_socket_line(line):<tab>lsp = line.strip().split()<tab>if not len(lsp) in {3, 5}:<tab><tab>print(line, ""is malformed"")<tab><tab>return UNPARSABLE<tab>else:<tab><tab>socket_type = sock_dict.get(lsp[2])<tab><tab>socket_name = lsp[1]<tab><tab><IF-STMT><tab><tab><tab>return UNPARSABLE<tab><tab>elif len(lsp) == 3:<tab><tab><tab>return socket_type, socket_name, None, None<tab><tab>else:<tab><tab><tab>default = processed(lsp[3])<tab><tab><tab>nested = processed(lsp[4])<tab><tab><tab>return socket_type, socket_name, default, nested",0,if not socket_type :,if len ( lsp ) == 0 :,0.034692192,5.669791111,0.3
"def release(self):<tab>me, lock_count = self.__begin()<tab>try:<tab><tab>if me is None:<tab><tab><tab>return<tab><tab>self._count = count = self._count - 1<tab><tab><IF-STMT><tab><tab><tab>self._owner = None<tab><tab><tab>self._block.release()<tab>finally:<tab><tab>self.__end(me, lock_count)",0,if not count :,if count == 0 :,0.045150551,10.68217516,0.4
"def Traverse(self):<tab>""""""A generator for _IMAGE_RESOURCE_DATA_ENTRY under this node.""""""<tab>for entry in self:<tab><tab><IF-STMT><tab><tab><tab>for subentry in entry.Entry.Traverse():<tab><tab><tab><tab>yield subentry<tab><tab>else:<tab><tab><tab>yield entry.OffsetToData.dereference()",0,if entry . ChildIsEntry :,"if isinstance ( entry , _IMAGE_RESOURCE_DATA_ENTRY ) :",0.02800146,3.458592114,0.4
"def getInstances_WithSource(self, instancesAmount, sourceObject, scenes):<tab>if sourceObject is None:<tab><tab>self.removeAllObjects()<tab><tab>return []<tab>else:<tab><tab>sourceHash = hash(sourceObject)<tab><tab><IF-STMT><tab><tab><tab>if lastSourceHashes[self.identifier] != sourceHash:<tab><tab><tab><tab>self.removeAllObjects()<tab><tab>lastSourceHashes[self.identifier] = sourceHash<tab>return self.getInstances_Base(instancesAmount, sourceObject, scenes)",1,if self . identifier in lastSourceHashes :,if self . identifier in lastSourceHashes :,0.75,100,1
"def used_pos():<tab>pos_along_edges = []<tab>for e in edges:<tab><tab>A, B = pos[e[0]], pos[e[1]]<tab><tab><IF-STMT>  # Y-axis edge.<tab><tab><tab>for i in range(A[1], B[1], np.sign(B[1] - A[1])):<tab><tab><tab><tab>pos_along_edges.append((A[0], i))<tab><tab>else:  # X-axis edge.<tab><tab><tab>for i in range(A[0], B[0], np.sign(B[0] - A[0])):<tab><tab><tab><tab>pos_along_edges.append((i, A[1]))<tab>return list(pos.values()) + pos_along_edges",0,if A [ 0 ] == B [ 0 ] :,if len ( A ) == 2 :,0.014083697,8.591316733,0.274725275
"def __init__(<tab>self, plugin_name=None, builtin=False, deprecated=False, config=None, session=None):<tab>if builtin and isinstance(builtin, (str, unicode)):<tab><tab>builtin = os.path.basename(builtin)<tab><tab>for ignore in ("".py"", "".pyo"", "".pyc""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>builtin = builtin[: -len(ignore)]<tab><tab>if builtin not in self.LOADED:<tab><tab><tab>self.LOADED.append(builtin)<tab>self.loading_plugin = plugin_name<tab>self.loading_builtin = plugin_name and builtin<tab>self.builtin = builtin<tab>self.deprecated = deprecated<tab>self.session = session<tab>self.config = config<tab>self.manifests = []",1,if builtin . endswith ( ignore ) :,if builtin . endswith ( ignore ) :,0.75,100,1
def input(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.input_ is None:<tab><tab><tab><tab>self.input_ = InputSettings()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.input_,1,if self . input_ is None :,if self . input_ is None :,0.75,100,1
"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab>if ""disk_shares"" in plugin_result[""device""]:<tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab>if ""disk_shares"" in subdevice:<tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice",0,"if plugin_result [ ""status"" ] == ""error"" :",if plugin_name not in plugin_result :,0.019830745,14.16667529,0.458333333
"def m2i(self, pkt, x):<tab>res = []<tab>while x:<tab><tab>cur = []<tab><tab># while x and x[0] != b'\x00':<tab><tab>while x and x[0] != 0:<tab><tab><tab>l = x[0]<tab><tab><tab>cur.append(x[1 : l + 1])<tab><tab><tab>x = x[l + 1 :]<tab><tab>res.append(b""."".join(cur))<tab><tab><IF-STMT><tab><tab><tab>x = x[1:]<tab>return res",0,if x and x [ 0 ] == 0 :,"if x [ 0 ] == b""\x00"" :",0.232029036,42.80320607,0.478787879
"def generate_idempotent_uuid(params, model, **kwargs):<tab>for name in model.idempotent_members:<tab><tab><IF-STMT><tab><tab><tab>params[name] = str(uuid.uuid4())<tab><tab><tab>logger.debug(<tab><tab><tab><tab>""injecting idempotency token (%s) into param '%s'.""<tab><tab><tab><tab>% (params[name], name)<tab><tab><tab>)",1,if name not in params :,if name not in params :,0.75,100,1
"def __init__(self, name, signatures, kind, vm):<tab>super().__init__(name, vm)<tab>assert signatures<tab>self.kind = kind<tab>self.bound_class = BoundPyTDFunction<tab>self.signatures = signatures<tab>self._signature_cache = {}<tab>self._return_types = {sig.pytd_sig.return_type for sig in signatures}<tab>for sig in signatures:<tab><tab>for param in sig.pytd_sig.params:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._has_mutable = True<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self._has_mutable = False<tab>for sig in signatures:<tab><tab>sig.function = self<tab><tab>sig.name = self.name",0,if param . mutated_type is not None :,if param . pytd_sig . return_type in self . _return_types :,0.189747298,10.52149517,0.365384615
"def sub_dict(d):<tab>r = {}<tab>for k in d:<tab><tab>if type(d[k]) in prims:<tab><tab><tab>r[k] = d[k]<tab><tab><IF-STMT><tab><tab><tab>r[k] = sub_list(d[k])<tab><tab>elif type(d[k]) is dict:<tab><tab><tab>r[k] = sub_dict(d[k])<tab><tab>else:<tab><tab><tab>print(""Unknown Type: {}"".format(type(d[k])))<tab>return r",1,elif type ( d [ k ] ) is list :,elif type ( d [ k ] ) is list :,0.75,100,1
"def listAdd():<tab>cpe = request.args.get(""cpe"")<tab>cpeType = request.args.get(""type"")<tab>lst = request.args.get(""list"")<tab>if cpe and cpeType and lst:<tab><tab>status = (<tab><tab><tab>""added_to_list""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""already_exists_in_list""<tab><tab>)<tab><tab>returnList = db.getWhitelist() if lst == ""whitelist"" else db.getBlacklist()<tab><tab>return jsonify({""status"": status, ""rules"": returnList, ""listType"": lst.title()})<tab>else:<tab><tab>return jsonify({""status"": ""could_not_add_to_list""})",0,"if addCPEToList ( cpe , lst , cpeType )","if lst == ""added""",0.015402161,5.868924819,0.287878788
"def _integrate_fixed_trajectory(self, h, T, step, relax):<tab>""""""Generates a solution trajectory of fixed length.""""""<tab># initialize the solution using initial condition<tab>solution = np.hstack((self.t, self.y))<tab>while self.successful():<tab><tab>self.integrate(self.t + h, step, relax)<tab><tab>current_step = np.hstack((self.t, self.y))<tab><tab>solution = np.vstack((solution, current_step))<tab><tab>if (h > 0) and (self.t >= T):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>continue<tab>return solution",0,elif ( h < 0 ) and ( self . t <= T ) :,elif h == 0 and ( self . y >= T ) :,0.230573852,33.33262696,0.833333333
"def transform(self, X):<tab>if self.preprocessor is None:<tab><tab>raise NotImplementedError()<tab>with warnings.catch_warnings():<tab><tab>warnings.filterwarnings(""error"")<tab><tab>X_new = self.preprocessor.transform(X)<tab><tab># TODO write a unittest for this case<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""KernelPCA removed all features!"")<tab><tab>return X_new",0,if X_new . shape [ 1 ] == 0 :,if X_new is None :,0.025595153,18.44837335,0.274725275
"def playerData(s):<tab>""""""Returns a list of tuples of original string and dict of values""""""<tab>p = []<tab>i = 0<tab>while True:<tab><tab>match = re_input.match(s, pos=i)<tab><tab><IF-STMT><tab><tab><tab>return p<tab><tab>else:<tab><tab><tab>d = match.groupdict()<tab><tab><tab>if d[""args""] is not None:<tab><tab><tab><tab>d[""degree""], d[""kwargs""] = getArgs(d[""args""])<tab><tab><tab>else:<tab><tab><tab><tab>d[""degree""], d[""kwargs""] = """", {}<tab><tab><tab>del d[""args""]<tab><tab><tab>p.append((match.group().strip(), d))<tab><tab><tab>i = match.end()<tab>return",1,if match is None :,if match is None :,0.75,100,1
"def extract_deps(file):<tab># ~ print('Extracting from %s' % file)<tab>deps = set()<tab>for line in open(file).readlines():<tab><tab>line = line.strip()<tab><tab>if line.startswith(""import"") or line.startswith(""from""):<tab><tab><tab>words = line.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>deps.add(words[1])<tab>return deps",0,"if words [ 0 ] == ""import"" or ( words [ 0 ] == ""from"" and words [ 2 ] == ""import"" ) :",if len ( words ) > 1 :,0.008361983,0.610200316,0.206349206
"def _remove_optional_none_type_hints(self, type_hints, defaults):<tab># If argument has None as a default, typing.get_type_hints adds<tab># optional None to the information it returns. We don't want that.<tab>for arg in defaults:<tab><tab><IF-STMT><tab><tab><tab>type_ = type_hints[arg]<tab><tab><tab>if self._is_union(type_):<tab><tab><tab><tab>types = type_.__args__<tab><tab><tab><tab>if len(types) == 2 and types[1] is type(None):<tab><tab><tab><tab><tab>type_hints[arg] = types[0]",0,if defaults [ arg ] is None and arg in type_hints :,if arg in type_hints :,0.229001319,30.93485033,0.201923077
"def _gaf10iterator(handle):<tab>for inline in handle:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>inrec = inline.rstrip(""\n"").split(""\t"")<tab><tab>if len(inrec) == 1:<tab><tab><tab>continue<tab><tab>inrec[3] = inrec[3].split(""|"")  # Qualifier<tab><tab>inrec[5] = inrec[5].split(""|"")  # DB:reference(s)<tab><tab>inrec[7] = inrec[7].split(""|"")  # With || From<tab><tab>inrec[10] = inrec[10].split(""|"")  # Synonym<tab><tab>inrec[12] = inrec[12].split(""|"")  # Taxon<tab><tab>yield dict(zip(GAF10FIELDS, inrec))",0,"if inline [ 0 ] == ""!"" :","if inline == """" :",0.037304456,20.29055433,0.727272727
"def cvePluginInfo(self, cve, **args):<tab>cveInfo = []<tab>for plugin in self.getWebPlugins():<tab><tab>try:<tab><tab><tab>data = plugin.cvePluginInfo(cve, **args)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cveInfo.append(data)<tab><tab>except Exception as e:<tab><tab><tab>print(<tab><tab><tab><tab>""[!] Plugin %s failed on fetching CVE plugin info!"" % plugin.getName()<tab><tab><tab>)<tab><tab><tab>print(""[!]  -> %s"" % e)<tab>return cveInfo",0,"if type ( data ) == dict and ""title"" in data and ""data"" in data :",if data :,0.00928478,1.00E-10,0.228571429
"def testLastContainerMarker(self):<tab>for format in [None, ""json"", ""xml""]:<tab><tab>containers = self.env.account.containers({""format"": format})<tab><tab>self.assertEquals(len(containers), len(self.env.containers))<tab><tab>self.assert_status(200)<tab><tab>containers = self.env.account.containers(<tab><tab><tab>parms={""format"": format, ""marker"": containers[-1]}<tab><tab>)<tab><tab>self.assertEquals(len(containers), 0)<tab><tab><IF-STMT><tab><tab><tab>self.assert_status(204)<tab><tab>else:<tab><tab><tab>self.assert_status(200)",1,if format is None :,if format is None :,0.75,100,1
"def _make_input_layers(self, rebuild=False):<tab>for name, layer in self.layer_map.items():<tab><tab>layer.left_in_edges = len(layer.in_edges)<tab><tab>if len(layer.in_edges) == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not layer.get_attr(""scope""):<tab><tab><tab><tab><tab>self.input_layers.append(name)<tab><tab><tab>else:<tab><tab><tab><tab>self.input_layers.append(name)",1,if rebuild :,if rebuild :,0.531170663,1.00E-10,1
"def widget_attrs(self, widget):<tab>attrs = super(IntegerField, self).widget_attrs(widget)<tab>if isinstance(widget, NumberInput):<tab><tab><IF-STMT><tab><tab><tab>attrs[""min""] = self.min_value<tab><tab>if self.max_value is not None:<tab><tab><tab>attrs[""max""] = self.max_value<tab>return attrs",1,if self . min_value is not None :,if self . min_value is not None :,0.75,100,1
"def _get_outfile(self):<tab>outfile = self.inputs.transformed_file<tab>if not isdefined(outfile):<tab><tab>if self.inputs.inverse is True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>src = ""orig.mgz""<tab><tab><tab>else:<tab><tab><tab><tab>src = self.inputs.target_file<tab><tab>else:<tab><tab><tab>src = self.inputs.source_file<tab><tab>outfile = fname_presuffix(src, newpath=os.getcwd(), suffix=""_warped"")<tab>return outfile",0,if self . inputs . fs_target is True :,"if self . inputs . target_file == ""orig.mgz"" :",0.237822612,25.74866102,0.633333333
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_num_memcacheg_backends(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 16 :,if tt == 16 :,0.75,100,1
"def try_to_find_osquery(self):<tab>extention = """"<tab>if platform.system() == ""Windows"":<tab><tab>extention = "".exe""<tab>try:<tab><tab>return resources.get_resource(""osqueryi"" + extention)<tab>except IOError as e:<tab><tab># Maybe it is installed on the system.<tab><tab>if platform.system() == ""Windows"":<tab><tab><tab>result = r""c:\ProgramData\osquery\osqueryi.exe""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return result<tab><tab>else:<tab><tab><tab># Try to find it somewhere on the system.<tab><tab><tab>return spawn.find_executable(""osqueryi"")<tab><tab>raise e",0,"if os . access ( result , os . R_OK ) :",if os . path . exists ( result ) :,0.115475465,15.91125987,0.380952381
"def cleanWhitespace(self, val):<tab>val = val.replace(""*"", "" AND "").replace(""  "", "" "")<tab>if re.match(""\S+ \S"", val):<tab><tab>matchs = re.findall(""(?:^|\(| )(.+?)(?:\)| OR| AND|$)"", val)<tab><tab>for strMatch in matchs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>strUnescapeMatch = self.unescapeCharacter(strMatch)<tab><tab><tab><tab>val = val.replace(strMatch, '""{}""'.format(strUnescapeMatch))<tab>return val.strip()",0,"if re . match ( ""\S+ \S"" , strMatch ) :","if re . match ( r""^[a-zA-Z]"" , strMatch ) :",0.297916226,46.89243888,1
"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab><IF-STMT><tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab>elif keyPressed == Constants.DOWN_KEY:<tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab>elif keyPressed == Constants.TAB_KEY and self.completerStrings:<tab><tab><tab>self.tabPressed()<tab><tab>if self.completerStrings:<tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",1,if keyPressed == Constants . UP_KEY :,if keyPressed == Constants . UP_KEY :,0.75,100,1
"def find_parent_for_new_to(self, pos):<tab>""""""Figure out the parent object for something at 'pos'.""""""<tab>for children in self._editable_children:<tab><tab><IF-STMT><tab><tab><tab>return children.find_parent_for_new_to(pos)<tab><tab>if children._start == pos and pos == children._end:<tab><tab><tab>return children.find_parent_for_new_to(pos)<tab>return self",0,if children . _start <= pos < children . _end :,if children . _start == pos and pos == children . _end :,0.572151059,46.15425016,0.608333333
"def get_sentence(self):<tab>while True:<tab><tab>self._seed += 1<tab><tab>all_files = list(self._all_files)<tab><tab>if self._shuffle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>random.seed(self._seed)<tab><tab><tab>random.shuffle(all_files)<tab><tab>for file_path in all_files:<tab><tab><tab>for ret in self._load_file(file_path):<tab><tab><tab><tab>yield ret<tab><tab>if self._mode == ""test"":<tab><tab><tab>break",0,if self . _n_gpus > 1 :,if self . _seed % 10000 == 0 :,0.20353088,24.808415,0.484848485
"def to_multidevice(batch_iter, num_trainer):<tab>""""""to_multidevice""""""<tab>batch_dict = []<tab>for batch in batch_iter():<tab><tab>batch_dict.append(batch)<tab><tab><IF-STMT><tab><tab><tab>yield batch_dict<tab><tab><tab>batch_dict = []<tab>if len(batch_dict) > 0:<tab><tab>log.warning(<tab><tab><tab>""The batch (%s) can't fill all device (%s)""<tab><tab><tab>""which will be discarded."" % (len(batch_dict), num_trainer)<tab><tab>)",1,if len ( batch_dict ) == num_trainer :,if len ( batch_dict ) == num_trainer :,0.75,100,1
"def get_word_parens_range(self, offset, opening=""("", closing="")""):<tab>end = self._find_word_end(offset)<tab>start_parens = self.code.index(opening, end)<tab>index = start_parens<tab>open_count = 0<tab>while index < len(self.code):<tab><tab>if self.code[index] == opening:<tab><tab><tab>open_count += 1<tab><tab>if self.code[index] == closing:<tab><tab><tab>open_count -= 1<tab><tab><IF-STMT><tab><tab><tab>return (start_parens, index + 1)<tab><tab>index += 1<tab>return (start_parens, index)",1,if open_count == 0 :,if open_count == 0 :,0.75,100,1
"def getNodeBySunid(self, sunid):<tab>""""""Return a node from its sunid.""""""<tab><IF-STMT><tab><tab>return self._sunidDict[sunid]<tab>if self.db_handle:<tab><tab>self.getDomainFromSQL(sunid=sunid)<tab><tab>if sunid in self._sunidDict:<tab><tab><tab>return self._sunidDict[sunid]<tab>else:<tab><tab>return None",1,if sunid in self . _sunidDict :,if sunid in self . _sunidDict :,0.75,100,1
"def get_cabal_in_dir(cabal_dir):<tab>""""""Return .cabal file for cabal directory""""""<tab>for entry in os.listdir(cabal_dir):<tab><tab><IF-STMT><tab><tab><tab>project_name = os.path.splitext(entry)[0]<tab><tab><tab>return (project_name, os.path.join(cabal_dir, entry))<tab>return (None, None)",1,"if entry . endswith ( "".cabal"" ) :","if entry . endswith ( "".cabal"" ) :",0.75,100,1
"def authenticate(self, username, password):<tab># The user entered an email, so try to log them in by e-mail<tab>emails = ContactValue.objects.filter(<tab><tab>value=username,<tab><tab>field__field_type=""email"",<tab><tab>contact__trash=False,<tab><tab>contact__related_user__isnull=False,<tab>)<tab>for email in emails:<tab><tab>try:<tab><tab><tab>user = email.contact.related_user.user.user<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return user<tab><tab>except:<tab><tab><tab>pass<tab>return None",0,if user . check_password ( password ) :,if user and user . password == password :,0.041941157,13.13454947,0.466666667
"def get_art_abs(story_file):<tab>lines = read_text_file(story_file)<tab>lines = [line.lower() for line in lines]<tab>lines = [fix_missing_period(line) for line in lines]<tab>article_lines = []<tab>highlights = []<tab>next_is_highlight = False<tab>for idx, line in enumerate(lines):<tab><tab><IF-STMT><tab><tab><tab>continue  # empty line<tab><tab>elif line.startswith(""@highlight""):<tab><tab><tab>next_is_highlight = True<tab><tab>elif next_is_highlight:<tab><tab><tab>highlights.append(line)<tab><tab>else:<tab><tab><tab>article_lines.append(line)<tab>article = "" "".join(article_lines)<tab>abstract = "" "".join(highlights)<tab>return article, abstract",0,"if line == """" :",if idx == 0 :,0.036540249,16.34121945,0.36
"def find_token(self):<tab>found = False<tab>while not found:<tab><tab>while self.data[self.index] in "" \t"":<tab><tab><tab>self.index += 1<tab><tab><IF-STMT><tab><tab><tab>while self.data[self.index] != ""\n"":<tab><tab><tab><tab>self.index += 1<tab><tab>if self.data[self.index] == ""\n"":<tab><tab><tab>self.index += 1<tab><tab>else:<tab><tab><tab>found = True",0,"if self . data [ self . index ] == ""#"" :","if self . data [ self . index ] == ""\t"" :",0.914422563,76.70387248,1
"def parseBamPEFDistributionFile(self, f):<tab>d = dict()<tab>lastsample = []<tab>for line in f[""f""].splitlines():<tab><tab>cols = line.rstrip().split(""\t"")<tab><tab>if cols[0] == ""#bamPEFragmentSize"":<tab><tab><tab>continue<tab><tab>elif cols[0] == ""Size"":<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d[s_name] = dict()<tab><tab><tab><tab>lastsample = s_name<tab><tab><tab>d[s_name].update({self._int(cols[0]): self._int(cols[1])})<tab>return d",0,if s_name != lastsample :,if s_name not in d :,0.057429006,36.55552229,0.277777778
"def get_user_home():<tab>if is_win():<tab><tab><IF-STMT><tab><tab><tab># Need the fully qualified directory<tab><tab><tab>output = (<tab><tab><tab><tab>subprocess.Popen(<tab><tab><tab><tab><tab>[""cygpath"", ""-m"", os.path.expanduser(""~"")],<tab><tab><tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab><tab>)<tab><tab><tab><tab>.communicate()[0]<tab><tab><tab><tab>.rstrip()<tab><tab><tab>)<tab><tab><tab>return output<tab><tab>else:<tab><tab><tab>return os.environ[""USERPROFILE""]<tab>else:<tab><tab>return os.path.expanduser(""~"")",0,"if sys . platform == ""cygwin"" :","if os . environ . get ( ""USERPROFILE"" ) == """" :",0.080926348,12.45164319,0.277310924
"def _grouping_intervals(grouping):<tab>last_interval = None<tab>for interval in grouping:<tab><tab># if grouping is -1, we are done<tab><tab>if interval == CHAR_MAX:<tab><tab><tab>return<tab><tab># 0: re-use last group ad infinitum<tab><tab><IF-STMT><tab><tab><tab>if last_interval is None:<tab><tab><tab><tab>raise ValueError(""invalid grouping"")<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_interval<tab><tab>yield interval<tab><tab>last_interval = interval",0,if interval == 0 :,if last_interval is not None :,0.030286783,7.267884212,0.257142857
def remove_duplicates(model):<tab>for struct in model.structs:<tab><tab>fields = []<tab><tab>names = []<tab><tab>for field in struct.fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>names.append(field.name)<tab><tab><tab><tab>fields.append(field)<tab><tab>struct.fields = fields,1,if field . name not in names :,if field . name not in names :,0.75,100,1
"def set_multi(self, value):<tab>del self[atype]<tab>for addr in value:<tab><tab># Support assigning dictionary versions of addresses<tab><tab># instead of full Address objects.<tab><tab>if not isinstance(addr, Address):<tab><tab><tab>if atype != ""all"":<tab><tab><tab><tab>addr[""type""] = atype<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addr[""type""] = addr[""atype""]<tab><tab><tab>addrObj = Address()<tab><tab><tab>addrObj.values = addr<tab><tab><tab>addr = addrObj<tab><tab>self.append(addr)",0,"elif ""atype"" in addr and ""type"" not in addr :","elif ""type"" in addr :",0.05745856,19.25177751,0.488888889
"def import_directives():<tab>files_list = os.listdir(os.path.dirname(__file__))<tab>for directive_file in files_list:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>__import__(<tab><tab><tab>""gixy.directives."" + os.path.splitext(directive_file)[0], None, None, [""""]<tab><tab>)",0,"if not directive_file . endswith ( "".py"" ) or directive_file . startswith ( ""_"" ) :","if directive_file . endswith ( "".py"" ) :",0.159044566,35.89962989,0.313333333
"def _get_all_tasks():<tab>proc = Popen([""yarn"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab><IF-STMT><tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if should_yield and ""- "" in line:<tab><tab><tab>yield line.split("" "")[-1]",0,"if ""Commands:"" in line :","if line . startswith ( ""#"" ) :",0.02800146,6.274655311,0.4
"def _waitFakenetStopped(self, timeoutsec=None):<tab>retval = False<tab>while True:<tab><tab>if self._confirmFakenetStopped():<tab><tab><tab>retval = True<tab><tab><tab>break<tab><tab>time.sleep(1)<tab><tab><IF-STMT><tab><tab><tab>timeoutsec -= 1<tab><tab><tab>if timeoutsec <= 0:<tab><tab><tab><tab>break<tab>return retval",1,if timeoutsec is not None :,if timeoutsec is not None :,0.75,100,1
"def parse_compare_fail(<tab>string,<tab>rex=re.compile(<tab><tab>r""^(?P<field>min|max|mean|median|stddev|iqr):""<tab><tab>r""((?P<percentage>[0-9]?[0-9])%|(?P<difference>[0-9]*\.?[0-9]+([eE][-+]?[""<tab><tab>r""0-9]+)?))$""<tab>),):<tab>m = rex.match(string)<tab>if m:<tab><tab>g = m.groupdict()<tab><tab><IF-STMT><tab><tab><tab>return PercentageRegressionCheck(g[""field""], int(g[""percentage""]))<tab><tab>elif g[""difference""]:<tab><tab><tab>return DifferenceRegressionCheck(g[""field""], float(g[""difference""]))<tab>raise argparse.ArgumentTypeError(""Could not parse value: %r."" % string)",1,"if g [ ""percentage"" ] :","if g [ ""percentage"" ] :",0.75,100,1
"def get_converter(self, key, default=None):<tab>""""""Gets a converter for the given key.""""""<tab>if key in self._vars:<tab><tab>return self._vars[key].convert<tab># necessary for keys that match regexes, such as `*PATH`s<tab>for k, var in self._vars.items():<tab><tab>if isinstance(k, str):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>converter = var.convert<tab><tab><tab>self._vars[key] = var<tab><tab><tab>break<tab>else:<tab><tab>converter = self._get_default_converter(default=default)<tab>return converter",0,if k . match ( key ) is not None :,if k . match ( key ) :,0.3837916,59.75579891,0.590909091
"def get_model_params(problem_type: str, hyperparameters):<tab>penalty = hyperparameters.get(""penalty"", L2)<tab>handle_text = hyperparameters.get(""handle_text"", IGNORE)<tab>if problem_type == REGRESSION:<tab><tab>if penalty == L2:<tab><tab><tab>model_class = Ridge<tab><tab><IF-STMT><tab><tab><tab>model_class = Lasso<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Unknown value for penalty {} - supported types are [l1, l2] - falling back to l2"".format(<tab><tab><tab><tab><tab>penalty<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>penalty = L2<tab><tab><tab>model_class = Ridge<tab>else:<tab><tab>model_class = LogisticRegression<tab>return model_class, penalty, handle_text",1,elif penalty == L1 :,elif penalty == L1 :,1,100,1
"def __init__(self, content=None, parent=None):<tab>Transformable.__init__(self, content, parent)<tab>self._items = []<tab>for element in content:<tab><tab>if not element.tag.startswith(namespace):<tab><tab><tab>continue<tab><tab>tag = element.tag[len(namespace) :]<tab><tab><IF-STMT><tab><tab><tab>item = Group(element, self)<tab><tab>elif tag == ""path"":<tab><tab><tab>item = Path(element, self)<tab><tab>else:<tab><tab><tab>log.warn(""Unhandled SVG tag (%s)"" % tag)<tab><tab><tab>continue<tab><tab>self._items.append(item)",0,"if tag == ""g"" :","if tag == ""group"" :",0.394778655,59.46035575,1
"def f_context(args: argparse.Namespace):<tab>choice = args.choice<tab>ctx = utils.get_context()<tab>if choice is None:<tab><tab><IF-STMT><tab><tab><tab>group = ctx.stem<tab><tab><tab>print(f""{group}: {' '.join(utils.get_groups()[group])}"")<tab><tab>else:<tab><tab><tab>print(""Context is not set"")<tab>elif choice == ""none"":  # remove context<tab><tab>ctx and ctx.unlink()<tab>else:  # set context<tab><tab>fname = Path(common.get_config_dir()) / (choice + "".context"")<tab><tab>if ctx:<tab><tab><tab>ctx.rename(fname)<tab><tab>else:<tab><tab><tab>open(fname, ""w"").close()",1,if ctx :,if ctx :,0.531170663,1.00E-10,1
"def check_checksum(self):<tab>""""""fix media checksums""""""<tab>self.progress.set_pass(<tab><tab>_(""Updating checksums on media""), len(self.db.get_media_handles())<tab>)<tab>for objectid in self.db.get_media_handles():<tab><tab>self.progress.step()<tab><tab>obj = self.db.get_media_from_handle(objectid)<tab><tab>full_path = media_path_full(self.db, obj.get_path())<tab><tab>new_checksum = create_checksum(full_path)<tab><tab><IF-STMT><tab><tab><tab>logging.info(""checksum: updating "" + obj.gramps_id)<tab><tab><tab>obj.checksum = new_checksum<tab><tab><tab>self.db.commit_media(obj, self.trans)",1,if new_checksum != obj . checksum :,if new_checksum != obj . checksum :,0.75,100,1
"def get_default_backend(self, user_backends):<tab>retval = None<tab>n_defaults = 0<tab>for name in user_backends:<tab><tab>args = user_backends.get(name)<tab><tab>if args.get(""default"", False):<tab><tab><tab>n_defaults = n_defaults + 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retval = name<tab>return (retval, n_defaults)",0,if retval is None :,"elif args . get ( ""default"" , False ) :",0.016872826,3.386498568,0.111111111
"def on_mqtt_packet_received(self, *args, **kwargs):<tab>packet = kwargs.get(""packet"")<tab>if packet:<tab><tab>packet_size = packet.bytes_length<tab><tab>self._stats[STAT_BYTES_RECEIVED] += packet_size<tab><tab>self._stats[STAT_MSG_RECEIVED] += 1<tab><tab><IF-STMT><tab><tab><tab>self._stats[STAT_PUBLISH_RECEIVED] += 1",0,if packet . fixed_header . packet_type == PUBLISH :,if packet . is_publish :,0.06668419,10.21828938,0.730769231
"def func(self):<tab>if self.schema:<tab><tab>d = {}<tab><tab>for key in self._schema_keys:<tab><tab><tab>d[key] = getattr(self, key)<tab><tab># arbitrary keys<tab><tab><IF-STMT><tab><tab><tab>akeys = set(self._data.keys()) - set(d.keys())<tab><tab><tab>for akey in akeys:<tab><tab><tab><tab>d[akey] = self._data[akey]<tab><tab>return d<tab>else:<tab><tab>return None",1,if self . _data :,if self . _data :,0.75,100,1
"def endElement(self, name, value, connection):<tab>if name == ""vpcId"":<tab><tab>self.vpc_id = value<tab>elif name == ""value"":<tab><tab>if value == ""true"":<tab><tab><tab>value = True<tab><tab>else:<tab><tab><tab>value = False<tab><tab><IF-STMT><tab><tab><tab>self.enable_dns_hostnames = value<tab><tab>elif self._current_attr == ""enableDnsSupport"":<tab><tab><tab>self.enable_dns_support = value",0,"if self . _current_attr == ""enableDnsHostnames"" :","elif self . _current_attr == ""enableDnsHostnames"" :",0.382940898,91.21679091,0.5
"def keyPressEvent(self, event):<tab>if event.key() in (Qt.Key_Right, Qt.Key_Left):<tab><tab>direction = 1<tab><tab><IF-STMT><tab><tab><tab>direction = -1<tab><tab>if event.modifiers() == Qt.ShiftModifier:<tab><tab><tab>print(""shift"")<tab><tab><tab>direction *= 10<tab><tab>self.timeline.setValue(self.timeline.value() + direction)<tab>else:<tab><tab>super(VideoPlayerWidget, self).keyPressEvent(event)",0,if event . key ( ) == Qt . Key_Left :,"if event . key ( ) in ( Qt . Key_Left , Qt . Key_Right ) :",0.343903008,40.27672046,0.652777778
"def find_config(pipeline_config_path: Union[str, Path]) -> Path:<tab>if not Path(pipeline_config_path).is_file():<tab><tab>configs = [<tab><tab><tab>c<tab><tab><tab>for c in Path(__file__).parent.parent.parent.glob(<tab><tab><tab><tab>f""configs/**/{pipeline_config_path}.json""<tab><tab><tab>)<tab><tab><tab>if str(c.with_suffix("""")).endswith(pipeline_config_path)<tab><tab>]  # a simple way to not allow * and ?<tab><tab><IF-STMT><tab><tab><tab>log.info(f""Interpreting '{pipeline_config_path}' as '{configs[0]}'"")<tab><tab><tab>pipeline_config_path = configs[0]<tab>return Path(pipeline_config_path)",0,if configs :,if len ( configs ) == 1 :,0.0465226,1.00E-10,0.36
"def list_translations(dirname):<tab>if not os.path.isdir(dirname):<tab><tab>return []<tab>result = []<tab>for entry in scandir(dirname):<tab><tab>locale_dir = os.path.join(entry.path, ""LC_MESSAGES"")<tab><tab>if not os.path.isdir(locale_dir):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>result.append(Locale.parse(entry.name))<tab>return result",0,"if any ( filter ( lambda x : x . name . endswith ( "".mo"" ) , scandir ( locale_dir ) ) ) :","if os . path . isfile ( os . path . join ( locale_dir , entry . name ) ) :",0.303709326,14.29571794,0.142857143
"def writeTo(self, writable):<tab>chunkStart = 0<tab>fileSize = blob.properties.content_length<tab>while chunkStart < fileSize:<tab><tab>chunkEnd = chunkStart + outer_self._maxAzureBlockBytes - 1<tab><tab>buf = container.get_blob_to_bytes(<tab><tab><tab>blob_name=str(jobStoreFileID), start_range=chunkStart, end_range=chunkEnd<tab><tab>).content<tab><tab><IF-STMT><tab><tab><tab>buf = encryption.decrypt(buf, outer_self.keyPath)<tab><tab>writable.write(buf)<tab><tab>chunkStart = chunkEnd + 1",0,if encrypted :,if outer_self . keyPath is not None :,0.044228356,1.00E-10,0.238095238
"def get_extractor(name):<tab>for extractor in ALL_EXTRACTORS:<tab><tab><IF-STMT><tab><tab><tab>module = import_module(<tab><tab><tab><tab>""anime_downloader.extractors.{}"".format(extractor[""modulename""])<tab><tab><tab>)<tab><tab><tab>return getattr(module, extractor[""class""])",0,"if extractor [ ""regex"" ] in name . lower ( ) :","if extractor [ ""name"" ] == name :",0.101289883,22.82547103,0.479166667
"def updateSize(self):<tab>if self.size is not None:<tab><tab>return<tab>height = 0<tab>width = 0<tab>for row in range(self.layout.rowCount()):<tab><tab>row_height = 0<tab><tab>col_witdh = 0<tab><tab>for col in range(self.layout.columnCount()):<tab><tab><tab>item = self.layout.itemAt(row, col)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>col_witdh += item.width() + 3<tab><tab><tab><tab>row_height = max(row_height, item.height())<tab><tab>width = max(width, col_witdh)<tab><tab>height += row_height<tab>self.setGeometry(0, 0, width, height)<tab>return",0,if item :,if item is not None :,0.090364769,1.00E-10,0.4
"def close_group(self):<tab>""""""Closes a grouping for previous filters""""""<tab>if self._filters:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Not enough open groups to close."")<tab><tab>if isinstance(self._filters[-1], ChainOperator):<tab><tab><tab>flt_sentence = self._filters[-2]<tab><tab>else:<tab><tab><tab>flt_sentence = self._filters[-1]<tab><tab>flt_sentence[1] = flt_sentence[1] + "")""  # closing the group<tab><tab>self._close_group_flag.append(False)  # flag a close group was added<tab>else:<tab><tab>raise RuntimeError(""No filters present. Can't close a group"")<tab>return self",0,if len ( self . _open_group_flag ) < ( len ( self . _close_group_flag ) + 1 ) :,if len ( self . _filters ) < 1 :,0.268638476,10.69025663,0.652380952
"def test_name_conflicts():<tab># Test that we handle participants having the same name correctly.<tab>ev = fake_event()<tab>ev2 = fake_event()<tab># Office365 sets the name to the email address when it's<tab># not available.<tab>ev2.participants[0][""email""] = None<tab>ev2.participants[0][""status""] = ""yes""<tab>merged_participants = ev._partial_participants_merge(ev2)<tab>assert len(merged_participants) == 2<tab>for participant in merged_participants:<tab><tab><IF-STMT><tab><tab><tab>assert participant[""status""] == ""yes""<tab><tab>else:<tab><tab><tab>assert participant[""name""] == ""Ronald Zubar""",0,"if participant [ ""email"" ] is None :","if participant [ ""name"" ] == ""Office365"" :",0.163252899,23.90108882,0.56
"def set_idle(view, idle):<tab>vid = view.id()<tab>current_idle = vid in State[""idle_views""]<tab>if idle != current_idle:<tab><tab><IF-STMT><tab><tab><tab>State[""idle_views""].add(vid)<tab><tab>else:<tab><tab><tab>State[""idle_views""].discard(vid)<tab><tab>toggle_demoted_regions(view, idle)",0,if idle :,if current_idle :,0.319750449,1.00E-10,0.555555556
"def _deserialize(self, value, attr, data, **kwargs):<tab>if isinstance(value, str):<tab><tab>return [value, 0, 0]<tab>if isinstance(value, list) and len(value) == 3:<tab><tab>condition = (<tab><tab><tab>isinstance(value[0], str)<tab><tab><tab>and isinstance(value[1], int)<tab><tab><tab>and isinstance(value[1], int)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return value<tab>raise ValidationError(""This field expects a str or a list of [str, int, int]."")",1,if condition :,if condition :,0.531170663,1.00E-10,1
"def _struct(self, fields):<tab>result = {}<tab>for field in fields:<tab><tab>if field[0] == ""__parent"":<tab><tab><tab>parent = self.instance(field[1])<tab><tab><tab>if isinstance(parent, dict):<tab><tab><tab><tab>result.update(parent)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = parent<tab><tab><tab>else:<tab><tab><tab><tab>result[field[0]] = parent<tab><tab>else:<tab><tab><tab>result[field[0]] = self.instance(field[1])<tab>return result",0,elif len ( fields ) == 1 :,"elif isinstance ( parent , list ) :",0.102974066,6.892168295,0.25
"def validate(self):<tab>if ""accounts"" in self.data and self.data[""accounts""] == ""matched"":<tab><tab>found = False<tab><tab>for f in self.manager.iter_filters():<tab><tab><tab>if isinstance(f, AmiCrossAccountFilter):<tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise PolicyValidationError(<tab><tab><tab><tab>""policy:%s filter:%s with matched requires cross-account filter""<tab><tab><tab><tab>% (self.manager.ctx.policy.name, self.type)<tab><tab><tab>)",1,if not found :,if not found :,0.75,100,1
"def add_rule6(self, rule):<tab>if self.cleared:<tab><tab>return<tab>self._lock.acquire()<tab>try:<tab><tab>self._other6.append(rule)<tab><tab><IF-STMT><tab><tab><tab>self._insert_iptables_rule(rule, ipv6=True)<tab>finally:<tab><tab>self._lock.release()",0,"if not self . _exists_iptables_rule ( rule , ipv6 = True ) :",if len ( self . _other6 ) == 0 :,0.022365231,9.770598012,0.319444444
"def load_grammar(self, *args):<tab>""Load a grammar from a pickle file""<tab>filename = askopenfilename(<tab><tab>filetypes=self.GRAMMAR_FILE_TYPES, defaultextension="".cfg""<tab>)<tab>if not filename:<tab><tab>return<tab>try:<tab><tab><IF-STMT><tab><tab><tab>with open(filename, ""rb"") as infile:<tab><tab><tab><tab>grammar = pickle.load(infile)<tab><tab>else:<tab><tab><tab>with open(filename, ""r"") as infile:<tab><tab><tab><tab>grammar = CFG.fromstring(infile.read())<tab><tab>self.set_grammar(grammar)<tab>except Exception as e:<tab><tab>tkinter.messagebox.showerror(<tab><tab><tab>""Error Loading Grammar"", ""Unable to open file: %r"" % filename<tab><tab>)",0,"if filename . endswith ( "".pickle"" ) :","if sys . platform == ""win32"" :",0.019627455,5.677542911,0.333333333
"def _join_printed_types(self, types):<tab>""""""Pretty-print the union of the printed types.""""""<tab>types = sorted(set(types))  # dedup<tab>if len(types) == 1:<tab><tab>return next(iter(types))<tab>elif types:<tab><tab><IF-STMT><tab><tab><tab>types.remove(""None"")<tab><tab><tab>return ""Optional[%s]"" % self._join_printed_types(types)<tab><tab>else:<tab><tab><tab>return ""Union[%s]"" % "", "".join(types)<tab>else:<tab><tab>return ""nothing""",1,"if ""None"" in types :","if ""None"" in types :",0.75,100,1
"def __init__(self, **kwargs):<tab>for key, val in kwargs.items():<tab><tab>field = getattr(self.__class__, key, None)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Field %r returned from raw SQL query does not have ""<tab><tab><tab><tab>""a column defined in the model"" % key<tab><tab><tab>)<tab><tab>setattr(self, field.get_attname() or key, field.to_python(val))",1,if field is None :,if field is None :,0.75,100,1
"def get_transaction_execution_results(self, batch_signature):<tab>with self._condition:<tab><tab>batch_status = self._batch_statuses.get(batch_signature)<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>annotated_batch = self._batch_by_id.get(batch_signature)<tab><tab>if annotated_batch is None:<tab><tab><tab>return None<tab><tab>results = []<tab><tab>for txn in annotated_batch.batch.transactions:<tab><tab><tab>result = self._txn_results.get(txn.header_signature)<tab><tab><tab>if result is not None:<tab><tab><tab><tab>results.append(result)<tab><tab>return results",1,if batch_status is None :,if batch_status is None :,0.75,100,1
"def _check_params(self) -> None:<tab>if self.augmentation and self.ratio <= 0:<tab><tab>raise ValueError(""The augmentation ratio must be positive."")<tab>if self.clip_values is not None:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""`clip_values` should be a tuple of 2 floats or arrays containing the allowed data range.""<tab><tab><tab>)<tab><tab>if np.array(self.clip_values[0] >= self.clip_values[1]).any():<tab><tab><tab>raise ValueError(""Invalid `clip_values`: min >= max."")",0,if len ( self . clip_values ) != 2 :,"if not isinstance ( self . clip_values , ( tuple , list ) ) :",0.125053499,31.18181498,0.211111111
def ping_all():<tab>for l in _all_listeners.values():<tab><tab>count = l.receiver.count()<tab><tab>if count:<tab><tab><tab>for dev in l.receiver:<tab><tab><tab><tab>dev.ping()<tab><tab><tab><tab>l._status_changed(dev)<tab><tab><tab><tab>count -= 1<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break,0,if not count :,if count <= 0 :,0.045150551,10.68217516,0.4
"def on_btOK_clicked(self, *a):<tab>""""""Handler for OK button""""""<tab>if self.ac_callback is not None:<tab><tab>self._set_title()<tab><tab>if self._mode == ActionEditor.AEC_MENUITEM:<tab><tab><tab>self.ac_callback(self.id, self)<tab><tab>else:<tab><tab><tab>a = self.generate_modifiers(<tab><tab><tab><tab>self._action, self._selected_component.NAME == ""custom""<tab><tab><tab>)<tab><tab><tab>self.ac_callback(self.id, a)<tab><tab><tab>self.ac_callback = None<tab><tab><IF-STMT><tab><tab><tab>self._selected_component.on_ok(a)<tab>self.close()",0,if self . _selected_component :,if self . _selected_component is not None :,0.351498834,59.00468726,0.444444444
"def apply_ssl(self, request):<tab>if self.ssl_protocol:<tab><tab><IF-STMT><tab><tab><tab>self.sslconf.setProtocol(self.ssl_protocol)<tab><tab><tab>QSslConfiguration.setDefaultConfiguration(self.sslconf)<tab>request.setSslConfiguration(self.sslconf)<tab>return request",0,if self . sslconf . protocol ( ) != self . ssl_protocol :,if self . sslconf . protocol != self . ssl_protocol :,0.672203526,74.9715377,1
"def _iter_process_args(mapping, pid, max_depth):<tab>""""""Iterator to traverse up the tree, yielding each process's argument list.""""""<tab>for _ in range(max_depth):<tab><tab>try:<tab><tab><tab>proc = mapping[pid]<tab><tab>except KeyError:  # We've reached the root process. Give up.<tab><tab><tab>break<tab><tab><IF-STMT>  # Persumably the process should always have a name?<tab><tab><tab>yield proc.args<tab><tab>pid = proc.ppid  # Go up one level.",0,if proc . args :,if proc . name :,0.394778655,42.72870064,0.6
"def store_data(self, store_loc, **kwargs):<tab>""""""Put arrays to store""""""<tab># print(store_loc)<tab>g = self.store.create_group(store_loc)<tab>for (<tab><tab>k,<tab><tab>v,<tab>) in kwargs.items():<tab><tab># print(type(v[0]))<tab><tab># print(k)<tab><tab>if type(v) == list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if type(v[0]) is np.str_ or type(v[0]) is str:<tab><tab><tab><tab><tab>v = [a.encode(""utf8"") for a in v]<tab><tab>g.create_dataset(k, data=v, compression=self.clib, compression_opts=self.clev)",0,if len ( v ) != 0 :,if len ( v ) == 1 :,0.524151519,48.54917717,0.666666667
"def add_system_info_creds_to_config(creds):<tab>for user in creds:<tab><tab>ConfigService.creds_add_username(creds[user][""username""])<tab><tab>if ""password"" in creds[user] and creds[user][""password""]:<tab><tab><tab>ConfigService.creds_add_password(creds[user][""password""])<tab><tab>if ""lm_hash"" in creds[user] and creds[user][""lm_hash""]:<tab><tab><tab>ConfigService.creds_add_lm_hash(creds[user][""lm_hash""])<tab><tab><IF-STMT><tab><tab><tab>ConfigService.creds_add_ntlm_hash(creds[user][""ntlm_hash""])",1,"if ""ntlm_hash"" in creds [ user ] and creds [ user ] [ ""ntlm_hash"" ] :","if ""ntlm_hash"" in creds [ user ] and creds [ user ] [ ""ntlm_hash"" ] :",1,100,1
"def _format_arg(self, name, spec, value):<tab>if name == ""title"":<tab><tab><IF-STMT><tab><tab><tab>return ""--title""<tab><tab>elif isinstance(value, str):<tab><tab><tab>return ""--title --title_text %s"" % (value,)<tab><tab>else:<tab><tab><tab>raise ValueError('Unknown value for ""title"" argument: ' + str(value))<tab>return super(Pik, self)._format_arg(name, spec, value)",0,"if isinstance ( value , bool ) and value :",if value is None :,0.014393213,5.171845311,0.225
"def handle_friend(self):<tab>tokens, last = self._get_var_tokens_up_to(False, ""("", "";"")<tab>if last.name == ""("":<tab><tab>tokens.append(last)<tab><tab>self._add_back_tokens(tokens)<tab><tab>token = self._get_next_token()<tab><tab>while token.name in (""inline"", ""typename"", ""::""):<tab><tab><tab>token = self._get_next_token()<tab><tab>result = self._generate_one(token)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>tokens = tokens[1:]<tab><tab>result = self.converter.to_type(tokens)[0]<tab>assert result<tab>return Friend(result.start, result.end, result, self.namespace_stack)",0,"if tokens [ 0 ] . name == ""class"" :","if tokens [ 0 ] . name == ""("" :",0.642805659,79.10665072,1
"def list_subtitles(self, video, languages):<tab>season = None<tab>episodes = []<tab>if isinstance(video, Episode):<tab><tab>titles = [video.series] + video.alternative_series<tab><tab>season = video.season<tab><tab>episodes = video.episodes<tab>else:<tab><tab>titles = [video.title] + video.alternative_titles<tab>for title in titles:<tab><tab>subtitles = [<tab><tab><tab>s<tab><tab><tab>for l in languages<tab><tab><tab>for s in self.query(<tab><tab><tab><tab>l, title, season=season, episodes=episodes, year=video.year<tab><tab><tab>)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return subtitles<tab>return []",1,if subtitles :,if subtitles :,0.531170663,1.00E-10,1
"def on_write_needed(self, nbytes, underflow):<tab>if underflow:<tab><tab>self._handle_underflow()<tab>else:<tab><tab>self._write_to_stream(nbytes)<tab># Asynchronously update time<tab>if self._events:<tab><tab><IF-STMT><tab><tab><tab>self._time_sync_operation.delete()<tab><tab><tab>self._time_sync_operation = None<tab><tab>if self._time_sync_operation is None:<tab><tab><tab>assert _debug(""PulseAudioPlayer: trigger timing info update"")<tab><tab><tab>self._time_sync_operation = self.stream.update_timing_info(<tab><tab><tab><tab>self._process_events<tab><tab><tab>)",0,if self . _time_sync_operation is not None and self . _time_sync_operation . is_done :,if self . _time_sync_operation is not None :,0.357729799,34.23503955,0.791666667
def _set_account_info(self):<tab>with session_scope(self.account_id) as db_session:<tab><tab>account = db_session.query(ImapAccount).get(self.account_id)<tab><tab>self.sync_state = account.sync_state<tab><tab>self.provider = account.provider<tab><tab>self.provider_info = account.provider_info<tab><tab>self.email_address = account.email_address<tab><tab>self.auth_handler = account.auth_handler<tab><tab><IF-STMT><tab><tab><tab>self.client_cls = GmailCrispinClient<tab><tab>else:<tab><tab><tab>self.client_cls = CrispinClient,0,"if account . provider == ""gmail"" :","if account . email_address . startswith ( ""gmail"" ) :",0.140212302,18.47686042,0.6
"def make_timesheet_records():<tab>employees = get_timesheet_based_salary_slip_employee()<tab>for e in employees:<tab><tab>ts = make_timesheet(<tab><tab><tab>e.employee,<tab><tab><tab>simulate=True,<tab><tab><tab>billable=1,<tab><tab><tab>activity_type=get_random(""Activity Type""),<tab><tab><tab>company=frappe.flags.company,<tab><tab>)<tab><tab>frappe.db.commit()<tab><tab>rand = random.random()<tab><tab><IF-STMT><tab><tab><tab>make_salary_slip_for_timesheet(ts.name)<tab><tab>rand = random.random()<tab><tab>if rand >= 0.2:<tab><tab><tab>make_sales_invoice_for_timesheet(ts.name)",0,if rand >= 0.3 :,if rand >= 0.2 :,0.394778655,53.72849659,1
"def free(self, addr, ban=0):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>self.ban.append({""addr"": addr, ""counter"": ban})<tab><tab>else:<tab><tab><tab>base, bit, is_allocated = self.locate(addr)<tab><tab><tab>if len(self.addr_map) <= base:<tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab>if self.addr_map[base] & (1 << bit):<tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab>self.allocated -= 1<tab><tab><tab>self.addr_map[base] ^= 1 << bit",0,if ban != 0 :,if ban :,0.067674239,1.00E-10,0.7
"def flush_log(self):<tab>try:<tab><tab>while len(self.log_buffer) > 0:<tab><tab><tab>level, message = self.log_buffer.pop(0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._display_log(message, level)<tab>except IndexError:<tab><tab>pass",0,if level <= self . log_level :,if message :,0.020447728,1.00E-10,0.377777778
"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab>if mysql_user:<tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab>if mysql_host:<tab><tab><tab>args[""host""] = mysql_host<tab><tab><IF-STMT><tab><tab><tab>args[""port""] = mysql_port<tab><tab>if mysql_socket:<tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",1,if mysql_port :,if mysql_port :,0.531170663,1.00E-10,1
"def get_middleware_resolvers(middlewares):<tab>for middleware in middlewares:<tab><tab># If the middleware is a function instead of a class<tab><tab><IF-STMT><tab><tab><tab>yield middleware<tab><tab>if not hasattr(middleware, MIDDLEWARE_RESOLVER_FUNCTION):<tab><tab><tab>continue<tab><tab>yield getattr(middleware, MIDDLEWARE_RESOLVER_FUNCTION)",0,if inspect . isfunction ( middleware ) :,"if callable ( middleware ) and issubclass ( middleware , MIDDLEWARE_RESOLVER_FUNCTION ) :",0.131903604,10.70454633,0.234375
"def get_sentence(self):<tab>while True:<tab><tab>self._seed += 1<tab><tab>all_files = list(self._all_files)<tab><tab><IF-STMT><tab><tab><tab>if self._n_gpus > 1:<tab><tab><tab><tab>random.seed(self._seed)<tab><tab><tab>random.shuffle(all_files)<tab><tab>for file_path in all_files:<tab><tab><tab>for ret in self._load_file(file_path):<tab><tab><tab><tab>yield ret<tab><tab>if self._mode == ""test"":<tab><tab><tab>break",1,if self . _shuffle :,if self . _shuffle :,0.75,100,1
"def extract_cookies(self, response, request):<tab>""""""Extract cookies from response, where allowable given the request.""""""<tab>_debug(""extract_cookies: %s"", response.info())<tab>self._cookies_lock.acquire()<tab>try:<tab><tab>self._policy._now = self._now = int(time.time())<tab><tab>for cookie in self.make_cookies(response, request):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_debug("" setting cookie: %s"", cookie)<tab><tab><tab><tab>self.set_cookie(cookie)<tab>finally:<tab><tab>self._cookies_lock.release()",0,"if self . _policy . set_ok ( cookie , request ) :",if cookie is not None :,0.011387186,2.383515454,0.241666667
"def _gen_filename(self, name):<tab>if name == ""in_average"":<tab><tab>avg_subject = str(self.inputs.hemisphere) + "".EC_average""<tab><tab>avg_directory = os.path.join(self.inputs.subjects_dir, avg_subject)<tab><tab><IF-STMT><tab><tab><tab>fs_home = os.path.abspath(os.environ.get(""FREESURFER_HOME""))<tab><tab>return avg_subject<tab>elif name == ""out_file"":<tab><tab>return self._list_outputs()[name]<tab>else:<tab><tab>return None",0,if not os . path . isdir ( avg_directory ) :,if os . path . exists ( fs_home ) :,0.152699025,25.67070566,0.274725275
"def decorated_view(*args, **kwargs):<tab>h = {}<tab>mechanisms = [(method, login_mechanisms.get(method)) for method in auth_methods]<tab>for method, mechanism in mechanisms:<tab><tab>if mechanism and mechanism():<tab><tab><tab>return fn(*args, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>r = _security.default_http_auth_realm<tab><tab><tab>h[""WWW-Authenticate""] = 'Basic realm=""%s""' % r<tab>if _security._unauthorized_callback:<tab><tab>return _security._unauthorized_callback()<tab>else:<tab><tab>return _get_unauthorized_response(headers=h)",0,"elif method == ""basic"" :",if _security . default_http_auth_realm :,0.026864248,3.386498568,0.214285714
"def _iterate_files(self, files, root, include_checksums, relpath):<tab>file_list = {}<tab>for file in files:<tab><tab>exclude = False<tab><tab># exclude defined filename patterns<tab><tab>for pattern in S3Sync.exclude_files:<tab><tab><tab>if fnmatch.fnmatch(file, pattern):<tab><tab><tab><tab>exclude = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>full_path = root + ""/"" + file<tab><tab><tab>if include_checksums:<tab><tab><tab><tab># get checksum<tab><tab><tab><tab>checksum = self._hash_file(full_path)<tab><tab><tab>else:<tab><tab><tab><tab>checksum = """"<tab><tab><tab>file_list[relpath + file] = [full_path, checksum]<tab>return file_list",0,if not exclude :,if exclude :,0.096488528,1.00E-10,0.416666667
"def attr(**kw):<tab>kw = kw.items()<tab>kw.sort()<tab>parts = []<tab>for name, value in kw:<tab><tab>if value is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>name = name[:-1]<tab><tab>parts.append('%s=""%s""' % (html_quote(name), html_quote(value)))<tab>return html("" "".join(parts))",0,"if name . endswith ( ""_"" ) :","if name [ - 1 ] == '""' :",0.032180044,8.054496385,0.6
"def create(self):<tab>if not self.created:<tab><tab>self.created = True<tab><tab>cmd = self._mode<tab><tab><IF-STMT><tab><tab><tab>cmd = u""""<tab><tab>vim.command(<tab><tab><tab>(u"":%snoremap %s %s"" % (cmd, str(self), self.command)).encode(u""utf-8"")<tab><tab>)",0,if cmd == MODE_ALL :,if self . command is None :,0.027969855,6.770186229,0.224489796
"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab><IF-STMT><tab><tab><tab>if self.stdlibhighlighting and value in self.stdlib_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.c99highlighting and value in self.c99_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.platformhighlighting and value in self.linux_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",1,if token is Name :,if token is Name :,0.75,100,1
"def _merge_colormaps(kwargs):<tab>""""""Merge colormaps listed in kwargs.""""""<tab>from trollimage.colormap import Colormap<tab>full_cmap = None<tab>palette = kwargs[""palettes""]<tab>if isinstance(palette, Colormap):<tab><tab>full_cmap = palette<tab>else:<tab><tab>for itm in palette:<tab><tab><tab>cmap = create_colormap(itm)<tab><tab><tab>cmap.set_range(itm[""min_value""], itm[""max_value""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>full_cmap = cmap<tab><tab><tab>else:<tab><tab><tab><tab>full_cmap = full_cmap + cmap<tab>return full_cmap",1,if full_cmap is None :,if full_cmap is None :,0.75,100,1
"def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):<tab>key_tag = tok.get_uint16()<tab>algorithm = tok.get_uint8()<tab>digest_type = tok.get_uint8()<tab>chunks = []<tab>while 1:<tab><tab>t = tok.get().unescape()<tab><tab>if t.is_eol_or_eof():<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise dns.exception.SyntaxError<tab><tab>chunks.append(t.value)<tab>digest = """".join(chunks)<tab>digest = digest.decode(""hex_codec"")<tab>return cls(rdclass, rdtype, key_tag, algorithm, digest_type, digest)",1,if not t . is_identifier ( ) :,if not t . is_identifier ( ) :,0.75,100,1
"def connect_reader_to_writer(reader, writer):<tab>BUF_SIZE = 8192<tab>try:<tab><tab>while True:<tab><tab><tab>data = await reader.read(BUF_SIZE)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not writer.transport.is_closing():<tab><tab><tab><tab><tab>writer.write_eof()<tab><tab><tab><tab><tab>await writer.drain()<tab><tab><tab><tab>return<tab><tab><tab>writer.write(data)<tab><tab><tab>await writer.drain()<tab>except (OSError, asyncio.IncompleteReadError) as e:<tab><tab>pass",1,if not data :,if not data :,0.75,100,1
"def _get_cuda_device(*args):<tab># Returns cuda.Device or DummyDevice.<tab>for arg in args:<tab><tab>if type(arg) is not bool and isinstance(arg, _integer_types):<tab><tab><tab>check_cuda_available()<tab><tab><tab>return Device(arg)<tab><tab>if isinstance(arg, ndarray):<tab><tab><tab>if arg.device is None:<tab><tab><tab><tab>continue<tab><tab><tab>return arg.device<tab><tab><IF-STMT><tab><tab><tab>return arg<tab># NOTE: This function returns DummyDevice for both NumPy and ChainerX<tab>return DummyDevice",0,"if available and isinstance ( arg , Device ) :","elif isinstance ( arg , Device ) :",0.381999995,65.48907867,0.1
"def skip_to_semicolon(s, i):<tab>n = len(s)<tab>while i < n:<tab><tab>c = s[i]<tab><tab>if c == "";"":<tab><tab><tab>return i<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_string(s, i)<tab><tab>elif g.match(s, i, ""//""):<tab><tab><tab>i = g.skip_to_end_of_line(s, i)<tab><tab>elif g.match(s, i, ""/*""):<tab><tab><tab>i = g.skip_block_comment(s, i)<tab><tab>else:<tab><tab><tab>i += 1<tab>return i",0,"elif c == ""'"" or c == '""' :","elif c == ""\\"" :",0.296124704,24.92597867,0.625
"def build_CallFunc(self, o):<tab>children = o.getChildren()<tab># Build callee from first child<tab>callee = self.build(children[0])<tab># Build args and kwargs from remaining children<tab>args = []<tab>kwargs = {}<tab>for child in children[1:]:<tab><tab>class_name = child.__class__.__name__<tab><tab># None is ignored<tab><tab>if class_name == ""NoneType"":<tab><tab><tab>continue<tab><tab># Keywords become kwargs<tab><tab><IF-STMT><tab><tab><tab>kwargs.update(self.build(child))<tab><tab># Everything else becomes args<tab><tab>else:<tab><tab><tab>args.append(self.build(child))<tab>return callee(*args, **kwargs)",0,"if class_name == ""Keyword"" :","elif class_name == ""Keyword"" :",0.311522644,88.01117368,0.333333333
"def _extract_constant_functions(slither: SlitherCore) -> Dict[str, List[str]]:<tab>ret: Dict[str, List[str]] = {}<tab>for contract in slither.contracts:<tab><tab>cst_functions = [<tab><tab><tab>_get_name(f) for f in contract.functions_entry_points if _is_constant(f)<tab><tab>]<tab><tab>cst_functions += [<tab><tab><tab>v.function_name<tab><tab><tab>for v in contract.state_variables<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if cst_functions:<tab><tab><tab>ret[contract.name] = cst_functions<tab>return ret",0,"if v . visibility in [ ""public"" ]",if _is_constant ( v ),0.018586852,5.114598707,0.56
"def acquire_read_lock(self, wait=True):<tab>state = self.state<tab>if state.writing:<tab><tab>raise LockError(""lock is in writing state"")<tab>if state.reentrantcount == 0:<tab><tab>x = self.do_acquire_read_lock(wait)<tab><tab><IF-STMT><tab><tab><tab>state.reentrantcount += 1<tab><tab><tab>state.reading = True<tab><tab>return x<tab>elif state.reading:<tab><tab>state.reentrantcount += 1<tab><tab>return True",0,if wait or x :,if x is not None :,0.157294704,10.68217516,0.208333333
"def get_optional_nargs(self, name):<tab>for n, kwargs in self.conf[""optional_args""]:<tab><tab><IF-STMT><tab><tab><tab>if ""action"" in kwargs:<tab><tab><tab><tab>action = kwargs[""action""]<tab><tab><tab><tab>if action in (""store_true"", ""store_false""):<tab><tab><tab><tab><tab>return 0<tab><tab><tab>break<tab>return 1",0,if name == n :,if n == name :,0.290171421,21.36435032,0.5
"def _requests_to_follow(self, response):<tab>if not isinstance(response, HtmlResponse):<tab><tab>return<tab>seen = set()<tab>for n, rule in enumerate(self._rules):<tab><tab>links = [<tab><tab><tab>lnk<tab><tab><tab>for lnk in rule.link_extractor.extract_links(response)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if links and rule.process_links:<tab><tab><tab>links = rule.process_links(links)<tab><tab>for link in links:<tab><tab><tab>seen.add(link)<tab><tab><tab>request = self._build_request(n, link)<tab><tab><tab>yield rule._process_request(request, response)",1,if lnk not in seen,if lnk not in seen,0.75,100,1
"def process_module(name, module, parent):<tab>if parent:<tab><tab>modules[parent][""items""].append(name)<tab><tab>mg = module_groups.setdefault(name, [])<tab><tab>mg.append(parent)<tab><tab>if get_module_type(name) == ""py3status"":<tab><tab><tab>module["".group""] = parent<tab># check module content<tab>for k, v in list(module.items()):<tab><tab><IF-STMT><tab><tab><tab># on_click event<tab><tab><tab>process_onclick(k, v, name)<tab><tab><tab># on_click should not be passed to the module via the config.<tab><tab><tab>del module[k]<tab><tab>if isinstance(v, ModuleDefinition):<tab><tab><tab># we are a container<tab><tab><tab>module[""items""] = []<tab>return module",0,"if k . startswith ( ""on_click"" ) :",if k in mg :,0.035401841,5.830425236,0.481481481
"def _mysql_version_validator(version, sku_info, tier):<tab>if version:<tab><tab>versions = get_mysql_versions(sku_info, tier)<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""Incorrect value for --version. Allowed values : {}"".format(versions)<tab><tab><tab>)",1,if version not in versions :,if version not in versions :,0.75,100,1
"def do_blocking_test(self, block_func, block_args, trigger_func, trigger_args):<tab>thread = _TriggerThread(trigger_func, trigger_args)<tab>thread.start()<tab>try:<tab><tab>self.result = block_func(*block_args)<tab><tab># If block_func returned before our thread made the call, we failed!<tab><tab><IF-STMT><tab><tab><tab>self.fail(""blocking function '%r' appeared not to block"" % block_func)<tab><tab>return self.result<tab>finally:<tab><tab>thread.join(10)  # make sure the thread terminates<tab><tab>if thread.is_alive():<tab><tab><tab>self.fail(""trigger function '%r' appeared to not return"" % trigger_func)",0,if not thread . startedEvent . is_set ( ) :,if thread . is_alive ( ) :,0.070938701,24.29991329,0.371428571
"def _fatal_error(self, exc, message=""Fatal error on pipe transport""):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if self._loop.get_debug():<tab><tab><tab><tab>logger.debug(""%r: %s"", self, message, exc_info=True)<tab><tab>else:<tab><tab><tab>self._loop.call_exception_handler(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""message"": message,<tab><tab><tab><tab><tab>""exception"": exc,<tab><tab><tab><tab><tab>""transport"": self,<tab><tab><tab><tab><tab>""protocol"": self._protocol,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>finally:<tab><tab>self._force_close(exc)",0,"if isinstance ( exc , OSError ) :",if exc is not None :,0.019830745,7.654112967,0.232142857
"def run_test_family(tests, mode_filter, files, open_func, *make_args):<tab>for test_func in tests:<tab><tab><IF-STMT><tab><tab><tab>out.write(""\n"")<tab><tab><tab>continue<tab><tab>if mode_filter in test_func.file_open_mode:<tab><tab><tab>continue<tab><tab>for s in test_func.file_sizes:<tab><tab><tab>name, size = files[size_names[s]]<tab><tab><tab># name += file_ext<tab><tab><tab>args = tuple(f(name, size) for f in make_args)<tab><tab><tab>run_one_test(name, size, open_func, test_func, *args)",0,if test_func is None :,if test_func . is_tty :,0.064978772,33.03164318,0.416666667
"def py__get__(self, obj):<tab># Arguments in __get__ descriptors are obj, class.<tab># `method` is the new parent of the array, don't know if that's good.<tab>names = self.get_function_slot_names(""__get__"")<tab>if names:<tab><tab><IF-STMT><tab><tab><tab>return self.execute_function_slots(names, obj, obj.class_context)<tab><tab>else:<tab><tab><tab>none_obj = compiled.create(self.evaluator, None)<tab><tab><tab>return self.execute_function_slots(names, none_obj, obj)<tab>else:<tab><tab>return ContextSet(self)",0,"if isinstance ( obj , AbstractInstanceContext ) :","if hasattr ( obj , ""class_context"" ) :",0.091668085,16.59038701,0.481481481
"def _options_fcheck(self, name, xflags, table):<tab>for entry in table:<tab><tab>if entry.name is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise XTablesError(""%s: --%s must be specified"" % (name, entry.name))<tab><tab><tab>if not xflags & (1 << entry.id):<tab><tab><tab><tab>continue",0,if entry . flags & XTOPT_MAND and not xflags & ( 1 << entry . id ) :,"if entry . name not in ( name , name . lower ( ) ) :",0.288889872,9.419061412,0.217836257
"def _consumer_healthy(self):<tab>abnormal_num = 0<tab>for w in self._consumers:<tab><tab>if not w.is_alive() and w.id not in self._consumer_endsig:<tab><tab><tab>abnormal_num += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally with exitcode[{}]"".format(<tab><tab><tab><tab><tab>w.pid, w.exitcode<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally"".format(w.ident)<tab><tab><tab>logger.warn(errmsg)<tab>if abnormal_num > 0:<tab><tab>logger.warn(""{} consumers have exited abnormally!!!"".format(abnormal_num))<tab>return abnormal_num == 0",0,if self . _use_process :,if w . exitcode :,0.286540249,7.715486568,0.36
"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if word not in ignored and len(word) >= 2:<tab><tab><tab>if previous == word:<tab><tab><tab><tab>group += 1<tab><tab><tab>elif group > 1:<tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",0,if not word :,if word in ignored :,0.045150551,14.05853313,0.277777778
"def _validate_callbacks(cls, callbacks):<tab>for callback in callbacks:<tab><tab>if not isinstance(callback, Callback):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TypeError(""Make sure to instantiate the callbacks."")<tab><tab><tab>raise TypeError(""Only accepts a `callbacks` instance."")",0,"if issubclass ( callback , Callback ) :","if not isinstance ( callback , Callback ) :",0.331463006,61.04735836,0.398148148
"def convert_errors(from_, to, msg=None):<tab>exc = None<tab>try:<tab><tab>yield None<tab>except from_ as e:<tab><tab>exc = e<tab>if exc:<tab><tab>info = ""%s: %s"" % (exc.__class__.__name__, str(exc))<tab><tab><IF-STMT><tab><tab><tab>info = ""%s: %s"" % (msg, info)<tab><tab>raise to(info)",1,if msg :,if msg :,0.531170663,1.00E-10,1
"def delete_loan(loan_key, loan=None):<tab><IF-STMT><tab><tab>loan = web.ctx.site.store.get(loan_key)<tab><tab>if not loan:<tab><tab><tab>raise Exception(""Could not find store record for %s"", loan_key)<tab>loan.delete()",1,if not loan :,if not loan :,0.75,100,1
"def last_action_for(self, agent_id: AgentID = _DUMMY_AGENT_ID) -> EnvActionType:<tab>""""""Returns the last action for the specified agent, or zeros.""""""<tab>if agent_id in self._agent_to_last_action:<tab><tab>return flatten_to_single_ndarray(self._agent_to_last_action[agent_id])<tab>else:<tab><tab>policy = self._policies[self.policy_for(agent_id)]<tab><tab>flat = flatten_to_single_ndarray(policy.action_space.sample())<tab><tab><IF-STMT><tab><tab><tab>return np.zeros_like(flat, dtype=policy.action_space.dtype)<tab><tab>return np.zeros_like(flat)",0,"if hasattr ( policy . action_space , ""dtype"" ) :",if policy . action_space . dtype is not None :,0.061266023,30.18135846,0.215909091
"def on_leave(<tab>self, original_node: CSTNodeT, updated_node: CSTNodeT) -> Union[cst.Import, cst.ImportFrom, CSTNodeT, RemovalSentinel]:<tab>if isinstance(updated_node, cst.Import):<tab><tab>for alias in updated_node.names:<tab><tab><tab>name = alias.name<tab><tab><tab>if isinstance(name, cst.Name) and name.value == ""b"":<tab><tab><tab><tab>return cst.RemoveFromParent()<tab>elif isinstance(updated_node, cst.ImportFrom):<tab><tab>module = updated_node.module<tab><tab><IF-STMT><tab><tab><tab>return cst.RemoveFromParent()<tab>return updated_node",0,"if isinstance ( module , cst . Name ) and module . value == ""e"" :","if isinstance ( module , RemovalSentinel ) and module . value == ""a"" :",0.618042826,59.34207737,0.382352941
"def sortkey(self, r, prog=None):<tab>ret = []<tab>for col, reverse in self._ordering:<tab><tab><IF-STMT><tab><tab><tab>col = self.column(col)<tab><tab>val = col.getTypedValue(r)<tab><tab>ret.append(Reversor(val) if reverse else val)<tab>if prog:<tab><tab>prog.addProgress(1)<tab>return ret",0,"if isinstance ( col , str ) :","if isinstance ( col , TypedColumn ) :",0.549040681,59.46035575,0.666666667
"def down_button_clicked(self, obj):<tab>ref = self.get_selected()<tab>if ref and ref[1] is not None:<tab><tab>pos = self.find_index(ref)<tab><tab><IF-STMT><tab><tab><tab>self._move_down(pos, ref[1])<tab>elif ref and ref[1] is None:<tab><tab>self._move_down_group(ref[0])",0,if pos [ 1 ] >= 0 and pos [ 1 ] < len ( self . get_data ( ) [ pos [ 0 ] ] ) - 1 :,if pos is not None :,0.02267101,0.199575407,0.212473573
"def maybe_swap_for_shadow_path(self, path: str) -> str:<tab>if not self.shadow_map:<tab><tab>return path<tab>path = normpath(path, self.options)<tab>previously_checked = path in self.shadow_equivalence_map<tab>if not previously_checked:<tab><tab>for source, shadow in self.shadow_map.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.shadow_equivalence_map[path] = shadow<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>self.shadow_equivalence_map[path] = None<tab>shadow_file = self.shadow_equivalence_map.get(path)<tab>return shadow_file if shadow_file else path",0,"if self . fscache . samefile ( path , source ) :",if source == path :,0.011348924,4.222794014,0.257142857
"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab>if type(x) in (type([]), type(())):<tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab>if x1:<tab><tab><tab><tab>kids[key] = x1<tab><tab><IF-STMT><tab><tab><tab>if hasattr(x, ""__iter__""):<tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x",0,"elif isinstance ( x , TVTKBase ) :",elif type ( x ) == type ( [ ] ) :,0.135424922,9.23843021,0.5
"def find_zone_id(domain, client=None):<tab>paginator = client.get_paginator(""list_hosted_zones"")<tab>zones = []<tab>for page in paginator.paginate():<tab><tab>for zone in page[""HostedZones""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not zone[""Config""][""PrivateZone""]:<tab><tab><tab><tab><tab>zones.append((zone[""Name""], zone[""Id""]))<tab>if not zones:<tab><tab>raise ValueError(""Unable to find a Route53 hosted zone for {}"".format(domain))<tab>return zones[0][1]",0,"if domain . endswith ( zone [ ""Name"" ] ) or ( domain + ""."" ) . endswith ( zone [ ""Name"" ] ) :","if zone [ ""Name"" ] == domain :",0.086577924,8.294511504,0.311965812
"def render(self, context):<tab>for condition, nodelist in self.conditions_nodelists:<tab><tab>if condition is not None:  # if / elif clause<tab><tab><tab>try:<tab><tab><tab><tab>match = condition.eval(context)<tab><tab><tab>except VariableDoesNotExist:<tab><tab><tab><tab>match = None<tab><tab>else:  # else clause<tab><tab><tab>match = True<tab><tab><IF-STMT><tab><tab><tab>return nodelist.render(context)<tab>return """"",1,if match :,if match :,0.531170663,1.00E-10,1
"def init_weight(self):<tab>if self.pretrained is not None:<tab><tab>load_entire_model(self, self.pretrained)<tab>else:<tab><tab>for sublayer in self.sublayers():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)<tab><tab><tab>elif isinstance(sublayer, (nn.BatchNorm, nn.SyncBatchNorm)):<tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)",0,"if isinstance ( sublayer , nn . Conv2D ) :","if isinstance ( sublayer , nn . Conv2d ) :",0.604939981,70.71067812,1
"def _next_empty_row(view, pt):<tab>r = utils.row_at(view, pt)<tab>while True:<tab><tab>r += 1<tab><tab>pt = view.text_point(r, 0)<tab><tab>if utils.row_at(view, pt) == utils.last_row(view):<tab><tab><tab>return view.size(), True<tab><tab><IF-STMT><tab><tab><tab>return pt, False",0,if view . line ( pt ) . empty ( ) :,"elif utils . row_at ( view , pt ) == utils . last_row ( view ) :",0.025048295,5.983278753,0.244565217
"def __init__(self, parent, name, max_size=None, description=None):<tab>Field.__init__(self, parent, name, size=0, description=description)<tab>value = 0<tab>addr = self.absolute_address<tab>while max_size is None or self._size < max_size:<tab><tab>byte = parent.stream.readBits(addr, 8, LITTLE_ENDIAN)<tab><tab>value += byte<tab><tab>self._size += 8<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>addr += 8<tab>self.createValue = lambda: value",0,if byte != 0xFF :,if not byte :,0.039851175,12.75073644,0.4
"def xdir(obj, return_values=False):<tab>for attr in dir(obj):<tab><tab>if attr[:2] != ""__"" and attr[-2:] != ""__"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield attr, getattr(obj, attr)<tab><tab><tab>else:<tab><tab><tab><tab>yield attr",1,if return_values :,if return_values :,0.531170663,1.00E-10,1
"def _extract_changes(doc_map, changes, read_time):<tab>deletes = []<tab>adds = []<tab>updates = []<tab>for name, value in changes.items():<tab><tab>if value == ChangeType.REMOVED:<tab><tab><tab>if name in doc_map:<tab><tab><tab><tab>deletes.append(name)<tab><tab><IF-STMT><tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>updates.append(value)<tab><tab>else:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>adds.append(value)<tab>return (deletes, adds, updates)",0,elif name in doc_map :,elif value == ChangeType . READING :,0.025793944,6.567274736,0.265306122
"def endElement(self, name):<tab>if self._is_active is True:<tab><tab><IF-STMT><tab><tab><tab>self._is_active = False<tab><tab><tab>self._tag_level = None<tab><tab><tab>if _callable(self._callback):<tab><tab><tab><tab>self._callback(self._record)<tab><tab><tab>self._record = None<tab><tab>elif self._level == self._tag_level + 1:<tab><tab><tab>if name != ""xref"":<tab><tab><tab><tab>self._record[name] = """".join(self._tag_payload)<tab><tab><tab><tab>self._tag_payload = None<tab><tab><tab><tab>self._tag_feeding = False<tab>self._level -= 1",0,"if name == ""record"" and self . _tag_level == self . _level :",if self . _level == 0 :,0.044916707,15.03428361,0.314814815
"def init_worker(<tab>status_queue: multiprocessing.SimpleQueue,<tab>param_queue: multiprocessing.SimpleQueue,<tab>result_queue: multiprocessing.SimpleQueue,) -> None:<tab>global result<tab>global coverage_run<tab># Make sure the generator is re-seeded, as we have inherited<tab># the seed from the parent process.<tab>random.seed()<tab>result = ChannelingTestResult(result_queue)<tab>if not param_queue.empty():<tab><tab>server_addr = param_queue.get()<tab><tab><IF-STMT><tab><tab><tab>os.environ[""EDGEDB_TEST_CLUSTER_ADDR""] = json.dumps(server_addr)<tab>coverage_run = devmode.CoverageConfig.start_coverage_if_requested()<tab>status_queue.put(True)",1,if server_addr is not None :,if server_addr is not None :,0.75,100,1
"def wait(uuid: str, kind: str, max_retries: int):<tab>""""""Delete an s3 subpath.""""""<tab>from polyaxon import settings<tab>from polyaxon.agents.spawners.spawner import Spawner<tab>spawner = Spawner(namespace=settings.CLIENT_CONFIG.namespace, in_cluster=True)<tab>retry = 1<tab>while retry < max_retries:<tab><tab>try:<tab><tab><tab>k8s_operation = spawner.get(run_uuid=uuid, run_kind=kind)<tab><tab>except:  # noqa<tab><tab><tab>k8s_operation = None<tab><tab><IF-STMT><tab><tab><tab>retry += 1<tab><tab><tab>time.sleep(retry)<tab><tab>else:<tab><tab><tab>return<tab>sys.exit(1)",1,if k8s_operation :,if k8s_operation :,0.531170663,1.00E-10,1
def _get_data_fields():<tab>global supported_kinds<tab>ret = []<tab>for data in supported_kinds:<tab><tab>msg = ifinfmsg.ifinfo.data_map.get(data)<tab><tab>if msg is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret += [msg.nla2name(i[0]) for i in msg.nla_map]<tab><tab><tab>else:<tab><tab><tab><tab>ret += [ifinfmsg.nla2name(i[0]) for i in msg.nla_map]<tab>return ret,0,"if getattr ( msg , ""prefix"" , None ) is not None :","if isinstance ( msg . nla_map , tuple ) :",0.022365231,6.942047568,0.311111111
"def loop_check(self):<tab>in_loop = []<tab># Add the tag for dfs check<tab>for node in self.nodes:<tab><tab>node.dfs_loop_status = ""DFS_UNCHECKED""<tab># Now do the job<tab>for node in self.nodes:<tab><tab># Run the dfs only if the node has not been already done */<tab><tab><IF-STMT><tab><tab><tab>self.dfs_loop_search(node)<tab><tab># If LOOP_INSIDE, must be returned<tab><tab>if node.dfs_loop_status == ""DFS_LOOP_INSIDE"":<tab><tab><tab>in_loop.append(node)<tab># Remove the tag<tab>for node in self.nodes:<tab><tab>del node.dfs_loop_status<tab>return in_loop",1,"if node . dfs_loop_status == ""DFS_UNCHECKED"" :","if node . dfs_loop_status == ""DFS_UNCHECKED"" :",0.75,100,1
"def _find_config(args, app_desc):<tab>path = os.path.join(args.galaxy_root, app_desc.destination)<tab>if not os.path.exists(path):<tab><tab>path = None<tab><tab>for possible_ini_config_rel in app_desc.config_paths:<tab><tab><tab>possible_ini_config = os.path.join(<tab><tab><tab><tab>args.galaxy_root, possible_ini_config_rel<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>path = possible_ini_config<tab>if path is None:<tab><tab>_warn(USING_SAMPLE_MESSAGE % path)<tab><tab>path = os.path.join(args.galaxy_root, app_desc.sample_destination)<tab>return path",1,if os . path . exists ( possible_ini_config ) :,if os . path . exists ( possible_ini_config ) :,0.75,100,1
"def parseArgs(self, argv):<tab>if sys.version_info < (3, 4):<tab><tab># We want these options to work on all versions, emulate them.<tab><tab>if ""-R"" in argv:<tab><tab><tab>argv.remove(""-R"")<tab><tab><tab>self.refleak = True<tab><tab><IF-STMT><tab><tab><tab>argv.remove(""-m"")<tab><tab><tab>self.multiprocess = True<tab>super(NumbaTestProgram, self).parseArgs(argv)<tab>if self.verbosity <= 0:<tab><tab># We aren't interested in informational messages / warnings when<tab><tab># running with '-q'.<tab><tab>self.buffer = True",1,"if ""-m"" in argv :","if ""-m"" in argv :",0.75,100,1
"def filter_custom_selected_callback(indices, old, new):<tab>logger.info(""filter custom callback"")<tab>filter_label.text = ""Please Wait...""<tab>global all_topics, apply_filter<tab>if new != [-1]:<tab><tab>apply_filter = True<tab><tab>selected_topics = [filter_custom_table_source.data[""topics""][x] for x in new]<tab><tab>for i, line in enumerate(all_topics):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_topics[i][2] = ""1""<tab><tab><tab>else:<tab><tab><tab><tab>all_topics[i][2] = ""0""<tab>filter_label.text = """"",0,if line [ 0 ] in selected_topics :,if line in selected_topics :,0.091106998,46.06369751,0.577777778
"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in list(self.unops.items()):<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)",1,"if hasattr ( a , name ) :","if hasattr ( a , name ) :",0.75,100,1
"def reader_matches(self, text):<tab>text = text[1:]<tab>matches = []<tab>for p in self.reader_path:<tab><tab>for k in p.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if k.startswith(text):<tab><tab><tab><tab><tab>matches.append(""#{}"".format(k))<tab>return matches",0,"if isinstance ( k , string_types ) :",if k . startswith ( text ) :,0.037791629,10.81605939,0.314814815
"def load_templates(templates: List[JobTemplateConfig]) -> None:<tab>handlers = {<tab><tab>TemplateSubmitHandler: build_template_func,<tab>}<tab>for handler in handlers:<tab><tab>for name in dir(handler):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>delattr(handler, name)<tab><tab>for template in templates:<tab><tab><tab>setattr(handler, template.name, handlers[handler](template))",1,"if name . startswith ( ""_"" ) :","if name . startswith ( ""_"" ) :",0.75,100,1
"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab>if ""supportsHttpsTrafficOnly"" in conf[""properties""]:<tab><tab><tab>if str(conf[""properties""][""supportsHttpsTrafficOnly""]).lower() == ""true"":<tab><tab><tab><tab>return CheckResult.PASSED<tab><tab><tab>else:<tab><tab><tab><tab>return CheckResult.FAILED<tab># Use default if supportsHttpsTrafficOnly is not set<tab>if ""apiVersion"" in conf:<tab><tab># Default for apiVersion 2019 and newer is supportsHttpsTrafficOnly = True<tab><tab>year = int(conf[""apiVersion""][0:4])<tab><tab><IF-STMT><tab><tab><tab>return CheckResult.FAILED<tab><tab>else:<tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",0,if year < 2019 :,"if year . lower ( ) == ""0"" :",0.047573492,7.495553473,0.6
"def gather_failed_tests(output):<tab>if output.upper() == ""NONE"":<tab><tab>return []<tab>gatherer = GatherFailedTests()<tab>tests_or_tasks = ""tests or tasks""<tab>try:<tab><tab>suite = ExecutionResult(output, include_keywords=False).suite<tab><tab>suite.visit(gatherer)<tab><tab>tests_or_tasks = ""tests"" if not suite.rpa else ""tasks""<tab><tab><IF-STMT><tab><tab><tab>raise DataError(""All %s passed."" % tests_or_tasks)<tab>except:<tab><tab>raise DataError(<tab><tab><tab>""Collecting failed %s from '%s' failed: %s""<tab><tab><tab>% (tests_or_tasks, output, get_error_message())<tab><tab>)<tab>return gatherer.tests",0,if not gatherer . tests :,if not tests_or_tasks :,0.05449376,13.13454947,0.533333333
"def ds_leak():<tab>print(""Testing vlens for dataset r/w"")<tab>print(""-----------------------------"")<tab>with h5py.File(FNAME, ""w"") as f:<tab><tab>ds = f.create_dataset(""dset"", (1000,), dtype=dt)<tab><tab>for idx in range(500):<tab><tab><tab># print idx<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_memory()<tab><tab><tab>ds[...] = data<tab><tab><tab>ds[...]",1,if idx % 100 == 0 :,if idx % 100 == 0 :,0.75,100,1
"def extract_geth_traces(input, batch_size, output, max_workers):<tab>""""""Extracts geth traces from JSON lines file.""""""<tab>with smart_open(input, ""r"") as geth_traces_file:<tab><tab><IF-STMT><tab><tab><tab>traces_iterable = (json.loads(line) for line in geth_traces_file)<tab><tab>else:<tab><tab><tab>traces_iterable = (trace for trace in csv.DictReader(geth_traces_file))<tab><tab>job = ExtractGethTracesJob(<tab><tab><tab>traces_iterable=traces_iterable,<tab><tab><tab>batch_size=batch_size,<tab><tab><tab>max_workers=max_workers,<tab><tab><tab>item_exporter=traces_item_exporter(output),<tab><tab>)<tab><tab>job.run()",0,"if input . endswith ( "".json"" ) :","if sys . version_info < ( 3 , 0 ) :",0.031857826,7.768562846,0.276190476
"def save_project_as():<tab>if PROJECT().last_save_path != None:<tab><tab>open_dir = os.path.dirname(PROJECT().last_save_path)<tab><tab># We don't  want to open hidden cache dir when saving file opened as autosave.<tab><tab><IF-STMT><tab><tab><tab>open_dir = expanduser(""~"")<tab>else:<tab><tab>open_dir = expanduser(""~"")<tab>dialogs.save_project_as_dialog(_save_as_dialog_callback, PROJECT().name, open_dir)",0,if open_dir . startswith ( userfolders . get_cache_dir ( ) ) == True :,"if open_dir == ""."" :",0.015612969,11.17412253,0.373913043
def _skip_to_next_iteration_group(self):<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif self._tgtkey is self._marker:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if not self._tgtkey == self._currkey:<tab><tab><tab><tab>break<tab><tab>newvalue = next(self._iterator)<tab><tab>if self._keyfunc is None:<tab><tab><tab>newkey = newvalue<tab><tab>else:<tab><tab><tab>newkey = self._keyfunc(newvalue)<tab><tab>self._currkey = newkey<tab><tab>self._currvalue = newvalue,0,if self . _currkey is self . _marker :,if self . _tgtkey is None :,0.213373451,26.29588998,0.733333333
"def extractNames(self, names):<tab>offset = names[""offset""].value<tab>for header in names.array(""header""):<tab><tab>key = header[""nameID""].value<tab><tab>foffset = offset + header[""offset""].value<tab><tab>field = names.getFieldByAddress(foffset * 8)<tab><tab>if not field or not isString(field):<tab><tab><tab>continue<tab><tab>value = field.value<tab><tab>if key not in self.NAMEID_TO_ATTR:<tab><tab><tab>continue<tab><tab>key = self.NAMEID_TO_ATTR[key]<tab><tab><IF-STMT><tab><tab><tab># ""Version 1.2"" => ""1.2""<tab><tab><tab>value = value[8:]<tab><tab>setattr(self, key, value)",0,"if key == ""version"" and value . startswith ( u""Version "" ) :","if key == ""version"" :",0.116061646,24.90992302,0.473684211
"def visit_BoolOp(self, node):<tab>for i, value in enumerate(node.values):<tab><tab><IF-STMT><tab><tab><tab>self.visit(value)<tab><tab>else:<tab><tab><tab>self.visit(value)<tab><tab><tab>self.visit(node.op)",0,if i == len ( node . values ) - 1 :,"if isinstance ( value , bool ) :",0.012620947,4.180311383,0.185714286
"def list_sparkline_type_id_values(<tab>date_range_sparkline, correlation_type, type_id, key_id):<tab>sparklines_value = []<tab>for date_day in date_range_sparkline:<tab><tab>nb_seen_this_day = r_serv_metadata.hget(<tab><tab><tab>""{}:{}:{}"".format(correlation_type, type_id, date_day), key_id<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>nb_seen_this_day = 0<tab><tab>sparklines_value.append(int(nb_seen_this_day))<tab>return sparklines_value",1,if nb_seen_this_day is None :,if nb_seen_this_day is None :,0.75,100,1
"def find_nameless_urls(self, conf):<tab>nameless = []<tab>patterns = self.get_patterns(conf)<tab>for u in patterns:<tab><tab>if self.has_patterns(u):<tab><tab><tab>nameless.extend(self.find_nameless_urls(u))<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nameless.append(u)<tab>return nameless",0,if u . name is None :,if u not in nameless :,0.09155306,15.20721822,0.333333333
"def find_zone_id(domain, client=None):<tab>paginator = client.get_paginator(""list_hosted_zones"")<tab>zones = []<tab>for page in paginator.paginate():<tab><tab>for zone in page[""HostedZones""]:<tab><tab><tab>if domain.endswith(zone[""Name""]) or (domain + ""."").endswith(zone[""Name""]):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>zones.append((zone[""Name""], zone[""Id""]))<tab>if not zones:<tab><tab>raise ValueError(""Unable to find a Route53 hosted zone for {}"".format(domain))<tab>return zones[0][1]",0,"if not zone [ ""Config"" ] [ ""PrivateZone"" ] :","if zone [ ""Id"" ] :",0.034337646,16.97232448,0.483333333
"def _lookup_reference(self, reference):<tab>if not reference.startswith(""#/""):<tab><tab>return<tab>path = reference[2:].split(""/"")<tab>pointer = self.swagger<tab>for component in path:<tab><tab><IF-STMT><tab><tab><tab>raise IndexError(<tab><tab><tab><tab>""Can't find location by reference %r at part %r""<tab><tab><tab><tab>% (reference, component)<tab><tab><tab>)<tab><tab>pointer = pointer[component]<tab>self.log.debug(""Found by reference %r: %r"", reference, pointer)<tab>return pointer",1,if component not in pointer :,if component not in pointer :,0.75,100,1
"def read_line_from_file(ff):<tab># assuming that ff contains BV<tab>line = b""""<tab>while True:<tab><tab>vv = ff.read_data(1)[0]<tab><tab>if vv.symbolic:<tab><tab><tab>break<tab><tab>ct = bytes(chr(vv.args[0]), ""utf-8"")<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>line += ct<tab>return line",0,"if ct == b""\n"" :","if ct == b"""" :",0.394778655,59.59429411,1
"def gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker=""sphere""):<tab>""""""Show N random gaussian distributed points using a scatter plot.""""""<tab>import ipyvolume as ipv<tab>rng = np.random.RandomState(seed)  # pylint: disable=no-member<tab>x, y, z = rng.normal(size=(3, N))<tab>if draw:<tab><tab>if color:<tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker, color=color)<tab><tab>else:<tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker)<tab><tab><IF-STMT><tab><tab><tab># ipv.squarelim()<tab><tab><tab>ipv.show()<tab><tab>return mesh<tab>else:<tab><tab>return x, y, z",1,if show :,if show :,0.531170663,1.00E-10,1
"def test_read_only_directory(self):<tab>with _inside_empty_temp_dir():<tab><tab>oldmode = mode = os.stat(tempfile.tempdir).st_mode<tab><tab>mode &= ~(stat.S_IWUSR | stat.S_IWGRP | stat.S_IWOTH)<tab><tab>os.chmod(tempfile.tempdir, mode)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.skipTest(""can't set the directory read-only"")<tab><tab><tab>with self.assertRaises(PermissionError):<tab><tab><tab><tab>self.make_temp()<tab><tab><tab>self.assertEqual(os.listdir(tempfile.tempdir), [])<tab><tab>finally:<tab><tab><tab>os.chmod(tempfile.tempdir, oldmode)",0,"if os . access ( tempfile . tempdir , os . W_OK ) :",if os . path . isdir ( tempfile . tempdir ) :,0.232714156,25.13906893,0.333333333
"def is_checked_sls_template(template):<tab>if template.__contains__(""provider""):<tab><tab># Case provider is a dictionary<tab><tab>if isinstance(template[""provider""], dict_node):<tab><tab><tab>if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab># Case provider is direct provider name<tab><tab><IF-STMT><tab><tab><tab>if template[""provider""] not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",0,"if isinstance ( template [ ""provider"" ] , str_node ) :","elif isinstance ( template [ ""provider"" ] , str ) :",0.353997721,67.82635236,0.488888889
"def detail(self, req):<tab>resp_backup = super(BackupsController, self).detail(req)<tab>context = req.environ[""cinder.context""]<tab>req_version = req.api_version_request<tab>if req_version.matches(mv.BACKUP_PROJECT):<tab><tab><IF-STMT><tab><tab><tab>for bak in resp_backup[""backups""]:<tab><tab><tab><tab>self._add_backup_project_attribute(req, bak)<tab>if req_version.matches(mv.BACKUP_PROJECT_USER_ID):<tab><tab>if context.authorize(policy.BACKUP_ATTRIBUTES_POLICY, fatal=False):<tab><tab><tab>for bak in resp_backup[""backups""]:<tab><tab><tab><tab>self._add_backup_user_attribute(req, bak)<tab>return resp_backup",1,"if context . authorize ( policy . BACKUP_ATTRIBUTES_POLICY , fatal = False ) :","if context . authorize ( policy . BACKUP_ATTRIBUTES_POLICY , fatal = False ) :",1,100,1
"def genConditional(self):<tab>for i in range(3):<tab><tab>x = 0<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>x = 1<tab><tab>finally:<tab><tab><tab>for j in range(x, x + 2):<tab><tab><tab><tab>yield j",0,if i == 2 :,if self . condition [ i ] :,0.02800146,7.267884212,0.314814815
def _cacheAffectedBones(self):<tab>self._affectedBones = []<tab>for f_idx in range(self.nFrames):<tab><tab>frameData = self.getAtFramePos(f_idx)<tab><tab>self._affectedBones.append([])<tab><tab>for b_idx in range(self.nBones):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._affectedBones[f_idx].append(b_idx),0,if not isRest ( frameData [ b_idx ] ) :,if frameData [ b_idx ] [ 0 ] == b_idx :,0.203330247,32.37722713,0.322222222
"def load_metrics(self, filename, config_dict):<tab># we don't try to validate metrics keys<tab>if ""metrics"" in config_dict:<tab><tab>metrics = config_dict[""metrics""]<tab><tab><IF-STMT><tab><tab><tab>error(""c['metrics'] must be a dictionary"")<tab><tab>else:<tab><tab><tab>self.metrics = metrics",1,"if not isinstance ( metrics , dict ) :","if not isinstance ( metrics , dict ) :",0.75,100,1
"def _decode_list_response(response: Iterable[Any], decode: bool) -> Any:<tab>if decode is True:<tab><tab>new_response = []<tab><tab>for val in response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = val.decode(""utf-8"")<tab><tab><tab>new_response.append(val)<tab><tab>return new_response<tab>return response",1,"if isinstance ( val , bytes ) :","if isinstance ( val , bytes ) :",0.75,100,1
"def _np_convert_in_place(d):<tab>""""""Convert any jax devicearray leaves to numpy arrays in place.""""""<tab>if isinstance(d, dict):<tab><tab>for k, v in d.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d[k] = np.array(v)<tab><tab><tab>elif isinstance(v, dict):<tab><tab><tab><tab>_np_convert_in_place(v)<tab>elif isinstance(d, jax.xla.DeviceArray):<tab><tab>return np.array(d)<tab>return d",0,"if isinstance ( v , jax . xla . DeviceArray ) :","if isinstance ( v , np . ndarray ) :",0.234349893,38.24602283,0.435897436
"def reader():<tab>with tarfile.open(filename, mode=""r"") as f:<tab><tab>names = (each_item.name for each_item in f if sub_name in each_item.name)<tab><tab>while True:<tab><tab><tab>for name in names:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name), encoding=""bytes"")<tab><tab><tab><tab>for item in read_batch(batch):<tab><tab><tab><tab><tab>yield item<tab><tab><tab>if not cycle:<tab><tab><tab><tab>break",0,if six . PY2 :,"if isinstance ( name , str ) :",0.026407399,6.567274736,0.26984127
"def _Determine_Do(self):<tab>self.applicable = 1<tab>method = ""moz-src""<tab>method_arg = None<tab>for opt, optarg in self.chosenOptions:<tab><tab>if opt == ""--moz-src"":<tab><tab><tab>method = ""moz-src""<tab><tab><IF-STMT><tab><tab><tab>method = ""moz-objdir""<tab><tab><tab>method_arg = optarg<tab>if method == ""moz-src"":<tab><tab>self.value = self._get_mozilla_objdir()<tab>elif method == ""moz-objdir"":<tab><tab>self.value = self._use_mozilla_objdir(method_arg)<tab>else:<tab><tab>raise black.configure.ConfigureError(""bogus method: %r"" % method)<tab>self.determined = 1",1,"elif opt == ""--moz-objdir"" :","elif opt == ""--moz-objdir"" :",1,100,1
"def close_all(map=None, ignore_all=False):<tab>if map is None:  # pragma: no cover<tab><tab>map = socket_map<tab>for x in list(map.values()):  # list() FBO py3<tab><tab>try:<tab><tab><tab>x.close()<tab><tab>except OSError as x:<tab><tab><tab>if x.args[0] == EBADF:<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>except _reraised_exceptions:<tab><tab><tab>raise<tab><tab>except:<tab><tab><tab>if not ignore_all:<tab><tab><tab><tab>raise<tab>map.clear()",1,elif not ignore_all :,elif not ignore_all :,0.736435402,100,1
"def _attributes_to_xml(self, xml_element, prefix_root, debug_context=None):<tab>del debug_context  # Unused.<tab>for attribute_name, attribute in six.iteritems(self._attributes):<tab><tab>attribute_value = attribute.to_xml_string(prefix_root)<tab><tab><IF-STMT><tab><tab><tab>xml_element.set(attribute_name, self.full_identifier)<tab><tab>elif attribute_value is None:<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>xml_element.set(attribute_name, attribute_value)",0,if attribute_name == self . _spec . identifier and attribute_value is None :,if attribute_value is None :,0.091061646,16.75947808,0.260504202
"def parse(s):<tab>""""""Parse the output below to create a new StopWatch.""""""<tab>stopwatch = StopWatch()<tab>for line in s.splitlines():<tab><tab>if line.strip():<tab><tab><tab>parts = line.split(None)<tab><tab><tab>name = parts[0]<tab><tab><tab><IF-STMT>  # ie not the header line<tab><tab><tab><tab>rest = (float(v) for v in parts[2:])<tab><tab><tab><tab>stopwatch.times[parts[0]].merge(Stat.build(*rest))<tab>return stopwatch",0,"if name != ""%"" :","if name . startswith ( ""stopwatch"" ) :",0.04979442,10.55267032,0.727272727
"def reverse_adjust_line_according_to_hunks(self, hunks, line):<tab>for hunk in reversed(hunks):<tab><tab>head_start = hunk.head_start<tab><tab>saved_start = hunk.saved_start<tab><tab>if hunk.saved_length == 0:<tab><tab><tab>saved_start += 1<tab><tab><IF-STMT><tab><tab><tab>saved_start -= 1<tab><tab>head_end = head_start + hunk.head_length<tab><tab>saved_end = saved_start + hunk.saved_length<tab><tab>if saved_end <= line:<tab><tab><tab>return head_end + line - saved_end<tab><tab>elif saved_start <= line:<tab><tab><tab>return head_start<tab># fails to find matching<tab>return line",0,elif hunk . head_length == 0 :,elif hunk . saved_length > 0 :,0.152783404,23.34165361,1
"def add(self, *args):<tab>self._digest = None<tab>llt = Hasher.list_like_types<tab>for arg in args:<tab><tab>t = type(arg)<tab><tab><IF-STMT><tab><tab><tab>self._hasher.update(bytes(f""{llt[t]} {len(arg)}"", ""utf8""))<tab><tab><tab>self.add(*arg)<tab><tab>else:<tab><tab><tab>self._hasher.update(bytes(str(arg), ""utf8""))",1,if t in llt :,if t in llt :,0.75,100,1
"def filter(self, qs, value):<tab>if value:<tab><tab>if value.start is not None and value.stop is not None:<tab><tab><tab>value = (value.start, value.stop)<tab><tab><IF-STMT><tab><tab><tab>self.lookup_expr = ""startswith""<tab><tab><tab>value = value.start<tab><tab>elif value.stop is not None:<tab><tab><tab>self.lookup_expr = ""endswith""<tab><tab><tab>value = value.stop<tab>return super().filter(qs, value)",1,elif value . start is not None :,elif value . start is not None :,0.75,100,1
"def _getResourceData(self, jid, dataname):<tab>""""""Return specific jid's resource representation in internal format. Used internally.""""""<tab>if jid.find(""/"") + 1:<tab><tab>jid, resource = jid.split(""/"", 1)<tab><tab>if self._data[jid][""resources""].has_key(resource):<tab><tab><tab>return self._data[jid][""resources""][resource][dataname]<tab>elif self._data[jid][""resources""].keys():<tab><tab>lastpri = -129<tab><tab>for r in self._data[jid][""resources""].keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resource, lastpri = r, int(self._data[jid][""resources""][r][""priority""])<tab><tab>return self._data[jid][""resources""][resource][dataname]",0,"if int ( self . _data [ jid ] [ ""resources"" ] [ r ] [ ""priority"" ] ) > lastpri :",if r != lastpri :,0.007138138,0.582956554,0.273469388
"def OnGetText(self, node_id):<tab>try:<tab><tab>ea, rows = self[node_id]<tab><tab><IF-STMT><tab><tab><tab>colour = self.colours[ea]<tab><tab>else:<tab><tab><tab>colour = 0xFFFFFF<tab><tab>ret = []<tab><tab>for row in rows:<tab><tab><tab>ret.append(row[2])<tab><tab>label = ""\n"".join(ret)<tab><tab>return (label, colour)<tab>except:<tab><tab>print(""GraphViewer.OnGetText:"", sys.exc_info()[1])<tab><tab>return (""ERROR"", 0x000000)",0,if ea in self . colours :,ifea in self . colours :,0.298071877,64.31870218,0.114285714
"def _apply_scales(array, scales, dtype):<tab>""""""Apply scales to the array.""""""<tab>new_array = np.empty(array.shape, dtype)<tab>for i in array.dtype.names:<tab><tab>try:<tab><tab><tab>new_array[i] = array[i] * scales[i]<tab><tab>except TypeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_array[i] = array[i]<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab>return new_array",0,if np . all ( scales [ i ] == 1 ) :,if np . isscalar ( array [ i ] ) :,0.118722078,20.90152065,0.437037037
"def run(self):<tab>self.running = True<tab>while self.running:<tab><tab>errCode, bytes, key, overlapped = GetQueuedCompletionStatus(<tab><tab><tab>self.io_req_port, INFINITE<tab><tab>)<tab><tab>if key == ISAPI_SHUTDOWN and overlapped is None:<tab><tab><tab>break<tab><tab># Let the parent extension handle the command.<tab><tab>dispatcher = self.extension.dispatch_map.get(key)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Bad request '%s'"" % (key,))<tab><tab>dispatcher(errCode, bytes, key, overlapped)",1,if dispatcher is None :,if dispatcher is None :,0.75,100,1
"def on_task_filter(self, task, config):<tab>if task.options.learn:<tab><tab>log.info(""Plugin limit_new is disabled with --learn"")<tab><tab>return<tab>amount = config<tab>for index, entry in enumerate(task.accepted):<tab><tab><IF-STMT><tab><tab><tab>log.verbose(""Allowed %s (%s)"" % (entry[""title""], entry[""url""]))<tab><tab>else:<tab><tab><tab>entry.reject(""limit exceeded"")<tab><tab><tab># Also save this in backlog so that it can be accepted next time.<tab><tab><tab>plugin.get(""backlog"", self).add_backlog(task, entry)<tab>log.debug(<tab><tab>""Rejected: %s Allowed: %s""<tab><tab>% (len(task.accepted[amount:]), len(task.accepted[:amount]))<tab>)",0,if index < amount :,if len ( entry ) > amount :,0.04979442,12.22307556,0.314814815
"def initialize_pairs(self):<tab># White on Black is fixed as color_pair 0<tab>self._defined_pairs[""WHITE_BLACK""] = (0, curses.COLOR_WHITE, curses.COLOR_BLACK)<tab>for cp in self.__class__._colors_to_define:<tab><tab><IF-STMT><tab><tab><tab># silently protect the user from breaking things.<tab><tab><tab>continue<tab><tab>self.initalize_pair(cp[0], cp[1], cp[2])",0,"if cp [ 0 ] == ""WHITE_BLACK"" :",if len ( cp ) < 3 :,0.019345088,3.890218086,0.314814815
"def get_story_task_body(payload: Dict[str, Any], action: str) -> str:<tab>primary_action = get_action_with_primary_id(payload)<tab>kwargs = {<tab><tab>""task_description"": primary_action[""description""],<tab><tab>""action"": action,<tab>}<tab>for a in payload[""actions""]:<tab><tab><IF-STMT><tab><tab><tab>kwargs[""name_template""] = STORY_NAME_TEMPLATE.format(<tab><tab><tab><tab>name=a[""name""],<tab><tab><tab><tab>app_url=a[""app_url""],<tab><tab><tab>)<tab>return STORY_TASK_TEMPLATE.format(**kwargs)",0,"if a [ ""entity_type"" ] == ""story"" :","if ""name"" in a and ""app_url"" in a :",0.018096169,4.419687163,0.32
"def _key_remap(key, keys, item):<tab>elements_list = []<tab>for r_item in item.get(key, []):<tab><tab>element = {}<tab><tab>for r_outkey, r_inkey in six.iteritems(keys):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>element[r_outkey] = r_item.get(r_inkey)<tab><tab>elements_list.append(element)<tab>return elements_list",0,if r_inkey in r_item :,if r_inkey is not None :,0.182429006,32.26013519,0.277777778
"def fix_identities(self, uniq=None):<tab>""""""Make pattern-tree tips point to same object if they are equal.""""""<tab>if not hasattr(self, ""children""):<tab><tab>return self<tab>uniq = list(set(self.flat())) if uniq is None else uniq<tab>for i, c in enumerate(self.children):<tab><tab><IF-STMT><tab><tab><tab>assert c in uniq<tab><tab><tab>self.children[i] = uniq[uniq.index(c)]<tab><tab>else:<tab><tab><tab>c.fix_identities(uniq)",0,"if not hasattr ( c , ""children"" ) :","if isinstance ( c , Leaf ) :",0.080387257,18.59400212,0.285714286
"def _apply_main_args(main_args, exec_args):<tab>i = 0<tab>while i < len(exec_args):<tab><tab><IF-STMT><tab><tab><tab>exec_args[i : i + 1] = main_args<tab><tab><tab>i += len(main_args)<tab><tab>i += 1",0,"if exec_args [ i ] == ""${main_args}"" :",if exec_args [ i ] == main_args [ i + 1 ] :,0.340227924,53.98995685,0.641666667
"def _clean_text(self, text):<tab>""""""Performs invalid character removal and whitespace cleanup on text.""""""<tab>output = []<tab>char_idx = []<tab>for i, char in enumerate(text):<tab><tab>cp = ord(char)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if _is_whitespace(char):<tab><tab><tab>output.append("" "")<tab><tab><tab>char_idx.append(i)<tab><tab>else:<tab><tab><tab>output.append(char)<tab><tab><tab>char_idx.append(i)<tab>return """".join(output), char_idx",0,if cp == 0 or cp == 0xFFFD or _is_control ( char ) :,if cp == 0 or cp == 0xFFFD or cp == 0xFFFD or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xDFFF or cp == 0xD,0.563866056,12.83642863,0.399969109
"def upgrade_state_dict_named(self, state_dict, name):<tab>prefix = name + ""."" if name != """" else """"<tab>for k, v in state_dict.items():<tab><tab>if k.endswith(prefix + ""weight""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state_dict[k] = v.squeeze(1)",0,if v . dim ( ) == 3 and v . size ( 1 ) == 1 :,"if isinstance ( v , np . ndarray ) :",0.008277921,2.41596536,0.165289256
"def fetch_with_retry(self):<tab>for i in range(self.max_retries):<tab><tab>try:<tab><tab><tab>self.is_truncated, self.next_marker = self._fetch()<tab><tab>except ServerError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>if i == self.max_retries - 1:<tab><tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>return",0,if e . status // 100 != 5 :,"if e . response [ ""Error"" ] [ ""Code"" ] != ""AccessDeniedException"" :",0.057462392,9.379601158,0.412698413
"def hg_hook(ui, repo, node=None, **kwargs):<tab>""""""Run pylama after mercurial commit.""""""<tab>seen = set()<tab>paths = []<tab>if len(repo):<tab><tab>for rev in range(repo[node], len(repo)):<tab><tab><tab>for file_ in repo[rev].files():<tab><tab><tab><tab>file_ = op.join(repo.root, file_)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>seen.add(file_)<tab><tab><tab><tab>paths.append(file_)<tab>options = parse_options()<tab>setup_logger(options)<tab>if paths:<tab><tab>process_paths(options, candidates=paths)",0,if file_ in seen or not op . exists ( file_ ) :,if file_ in seen :,0.20469801,17.74488851,0.46875
"def test_playlist_items(self):<tab>playlists = self.spotify.user_playlists(self.username, limit=5)<tab>self.assertTrue(""items"" in playlists)<tab>for playlist in playlists[""items""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pid = playlist[""id""]<tab><tab>results = self.spotify.playlist_items(pid)<tab><tab>self.assertEqual(len(results[""items""]), 0)",0,"if playlist [ ""uri"" ] != self . new_playlist_uri :","if ""id"" not in playlist :",0.014786244,2.680951115,0.320512821
"def update_execute_option_setting(<tab>css_selector_of_option_status, css_selector_of_option):<tab>retry = 3<tab>check_status = self.driver.find_element_by_css_selector(<tab><tab>css_selector_of_option_status<tab>)<tab>if ""visibility-hidden"" not in check_status.get_attribute(""class""):<tab><tab>while retry > 0:<tab><tab><tab>self.find_by_css_selector(css_selector_of_option).click()<tab><tab><tab>time.sleep(0.2)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>retry -= 1",1,"if ""visibility-hidden"" in check_status . get_attribute ( ""class"" ) :","if ""visibility-hidden"" in check_status . get_attribute ( ""class"" ) :",0.75,100,1
"def _validate_config(self):<tab># convert comma separated strings to lists (ConfigParser)<tab>for item in [""to"", ""cc"", ""bcc""]:<tab><tab>if item in self.app.config.keys(self._meta.config_section):<tab><tab><tab>value = self.app.config.get(self._meta.config_section, item)<tab><tab><tab># convert a comma-separated string to a list<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value_list = value.split("","")<tab><tab><tab><tab># clean up extra space if they had it inbetween commas<tab><tab><tab><tab>value_list = [x.strip() for x in value_list]<tab><tab><tab><tab># set the new extensions value in the config<tab><tab><tab><tab>self.app.config.set(self._meta.config_section, item, value_list)",0,if type ( value ) is str :,"if "","" in value :",0.019907918,7.492442692,0.392857143
"def cell_func(combo, render, model, iter_, *args):<tab>value = model.get_value(iter_)<tab>if value is None:<tab><tab>text = escape(_(""System Default""))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>value = u""en""<tab><tab>text = ""%s <span weight='light'>(%s)</span>"" % (<tab><tab><tab>escape(value),<tab><tab><tab>escape(iso639.translate(value.split(""_"", 1)[0])),<tab><tab>)<tab>render.set_property(""markup"", text)",0,"if value == u""C"" :","if value . startswith ( u""en"" ) :",0.11229442,11.73117516,0.727272727
"def _get_all_tasks():<tab>proc = Popen([""yarn"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab>if ""Commands:"" in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield line.split("" "")[-1]",0,"if should_yield and ""- "" in line :",if should_yield :,0.030705693,1.00E-10,0.345454545
"def _staged_model_references(self, load_relationships=False):<tab>for name, field in self._fields.items():<tab><tab>if isinstance(field, BaseRelationship):<tab><tab><tab>try:<tab><tab><tab><tab>if load_relationships:<tab><tab><tab><tab><tab>value = getattr(self, name)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>value = self.data_store.get(name, (""staged"", ""committed""))<tab><tab><tab>except (AttributeError, KeyError, PathResolutionError):<tab><tab><tab><tab>continue<tab><tab><tab>if value is None:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = [value]<tab><tab><tab>for related in value:<tab><tab><tab><tab>related_name = field.related_name<tab><tab><tab><tab>yield related, related_name",0,"if not isinstance ( value , ModelCollection ) :","if not isinstance ( value , list ) :",0.581882088,66.06328636,0.714285714
"def get_all_fix_names(fixer_pkg, remove_prefix=True):<tab>""""""Return a sorted list of all available fix names in the given package.""""""<tab>pkg = __import__(fixer_pkg, [], [], [""*""])<tab>fixer_dir = os.path.dirname(pkg.__file__)<tab>fix_names = []<tab>for name in sorted(os.listdir(fixer_dir)):<tab><tab>if name.startswith(""fix_"") and name.endswith("".py""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>name = name[4:]<tab><tab><tab>fix_names.append(name[:-3])<tab>return fix_names",1,if remove_prefix :,if remove_prefix :,0.531170663,1.00E-10,1
"def extract_info_to_dest(self, info, dest):<tab>""""""Extracts the given info to a directory and checks the file size.""""""<tab>self.zip_file.extract(info, dest)<tab>dest = os.path.join(dest, info.filename)<tab>if not os.path.isdir(dest):<tab><tab># Directories consistently report their size incorrectly.<tab><tab>size = os.stat(dest)[stat.ST_SIZE]<tab><tab><IF-STMT><tab><tab><tab>log.error(<tab><tab><tab><tab>""Extraction error, uncompressed size: %s, %s not %s""<tab><tab><tab><tab>% (self.source, size, info.file_size)<tab><tab><tab>)<tab><tab><tab>raise forms.ValidationError(gettext(""Invalid archive.""))",1,if size != info . file_size :,if size != info . file_size :,0.75,100,1
"def _close_brackets(self, fragment):<tab># If there any unclosed brackets in the text we try to close them<tab># and we return part with closing brackets if they are ""closable""<tab>stack = []<tab>for char in fragment:<tab><tab><IF-STMT><tab><tab><tab>stack.append(char)<tab><tab>elif char in self._PARENS.values():<tab><tab><tab>if stack and self._PARENS[stack[-1]] == char:<tab><tab><tab><tab>stack.pop()<tab><tab><tab>else:<tab><tab><tab><tab>return """"<tab>return """".join(self._PARENS[paren] for paren in reversed(stack))",0,if char in self . _PARENS . keys ( ) :,if char in self . _PARENS . values ( ) :,0.602662057,73.48889201,0.714285714
"def __call__(self, input_tensors, shape):<tab>if self.order in ""KA"":<tab><tab>if any(t.order == TensorOrder.C_ORDER for t in input_tensors):<tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>else:<tab><tab><IF-STMT><tab><tab><tab>order = TensorOrder.C_ORDER<tab><tab>else:<tab><tab><tab>order = TensorOrder.F_ORDER<tab>return self.new_tensor(input_tensors, shape=shape, dtype=self.dtype, order=order)",0,"if self . order == ""C"" :",if self . order == TensorOrder . C_ORDER for t in input_tensors :,0.301414645,28.43329182,0.46875
"def __iter__(self):<tab>iteration = self.start_iter<tab>while iteration <= self.num_iterations:<tab><tab># if the underlying sampler has a set_epoch method, like<tab><tab># DistributedSampler, used for making each process see<tab><tab># a different split of the dataset, then set it<tab><tab><IF-STMT><tab><tab><tab>self.batch_sampler.sampler.set_epoch(iteration)<tab><tab>for batch in self.batch_sampler:<tab><tab><tab>iteration += 1<tab><tab><tab>if iteration > self.num_iterations:<tab><tab><tab><tab>break<tab><tab><tab>yield batch",0,"if hasattr ( self . batch_sampler . sampler , ""set_epoch"" ) :","if hasattr ( self . batch_sampler , ""set_epoch"" ) :",0.362928333,83.08628713,0.788235294
def all_pairs_shortest_path(adjacency_matrix):<tab>new_array = copy.deepcopy(adjacency_matrix)<tab>for k in range(len(new_array)):<tab><tab>for i in range(len(new_array)):<tab><tab><tab>for j in range(len(new_array)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>new_array[i][j] = new_array[i][k] + new_array[k][j]<tab>return new_array,0,if new_array [ i ] [ j ] > new_array [ i ] [ k ] + new_array [ k ] [ j ] :,if new_array [ i ] [ j ] != new_array [ i ] [ k ] :,0.541794554,52.82164968,0.856140351
"def cancel_pp(self, nzo_id):<tab>""""""Change the status, so that the PP is canceled""""""<tab>for nzo in self.history_queue:<tab><tab>if nzo.nzo_id == nzo_id:<tab><tab><tab>nzo.abort_direct_unpacker()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nzo.pp_active = False<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab># Try to kill any external running process<tab><tab><tab><tab><tab>self.external_process.kill()<tab><tab><tab><tab><tab>logging.info(<tab><tab><tab><tab><tab><tab>""Killed external process %s"", self.external_process.args[0]<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab><tab>return True<tab>return None",1,if nzo . pp_active :,if nzo . pp_active :,0.75,100,1
"def cvPreprocess():<tab>import cv2<tab>imgarr_orig = []<tab>image_ext_list = ["".jpg"", "".png"", "".JPEG"", "".jpeg"", "".PNG"", "".JPG""]<tab>for file in onlyfiles:<tab><tab>fimg = imgroot + file<tab><tab>if any([x in image_ext_list for x in fimg]):<tab><tab><tab>print(fimg + "" is not an image file"")<tab><tab><tab>continue<tab><tab>img1 = cv2.imread(fimg)<tab><tab><IF-STMT><tab><tab><tab>print(""ERROR opening "", fimg)<tab><tab><tab>continue<tab><tab>img1 = cv2.resize(img1, (896, 896))<tab><tab>imgarr_orig.append(img1)<tab>return imgarr_orig",1,if img1 is None :,if img1 is None :,0.75,100,1
"def substituteargs(self, pattern, replacement, old):<tab>new = []<tab>for k in range(len(replacement)):<tab><tab>item = replacement[k]<tab><tab>newitem = [item[0], item[1], item[2]]<tab><tab>for i in range(3):<tab><tab><tab>if item[i] == ""*"":<tab><tab><tab><tab>newitem[i] = old[k][i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>index = int(item[i][1:]) - 1<tab><tab><tab><tab>newitem[i] = old[index][i]<tab><tab>new.append(tuple(newitem))<tab>##self.report(""old: %r"", old)<tab>##self.report(""new: %r"", new)<tab>return new",0,"elif item [ i ] [ : 1 ] == ""$"" :",elif item [ i ] == pattern :,0.50274704,30.64839278,0.666666667
"def process(self, profile):<tab>contributors = self.createContributors(profile)<tab>for contributor in contributors:<tab><tab><IF-STMT><tab><tab><tab>reasons = self.createExecSqlNodeReason(contributor, profile)<tab><tab>else:<tab><tab><tab>reasons = self.createExecNodeReason(contributor, profile)<tab><tab>contributor.reason = reasons<tab>return contributors",0,"if contributor . type == ""SQLOperator"" :",if contributor . is_sql :,0.094532291,17.11271706,0.722222222
"def showImage(filename):<tab>osName = platform.system()<tab>if osName == ""Windows"":<tab><tab>subprocess.Popen([filename], shell=True)<tab>elif osName == ""Linux"":<tab><tab># TODO: should I leave it to user's config ?<tab><tab>LINUX_DISPLAY_COMMAND = (""xdg-open"", ""display"", ""gvfs-open"", ""shotwell"")<tab><tab>commands = list(filter(HasCommand, LINUX_DISPLAY_COMMAND))<tab><tab><IF-STMT>  # command found<tab><tab><tab>subprocess.Popen([commands[0], filename])<tab><tab>else:<tab><tab><tab>raise<tab>elif osName == ""Darwin"":  # by @Naville<tab><tab>subprocess.Popen([""open"", filename])<tab>else:<tab><tab>raise Exception(""other system"")",1,if commands :,if commands :,0.531170663,1.00E-10,1
"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab>if not dir:<tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab><IF-STMT><tab><tab><tab>if not dir in self.library_dirs:<tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab>elif fatal:<tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",1,if os . path . isdir ( dir ) :,if os . path . isdir ( dir ) :,0.75,100,1
"def add(self, state):<tab>if state.key in self:<tab><tab><IF-STMT><tab><tab><tab>raise sa_exc.InvalidRequestError(<tab><tab><tab><tab>""Can't attach instance ""<tab><tab><tab><tab>""%s; another instance with key %s is already ""<tab><tab><tab><tab>""present in this session."" % (orm_util.state_str(state), state.key)<tab><tab><tab>)<tab><tab>return False<tab>else:<tab><tab>self._dict[state.key] = state.obj()<tab><tab>self._manage_incoming_state(state)<tab><tab>return True",0,if attributes . instance_state ( self . _dict [ state . key ] ) is not state :,if state . obj ( ) in self . _dict :,0.038274715,13.53154933,0.186956522
"def request(self, stream=None, tty=None, demux=None):<tab>assert stream is not None and tty is not None and demux is not None<tab>with APIClient(base_url=self.address, version=DEFAULT_DOCKER_API_VERSION) as client:<tab><tab><IF-STMT><tab><tab><tab>url = client._url(""/tty"")<tab><tab>else:<tab><tab><tab>url = client._url(""/no-tty"")<tab><tab>resp = client._post(url, stream=True)<tab><tab>return client._read_from_socket(resp, stream=stream, tty=tty, demux=demux)",1,if tty :,if tty :,0.531170663,1.00E-10,1
"def select(model, path, iter_, paths_):<tab>(paths, first) = paths_<tab>value = model.get_value(iter_)<tab>if value is None:<tab><tab>return not bool(paths)<tab>value = normalize_path(value)<tab>if value in paths:<tab><tab>self.get_child().get_selection().select_path(path)<tab><tab>paths.remove(value)<tab><tab><IF-STMT><tab><tab><tab>self.get_child().set_cursor(path)<tab><tab><tab># copy treepath, gets invalid after the callback<tab><tab><tab>first.append(path.copy())<tab>else:<tab><tab>for fpath in paths:<tab><tab><tab>if fpath.startswith(value):<tab><tab><tab><tab>self.get_child().expand_row(path, False)<tab>return not bool(paths)",0,if not first :,if first :,0.096488528,1.00E-10,0.416666667
"def _validate(self, qobj):<tab>for experiment in qobj.experiments:<tab><tab><IF-STMT><tab><tab><tab>logger.warning(<tab><tab><tab><tab>""no measurements in circuit '%s', ""<tab><tab><tab><tab>""classical register will remain all zeros."",<tab><tab><tab><tab>experiment.header.name,<tab><tab><tab>)",0,"if ""measure"" not in [ op . name for op in experiment . instructions ] :",if experiment . measurements and experiment . measurements [ 0 ] == 0 :,0.10128622,5.885822266,0.154761905
"def exitval_from_opts(options, project):<tab>exit_value_from = options.get(""--exit-code-from"")<tab>if exit_value_from:<tab><tab>if not options.get(""--abort-on-container-exit""):<tab><tab><tab>log.warning(""using --exit-code-from implies --abort-on-container-exit"")<tab><tab><tab>options[""--abort-on-container-exit""] = True<tab><tab><IF-STMT><tab><tab><tab>log.error(<tab><tab><tab><tab>'No service named ""%s"" was found in your compose file.', exit_value_from<tab><tab><tab>)<tab><tab><tab>sys.exit(2)<tab>return exit_value_from",0,if exit_value_from not in [ s . name for s in project . get_services ( ) ] :,if exit_value_from not in project . services :,0.160461198,27.62958475,0.387205387
"def __call__(self, tokens, reader):<tab>first_return = False<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>reader.context.current_function.exit_count = 1<tab><tab><tab>first_return = True<tab><tab>if token == ""return"":<tab><tab><tab>if first_return:<tab><tab><tab><tab>first_return = False<tab><tab><tab>else:<tab><tab><tab><tab>reader.context.current_function.exit_count += 1<tab><tab>yield token",0,"if not hasattr ( reader . context . current_function , ""exit_count"" ) :","if token == ""return"" :",0.0089099,1.974639277,0.263157895
"def _register_builtin_handlers(self, events):<tab>for spec in handlers.BUILTIN_HANDLERS:<tab><tab>if len(spec) == 2:<tab><tab><tab>event_name, handler = spec<tab><tab><tab>self.register(event_name, handler)<tab><tab>else:<tab><tab><tab>event_name, handler, register_type = spec<tab><tab><tab>if register_type is handlers.REGISTER_FIRST:<tab><tab><tab><tab>self._events.register_first(event_name, handler)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._events.register_last(event_name, handler)",0,elif register_type is handlers . REGISTER_LAST :,elif register_type is handlers .REGISTER_LAST :,0.472380694,100,1
"def test_sql(self):<tab>with self.get_temp() as temp:<tab><tab>railroad = to_railroad(simpleSQL)<tab><tab>assert len(railroad) == 7<tab><tab>temp.write(railroad_to_html(railroad))<tab><tab><IF-STMT><tab><tab><tab>print(""sql: "" + temp.name)",1,if self . railroad_debug ( ) :,if self . railroad_debug ( ) :,0.75,100,1
"def resources_to_link(self, resources):<tab>if isinstance(self.Bucket, dict) and ""Ref"" in self.Bucket:<tab><tab>bucket_id = self.Bucket[""Ref""]<tab><tab>if not isinstance(bucket_id, string_types):<tab><tab><tab>raise InvalidEventException(<tab><tab><tab><tab>self.relative_id, ""'Ref' value in S3 events is not a valid string.""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return {""bucket"": resources[bucket_id], ""bucket_id"": bucket_id}<tab>raise InvalidEventException(<tab><tab>self.relative_id, ""S3 events must reference an S3 bucket in the same template.""<tab>)",1,if bucket_id in resources :,if bucket_id in resources :,0.75,100,1
"def list_target_unit_files(self, *modules):  # -> [ (unit,enabled) ]<tab>""""""show all the target units and the enabled status""""""<tab>result = {}<tab>enabled = {}<tab>for unit in _all_common_targets:<tab><tab>result[unit] = None<tab><tab>enabled[unit] = ""static""<tab><tab>if unit in _all_common_enabled:<tab><tab><tab>enabled[unit] = ""enabled""<tab><tab><IF-STMT><tab><tab><tab>enabled[unit] = ""enabled""<tab>return [(unit, enabled[unit]) for unit in sorted(result)]",0,if unit in _all_common_disabled :,elif unit in _all_common_enabled :,0.183575651,66.06328636,0.6
"def teardown_network_port(self):<tab>""""""tearDown for Network and Port table""""""<tab>networks = self.quantum.get_all_networks(""t1"")<tab>for net in networks:<tab><tab>netid = net[""net-id""]<tab><tab>name = net[""net-name""]<tab><tab><IF-STMT><tab><tab><tab>ports = self.quantum.get_all_ports(netid)<tab><tab><tab>for por in ports:<tab><tab><tab><tab>self.quantum.delete_port(netid, por[""port-id""])<tab><tab><tab>self.quantum.delete_network(netid)",0,"if ""net"" in name :","if name == ""port"" :",0.036540249,8.257910795,0.45
"def findConfigFiles(self, cfg_args):<tab>""""""Find available config files""""""<tab>filenames = cfg_args.config[:]<tab>proj_opts = (""unittest.cfg"", ""nose2.cfg"")<tab>for fn in proj_opts:<tab><tab><IF-STMT><tab><tab><tab>fn = os.path.abspath(os.path.join(cfg_args.top_level_directory, fn))<tab><tab>filenames.append(fn)<tab>if cfg_args.user_config:<tab><tab>user_opts = (""~/.unittest.cfg"", ""~/.nose2.cfg"")<tab><tab>for fn in user_opts:<tab><tab><tab>filenames.append(os.path.expanduser(fn))<tab>return filenames",1,if cfg_args . top_level_directory :,if cfg_args . top_level_directory :,0.75,100,1
"def make_aware(value):<tab>if settings.USE_TZ:<tab><tab># naive datetimes are assumed to be in UTC.<tab><tab><IF-STMT><tab><tab><tab>value = timezone.make_aware(value, timezone.utc)<tab><tab># then convert to the Django configured timezone.<tab><tab>default_tz = timezone.get_default_timezone()<tab><tab>value = timezone.localtime(value, default_tz)<tab>return value",0,if timezone . is_naive ( value ) :,if timezone . isnaive ( value ) :,0.501462237,38.94003915,0.577777778
"def update(id):<tab>""""""Update a post if the current user is the author.""""""<tab>post = get_post(id)<tab>if request.method == ""POST"":<tab><tab>title = request.form[""title""]<tab><tab>body = request.form[""body""]<tab><tab>error = None<tab><tab>if not title:<tab><tab><tab>error = ""Title is required.""<tab><tab><IF-STMT><tab><tab><tab>flash(error)<tab><tab>else:<tab><tab><tab>post.title = title<tab><tab><tab>post.body = body<tab><tab><tab>db.session.commit()<tab><tab><tab>return redirect(url_for(""blog.index""))<tab>return render_template(""blog/update.html"", post=post)",0,if error is not None :,if error :,0.050438393,1.00E-10,0.4
"def copyfileobj(src, dest, length=512):<tab>if hasattr(src, ""readinto""):<tab><tab>buf = bytearray(length)<tab><tab>while True:<tab><tab><tab>sz = src.readinto(buf)<tab><tab><tab>if not sz:<tab><tab><tab><tab>break<tab><tab><tab>if sz == length:<tab><tab><tab><tab>dest.write(buf)<tab><tab><tab>else:<tab><tab><tab><tab>b = memoryview(buf)[:sz]<tab><tab><tab><tab>dest.write(b)<tab>else:<tab><tab>while True:<tab><tab><tab>buf = src.read(length)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>dest.write(buf)",1,if not buf :,if not buf :,0.75,100,1
"def imgFileProcessingTick(output):<tab>if isinstance(output, tuple):<tab><tab>workerOutput.append(output)<tab><tab>workerPool.terminate()<tab>else:<tab><tab>for page in output:<tab><tab><tab>if page is not None:<tab><tab><tab><tab>options.imgMetadata[page[0]] = page[1]<tab><tab><tab><tab>options.imgOld.append(page[2])<tab>if GUI:<tab><tab>GUI.progressBarTick.emit(""tick"")<tab><tab><IF-STMT><tab><tab><tab>workerPool.terminate()",0,if not GUI . conversionAlive :,if not options . imgOld :,0.052531501,19.30486975,0.428571429
"def process_word(word):<tab>if word.parent == ""remapping"":<tab><tab>raise UDError(""There is a cycle in a sentence"")<tab>if word.parent is None:<tab><tab>head = int(word.columns[HEAD])<tab><tab>if head > len(ud.words) - sentence_start:<tab><tab><tab>raise UDError(<tab><tab><tab><tab>""HEAD '{}' points outside of the sentence"".format(word.columns[HEAD])<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>parent = ud.words[sentence_start + head - 1]<tab><tab><tab>word.parent = ""remapping""<tab><tab><tab>process_word(parent)<tab><tab><tab>word.parent = parent",0,if head :,if head > 0 :,0.097914534,1.00E-10,0.7
"def validate_export(namespace):<tab>destination = namespace.destination<tab>if destination == ""file"":<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(""usage error: --path PATH --format FORMAT"")<tab>elif destination == ""appconfig"":<tab><tab>if (namespace.dest_name is None) and (namespace.dest_connection_string is None):<tab><tab><tab>raise CLIError(""usage error: --config-name NAME | --connection-string STR"")<tab>elif destination == ""appservice"":<tab><tab>if namespace.appservice_account is None:<tab><tab><tab>raise CLIError(""usage error: --appservice-account NAME_OR_ID"")",0,if namespace . path is None or namespace . format_ is None :,if namespace . path is None :,0.38830671,34.23503955,0.666666667
"def get_change_set_status(context, stack_name, change_set_name):<tab>try:<tab><tab>response = retry_boto_call(<tab><tab><tab>context.client.describe_change_set,<tab><tab><tab>ChangeSetName=change_set_name,<tab><tab><tab>StackName=stack_name,<tab><tab>)<tab>except ClientError as e:<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise e<tab>return response[""Status""]",0,"if e . response [ ""Error"" ] [ ""Code"" ] == ""ChangeSetNotFound"" :","if e . response [ ""Error"" ] [ ""Code"" ] == ""ResourceNotFoundException"" :",0.67220614,87.39351325,1
"def predict(self, predict_data):<tab>assert self.predict_fn is not None<tab># For the batch by batch prediction case, we do not want to include the cost of<tab># doing final outputs concatenation into time measurement<tab>with Timer() as t:<tab><tab><IF-STMT><tab><tab><tab>self.predictions = self.predict_fn(predict_data)<tab><tab>else:<tab><tab><tab>self.predictions = self.predict_fn(predict_data, concatenate_outputs=False)<tab>if not self.batch_benchmark:<tab><tab>self.predictions = np.concatenate(self.predictions)<tab>return t.interval",1,if self . batch_benchmark :,if self . batch_benchmark :,0.75,100,1
"def __str__(self):<tab>s = ""("" + str(self[0])<tab>s += "", ""<tab>if isinstance(self[1], Tensor):<tab><tab>if self[1].name and self[1].name is not None:<tab><tab><tab>s += self[1].name<tab><tab>else:<tab><tab><tab>s += ""tensor-"" + hex(id(self[1]))<tab>else:<tab><tab>s += str(self[1])<tab>s += "", ""<tab>if isinstance(self[2], Tensor):<tab><tab><IF-STMT><tab><tab><tab>s += self[2].name<tab><tab>else:<tab><tab><tab>s += ""tensor-"" + hex(id(self[2]))<tab>else:<tab><tab>s += str(self[2])<tab>s += "")""<tab>return s",1,if self [ 2 ] . name and self [ 2 ] . name is not None :,if self [ 2 ] . name and self [ 2 ] . name is not None :,1,100,1
"def get_local_cache(self, past, data, from_file, temp_id):<tab>""""""parse individual cached geometry if there is any""""""<tab>cache = []<tab>if self.accumulative:<tab><tab><IF-STMT><tab><tab><tab>cache = past[temp_id]<tab><tab>if not from_file and len(data) > 0:<tab><tab><tab>cache = data.get(temp_id, [])<tab>return cache",0,if from_file and len ( past ) > 0 :,if not from_file and len ( past ) > 0 :,0.521414433,84.23626744,0.272727273
def get_mappings(index):<tab>mappings = {}<tab>from kitsune.search.models import get_mapping_types<tab>for cls in get_mapping_types():<tab><tab>group = cls.get_index_group()<tab><tab><IF-STMT><tab><tab><tab>mappings[cls.get_mapping_type_name()] = cls.get_mapping()<tab>return mappings,0,if index == write_index ( group ) or index == read_index ( group ) :,if group . get_index_name ( ) == index :,0.010679218,6.273712355,0.371428571
"def find_first_of_filetype(content, filterfiltype, attr=""name""):<tab>""""""Find the first of the file type.""""""<tab>filename = """"<tab>for _filename in content:<tab><tab><IF-STMT><tab><tab><tab>if _filename.endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = _filename<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if getattr(_filename, attr).endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = getattr(_filename, attr)<tab><tab><tab><tab>break<tab>return filename",1,"if isinstance ( _filename , str ) :","if isinstance ( _filename , str ) :",0.75,100,1
"def _timer(<tab>duetime: typing.AbsoluteOrRelativeTime,<tab>period: Optional[typing.RelativeTime] = None,<tab>scheduler: Optional[typing.Scheduler] = None,) -> Observable:<tab>if isinstance(duetime, datetime):<tab><tab><IF-STMT><tab><tab><tab>return observable_timer_date(duetime, scheduler)<tab><tab>else:<tab><tab><tab>return observable_timer_duetime_and_period(duetime, period, scheduler)<tab>if period is None:<tab><tab>return observable_timer_timespan(duetime, scheduler)<tab>return observable_timer_timespan_and_period(duetime, period, scheduler)",1,if period is None :,if period is None :,0.75,100,1
"def __getattribute__(self, attrname):<tab>result = object.__getattribute__(self, attrname)<tab><IF-STMT><tab><tab>try:<tab><tab><tab>self._read_info(attrname)<tab><tab>except Exception as e:<tab><tab><tab>logging.warning(<tab><tab><tab><tab>""An error '%s' was raised while decoding '%s'"", e, repr(self.path)<tab><tab><tab>)<tab><tab>result = object.__getattribute__(self, attrname)<tab><tab>if result is NOT_SET:<tab><tab><tab>result = self.INITIAL_INFO[attrname]<tab>return result",1,if result is NOT_SET :,if result is NOT_SET :,0.75,100,1
"def on_btOK_clicked(self, *a):<tab>""""""Handler for OK button""""""<tab>if self.ac_callback is not None:<tab><tab>self._set_title()<tab><tab><IF-STMT><tab><tab><tab>self.ac_callback(self.id, self)<tab><tab>else:<tab><tab><tab>a = self.generate_modifiers(<tab><tab><tab><tab>self._action, self._selected_component.NAME == ""custom""<tab><tab><tab>)<tab><tab><tab>self.ac_callback(self.id, a)<tab><tab><tab>self.ac_callback = None<tab><tab>if self._selected_component:<tab><tab><tab>self._selected_component.on_ok(a)<tab>self.close()",0,if self . _mode == ActionEditor . AEC_MENUITEM :,"if self . _selected_component . NAME == ""custom"" :",0.134355139,21.65195675,0.6
"def execute():<tab>if frappe.db.get_value(""Company"", {""country"": ""India""}, ""name""):<tab><tab>address_template = frappe.db.get_value(""Address Template"", ""India"", ""template"")<tab><tab><IF-STMT><tab><tab><tab>set_up_address_templates(default_country=""India"")",0,"if not address_template or ""gstin"" not in address_template :",if address_template not in address_template :,0.295856188,40.97721606,0.493333333
"def is_ncname(name):<tab>first = name[0]<tab>if first == ""_"" or category(first) in NAME_START_CATEGORIES:<tab><tab>for i in xrange(1, len(name)):<tab><tab><tab>c = name[i]<tab><tab><tab>if not category(c) in NAME_CATEGORIES:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>return 0<tab><tab><tab># if in compatibility area<tab><tab><tab># if decomposition(c)!='':<tab><tab><tab>#<tab>return 0<tab><tab>return 1<tab>else:<tab><tab>return 0",0,if c in ALLOWED_NAME_CHARS :,if c in NAME_START_CATEGORIES :,0.394778655,24.27458859,1
"def _get_sonnet_version():<tab>with open(""sonnet/__init__.py"") as fp:<tab><tab>for line in fp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>g = {}<tab><tab><tab><tab>exec(line, g)  # pylint: disable=exec-used<tab><tab><tab><tab>return g[""__version__""]<tab><tab>raise ValueError(""`__version__` not defined in `sonnet/__init__.py`"")",0,"if line . startswith ( ""__version__"" ) :","if ""__version__"" in line :",0.020977837,47.49742509,0.4
def disjoined(self):<tab>gridscope = GridScope(globals=self.globals)<tab>for key in self.user_added:<tab><tab>value = self[key]<tab><tab><IF-STMT><tab><tab><tab>grid = vaex.utils.disjoined(value)<tab><tab><tab>gridscope[key] = grid<tab><tab>else:<tab><tab><tab>gridscope[key] = value<tab>return gridscope,0,"if isinstance ( value , np . ndarray ) :","if isinstance ( value , ( list , tuple ) ) :",0.207416754,36.46285862,0.5
def _maybe_uncompress(self):<tab>if not self._decompressed:<tab><tab>compression_type = self.compression_type<tab><tab><IF-STMT><tab><tab><tab>data = memoryview(self._buffer)[self._pos :]<tab><tab><tab>if compression_type == self.CODEC_GZIP:<tab><tab><tab><tab>uncompressed = gzip_decode(data)<tab><tab><tab>if compression_type == self.CODEC_SNAPPY:<tab><tab><tab><tab>uncompressed = snappy_decode(data.tobytes())<tab><tab><tab>if compression_type == self.CODEC_LZ4:<tab><tab><tab><tab>uncompressed = lz4_decode(data.tobytes())<tab><tab><tab>self._buffer = bytearray(uncompressed)<tab><tab><tab>self._pos = 0<tab>self._decompressed = True,0,if compression_type != self . CODEC_NONE :,if self . _pos :,0.128034894,7.509307648,1
"def read_chat_forever(reader, pub_socket):<tab>line = reader.readline()<tab>who = ""someone""<tab>while line:<tab><tab>print(""Chat:"", line.strip())<tab><tab><IF-STMT><tab><tab><tab>who = line.split("":"")[-1].strip()<tab><tab>try:<tab><tab><tab>pub_socket.send_pyobj((who, line))<tab><tab>except socket.error as e:<tab><tab><tab># ignore broken pipes, they just mean the participant<tab><tab><tab># closed its connection already<tab><tab><tab>if e[0] != 32:<tab><tab><tab><tab>raise<tab><tab>line = reader.readline()<tab>print(""Participant left chat."")",0,"if line . startswith ( ""name:"" ) :","if "":"" in line :",0.019907918,9.761739612,0.4
"def items(self, section=None):<tab>section = section if section is not None else Settings.DEFAULT_SECTION<tab>result = {""section"": section}<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for option in self._global_settings.options(section):<tab><tab><tab><tab>result[option] = self._global_settings.get(section, option)<tab><tab>if section in self._local_settings.sections():<tab><tab><tab>for option in self._local_settings.options(section):<tab><tab><tab><tab>result[option] = self._local_settings.get(section, option)<tab>except configparser.InterpolationSyntaxError:<tab><tab>core.termwarn(""Unable to parse settings file"")<tab>return result",1,if section in self . _global_settings . sections ( ) :,if section in self . _global_settings . sections ( ) :,0.75,100,1
"def before_train(self, program):<tab>""""""doc""""""<tab>if self.summary_record:<tab><tab>if self.summary_record.scalar:<tab><tab><tab>self.s_name, self.s_tolog = zip(*self.summary_record.scalar)<tab><tab>else:<tab><tab><tab>self.s_name, self.s_tolog = [], []<tab><tab><IF-STMT><tab><tab><tab>self.h_name, self.h_tolog = zip(*self.summary_record.histogram)<tab><tab>else:<tab><tab><tab>self.h_name, self.h_tolog = [], []",1,if self . summary_record . histogram :,if self . summary_record . histogram :,0.75,100,1
"def _s3_init(self):<tab>""""""Initialize s3 bucket.""""""<tab>try:<tab><tab>bucket_exists = yield self._bucket_exists()<tab><tab><IF-STMT><tab><tab><tab>LOGGER.warning(""Will attempt to create bucket"")<tab><tab><tab>yield self._create_bucket()<tab>except botocore.exceptions.NoCredentialsError:<tab><tab>LOGGER.error(<tab><tab><tab>'You must set ""s3.accessKeyId"" and ""s3.secretAccessKey"", or '<tab><tab><tab>'""s3.profile"" in your Streamlit configuration.'<tab><tab>)<tab><tab>raise errors.S3NoCredentials",1,if not bucket_exists :,if not bucket_exists :,0.75,100,1
"def id2unit(self, id):<tab>items = []<tab>for v, k in zip(id, self._id2unit.keys()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if self.keyed:<tab><tab><tab>items.append(""{}={}"".format(k, self._id2unit[k][v]))<tab><tab>else:<tab><tab><tab>items.append(self._id2unit[k][v])<tab>res = self.sep.join(items)<tab>if res == """":<tab><tab>res = ""_""<tab>return res",0,if v == EMPTY_ID :,if k not in self . _id2unit :,0.026407399,6.274655311,0.238095238
"def forward(model: TransformerListener, docs, is_train):<tab>if is_train:<tab><tab>model.verify_inputs(docs)<tab><tab>return model._outputs, model.backprop_and_clear<tab>else:<tab><tab><IF-STMT><tab><tab><tab>outputs = []<tab><tab>elif any(doc._.trf_data is None for doc in docs):<tab><tab><tab>width = model.get_dim(""nO"")<tab><tab><tab>outputs = [<tab><tab><tab><tab>TransformerData.zeros(len(doc), width, xp=model.ops.xp) for doc in docs<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>outputs = [doc._.trf_data for doc in docs]<tab><tab>return outputs, lambda d_data: []",1,if len ( docs ) == 0 :,if len ( docs ) == 0 :,0.75,100,1
"def get_plugin_dir(shooting_dir):<tab>DIRNAME = ""lunapark""<tab>parent = os.path.abspath(os.path.join(shooting_dir, os.pardir))<tab>if os.path.basename(parent) == DIRNAME:<tab><tab>return parent<tab>else:<tab><tab>plugin_dir = os.path.join(parent, DIRNAME)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(plugin_dir)<tab><tab>return plugin_dir",1,if not os . path . exists ( plugin_dir ) :,if not os . path . exists ( plugin_dir ) :,0.75,100,1
"def _get_plugin(self, name, lang=None, check=False):<tab>if lang is None:<tab><tab>lang = self.get_lang()<tab>if name not in self.plugin_attrib_map:<tab><tab>return None<tab>plugin_class = self.plugin_attrib_map[name]<tab>if plugin_class.is_extension:<tab><tab><IF-STMT><tab><tab><tab>return self.plugins[(name, None)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)<tab>else:<tab><tab>if (name, lang) in self.plugins:<tab><tab><tab>return self.plugins[(name, lang)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)",0,"if ( name , None ) in self . plugins :","if ( name , lang ) in self . plugins :",0.602001933,70.16879391,0.75
"def globs_relative_to_buildroot(self):<tab>buildroot = get_buildroot()<tab>globs = []<tab>for bundle in self.bundles:<tab><tab>fileset = bundle.fileset<tab><tab>if fileset is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>globs += bundle.fileset.filespec[""globs""]<tab><tab>else:<tab><tab><tab># NB(nh): filemap is an OrderedDict, so this ordering is stable.<tab><tab><tab>globs += [fast_relpath(f, buildroot) for f in bundle.filemap.keys()]<tab>super_globs = super().globs_relative_to_buildroot()<tab>if super_globs:<tab><tab>globs += super_globs[""globs""]<tab>return {""globs"": globs}",0,"elif hasattr ( fileset , ""filespec"" ) :","if ""globs"" in fileset . filespec :",0.058437636,6.379653897,0.26984127
"def running_jobs(self, exit_on_error=True):<tab>""""""Initialize multiprocessing.""""""<tab>with self.handling_exceptions():<tab><tab><IF-STMT><tab><tab><tab>from concurrent.futures import ProcessPoolExecutor<tab><tab><tab>try:<tab><tab><tab><tab>with ProcessPoolExecutor(self.jobs) as self.executor:<tab><tab><tab><tab><tab>yield<tab><tab><tab>finally:<tab><tab><tab><tab>self.executor = None<tab><tab>else:<tab><tab><tab>yield<tab>if exit_on_error:<tab><tab>self.exit_on_error()",0,if self . using_jobs :,if self . executor is not None :,0.193606478,22.08959113,0.357142857
"def _get_all_checkpoint_paths(self) -> List[str]:<tab>""""""Returns all the checkpoint paths managed by the instance.""""""<tab># Due to tensorflow/issues/19378, we cannot use `tf.io.gfile.glob` here<tab># because it returns directory contents recursively on Windows.<tab>if tf.io.gfile.exists(self._root_dir):<tab><tab>root_dir_entries = tf.io.gfile.listdir(self._root_dir)<tab><tab>return [<tab><tab><tab>os.path.join(self._root_dir, e)<tab><tab><tab>for e in root_dir_entries<tab><tab><tab><IF-STMT><tab><tab>]<tab>else:<tab><tab>return []",0,if e . startswith ( self . _prefix ),"if os . path . isdir ( os . path . join ( self . _root_dir , e ) )",0.102178372,12.25914996,0.201646091
"def test_tag_priority(self):<tab>for tag in _low_priority_D_TAG:<tab><tab>val = ENUM_D_TAG[tag]<tab><tab># if the low priority tag is present in the descriptions,<tab><tab># assert that it has not overridden any other tag<tab><tab>if _DESCR_D_TAG[val] == tag:<tab><tab><tab>for tag2 in ENUM_D_TAG:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>self.assertNotEqual(ENUM_D_TAG[tag2], val)",0,if tag2 == tag :,if _DESCR_D_TAG [ tag2 ] == tag :,0.114583634,19.67497981,1
"def cycle(self, forward=True):<tab>if self.cycle_list:<tab><tab>if forward is True:<tab><tab><tab>self.cycle_list.rotate(-1)<tab><tab><IF-STMT><tab><tab><tab>self.cycle_list.rotate(1)<tab><tab>self.move_to_obj(self.cycle_list[0])",1,elif forward is False :,elif forward is False :,0.75,100,1
"def __init__(self):<tab>self.keyring = None<tab>if not haveKeyring:<tab><tab>return<tab>try:<tab><tab>self.keyring = gnomekeyring.get_default_keyring_sync()<tab><tab><IF-STMT><tab><tab><tab># Code borrowed from<tab><tab><tab># http://trac.gajim.org/browser/src/common/passwords.py<tab><tab><tab>self.keyring = ""default""<tab><tab><tab>try:<tab><tab><tab><tab>gnomekeyring.create_sync(self.keyring, None)<tab><tab><tab>except gnomekeyring.AlreadyExistsError:<tab><tab><tab><tab>pass<tab>except:<tab><tab>logging.exception(""Error determining keyring"")<tab><tab>self.keyring = None",0,if self . keyring == None :,if self . keyring is None :,0.246272831,42.38365628,0.633333333
"def _coerce_trials_data(data, path):<tab>if not isinstance(data, list):<tab><tab><IF-STMT><tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path,<tab><tab><tab><tab>""invalid data type for trials: expected list or dict""<tab><tab><tab><tab>"", got %s"" % type(data).__name__,<tab><tab><tab>)<tab><tab>data = [data]<tab>for item in data:<tab><tab>if not isinstance(item, dict):<tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path, ""invalid data type for trial %r: expected dict"" % item<tab><tab><tab>)<tab>return data",1,"if not isinstance ( data , dict ) :","if not isinstance ( data , dict ) :",0.75,100,1
def update(self):<tab>if self.openfilename is not None:<tab><tab>try:<tab><tab><tab>current_mtime = os.stat(self.openfilename).st_mtime<tab><tab>except OSError:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>self.last_mtime = current_mtime<tab><tab><tab>self.reload()<tab>return True,1,if current_mtime != self . last_mtime :,if current_mtime != self . last_mtime :,0.75,100,1
"def _wrap_new_compiler(*args, **kwargs):<tab>try:<tab><tab>return func(*args, **kwargs)<tab>except errors.DistutilsPlatformError:<tab><tab><IF-STMT><tab><tab><tab>CCompiler = _UnixCCompiler<tab><tab>else:<tab><tab><tab>CCompiler = _MSVCCompiler<tab><tab>return CCompiler(None, kwargs[""dry_run""], kwargs[""force""])",0,"if not sys . platform == ""win32"" :","if sys . platform == ""win32"" :",0.36108324,81.76129039,0.377777778
"def _run_eagerly(*inputs):  # pylint: disable=missing-docstring<tab>with context.eager_mode():<tab><tab>constants = [<tab><tab><tab>_wrap_as_constant(value, tensor_spec)<tab><tab><tab>for value, tensor_spec in zip(inputs, input_signature)<tab><tab>]<tab><tab>output = fn(*constants)<tab><tab>if hasattr(output, ""_make""):<tab><tab><tab>return output._make([tensor.numpy() for tensor in output])<tab><tab><IF-STMT><tab><tab><tab>return [tensor.numpy() for tensor in output]<tab><tab>else:<tab><tab><tab>return output.numpy()",0,"if isinstance ( output , ( tuple , list ) ) :","elif isinstance ( output , list ) :",0.237346379,31.74081508,0.419047619
"def _on_event_MetadataAnalysisFinished(self, event, data):<tab>with self._selectedFileMutex:<tab><tab><IF-STMT><tab><tab><tab>self._setJobData(<tab><tab><tab><tab>self._selectedFile[""filename""],<tab><tab><tab><tab>self._selectedFile[""filesize""],<tab><tab><tab><tab>self._selectedFile[""sd""],<tab><tab><tab><tab>self._selectedFile[""user""],<tab><tab><tab>)",0,if self . _selectedFile :,if self . _selectedFile is not None :,0.351498834,46.71379777,0.444444444
"def env_asset_url_default(endpoint, values):<tab>""""""Create asset URLs dependent on the current env""""""<tab>if endpoint == ""views.themes"":<tab><tab>path = values.get(""path"", """")<tab><tab>static_asset = path.endswith("".js"") or path.endswith("".css"")<tab><tab>direct_access = "".dev"" in path or "".min"" in path<tab><tab><IF-STMT><tab><tab><tab>env = values.get(""env"", current_app.env)<tab><tab><tab>mode = "".dev"" if env == ""development"" else "".min""<tab><tab><tab>base, ext = os.path.splitext(path)<tab><tab><tab>values[""path""] = base + mode + ext",0,if static_asset and not direct_access :,if static_asset and direct_access :,0.233190283,66.90484409,0.714285714
"def __init__(self, inStr):<tab>""""""Initialize the class.""""""<tab>inStr = inStr.strip()<tab>if len(inStr) != 1 and len(inStr) != 2:<tab><tab>raise ValueError(""PosAlign: length not 2 chars"" + inStr)<tab>if inStr == "".."":<tab><tab>self.aa = ""-""<tab><tab>self.gap = 1<tab>else:<tab><tab>self.gap = 0<tab><tab>self.aa = inStr[0]<tab><tab><IF-STMT><tab><tab><tab>self.aa = ""C""<tab><tab>if len(inStr) == 2:<tab><tab><tab>self.ss = inStr[1].upper()<tab><tab>else:<tab><tab><tab>self.ss = ""0""",0,if self . aa == self . aa . lower ( ) :,"if inStr [ 1 ] . upper ( ) == ""C"" :",0.058104611,8.549161846,0.234375
"def iter_ReassignParameters(self, inputNode, variables, nodeByID):<tab>for node in inputNode.getReassignParameterNodes(nodeByID):<tab><tab>yield from iterNodeCommentLines(node)<tab><tab>yield from iterInputConversionLines(node, variables)<tab><tab>socket = node.inputs[0]<tab><tab>if socket.isUnlinked and socket.isCopyable():<tab><tab><tab>expression = getCopyExpression(socket, variables)<tab><tab>else:<tab><tab><tab>expression = variables[socket]<tab><tab><IF-STMT><tab><tab><tab>conditionPrefix = """"<tab><tab>else:<tab><tab><tab>conditionPrefix = ""if {}: "".format(variables[node.conditionSocket])<tab><tab>yield ""{}{} = {}"".format(<tab><tab><tab>conditionPrefix, variables[node.linkedParameterSocket], expression<tab><tab>)",1,if node . conditionSocket is None :,if node . conditionSocket is None :,0.75,100,1
"def init_weight(self):<tab>if self.pretrained is not None:<tab><tab>load_entire_model(self, self.pretrained)<tab>else:<tab><tab>for sublayer in self.sublayers():<tab><tab><tab>if isinstance(sublayer, nn.Conv2D):<tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kaiming_normal_init(sublayer.weight)",0,"elif isinstance ( sublayer , ( nn . BatchNorm , nn . SyncBatchNorm ) ) :","elif isinstance ( sublayer , nn . BatchNorm2d ) :",0.209091286,30.86194627,0.570833333
def logic():<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>yield reset.posedge<tab><tab>for i in range(20):<tab><tab><tab>yield clock.posedge<tab><tab><tab>if enable:<tab><tab><tab><tab>count.next = i<tab><tab>j = 1<tab><tab>while j < 25:<tab><tab><tab>if enable:<tab><tab><tab><tab>yield clock.posedge<tab><tab><tab>yield clock.posedge<tab><tab><tab>count.next = 2 * j<tab><tab><tab>j += 1,0,if reset == ACTIVE_LOW :,if reset :,0.067674239,1.00E-10,1
"def clean_log_messages(result_data):<tab>for idx in range(len(result_data[""executePlan""][""stepEvents""])):<tab><tab>message = result_data[""executePlan""][""stepEvents""][idx].get(""message"")<tab><tab><IF-STMT><tab><tab><tab>result_data[""executePlan""][""stepEvents""][idx][""message""] = re.sub(<tab><tab><tab><tab>r""(\d+(\.\d+)?)"", ""{N}"", message<tab><tab><tab>)<tab>return result_data",0,if message is not None :,if message :,0.050438393,1.00E-10,0.4
"def headerData(self, section, orientation, role=Qt.DisplayRole):<tab>if role == Qt.TextAlignmentRole:<tab><tab>if orientation == Qt.Horizontal:<tab><tab><tab>return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))<tab><tab>return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))<tab>if role != Qt.DisplayRole:<tab><tab>return to_qvariant()<tab>if orientation == Qt.Horizontal:<tab><tab>if section == NAME:<tab><tab><tab>return to_qvariant(""Name"")<tab><tab>elif section == VERSION:<tab><tab><tab>return to_qvariant(""Version"")<tab><tab><IF-STMT><tab><tab><tab>return to_qvariant(""Action"")<tab><tab>elif section == DESCRIPTION:<tab><tab><tab>return to_qvariant(""Description"")<tab>return to_qvariant()",1,elif section == ACTION :,elif section == ACTION :,1,100,1
"def _gather_infos(self):<tab># Carry over information from previous game step.<tab>if self._prev_state is not None:<tab><tab>for attr in self._tracked_infos:<tab><tab><tab>self.state[attr] = self.state.get(attr) or self._prev_state.get(attr)<tab>for info in [""score"", ""moves""]:<tab><tab><IF-STMT><tab><tab><tab>self.state[info] = int(self.state[info].strip())<tab>self.state[""won""] = ""*** The End ***"" in self.state[""feedback""]<tab>self.state[""lost""] = ""*** You lost! ***"" in self.state[""feedback""]",0,if self . state [ info ] is not None and type ( self . state [ info ] ) is not int :,if info in self . state :,0.088025253,2.563024872,0.136904762
"def calc_parity(sig, kind):<tab>if kind in (""zero"", ""none""):<tab><tab>return C(0, 1)<tab>elif kind == ""one"":<tab><tab>return C(1, 1)<tab>else:<tab><tab>bits, _ = value_bits_sign(sig)<tab><tab>even_parity = sum([sig[b] for b in range(bits)]) & 1<tab><tab><IF-STMT><tab><tab><tab>return ~even_parity<tab><tab>elif kind == ""even"":<tab><tab><tab>return even_parity<tab><tab>else:<tab><tab><tab>assert False",0,"if kind == ""odd"" :","if kind == ""negative"" :",0.394778655,59.46035575,1
"def tool(self, **kwds):<tab>process_definition = kwds.get(""process_definition"", None)<tab>if process_definition is None:<tab><tab>raw_process_reference = kwds.get(""raw_process_reference"", None)<tab><tab><IF-STMT><tab><tab><tab>raw_process_reference = self.raw_process_reference(kwds[""path""])<tab><tab>process_definition = self.process_definition(raw_process_reference)<tab>tool = load_tool.make_tool(<tab><tab>process_definition.uri,<tab><tab>process_definition.loading_context,<tab>)<tab>return tool",1,if raw_process_reference is None :,if raw_process_reference is None :,0.75,100,1
def context(self):<tab># Needed to avoid Translate Toolkit construct ID<tab># as context\04source<tab>if self.template is not None:<tab><tab>if self.template.id:<tab><tab><tab>return self.template.id<tab><tab><IF-STMT><tab><tab><tab>return self.template.context<tab><tab>return self.template.getid()<tab>return self.unescape_csv(self.mainunit.getcontext()),1,if self . template . context :,if self . template . context :,0.75,100,1
"def test_six_thread_safety():<tab>_reload_six()<tab>with patch(<tab><tab>""botocore.vendored.six.moves.__class__.__setattr__"", wraps=_wrapped_setattr<tab>):<tab><tab>threads = []<tab><tab>for i in range(2):<tab><tab><tab>t = _ExampleThread()<tab><tab><tab>threads.append(t)<tab><tab><tab>t.start()<tab><tab>while threads:<tab><tab><tab>t = threads.pop()<tab><tab><tab>t.join()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>six.reraise(*t.exc_info)",0,if t . exc_info :,"if hasattr ( t , ""exc_info"" ) :",0.02800146,14.99110695,0.477272727
"def _handle_js_events(self, change):<tab>if self.js_events:<tab><tab>if self.eventHandlers:<tab><tab><tab>for event in self.js_events:<tab><tab><tab><tab>event_name = event[""name""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.eventHandlers[event_name](event[""detail""])<tab><tab># clears the event queue.<tab><tab>self.js_events = []",1,if event_name in self . eventHandlers :,if event_name in self . eventHandlers :,0.75,100,1
"def single_discriminator(x, filters=128, kernel_size=8, strides=4, pure_mean=False):<tab>""""""A simple single-layer convolutional discriminator.""""""<tab>with tf.variable_scope(""discriminator""):<tab><tab>net = layers().Conv2D(<tab><tab><tab>filters, kernel_size, strides=strides, padding=""SAME"", name=""conv1""<tab><tab>)(x)<tab><tab><IF-STMT><tab><tab><tab>net = tf.reduce_mean(net, [1, 2])<tab><tab>else:<tab><tab><tab>net = mean_with_attention(net, ""mean_with_attention"")<tab><tab>return net",1,if pure_mean :,if pure_mean :,0.531170663,1.00E-10,1
"def find_path(self, from_location, to_location):<tab>end = to_location<tab>f_node = self.mh.get_node(from_location)<tab>self.on.append(f_node)<tab>self.o.append(f_node.lid)<tab>next_node = f_node<tab>counter = 0  # a bail-out counter<tab>while next_node is not None:<tab><tab><IF-STMT><tab><tab><tab>break  # no path found under limit<tab><tab>finish = self._handle_node(next_node, end)<tab><tab>if finish:<tab><tab><tab>return self._trace_path(finish)<tab><tab>next_node = self._get_best_open_node()<tab><tab>counter += 1<tab>return None",0,if counter > 10000 :,if counter >= self . max_path :,0.052869316,16.78445963,0.6
"def format_var_dict(dct, indent=4, max_width=80):<tab>lines = []<tab>pre = "" "" * indent<tab>for key, value in dct.items():<tab><tab>line = pre + key + "" = "" + repr(value)<tab><tab><IF-STMT><tab><tab><tab>line = line[: max_width - 3] + ""...""<tab><tab><tab>try:<tab><tab><tab><tab>value_len = len(value)<tab><tab><tab>except:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>line += ""\n"" + pre + ""len(%s) = %s"" % (key, value_len)<tab><tab>lines.append(line)<tab>return ""\n"".join(lines)",1,if len ( line ) > max_width :,if len ( line ) > max_width :,0.75,100,1
"def _recursive_name_seach(self, layer_names, layer, pre_name, depth):<tab>for name, module in layer.named_children():<tab><tab>nname = pre_name + ""_"" + name if pre_name != """" else name<tab><tab><IF-STMT><tab><tab><tab>if self._wrap_layer_check(module, name, nname):<tab><tab><tab><tab>layer_names.append(nname)<tab><tab>if self.depth is None or depth <= self.depth:<tab><tab><tab>if len(list(layer.named_children())) > 0:<tab><tab><tab><tab>self._recursive_name_seach(layer_names, module, nname, depth + 1)<tab>return layer_names",0,if depth == self . depth or self . depth is None :,if name not in layer_names :,0.009464483,3.102160928,0.161538462
"def finished_at(self):<tab>f = self.metadata_get([""State"", ""FinishedAt""])<tab>if f:<tab><tab>f = f[:26]<tab><tab><IF-STMT><tab><tab><tab>return DINOSAUR_TIME<tab><tab>finished_at = datetime.datetime.strptime(f, ISO_DATETIME_PARSE_STRING)<tab><tab>return finished_at",0,"if f == ""0001-01-01T00:00:00Z"" :",if f == DINOSAUR_TIME :,0.144778655,13.44802511,1
"def write_bool(self, bool):<tab>if (<tab><tab>self._bool_fid<tab><tab>and self._bool_fid > self._last_fid<tab><tab>and self._bool_fid - self._last_fid <= 15<tab>):<tab><tab><IF-STMT><tab><tab><tab>ctype = CompactType.TRUE<tab><tab>else:<tab><tab><tab>ctype = CompactType.FALSE<tab><tab>self._write_field_header(ctype, self._bool_fid)<tab>else:<tab><tab>if bool:<tab><tab><tab>self.write_byte(CompactType.TRUE)<tab><tab>else:<tab><tab><tab>self.write_byte(CompactType.FALSE)",1,if bool :,if bool :,0.531170663,1.00E-10,1
"def update(self, topLeft, bottomRight):<tab>if self._updating:<tab><tab># We are currently putting data in the model, so no updates<tab><tab>return<tab>if self._index:<tab><tab>if topLeft.row() <= self._index.row() <= bottomRight.row():<tab><tab><tab>self.updateText()<tab>elif self._indexes:<tab><tab>update = False<tab><tab>for i in self._indexes:<tab><tab><tab>if topLeft.row() <= i.row() <= bottomRight.row():<tab><tab><tab><tab>update = True<tab><tab><IF-STMT><tab><tab><tab>self.updateText()",1,if update :,if update :,0.531170663,1.00E-10,1
"def _preprocess_add_items(self, items):<tab>""""""Split the items into two lists of path strings and BaseEntries.""""""<tab>paths = []<tab>entries = []<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>paths.append(self._to_relative_path(item))<tab><tab>elif isinstance(item, (Blob, Submodule)):<tab><tab><tab>entries.append(BaseIndexEntry.from_blob(item))<tab><tab>elif isinstance(item, BaseIndexEntry):<tab><tab><tab>entries.append(item)<tab><tab>else:<tab><tab><tab>raise TypeError(""Invalid Type: %r"" % item)<tab># END for each item<tab>return (paths, entries)",0,"if isinstance ( item , string_types ) :","if isinstance ( item , str ) :",0.549040681,46.30777162,0.777777778
def ping_all():<tab>for l in _all_listeners.values():<tab><tab>count = l.receiver.count()<tab><tab><IF-STMT><tab><tab><tab>for dev in l.receiver:<tab><tab><tab><tab>dev.ping()<tab><tab><tab><tab>l._status_changed(dev)<tab><tab><tab><tab>count -= 1<tab><tab><tab><tab>if not count:<tab><tab><tab><tab><tab>break,0,if count :,if count > 0 :,0.097914534,1.00E-10,0.7
"def stage_node_dot(g, stage):<tab>""""""Create a stage node.""""""<tab>with g.subgraph(name=""cluster_"" + stage[""id""]) as subgraph:<tab><tab>subgraph.attr(label=stage[""name""])<tab><tab><IF-STMT><tab><tab><tab>for itervar in stage[""all_itervars""]:<tab><tab><tab><tab>iv_type = itervar[""itervar_type""]<tab><tab><tab><tab>itervar_node_dot(subgraph, itervar, iv_type, itervar[""index""])<tab><tab><tab>for rel in stage[""relations""]:<tab><tab><tab><tab>node_id = rel[""id""]<tab><tab><tab><tab>itervar_relation_dot(subgraph, rel, node_id)<tab><tab>else:<tab><tab><tab>subgraph.node(stage[""name""] + ""_placeholder"", style=""invis"")",1,"if stage [ ""all_itervars"" ] :","if stage [ ""all_itervars"" ] :",0.75,100,1
"def run() -> None:<tab>nonlocal state, timeout<tab>while True:<tab><tab>if timeout > 0.0:<tab><tab><tab>disposed.wait(timeout)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>time: datetime = self.now<tab><tab>state = action(state)<tab><tab>timeout = seconds - (self.now - time).total_seconds()",0,if disposed . is_set ( ) :,if state is None :,0.022250825,6.316906128,0.291666667
"def increment(s):<tab>if not s:<tab><tab>return ""1""<tab>for sequence in string.digits, string.lowercase, string.uppercase:<tab><tab>lastc = s[-1]<tab><tab>if lastc in sequence:<tab><tab><tab>i = sequence.index(lastc) + 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if len(s) == 1:<tab><tab><tab><tab><tab>s = sequence[0] * 2<tab><tab><tab><tab><tab>if s == ""00"":<tab><tab><tab><tab><tab><tab>s = ""10""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>s = increment(s[:-1]) + sequence[0]<tab><tab><tab>else:<tab><tab><tab><tab>s = s[:-1] + sequence[i]<tab><tab><tab>return s<tab>return s  # Don't increment",0,if i >= len ( sequence ) :,if i < len ( sequence ) :,0.549040681,52.47357978,1
"def Import(self, patch, force):<tab>if not patch.get(""file""):<tab><tab><IF-STMT><tab><tab><tab>raise PatchError(""Patch file must be specified in patch import."")<tab><tab>else:<tab><tab><tab>patch[""file""] = bb.fetch2.localpath(patch[""remote""], self.d)<tab>for param in PatchSet.defaults:<tab><tab>if not patch.get(param):<tab><tab><tab>patch[param] = PatchSet.defaults[param]<tab>if patch.get(""remote""):<tab><tab>patch[""file""] = self.d.expand(bb.fetch2.localpath(patch[""remote""], self.d))<tab>patch[""filemd5""] = bb.utils.md5_file(patch[""file""])",0,"if not patch . get ( ""remote"" ) :",if not force :,0.029285605,6.14383669,0.484848485
"def _setReadyState(self, state: str) -> None:<tab>if state != self.__readyState:<tab><tab>self.__log_debug(""- %s -> %s"", self.__readyState, state)<tab><tab>self.__readyState = state<tab><tab><IF-STMT><tab><tab><tab>self.emit(""open"")<tab><tab>elif state == ""closed"":<tab><tab><tab>self.emit(""close"")<tab><tab><tab># no more events will be emitted, so remove all event listeners<tab><tab><tab># to facilitate garbage collection.<tab><tab><tab>self.remove_all_listeners()",1,"if state == ""open"" :","if state == ""open"" :",0.75,100,1
def count_brokers(self):<tab>self.nb_brokers = 0<tab>for broker in self.brokers:<tab><tab>if not broker.spare:<tab><tab><tab>self.nb_brokers += 1<tab>for realm in self.higher_realms:<tab><tab>for broker in realm.brokers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.nb_brokers += 1,0,if not broker . spare and broker . manage_sub_realms :,if not broker . spare and not broker . spare [ broker ] :,0.502190403,40.52587697,0.75042735
"def _refresh(self):<tab>self.uiProfileSelectComboBox.clear()<tab>self.uiProfileSelectComboBox.addItem(""default"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for profile in sorted(os.listdir(self.profiles_path)):<tab><tab><tab><tab>if not profile.startswith("".""):<tab><tab><tab><tab><tab>self.uiProfileSelectComboBox.addItem(profile)<tab>except OSError:<tab><tab>pass",0,if os . path . exists ( self . profiles_path ) :,if os . path . isdir ( self . profiles_path ) :,0.618479556,78.254229,0.714285714
"def run(self):<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v[""_class""] == ""Dataset"" and v[""task_type""] == ""Communication"":<tab><tab><tab>try:<tab><tab><tab><tab>params = json.loads(v[""task_type_parameters""])<tab><tab><tab>except json.JSONDecodeError:<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>if len(params) == 1:<tab><tab><tab><tab><tab>params.extend([""stub"", ""fifo_io""])<tab><tab><tab><tab>v[""task_type_parameters""] = json.dumps(params)<tab>return self.objs",1,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,100,1
"def _listen(self, consumer_id: str) -> AsyncIterable[Any]:<tab>try:<tab><tab>while True:<tab><tab><tab>if self._listening:<tab><tab><tab><tab>async for msg in self._listen_to_queue(consumer_id):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield msg<tab><tab><tab><tab>await asyncio.sleep(0.5)<tab><tab><tab>else:<tab><tab><tab><tab>async for msg in self._listen_to_ws():<tab><tab><tab><tab><tab>yield msg<tab>except asyncio.CancelledError:<tab><tab>pass<tab>except Exception as e:<tab><tab>raise e",1,if msg is not None :,if msg is not None :,0.75,100,1
"def recv(self, bufsiz, flags=0):<tab>d = self._sock.recv(bufsiz, flags)<tab>if self.replace_pattern and b"" HTTP/1.1\r\n"" in d:<tab><tab>line_end = d.find(b""\r\n"")<tab><tab>req_line = d[:line_end]<tab><tab>words = req_line.split()<tab><tab><IF-STMT><tab><tab><tab>method, url, http_version = words<tab><tab><tab>url = url.replace(self.replace_pattern[0], self.replace_pattern[1])<tab><tab><tab>d = b""%s %s %s"" % (method, url, http_version) + d[line_end:]<tab>return d",0,if len ( words ) == 3 :,if len ( words ) == 2 :,0.605621306,75.06238538,0.666666667
"def Import(self, patch, force):<tab>if not patch.get(""file""):<tab><tab>if not patch.get(""remote""):<tab><tab><tab>raise PatchError(""Patch file must be specified in patch import."")<tab><tab>else:<tab><tab><tab>patch[""file""] = bb.fetch2.localpath(patch[""remote""], self.d)<tab>for param in PatchSet.defaults:<tab><tab><IF-STMT><tab><tab><tab>patch[param] = PatchSet.defaults[param]<tab>if patch.get(""remote""):<tab><tab>patch[""file""] = self.d.expand(bb.fetch2.localpath(patch[""remote""], self.d))<tab>patch[""filemd5""] = bb.utils.md5_file(patch[""file""])",0,if not patch . get ( param ) :,if param not in patch :,0.018728518,7.361641114,0.285714286
"def delete(post_id):<tab>blogging_engine = _get_blogging_engine(current_app)<tab>storage = blogging_engine.storage<tab>post = storage.get_post_by_id(post_id)<tab>if (post is not None) and (current_user.get_id() == post[""user_id""]):<tab><tab>success = storage.delete_post(post_id)<tab><tab><IF-STMT><tab><tab><tab>flash(""Your post was successfully deleted"", ""info"")<tab><tab>else:<tab><tab><tab>flash(""Something went wrong while deleting your post"", ""warning"")<tab>else:<tab><tab>flash(""You do not have the rights to delete this post"", ""warning"")<tab>return redirect(url_for(""blog_app.index""))",1,if success :,if success :,0.531170663,1.00E-10,1
"def update_schema_configs(state, schema):<tab>RegistrationSchema = state.get_model(""osf"", ""registrationschema"")<tab>for rs in RegistrationSchema.objects.all():<tab><tab>if rs.schema.get(""description"", False):<tab><tab><tab>rs.description = rs.schema[""description""]<tab><tab><IF-STMT><tab><tab><tab>rs.config = rs.schema[""config""]<tab><tab>rs.save()",1,"if rs . schema . get ( ""config"" , False ) :","if rs . schema . get ( ""config"" , False ) :",0.75,100,1
"def set_payload(self, value):<tab>del self[""payload""]<tab>if isinstance(value, ElementBase):<tab><tab><IF-STMT><tab><tab><tab>self.init_plugin(value.plugin_attrib, existing_xml=value.xml)<tab><tab>self.xml.append(value.xml)<tab>else:<tab><tab>self.xml.append(value)",0,if value . tag_name ( ) in self . plugin_tag_map :,if value . plugin_attrib :,0.049097371,9.852859741,0.575
"def getCellPropertyNames_aux(self, col_id):<tab>if col_id == ""name"":<tab><tab>if self.image_icon == ""places_busy"":<tab><tab><tab>return [""places_busy""]<tab><tab>baseName = self.image_icon<tab><tab><IF-STMT><tab><tab><tab>return [baseName + ""_open""]<tab><tab>else:<tab><tab><tab>return [baseName + ""_closed""]<tab>return []",0,if self . isOpen :,"if self . image_icon == ""open"" :",0.117260658,13.54599427,0.722222222
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr<tab>i, j, n = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_reg(op) and op_xmm(op):<tab><tab><tab>n += 1<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab>elif op_imm8_2(op):<tab><tab><tab>j += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and i == 1 and j <= 1",1,elif op_imm8 ( op ) :,elif op_imm8 ( op ) :,0.75,100,1
"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab><IF-STMT><tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab>if done:<tab><tab><tab>break<tab># Note that the observation on the done=True frame doesn't matter.<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",1,if i == self . _skip - 2 :,if i == self . _skip - 2 :,0.75,100,1
"def assertNodeSequenceEqual(<tab>self,<tab>seq1: Sequence[cst.CSTNode],<tab>seq2: Sequence[cst.CSTNode],<tab>msg: Optional[str] = None,) -> None:<tab>suffix = """" if msg is None else f""\n{msg}""<tab>if len(seq1) != len(seq2):<tab><tab>raise AssertionError(f""\n{seq1!r}\nis not deeply equal to \n{seq2!r}{suffix}"")<tab>for node1, node2 in zip(seq1, seq2):<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(<tab><tab><tab><tab>f""\n{seq1!r}\nis not deeply equal to \n{seq2!r}{suffix}""<tab><tab><tab>)",0,if not node1 . deep_equals ( node2 ) :,if len ( node1 ) != len ( node2 ) :,0.150500271,23.46235032,0.487179487
"def close(self):<tab>if self._file_writer is not None:<tab><tab><IF-STMT><tab><tab><tab>flat_result = flatten_dict(self.last_result, delimiter=""/"")<tab><tab><tab>scrubbed_result = {<tab><tab><tab><tab>k: value<tab><tab><tab><tab>for k, value in flat_result.items()<tab><tab><tab><tab>if isinstance(value, tuple(VALID_SUMMARY_TYPES))<tab><tab><tab>}<tab><tab><tab>self._try_log_hparams(scrubbed_result)<tab><tab>self._file_writer.close()",0,if self . trial and self . trial . evaluated_params and self . last_result :,if self . last_result is not None :,0.207215733,19.73862244,0.290441176
"def check_space(arr, task_id):<tab>for a in arr:<tab><tab>if a.startswith(""hadoop jar""):<tab><tab><tab>found = False<tab><tab><tab>for x in shlex.split(a):<tab><tab><tab><tab>if task_id in x:<tab><tab><tab><tab><tab>found = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise AssertionError",1,if not found :,if not found :,0.75,100,1
"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",0,"if self . block . get ( i , j ) :","if self . block . get ( ( i , j ) , False ) :",0.417928304,61.71392022,0.868421053
"def undo_block_stop(self):<tab>if self.undoblock.bump_depth(-1) == 0:<tab><tab>cmd = self.undoblock<tab><tab>self.undoblock = 0<tab><tab><IF-STMT><tab><tab><tab>if len(cmd) == 1:<tab><tab><tab><tab># no need to wrap a single cmd<tab><tab><tab><tab>cmd = cmd.getcmd(0)<tab><tab><tab># this blk of cmds, or single cmd, has already<tab><tab><tab># been done, so don't execute it again<tab><tab><tab>self.addcmd(cmd, 0)",0,if len ( cmd ) > 0 :,if cmd :,0.01726708,1.00E-10,0.36
"def __(task: pipelines.Task):<tab>if not acl.current_user_has_permission(views.acl_resource):<tab><tab>return bootstrap.card(<tab><tab><tab>header_left=""Commands"", body=acl.inline_permission_denied_message()<tab><tab>)<tab>else:<tab><tab>commands_card = bootstrap.card(<tab><tab><tab>header_left=""Commands"",<tab><tab><tab>fixed_header_height=True,<tab><tab><tab>sections=[_render_command(command) for command in task.commands],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return [<tab><tab><tab><tab>bootstrap.card(header_left=f""Max retries: {task.max_retries}""),<tab><tab><tab><tab>commands_card,<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>return commands_card",0,if task . max_retries :,if task . max_retries > 0 :,0.285456913,61.04735836,0.722222222
"def closeEvent(self, e=None):<tab>""""""Save settings and remove registered logging handler""""""<tab>if self.editor.isModified():<tab><tab># ask if user wants to save<tab><tab>if self.wants_save():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>e.accept()<tab><tab><tab>else:<tab><tab><tab><tab># saving error or user canceled<tab><tab><tab><tab>e.ignore()<tab><tab>else:<tab><tab><tab># discard changes<tab><tab><tab>e.accept()<tab>else:<tab><tab># unchanged<tab><tab>e.accept()",0,if self . save ( ) :,if e :,0.020447728,1.00E-10,0.377777778
"def _merge(self, a, b, path=None):<tab>""""""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge""""""<tab>if path is None:<tab><tab>path = []<tab>for key in b:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(a[key], dict) and isinstance(b[key], dict):<tab><tab><tab><tab>self._merge(a[key], b[key], path + [str(key)])<tab><tab><tab>elif a[key] == b[key]:<tab><tab><tab><tab>pass  # same leaf value<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)]))<tab><tab>else:<tab><tab><tab>a[key] = b[key]<tab>return a",1,if key in a :,if key in a :,0.75,100,1
"def _flags_helper(conf, atom, new_flags, test=False):<tab>try:<tab><tab>new_flags = __salt__[""portage_config.get_missing_flags""](conf, atom, new_flags)<tab>except Exception:  # pylint: disable=broad-except<tab><tab>import traceback<tab><tab>return {""result"": False, ""comment"": traceback.format_exc()}<tab>if new_flags:<tab><tab>old_flags = __salt__[""portage_config.get_flags_from_package_conf""](conf, atom)<tab><tab><IF-STMT><tab><tab><tab>__salt__[""portage_config.append_to_package_conf""](conf, atom, new_flags)<tab><tab>return {""result"": True, ""changes"": {""old"": old_flags, ""new"": new_flags}}<tab>return {""result"": None}",0,if not test :,if test :,0.096488528,1.00E-10,0.416666667
"def _confirm_deps(self, trans):<tab>if [pkgs for pkgs in trans.dependencies if pkgs]:<tab><tab>dia = AptConfirmDialog(trans, parent=self.parent)<tab><tab>res = dia.run()<tab><tab>dia.hide()<tab><tab>if res != Gtk.ResponseType.OK:<tab><tab><tab>log.debug(""Response is: %s"" % res)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.debug(""Finish_handler..."")<tab><tab><tab><tab>self.finish_handler(trans, 0, self.data)<tab><tab><tab>return<tab>self._run_transaction(trans)",1,if self . finish_handler :,if self . finish_handler :,0.75,100,1
def get_supported_extensions(self):<tab>for item in self.get_subclasses():<tab><tab>instance = item()<tab><tab><IF-STMT><tab><tab><tab>for ext in instance.supports_extensions:<tab><tab><tab><tab>self.extractors.update({instance.cls_name: instance})<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.extractors_by_extension[ext].append(instance)<tab><tab><tab><tab>except KeyError:<tab><tab><tab><tab><tab>self.extractors_by_extension[ext] = [instance],0,if instance . check ( ) :,if instance . supports_extensions :,0.094532291,26.26909894,0.722222222
"def find_module(self, fullname, path=None):<tab># Check for local modules first...<tab>localname = fullname.split(""."")[-1]<tab>name, ext = os.path.splitext(localname)<tab>try:<tab><tab>fobj, filename, typeinfo = imp.find_module(name, path)<tab>except ImportError:<tab><tab>logger.info(""Dcode Searching: %s (%s)"", name, path)<tab><tab>pymod = self.proxy.getPythonModule(fullname, path)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Dcode Loaded: %s"", fullname)<tab><tab><tab>return DcodeLoader(*pymod)",0,if pymod :,if pymod is not None :,0.090364769,1.00E-10,0.4
def run(self):<tab>try:<tab><tab>self.server_sock = self._create_socket_and_bind()<tab><tab># in case self.port = 0<tab><tab>self.port = self.server_sock.getsockname()[1]<tab><tab>self.ready_event.set()<tab><tab>self._handle_requests()<tab><tab><IF-STMT><tab><tab><tab>self.wait_to_close_event.wait(self.WAIT_EVENT_TIMEOUT)<tab>finally:<tab><tab>self.ready_event.set()  # just in case of exception<tab><tab>self._close_server_sock_ignore_errors()<tab><tab>self.stop_event.set(),0,if self . wait_to_close_event :,if self . wait_to_close_event is not None :,0.351498834,69.30977286,0.444444444
"def connection(self, commit_on_success=False):<tab>with self._lock:<tab><tab>if self._bulk_commit:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._pending_connection = sqlite.connect(self.filename)<tab><tab><tab>con = self._pending_connection<tab><tab>else:<tab><tab><tab>con = sqlite.connect(self.filename)<tab><tab>try:<tab><tab><tab>if self.fast_save:<tab><tab><tab><tab>con.execute(""PRAGMA synchronous = 0;"")<tab><tab><tab>yield con<tab><tab><tab>if commit_on_success and self.can_commit:<tab><tab><tab><tab>con.commit()<tab><tab>finally:<tab><tab><tab>if not self._bulk_commit:<tab><tab><tab><tab>con.close()",1,if self . _pending_connection is None :,if self . _pending_connection is None :,0.75,100,1
"def getReceiptInfo(pkgname):<tab>""""""Get receipt info from a package""""""<tab>info = []<tab>if hasValidPackageExt(pkgname):<tab><tab>display.display_debug2(""Examining %s"" % pkgname)<tab><tab><IF-STMT>  # new flat package<tab><tab><tab>info = getFlatPackageInfo(pkgname)<tab><tab>if os.path.isdir(pkgname):  # bundle-style package?<tab><tab><tab>info = getBundlePackageInfo(pkgname)<tab>elif pkgname.endswith("".dist""):<tab><tab>info = parsePkgRefs(pkgname)<tab>return info",1,if os . path . isfile ( pkgname ) :,if os . path . isfile ( pkgname ) :,0.75,100,1
"def test_gen_speed(gen_func):<tab>cur_time = time.time()<tab>for idx, _ in enumerate(gen_func()):<tab><tab>log.info(""iter %s: %s s"" % (idx, time.time() - cur_time))<tab><tab>cur_time = time.time()<tab><tab><IF-STMT><tab><tab><tab>break",0,if idx == 100 :,if cur_time > cur_time + 10 :,0.027969855,4.456882761,0.377777778
"def __init__(self, *args, **kwargs):<tab>if not quickjs_available:<tab><tab>msg = ""No supported QuickJS package found on custom python environment!""<tab><tab><IF-STMT><tab><tab><tab>msg += "" Please install python package quickjs or use ChakraJSEngine.""<tab><tab>elif external_interpreter:<tab><tab><tab>msg += "" Please install python package quickjs or use ExternalJSEngine.""<tab><tab>else:<tab><tab><tab>msg += "" Please install python package quickjs.""<tab><tab>raise RuntimeError(msg)<tab>self._context = self.Context(self)<tab>InternalJSEngine.__init__(self, *args, **kwargs)",0,if chakra_available :,"if sys . platform == ""win32"" :",0.045790811,1.00E-10,0.45
"def _draw_nodes(self, cr, bounding, highlight_items):<tab>highlight_nodes = []<tab>for element in highlight_items:<tab><tab>if isinstance(element, Edge):<tab><tab><tab>highlight_nodes.append(element.src)<tab><tab><tab>highlight_nodes.append(element.dst)<tab><tab>else:<tab><tab><tab>highlight_nodes.append(element)<tab>for node in self.nodes:<tab><tab><IF-STMT><tab><tab><tab>node._draw(cr, highlight=(node in highlight_nodes), bounding=bounding)",0,if bounding is None or node . _intersects ( bounding ) :,"if hasattr ( node , ""draw"" ) :",0.023405416,7.817610447,0.214285714
"def upgrade():<tab>bind = op.get_bind()<tab>session = db.Session(bind=bind)<tab>for slc in session.query(Slice).filter(Slice.viz_type.like(""deck_%"")):<tab><tab>params = json.loads(slc.params)<tab><tab><IF-STMT><tab><tab><tab>params[""spatial""] = {<tab><tab><tab><tab>""lonCol"": params.get(""longitude""),<tab><tab><tab><tab>""latCol"": params.get(""latitude""),<tab><tab><tab><tab>""type"": ""latlong"",<tab><tab><tab>}<tab><tab><tab>del params[""latitude""]<tab><tab><tab>del params[""longitude""]<tab><tab>slc.params = json.dumps(params)<tab><tab>session.merge(slc)<tab><tab>session.commit()<tab>session.close()",0,"if params . get ( ""latitude"" ) :","if ""spatial"" not in params :",0.019830745,6.431267394,0.314814815
"def list_completers():<tab>""""""List the active completers""""""<tab>o = ""Registered Completer Functions: \n""<tab>_comp = xsh_session.completers<tab>ml = max((len(i) for i in _comp), default=0)<tab>_strs = []<tab>for c in _comp:<tab><tab><IF-STMT><tab><tab><tab>doc = ""No description provided""<tab><tab>else:<tab><tab><tab>doc = "" "".join(_comp[c].__doc__.split())<tab><tab>doc = justify(doc, 80, ml + 3)<tab><tab>_strs.append(""{: >{}} : {}"".format(c, ml, doc))<tab>return o + ""\n"".join(_strs) + ""\n""",0,if _comp [ c ] . __doc__ is None :,if not _comp [ c ] . __doc__ :,0.282502131,73.55913235,0.320512821
"def test_numeric_literals(self):<tab>@udf(BigIntVal(FunctionContext, SmallIntVal))<tab>def fn(context, a):<tab><tab>if a is None:<tab><tab><tab>return 1729<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>elif a < 10:<tab><tab><tab>return a + 5<tab><tab>else:<tab><tab><tab>return a * 2",0,elif a < 0 :,elif a is None :,0.062871671,23.64354023,0.444444444
"def get_normal_sample(in_file):<tab>""""""Retrieve normal sample if normal/turmor""""""<tab>with utils.open_gzipsafe(in_file) as in_handle:<tab><tab>for line in in_handle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parts = line.strip().split(""Original="")[1][:-1]<tab><tab><tab><tab>return parts",0,"if line . startswith ( ""##PEDIGREE"" ) :","if line . startswith ( ""Original="" ) :",0.549040681,53.66551979,1
"def generate_html_index(index_file, outdir):<tab>data = parse_index_file(index_file)<tab>data = ((d[0], d[1]) for d in data)<tab>for i, chunk in enumerate(web.group(data, 1000)):<tab><tab>back = ""..""<tab><tab>index = t_html_layout(t_html_sitemap(back, chunk))<tab><tab>path = outdir + ""/%02d/%05d.html"" % (i / 1000, i)<tab><tab>write(path, web.safestr(index))<tab>for f in os.listdir(outdir):<tab><tab>path = os.path.join(outdir, f)<tab><tab><IF-STMT><tab><tab><tab>dirindex(path)<tab>dirindex(outdir, back=""."")",1,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1,100,1
"def _aggregate_metadata_attribute(<tab>self, attr, agg_func=np.max, default_value=0, from_type_metadata=True):<tab>attr_values = []<tab>for a in self.appliances:<tab><tab><IF-STMT><tab><tab><tab>attr_value = a.type.get(attr)<tab><tab>else:<tab><tab><tab>attr_value = a.metadata.get(attr)<tab><tab>if attr_value is not None:<tab><tab><tab>attr_values.append(attr_value)<tab>if len(attr_values) == 0:<tab><tab>return default_value<tab>else:<tab><tab>return agg_func(attr_values)",1,if from_type_metadata :,if from_type_metadata :,0.531170663,1.00E-10,1
"def install(self, unicode=False, names=None):<tab>import __builtin__<tab>__builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext<tab>if hasattr(names, ""__contains__""):<tab><tab>if ""gettext"" in names:<tab><tab><tab>__builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""]<tab><tab>if ""ngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""ngettext""] = (<tab><tab><tab><tab>unicode and self.ungettext or self.ngettext<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>__builtin__.__dict__[""lgettext""] = self.lgettext<tab><tab>if ""lngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lngettext""] = self.lngettext",1,"if ""lgettext"" in names :","if ""lgettext"" in names :",0.75,100,1
def logic():<tab>while 1:<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>yield reset.posedge<tab><tab>for i in range(20):<tab><tab><tab>yield clock.posedge<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count.next = i<tab><tab>j = 1<tab><tab>while j < 25:<tab><tab><tab>if enable:<tab><tab><tab><tab>yield clock.posedge<tab><tab><tab>yield clock.posedge<tab><tab><tab>count.next = 2 * j<tab><tab><tab>j += 1,1,if enable :,if enable :,0.531170663,1.00E-10,1
"def multi_device(reader, dev_count):<tab>if dev_count == 1:<tab><tab>for batch in reader:<tab><tab><tab>yield batch<tab>else:<tab><tab>batches = []<tab><tab>for batch in reader:<tab><tab><tab>batches.append(batch)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield batches<tab><tab><tab><tab>batches = []",1,if len ( batches ) == dev_count :,if len ( batches ) == dev_count :,0.75,100,1
"def lockfile_from_pipfile(cls, pipfile_path):<tab>from .pipfile import Pipfile<tab>if os.path.isfile(pipfile_path):<tab><tab><IF-STMT><tab><tab><tab>pipfile_path = os.path.abspath(pipfile_path)<tab><tab>pipfile = Pipfile.load(os.path.dirname(pipfile_path))<tab><tab>return plette.lockfiles.Lockfile.with_meta_from(pipfile._pipfile)<tab>raise PipfileNotFound(pipfile_path)",1,if not os . path . isabs ( pipfile_path ) :,if not os . path . isabs ( pipfile_path ) :,0.75,100,1
"def _resolve_result(self, f=None):<tab>try:<tab><tab>if f:<tab><tab><tab>results = f.result()<tab><tab>else:<tab><tab><tab>results = list(map(self._client.results.get, self.msg_ids))<tab><tab><IF-STMT><tab><tab><tab>r = results[0]<tab><tab><tab>if isinstance(r, Exception):<tab><tab><tab><tab>raise r<tab><tab>else:<tab><tab><tab>results = error.collect_exceptions(results, self._fname)<tab><tab>self._success = True<tab><tab>self.set_result(self._reconstruct_result(results))<tab>except Exception as e:<tab><tab>self._success = False<tab><tab>self.set_exception(e)",0,if self . _single_result :,if len ( results ) == 1 :,0.026407399,5.669791111,0.3
"def config_update(self, *updates):<tab>filename = os.path.join(self.path, "".git"", ""config"")<tab>with GitConfigParser(file_or_files=filename, read_only=False) as config:<tab><tab>for section, key, value in updates:<tab><tab><tab>try:<tab><tab><tab><tab>old = config.get(section, key)<tab><tab><tab><tab>if value is None:<tab><tab><tab><tab><tab>config.remove_option(section, key)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if old == value:<tab><tab><tab><tab><tab>continue<tab><tab><tab>except (NoSectionError, NoOptionError):<tab><tab><tab><tab>pass<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config.set_value(section, key, value)",0,if value is not None :,if old != value :,0.029084143,10.68217516,0.214285714
"def process_percent(token, state, command_line):<tab>if not state.is_range_start_line_parsed:<tab><tab>if command_line.line_range.start:<tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.start.append(token)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""bad range: {0}"".format(state.scanner.state.source))<tab><tab>command_line.line_range.end.append(token)<tab>return parse_line_ref, command_line",1,if command_line . line_range . end :,if command_line . line_range . end :,0.75,100,1
"def Flatten(self, metadata, value_to_flatten):<tab>if metadata:<tab><tab>self.metadata = metadata<tab>for desc in value_to_flatten.type_infos:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if hasattr(self, desc.name) and value_to_flatten.HasField(desc.name):<tab><tab><tab>setattr(self, desc.name, getattr(value_to_flatten, desc.name))",0,"if desc . name == ""metadata"" :",if desc . name in self . metadata :,0.191332916,29.55801302,0.523809524
"def create_model(model, args, is_train):<tab>""""""Create model, include basic model, googlenet model and mixup model""""""<tab>data_loader, data = utility.create_data_loader(is_train, args)<tab>if args.model == ""GoogLeNet"":<tab><tab>loss_out = _googlenet_model(data, model, args, is_train)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>loss_out = _mixup_model(data, model, args, is_train)<tab><tab>else:<tab><tab><tab>loss_out = _basic_model(data, model, args, is_train)<tab>return data_loader, loss_out",0,if args . use_mixup and is_train :,if args . mixup :,0.144532291,13.60798467,0.6
"def __init__(self, store):<tab>if store.context_aware:<tab><tab>self.contexts = list(store.contexts())<tab><tab>self.default_context = store.default_context.identifier<tab><tab><IF-STMT><tab><tab><tab>self.contexts.append(store.default_context)<tab>else:<tab><tab>self.contexts = [store]<tab><tab>self.default_context = None<tab>super(TrigSerializer, self).__init__(store)",0,if store . default_context :,if self . default_context is not None :,0.135478284,29.07153685,0.238095238
"def validate_import_depth(namespace):<tab>depth = namespace.depth<tab>if depth is not None:<tab><tab>try:<tab><tab><tab>depth = int(depth)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise CLIError(""Depth should be at least 1."")<tab><tab>except ValueError:<tab><tab><tab>raise CLIError(""Depth is not a number."")",1,if depth < 1 :,if depth < 1 :,0.75,100,1
"def __sync(self):<tab>""""""Skip reader to the block boundary.""""""<tab>pad_length = BLOCK_SIZE - self.__reader.tell() % BLOCK_SIZE<tab>if pad_length and pad_length != BLOCK_SIZE:<tab><tab>data = self.__reader.read(pad_length)<tab><tab><IF-STMT><tab><tab><tab>raise EOFError(""Read %d bytes instead of %d"" % (len(data), pad_length))",1,if len ( data ) != pad_length :,if len ( data ) != pad_length :,0.75,100,1
"def _split_long_text(text, idx, size):<tab>splited_text = text.split()<tab>if len(splited_text) > 25:<tab><tab><IF-STMT><tab><tab><tab># The first is (...)text<tab><tab><tab>first = """"<tab><tab>else:<tab><tab><tab>first = "" "".join(splited_text[:10])<tab><tab>if idx != 0 and idx == size - 1:<tab><tab><tab># The last is text(...)<tab><tab><tab>last = """"<tab><tab>else:<tab><tab><tab>last = "" "".join(splited_text[-10:])<tab><tab>return ""{}(...){}"".format(first, last)<tab>return text",0,if idx == 0 :,if idx != 0 and idx == size - 1 :,0.140711925,16.26170172,0.476190476
"def download_label_map(out_dir):<tab>log.info(""Downloading ScanNet "" + RELEASE_NAME + "" label mapping file..."")<tab>files = [LABEL_MAP_FILE]<tab>for file in files:<tab><tab>url = BASE_URL + RELEASE_TASKS + ""/"" + file<tab><tab>localpath = os.path.join(out_dir, file)<tab><tab>localdir = os.path.dirname(localpath)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(localdir)<tab><tab>download_file(url, localpath)<tab>log.info(""Downloaded ScanNet "" + RELEASE_NAME + "" label mapping file."")",0,if not os . path . isdir ( localdir ) :,if not os . path . exists ( localdir ) :,0.602001933,70.16879391,0.75
"def get_related_ids(self, resources):<tab>vpc_ids = [vpc[""VpcId""] for vpc in resources]<tab>vpc_igw_ids = set()<tab>for igw in self.manager.get_resource_manager(""internet-gateway"").resources():<tab><tab>for attachment in igw[""Attachments""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vpc_igw_ids.add(igw[""InternetGatewayId""])<tab>return vpc_igw_ids",0,"if attachment . get ( ""VpcId"" , """" ) in vpc_ids :","if attachment [ ""VpcId"" ] in vpc_ids :",0.056761587,30.71757041,0.588235294
"def visit_Assign(self, node):<tab>""""""Handle visiting an assignment statement.""""""<tab>ups = set()<tab>for targ in node.targets:<tab><tab>if isinstance(targ, (Tuple, List)):<tab><tab><tab>ups.update(leftmostname(elt) for elt in targ.elts)<tab><tab>elif isinstance(targ, BinOp):<tab><tab><tab>newnode = self.try_subproc_toks(node)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ups.add(leftmostname(targ))<tab><tab><tab>else:<tab><tab><tab><tab>return newnode<tab><tab>else:<tab><tab><tab>ups.add(leftmostname(targ))<tab>self.ctxupdate(ups)<tab>return node",0,if newnode is node :,if newnode is None :,0.394778655,42.72870064,0.666666667
"def evex_mask_dest_reg_only(ii):  # optional imm8<tab>i, m, xyz = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_mask_reg(op):<tab><tab><tab>m += 1<tab><tab>elif op_xmm(op) or op_ymm(op) or op_zmm(op):<tab><tab><tab>xyz += 1<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>return False<tab>return m == 1 and xyz > 0 and i <= 1",0,elif op_imm8 ( op ) :,elif op_imm8 ( op ) or op_imm8 ( op ) :,0.465434158,47.58733096,0.635416667
"def get_pynames(self, parameters):<tab>result = [None] * max(len(parameters), len(self.args))<tab>for index, arg in enumerate(self.args):<tab><tab><IF-STMT><tab><tab><tab>result[parameters.index(arg.arg)] = self._evaluate(arg.value)<tab><tab>else:<tab><tab><tab>result[index] = self._evaluate(arg)<tab>return result",0,"if isinstance ( arg , ast . keyword ) and arg . arg in parameters :","if isinstance ( arg , Parameter ) :",0.117642344,20.68738125,0.316666667
"def _discovery_modules(self) -> List[str]:<tab>modules: List[str] = []<tab>autodiscover = self.conf.autodiscover<tab>if autodiscover:<tab><tab><IF-STMT><tab><tab><tab>if self.conf.origin is None:<tab><tab><tab><tab>raise ImproperlyConfigured(E_NEED_ORIGIN)<tab><tab>elif callable(autodiscover):<tab><tab><tab>modules.extend(cast(Callable[[], Iterator[str]], autodiscover)())<tab><tab>else:<tab><tab><tab>modules.extend(autodiscover)<tab><tab>if self.conf.origin:<tab><tab><tab>modules.append(self.conf.origin)<tab>return modules",0,"if isinstance ( autodiscover , bool ) :",if self . conf . origin is not None :,0.016095022,4.990049702,0.151515152
"def _lock(self, files, type):<tab>for i in count(0):<tab><tab>lockfile = os.path.join(self._lockdir, ""{}.{}.lock"".format(i, type))<tab><tab><IF-STMT><tab><tab><tab>self._lockfile[type] = lockfile<tab><tab><tab>with open(lockfile, ""w"") as lock:<tab><tab><tab><tab>print(*files, sep=""\n"", file=lock)<tab><tab><tab>return",0,if not os . path . exists ( lockfile ) :,if os . path . exists ( lockfile ) :,0.407499005,81.76129039,0.272727273
"def _init_inheritable_dicts_(cls):<tab>if cls.__bases__ != (object,):<tab><tab>return<tab>for attr in cls._inheritable_dict_attrs_:<tab><tab>if isinstance(attr, tuple):<tab><tab><tab>attr_name, default = attr<tab><tab>else:<tab><tab><tab>attr_name, default = attr, {}<tab><tab><IF-STMT><tab><tab><tab>raise SyntaxError(""{} is not a dictionary"".format(attr_name))<tab><tab>setattr(cls, attr_name, default)",0,"if not isinstance ( default , dict ) :","if not isinstance ( attr_name , dict ) :",0.290117047,46.92470064,0.648148148
"def _validate_name(self, name):<tab>if isinstance(name, str):<tab><tab>name = dns.name.from_text(name, None)<tab>elif not isinstance(name, dns.name.Name):<tab><tab>raise KeyError(""name parameter must be convertible to a DNS name"")<tab>if name.is_absolute():<tab><tab>if not name.is_subdomain(self.origin):<tab><tab><tab>raise KeyError(""name parameter must be a subdomain of the zone origin"")<tab><tab><IF-STMT><tab><tab><tab>name = name.relativize(self.origin)<tab>return name",1,if self . relativize :,if self . relativize :,0.75,100,1
"def hard_update(self, cache, size_change, pins_gates):<tab>""""""replace verts, rads and vel (in NumPy)""""""<tab>verts, rads, vel, react = cache<tab>if len(verts) == self.v_len:<tab><tab><IF-STMT><tab><tab><tab>unpinned = self.params[""unpinned""]<tab><tab><tab>self.verts[unpinned] = verts[unpinned]<tab><tab>else:<tab><tab><tab>self.verts = verts<tab><tab>self.vel = vel<tab><tab>if not size_change:<tab><tab><tab>self.rads = rads",0,if pins_gates [ 0 ] and pins_gates [ 1 ] :,if self . pinned :,0.011636451,1.719207235,0.276190476
"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab>if pyv == 2:<tab><tab><tab>if self.PY2 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab>if pyv == 3:<tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",1,if not self . PY3 :,if not self . PY3 :,0.75,100,1
def on_project_dialog_finished(self):<tab>if self.sender().committed:<tab><tab><IF-STMT><tab><tab><tab>self.close_project()<tab><tab><tab>self.project_manager.from_dialog(self.sender())<tab><tab>else:<tab><tab><tab>self.project_manager.project_updated.emit(),0,if self . sender ( ) . new_project :,if self . project_manager . project_updated . is_set ( ) :,0.123349131,12.39899236,0.735294118
"def filter_database(db, user, filter_name):<tab>""""""Returns a list of person handles""""""<tab>filt = MatchesFilter([filter_name])<tab>filt.requestprepare(db, user)<tab>if user:<tab><tab>user.begin_progress(<tab><tab><tab>_(""Finding relationship paths""),<tab><tab><tab>_(""Retrieving all sub-filter matches""),<tab><tab><tab>db.get_number_of_people(),<tab><tab>)<tab>matches = []<tab>for handle in db.iter_person_handles():<tab><tab>person = db.get_person_from_handle(handle)<tab><tab><IF-STMT><tab><tab><tab>matches.append(handle)<tab><tab>if user:<tab><tab><tab>user.step_progress()<tab>if user:<tab><tab>user.end_progress()<tab>filt.requestreset()<tab>return matches",0,"if filt . apply ( db , person ) :",if person :,0.011515134,1.00E-10,0.294871795
"def add(self, key, val):<tab>if key is None:<tab><tab>g.trace(""TypeDict: None is not a valid key"", g.callers())<tab><tab>return<tab>self._checkKeyType(key)<tab>self._checkValType(val)<tab>if self.isList:<tab><tab>aList = self.d.get(key, [])<tab><tab><IF-STMT><tab><tab><tab>aList.append(val)<tab><tab><tab>self.d[key] = aList<tab>else:<tab><tab>self.d[key] = val",0,if val not in aList :,if aList :,0.050438393,1.00E-10,0.233333333
"def show_help(ctx, param, value):<tab>if value and not ctx.resilient_parsing:<tab><tab><IF-STMT><tab><tab><tab># legit main help<tab><tab><tab>echo(format_help(ctx.get_help()))<tab><tab>else:<tab><tab><tab># legit sub-command help<tab><tab><tab>echo(ctx.get_help(), color=ctx.color)<tab><tab>ctx.exit()",0,if not ctx . invoked_subcommand :,"if hasattr ( ctx , ""get_help"" ) :",0.023749772,4.789232204,0.6
"def wav_to_spec(wav_audio, hparams):<tab>""""""Transforms the contents of a wav file into a series of spectrograms.""""""<tab>if hparams.spec_type == ""raw"":<tab><tab>spec = _wav_to_framed_samples(wav_audio, hparams)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>spec = _wav_to_cqt(wav_audio, hparams)<tab><tab>elif hparams.spec_type == ""mel"":<tab><tab><tab>spec = _wav_to_mel(wav_audio, hparams)<tab><tab>else:<tab><tab><tab>raise ValueError(""Invalid spec_type: {}"".format(hparams.spec_type))<tab><tab>if hparams.spec_log_amplitude:<tab><tab><tab>spec = librosa.power_to_db(spec)<tab>return spec",1,"if hparams . spec_type == ""cqt"" :","if hparams . spec_type == ""cqt"" :",0.75,100,1
"def __bytes__(self) -> bytes:<tab>payload = pack(""!LL"", self.ssrc, self.media_ssrc)<tab>if self.lost:<tab><tab>pid = self.lost[0]<tab><tab>blp = 0<tab><tab>for p in self.lost[1:]:<tab><tab><tab>d = p - pid - 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>blp |= 1 << d<tab><tab><tab>else:<tab><tab><tab><tab>payload += pack(""!HH"", pid, blp)<tab><tab><tab><tab>pid = p<tab><tab><tab><tab>blp = 0<tab><tab>payload += pack(""!HH"", pid, blp)<tab>return pack_rtcp_packet(RTCP_RTPFB, self.fmt, payload)",0,if d < 16 :,if d > 0 :,0.314978772,23.64354023,0.6
"def run() -> None:<tab>nonlocal state, timeout<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>disposed.wait(timeout)<tab><tab>if disposed.is_set():<tab><tab><tab>return<tab><tab>time: datetime = self.now<tab><tab>state = action(state)<tab><tab>timeout = seconds - (self.now - time).total_seconds()",0,if timeout > 0.0 :,if state is None :,0.034123066,12.7033187,0.25
"def _get_host(self, array, connector, remote=False):<tab>""""""Return dict describing existing Purity host object or None.""""""<tab>if remote and array.get_rest_version() in SYNC_REPLICATION_REQUIRED_API_VERSIONS:<tab><tab>hosts = array.list_hosts(remote=True)<tab>else:<tab><tab>hosts = array.list_hosts()<tab>matching_hosts = []<tab>for host in hosts:<tab><tab>for wwn in connector[""wwpns""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>matching_hosts.append(host)<tab><tab><tab><tab>break  # go to next host<tab>return matching_hosts",0,"if wwn . lower ( ) in str ( host [ ""wwn"" ] ) . lower ( ) :",if host . get_wwn ( wwn ) == wwn :,0.25790906,2.807631069,0.26984127
"def validate_moment(self, moment: ""cirq.Moment""):<tab>super().validate_moment(moment)<tab>for op in moment.operations:<tab><tab><IF-STMT><tab><tab><tab>for other in moment.operations:<tab><tab><tab><tab>if other is not op and self._check_if_exp11_operation_interacts(<tab><tab><tab><tab><tab>cast(ops.GateOperation, op), cast(ops.GateOperation, other)<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>raise ValueError(""Adjacent Exp11 operations: {}."".format(moment))",0,"if isinstance ( op . gate , ops . CZPowGate ) :","if isinstance ( op , ops . GateOperation ) :",0.257157611,34.66667773,0.490384615
"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab>if key not in collected_models:<tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab>if attr is None:<tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab>if conv is not None:<tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",1,if keys is not None and key not in keys :,if keys is not None and key not in keys :,0.75,100,1
"def test_all(self):<tab>expected = []<tab>blacklist = {""executable"", ""nobody_uid"", ""test""}<tab>for name in dir(server):<tab><tab>if name.startswith(""_"") or name in blacklist:<tab><tab><tab>continue<tab><tab>module_object = getattr(server, name)<tab><tab><IF-STMT><tab><tab><tab>expected.append(name)<tab>self.assertCountEqual(server.__all__, expected)",0,"if getattr ( module_object , ""__module__"" , None ) == ""http.server"" :",if inspect . isclass ( module_object ) and inspect . isclass ( module_object ) :,0.020992796,12.48757525,0.265306122
"def _adjust_input(self):<tab>for i in range(len(self.block.ops)):<tab><tab>current_op = self.block.ops[i]<tab><tab>for input_arg in current_op.input_arg_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>current_op._rename_input(input_arg, self.input_map[input_arg])",1,if input_arg in self . input_map :,if input_arg in self . input_map :,0.75,100,1
"def __getitem__(self, cls):<tab>try:<tab><tab>return dict.__getitem__(self, cls)<tab>except KeyError as e:<tab><tab><IF-STMT><tab><tab><tab>cls = cls.__class__<tab><tab>for b in reversed(cls.__bases__):<tab><tab><tab>try:<tab><tab><tab><tab>retval = self[b]<tab><tab><tab><tab># this is why a cdict instance must never be modified after<tab><tab><tab><tab># the first lookup<tab><tab><tab><tab>self[cls] = retval<tab><tab><tab><tab>return retval<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab><tab>raise e",0,"if not hasattr ( cls , ""__bases__"" ) :","if isinstance ( cls , type ) :",0.080387257,11.27783237,0.285714286
"def before_read(self, parser, section, option, value):<tab># If we're dealing with a quoted string as the interpolation value,<tab># make sure we load and unquote it so we don't end up with '""value""'<tab>try:<tab><tab>json_value = srsly.json_loads(value)<tab><tab><IF-STMT><tab><tab><tab>value = json_value<tab>except Exception:<tab><tab>pass<tab>return super().before_read(parser, section, option, value)",0,"if isinstance ( json_value , str ) and json_value not in JSON_EXCEPTIONS :",if json_value :,0.007241876,1.00E-10,0.248120301
"def insert_files(self, urls, pos):<tab>""""""Not only images""""""<tab>image_extensions = ["".png"", "".jpg"", "".bmp"", "".gif""]<tab>for url in urls:<tab><tab>if url.scheme() == ""file"":<tab><tab><tab>path = url.path()<tab><tab><tab>ext = os.path.splitext(path)[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._insert_image_from_path(path)<tab><tab><tab>else:<tab><tab><tab><tab>self.parent.resource_edit.add_attach(path)",0,if os . path . exists ( path ) and ext in image_extensions :,if ext in image_extensions :,0.14284101,23.24683759,0.213235294
"def p_constant(self, p):<tab>""""""constant : PP_NUMBER""""""<tab>value = p[1].rstrip(""LlUu"")<tab>try:<tab><tab><IF-STMT><tab><tab><tab>value = int(value[2:], 16)<tab><tab>elif value[0] == ""0"":<tab><tab><tab>value = int(value, 8)<tab><tab>else:<tab><tab><tab>value = int(value)<tab>except ValueError:<tab><tab>value = value.rstrip(""eEfF"")<tab><tab>try:<tab><tab><tab>value = float(value)<tab><tab>except ValueError:<tab><tab><tab>value = 0<tab>p[0] = ConstantExpressionNode(value)",0,"if value [ : 2 ] == ""0x"" :","if value [ 0 ] == ""x"" :",0.080387257,34.53155548,0.6
"def _decode_pattern_list(data):<tab>rv = []<tab>contains_dict = False<tab>for item in data:<tab><tab>if isinstance(item, list):<tab><tab><tab>item = _decode_pattern_list(item)<tab><tab><IF-STMT><tab><tab><tab>item = _decode_pattern_dict(item)<tab><tab><tab>contains_dict = True<tab><tab>rv.append(item)<tab># avoid sorting if any element in the list is a dict<tab>if not contains_dict:<tab><tab>rv = sorted(rv)<tab>return rv",1,"elif isinstance ( item , dict ) :","elif isinstance ( item , dict ) :",0.75,100,1
"def value(self, mode):<tab>v = super(mn_armt, self).value(mode)<tab>if mode == ""l"":<tab><tab>out = []<tab><tab>for x in v:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out.append(x[::-1])<tab><tab><tab>elif len(x) == 4:<tab><tab><tab><tab>out.append(x[:2][::-1] + x[2:4][::-1])<tab><tab>return out<tab>elif mode == ""b"":<tab><tab>return [x for x in v]<tab>else:<tab><tab>raise NotImplementedError(""bad attrib"")",1,if len ( x ) == 2 :,if len ( x ) == 2 :,0.75,100,1
"def _press_fire(self):<tab>fire_action = 1<tab>if (<tab><tab>self.is_atari_env<tab><tab>and self.env.unwrapped.get_action_meanings()[fire_action] == ""FIRE""<tab>):<tab><tab>self.current_ale_lives = self.env.unwrapped.ale.lives()<tab><tab>self.step(fire_action)<tab><tab><IF-STMT><tab><tab><tab>self.reset_internal_state()",0,if self . done :,if self . current_ale_lives == self . current_ale_lives :,0.188559557,8.590764836,0.666666667
"def update_fid_err_log(self, fid_err):<tab>""""""add an entry to the fid_err log""""""<tab>self.fid_err_log.append(fid_err)<tab>if self.write_to_file:<tab><tab><IF-STMT><tab><tab><tab>mode = ""w""<tab><tab>else:<tab><tab><tab>mode = ""a""<tab><tab>f = open(self.fid_err_file, mode)<tab><tab>f.write(""{}\n"".format(fid_err))<tab><tab>f.close()",0,if len ( self . fid_err_log ) == 1 :,if os . path . isfile ( self . fid_err_file ) :,0.14083451,40.71220776,0.241666667
"def _name(self, sender, short=True, full_email=False):<tab>words = re.sub('[""<>]', """", sender).split()<tab>nomail = [w for w in words if not ""@"" in w]<tab>if nomail:<tab><tab>if short:<tab><tab><tab>if len(nomail) > 1 and nomail[0].lower() in self._NAME_TITLES:<tab><tab><tab><tab>return nomail[1]<tab><tab><tab>return nomail[0]<tab><tab>return "" "".join(nomail)<tab>elif words:<tab><tab><IF-STMT><tab><tab><tab>return words[0].split(""@"", 1)[0]<tab><tab>return words[0]<tab>return ""(nobody)""",0,if not full_email :,if full_email :,0.096488528,1.00E-10,0.6
"def zrx_order_to_json(order: Optional[ZeroExOrder]) -> Optional[Dict[str, any]]:<tab>if order is None:<tab><tab>return None<tab>retval: Dict[str, any] = {}<tab>for key, value in order.items():<tab><tab><IF-STMT><tab><tab><tab>retval[key] = value<tab><tab>else:<tab><tab><tab>retval[f""__binary__{key}""] = base64.b64encode(value).decode(""utf8"")<tab>return retval",0,"if not isinstance ( value , bytes ) :","if isinstance ( value , str ) :",0.18845666,37.70794597,0.26984127
"def _get_outfile(self):<tab>outfile = self.inputs.transformed_file<tab>if not isdefined(outfile):<tab><tab><IF-STMT><tab><tab><tab>if self.inputs.fs_target is True:<tab><tab><tab><tab>src = ""orig.mgz""<tab><tab><tab>else:<tab><tab><tab><tab>src = self.inputs.target_file<tab><tab>else:<tab><tab><tab>src = self.inputs.source_file<tab><tab>outfile = fname_presuffix(src, newpath=os.getcwd(), suffix=""_warped"")<tab>return outfile",0,if self . inputs . inverse is True :,if isdefined ( self . inputs . target_file ) :,0.158265716,23.46235032,0.225
"def close(self):<tab>if self.changed:<tab><tab>save = EasyDialogs.AskYesNoCancel(<tab><tab><tab>'Save window ""%s"" before closing?' % self.name, 1<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.menu_save()<tab><tab>elif save < 0:<tab><tab><tab>return<tab>if self.parent.active == self:<tab><tab>self.parent.active = None<tab>self.parent.updatemenubar()<tab>del self.ted<tab>self.do_postclose()",1,if save > 0 :,if save > 0 :,0.75,100,1
"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>if i == self._skip - 2:<tab><tab><tab>self._obs_buffer[0] = obs<tab><tab>if i == self._skip - 1:<tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab><IF-STMT><tab><tab><tab>break<tab># Note that the observation on the done=True frame doesn't matter.<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",1,if done :,if done :,0.531170663,1.00E-10,1
"def __isub__(self, other):<tab>""""""In-place subtraction of a matrix or scalar.""""""<tab>if isinstance(other, Matrix):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""matrix shapes do not match"")<tab><tab>for row_a, row_b in izip(self._data, other):<tab><tab><tab>for i in xrange(len(row_a)):<tab><tab><tab><tab>row_a[i] -= row_b[i]<tab>else:<tab><tab>for row in self._data:<tab><tab><tab>for i in xrange(len(row)):<tab><tab><tab><tab>row[i] -= other<tab>return self",0,if self . shape != other . shape :,if len ( self . _data ) != len ( other ) :,0.340603528,8.549161846,0.333333333
"def check(self, count, count_v, enable, clock, reset, n):<tab>expect = 0<tab>yield reset.posedge<tab>self.assertEqual(count, expect)<tab>self.assertEqual(count, count_v)<tab>while 1:<tab><tab>yield clock.posedge<tab><tab>if enable:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expect = n - 1<tab><tab><tab>else:<tab><tab><tab><tab>expect -= 1<tab><tab>yield delay(1)<tab><tab># print ""%d count %s expect %s count_v %s"" % (now(), count, expect, count_v)<tab><tab>self.assertEqual(count, expect)<tab><tab>self.assertEqual(count, count_v)",0,if expect == - n :,if n > 0 :,0.029084143,9.423716575,0.4
"def getmod(self, nm):<tab>mod = None<tab>for thing in self.path:<tab><tab>if isinstance(thing, basestring):<tab><tab><tab>owner = self.shadowpath.get(thing, -1)<tab><tab><tab>if owner == -1:<tab><tab><tab><tab>owner = self.shadowpath[thing] = self.__makeOwner(thing)<tab><tab><tab>if owner:<tab><tab><tab><tab>mod = owner.getmod(nm)<tab><tab>else:<tab><tab><tab>mod = thing.getmod(nm)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return mod",0,if mod :,if mod is not None :,0.090364769,1.00E-10,0.4
"def get_file_language(filename, text=None):<tab>""""""Get file language from filename""""""<tab>ext = osp.splitext(filename)[1]<tab>if ext.startswith("".""):<tab><tab>ext = ext[1:]  # file extension with leading dot<tab>language = ext<tab>if not ext:<tab><tab>if text is None:<tab><tab><tab>text, _enc = encoding.read(filename)<tab><tab>for line in text.splitlines():<tab><tab><tab>if not line.strip():<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shebang = line[2:]<tab><tab><tab><tab>if ""python"" in shebang:<tab><tab><tab><tab><tab>language = ""python""<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>return language",0,"if line . startswith ( ""#!"" ) :",if line . startswith ( ext ) :,0.299040681,40.86646502,0.777777778
"def do_status(self, directory, path):<tab>with self._repo(directory) as repo:<tab><tab>if path:<tab><tab><tab>path = os.path.join(directory, path)<tab><tab><tab>statuses = repo.status(include=path, all=True)<tab><tab><tab>for status, paths in statuses:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return self.statuses[status][0]<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>resulting_status = 0<tab><tab><tab>for status, paths in repo.status(all=True):<tab><tab><tab><tab>if paths:<tab><tab><tab><tab><tab>resulting_status |= self.statuses[status][1]<tab><tab><tab>return self.repo_statuses_str[resulting_status]",1,if paths :,if paths :,0.531170663,1.00E-10,1
def _kill(proc):<tab>if proc is None:<tab><tab>return<tab>if proc.stdout is not None:<tab><tab>proc.stdout.close()<tab>if proc.stderr is not None:<tab><tab>proc.stderr.close()<tab><IF-STMT><tab><tab>try:<tab><tab><tab>proc.terminate()<tab><tab>except:<tab><tab><tab>if proc.returncode is None:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>proc.kill()<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass,1,if proc . returncode is None :,if proc . returncode is None :,0.75,100,1
"def decorated_function(*args, **kwargs):<tab>rv = f(*args, **kwargs)<tab>if isinstance(rv, flask.Response):<tab><tab>try:<tab><tab><tab>result = etag<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = result(rv)<tab><tab><tab>if result:<tab><tab><tab><tab>rv.set_etag(result)<tab><tab>except Exception:<tab><tab><tab>logging.getLogger(__name__).exception(<tab><tab><tab><tab>""Error while calculating the etag value for response {!r}"".format(rv)<tab><tab><tab>)<tab>return rv",1,if callable ( result ) :,if callable ( result ) :,0.75,100,1
"def _list_shape_iter(shape):<tab>last_shape = _void<tab>for item in shape:<tab><tab>if item is Ellipsis:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""invalid shape spec: Ellipsis cannot be the"" ""first element""<tab><tab><tab><tab>)<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_shape<tab><tab>last_shape = item<tab><tab>yield item",1,if last_shape is _void :,if last_shape is _void :,0.75,100,1
"def delete_oidc_session_tokens(session):<tab>if session:<tab><tab><IF-STMT><tab><tab><tab>del session[""oidc_access_token""]<tab><tab>if ""oidc_id_token"" in session:<tab><tab><tab>del session[""oidc_id_token""]<tab><tab>if ""oidc_id_token_expiration"" in session:<tab><tab><tab>del session[""oidc_id_token_expiration""]<tab><tab>if ""oidc_login_next"" in session:<tab><tab><tab>del session[""oidc_login_next""]<tab><tab>if ""oidc_refresh_token"" in session:<tab><tab><tab>del session[""oidc_refresh_token""]<tab><tab>if ""oidc_state"" in session:<tab><tab><tab>del session[""oidc_state""]",1,"if ""oidc_access_token"" in session :","if ""oidc_access_token"" in session :",0.75,100,1
"def calc_parity(sig, kind):<tab>if kind in (""zero"", ""none""):<tab><tab>return C(0, 1)<tab>elif kind == ""one"":<tab><tab>return C(1, 1)<tab>else:<tab><tab>bits, _ = value_bits_sign(sig)<tab><tab>even_parity = sum([sig[b] for b in range(bits)]) & 1<tab><tab>if kind == ""odd"":<tab><tab><tab>return ~even_parity<tab><tab><IF-STMT><tab><tab><tab>return even_parity<tab><tab>else:<tab><tab><tab>assert False",1,"elif kind == ""even"" :","elif kind == ""even"" :",1,100,1
"def parse_cookies(cookies_headers):<tab>parsed = {}<tab>for cookie in cookies_headers:<tab><tab>cookie = cookie.split("";"")<tab><tab>for c in cookie:<tab><tab><tab>(name, value) = c.split(""="", 1)<tab><tab><tab>name = name.strip()<tab><tab><tab>value = value.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>parsed[name] = value<tab>return parsed",0,if name . lower ( ) in _SPECIAL_COOKIE_NAMES :,"if name == """" or value == """" :",0.029848275,6.330984179,0.428571429
"def search_rotate(array, val):<tab>low, high = 0, len(array) - 1<tab>while low <= high:<tab><tab>mid = (low + high) // 2<tab><tab>if val == array[mid]:<tab><tab><tab>return mid<tab><tab><IF-STMT><tab><tab><tab>if array[low] <= val <= array[mid]:<tab><tab><tab><tab>high = mid - 1<tab><tab><tab>else:<tab><tab><tab><tab>low = mid + 1<tab><tab>else:<tab><tab><tab>if array[mid] <= val <= array[high]:<tab><tab><tab><tab>low = mid + 1<tab><tab><tab>else:<tab><tab><tab><tab>high = mid - 1<tab>return -1",0,if array [ low ] <= array [ mid ] :,elif mid < len ( array ) - 1 :,0.012022606,4.858514172,0.208333333
"def _get_instance_attribute(<tab>self, attr, default=None, defaults=None, incl_metadata=False):<tab>if self.instance is None or not hasattr(self.instance, attr):<tab><tab><IF-STMT><tab><tab><tab>return self.parsed_metadata[attr]<tab><tab>elif defaults is not None:<tab><tab><tab>for value in defaults:<tab><tab><tab><tab>if callable(value):<tab><tab><tab><tab><tab>value = value()<tab><tab><tab><tab>if value is not None:<tab><tab><tab><tab><tab>return value<tab><tab>return default<tab>return getattr(self.instance, attr)",0,if incl_metadata and attr in self . parsed_metadata :,if attr in self . parsed_metadata :,0.532596056,57.00989414,0.314814815
"def _handle_rate_limit(<tab>self, exception: RedditAPIException) -> Optional[Union[int, float]]:<tab>for item in exception.items:<tab><tab><IF-STMT><tab><tab><tab>amount_search = self._ratelimit_regex.search(item.message)<tab><tab><tab>if not amount_search:<tab><tab><tab><tab>break<tab><tab><tab>seconds = int(amount_search.group(1))<tab><tab><tab>if ""minute"" in amount_search.group(2):<tab><tab><tab><tab>seconds *= 60<tab><tab><tab>if seconds <= int(self.config.ratelimit_seconds):<tab><tab><tab><tab>sleep_seconds = seconds + min(seconds / 10, 1)<tab><tab><tab><tab>return sleep_seconds<tab>return None",0,"if item . error_type == ""RATELIMIT"" :",if item . message :,0.094532291,10.53676785,0.722222222
"def _split_values(self, value):<tab># do the regex mojo here<tab>if not self.allowed_values:<tab><tab>return ("""",)<tab>try:<tab><tab>r = re.compile(self.allowed_values)<tab>except:<tab><tab>print(self.allowed_values, file=sys.stderr)<tab><tab>raise<tab>s = str(value)<tab>i = 0<tab>vals = []<tab>while True:<tab><tab>m = r.search(s[i:])<tab><tab>if m is None:<tab><tab><tab>break<tab><tab>vals.append(m.group())<tab><tab>delimiter = s[i : i + m.start()]<tab><tab><IF-STMT><tab><tab><tab>self.delimiter = delimiter<tab><tab>i += m.end()<tab>return tuple(vals)",0,"if self . delimiter is None and delimiter != """" :",if delimiter != self . delimiter :,0.092399608,19.88502416,0.246753247
"def render(self, mode=""none""):<tab>""""""Renders the environment via matplotlib.""""""<tab>if mode == ""log"":<tab><tab>self.logger.info(""Performance: "" + str(self._portfolio.performance))<tab>elif mode == ""chart"":<tab><tab><IF-STMT><tab><tab><tab>raise NotImplementedError()<tab><tab>self.viewer.render(<tab><tab><tab>self.clock.step - 1, self._portfolio.performance, self._broker.trades<tab><tab>)",0,if self . viewer is None :,if self . _broker . traades is None :,0.219654482,26.26909894,0.714285714
"def load_vocabulary(vocab_file):<tab>with open(vocab_file, ""r"") as f:<tab><tab>vocabulary = []<tab><tab>for line in f:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = line.split("" "")[0]<tab><tab><tab>vocabulary.append(line)<tab><tab>return vocabulary",1,"if "" "" in line :","if "" "" in line :",0.75,100,1
"def test_confirm_extension_is_yml(self):<tab>files_with_incorrect_extensions = []<tab>for file in self.yield_next_rule_file_path(self.path_to_rules):<tab><tab>file_name_and_extension = os.path.splitext(file)<tab><tab>if len(file_name_and_extension) == 2:<tab><tab><tab>extension = file_name_and_extension[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>files_with_incorrect_extensions.append(file)<tab>self.assertEqual(<tab><tab>files_with_incorrect_extensions,<tab><tab>[],<tab><tab>Fore.RED + ""There are rule files with extensions other than .yml"",<tab>)",0,"if extension != "".yml"" :","if extension == "".yml"" :",0.331415021,66.06328636,1
"def diff_from_indeces(self, indeces):<tab>rgroups = []<tab>with self._lock:<tab><tab>for i in indeces:<tab><tab><tab>rgroup = self.events[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rgroups.append(rgroup)<tab>return ""\n"".join(rgroup.diff for rgroup in rgroups)",0,"if isinstance ( rgroup , findlib2 . ReplaceHitGroup ) :",if rgroup . diff is not None :,0.015805905,6.082317173,0.188888889
"def deep_update(config, override_config):<tab>for k, v in override_config.items():<tab><tab>if isinstance(v, Mapping):<tab><tab><tab>k_config = config.get(k, {})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v_config = deep_update(k_config, v)<tab><tab><tab><tab>config[k] = v_config<tab><tab><tab>else:<tab><tab><tab><tab>config[k] = v<tab><tab>else:<tab><tab><tab>config[k] = override_config[k]<tab>return config",0,"if isinstance ( k_config , Mapping ) :","if isinstance ( k_config , dict ) :",0.549040681,70.71067812,0.6
"def GetBoundingBoxMin(self):<tab>""""""Get the minimum bounding box.""""""<tab>x1, y1 = 10000, 10000<tab>x2, y2 = -10000, -10000<tab>for point in self._lineControlPoints:<tab><tab>if point[0] < x1:<tab><tab><tab>x1 = point[0]<tab><tab><IF-STMT><tab><tab><tab>y1 = point[1]<tab><tab>if point[0] > x2:<tab><tab><tab>x2 = point[0]<tab><tab>if point[1] > y2:<tab><tab><tab>y2 = point[1]<tab>return x2 - x1, y2 - y1",1,if point [ 1 ] < y1 :,if point [ 1 ] < y1 :,0.75,100,1
"def insertChars(self, chars):<tab>tc = self.editBoxes[self.ind].textCursor()<tab>if tc.hasSelection():<tab><tab>selection = tc.selectedText()<tab><tab><IF-STMT><tab><tab><tab>if len(selection) > 2 * len(chars):<tab><tab><tab><tab>selection = selection[len(chars) : -len(chars)]<tab><tab><tab><tab>tc.insertText(selection)<tab><tab>else:<tab><tab><tab>tc.insertText(chars + tc.selectedText() + chars)<tab>else:<tab><tab>tc.insertText(chars)",0,if selection . startswith ( chars ) and selection . endswith ( chars ) :,if selection :,0.010227354,1.00E-10,0.338095238
"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",0,if sty . strikeout :,"if not fragment . startswith ( ""#"" ) :",0.026752541,4.932351569,0.272727273
"def mFEBRUARY(<tab>self,):<tab>try:<tab><tab>_type = FEBRUARY<tab><tab>_channel = DEFAULT_CHANNEL<tab><tab>pass<tab><tab>self.match(""feb"")<tab><tab>alt14 = 2<tab><tab>LA14_0 = self.input.LA(1)<tab><tab><IF-STMT><tab><tab><tab>alt14 = 1<tab><tab>if alt14 == 1:<tab><tab><tab>pass<tab><tab><tab>self.match(""ruary"")<tab><tab>self._state.type = _type<tab><tab>self._state.channel = _channel<tab>finally:<tab><tab>pass",0,if LA14_0 == 114 :,if LA14_0 == 101 :,0.394778655,70.71067812,0.5
"def test_calendar(self):<tab>subreddit = self.reddit.subreddit(pytest.placeholders.test_subreddit)<tab>widgets = subreddit.widgets<tab>with self.use_cassette(""TestSubredditWidgets.fetch_widgets""):<tab><tab>calendar = None<tab><tab>for widget in widgets.sidebar:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>calendar = widget<tab><tab><tab><tab>break<tab><tab>assert isinstance(calendar, Calendar)<tab><tab>assert calendar == calendar<tab><tab>assert calendar.id == calendar<tab><tab>assert calendar in widgets.sidebar<tab><tab>assert isinstance(calendar.configuration, dict)<tab><tab>assert hasattr(calendar, ""requiresSync"")<tab><tab>assert subreddit == calendar.subreddit",0,"if isinstance ( widget , Calendar ) :",if widget . configuration == dict :,0.019627455,7.267884212,0.285714286
"def count(num):<tab>cnt = 0<tab>for i in range(num):<tab><tab>try:<tab><tab><tab>if i % 2:<tab><tab><tab><tab>raise ValueError<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ArithmeticError(""1"")<tab><tab>except Exception as e:<tab><tab><tab>cnt += 1<tab>return cnt",1,if i % 3 :,if i % 3 :,0.75,100,1
"def pop(self):<tab>""""""Pop a nonterminal.  (Internal)""""""<tab>popdfa, popstate, popnode = self.stack.pop()<tab>newnode = self.convert(self.grammar, popnode)<tab>if newnode is not None:<tab><tab><IF-STMT><tab><tab><tab>dfa, state, node = self.stack[-1]<tab><tab><tab>node[-1].append(newnode)<tab><tab>else:<tab><tab><tab>self.rootnode = newnode<tab><tab><tab>try:<tab><tab><tab><tab>self.rootnode.used_names = self.used_names<tab><tab><tab>except AttributeError:<tab><tab><tab><tab># Don't need this hack?<tab><tab><tab><tab>pass",0,if self . stack :,if len ( self . stack ) > 0 :,0.105205398,17.74740528,0.305555556
"def handle_custom_actions(self):<tab>for _, action in CustomAction.registry.items():<tab><tab>if action.resource != self.resource:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.parser.add_parser(action.action, help="""")<tab><tab>action(self.page).add_arguments(self.parser, self)",0,if action . action not in self . parser . choices :,if action . action :,0.139715605,17.43703854,0.326923077
"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(self.agent_url, timeout=1).json().get(""config"", {})<tab><tab><tab>if ""Version"" in resp:<tab><tab><tab><tab>meta[""nomad_version""] = resp.get(""Version"")<tab><tab><tab>if ""Region"" in resp:<tab><tab><tab><tab>meta[""nomad_region""] = resp.get(""Region"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>meta[""nomad_datacenter""] = resp.get(""Datacenter"")<tab><tab>except Exception as ex:<tab><tab><tab>self.log.debug(""Error getting Nomad version: %s"" % str(ex))<tab>return meta",1,"if ""Datacenter"" in resp :","if ""Datacenter"" in resp :",0.75,100,1
"def _source_tuple(af, address, port):<tab># Make a high level source tuple, or return None if address and port<tab># are both None<tab>if address or port:<tab><tab>if address is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>address = ""0.0.0.0""<tab><tab><tab>elif af == socket.AF_INET6:<tab><tab><tab><tab>address = ""::""<tab><tab><tab>else:<tab><tab><tab><tab>raise NotImplementedError(f""unknown address family {af}"")<tab><tab>return (address, port)<tab>else:<tab><tab>return None",1,if af == socket . AF_INET :,if af == socket . AF_INET :,0.75,100,1
"def _evoke_request(cls):<tab>succeed = False<tab>with cls.LOCK:<tab><tab>if len(cls.REQUESTING_STACK) > 0:<tab><tab><tab>resource, request_semaphore = cls.REQUESTING_STACK.pop()<tab><tab><tab>node = cls.check_availability(resource)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cls.NODE_RESOURCE_MANAGER[node]._request(node, resource)<tab><tab><tab><tab>logger.debug(""\nEvoking requesting resource {}"".format(resource))<tab><tab><tab><tab>request_semaphore.release()<tab><tab><tab><tab>succeed = True<tab><tab><tab>else:<tab><tab><tab><tab>cls.REQUESTING_STACK.append((resource, request_semaphore))<tab><tab><tab><tab>return<tab>if succeed:<tab><tab>cls._evoke_request()",0,if node is not None :,if node in cls . NODE_RESOURCE_MANAGER :,0.195308626,8.295193507,0.35
"def update_all_rhos(instances, scenario_tree, rho_value=None, rho_scale=None):<tab>assert not ((rho_value is not None) and (rho_scale is not None))<tab>for stage in scenario_tree._stages[:-1]:<tab><tab>for tree_node in stage._tree_nodes:<tab><tab><tab>for scenario in tree_node._scenarios:<tab><tab><tab><tab>rho = scenario._rho[tree_node._name]<tab><tab><tab><tab>for variable_id in tree_node._variable_ids:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>rho[variable_id] = rho_value<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>rho[variable_id] *= rho_scale",0,if rho_value is not None :,if variable_id not in rho :,0.278043015,8.257910795,0.285714286
"def configured_request_log_handlers(config, prefix=""query_log"", default_logger=None):<tab>""""""Returns configured query loggers as defined in the `config`.""""""<tab>handlers = []<tab>for section in config.sections():<tab><tab><IF-STMT><tab><tab><tab>options = dict(config.items(section))<tab><tab><tab>type_ = options.pop(""type"")<tab><tab><tab>if type_ == ""default"":<tab><tab><tab><tab>logger = default_logger or get_logger()<tab><tab><tab><tab>handler = ext.request_log_handler(""default"", logger)<tab><tab><tab>else:<tab><tab><tab><tab>handler = ext.request_log_handler(type_, **options)<tab><tab><tab>handlers.append(handler)<tab>return handlers",1,if section . startswith ( prefix ) :,if section . startswith ( prefix ) :,0.75,100,1
"def eval_dummy_genomes_ctrnn_bad(genomes, config):<tab>for genome_id, genome in genomes:<tab><tab>net = neat.ctrnn.CTRNN.create(genome, config, 0.01)<tab><tab>net.advance([0.5, 0.5, 0.5], 0.01, 0.05)<tab><tab><IF-STMT><tab><tab><tab>genome.fitness = 0.0<tab><tab>else:<tab><tab><tab>net.reset()<tab><tab><tab>genome.fitness = 1.0",0,if genome_id <= 150 :,if genome_id == 0 :,0.314978772,38.26029416,0.5
"def housenumber(self):<tab>if self.street:<tab><tab>expression = r""\d+""<tab><tab>pattern = re.compile(expression)<tab><tab>match = pattern.search(self.street, re.UNICODE)<tab><tab><IF-STMT><tab><tab><tab>return match.group(0)",1,if match :,if match :,0.531170663,1.00E-10,1
"def func():<tab>end_received = False<tab>while True:<tab><tab>for idx, q in enumerate(self._local_out_queues):<tab><tab><tab>data = q.get()<tab><tab><tab>q.task_done()<tab><tab><tab>if isinstance(data, EndSignal):<tab><tab><tab><tab>end_received = True<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>self._out_queue.put(data)<tab><tab>if end_received:<tab><tab><tab>break",0,if idx > 0 :,if idx >= len ( self . _local_out_queues ) :,0.045891393,9.782375749,0.487179487
"def spin():<tab>""""""Wheeeee!""""""<tab>state = 0<tab>states = random.choice(spinners.spinners)<tab>while True:<tab><tab>prefix = ""[%s] "" % _spinner_style(states[state])<tab><tab>spinner_handle.update(prefix)<tab><tab>state = (state + 1) % len(states)<tab><tab><IF-STMT><tab><tab><tab>break",0,if stop . wait ( 0.1 ) :,if state >= len ( states ) :,0.036228951,11.33958222,0.26984127
"def _format_ip_address(container_group):<tab>""""""Format IP address.""""""<tab>ip_address = container_group.get(""ipAddress"")<tab>if ip_address:<tab><tab>ports = ip_address[""ports""] or []<tab><tab><IF-STMT><tab><tab><tab>for container in container_group.get(""containers""):<tab><tab><tab><tab>ports += container.get(""ports"")<tab><tab>ports = "","".join(str(p[""port""]) for p in ports)<tab><tab>return ""{0}:{1}"".format(ip_address.get(""ip""), ports)<tab>return None",0,"if ip_address [ ""type"" ] == ""Private"" :","if container_group . get ( ""containers"" ) :",0.018078277,3.943844445,0.641025641
"def check(self, count, count_v, enable, clock, reset, n):<tab>expect = 0<tab>yield reset.posedge<tab>self.assertEqual(count, expect)<tab>self.assertEqual(count, count_v)<tab>while 1:<tab><tab>yield clock.posedge<tab><tab><IF-STMT><tab><tab><tab>if expect == -n:<tab><tab><tab><tab>expect = n - 1<tab><tab><tab>else:<tab><tab><tab><tab>expect -= 1<tab><tab>yield delay(1)<tab><tab># print ""%d count %s expect %s count_v %s"" % (now(), count, expect, count_v)<tab><tab>self.assertEqual(count, expect)<tab><tab>self.assertEqual(count, count_v)",1,if enable :,if enable :,0.531170663,1.00E-10,1
"def _to_str(self, tokens: List[int]) -> str:<tab>pos = next(<tab><tab>(idx for idx, x in enumerate(tokens) if x == self.vocab.eos_token_id), -1<tab>)<tab>if pos != -1:<tab><tab>tokens = tokens[:pos]<tab>vocab_map = self.vocab.id_to_token_map_py<tab>words = [vocab_map[t] for t in tokens]<tab>if self.encoding is not None and self.perform_decode:<tab><tab>if self.encoding == ""bpe"":<tab><tab><tab>words = self.bpe_decode(words)<tab><tab><IF-STMT><tab><tab><tab>words = self.spm_decode(words)<tab>sentence = "" "".join(words)<tab>return sentence",1,"elif self . encoding == ""spm"" :","elif self . encoding == ""spm"" :",1,100,1
"def _iterate_files(self, files, root, include_checksums, relpath):<tab>file_list = {}<tab>for file in files:<tab><tab>exclude = False<tab><tab># exclude defined filename patterns<tab><tab>for pattern in S3Sync.exclude_files:<tab><tab><tab>if fnmatch.fnmatch(file, pattern):<tab><tab><tab><tab>exclude = True<tab><tab><tab><tab>break<tab><tab>if not exclude:<tab><tab><tab>full_path = root + ""/"" + file<tab><tab><tab><IF-STMT><tab><tab><tab><tab># get checksum<tab><tab><tab><tab>checksum = self._hash_file(full_path)<tab><tab><tab>else:<tab><tab><tab><tab>checksum = """"<tab><tab><tab>file_list[relpath + file] = [full_path, checksum]<tab>return file_list",1,if include_checksums :,if include_checksums :,0.531170663,1.00E-10,1
"def render(self, context):<tab>if self.user is None:<tab><tab>entries = LogEntry.objects.all()<tab>else:<tab><tab>user_id = self.user<tab><tab><IF-STMT><tab><tab><tab>user_id = context[self.user].pk<tab><tab>entries = LogEntry.objects.filter(user__pk=user_id)<tab>context[self.varname] = entries.select_related(""content_type"", ""user"")[<tab><tab>: int(self.limit)<tab>]<tab>return """"",0,if not user_id . isdigit ( ) :,if self . user in context :,0.019627455,6.050259138,0.21875
"def pin_data_keys(self, session_id, data_keys, token, devices=None):<tab>if not devices:<tab><tab>devices = functools.reduce(<tab><tab><tab>operator.or_,<tab><tab><tab>self._manager_ref.get_data_locations(session_id, data_keys),<tab><tab><tab>set(),<tab><tab>)<tab>else:<tab><tab>devices = self._normalize_devices(devices)<tab>pinned = set()<tab>for dev in devices:<tab><tab>handler = self.get_storage_handler(dev)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>keys = handler.pin_data_keys(session_id, data_keys, token)<tab><tab>pinned.update(keys)<tab>return list(pinned)",0,"if not getattr ( handler , ""_spillable"" , False ) :",if not handler :,0.021820195,3.118555561,0.476190476
"def resolve(self, value: Optional[T]) -> T:<tab>v: Optional[Any] = value<tab>if value is None:<tab><tab>t = os.environ.get(self.envvar)<tab><tab>if self.type is bool and t:<tab><tab><tab>v = t in [""true"", ""True"", ""1"", ""yes""]<tab><tab>elif self.type is str and t:<tab><tab><tab>v = t<tab><tab><IF-STMT><tab><tab><tab>v = ast.literal_eval(t) if t is not None else None<tab>if v is None:<tab><tab>v = self.default<tab>return v",0,elif t :,elif self . type is ast . literal :,0.036859563,1.00E-10,0.2
"def remove(self, *objs):<tab>val = getattr(instance, rel_field.rel.get_related_field().attname)<tab>for obj in objs:<tab><tab># Is obj actually part of this descriptor set?<tab><tab><IF-STMT><tab><tab><tab>setattr(obj, rel_field.name, None)<tab><tab><tab>obj.save()<tab><tab>else:<tab><tab><tab>raise rel_field.rel.to.DoesNotExist(<tab><tab><tab><tab>""%r is not related to %r."" % (obj, instance)<tab><tab><tab>)",0,"if getattr ( obj , rel_field . attname ) == val :",if obj . attname == val :,0.09906802,18.41662315,0.322222222
"def generate_segment_memory(chart_type, race_configs, environment):<tab>structures = []<tab>for race_config in race_configs:<tab><tab>if ""segment_memory"" in race_config.charts:<tab><tab><tab>title = chart_type.format_title(<tab><tab><tab><tab>environment,<tab><tab><tab><tab>race_config.track,<tab><tab><tab><tab>es_license=race_config.es_license,<tab><tab><tab><tab>suffix=""%s-segment-memory"" % race_config.label,<tab><tab><tab>)<tab><tab><tab>chart = chart_type.segment_memory(title, environment, race_config)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>structures.append(chart)<tab>return structures",0,if chart :,if chart is not None :,0.090364769,1.00E-10,0.4
"def comment_multiline(self, text, delimiter_end, delimiter_start, style):<tab>""""""Process the beggining and end of a multiline comment.""""""<tab>startIndex = 0<tab>if self.previousBlockState() != 1:<tab><tab>startIndex = delimiter_start.indexIn(text)<tab>while startIndex >= 0:<tab><tab>endIndex = delimiter_end.indexIn(text, startIndex)<tab><tab>commentLength = 0<tab><tab><IF-STMT><tab><tab><tab>self.setCurrentBlockState(1)<tab><tab><tab>commentLength = len(text) - startIndex<tab><tab>else:<tab><tab><tab>commentLength = endIndex - startIndex + delimiter_end.matchedLength()<tab><tab>self.setFormat(startIndex, commentLength, style)<tab><tab>startIndex = delimiter_start.indexIn(text, startIndex + commentLength)",1,if endIndex == - 1 :,if endIndex == - 1 :,0.75,100,1
"def getLatestFile(self):<tab>highestNsp = None<tab>highestNsx = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab>if nsp.path.endswith("".nsx""):<tab><tab><tab><tab>if not highestNsx or int(nsp.version) > int(highestNsx.version):<tab><tab><tab><tab><tab>highestNsx = nsp<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>highestNsp = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highestNsp or highestNsx",1,if not highestNsp or int ( nsp . version ) > int ( highestNsp . version ) :,if not highestNsp or int ( nsp . version ) > int ( highestNsp . version ) :,1,100,1
"def handle(self, msg):<tab>self._mic.send(msg)<tab>for calculate_seed, make_delegate, dict in self._delegate_records:<tab><tab>id = calculate_seed(msg)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(id, collections.Hashable):<tab><tab><tab>if id not in dict or not dict[id].is_alive():<tab><tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab><tab>dict[id] = d<tab><tab><tab><tab>dict[id].start()<tab><tab>else:<tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab>d.start()",1,if id is None :,if id is None :,0.75,100,1
"def _build_pcf(named_sc, named_pc):<tab>r = """"<tab>for sig, pins, others, resname in named_sc:<tab><tab><IF-STMT><tab><tab><tab>for bit, pin in enumerate(pins):<tab><tab><tab><tab>r += ""set_io {}[{}] {}\n"".format(sig, bit, pin)<tab><tab>else:<tab><tab><tab>r += ""set_io {} {}\n"".format(sig, pins[0])<tab>if named_pc:<tab><tab>r += ""\n"" + ""\n\n"".join(named_pc)<tab>return r",1,if len ( pins ) > 1 :,if len ( pins ) > 1 :,0.75,100,1
"def __init__(self, profile, report_dir=None, timestamp=None):<tab># self.metadata = {}<tab>self.report_dir = report_dir if report_dir else DEFAULT_REPORT_DIR<tab>self.profile = profile.replace(""/"", ""_"").replace(""\\"", ""_"")  # Issue 111<tab>self.current_time = datetime.datetime.now(dateutil.tz.tzlocal())<tab>if timestamp != False:<tab><tab>self.timestamp = (<tab><tab><tab>self.current_time.strftime(""%Y-%m-%d_%Hh%M%z"")<tab><tab><tab><IF-STMT><tab><tab><tab>else timestamp<tab><tab>)",0,if not timestamp,if self . current_time,0.054453413,1.00E-10,0.333333333
"def _convert_params_to_v3(params):<tab>for k, v in OLD_TO_NEW_PARAMS.items():<tab><tab>if k in params:<tab><tab><tab>msg = Message.WARN_PARAMS_NOT_SUPPORTED % (k, v)<tab><tab><tab>warnings.warn(msg, DeprecationWarning)<tab><tab><tab># update to the new query param if not specified already<tab><tab><tab><IF-STMT><tab><tab><tab><tab>params[v] = params.pop(k)",0,if v not in params :,if v in params :,0.133190283,40.93653765,0.444444444
"def rollup_logical(counter, lookup, logical_keys):<tab>logical = Counter()<tab>for k, v in counter.items():<tab><tab># TODO: eek, do a fallback of some kind<tab><tab><IF-STMT><tab><tab><tab>logical[(""unknown"", k)] = v<tab><tab><tab>continue<tab><tab>linfo = lookup[k]<tab><tab>lkey = tuple(linfo.get(lk, ""unknown"") for lk in logical_keys)<tab><tab>logical[lkey] += v<tab>return logical",1,if k not in lookup :,if k not in lookup :,0.75,100,1
"def assert_summary_equals(self, records, tag, step, value):<tab>for record in records[1:]:<tab><tab>if record.summary.value[0].tag != tag:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.assertEqual(value, tf.make_ndarray(record.summary.value[0].tensor))<tab><tab>return<tab>self.fail(""Could not find record for tag {} and step {}"".format(tag, step))",1,if record . step != step :,if record . step != step :,1,100,1
"def get_name_from_types(types: Iterable[Union[Type, StrawberryUnion]]):<tab>names = []<tab>for type_ in types:<tab><tab>if isinstance(type_, StrawberryUnion):<tab><tab><tab>return type_.name<tab><tab><IF-STMT><tab><tab><tab>name = capitalize_first(type_._type_definition.name)<tab><tab>else:<tab><tab><tab>name = capitalize_first(type_.__name__)<tab><tab>names.append(name)<tab>return """".join(names)",1,"elif hasattr ( type_ , ""_type_definition"" ) :","elif hasattr ( type_ , ""_type_definition"" ) :",0.75,100,1
"def parseBamPEFDistributionFile(self, f):<tab>d = dict()<tab>lastsample = []<tab>for line in f[""f""].splitlines():<tab><tab>cols = line.rstrip().split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif cols[0] == ""Size"":<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>s_name = self.clean_s_name(cols[2].rstrip().split(""/"")[-1], f[""root""])<tab><tab><tab>if s_name != lastsample:<tab><tab><tab><tab>d[s_name] = dict()<tab><tab><tab><tab>lastsample = s_name<tab><tab><tab>d[s_name].update({self._int(cols[0]): self._int(cols[1])})<tab>return d",0,"if cols [ 0 ] == ""#bamPEFragmentSize"" :","if cols [ 0 ] == ""Name"" :",0.605621306,67.7470203,1
"def read_output(meteor_output_path, n_repeats):<tab>n_combinations = math.factorial(n_repeats) / (<tab><tab>math.factorial(2) * math.factorial(n_repeats - 2)<tab>)<tab>raw_scores = []<tab>average_scores = []<tab>for line in open(meteor_output_path):<tab><tab>if not line.startswith(""Segment ""):<tab><tab><tab>continue<tab><tab>score = float(line.strip().split(""\t"")[1])<tab><tab>raw_scores.append(score)<tab><tab><IF-STMT><tab><tab><tab>average_scores.append(sum(raw_scores) / n_combinations)<tab><tab><tab>raw_scores = []<tab>os.remove(meteor_output_path)<tab>return average_scores",0,if len ( raw_scores ) == n_combinations :,if len ( raw_scores ) >= n_combinations :,0.549040681,76.11606003,1
"def get_new_pids(self):<tab>if not self.need_poll():<tab><tab>return<tab>for process in psutil.process_iter():<tab><tab>info = process.as_dict([""create_time"", ""pid"", ""name"", ""exe""])<tab><tab>pid = info[""pid""]<tab><tab>if pid not in self.pids or self.pids[pid] == info[""create_time""]:<tab><tab><tab>for name in self.names:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield pid<tab><tab><tab><tab><tab>self.pids[pid] = info[""create_time""]",0,"if name . match ( info [ ""name"" ] ) or name . match ( info [ ""exe"" ] ) :","if name == info [ ""name"" ] :",0.121188496,14.97869662,0.417562724
"def _Attribute(self, node):<tab>if not isinstance(node.ctx, ast.Store):<tab><tab>scope = self.scope.get_inner_scope_for_line(node.lineno)<tab><tab>pyname = evaluate.eval_node(scope, node.value)<tab><tab><IF-STMT><tab><tab><tab>if node.attr not in pyname.get_object():<tab><tab><tab><tab>self._add_error(node, ""Unresolved attribute"")<tab>ast.walk(node.value, self)",0,if pyname is not None and pyname . get_object ( ) != pyobjects . get_unknown ( ) :,if pyname is not None :,0.199140568,4.677501827,0.692028986
def _init_neighbor(neighbor):<tab>families = neighbor.families()<tab>for change in neighbor.changes:<tab><tab>if change.nlri.family() in families:<tab><tab><tab># This add the family to neighbor.families()<tab><tab><tab>neighbor.rib.outgoing.add_to_rib_watchdog(change)<tab>for message in messages:<tab><tab>if message.family() in families:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>neighbor.asm[message.family()] = message<tab><tab><tab>else:<tab><tab><tab><tab>neighbor.messages.append(message)<tab>self.neighbors[neighbor.name()] = neighbor,0,"if message . name == ""ASM"" :",if message . name ( ) in families :,0.191332916,28.24099049,0.633333333
"def date_match(self, date1, date2):<tab>if date1.is_empty() or date2.is_empty():<tab><tab>return 0<tab>if date1.is_equal(date2):<tab><tab>return 1<tab>if date1.is_compound() or date2.is_compound():<tab><tab>return self.range_compare(date1, date2)<tab>if date1.get_year() == date2.get_year():<tab><tab><IF-STMT><tab><tab><tab>return 0.75<tab><tab>if not date1.get_month_valid() or not date2.get_month_valid():<tab><tab><tab>return 0.75<tab><tab>else:<tab><tab><tab>return -1<tab>else:<tab><tab>return -1",1,if date1 . get_month ( ) == date2 . get_month ( ) :,if date1 . get_month ( ) == date2 . get_month ( ) :,1,100,1
"def del_var_history(self, var, f=None, line=None):<tab>""""""If file f and line are not given, the entire history of var is deleted""""""<tab>if var in self.variables:<tab><tab><IF-STMT><tab><tab><tab>self.variables[var] = [<tab><tab><tab><tab>x for x in self.variables[var] if x[""file""] != f and x[""line""] != line<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>self.variables[var] = []",1,if f and line :,if f and line :,0.75,100,1
"def test_certs(self):<tab>self.assertTrue(len(self.regions) > 0)<tab>for region in self.regions:<tab><tab>special_access_required = False<tab><tab>for snippet in (""gov"", ""cn-""):<tab><tab><tab>if snippet in region.name:<tab><tab><tab><tab>special_access_required = True<tab><tab><tab><tab>break<tab><tab>try:<tab><tab><tab>c = region.connect()<tab><tab><tab>self.sample_service_call(c)<tab><tab>except:<tab><tab><tab># This is bad (because the SSL cert failed). Re-raise the<tab><tab><tab># exception.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",1,if not special_access_required :,if not special_access_required :,0.75,100,1
"def convert_encoder_layer(opus_dict, layer_prefix: str, converter: dict):<tab>sd = {}<tab>for k in opus_dict:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>stripped = remove_prefix(k, layer_prefix)<tab><tab>v = opus_dict[k].T  # besides embeddings, everything must be transposed.<tab><tab>sd[converter[stripped]] = torch.tensor(v).squeeze()<tab>return sd",0,if not k . startswith ( layer_prefix ) :,if k not in converter :,0.017951424,4.98864168,0.26984127
"def test_sequence(self, sequence):<tab>for test in sequence:<tab><tab><IF-STMT><tab><tab><tab>test, kwargs = test<tab><tab>else:<tab><tab><tab>kwargs = {}<tab><tab>self.do_check(test, **kwargs)<tab><tab>if test == ExpectedError:<tab><tab><tab>return False<tab>return True",1,"if isinstance ( test , tuple ) :","if isinstance ( test , tuple ) :",0.75,100,1
"def make_table(grid):<tab>max_cols = [<tab><tab>max(out)<tab><tab>for out in map(list, zip(*[[len(item) for item in row] for row in grid]))<tab>]<tab>rst = table_div(max_cols, 1)<tab>for i, row in enumerate(grid):<tab><tab>header_flag = False<tab><tab><IF-STMT><tab><tab><tab>header_flag = True<tab><tab>rst += normalize_row(row, max_cols)<tab><tab>rst += table_div(max_cols, header_flag)<tab>return rst",0,if i == 0 or i == len ( grid ) - 1 :,if i % 2 == 0 :,0.046889909,9.952652138,0.268518519
"def test_float_overflow(self):<tab>import sys<tab>big_int = int(sys.float_info.max) * 2<tab>for t in float_types + [c_longdouble]:<tab><tab>self.assertRaises(OverflowError, t, big_int)<tab><tab>if hasattr(t, ""__ctype_be__""):<tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_be__, big_int)<tab><tab><IF-STMT><tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_le__, big_int)",1,"if hasattr ( t , ""__ctype_le__"" ) :","if hasattr ( t , ""__ctype_le__"" ) :",0.75,100,1
"def _process_folder(config, folder, cache, output):<tab>if not os.path.isdir(folder):<tab><tab>raise ConanException(""No such directory: '%s'"" % str(folder))<tab>if config.source_folder:<tab><tab>folder = os.path.join(folder, config.source_folder)<tab>for root, dirs, files in walk(folder):<tab><tab>dirs[:] = [d for d in dirs if d != "".git""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for f in files:<tab><tab><tab>_process_file(root, f, config, cache, output, folder)",0,"if "".git"" in root :","if root . endswith ( "".git"" ) :",0.029323261,26.98553467,0.4
"def setChanged(self, c, changed):<tab># Find the tab corresponding to c.<tab>dw = c.frame.top  # A DynamicWindow<tab>i = self.indexOf(dw)<tab>if i < 0:<tab><tab>return<tab>s = self.tabText(i)<tab>s = g.u(s)<tab>if len(s) > 2:<tab><tab><IF-STMT><tab><tab><tab>if not s.startswith(""* ""):<tab><tab><tab><tab>title = ""* "" + s<tab><tab><tab><tab>self.setTabText(i, title)<tab><tab>else:<tab><tab><tab>if s.startswith(""* ""):<tab><tab><tab><tab>title = s[2:]<tab><tab><tab><tab>self.setTabText(i, title)",1,if changed :,if changed :,0.531170663,1.00E-10,1
"def dump_metrics(self):<tab>metrics = self._registry.dump_metrics()<tab># Filter out min and max if there have been no samples.<tab>for metric in metrics.itervalues():<tab><tab>if metric.get(""count"") == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>metric[""min""] = 0.0<tab><tab><tab>if ""max"" in metric:<tab><tab><tab><tab>metric[""max""] = 0.0<tab>return metrics",1,"if ""min"" in metric :","if ""min"" in metric :",0.75,100,1
"def ref_max_pooling_3d(x, kernel, stride, ignore_border, pad):<tab>y = []<tab>for xx in x.reshape((-1,) + x.shape[-4:]):<tab><tab><IF-STMT><tab><tab><tab>xx = xx[np.newaxis]<tab><tab>y += [<tab><tab><tab>refs.pooling_3d(xx, ""max"", kernel, stride, pad, ignore_border)[np.newaxis]<tab><tab>]<tab>y = np.vstack(y)<tab>if x.ndim == 3:<tab><tab>y = np.squeeze(y, 1)<tab>return y.reshape(x.shape[:-4] + y.shape[1:])",1,if xx . ndim == 3 :,if xx . ndim == 3 :,0.75,100,1
def reader_():<tab>with open(file_list) as flist:<tab><tab>lines = [line.strip() for line in flist]<tab><tab><IF-STMT><tab><tab><tab>random.shuffle(lines)<tab><tab>for line in lines:<tab><tab><tab>file_path = line.strip()<tab><tab><tab>yield [file_path],1,if shuffle :,if shuffle :,0.531170663,1.00E-10,1
"def _sql_like_to_regex(pattern, escape):<tab>cur_i = 0<tab>pattern_length = len(pattern)<tab>while cur_i < pattern_length:<tab><tab>nxt_i = cur_i + 1<tab><tab>cur = pattern[cur_i]<tab><tab>nxt = pattern[nxt_i] if nxt_i < pattern_length else None<tab><tab>skip = 1<tab><tab>if nxt is not None and escape is not None and cur == escape:<tab><tab><tab>yield nxt<tab><tab><tab>skip = 2<tab><tab>elif cur == ""%"":<tab><tab><tab>yield "".*""<tab><tab><IF-STMT><tab><tab><tab>yield "".""<tab><tab>else:<tab><tab><tab>yield cur<tab><tab>cur_i += skip",0,"elif cur == ""_"" :","elif cur == ""."" :",0.642872021,59.46035575,1
"def gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker=""sphere""):<tab>""""""Show N random gaussian distributed points using a scatter plot.""""""<tab>import ipyvolume as ipv<tab>rng = np.random.RandomState(seed)  # pylint: disable=no-member<tab>x, y, z = rng.normal(size=(3, N))<tab>if draw:<tab><tab><IF-STMT><tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker, color=color)<tab><tab>else:<tab><tab><tab>mesh = ipv.scatter(x, y, z, marker=marker)<tab><tab>if show:<tab><tab><tab># ipv.squarelim()<tab><tab><tab>ipv.show()<tab><tab>return mesh<tab>else:<tab><tab>return x, y, z",1,if color :,if color :,0.531170663,1.00E-10,1
"def _delete_keys(bucket, keys):<tab>for name in keys:<tab><tab>while True:<tab><tab><tab>try:<tab><tab><tab><tab>k = boto.s3.connection.Key(bucket, name)<tab><tab><tab><tab>bucket.delete_key(k)<tab><tab><tab>except boto.exception.S3ResponseError as e:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># Key is already not present.  Continue the<tab><tab><tab><tab><tab># deletion iteration.<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>break",1,if e . status == 404 :,if e . status == 404 :,0.75,100,1
"def detect(self):<tab>hardware = self.middleware.call_sync(""failover.hardware"")<tab>if hardware == ""ECHOSTREAM"":<tab><tab>proc = subprocess.check_output(<tab><tab><tab>'/usr/sbin/pciconf -lv | grep ""card=0xa01f8086 chip=0x10d38086""',<tab><tab><tab>shell=True,<tab><tab><tab>encoding=""utf8"",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return [proc.split(""@"")[0]]<tab>if hardware in (""ECHOWARP"", ""PUMA""):<tab><tab>return [""ntb0""]<tab>if hardware == ""BHYVE"":<tab><tab>return [""vtnet1""]<tab>if hardware == ""SBB"":<tab><tab>return [""ix0""]<tab>if hardware == ""ULTIMATE"":<tab><tab>return [""igb1""]<tab>return []",1,if proc :,if proc :,0.531170663,1.00E-10,1
"def check_config(param):<tab>fileopen = open(""/etc/setoolkit/set.config"", ""r"")<tab>for line in fileopen:<tab><tab>line = line.rstrip()<tab><tab># print line<tab><tab># if the line starts with the param we want then we are set, otherwise<tab><tab># if it starts with a # then ignore<tab><tab>if line.startswith(param) != ""#"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>line = line.rstrip()<tab><tab><tab><tab># remove any quotes or single quotes<tab><tab><tab><tab>line = line.replace('""', """")<tab><tab><tab><tab>line = line.replace(""'"", """")<tab><tab><tab><tab>line = line.split(""="", 1)<tab><tab><tab><tab>return line[1]",1,if line . startswith ( param ) :,if line . startswith ( param ) :,0.75,100,1
"def put(self, s):<tab>""""""Put string s to self.outputFile. All output eventually comes here.""""""<tab># Improved code: self.outputFile (a cStringIO object) always exists.<tab>if s:<tab><tab>self.putCount += 1<tab><tab><IF-STMT><tab><tab><tab>s = g.toEncodedString(s, self.leo_file_encoding, reportErrors=True)<tab><tab>self.outputFile.write(s)",0,if not g . isPython3 :,if self . leo_file_encoding :,0.029084143,6.274655311,0.277777778
"def get_system_prop_font(self):<tab>""""""Look up the system font""""""<tab>if self.system_prop_font is not None:<tab><tab>return self.system_prop_font<tab>elif ""org.gnome.desktop.interface"" not in Gio.Settings.list_schemas():<tab><tab>return<tab>else:<tab><tab>gsettings = Gio.Settings.new(""org.gnome.desktop.interface"")<tab><tab>value = gsettings.get_value(""font-name"")<tab><tab><IF-STMT><tab><tab><tab>self.system_prop_font = value.get_string()<tab><tab>else:<tab><tab><tab>self.system_prop_font = ""Sans 10""<tab><tab>return self.system_prop_font",1,if value :,if value :,0.531170663,1.00E-10,1
"def _setoct(self, octstring):<tab>""""""Reset the bitstring to have the value given in octstring.""""""<tab>octstring = tidy_input_string(octstring)<tab># remove any 0o if present<tab>octstring = octstring.replace(""0o"", """")<tab>binlist = []<tab>for i in octstring:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError<tab><tab><tab>binlist.append(OCT_TO_BITS[int(i)])<tab><tab>except ValueError:<tab><tab><tab>raise CreationError(""Invalid symbol '{0}' in oct initialiser."", i)<tab>self._setbin_unsafe("""".join(binlist))",0,if not 0 <= int ( i ) < 8 :,if int ( i ) not in OCT_TO_BITS :,0.175636333,22.2424694,0.238636364
"def group(self, resources):<tab>groups = {}<tab>for r in resources:<tab><tab>v = self._value_to_sort(self.group_by, r)<tab><tab>vstr = str(v)<tab><tab><IF-STMT><tab><tab><tab>groups[vstr] = {""sortkey"": v, ""resources"": []}<tab><tab>groups[vstr][""resources""].append(r)<tab>return groups",1,if vstr not in groups :,if vstr not in groups :,0.75,100,1
"def rd(line_number, row, col, key, default=None):<tab>""""""Return Row data by column name""""""<tab>if key in col:<tab><tab>if col[key] >= len(row):<tab><tab><tab>LOG.warning(""missing '%s, on line %d"" % (key, line_number))<tab><tab><tab>return default<tab><tab>retval = row[col[key]].strip()<tab><tab><IF-STMT><tab><tab><tab>return default<tab><tab>else:<tab><tab><tab>return retval<tab>else:<tab><tab>return default",1,"if retval == """" :","if retval == """" :",0.75,100,1
"def _run(self):<tab>while True:<tab><tab>tup = self._pop()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>method_name, kwargs, msg = tup<tab><tab>try:<tab><tab><tab>super(SerializedInvoker, self).invoke(method_name, kwargs, msg)<tab><tab>except mitogen.core.CallError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>LOG.warning(""%r: call error: %s: %s"", self, msg, e)<tab><tab><tab>msg.reply(e)<tab><tab>except Exception:<tab><tab><tab>LOG.exception(""%r: while invoking %s()"", self, method_name)<tab><tab><tab>msg.reply(mitogen.core.Message.dead())",1,if tup is None :,if tup is None :,0.75,100,1
"def raises(except_cls, message=None):<tab>try:<tab><tab>yield<tab><tab>success = False<tab>except except_cls as e:<tab><tab><IF-STMT><tab><tab><tab>assert re.search(message, compat.text_type(e), re.UNICODE), ""%r !~ %s"" % (<tab><tab><tab><tab>message,<tab><tab><tab><tab>e,<tab><tab><tab>)<tab><tab><tab>print(compat.text_type(e).encode(""utf-8""))<tab><tab>success = True<tab># assert outside the block so it works for AssertionError too !<tab>assert success, ""Callable did not raise an exception""",1,if message :,if message :,0.531170663,1.00E-10,1
"def buttonClicked(self, button):<tab>role = self.buttonBox.buttonRole(button)<tab>if role == QDialogButtonBox.ResetRole:<tab><tab>current_tab = self.tabwidget.currentWidget()<tab><tab>section_to_update = Sections.ALL<tab><tab>if current_tab is self.page_general:<tab><tab><tab>section_to_update = Sections.GENERAL<tab><tab><IF-STMT><tab><tab><tab>section_to_update = Sections.DISPLAY<tab><tab>self.resetToDefaults(section_to_update)",0,if current_tab is self . page_display :,elif current_tab is self . page_display :,0.466274232,89.31539818,0.6
"def make_range_list(*values):<tab>ranges = []<tab>for v in values:<tab><tab><IF-STMT><tab><tab><tab>val_node = plural.value_node(v)<tab><tab><tab>ranges.append((val_node, val_node))<tab><tab>else:<tab><tab><tab>assert isinstance(v, tuple)<tab><tab><tab>ranges.append((plural.value_node(v[0]), plural.value_node(v[1])))<tab>return plural.range_list_node(ranges)",0,"if isinstance ( v , int ) :","if isinstance ( v , plural . range ) :",0.252903722,45.18010018,0.558441558
"def __in_comment(self):<tab>if self.highlighter:<tab><tab>current_color = self.__get_current_color()<tab><tab>comment_color = self.highlighter.get_color_name(""comment"")<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>return False",1,if current_color == comment_color :,if current_color == comment_color :,0.75,100,1
"def __str__(self):<tab>""""""Constructs to variable list output used in cron jobs""""""<tab>ret = []<tab>for key, value in self.items():<tab><tab>if self.previous:<tab><tab><tab>if self.previous.all().get(key, None) == value:<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>value = '""%s""' % value<tab><tab>ret.append(""%s=%s"" % (key, unicode(value)))<tab>ret.append("""")<tab>return ""\n"".join(ret)",0,"if "" "" in unicode ( value ) or value == """" :","if isinstance ( value , six . string_types ) :",0.021581897,6.632729312,0.234375
"def _on_config_changed(changed_name: str) -> None:<tab>""""""Call config_changed hooks if the config changed.""""""<tab>for mod_info in _module_infos:<tab><tab>if mod_info.skip_hooks:<tab><tab><tab>continue<tab><tab>for option, hook in mod_info.config_changed_hooks:<tab><tab><tab>if option is None:<tab><tab><tab><tab>hook()<tab><tab><tab>else:<tab><tab><tab><tab>cfilter = config.change_filter(option)<tab><tab><tab><tab>cfilter.validate()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>hook()",0,if cfilter . check_match ( changed_name ) :,if cfilter is not None :,0.035264605,6.609029796,0.444444444
"def __init__(self, transcripts, vocab=None, unknown=None, *args, **kwargs):<tab>""""""Creates a new raw transcript source.""""""<tab>super().__init__(*args, **kwargs)<tab>self.transcripts = transcripts<tab>self.indices = numpy.arange(len(self))<tab>self.vocab = self.make_vocab(vocab)<tab>if unknown is None:<tab><tab>self.unknown = self.unknown_index = None<tab>else:<tab><tab>self.unknown_index = self.vocab.get(unknown)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>'The ""unknown"" vocabulary word must be '<tab><tab><tab><tab>""part of the vocabulary itself.""<tab><tab><tab>)<tab><tab>self.unknown = unknown",1,if self . unknown_index is None :,if self . unknown_index is None :,0.75,100,1
"def load_info(cls, path, reset_paths=False, load_model_if_required=True):<tab>load_path = path + cls.trainer_info_name<tab>try:<tab><tab>return load_pkl.load(path=load_path)<tab>except:<tab><tab><IF-STMT><tab><tab><tab>trainer = cls.load(path=path, reset_paths=reset_paths)<tab><tab><tab>return trainer.get_info()<tab><tab>else:<tab><tab><tab>raise",1,if load_model_if_required :,if load_model_if_required :,0.531170663,1.00E-10,1
"def createActions(actions, target):<tab># actions = [(name, shortcut, icon, desc, func)]<tab>for name, shortcut, icon, desc, func in actions:<tab><tab>action = QAction(target)<tab><tab><IF-STMT><tab><tab><tab>action.setIcon(icon)<tab><tab>if shortcut:<tab><tab><tab>action.setShortcut(shortcut)<tab><tab>action.setText(desc)<tab><tab>action.triggered.connect(func)<tab><tab>setattr(target, name, action)",1,if icon :,if icon :,0.531170663,1.00E-10,1
"def load_user_logins(self, key, dates, timestamps, size_threshold=None):<tab>date_bucket = {}<tab>for user_data in self.fetch_user_table():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># note: ts should already be utc!<tab><tab>dt = datetime.fromtimestamp(user_data[6] / 1000)<tab><tab>dt = dt.date().isoformat()<tab><tab>date_bucket[dt] = date_bucket.get(dt, 0) + 1<tab>datapoints = []<tab>for dt, ts in zip(dates, timestamps):<tab><tab>count = date_bucket.get(dt, 0)<tab><tab>datapoints.append((count, ts))<tab>return {""target"": key, ""datapoints"": datapoints}",0,if size_threshold is not None and user_data [ 1 ] < size_threshold :,if size_threshold and len ( user_data ) < 7 :,0.16125412,19.66782398,0.208333333
def apply_batch(it):<tab>batch = []<tab>for item in it:<tab><tab><IF-STMT><tab><tab><tab>yield item<tab><tab>else:<tab><tab><tab>batch.append(item)<tab><tab><tab>if len(batch) >= n:<tab><tab><tab><tab>yield batch<tab><tab><tab><tab>batch = []<tab>if batch:<tab><tab>yield batch,0,"if isinstance ( item , _NextValueNotReady ) :",if len ( batch ) >= n :,0.020373037,6.74255593,0.26984127
"def convert_tomlkit_table(section):<tab>if isinstance(section, tomlkit.items.Table):<tab><tab>body = section.value._body<tab>else:<tab><tab>body = section._body<tab>for key, value in body:<tab><tab>if not key:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>table = tomlkit.inline_table()<tab><tab><tab>table.update(value.value)<tab><tab><tab>section[key.key] = table",0,"if hasattr ( value , ""keys"" ) and not isinstance ( value , tomlkit . items . InlineTable ) :","if isinstance ( value , tomlkit . items . Table ) :",0.301957549,29.83903702,0.227272727
"def _do_ssl_handshake(self):<tab>try:<tab><tab>self.socket.do_handshake()<tab>except ssl.SSLError as err:<tab><tab>if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return self.handle_close()<tab><tab>raise<tab>except OSError as err:<tab><tab>if err.args[0] == errno.ECONNABORTED:<tab><tab><tab>return self.handle_close()<tab>else:<tab><tab>self._ssl_accepting = False",1,elif err . args [ 0 ] == ssl . SSL_ERROR_EOF :,elif err . args [ 0 ] == ssl . SSL_ERROR_EOF :,0.75,100,1
"def get_filechanges(repo, revision, parents, mleft):<tab>""""""Given some repository and revision, find all changed/deleted files.""""""<tab>l, c, r = [], [], []<tab>for p in parents:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>mright = revsymbol(repo, b""%d"" % p).manifest()<tab><tab>l, c, r = split_dict(mleft, mright, l, c, r)<tab>l.sort()<tab>c.sort()<tab>r.sort()<tab>return l, c, r",0,if p < 0 :,if p == revision :,0.064978772,17.9652056,0.6
"def close_share(self, share_name):<tab>c = await run(<tab><tab>[SMBCmd.SMBCONTROL.value, ""smbd"", ""close-share"", share_name], check=False<tab>)<tab>if c.returncode != 0:<tab><tab><IF-STMT><tab><tab><tab># smbd is not running. Don't log error message.<tab><tab><tab>return<tab><tab>self.logger.warn(<tab><tab><tab>""Failed to close smb share [%s]: [%s]"",<tab><tab><tab>share_name,<tab><tab><tab>c.stderr.decode().strip(),<tab><tab>)",0,"if ""Can't find pid"" in c . stderr . decode ( ) :","if c . stderr . strip ( ) == """" :",0.126431374,22.40415869,0.234375
"def execute(self, context):<tab>if self.tree_name:<tab><tab>ng = bpy.data.node_groups.get(self.tree_name)<tab><tab><IF-STMT><tab><tab><tab>apply_theme(ng)<tab><tab>else:<tab><tab><tab>return {""CANCELLED""}<tab>else:<tab><tab>apply_theme()<tab>return {""FINISHED""}",1,if ng :,if ng :,0.531170663,1.00E-10,1
"def apply(self, db, object):<tab>if not self.source_handle:<tab><tab><IF-STMT><tab><tab><tab># check whether the citation list is empty as a proxy for<tab><tab><tab># there being no sources<tab><tab><tab>return len(object.get_all_citation_lists()) == 0<tab><tab>else:<tab><tab><tab>return False<tab>else:<tab><tab>for citation_handle in object.get_all_citation_lists():<tab><tab><tab>citation = db.get_citation_from_handle(citation_handle)<tab><tab><tab>if citation.get_reference_handle() == self.source_handle:<tab><tab><tab><tab>return True<tab><tab>return False",0,if self . nosource :,if object . get_all_citation_lists ( ) :,0.029730601,4.065425429,0.377777778
"def get_data_dir():<tab>""""""Get the directory path for flit user data files.""""""<tab>home = os.path.realpath(os.path.expanduser(""~""))<tab>if sys.platform == ""darwin"":<tab><tab>d = Path(home, ""Library"")<tab>elif os.name == ""nt"":<tab><tab>appdata = os.environ.get(""APPDATA"", None)<tab><tab><IF-STMT><tab><tab><tab>d = Path(appdata)<tab><tab>else:<tab><tab><tab>d = Path(home, ""AppData"", ""Roaming"")<tab>else:<tab><tab># Linux, non-OS X Unix, AIX, etc.<tab><tab>xdg = os.environ.get(""XDG_DATA_HOME"", None)<tab><tab>d = Path(xdg) if xdg else Path(home, "".local/share"")<tab>return d / ""flit""",1,if appdata :,if appdata :,0.531170663,1.00E-10,1
"def wait_for_service(name, timeout=200):<tab>start = time.time()<tab>while True:<tab><tab>status = win32serviceutil.QueryServiceStatus(name)<tab><tab>if status[1] == win32service.SERVICE_STOPPED:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise TimeoutError(<tab><tab><tab><tab>""Timeout waiting for service""<tab><tab><tab>)  # pylint: disable=undefined-variable<tab><tab>time.sleep(0.3)",0,if time . time ( ) - start > timeout :,if time . time ( ) - start >= timeout :,0.872196729,76.91605673,1
"def get_selection(self):<tab>if self.uistate[""selection""] == ""all"":<tab><tab>return AllPages(self.notebook)<tab>else:<tab><tab>path = self.uistate[""selected_page""]<tab><tab><IF-STMT><tab><tab><tab>return SubPages(self.notebook, path)<tab><tab>else:<tab><tab><tab>return SinglePage(self.notebook, path)",0,"if self . uistate [ ""selection_recursive"" ] :","if self . uistate [ ""selection"" ] == ""sub"" :",0.374051635,45.46697237,1
"def test_repeated_edges(self):<tab>graph_size = 20<tab>for _ in range(20):<tab><tab>graph = Graph.graph(graph_size, int(graph_size * 2), repeated_edges=True)<tab><tab>edges = [(e.start, e.end) for e in graph.iterate_edges()]<tab><tab>has_repeated_edges = len(edges) > len(set(edges))<tab><tab><IF-STMT><tab><tab><tab>break<tab>self.assertTrue(has_repeated_edges)<tab>for _ in range(10):<tab><tab>graph = Graph.graph(graph_size, int(graph_size * 2), repeated_edges=False)<tab><tab>edges = list(graph.iterate_edges())<tab><tab>self.assertEqual(len(edges), len(set(edges)))",1,if has_repeated_edges :,if has_repeated_edges :,0.531170663,1.00E-10,1
"def cs(self):<tab>""""""ConfigSpace representation of this search space.""""""<tab>cs = CS.ConfigurationSpace()<tab>for k, v in self.kwvars.items():<tab><tab><IF-STMT><tab><tab><tab>_add_cs(cs, v.cs, k)<tab><tab>elif isinstance(v, Space):<tab><tab><tab>hp = v.get_hp(name=k)<tab><tab><tab>_add_hp(cs, hp)<tab><tab>else:<tab><tab><tab>_rm_hp(cs, k)<tab>return cs",1,"if isinstance ( v , NestedSpace ) :","if isinstance ( v , NestedSpace ) :",0.75,100,1
"def packet_handler(Packet):<tab>global add_new_line<tab>if Packet.haslayer(ICMP):<tab><tab>Data = Packet.getlayer(ICMP).getlayer(Raw)<tab><tab>exfiltrated_data = Data.load[int(exfiltration_length) :].replace(<tab><tab><tab>exfiltration_length * ""\n"", ""\n""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>add_new_line = False<tab><tab>sys.stdout.write(exfiltrated_data)<tab><tab>sys.stdout.flush()",0,"if exfiltrated_data . endswith ( ""\n"" ) :",if add_new_line :,0.016200585,1.00E-10,0.641025641
"def acquire(self, *, wait=False):<tab>if not wait and self.value <= 0:<tab><tab># signal that we're not acquiring<tab><tab>return False<tab>while self.value <= 0:<tab><tab>future = self.loop.create_future()<tab><tab>self._waiters.append(future)<tab><tab>try:<tab><tab><tab>await future<tab><tab>except:<tab><tab><tab>future.cancel()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.wake_up()<tab><tab><tab>raise<tab>self.value -= 1<tab>return True",0,if self . value > 0 and not future . cancelled ( ) :,if self . value <= 0 :,0.144330164,18.07288326,0.527777778
"def handle_events(self, events):<tab>for event in events:<tab><tab><IF-STMT><tab><tab><tab>self.recording ^= True<tab><tab><tab>if not self.recording:<tab><tab><tab><tab>self.save()<tab><tab><tab>else:<tab><tab><tab><tab>logger.info(""ScreenRecorder started"")<tab><tab><tab>break<tab>return events",0,if event == WindowEvent . SCREEN_RECORDING_TOGGLE :,"if event . get ( ""type"" ) == ""recording"" :",0.036747879,8.2259647,0.6
"def _register_for_operations(config, session, service_name):<tab># There's certainly a tradeoff for registering the retry config<tab># for the operations when the service is created.  In practice,<tab># there aren't a whole lot of per operation retry configs so<tab># this is ok for now.<tab>for key in config:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>handler = retryhandler.create_retry_handler(config, key)<tab><tab>unique_id = ""retry-config-%s-%s"" % (service_name, key)<tab><tab>session.register(<tab><tab><tab>""needs-retry.%s.%s"" % (service_name, key), handler, unique_id=unique_id<tab><tab>)",0,"if key == ""__default__"" :","if key . startswith ( ""retry-"" ) :",0.04979442,8.639795715,0.727272727
"def showTicks(self, show=True):<tab>for tick in self.ticks.keys():<tab><tab>if show:<tab><tab><tab>tick.show()<tab><tab><tab>orig = getattr(self, ""_allowAdd_backup"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.allowAdd = orig<tab><tab>else:<tab><tab><tab>self._allowAdd_backup = self.allowAdd<tab><tab><tab>self.allowAdd = False  # block tick creation<tab><tab><tab>tick.hide()",0,if orig :,if orig is not None :,0.090364769,1.00E-10,0.4
"def _has_cycle(self, node, visited, visit_stack):<tab>self.last_visited_node = node<tab>self.path.append(node)<tab>visited[node] = True<tab>visit_stack[node] = True<tab>for neighbor in self.graph[node]:<tab><tab>if not visited[neighbor]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>elif visit_stack[neighbor]:<tab><tab><tab>self.path.append(neighbor)<tab><tab><tab>return True<tab>self.path.remove(node)<tab>visit_stack[node] = False<tab>return False",0,"if self . _has_cycle ( neighbor , visited , visit_stack ) :",if visit_stack [ neighbor ] :,0.011974477,7.936503279,0.377777778
"def get_project_list(exclude_default=False):<tab>""""""get_project_list - get list of all projects""""""<tab>projects_path = __project__.get_projects_path()<tab>project_list = []<tab>if os.path.exists(projects_path):<tab><tab>for project in os.listdir(projects_path):<tab><tab><tab>project_path = os.path.join(projects_path, project)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>project_list.append(project)<tab>if exclude_default:<tab><tab>pass<tab>else:<tab><tab>project_list.append(""default"")<tab>return sorted(project_list)",0,if os . path . isdir ( project_path ) :,if os . path . exists ( project_path ) :,0.580308871,73.48889201,0.666666667
"def split(self, chunksize):<tab>modulus_map = {<tab><tab>4: 256,<tab><tab>5: 10,<tab><tab>8: 100,<tab>}<tab>chunks, ip = self.preprocess(chunksize)<tab>ret = """"<tab>for i in range(len(chunks)):<tab><tab>ip_part = compat_str(ip[i] % modulus_map[chunksize]) if i < 4 else """"<tab><tab><IF-STMT><tab><tab><tab>ret += ip_part + chunks[i]<tab><tab>else:<tab><tab><tab>ret += chunks[i] + ip_part<tab>self.target = ret",0,if chunksize == 8 :,if i < len ( chunks ) - 1 :,0.024424144,4.990049702,0.229166667
"def DepsToModules(deps, prefix, suffix):<tab>modules = []<tab>for filepath in deps:<tab><tab>filename = os.path.basename(filepath)<tab><tab><IF-STMT><tab><tab><tab>modules.append(filename[len(prefix) : -len(suffix)])<tab>return modules",1,if filename . startswith ( prefix ) and filename . endswith ( suffix ) :,if filename . startswith ( prefix ) and filename . endswith ( suffix ) :,1,100,1
"def listdir(path):<tab>path = path.rstrip(""/"") + ""/""<tab>dir_set, file_set = set(), set()<tab>for p in files.keys():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>parts = p[len(path) :].split(""/"")<tab><tab>if len(parts) == 1:<tab><tab><tab>file_set.add(parts[0])<tab><tab>else:<tab><tab><tab>dir_set.add(parts[0])<tab>return sorted(dir_set), sorted(file_set)",1,if not p . startswith ( path ) :,if not p . startswith ( path ) :,0.75,100,1
"def read_series(rec):<tab>found = []<tab>for tag in (""440"", ""490"", ""830""):<tab><tab>fields = rec.get_fields(tag)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for f in fields:<tab><tab><tab>this = []<tab><tab><tab>for k, v in f.get_subfields([""a"", ""v""]):<tab><tab><tab><tab>if k == ""v"" and v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>v = v.rstrip("".,; "")<tab><tab><tab><tab>if v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab>if this:<tab><tab><tab><tab>found += ["" -- "".join(this)]<tab>return found",1,if not fields :,if not fields :,0.75,100,1
"def find_nameless_urls(self, conf):<tab>nameless = []<tab>patterns = self.get_patterns(conf)<tab>for u in patterns:<tab><tab><IF-STMT><tab><tab><tab>nameless.extend(self.find_nameless_urls(u))<tab><tab>else:<tab><tab><tab>if u.name is None:<tab><tab><tab><tab>nameless.append(u)<tab>return nameless",0,if self . has_patterns ( u ) :,"if isinstance ( u , str ) :",0.044942074,12.86253479,0.481481481
"def update_billing_status(self, update_modified=True):<tab>updated_pr = [self.name]<tab>for d in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>updated_pr += update_billed_amount_based_on_po(<tab><tab><tab><tab>d.purchase_order_item, update_modified<tab><tab><tab>)<tab>for pr in set(updated_pr):<tab><tab>pr_doc = self if (pr == self.name) else frappe.get_doc(""Purchase Receipt"", pr)<tab><tab>update_billing_percentage(pr_doc, update_modified=update_modified)<tab>self.load_from_db()",1,if d . purchase_order_item :,if d . purchase_order_item :,0.75,100,1
"def _get_version():<tab>with open(""haiku/__init__.py"") as fp:<tab><tab>for line in fp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>g = {}<tab><tab><tab><tab>exec(line, g)  # pylint: disable=exec-used<tab><tab><tab><tab>return g[""__version__""]<tab><tab>raise ValueError(""`__version__` not defined in `haiku/__init__.py`"")",1,"if line . startswith ( ""__version__"" ) :","if line . startswith ( ""__version__"" ) :",0.75,100,1
"def GetSelected(self):<tab>if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0)<tab><tab>if result:<tab><tab><tab>return self.SendMessage(self.Hwnd, self.Msg.LB_GETANCHORINDEX, 0, 0)<tab>else:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0)<tab><tab><IF-STMT><tab><tab><tab>return result",0,if result != LB_ERR :,if result :,0.067674239,1.00E-10,1
"def __init__(self, column_names, column_types, **kwargs):<tab>super().__init__(**kwargs)<tab>self.column_names = column_names<tab>self.column_types = column_types<tab>encoding = []<tab>for column_name in self.column_names:<tab><tab>column_type = self.column_types[column_name]<tab><tab><IF-STMT><tab><tab><tab># TODO: Search to use one-hot or int.<tab><tab><tab>encoding.append(keras_layers.INT)<tab><tab>else:<tab><tab><tab>encoding.append(keras_layers.NONE)<tab>self.layer = keras_layers.MultiCategoryEncoding(encoding)",0,if column_type == analysers . CATEGORICAL :,"if column_type == ""hot"" :",0.094532291,53.72849659,0.45
"def rotate(cls, axis, theta):<tab>""""""Prepare a quaternion that represents a rotation on a given axis.""""""<tab>if isinstance(axis, str):<tab><tab><IF-STMT><tab><tab><tab>axis = V.X<tab><tab>elif axis in (""y"", ""Y""):<tab><tab><tab>axis = V.Y<tab><tab>elif axis in (""z"", ""Z""):<tab><tab><tab>axis = V.Z<tab>axis = axis.normalize()<tab>s = math.sin(theta / 2.0)<tab>c = math.cos(theta / 2.0)<tab>return Q(axis._v[0] * s, axis._v[1] * s, axis._v[2] * s, c)",1,"if axis in ( ""x"" , ""X"" ) :","if axis in ( ""x"" , ""X"" ) :",0.75,100,1
"def log(self, request):<tab>web_socket = WebSocketResponse()<tab>await web_socket.prepare(request)<tab>self.app[""websockets""].add(web_socket)<tab>try:<tab><tab>async for msg in web_socket:<tab><tab><tab>if msg.type == WSMsgType.TEXT:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>await web_socket.close()<tab><tab><tab>elif msg.type == WSMsgType.ERROR:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>""web socket connection closed with exception %s""<tab><tab><tab><tab><tab>% web_socket.exception()<tab><tab><tab><tab>)<tab>finally:<tab><tab>self.app[""websockets""].remove(web_socket)<tab>return web_socket",0,"if msg . data == ""close"" :","if web_socket . text ( ) . endswith ( ""\n"" ) :",0.017601189,3.419798031,0.333333333
"def test_loc_is_stochastic_parameter(self):<tab>param = iap.Laplace(iap.Choice([-100, 100]), 1)<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>samples = param.draw_samples((100,))<tab><tab>exp = np.mean(samples)<tab><tab><IF-STMT><tab><tab><tab>seen[0] += 1<tab><tab>elif 100 - 10 < exp < 100 + 10:<tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert 500 - 100 < seen[0] < 500 + 100<tab>assert 500 - 100 < seen[1] < 500 + 100",1,if - 100 - 10 < exp < - 100 + 10 :,if - 100 - 10 < exp < - 100 + 10 :,0.75,100,1
"def cli_setup(args=None):<tab>""""""future api for setup env by cli""""""<tab>if not args:<tab><tab><IF-STMT><tab><tab><tab>print(""no cmdline args"")<tab><tab><tab>return False<tab><tab>args = sys.argv<tab>print(args)<tab>ap = argparse.ArgumentParser()<tab>if ""--report"" in args:<tab><tab>from airtest.report.report import main as report_main<tab><tab>ap = report_parser(ap)<tab><tab>args = ap.parse_args(args)<tab><tab>report_main(args)<tab><tab>exit(0)<tab>else:<tab><tab>ap = runner_parser(ap)<tab><tab>args = ap.parse_args(args)<tab><tab>setup_by_args(args)<tab>return True",0,if len ( sys . argv ) < 2 :,if not sys . argv :,0.061061929,17.62532855,0.558441558
"def validate_attributes(cls, cleaned_data):<tab>errors = {}<tab>for field in [""product_attributes"", ""variant_attributes""]:<tab><tab>attributes = cleaned_data.get(field)<tab><tab>if not attributes:<tab><tab><tab>continue<tab><tab>not_valid_attributes = [<tab><tab><tab>graphene.Node.to_global_id(""Attribute"", attr.pk)<tab><tab><tab>for attr in attributes<tab><tab><tab>if attr.type != AttributeType.PRODUCT_TYPE<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>errors[field] = ValidationError(<tab><tab><tab><tab>""Only Product type attributes are allowed."",<tab><tab><tab><tab>code=ProductErrorCode.INVALID.value,<tab><tab><tab><tab>params={""attributes"": not_valid_attributes},<tab><tab><tab>)<tab>if errors:<tab><tab>raise ValidationError(errors)",1,if not_valid_attributes :,if not_valid_attributes :,0.531170663,1.00E-10,1
"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab>if layer == ""conv"":<tab><tab><tab>if self.with_explicit_padding:<tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab><IF-STMT><tab><tab><tab>x = self.norm(x)<tab><tab>elif layer == ""act"" and activate and self.with_activation:<tab><tab><tab>x = self.activate(x)<tab>return x",0,"elif layer == ""norm"" and norm and self . with_norm :",elif norm :,0.008799654,1.00E-10,0.285714286
"def _FunctionDef(self, node):<tab>_ScopeVisitor._FunctionDef(self, node)<tab>if len(node.args.args) > 0:<tab><tab>first = node.args.args[0]<tab><tab><IF-STMT><tab><tab><tab>new_visitor = _ClassInitVisitor(self, first.id)<tab><tab><tab>for child in ast.get_child_nodes(node):<tab><tab><tab><tab>ast.walk(child, new_visitor)",1,"if isinstance ( first , ast . Name ) :","if isinstance ( first , ast . Name ) :",0.75,100,1
"def result(self):<tab>""""""Gets the formatted string result.""""""<tab>if self.__group.isChecked():<tab><tab>if self.__moreThan.isChecked():<tab><tab><tab>return ""gt%d"" % self.__min.value()<tab><tab><IF-STMT><tab><tab><tab>return ""lt%d"" % self.__max.value()<tab><tab>if self.__range.isChecked():<tab><tab><tab>return ""%d-%d"" % (self.__min.value(), self.__max.value())<tab>return """"",0,if self . __lessThan . isChecked ( ) :,if self . __min . isChecked ( ) :,0.549889319,70.16879391,1
"def hash_of_file(path):<tab>""""""Return the hash of a downloaded file.""""""<tab>with open(path, ""rb"") as archive:<tab><tab>sha = sha256()<tab><tab>while True:<tab><tab><tab>data = archive.read(2 ** 20)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>sha.update(data)<tab>return encoded_hash(sha)",1,if not data :,if not data :,0.75,100,1
"def read_boolean(file: BinaryIO, count: int, checkall: bool = False) -> List[bool]:<tab>if checkall:<tab><tab>all_defined = file.read(1)<tab><tab><IF-STMT><tab><tab><tab>return [True] * count<tab>result = []<tab>b = 0<tab>mask = 0<tab>for i in range(count):<tab><tab>if mask == 0:<tab><tab><tab>b = ord(file.read(1))<tab><tab><tab>mask = 0x80<tab><tab>result.append(b & mask != 0)<tab><tab>mask >>= 1<tab>return result",0,"if all_defined != unhexlify ( ""00"" ) :","if all_defined == ""true"" :",0.035401841,23.14271626,0.641025641
"def start_prompt(self):<tab>""""""Start the interpreter.""""""<tab>logger.show(""Coconut Interpreter:"")<tab>logger.show(""(type 'exit()' or press Ctrl-D to end)"")<tab>self.start_running()<tab>while self.running:<tab><tab>try:<tab><tab><tab>code = self.get_input()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>compiled = self.handle_input(code)<tab><tab><tab><tab>if compiled:<tab><tab><tab><tab><tab>self.execute(compiled, use_eval=None)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>printerr(""\nKeyboardInterrupt"")",1,if code :,if code :,0.531170663,1.00E-10,1
"def _wrap_lineanchors(self, inner):<tab>s = self.lineanchors<tab>i = self.linenostart - 1  # subtract 1 since we have to increment i<tab># *before* yielding<tab>for t, line in inner:<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>yield 1, '<a name=""%s-%d""></a>' % (s, i) + line<tab><tab>else:<tab><tab><tab>yield 0, line",1,if t :,if t :,0.531170663,1.00E-10,1
"def __UpdateQueryHistory(self, query):<tab>clone = datastore_pb.Query()<tab>clone.CopyFrom(query)<tab>clone.clear_hint()<tab>clone.clear_limit()<tab>clone.clear_offset()<tab>clone.clear_count()<tab>if clone in self.__query_history:<tab><tab>self.__query_history[clone] += 1<tab>else:<tab><tab>self.__query_history[clone] = 1<tab><tab><IF-STMT><tab><tab><tab>self.__query_ci_history.add(datastore_index.CompositeIndexForQuery(clone))",0,if clone . app ( ) == self . _app_id :,if self . __query_ci_history :,0.073216713,11.5327068,0.375
"def call(self, trajectory: traj.Trajectory):<tab>if not self._batch_size:<tab><tab><IF-STMT><tab><tab><tab>self._batch_size = 1<tab><tab>else:<tab><tab><tab>assert trajectory.step_type.ndim == 1<tab><tab><tab>self._batch_size = trajectory.step_type.shape[0]<tab><tab>self.reset()<tab>if trajectory.step_type.ndim == 0:<tab><tab>trajectory = nest_utils.batch_nested_array(trajectory)<tab>self._batched_call(trajectory)",0,if trajectory . step_type . ndim == 0 :,if trajectory . step_type . ndim == 1 :,0.627090855,82.65168184,0.666666667
"def steps(self):<tab>""""""""""""<tab>for step_id in range(self.micro_batches):<tab><tab>cmds = [<tab><tab><tab>LoadMicroBatch(buffer_id=0),<tab><tab><tab>ForwardPass(buffer_id=0),<tab><tab><tab>BackwardPass(buffer_id=0),<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>cmds.extend(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>ReduceGrads(),<tab><tab><tab><tab><tab>OptimizerStep(),<tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>yield cmds",0,if step_id == self . micro_batches - 1 :,if step_id == self . num_steps - 1 :,0.549889319,62.98129992,1
"def resolve_project(self, workspace, project_name):<tab>if isinstance(project_name, (int, float)):  # project id<tab><tab>project_id = int(project_name)<tab><tab>self.log.debug(""Treating project name as ID: %s"", project_id)<tab><tab>project = workspace.projects(ident=project_id).first()<tab><tab><IF-STMT><tab><tab><tab>raise TaurusConfigError(<tab><tab><tab><tab>""BlazeMeter project not found by ID: %s"" % project_id<tab><tab><tab>)<tab>elif project_name:<tab><tab>project = workspace.projects(name=project_name).first()<tab>else:<tab><tab>project = None<tab>if not project:<tab><tab>project = self._create_project_or_use_default(workspace, project_name)<tab>return project",1,if not project :,if not project :,0.75,100,1
"def __reader(self, collector, source):<tab>while True:<tab><tab>data = os.read(source.fileno(), 65536)<tab><tab>self.__lock.acquire()<tab><tab>collector.append(data)<tab><tab>self.__lock.release()<tab><tab><IF-STMT><tab><tab><tab>source.close()<tab><tab><tab>break<tab>return",0,"if data == """" :",if not data :,0.039449619,9.930283522,0.45
"def add(self, undoinfo, msg=None):<tab>if not undoinfo:<tab><tab>return<tab>if msg is not None:<tab><tab>if isinstance(undoinfo[0], str):<tab><tab><tab># replace message<tab><tab><tab>undoinfo = (msg,) + undoinfo[1:]<tab><tab><IF-STMT><tab><tab><tab>undoinfo = (msg,) + undoinfo<tab><tab>else:<tab><tab><tab>undoinfo = (msg, undoinfo)<tab><tab>f = 1<tab>else:<tab><tab>f = int(isinstance(undoinfo[0], str))<tab>assert (<tab><tab>isinstance(undoinfo, list)<tab><tab>or callable(undoinfo[f])<tab><tab>or isinstance(undoinfo[f], list)<tab>)<tab>self.undoList.append(undoinfo)<tab>del self.redoList[:]",0,"elif isinstance ( undoinfo , tuple ) :","elif isinstance ( undoinfo , list ) :",0.547301779,59.46035575,0.666666667
"def get_history_data(self, guid, count=1):<tab>history = {}<tab>if count < 1:<tab><tab>return history<tab>key = self._make_key(guid)<tab>for i in range(0, self.db.llen(key)):<tab><tab>r = self.db.lindex(key, i)<tab><tab>c = msgpack.unpackb(r)<tab><tab>if c[""tries""] == 0 or c[""tries""] is None:<tab><tab><tab>if c[""data""] not in history:<tab><tab><tab><tab>history[c[""data""]] = c[""timestamp""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab>return history",0,if len ( history ) >= count :,"if c [ ""tries"" ] == count :",0.034400971,14.99110695,0.314814815
"def __str__(self):<tab>from sqlalchemy.sql import util<tab>details = [SQLAlchemyError.__str__(self)]<tab>if self.statement:<tab><tab>details.append(""[SQL: %r]"" % self.statement)<tab><tab><IF-STMT><tab><tab><tab>params_repr = util._repr_params(self.params, 10)<tab><tab><tab>details.append(""[parameters: %r]"" % params_repr)<tab>return "" "".join([""(%s)"" % det for det in self.detail] + details)",1,if self . params :,if self . params :,0.75,100,1
"def _consume_msg(self):<tab>async for data in self._stream:<tab><tab>stream = data.get(""ev"")<tab><tab><IF-STMT><tab><tab><tab>await self._dispatch(data)<tab><tab>elif data.get(""status"") == ""disconnected"":<tab><tab><tab># Polygon returns this on an empty 'ev' id..<tab><tab><tab>data[""ev""] = ""status""<tab><tab><tab>await self._dispatch(data)<tab><tab><tab>raise ConnectionResetError(<tab><tab><tab><tab>""Polygon terminated connection: "" f'({data.get(""message"")})'<tab><tab><tab>)",0,if stream :,if stream is None :,0.097914534,1.00E-10,0.5
"def nan2none(l):<tab>for idx, val in enumerate(l):<tab><tab>if isinstance(val, Sequence):<tab><tab><tab>l[idx] = nan2none(l[idx])<tab><tab><IF-STMT><tab><tab><tab>l[idx] = None<tab>return l",0,elif isnum ( val ) and math . isnan ( val ) :,elif val is None :,0.071181062,2.838368887,0.2
"def _make_binary_stream(s, encoding):<tab>try:<tab><tab>if _py3k:<tab><tab><tab>if isinstance(s, str):<tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>from io import BytesIO<tab><tab>rv = BytesIO(s)<tab>except ImportError:<tab><tab>rv = StringIO(s)<tab>return rv",0,if type ( s ) is not str :,"if isinstance ( s , bytes ) :",0.033138934,12.25620097,0.305555556
"def __set__(self, instance, value):<tab>try:<tab><tab>value = int(value)<tab><tab><IF-STMT>  # max port number is 65535<tab><tab><tab>self.display_value = str(value)<tab><tab><tab>self.value = value<tab><tab>else:<tab><tab><tab>raise PocsuiteValidationException(<tab><tab><tab><tab>""Invalid option. Port value should be between 0 and 65536.""<tab><tab><tab>)<tab>except ValueError:<tab><tab>raise PocsuiteValidationException(<tab><tab><tab>""Invalid option. Cannot cast '{}' to integer."".format(value)<tab><tab>)",0,if 0 <= value <= 65535 :,if value >= 0 and value <= 65535 :,0.198013266,39.45881256,0.291666667
"def addVaXref(self, va, parent=None):<tab>if parent is None:<tab><tab>parent = self<tab>xtova, ok = QInputDialog.getText(parent, ""Enter..."", ""Make Code Xref 0x%x -> "" % va)<tab>if ok:<tab><tab>try:<tab><tab><tab>val = self.vw.parseExpression(str(xtova))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.vw.addXref(va, val, REF_CODE)<tab><tab><tab>else:<tab><tab><tab><tab>self.vw.vprint(""Invalid Expression: %s   (%s)"" % (xtova, val))<tab><tab>except Exception as e:<tab><tab><tab>self.vw.vprint(repr(e))",0,if self . vw . isValidPointer ( val ) :,if val != REF_CODE :,0.014393213,5.660233916,0.294871795
"def ArrayBuffer():<tab>a = arguments[0]<tab>if isinstance(a, PyJsNumber):<tab><tab>length = a.to_uint32()<tab><tab><IF-STMT><tab><tab><tab>raise MakeError(""RangeError"", ""Invalid array length"")<tab><tab>temp = Js(bytearray([0] * length))<tab><tab>return temp<tab>return Js(bytearray([0]))",0,if length != a . value :,if length < 0 :,0.042406009,12.97584999,0.476190476
"def _update_positions(nodes, line_offset, last_leaf):<tab>for node in nodes:<tab><tab>try:<tab><tab><tab>children = node.children<tab><tab>except AttributeError:<tab><tab><tab># Is a leaf<tab><tab><tab>node.line += line_offset<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise _PositionUpdatingFinished<tab><tab>else:<tab><tab><tab>_update_positions(children, line_offset, last_leaf)",0,if node is last_leaf :,if children is None :,0.286540249,9.423716575,0.444444444
"def class_has_method(self, curr_node, the_text):<tab>try:<tab><tab>class_node = self.containers[VAR_KIND_CLASS][-1]<tab><tab>for c in class_node.children:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>except:<tab><tab>pass<tab>return False",0,"if isinstance ( c , MethodNode ) and c . name == the_text :","if c . name == ""method"" and c . value == the_text :",0.51393709,46.42182223,0.241666667
"def _fm(map_id):<tab>for i in range(num_key):<tab><tab>for j in range(num_value_per_key):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (i, j)<tab><tab><tab>else:<tab><tab><tab><tab>yield ((map_id, i), j)",0,if dup_key :,if map_id == i :,0.051944023,1.00E-10,0.619047619
"def _compileRules(rulesList, maxLength=4):<tab>ruleChecking = collections.defaultdict(list)<tab>for ruleIndex in range(len(rulesList)):<tab><tab>args = []<tab><tab>if len(rulesList[ruleIndex]) == maxLength:<tab><tab><tab>args = rulesList[ruleIndex][-1]<tab><tab>if maxLength == 4:<tab><tab><tab>(shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, isCorrect, args))<tab><tab><IF-STMT><tab><tab><tab>(shouldRunMethod, method) = rulesList[ruleIndex][0:2]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, args))<tab>return ruleChecking",1,elif maxLength == 3 :,elif maxLength == 3 :,1,100,1
"def select(result):<tab>for elem in result:<tab><tab>parent = elem.getparent()<tab><tab>if parent is None:<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab># FIXME: what if the selector is ""*"" ?<tab><tab><tab>elems = list(parent.iterchildren(elem.tag))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield elem<tab><tab>except IndexError:<tab><tab><tab>pass",0,if elems [ index ] is elem :,"if elems [ 0 ] . startswith ( ""*"" ) :",0.0673711,13.0651133,0.365384615
"def get_kwarg_or_param(request, kwargs, key):<tab>value = None<tab>try:<tab><tab>value = kwargs[key]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>value = request.GET.get(key)<tab><tab>elif request.method == ""POST"":<tab><tab><tab>value = request.POST.get(key)<tab>return value",1,"if request . method == ""GET"" :","if request . method == ""GET"" :",0.75,100,1
"def __imul__(self, other):<tab>if isinstance(other, str):<tab><tab>other = Matrix(other)<tab>if isinstance(other, Matrix):<tab><tab>if self.start is not None:<tab><tab><tab>self.start *= other<tab><tab><IF-STMT><tab><tab><tab>self.control1 *= other<tab><tab>if self.control2 is not None:<tab><tab><tab>self.control2 *= other<tab><tab>if self.end is not None:<tab><tab><tab>self.end *= other<tab>return self",1,if self . control1 is not None :,if self . control1 is not None :,0.75,100,1
"def _parse_date_fmt():<tab>fmt = get_format(""DATE_FORMAT"")<tab>escaped = False<tab>for char in fmt:<tab><tab>if escaped:<tab><tab><tab>escaped = False<tab><tab>elif char == ""\\"":<tab><tab><tab>escaped = True<tab><tab><IF-STMT><tab><tab><tab>yield ""year""<tab><tab>elif char in ""bEFMmNn"":<tab><tab><tab>yield ""month""<tab><tab>elif char in ""dj"":<tab><tab><tab>yield ""day""",0,"elif char in ""Yy"" :","elif char in ""bFmYn"" :",0.394778655,48.89230224,1
def filter_forms(forms):<tab>result = []<tab>seen = set()<tab>for form in forms:<tab><tab><IF-STMT><tab><tab><tab>if pos in self._lemma_pos_offset_map[form]:<tab><tab><tab><tab>if form not in seen:<tab><tab><tab><tab><tab>result.append(form)<tab><tab><tab><tab><tab>seen.add(form)<tab>return result,0,if form in self . _lemma_pos_offset_map :,if form . is_valid ( ) :,0.042825693,6.879388649,0.55
"def calculate(self):<tab>""""""Enumerate processes by scanning for _EPROCESS.""""""<tab>result = set()<tab>psscan = self.session.plugins.psscan()<tab>pslist = self.session.plugins.pslist()<tab>for row in psscan.collect():<tab><tab>physical_eprocess = row[""offset_p""]<tab><tab><IF-STMT><tab><tab><tab>eprocess = pslist.virtual_process_from_physical_offset(physical_eprocess)<tab><tab>else:<tab><tab><tab>eprocess = physical_eprocess<tab><tab>if eprocess != None:<tab><tab><tab>result.add(eprocess.obj_offset)<tab>self.session.logging.debug(""Listed %s processes using PSScan"", len(result))<tab>return result",0,if physical_eprocess . obj_vm == self . session . physical_address_space :,if pslist . is_virtual_offset ( physical_eprocess ) :,0.014083697,8.800046367,0.388235294
"def _build_kwargs_string(cls, expectation):<tab>kwargs = []<tab>for k, v in expectation[""kwargs""].items():<tab><tab><IF-STMT><tab><tab><tab># make the column a positional argument<tab><tab><tab>kwargs.insert(0, ""{}='{}'"".format(k, v))<tab><tab>elif isinstance(v, str):<tab><tab><tab># Put strings in quotes<tab><tab><tab>kwargs.append(""{}='{}'"".format(k, v))<tab><tab>else:<tab><tab><tab># Pass other types as is<tab><tab><tab>kwargs.append(""{}={}"".format(k, v))<tab>return "", "".join(kwargs)",0,"if k == ""column"" :","if isinstance ( v , int ) :",0.026407399,6.567274736,0.3
"def prec3_expr(self, arg_type):<tab>pass<tab>self.prec4_expr(arg_type)<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab><tab>pass<tab><tab><tab>self.match(POWER)<tab><tab><tab>op = struct.pack(""B"", ptgPower)<tab><tab><tab>self.prec4_expr(arg_type)<tab><tab><tab>self.rpn += op<tab><tab>else:<tab><tab><tab>break",0,if self . LA ( 1 ) == POWER :,if self . rpn . isdigit ( ) :,0.064012671,16.89983565,0.363636364
"def evaluate(analysis, rule):<tab>try:<tab><tab>if isinstance(rule, MetaRule):<tab><tab><tab>result = _evaluate_meta_rule(analysis, rule)<tab><tab>elif isinstance(rule, SingleRule):<tab><tab><tab>result = _evaluate_single_rule(analysis, rule)<tab><tab><IF-STMT><tab><tab><tab>result = _evaluate_sub_path_rule(analysis, rule)<tab><tab>else:<tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""rule must be of one in types [SingleRule, MetaRule, SubPathRule]""<tab><tab><tab>)<tab><tab>return result<tab>except KeyError:  # expected behavior as long as this does not have all other plugins as dependency<tab><tab>return False",1,"elif isinstance ( rule , SubPathRule ) :","elif isinstance ( rule , SubPathRule ) :",0.75,100,1
"def create_log_file(d, logname):<tab>logpath = d.getVar(""LOG_DIR"")<tab>bb.utils.mkdirhier(logpath)<tab>logfn, logsuffix = os.path.splitext(logname)<tab>logfile = os.path.join(<tab><tab>logpath, ""%s.%s%s"" % (logfn, d.getVar(""DATETIME""), logsuffix)<tab>)<tab>if not os.path.exists(logfile):<tab><tab>slogfile = os.path.join(logpath, logname)<tab><tab><IF-STMT><tab><tab><tab>os.remove(slogfile)<tab><tab>open(logfile, ""w+"").close()<tab><tab>os.symlink(logfile, slogfile)<tab><tab>d.setVar(""LOG_FILE"", logfile)<tab>return logfile",1,if os . path . exists ( slogfile ) :,if os . path . exists ( slogfile ) :,0.75,100,1
"def init_eventlog(self):<tab>""""""Set up the event logging system.""""""<tab>self.eventlog = EventLog(parent=self)<tab>for dirname, _, files in os.walk(os.path.join(here, ""event-schemas"")):<tab><tab>for file in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self.eventlog.register_schema_file(os.path.join(dirname, file))",0,"if not file . endswith ( "".yaml"" ) :","if not file . endswith ( "".py"" ) :",0.581882088,73.48889201,1
"def resize(self, limit, force=False, ignore_errors=False, reset=False):<tab>prev_limit = self._limit<tab>if (self._dirty and 0 < limit < self._limit) and not ignore_errors:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Can't shrink pool when in use: was={0} now={1}"".format(<tab><tab><tab><tab><tab>self._limit, limit<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>reset = True<tab>self._limit = limit<tab>if reset:<tab><tab>try:<tab><tab><tab>self.force_close_all()<tab><tab>except Exception:<tab><tab><tab>pass<tab>self.setup()<tab>if limit < prev_limit:<tab><tab>self._shrink_down(collect=limit > 0)",0,if not force :,if force :,0.096488528,1.00E-10,0.416666667
"def accept_request(self, request):<tab>if self.restriction_type == BaseViewRestriction.PASSWORD:<tab><tab>passed_restrictions = request.session.get(<tab><tab><tab>self.passed_view_restrictions_session_key, []<tab><tab>)<tab><tab>if self.id not in passed_restrictions:<tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.LOGIN:<tab><tab>if not request.user.is_authenticated:<tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.GROUPS:<tab><tab><IF-STMT><tab><tab><tab>current_user_groups = request.user.groups.all()<tab><tab><tab>if not any(group in current_user_groups for group in self.groups.all()):<tab><tab><tab><tab>return False<tab>return True",0,if not request . user . is_superuser :,if request . user . is_authenticated :,0.196809754,56.48198098,0.377777778
"def getLatestXci(self, version=None):<tab>highest = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab>if nsp.path.endswith("".xci""):<tab><tab><tab><tab>if version is not None and nsp.version == version:<tab><tab><tab><tab><tab>return nsp<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>highest = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highest",1,if not highest or int ( nsp . version ) > int ( highest . version ) :,if not highest or int ( nsp . version ) > int ( highest . version ) :,1,100,1
"def evaluate(self, x, y, z):<tab>vertex = Vector((x, y, z))<tab>nearest, normal, idx, distance = self.bvh.find_nearest(vertex)<tab>if self.use_normal:<tab><tab>if self.signed_normal:<tab><tab><tab>sign = (v - nearest).dot(normal)<tab><tab><tab>sign = copysign(1, sign)<tab><tab>else:<tab><tab><tab>sign = 1<tab><tab>return sign * np.array(normal)<tab>else:<tab><tab>dv = np.array(nearest - vertex)<tab><tab><IF-STMT><tab><tab><tab>norm = np.linalg.norm(dv)<tab><tab><tab>len = self.falloff(norm)<tab><tab><tab>dv = len * dv<tab><tab><tab>return dv<tab><tab>else:<tab><tab><tab>return dv",0,if self . falloff is not None :,if self . use_norm :,0.120555985,22.77210132,0.357142857
"def to_py(self, value: _StrUnset) -> _StrUnsetNone:<tab>self._basic_py_validation(value, str)<tab>if isinstance(value, usertypes.Unset):<tab><tab>return value<tab>elif not value:<tab><tab>return None<tab>value = os.path.expandvars(value)<tab>value = os.path.expanduser(value)<tab>try:<tab><tab>if not os.path.isdir(value):<tab><tab><tab>raise configexc.ValidationError(value, ""must be a valid directory!"")<tab><tab><IF-STMT><tab><tab><tab>raise configexc.ValidationError(value, ""must be an absolute path!"")<tab>except UnicodeEncodeError as e:<tab><tab>raise configexc.ValidationError(value, e)<tab>return value",1,if not os . path . isabs ( value ) :,if not os . path . isabs ( value ) :,0.75,100,1
"def validate_load_balancer_sku(namespace):<tab>""""""Validates the load balancer sku string.""""""<tab>if namespace.load_balancer_sku is not None:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if (<tab><tab><tab>namespace.load_balancer_sku.lower() != ""basic""<tab><tab><tab>and namespace.load_balancer_sku.lower() != ""standard""<tab><tab>):<tab><tab><tab>raise CLIError(""--load-balancer-sku can only be standard or basic"")",1,"if namespace . load_balancer_sku == """" :","if namespace . load_balancer_sku == """" :",0.75,100,1
"def _getLocalSpineType(self):<tab>if self._spineType is not None:<tab><tab>return self._spineType<tab>else:<tab><tab>for thisEvent in self.eventList:<tab><tab><tab>m1 = re.match(r""\*\*(.*)"", thisEvent.contents)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._spineType = m1.group(1)<tab><tab><tab><tab>return self._spineType<tab><tab>return None",1,if m1 :,if m1 :,0.531170663,1.00E-10,1
"def set_selected_device(self):<tab>current_devices = self.get_current_devices()<tab>if self.device in current_devices.values():<tab><tab>return<tab>for device_name in current_devices.values():<tab><tab><IF-STMT><tab><tab><tab>self.parent.py3.log(f""device {self.device} detected as {device_name}"")<tab><tab><tab>self.device = device_name<tab><tab><tab>break",0,if self . device in device_name :,if device_name != self . device :,0.147926787,28.22798386,0.771428571
"def write(self, buff):<tab>if not self.handle:<tab><tab>raise TTransportException(<tab><tab><tab>type=TTransportException.NOT_OPEN, message=""Transport not open""<tab><tab>)<tab>sent = 0<tab>have = len(buff)<tab>while sent < have:<tab><tab>plus = self.handle.send(buff)<tab><tab><IF-STMT><tab><tab><tab>raise TTransportException(<tab><tab><tab><tab>type=TTransportException.END_OF_FILE, message=""TSocket sent 0 bytes""<tab><tab><tab>)<tab><tab>sent += plus<tab><tab>buff = buff[plus:]",1,if plus == 0 :,if plus == 0 :,0.75,100,1
"def get_named_key_value(self, rule, match, key_name):<tab># search the match for the key specified in the rule to get the value<tab>if key_name in rule:<tab><tab>try:<tab><tab><tab>key_value = lookup_es_key(match, rule[key_name])<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Only do the unicode conversion if we actually found something)<tab><tab><tab><tab># otherwise we might transform None --> 'None'<tab><tab><tab><tab>key_value = str(key_value)<tab><tab>except KeyError:<tab><tab><tab># Some matches may not have the specified key<tab><tab><tab># use a special token for these<tab><tab><tab>key_value = ""_missing""<tab>else:<tab><tab>key_value = None<tab>return key_value",1,if key_value is not None :,if key_value is not None :,0.75,100,1
"def __iter__(self):<tab>protocol = self.protocol<tab>source = write_source_from_arg(self.source)<tab>with source.open(""wb"") as f:<tab><tab>it = iter(self.table)<tab><tab>hdr = next(it)<tab><tab><IF-STMT><tab><tab><tab>pickle.dump(hdr, f, protocol)<tab><tab>yield tuple(hdr)<tab><tab>for row in it:<tab><tab><tab>pickle.dump(row, f, protocol)<tab><tab><tab>yield tuple(row)",0,if self . write_header :,"if isinstance ( hdr , tuple ) :",0.026407399,6.567274736,0.3
"def abs__file__():<tab>""""""Set all module' __file__ attribute to an absolute path""""""<tab>for m in sys.modules.values():<tab><tab><IF-STMT><tab><tab><tab>continue  # don't mess with a PEP 302-supplied __file__<tab><tab>try:<tab><tab><tab>m.__file__ = os.path.abspath(m.__file__)<tab><tab>except (AttributeError, OSError):<tab><tab><tab>pass",0,"if hasattr ( m , ""__loader__"" ) :","if not hasattr ( m , ""__file__"" ) :",0.200294835,66.06328636,0.381818182
"def _run(self):<tab>when_pressed = 0.0<tab>pressed = False<tab>while not self._done.is_set():<tab><tab>now = time.monotonic()<tab><tab>if now - when_pressed > self._debounce_time:<tab><tab><tab>if GPIO.input(self._channel) == self._expected:<tab><tab><tab><tab>if not pressed:<tab><tab><tab><tab><tab>pressed = True<tab><tab><tab><tab><tab>when_pressed = now<tab><tab><tab><tab><tab>self._trigger(self._pressed_queue, self._pressed_callback)<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pressed = False<tab><tab><tab><tab><tab>self._trigger(self._released_queue, self._released_callback)<tab><tab>self._done.wait(0.05)",0,if pressed :,if not pressed :,0.113486237,1.00E-10,0.416666667
"def get_run_cmd(submission_dir):<tab>""""""Get the language of a submission""""""<tab>with CD(submission_dir):<tab><tab>if os.path.exists(""run.sh""):<tab><tab><tab>with open(""run.sh"") as f:<tab><tab><tab><tab>for line in f:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return line.rstrip(""\r\n"")",0,"if line [ 0 ] != ""#"" :","if line . startswith ( ""run"" ) :",0.034400971,9.548450962,0.6
"def client_read(self, path, **kwargs):<tab>""""""Retrieve a value from a etcd key.""""""<tab>try:<tab><tab>res = self.client.read(<tab><tab><tab>path,<tab><tab><tab>timeout=kwargs.get(""timeout"", DEFAULT_TIMEOUT),<tab><tab><tab>recursive=kwargs.get(""recursive"") or kwargs.get(""all"", False),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>modified_indices = (res.modifiedIndex,) + tuple(<tab><tab><tab><tab>leaf.modifiedIndex for leaf in res.leaves<tab><tab><tab>)<tab><tab><tab>return max(modified_indices)<tab><tab>else:<tab><tab><tab>return res.value<tab>except EtcdKeyNotFound:<tab><tab>raise KeyNotFound(""The key %s was not found in etcd"" % path)<tab>except TimeoutError as e:<tab><tab>raise e",0,"if kwargs . get ( ""watch"" , False ) :",if res . hasModified ( ) :,0.029245312,8.08518271,0.274725275
"def populate_wrapper(klass, wrapping):<tab>for meth, how in klass._wrap_methods.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>func = getattr(wrapping, meth)<tab><tab>wrapper = make_wrapper(func, how)<tab><tab>setattr(klass, meth, wrapper)",1,"if not hasattr ( wrapping , meth ) :","if not hasattr ( wrapping , meth ) :",0.75,100,1
"def _copy_files(self, files, src, dest, message=""""):<tab>for filepath in files:<tab><tab>srcpath = os.path.join(src, filepath)<tab><tab>destpath = os.path.join(dest, filepath)<tab><tab>if message:<tab><tab><tab>print(""{}: {}"".format(message, destpath))<tab><tab>if os.path.exists(srcpath):<tab><tab><tab>destdir = os.path.dirname(destpath)<tab><tab><tab>if not os.path.isdir(destdir):<tab><tab><tab><tab>os.makedirs(destdir)<tab><tab><tab>shutil.copy(srcpath, destpath)<tab><tab><IF-STMT><tab><tab><tab>os.remove(destpath)",1,elif os . path . exists ( destpath ) :,elif os . path . exists ( destpath ) :,0.75,100,1
"def scan_iter(self, match=None, count=None):<tab>nodes = await self.cluster_nodes()<tab>for node in nodes:<tab><tab>if ""master"" in node[""flags""]:<tab><tab><tab>cursor = ""0""<tab><tab><tab>while cursor != 0:<tab><tab><tab><tab>pieces = [cursor]<tab><tab><tab><tab>if match is not None:<tab><tab><tab><tab><tab>pieces.extend([""MATCH"", match])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pieces.extend([""COUNT"", count])<tab><tab><tab><tab>response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces)<tab><tab><tab><tab>cursor, data = list(response.values())[0]<tab><tab><tab><tab>for item in data:<tab><tab><tab><tab><tab>yield item",1,if count is not None :,if count is not None :,0.75,100,1
"def restart(cls, request, server_name):<tab>with cls._servername_to_shell_server_lock:<tab><tab><IF-STMT><tab><tab><tab>servr = cls._servername_to_shell_server[server_name]<tab><tab><tab>servr.restart()",1,if server_name in cls . _servername_to_shell_server :,if server_name in cls . _servername_to_shell_server :,0.75,100,1
"def human_waiting_on(self):<tab>if self.waiting_on is None:<tab><tab>return ""N/A""<tab>things = []<tab>for cluster, queue in self.waiting_on.items():<tab><tab>queue_length = len(queue)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif queue_length == 1:<tab><tab><tab>things.append(f""`{cluster}`: `{queue[0].get_instance()}`"")<tab><tab>else:<tab><tab><tab>things.append(f""`{cluster}`: {len(queue)} instances"")<tab>return "", "".join(things)",1,if queue_length == 0 :,if queue_length == 0 :,0.75,100,1
"def psea(pname):<tab>""""""Parse PSEA output file.""""""<tab>fname = run_psea(pname)<tab>start = 0<tab>ss = """"<tab>with open(fname) as fp:<tab><tab>for l in fp:<tab><tab><tab>if l[0:6] == "">p-sea"":<tab><tab><tab><tab>start = 1<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if l[0] == ""\n"":<tab><tab><tab><tab>break<tab><tab><tab>ss = ss + l[0:-1]<tab>return ss",0,if not start :,if start == 0 :,0.045150551,10.68217516,0.4
"def encrypt_system_info_ssh_keys(ssh_info):<tab>for idx, user in enumerate(ssh_info):<tab><tab>for field in [""public_key"", ""private_key"", ""known_hosts""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ssh_info[idx][field] = encryptor.enc(ssh_info[idx][field])",0,if ssh_info [ idx ] [ field ] :,if user == ssh_info [ idx ] [ field ] :,0.522017617,69.30977286,0.386666667
"def get_shape(shape):<tab>""""""Convert the shape to correct dtype and vars.""""""<tab>ret = []<tab>for dim in shape:<tab><tab>if isinstance(dim, tvm.tir.IntImm):<tab><tab><tab>if libinfo()[""INDEX_DEFAULT_I64""] == ""ON"":<tab><tab><tab><tab>ret.append(dim)<tab><tab><tab>else:<tab><tab><tab><tab>val = int(dim)<tab><tab><tab><tab>assert val <= np.iinfo(np.int32).max<tab><tab><tab><tab>ret.append(tvm.tir.IntImm(""int32"", val))<tab><tab><IF-STMT><tab><tab><tab>ret.append(te.var(""any_dim"", ""int32""))<tab><tab>else:<tab><tab><tab>ret.append(dim)<tab>return ret",0,"elif isinstance ( dim , tvm . tir . Any ) :","elif dim == ""Any"" :",0.009963493,4.736913377,0.25
"def unpack(sources):<tab>temp_dir = tempfile.mkdtemp(""-scratchdir"", ""unpacker-"")<tab>for package, content in sources.items():<tab><tab>filepath = package.split(""/"")<tab><tab>dirpath = os.sep.join(filepath[:-1])<tab><tab>packagedir = os.path.join(temp_dir, dirpath)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(packagedir)<tab><tab>mod = open(os.path.join(packagedir, filepath[-1]), ""wb"")<tab><tab>try:<tab><tab><tab>mod.write(base64.b64decode(content))<tab><tab>finally:<tab><tab><tab>mod.close()<tab>return temp_dir",0,if not os . path . isdir ( packagedir ) :,if not os . path . exists ( packagedir ) :,0.602001933,70.16879391,0.75
"def set_torrent_path(self, torrent_id, path):<tab>try:<tab><tab>if not self.connect():<tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_move_completed_path(torrent_id, path).get()<tab><tab>self.client.core.set_torrent_move_completed(torrent_id, 1).get()<tab>except Exception:<tab><tab>return False<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>self.disconnect()<tab>return True",1,if self . client :,if self . client :,0.75,100,1
"def _get_specs(self, link, source, target):<tab>for src_spec, code in link.code.items():<tab><tab>src_specs = src_spec.split(""."")<tab><tab>if src_spec.startswith(""event:""):<tab><tab><tab>src_spec = (None, src_spec)<tab><tab><IF-STMT><tab><tab><tab>src_spec = (""."".join(src_specs[:-1]), src_specs[-1])<tab><tab>else:<tab><tab><tab>src_prop = src_specs[0]<tab><tab><tab>if isinstance(source, Reactive):<tab><tab><tab><tab>src_prop = source._rename.get(src_prop, src_prop)<tab><tab><tab>src_spec = (None, src_prop)<tab>return [(src_spec, (None, None), code)]",1,elif len ( src_specs ) > 1 :,elif len ( src_specs ) > 1 :,0.75,100,1
"def deserialize(self, meth, content_type, body):<tab>meth_deserializers = getattr(meth, ""wsgi_deserializers"", {})<tab>try:<tab><tab>mtype = _MEDIA_TYPE_MAP.get(content_type, content_type)<tab><tab><IF-STMT><tab><tab><tab>deserializer = meth_deserializers[mtype]<tab><tab>else:<tab><tab><tab>deserializer = self.default_deserializers[mtype]<tab>except (KeyError, TypeError):<tab><tab>raise exception.InvalidContentType(content_type=content_type)<tab>return deserializer().deserialize(body)",0,if mtype in meth_deserializers :,if meth_deserializers :,0.067674239,1.00E-10,0.416666667
"def object_inspect(self, oname, detail_level=0):<tab>""""""Get object info about oname""""""<tab>with self.builtin_trap:<tab><tab>info = self._object_find(oname)<tab><tab><IF-STMT><tab><tab><tab>return self.inspector.info(<tab><tab><tab><tab>info.obj, oname, info=info, detail_level=detail_level<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return oinspect.object_info(name=oname, found=False)",0,if info . found :,if info :,0.067674239,1.00E-10,0.7
"def wrapper(*args, **kargs):<tab>for key, value in vkargs.items():<tab><tab><IF-STMT><tab><tab><tab>abort(403, ""Missing parameter: %s"" % key)<tab><tab>try:<tab><tab><tab>kargs[key] = value(kargs[key])<tab><tab>except ValueError:<tab><tab><tab>abort(403, ""Wrong parameter format for: %s"" % key)<tab>return func(*args, **kargs)",1,if key not in kargs :,if key not in kargs :,0.75,100,1
"def _append_fragment(self, ctx, frag_content):<tab>try:<tab><tab>ctx[""dest_stream""].write(frag_content)<tab><tab>ctx[""dest_stream""].flush()<tab>finally:<tab><tab>if self.__do_ytdl_file(ctx):<tab><tab><tab>self._write_ytdl_file(ctx)<tab><tab><IF-STMT><tab><tab><tab>os.remove(encodeFilename(ctx[""fragment_filename_sanitized""]))<tab><tab>del ctx[""fragment_filename_sanitized""]",0,"if not self . params . get ( ""keep_fragments"" , False ) :","if ctx [ ""fragment_filename_sanitized"" ] :",0.009464483,3.338392248,0.222222222
"def override_args_required_option(argument_table, args, session, **kwargs):<tab># This function overrides the 'required' property of an argument<tab># if a value corresponding to that argument is present in the config<tab># file<tab># We don't want to override when user is viewing the help so that we<tab># can show the required options correctly in the help<tab>need_to_override = False if len(args) == 1 and args[0] == ""help"" else True<tab>if need_to_override:<tab><tab>parsed_configs = configutils.get_configs(session)<tab><tab>for arg_name in argument_table.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>argument_table[arg_name].required = False",0,"if arg_name . replace ( ""-"" , ""_"" ) in parsed_configs :",if arg_name in parsed_configs :,0.049179187,22.02460552,0.486842105
"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",0,elif element in child :,elif element == child :,0.080342842,22.95748847,0.533333333
"def teardown_class(cls):<tab>collections = cls.discovery.list_collections(cls.environment_id).get_result()[<tab><tab>""collections""<tab>]<tab>for collection in collections:<tab><tab><IF-STMT><tab><tab><tab>print(""Deleting the temporary collection"")<tab><tab><tab>cls.discovery.delete_collection(cls.environment_id, cls.collection_id)<tab><tab><tab>break",0,"if collection [ ""name"" ] == cls . collection_name :","if collection [ ""name"" ] == cls . collection_id :",0.642805659,86.66415731,1
"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""disk_shares"" in plugin_result[""device""]:<tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab>if ""disk_shares"" in subdevice:<tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice",0,"if ""device"" not in plugin_result :","if plugin_result [ ""name"" ] != plugin_name :",0.023749772,12.09034063,0.458333333
"def accept_request(self, request):<tab>if self.restriction_type == BaseViewRestriction.PASSWORD:<tab><tab>passed_restrictions = request.session.get(<tab><tab><tab>self.passed_view_restrictions_session_key, []<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.LOGIN:<tab><tab>if not request.user.is_authenticated:<tab><tab><tab>return False<tab>elif self.restriction_type == BaseViewRestriction.GROUPS:<tab><tab>if not request.user.is_superuser:<tab><tab><tab>current_user_groups = request.user.groups.all()<tab><tab><tab>if not any(group in current_user_groups for group in self.groups.all()):<tab><tab><tab><tab>return False<tab>return True",0,if self . id not in passed_restrictions :,if not passed_restrictions :,0.079014916,28.87156631,0.277777778
"def __setitem__(self, index, item):<tab>try:<tab><tab>start, stop, step = index.start, index.stop, index.step<tab>except AttributeError:<tab><tab>index = operator.index(index)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.lists[0][index] = item<tab><tab>else:<tab><tab><tab>tmp = list(self)<tab><tab><tab>tmp[index] = item<tab><tab><tab>self.lists[:] = [tmp]<tab><tab>self._balance_list(0)<tab><tab>return<tab>list_idx, rel_idx = self._translate_index(index)<tab>if list_idx is None:<tab><tab>raise IndexError()<tab>self.lists[list_idx][rel_idx] = item",0,if len ( self . lists ) == 1 :,if self . lists [ 0 ] :,0.103673262,16.05294619,0.272727273
"def random_permutation_equality_groups(n_groups, n_perms_per_group, n_items, prob):<tab>fingerprints = set()<tab>for _ in range(n_groups):<tab><tab>perms = random_equal_permutations(n_perms_per_group, n_items, prob)<tab><tab>perm = perms[0]<tab><tab>fingerprint = tuple(perm.get(i, i) for i in range(n_items))<tab><tab><IF-STMT><tab><tab><tab>yield perms<tab><tab><tab>fingerprints.add(fingerprint)",1,if fingerprint not in fingerprints :,if fingerprint not in fingerprints :,0.75,100,1
"def get_proper_pip():  # no cov<tab>if not venv_active():<tab><tab>default_pip = os.environ.get(""_DEFAULT_PIP_"", None)<tab><tab><IF-STMT><tab><tab><tab>return default_pip<tab><tab>elif not ON_WINDOWS:<tab><tab><tab>return ""pip3""<tab>return ""pip""",0,if default_pip :,if default_pip is not None :,0.090364769,1.00E-10,0.314285714
"def close(self, checkcount=False):<tab>self.mutex.acquire()<tab>try:<tab><tab>if checkcount:<tab><tab><tab>self.openers -= 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.do_close()<tab><tab>else:<tab><tab><tab>if self.openers > 0:<tab><tab><tab><tab>self.do_close()<tab><tab><tab>self.openers = 0<tab>finally:<tab><tab>self.mutex.release()",0,if self . openers == 0 :,if self .eners == 0 :,0.356932062,50,0.571428571
"def _lxml_default_loader(href, parse, encoding=None, parser=None):<tab>if parse == ""xml"":<tab><tab>data = etree.parse(href, parser).getroot()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>f = urlopen(href)<tab><tab>else:<tab><tab><tab>f = open(href, ""rb"")<tab><tab>data = f.read()<tab><tab>f.close()<tab><tab>if not encoding:<tab><tab><tab>encoding = ""utf-8""<tab><tab>data = data.decode(encoding)<tab>return data",0,"if ""://"" in href :","if parse == ""http"" :",0.034123066,11.59119923,0.36
"def Save(self):<tab># Save the AUI perspectives if PersistenceManager allows it<tab>eventHandler = self._window.GetEventHandler()<tab>isAGWAui = isinstance(eventHandler, AUI.AuiManager)<tab>if not isAGWAui:<tab><tab>return True<tab>if self._manager.GetManagerStyle() & PM_SAVE_RESTORE_AUI_PERSPECTIVES:<tab><tab># Allowed to save and restore perspectives<tab><tab>perspective = eventHandler.SavePerspective()<tab><tab><IF-STMT><tab><tab><tab>name = PERSIST_AGW_AUI_PERSPECTIVE<tab><tab>else:<tab><tab><tab>name = PERSIST_AUI_PERSPECTIVE<tab><tab>self._pObject.SaveValue(name, perspective)<tab>return True",1,if isAGWAui :,if isAGWAui :,0.531170663,1.00E-10,1
"def get_arg_list_scalar_arg_dtypes(arg_types):<tab>result = []<tab>for arg_type in arg_types:<tab><tab>if isinstance(arg_type, ScalarArg):<tab><tab><tab>result.append(arg_type.dtype)<tab><tab>elif isinstance(arg_type, VectorArg):<tab><tab><tab>result.append(None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(np.int64)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""arg type not understood: %s"" % type(arg_type))<tab>return result",0,if arg_type . with_offset :,"elif isinstance ( arg_type , int ) :",0.02204854,16.78445963,0.166666667
"def perform_secure_deletion_of_temporary_files(self):<tab># Delete the outdated temp files if older than 1 day<tab>for f in os.listdir(self.state.settings.tmp_path):<tab><tab>path = os.path.join(self.state.settings.tmp_path, f)<tab><tab>timestamp = datetime.fromtimestamp(os.path.getmtime(path))<tab><tab><IF-STMT><tab><tab><tab>overwrite_and_remove(path)",0,"if is_expired ( timestamp , days = 1 ) :",if timestamp > 1 :,0.015145995,3.72531,0.584615385
"def set_torrent_ratio(self, torrent_ids, ratio):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_stop_at_ratio(torrent_ids, True).get()<tab><tab>self.client.core.set_torrent_stop_ratio(torrent_ids, ratio).get()<tab>except Exception as err:<tab><tab>return False<tab>finally:<tab><tab>if self.client:<tab><tab><tab>self.disconnect()<tab>return True",0,if not self . connect ( ) :,"if self . client . core . get_torrent_stop_ratio ( torrent_ids , ratio ) is None :",0.02840089,4.14114133,0.185714286
"def value_to_db_datetime(self, value):<tab>if value is None:<tab><tab>return None<tab># MySQL doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = value.astimezone(timezone.utc).replace(tzinfo=None)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""MySQL backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab># MySQL doesn't support microseconds<tab>return six.text_type(value.replace(microsecond=0))",1,if settings . USE_TZ :,if settings . USE_TZ :,0.75,100,1
"def remote_run_capture_all(login, cmd, log=None):<tab>""""""Run the remote command and return the (retval, stdout, stderr) result.""""""<tab>if sys.platform == ""win32"":<tab><tab><IF-STMT><tab><tab><tab>login = ""%s@%s"" % (getpass.getuser(), login)<tab><tab>cmd = 'plink -A -batch %s ""%s""' % (login, cmd)<tab>else:<tab><tab>cmd = 'ssh -A -o BatchMode=yes %s ""%s""' % (login, cmd)<tab>__run_log(logstream, ""running '%s'"", cmd)<tab>p = subprocess.Popen(argv, stdout=subprocess.PIPE, stderr=subprocess.PIPE)<tab>stdout, stderr = p.communicate()<tab>status = p.returncode<tab>return status, stdout, stderr",1,"if ""@"" not in login :","if ""@"" not in login :",0.75,100,1
"def parseLeftHandSideExpressionAllowCall():<tab>marker = None<tab>expr = None<tab>args = None<tab>property = None<tab>marker = createLocationMarker()<tab>expr = parseNewExpression() if matchKeyword(""new"") else parsePrimaryExpression()<tab>while (match(""."") or match(""["")) or match(""(""):<tab><tab><IF-STMT><tab><tab><tab>args = parseArguments()<tab><tab><tab>expr = delegate.createCallExpression(expr, args)<tab><tab>elif match(""[""):<tab><tab><tab>property = parseComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""["", expr, property)<tab><tab>else:<tab><tab><tab>property = parseNonComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""."", expr, property)<tab><tab>if marker:<tab><tab><tab>marker.end()<tab><tab><tab>marker.apply(expr)<tab>return expr",0,"if match ( ""("" ) :","if match ( ""["" ) :",0.378267095,50,1
"def getImageId(self, stuff):<tab>if not isinstance(stuff, Module):<tab><tab>return -1<tab>if stuff.charge is None:<tab><tab>return -1<tab>else:<tab><tab>iconFile = stuff.charge.iconID if stuff.charge.iconID else """"<tab><tab><IF-STMT><tab><tab><tab>return self.fittingView.imageList.GetImageIndex(iconFile, ""icons"")<tab><tab>else:<tab><tab><tab>return -1",1,if iconFile :,if iconFile :,0.531170663,1.00E-10,1
"def instance_reader():<tab>for epoch_index in range(epoch):<tab><tab>if shuffle:<tab><tab><tab>if shuffle_seed is not None:<tab><tab><tab><tab>np.random.seed(shuffle_seed)<tab><tab><tab>np.random.shuffle(examples)<tab><tab><IF-STMT><tab><tab><tab>self.current_train_epoch = epoch_index<tab><tab>for (index, example) in enumerate(examples):<tab><tab><tab>if phase == ""train"":<tab><tab><tab><tab>self.current_train_example = index + 1<tab><tab><tab>feature = self.convert_example(<tab><tab><tab><tab>index, example, self.get_labels(), self.max_seq_len, self.tokenizer<tab><tab><tab>)<tab><tab><tab>instance = self.generate_instance(feature)<tab><tab><tab>yield instance",1,"if phase == ""train"" :","if phase == ""train"" :",0.75,100,1
"def i2h(self, pkt, x):<tab>if x is not None:<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_6: Internal value too negative: %d"" % x)<tab><tab><tab>x = 0<tab><tab>elif x > 999999999:<tab><tab><tab>warning(""Fixed3_6: Internal value too positive: %d"" % x)<tab><tab><tab>x = 999999999<tab><tab>x = x * 1e-6<tab>return x",1,if x < 0 :,if x < 0 :,0.75,100,1
"def _is_section_header(self) -> bool:<tab>section, underline = self._line_iter.peek(2)<tab>section = section.lower()<tab>if section in self._sections and isinstance(underline, str):<tab><tab>return bool(_numpy_section_regex.match(underline))<tab>elif self._directive_sections:<tab><tab><IF-STMT><tab><tab><tab>for directive_section in self._directive_sections:<tab><tab><tab><tab>if section.startswith(directive_section):<tab><tab><tab><tab><tab>return True<tab>return False",0,if _directive_regex . match ( section ) :,if self . _directive_regex . match ( section ) :,0.445018652,75.3922118,0.384615385
"def _parse_date_fmt():<tab>fmt = get_format(""DATE_FORMAT"")<tab>escaped = False<tab>for char in fmt:<tab><tab>if escaped:<tab><tab><tab>escaped = False<tab><tab>elif char == ""\\"":<tab><tab><tab>escaped = True<tab><tab>elif char in ""Yy"":<tab><tab><tab>yield ""year""<tab><tab>elif char in ""bEFMmNn"":<tab><tab><tab>yield ""month""<tab><tab><IF-STMT><tab><tab><tab>yield ""day""",0,"elif char in ""dj"" :","elif char in ""d"" :",0.394778655,48.89230224,1
"def _wait_port_open(port, max_wait=60):<tab>print(f""Waiting for port {port}"")<tab>start = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>socket.create_connection((""localhost"", port), timeout=1)<tab><tab>except OSError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>time.sleep(1)<tab><tab>else:<tab><tab><tab>return",0,if time . time ( ) - start > max_wait :,if time . time ( ) - start >= max_wait :,0.872196729,78.254229,1
"def _list(self):<tab>data_sources = self.mkt_contract.functions.getAllProviders().call()<tab>data = []<tab>for index, data_source in enumerate(data_sources):<tab><tab>if index > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data.append(dict(dataset=self.to_text(data_source)))<tab>return pd.DataFrame(data)",0,"if ""test"" not in Web3 . toText ( data_source ) . lower ( ) :","if isinstance ( data_source , str ) :",0.020563112,13.20001239,0.206349206
"def log_start(self, prefix, msg):<tab>with self._log_lock:<tab><tab>if self._last_log_prefix != prefix:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._log_file.write(""\n"")<tab><tab><tab>self._log_file.write(prefix)<tab><tab>self._log_file.write(msg)<tab><tab>self._last_log_prefix = prefix",0,if self . _last_log_prefix is not None :,if self . _log_file :,0.120555985,26.76307143,0.444444444
"def _split_string_to_tokens(text):<tab>""""""Splits text to a list of string tokens.""""""<tab>if not text:<tab><tab>return []<tab>ret = []<tab>token_start = 0<tab># Classify each character in the input string<tab>is_alnum = [c in _ALPHANUMERIC_CHAR_SET for c in text]<tab>for pos in xrange(1, len(text)):<tab><tab>if is_alnum[pos] != is_alnum[pos - 1]:<tab><tab><tab>token = text[token_start:pos]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(token)<tab><tab><tab>token_start = pos<tab>final_token = text[token_start:]<tab>ret.append(final_token)<tab>return ret",0,"if token != u"" "" or token_start == 0 :",if token :,0.051727126,1.00E-10,0.571428571
"def _install_groups(self, grp_specs):<tab>try:<tab><tab>self.base.env_group_install(<tab><tab><tab>grp_specs,<tab><tab><tab>tuple(self.base.conf.group_package_types),<tab><tab><tab>strict=self.base.conf.strict,<tab><tab>)<tab>except dnf.exceptions.Error:<tab><tab><IF-STMT><tab><tab><tab>raise",1,if self . base . conf . strict :,if self . base . conf . strict :,0.75,100,1
def _idx2token(idxs):<tab>for idx in idxs:<tab><tab>if idx < self.tgt_vocab_size:<tab><tab><tab>token = self.tgt_vocab([[idx]])[0][0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield token<tab><tab>else:<tab><tab><tab>yield self.kb_keys[idx - self.tgt_vocab_size],0,if token == self . eos_token :,if token in self . kb_keys :,0.136462742,13.35433989,0.571428571
"def increment(s):<tab>if not s:<tab><tab>return ""1""<tab>for sequence in string.digits, string.lowercase, string.uppercase:<tab><tab>lastc = s[-1]<tab><tab>if lastc in sequence:<tab><tab><tab>i = sequence.index(lastc) + 1<tab><tab><tab>if i >= len(sequence):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>s = sequence[0] * 2<tab><tab><tab><tab><tab>if s == ""00"":<tab><tab><tab><tab><tab><tab>s = ""10""<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>s = increment(s[:-1]) + sequence[0]<tab><tab><tab>else:<tab><tab><tab><tab>s = s[:-1] + sequence[i]<tab><tab><tab>return s<tab>return s  # Don't increment",1,if len ( s ) == 1 :,if len ( s ) == 1 :,0.75,100,1
"def main():<tab>import sys, getopt<tab>try:<tab><tab>opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""])<tab>except getopt.GetoptError as err:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>output = None<tab>for o, a in opts:<tab><tab>if o in (""-h"", ""--help""):<tab><tab><tab>usage()<tab><tab><tab>sys.exit()<tab><tab><IF-STMT><tab><tab><tab>output = a<tab><tab>else:<tab><tab><tab>usage()<tab><tab><tab>sys.exit(1)<tab>if not args:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>concat_flv(args, output)",0,"elif o in ( ""-o"" , ""--output"" ) :","if o in ( ""-o"" , ""--output"" ) :",0.515003344,91.21679091,0.6
def binaryFindInDocument():<tab>hi = len(self.headings)<tab>lo = 0<tab>while lo < hi:<tab><tab>mid = (lo + hi) // 2<tab><tab>h = self.headings[mid]<tab><tab><IF-STMT><tab><tab><tab>lo = mid + 1<tab><tab>elif h.start > position:<tab><tab><tab>hi = mid<tab><tab>else:<tab><tab><tab>return binaryFindHeading(h),0,if h . end_of_last_child < position :,if h . start < position :,0.38848939,17.4473943,0.571428571
"def on_key_press(self, *events):<tab># The JS editor has already** handled the key!<tab>for ev in events:<tab><tab><IF-STMT><tab><tab><tab>ivar = ""minibufferWidget"" if self.name == ""minibuffer"" else self.name<tab><tab><tab>self.root.do_key(ev, ivar)",0,if self . should_be_leo_key ( ev ) :,if ev . key_code == KEY_PRESS :,0.02067646,4.662759254,0.477272727
"def _make_dataset(data_dir):<tab>data_dir = os.path.expanduser(data_dir)<tab>if not os.path.isdir(data_dir):<tab><tab>raise (""{} should be a dir"".format(data_dir))<tab>images = []<tab>for root, _, fnames in sorted(os.walk(data_dir, followlinks=True)):<tab><tab>for fname in sorted(fnames):<tab><tab><tab>file_path = os.path.join(root, fname)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>images.append(file_path)<tab>return images",0,if _is_valid_file ( file_path ) :,if os . path . isfile ( file_path ) :,0.268871115,39.89486553,0.36
"def release(provider, connection, cache=None):<tab>if cache is not None:<tab><tab>db_session = cache.db_session<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>cursor = connection.cursor()<tab><tab><tab><tab>sql = ""SET foreign_key_checks = 1""<tab><tab><tab><tab>if core.local.debug:<tab><tab><tab><tab><tab>log_orm(sql)<tab><tab><tab><tab>cursor.execute(sql)<tab><tab><tab>except:<tab><tab><tab><tab>provider.pool.drop(connection)<tab><tab><tab><tab>raise<tab>DBAPIProvider.release(provider, connection, cache)",0,if db_session is not None and db_session . ddl and cache . saved_fk_state :,if db_session is not None and db_session . foreign_key :,0.423700174,51.58337092,0.683333333
"def get_pfunctions(self):<tab>p_functions = []<tab>for name, item in self.pdict.items():<tab><tab>if name[:2] != ""p_"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(item, (types.FunctionType, types.MethodType)):<tab><tab><tab>line = func_code(item).co_firstlineno<tab><tab><tab>file = func_code(item).co_filename<tab><tab><tab>p_functions.append((line, file, name, item.__doc__))<tab># Sort all of the actions by line number<tab>p_functions.sort()<tab>self.pfuncs = p_functions",0,"if name == ""p_error"" :","if name . startswith ( ""_"" ) :",0.04979442,11.04479557,0.727272727
"def get_output_sizes(self):<tab>sizes = []<tab>output_paths = self.get_output_fnames()<tab>for outfile in [unicodify(o) for o in output_paths]:<tab><tab><IF-STMT><tab><tab><tab>sizes.append((outfile, os.stat(outfile).st_size))<tab><tab>else:<tab><tab><tab>sizes.append((outfile, 0))<tab>return sizes",1,if os . path . exists ( outfile ) :,if os . path . exists ( outfile ) :,0.75,100,1
"def normalize_crlf(tree):<tab>for elem in tree.getiterator():<tab><tab><IF-STMT><tab><tab><tab>elem.text = elem.text.replace(""\r\n"", ""\n"")<tab><tab>if elem.tail:<tab><tab><tab>elem.tail = elem.tail.replace(""\r\n"", ""\n"")",1,if elem . text :,if elem . text :,0.75,100,1
"def visit_decorator(self, o: Decorator) -> None:<tab>if self.is_private_name(o.func.name, o.func.fullname):<tab><tab>return<tab>is_abstract = False<tab>for decorator in o.original_decorators:<tab><tab><IF-STMT><tab><tab><tab>if self.process_name_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab><tab>elif isinstance(decorator, MemberExpr):<tab><tab><tab>if self.process_member_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab>self.visit_func_def(o.func, is_abstract=is_abstract)",1,"if isinstance ( decorator , NameExpr ) :","if isinstance ( decorator , NameExpr ) :",0.75,100,1
"def formatweekday(self, day, width):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab><IF-STMT><tab><tab><tab>names = day_name<tab><tab>else:<tab><tab><tab>names = day_abbr<tab><tab>name = names[day]<tab><tab>if encoding is not None:<tab><tab><tab>name = name.decode(encoding)<tab><tab>return name[:width].center(width)",0,if width >= 9 :,if self . use_abbr :,0.034123066,7.809849842,0.36
"def autocommitter():<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if self._auto_commit_enable:<tab><tab><tab><tab>self._auto_commit()<tab><tab><tab>self._cluster.handler.sleep(self._auto_commit_interval_ms / 1000)<tab><tab>except ReferenceError:<tab><tab><tab>break<tab><tab>except Exception:<tab><tab><tab># surface all exceptions to the main thread<tab><tab><tab>self._worker_exception = sys.exc_info()<tab><tab><tab>break<tab>log.debug(""Autocommitter thread exiting"")",0,if not self . _running :,if self . _auto_commit_interval_ms == 0 :,0.047631794,11.11492478,0.4
"def pseudo_raw_input(self, prompt):<tab>""""""copied from cmd's cmdloop; like raw_input, but accounts for changed stdin, stdout""""""<tab>if self.use_rawinput:<tab><tab>try:<tab><tab><tab>line = raw_input(prompt)<tab><tab>except EOFError:<tab><tab><tab>line = ""EOF""<tab>else:<tab><tab>self.stdout.write(prompt)<tab><tab>self.stdout.flush()<tab><tab>line = self.stdin.readline()<tab><tab>if not len(line):<tab><tab><tab>line = ""EOF""<tab><tab>else:<tab><tab><tab><IF-STMT>  # this was always true in Cmd<tab><tab><tab><tab>line = line[:-1]<tab>return line",1,"if line [ - 1 ] == ""\n"" :","if line [ - 1 ] == ""\n"" :",0.75,100,1
"def get_suggestion(self, suggestion):<tab>if suggestion is None:<tab><tab>return suggestion<tab>counter = 0<tab>results = []<tab>for feature in self._features:<tab><tab>if feature in self._discrete_features:<tab><tab><tab>result, counter = self._get_discrete_suggestion(<tab><tab><tab><tab>feature=feature, suggestion=suggestion, counter=counter<tab><tab><tab>)<tab><tab><tab>results.append(result)<tab><tab><IF-STMT><tab><tab><tab>result, counter = self._get_categorical_suggestion(<tab><tab><tab><tab>feature=feature, suggestion=suggestion, counter=counter<tab><tab><tab>)<tab><tab><tab>results.append(result)<tab><tab>else:<tab><tab><tab>results.append(suggestion[counter])<tab><tab><tab>counter = counter + 1<tab>return dict(zip(self._features, results))",1,elif feature in self . _categorical_features :,elif feature in self . _categorical_features :,0.75,100,1
"def gen_raw_options(modelines):<tab>for m in modelines:<tab><tab>opt = m.partition("":"")[2].strip()<tab><tab><IF-STMT><tab><tab><tab>for subopt in (s for s in opt.split(MULTIOPT_SEP)):<tab><tab><tab><tab>yield subopt<tab><tab>else:<tab><tab><tab>yield opt",1,if MULTIOPT_SEP in opt :,if MULTIOPT_SEP in opt :,0.75,100,1
"def _parse_chunked(self, data):<tab>body = []<tab>trailers = {}<tab>n = 0<tab>lines = data.split(b""\r\n"")<tab># parse body<tab>while True:<tab><tab>size, chunk = lines[n : n + 2]<tab><tab>size = int(size, 16)<tab><tab>if size == 0:<tab><tab><tab>n += 1<tab><tab><tab>break<tab><tab>self.assertEqual(size, len(chunk))<tab><tab>body.append(chunk)<tab><tab>n += 2<tab><tab># we /should/ hit the end chunk, but check against the size of<tab><tab># lines so we're not stuck in an infinite loop should we get<tab><tab># malformed data<tab><tab><IF-STMT><tab><tab><tab>break<tab>return b"""".join(body)",0,if n > len ( lines ) :,if n >= len ( lines ) :,0.549040681,59.69491792,1
"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab><IF-STMT><tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab>if t[:1] == "":"":<tab><tab><tab>t = t[1:]<tab><tab>if "":"" not in path:<tab><tab><tab>path = "":"" + path<tab><tab>if path[-1:] != "":"":<tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path",0,if ( not s ) or isabs ( t ) :,if path is None :,0.074136451,3.826166066,0.183333333
"def validate_route_filter(cmd, namespace):<tab>from msrestazure.tools import is_valid_resource_id, resource_id<tab>if namespace.route_filter:<tab><tab><IF-STMT><tab><tab><tab>namespace.route_filter = resource_id(<tab><tab><tab><tab>subscription=get_subscription_id(cmd.cli_ctx),<tab><tab><tab><tab>resource_group=namespace.resource_group_name,<tab><tab><tab><tab>namespace=""Microsoft.Network"",<tab><tab><tab><tab>type=""routeFilters"",<tab><tab><tab><tab>name=namespace.route_filter,<tab><tab><tab>)",1,if not is_valid_resource_id ( namespace . route_filter ) :,if not is_valid_resource_id ( namespace . route_filter ) :,0.75,100,1
"def expanded_output(self):<tab>""""""Iterate over output files while dynamic output is expanded.""""""<tab>for f, f_ in zip(self.output, self.rule.output):<tab><tab>if f in self.dynamic_output:<tab><tab><tab>expansion = self.expand_dynamic(f_)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield f_<tab><tab><tab>for f, _ in expansion:<tab><tab><tab><tab>file_to_yield = IOFile(f, self.rule)<tab><tab><tab><tab>file_to_yield.clone_flags(f_)<tab><tab><tab><tab>yield file_to_yield<tab><tab>else:<tab><tab><tab>yield f",0,if not expansion :,if expansion :,0.096488528,1.00E-10,0.416666667
"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",0,if sty . drawing :,"if fragment . endswith ( ""\n"" ) :",0.02800146,4.932351569,0.333333333
"def decref(self, key, count=1):<tab>with self._lock:<tab><tab>slot = self._dict[key]<tab><tab><IF-STMT><tab><tab><tab>del self._dict[key]<tab><tab>else:<tab><tab><tab>slot[1] -= count<tab><tab><tab>self._dict[key] = slot",0,if slot [ 1 ] < count :,if count == 0 :,0.019907918,7.654112967,0.314814815
"def stale_rec(node, nodes):<tab>if node.abspath() in node.ctx.env[Build.CFG_FILES]:<tab><tab>return<tab>if getattr(node, ""children"", []):<tab><tab>for x in node.children.values():<tab><tab><tab>if x.name != ""c4che"":<tab><tab><tab><tab>stale_rec(x, nodes)<tab>else:<tab><tab>for ext in DYNAMIC_EXT:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if not node in nodes:<tab><tab><tab><tab>if can_delete(node):<tab><tab><tab><tab><tab>Logs.warn(""Removing stale file -> %r"", node)<tab><tab><tab><tab><tab>node.delete()",1,if node . name . endswith ( ext ) :,if node . name . endswith ( ext ) :,0.75,100,1
"def _do_ssl_handshake(self):<tab>try:<tab><tab>self.socket.do_handshake()<tab>except ssl.SSLError as err:<tab><tab>if err.args[0] in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):<tab><tab><tab>return<tab><tab>elif err.args[0] == ssl.SSL_ERROR_EOF:<tab><tab><tab>return self.handle_close()<tab><tab>raise<tab>except OSError as err:<tab><tab><IF-STMT><tab><tab><tab>return self.handle_close()<tab>else:<tab><tab>self._ssl_accepting = False",0,if err . args [ 0 ] == errno . ECONNABORTED :,if err . args [ 0 ] == errno . EBADF :,0.664422563,84.23626744,0.75
"def test_full_hd_tv(self):<tab>cur_test = ""full_hd_tv""<tab>cur_qual = common.Quality.FULLHDTV<tab>for name, tests in iteritems(self.test_cases):<tab><tab>for test in tests:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertEqual(cur_qual, common.Quality.name_quality(test))<tab><tab><tab>else:<tab><tab><tab><tab>self.assertNotEqual(cur_qual, common.Quality.name_quality(test))",1,if name == cur_test :,if name == cur_test :,0.75,100,1
"def debug_tree(tree):<tab>l = []<tab>for elt in tree:<tab><tab>if isinstance(elt, int):<tab><tab><tab>l.append(_names.get(elt, elt))<tab><tab><IF-STMT><tab><tab><tab>l.append(elt)<tab><tab>else:<tab><tab><tab>l.append(debug_tree(elt))<tab>return l",1,"elif isinstance ( elt , str ) :","elif isinstance ( elt , str ) :",0.75,100,1
"def get_all_missing_headers(self):<tab># Heavy operation done in one optimized shot<tab>for chunk_height, expected_hash in reversed(list(self.checkpoints.items())):<tab><tab>if chunk_height in self.known_missing_checkpointed_chunks:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.known_missing_checkpointed_chunks.add(chunk_height)<tab>return self.known_missing_checkpointed_chunks",0,"if self . chunk_hash ( chunk_height , 1000 ) != expected_hash :",if expected_hash in self . known_missing_checkpointed_chunks :,0.022955525,10.9127852,0.4
"def get_byname(userId, documentName, session=None):<tab>if not session:<tab><tab>session = db.Session<tab>ret = {}<tab>result = (<tab><tab>session.query(LegacyArchiveDocument)<tab><tab>.filter_by(userId=userId, documentName=documentName)<tab><tab>.first()<tab>)<tab>if result:<tab><tab>obj = dict(<tab><tab><tab>(key, value)<tab><tab><tab>for key, value in vars(result).items()<tab><tab><tab><IF-STMT><tab><tab>)<tab><tab>ret = obj<tab>return ret",1,"if not key . startswith ( ""_"" )","if not key . startswith ( ""_"" )",0.75,100,1
"def cb(ipdb, msg, action):<tab>if action == ""RTM_NEWLINK"" and msg.get_attr(""IFLA_IFNAME"", """") in (ifP1, ifP2):<tab><tab>obj = ipdb.interfaces[msg[""index""]]<tab><tab><IF-STMT><tab><tab><tab>ipdb.interfaces[ifM].add_port(obj)<tab><tab>try:<tab><tab><tab>ipdb.interfaces[ifM].commit()<tab><tab>except Exception:<tab><tab><tab>pass",0,if obj not in ipdb . interfaces [ ifM ] :,if obj is not None :,0.149197313,8.389861811,0.28
"def reorder_encoder_rules(self, nts):<tab>""""""reorder rules so that any rules with ENCODER_PREFERRED is first""""""<tab>for nt in nts.values():<tab><tab>first_rules = []<tab><tab>rest_of_the_rules = []<tab><tab>for r in nt.rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>first_rules.append(r)<tab><tab><tab>else:<tab><tab><tab><tab>rest_of_the_rules.append(r)<tab><tab>nt.rules = first_rules + rest_of_the_rules",0,"if r . conditions . contains ( ""ENCODER_PREFERRED"" ) :","if r . type == ""ENCODER_PREFERRED"" :",0.111846305,36.96446398,0.487179487
"def update_url(self, s, keywords):<tab>pc = self<tab>w = pc.ensure_text_widget()<tab>pc.show()<tab>if 1:<tab><tab>w.setPlainText("""")<tab>else:<tab><tab>url = pc.get_url(s, ""@url"")<tab><tab><IF-STMT><tab><tab><tab>w.setPlainText(""@url %s"" % url)<tab><tab>else:<tab><tab><tab>w.setPlainText(""@url: no url given"")",1,if url :,if url :,0.531170663,1.00E-10,1
"def _update_engines(self, engines):<tab>""""""Update our engines dict and _ids from a dict of the form: {id:uuid}.""""""<tab>for k, v in iteritems(engines):<tab><tab>eid = int(k)<tab><tab><IF-STMT><tab><tab><tab>self._ids.append(eid)<tab><tab>self._engines[eid] = v<tab>self._ids = sorted(self._ids)<tab>if (<tab><tab>sorted(self._engines.keys()) != list(range(len(self._engines)))<tab><tab>and self._task_scheme == ""pure""<tab><tab>and self._task_socket<tab>):<tab><tab>self._stop_scheduling_tasks()",0,if eid not in self . _engines :,if eid not in self . _ids :,0.480621306,75.06238538,1
def test_delete_chat_thread(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>await self.chat_client.delete_chat_thread(self.thread_id)<tab><tab># delete created users and chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id),1,if not self . is_playback ( ) :,if not self . is_playback ( ) :,0.75,100,1
"def _to_protobuf_matrix(matrix, p_matrix, transformation=None):<tab>for row in matrix:<tab><tab>p_row = p_matrix.rows.add()<tab><tab>for cell in row:<tab><tab><tab>value = cell<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = transformation(value)<tab><tab><tab>p_row.cells.append(value)",0,if transformation :,if transformation is not None :,0.090364769,1.00E-10,0.4
"def apply(self, db, family):<tab>if self.rtype:<tab><tab><IF-STMT><tab><tab><tab>if self.regex[0].search(str(family.get_relationship())) is None:<tab><tab><tab><tab>return False<tab><tab>elif self.rtype != family.get_relationship():<tab><tab><tab>return False<tab>return True",0,if self . rtype . is_custom ( ) and self . use_regex :,if self . regex :,0.037395501,4.535897664,0.425925926
"def get_somatic_variantcallers(items):<tab>""""""Retrieve all variant callers for somatic calling, handling somatic/germline.""""""<tab>out = []<tab>for data in items:<tab><tab>vcs = dd.get_variantcaller(data)<tab><tab><IF-STMT><tab><tab><tab>vcs = vcs[""somatic""]<tab><tab>if not isinstance(vcs, (list, tuple)):<tab><tab><tab>vcs = [vcs]<tab><tab>out += vcs<tab>return set(vcs)",0,"if isinstance ( vcs , dict ) and ""somatic"" in vcs :","if vcs [ ""somatic"" ] :",0.011974477,11.54754413,0.238095238
"def balancer_list_members(self, balancer):<tab>lb = self._get_balancer_model(balancer.id)<tab>members = []<tab>vs = self._locate_service_group(lb, balancer.port)<tab>if vs:<tab><tab><IF-STMT><tab><tab><tab>srvgrp = vs[""serviceGroups""][0]<tab><tab><tab>members = [self._to_member(srv, balancer) for srv in srvgrp[""services""]]<tab>return members",1,"if vs [ ""serviceGroups"" ] :","if vs [ ""serviceGroups"" ] :",0.75,100,1
"def https_open(self, req):<tab>try:<tab><tab>return self.do_open(do_connection, req)<tab>except Exception as err_msg:<tab><tab>try:<tab><tab><tab>error_msg = str(err_msg.args[0]).split(""] "")[1] + "".""<tab><tab>except IndexError:<tab><tab><tab>error_msg = str(err_msg.args[0]) + "".""<tab><tab><IF-STMT><tab><tab><tab>if settings.VERBOSITY_LEVEL < 2:<tab><tab><tab><tab>print(settings.FAIL_STATUS)<tab><tab>else:<tab><tab><tab>if settings.VERBOSITY_LEVEL < 1:<tab><tab><tab><tab>print("""")<tab><tab>print(settings.print_critical_msg(error_msg))<tab><tab>raise SystemExit()",0,if settings . INIT_TEST == True :,if settings . VERBOSITY_LEVEL >= 1 :,0.153065314,18.575058,0.6
"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab>if not dir:<tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab>if os.path.isdir(dir):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab>elif fatal:<tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",0,if not dir in self . library_dirs :,if os . path . isfile ( dir ) :,0.018014535,5.93420261,0.222222222
"def check_placement_group_index(placement_group: PlacementGroup, bundle_index: int):<tab>assert placement_group is not None<tab>if placement_group.id.is_nil():<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""If placement group is not set, ""<tab><tab><tab><tab>""the value of bundle index must be -1.""<tab><tab><tab>)<tab>elif bundle_index >= placement_group.bundle_count or bundle_index < -1:<tab><tab>raise ValueError(<tab><tab><tab>f""placement group bundle index {bundle_index} ""<tab><tab><tab>f""is invalid. Valid placement group indexes: ""<tab><tab><tab>f""0-{placement_group.bundle_count}""<tab><tab>)",0,if bundle_index != - 1 :,if placement_group . bundle_count is None :,0.023878899,8.913765521,0.377777778
"def incoming():<tab>while True:<tab><tab>m = ws.receive()<tab><tab>if m is not None:<tab><tab><tab>m = str(m)<tab><tab><tab>print((m, len(m)))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ws.close()<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>break<tab>print((""Connection closed!"",))",0,if len ( m ) == 35 :,"if m == """" :",0.020977837,12.4112649,0.36
"def walk_tree(<tab>root: Element,<tab>processor: Callable[[Element], Optional[_T]],<tab>stop_after_first: bool = False,) -> List[_T]:<tab>results = []<tab>queue = deque([root])<tab>while queue:<tab><tab>currElement = queue.popleft()<tab><tab>for child in currElement:<tab><tab><tab>if child:<tab><tab><tab><tab>queue.append(child)<tab><tab><tab>result = processor(child)<tab><tab><tab>if result is not None:<tab><tab><tab><tab>results.append(result)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return results<tab>return results",1,if stop_after_first :,if stop_after_first :,0.531170663,1.00E-10,1
"def _find_node_with_predicate(self, node, predicate):<tab>if node != self._tree._root and predicate(node):<tab><tab>return node<tab>item, cookie = self._tree.GetFirstChild(node)<tab>while item:<tab><tab><IF-STMT><tab><tab><tab>return item<tab><tab>if self._tree.ItemHasChildren(item):<tab><tab><tab>result = self._find_node_with_predicate(item, predicate)<tab><tab><tab>if result:<tab><tab><tab><tab>return result<tab><tab>item, cookie = self._tree.GetNextChild(node, cookie)<tab>return None",1,if predicate ( item ) :,if predicate ( item ) :,0.75,100,1
"def traverse_coords(coords, dst_coords):<tab>for p in coords:<tab><tab><IF-STMT><tab><tab><tab>lst = []<tab><tab><tab>traverse_coords(p, lst)<tab><tab><tab>dst_coords.append(lst)<tab><tab>else:<tab><tab><tab>x, y = p[0], p[1]<tab><tab><tab>d = (x + (y - b) * m) / (1 + m * m)<tab><tab><tab>x2 = 2 * d - x<tab><tab><tab>y2 = 2 * d * m - y + 2 * b<tab><tab><tab>dst_coords.append((x2, y2))<tab>return dst_coords",0,if type ( p [ 0 ] ) is list :,"if isinstance ( p , tuple ) :",0.026123092,9.545138913,0.314814815
"def normalize_replies(self, x):<tab>xs = x.split(""\n"")<tab>xs2 = []<tab>for x in xs:<tab><tab><IF-STMT><tab><tab><tab># Normalize the sentence appearing after 'your persona:'<tab><tab><tab>x = x[len(""your persona: "") :]<tab><tab><tab>x = normalize_reply(x)<tab><tab><tab>x = ""your persona: "" + x<tab><tab>else:<tab><tab><tab>x = normalize_reply(x)<tab><tab>xs2.append(x)<tab>return ""\n"".join(xs2)",0,"if ""your persona:"" in x :","if x . startswith ( ""your persona: "" ) :",0.022568742,35.65506209,0.4
"def run_unittest(*classes):<tab>suite = unittest.TestSuite()<tab>for c in classes:<tab><tab><IF-STMT><tab><tab><tab>c = __import__(c)<tab><tab><tab>for name in dir(c):<tab><tab><tab><tab>obj = getattr(c, name)<tab><tab><tab><tab>if isinstance(obj, type) and issubclass(obj, unittest.TestCase):<tab><tab><tab><tab><tab>suite.addTest(obj)<tab><tab>else:<tab><tab><tab>suite.addTest(c)<tab>runner = unittest.TestRunner()<tab>result = runner.run(suite)",0,"if isinstance ( c , str ) :","if hasattr ( c , ""__module__"" ) :",0.091668085,13.91231164,0.481481481
"def bprop_naive(self, error, permute=False):<tab>for dst in range(self.ofmsize):<tab><tab>rflinks = self.links[dst]<tab><tab>A = error[:, self.ofmlocs[dst]]<tab><tab>B = self.weights<tab><tab><IF-STMT><tab><tab><tab>inds = np.random.permutation(A.shape[1])<tab><tab><tab>np.dot(A[:, inds], B[inds, :], self.bpropbuf)<tab><tab>else:<tab><tab><tab>np.dot(A, B, self.bpropbuf)<tab><tab>self.berror[:, rflinks] += self.bpropbuf",1,if permute :,if permute :,0.531170663,1.00E-10,1
"def rewrite_order_lookup_key(model, lookup_key):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return ""-"" + rewrite_lookup_key(model, lookup_key[1:])<tab><tab>else:<tab><tab><tab>return rewrite_lookup_key(model, lookup_key)<tab>except AttributeError:<tab><tab>return lookup_key",1,"if lookup_key . startswith ( ""-"" ) :","if lookup_key . startswith ( ""-"" ) :",0.75,100,1
"def test_default_configuration(self):<tab>transformations = []<tab>for i in range(2):<tab><tab>transformation, original = self._test_helper(RescalingChoice, dataset=""boston"")<tab><tab># The maximum is around 1.95 for the transformed array...<tab><tab>self.assertAlmostEqual(np.mean(transformation), 0, places=5)<tab><tab>self.assertAlmostEqual(np.std(transformation), 1, places=5)<tab><tab>self.assertFalse((original == transformation).all())<tab><tab>transformations.append(transformation)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue((transformations[-1] == transformations[-2]).all())",1,if len ( transformations ) > 1 :,if len ( transformations ) > 1 :,0.75,100,1
"def test_get_filter_text(self):<tab>with realized(self.b):<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(self.b.get_filter_text(), u"""")<tab><tab><tab>self.assertTrue(isinstance(self.b.get_filter_text(), str))<tab><tab><tab>self.b.filter_text(u""foo"")<tab><tab><tab>self.assertEqual(self.b.get_filter_text(), u""foo"")<tab><tab><tab>self.assertTrue(isinstance(self.b.get_filter_text(), str))",0,if self . b . can_filter_text ( ) :,if self . b . get_filter_text ( ) :,0.549889319,76.11606003,1
"def _namelist(instance):<tab>namelist, namedict, classlist = [], {}, [instance.__class__]<tab>for c in classlist:<tab><tab>for b in c.__bases__:<tab><tab><tab>classlist.append(b)<tab><tab>for name in c.__dict__.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>namelist.append(name)<tab><tab><tab><tab>namedict[name] = 1<tab>return namelist",0,if not namedict . has_key ( name ) :,if name not in namedict :,0.018728518,5.274846356,0.314814815
"def resolve_cloudtrail_payload(self, payload):<tab>sources = self.data.get(""sources"", [])<tab>events = []<tab>for e in self.data.get(""events""):<tab><tab>if not isinstance(e, dict):<tab><tab><tab>events.append(e)<tab><tab><tab>event_info = CloudWatchEvents.get(e)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>event_info = e<tab><tab><tab>events.append(e[""event""])<tab><tab>sources.append(event_info[""source""])<tab>payload[""detail""] = {""eventSource"": list(set(sources)), ""eventName"": events}",1,if event_info is None :,if event_info is None :,0.75,100,1
"def __setitem__(self, aset, c):<tab>if isinstance(aset, tuple):<tab><tab><IF-STMT><tab><tab><tab>row = self.rownames.index(aset[0])<tab><tab>else:<tab><tab><tab>row = aset[0]<tab><tab>if isinstance(aset[1], str):<tab><tab><tab>column = self.colnames.index(aset[1])<tab><tab>else:<tab><tab><tab>column = aset[1]<tab><tab>self.cell_value(row, column, c)<tab>else:<tab><tab>Matrix.__setitem__(self, aset, c)",1,"if isinstance ( aset [ 0 ] , str ) :","if isinstance ( aset [ 0 ] , str ) :",0.75,100,1
"def test_retrieve_robots_token_permission(<tab>username, is_admin, with_permissions, app, client):<tab>with client_with_identity(username, client) as cl:<tab><tab>params = {""orgname"": ""buynlarge"", ""token"": ""true""}<tab><tab><IF-STMT><tab><tab><tab>params[""permissions""] = ""true""<tab><tab>result = conduct_api_call(cl, OrgRobotList, ""GET"", params, None)<tab><tab>assert result.json[""robots""]<tab><tab>for robot in result.json[""robots""]:<tab><tab><tab>assert (robot.get(""token"") is not None) == is_admin<tab><tab><tab>assert (robot.get(""repositories"") is not None) == (<tab><tab><tab><tab>is_admin and with_permissions<tab><tab><tab>)",1,if with_permissions :,if with_permissions :,0.531170663,1.00E-10,1
"def _analyze_ast(contents):<tab>try:<tab><tab>return ast.literal_eval(contents)<tab>except SyntaxError:<tab><tab>pass<tab>try:<tab><tab># remove all comments<tab><tab>contents = re.sub(re.compile(r""/\*.*?\*/"", re.DOTALL), """", contents)<tab><tab>contents = re.sub(re.compile(r""#.*?\n""), """", contents)<tab><tab># remove anything before dict declaration like: ""caps = { ...""<tab><tab>match = re.match(r""^([^{]+)"", contents)<tab><tab><IF-STMT><tab><tab><tab>contents = contents.replace(match.group(1), """")<tab><tab># and try again<tab><tab>return ast.literal_eval(contents)<tab>except SyntaxError:<tab><tab>pass<tab>return False",1,if match :,if match :,0.531170663,1.00E-10,1
"def bulk_disable_accounts(account_names):<tab>""""""Bulk disable accounts""""""<tab>for account_name in account_names:<tab><tab>account = Account.query.filter(Account.name == account_name).first()<tab><tab><IF-STMT><tab><tab><tab>app.logger.debug(""Disabling account %s"", account.name)<tab><tab><tab>account.active = False<tab><tab><tab>db.session.add(account)<tab>db.session.commit()<tab>db.session.close()",1,if account :,if account :,0.531170663,1.00E-10,1
"def _add_agent_rewards(self, reward_dict: Dict[AgentID, float]) -> None:<tab>for agent_id, reward in reward_dict.items():<tab><tab><IF-STMT><tab><tab><tab>self.agent_rewards[agent_id, self.policy_for(agent_id)] += reward<tab><tab><tab>self.total_reward += reward<tab><tab><tab>self._agent_reward_history[agent_id].append(reward)",0,if reward is not None :,if self . _agent_reward [ agent_id ] is None :,0.040133529,6.608973813,0.415584416
"def wrapper(strategy, backend, pipeline_index, *args, **kwargs):<tab>current_partial = partial_prepare(<tab><tab>strategy, backend, pipeline_index, *args, **kwargs<tab>)<tab>out = (<tab><tab>func(<tab><tab><tab>strategy=strategy,<tab><tab><tab>backend=backend,<tab><tab><tab>pipeline_index=pipeline_index,<tab><tab><tab>current_partial=current_partial,<tab><tab><tab>*args,<tab><tab><tab>**kwargs<tab><tab>)<tab><tab>or {}<tab>)<tab>if not isinstance(out, dict):<tab><tab>strategy.storage.partial.store(current_partial)<tab><tab><IF-STMT><tab><tab><tab>strategy.session_set(PARTIAL_TOKEN_SESSION_NAME, current_partial.token)<tab>return out",0,if save_to_session :,if current_partial . token is not None :,0.044228356,1.00E-10,0.266666667
def restore_text(self):<tab>if self.source_is_console():<tab><tab>cb = self._last_console_cb<tab>else:<tab><tab>cb = self._last_editor_cb<tab>if cb is None:<tab><tab><IF-STMT><tab><tab><tab>self.plain_text.clear()<tab><tab>else:<tab><tab><tab>self.rich_text.clear()<tab>else:<tab><tab>func = cb[0]<tab><tab>args = cb[1:]<tab><tab>func(*args)<tab><tab>if get_meth_class_inst(func) is self.rich_text:<tab><tab><tab>self.switch_to_rich_text()<tab><tab>else:<tab><tab><tab>self.switch_to_plain_text(),0,if self . is_plain_text_mode ( ) :,if get_meth_class_inst ( self . plain_text ) is self . plain_text :,0.035175161,10.06263531,0.638888889
"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab>if not word:<tab><tab><tab>continue<tab><tab>if word not in ignored and len(word) >= 2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>group += 1<tab><tab><tab>elif group > 1:<tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",0,if previous == word :,if previous is None :,0.064978772,19.35769349,0.444444444
"def pendingcalls_thread(self, context):<tab>try:<tab><tab>self.pendingcalls_submit(context.l, context.n)<tab>finally:<tab><tab>with context.lock:<tab><tab><tab>context.nFinished += 1<tab><tab><tab>nFinished = context.nFinished<tab><tab><tab>if False and support.verbose:<tab><tab><tab><tab>print(""finished threads: "", nFinished)<tab><tab><IF-STMT><tab><tab><tab>context.event.set()",0,if nFinished == context . nThreads :,if not context . event . is_set ( ) :,0.035327427,8.054496385,0.428571429
"def __getattr__(self, item: str) -> Any:<tab>if hasattr(MissingPandasLikeRolling, item):<tab><tab>property_or_func = getattr(MissingPandasLikeRolling, item)<tab><tab><IF-STMT><tab><tab><tab>return property_or_func.fget(self)  # type: ignore<tab><tab>else:<tab><tab><tab>return partial(property_or_func, self)<tab>raise AttributeError(item)",1,"if isinstance ( property_or_func , property ) :","if isinstance ( property_or_func , property ) :",0.75,100,1
"def _csv(self, match=None, dump=None):<tab>if dump is None:<tab><tab>dump = self._dump(match)<tab>for record in dump:<tab><tab>row = []<tab><tab>for field in record:<tab><tab><tab>if isinstance(field, int):<tab><tab><tab><tab>row.append(""%i"" % field)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>row.append("""")<tab><tab><tab>else:<tab><tab><tab><tab>row.append(""'%s'"" % field)<tab><tab>yield "","".join(row)",0,elif field is None :,"elif isinstance ( field , list ) :",0.15181655,7.267884212,0.285714286
"def get_default_dict(section_definition):<tab>section_key = section_definition.get(""key"")<tab>if section_key == ""global"":<tab><tab>section_key += ""_""<tab>if ""cluster"" == section_key:<tab><tab>section_key += (<tab><tab><tab>""_sit""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""_hit""<tab><tab>)<tab>default_dict = DefaultDict[section_key].value<tab>return default_dict",0,"if section_definition . get ( ""cluster_model"" ) == ClusterModel . SIT . name","if section_definition . get ( ""_sit"" )",0.231996446,35.2506571,0.473684211
"def scan_resource_conf(self, conf):<tab>subscription = re.compile(r""\/|\/subscriptions\/[\w\d-]+$|\[subscription\(\).id\]"")<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if any(<tab><tab><tab><tab>re.match(subscription, scope)<tab><tab><tab><tab>for scope in conf[""properties""][""assignableScopes""]<tab><tab><tab>):<tab><tab><tab><tab>if ""permissions"" in conf[""properties""]:<tab><tab><tab><tab><tab>if conf[""properties""][""permissions""]:<tab><tab><tab><tab><tab><tab>for permission in conf[""properties""][""permissions""]:<tab><tab><tab><tab><tab><tab><tab>if ""actions"" in permission and ""*"" in permission[""actions""]:<tab><tab><tab><tab><tab><tab><tab><tab>return CheckResult.FAILED<tab>return CheckResult.PASSED",1,"if ""assignableScopes"" in conf [ ""properties"" ] :","if ""assignableScopes"" in conf [ ""properties"" ] :",0.75,100,1
"def hard_update(self, cache, size_change, pins_gates):<tab>""""""replace verts, rads and vel (in NumPy)""""""<tab>verts, rads, vel, react = cache<tab>if len(verts) == self.v_len:<tab><tab>if pins_gates[0] and pins_gates[1]:<tab><tab><tab>unpinned = self.params[""unpinned""]<tab><tab><tab>self.verts[unpinned] = verts[unpinned]<tab><tab>else:<tab><tab><tab>self.verts = verts<tab><tab>self.vel = vel<tab><tab><IF-STMT><tab><tab><tab>self.rads = rads",0,if not size_change :,if size_change :,0.096488528,1.00E-10,0.6
"def run(self):<tab>if self.check():<tab><tab>path = ""/../../../../../../../../../../../..{}"".format(self.filename)<tab><tab>response = self.http_request(method=""GET"", path=path)<tab><tab>if response is None:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>print_success(""Success! File: %s"" % self.filename)<tab><tab><tab>print_info(response.text)<tab><tab>else:<tab><tab><tab>print_error(""Exploit failed"")<tab>else:<tab><tab>print_error(""Device seems to be not vulnerable"")",0,if response . status_code == 200 and response . text :,if response . status_code == 200 :,0.326350387,60.57025367,0.572649573
"def write_text(self, text):<tab>""""""Writes re-indented text into the buffer.""""""<tab>should_indent = False<tab>rows = []<tab>for row in text.split(""\n""):<tab><tab>if should_indent:<tab><tab><tab>row = ""<tab>{}"".format(row)<tab><tab>if ""\b"" in row:<tab><tab><tab>row = row.replace(""\b"", """", 1)<tab><tab><tab>should_indent = True<tab><tab><IF-STMT><tab><tab><tab>should_indent = False<tab><tab>rows.append(row)<tab>self.write(""{}\n"".format(""\n"".join(rows)))",0,elif not len ( row . strip ( ) ) :,"elif ""\n"" in row :",0.042776515,4.995138898,0.265306122
"def default_logger():<tab>""""""A logger used to output seed information to nosetests logs.""""""<tab>logger = logging.getLogger(__name__)<tab># getLogger() lookups will return the same logger, but only add the handler once.<tab>if not len(logger.handlers):<tab><tab>handler = logging.StreamHandler(sys.stderr)<tab><tab>handler.setFormatter(logging.Formatter(""[%(levelname)s] %(message)s""))<tab><tab>logger.addHandler(handler)<tab><tab><IF-STMT><tab><tab><tab>logger.setLevel(logging.INFO)<tab>return logger",0,if logger . getEffectiveLevel ( ) == logging . NOTSET :,"if hasattr ( logger , ""setLevel"" ) :",0.014690094,5.137253268,0.265306122
"def while1_test(a, b, c):<tab>while 1:<tab><tab>if a != 2:<tab><tab><tab>if b:<tab><tab><tab><tab>a = 3<tab><tab><tab><tab>b = 0<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c = 0<tab><tab><tab>else:<tab><tab><tab><tab>a += b + c<tab><tab><tab><tab>break<tab>return a, b, c",1,elif c :,elif c :,0.514316131,1.00E-10,1
"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab>if not line or line.startswith(""#"") or ""."" not in line:<tab><tab><tab><tab>continue<tab><tab><tab>if "" # "" in line:<tab><tab><tab><tab>reason = line.split("" # "")[1].split()[0].lower()<tab><tab><tab><tab><IF-STMT>  # too many false positives<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>retval[line.split("" # "")[0]] = (__info__, __reference__)<tab>return retval",0,"if reason == ""scanning"" :","if reason in ( ""unavailable"" , ""unavailable"" ) :",0.047573492,7.768562846,0.730769231
"def create_order(order, shopify_settings, old_order_sync=False, company=None):<tab>so = create_sales_order(order, shopify_settings, company)<tab>if so:<tab><tab><IF-STMT><tab><tab><tab>create_sales_invoice(<tab><tab><tab><tab>order, shopify_settings, so, old_order_sync=old_order_sync<tab><tab><tab>)<tab><tab>if order.get(""fulfillments"") and not old_order_sync:<tab><tab><tab>create_delivery_note(order, shopify_settings, so)",0,"if order . get ( ""financial_status"" ) == ""paid"" :","if order . get ( ""invoice"" ) and not old_order_sync :",0.305359821,33.5070408,0.642857143
"def __getitem__(self, key):<tab>if isinstance(key, numbers.Number):<tab><tab>l = len(self)<tab><tab>if key >= l:<tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><IF-STMT><tab><tab><tab>if key < -l:<tab><tab><tab><tab>raise IndexError(""Index %s out of range (%s elements)"" % (key, l))<tab><tab><tab>key += l<tab><tab>return self(key + 1)<tab>elif isinstance(key, slice):<tab><tab>raise ValueError(<tab><tab><tab>self.impl.__class__.__name__ + "" object does not support slicing""<tab><tab>)<tab>else:<tab><tab>return self(key)",0,if key < 0 :,elif key < 0 :,0.311522644,66.8740305,0.6
"def load_checks(path=None, subpkg=""""):<tab>""""""Dynamically import all check modules for the side effect of registering checks.""""""<tab>if path is None:<tab><tab>path = os.path.dirname(__file__)<tab>modules = []<tab>for name in os.listdir(path):<tab><tab>if os.path.isdir(os.path.join(path, name)):<tab><tab><tab>modules = modules + load_checks(<tab><tab><tab><tab>os.path.join(path, name), subpkg + ""."" + name<tab><tab><tab>)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>modules.append(import_module(__package__ + subpkg + ""."" + name[:-3]))<tab>return modules",0,"if name . endswith ( "".py"" ) and name not in LOADER_EXCLUDES :","if name . endswith ( "".py"" ) :",0.304671969,48.40667966,0.488095238
"def _remove_temporary_files(self, temporary_files):<tab>""""""Internal function for cleaning temporary files""""""<tab>for file_object in temporary_files:<tab><tab>file_name = file_object.name<tab><tab>file_object.close()<tab><tab>if os.path.exists(file_name):<tab><tab><tab>os.remove(file_name)<tab><tab>arff_file_name = file_name + "".arff""<tab><tab><IF-STMT><tab><tab><tab>os.remove(arff_file_name)",1,if os . path . exists ( arff_file_name ) :,if os . path . exists ( arff_file_name ) :,0.75,100,1
"def search_rotate(array, val):<tab>low, high = 0, len(array) - 1<tab>while low <= high:<tab><tab>mid = (low + high) // 2<tab><tab>if val == array[mid]:<tab><tab><tab>return mid<tab><tab>if array[low] <= array[mid]:<tab><tab><tab>if array[low] <= val <= array[mid]:<tab><tab><tab><tab>high = mid - 1<tab><tab><tab>else:<tab><tab><tab><tab>low = mid + 1<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>low = mid + 1<tab><tab><tab>else:<tab><tab><tab><tab>high = mid - 1<tab>return -1",0,if array [ mid ] <= val <= array [ high ] :,if array [ mid ] <= val <= array [ mid + 1 ] :,0.741975645,71.72835948,0.658263305
"def match_file(self, file, tff_format):<tab>match = tff_format.search(file.filename.replace(""\\"", ""/""))<tab>if match:<tab><tab>result = {}<tab><tab>for name, value in match.groupdict().items():<tab><tab><tab>value = value.strip()<tab><tab><tab>if name in self.numeric_tags:<tab><tab><tab><tab>value = value.lstrip(""0"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.replace(""_"", "" "")<tab><tab><tab>result[name] = value<tab><tab>return result<tab>else:<tab><tab>return {}",0,if self . ui . replace_underscores . isChecked ( ) :,"elif name . endswith ( ""_tags"" ) :",0.02296966,7.858254246,0.116666667
"def exclude_pkgs(self, pkgs):<tab># :api<tab>name = ""excludepkgs""<tab>if pkgs is not None and pkgs != []:<tab><tab><IF-STMT><tab><tab><tab>self._set_value(name, pkgs, dnf.conf.PRIO_COMMANDLINE)<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>_(""Unknown configuration option: %s = %s""), ucd(name), ucd(pkgs)<tab><tab><tab>)",0,if self . _has_option ( name ) :,if dnf . conf . PRIO_COMMANDLINE in pkgs :,0.018096169,5.30015669,0.225
"def button_press_cb(self, tdw, event):<tab>if self.zone in (_EditZone.CREATE_AXIS, _EditZone.DELETE_AXIS):<tab><tab>button = event.button<tab><tab><IF-STMT><tab><tab><tab>self._click_info = (button, self.zone)<tab><tab><tab>return False<tab>return super(SymmetryEditMode, self).button_press_cb(tdw, event)",0,if button == 1 and event . type == Gdk . EventType . BUTTON_PRESS :,if button is not None :,0.069895013,2.058073185,0.235294118
"def declare_var(<tab>self,<tab>type_name: Union[str, Tuple[str, str]],<tab>*,<tab>var_name: str = """",<tab>var_name_prefix: str = ""v"",<tab>shared: bool = False,) -> str:<tab>if shared:<tab><tab><IF-STMT><tab><tab><tab>var_name = var_name_prefix<tab><tab>if var_name not in self.shared_vars:<tab><tab><tab>self.declarations.append((var_name, type_name))<tab><tab><tab>self.shared_vars.add(var_name)<tab>else:<tab><tab>if not var_name:<tab><tab><tab>var_name = self.get_var_name(var_name_prefix)<tab><tab>self.declarations.append((var_name, type_name))<tab>return var_name",1,if not var_name :,if not var_name :,0.75,100,1
"def get_module_map(module, module_path):<tab>""""""Map true modules to exported name""""""<tab>if not module_is_public(module):<tab><tab>return {}<tab>m = {}<tab>for symbol_name in dir(module):<tab><tab>if symbol_name.startswith(""_""):<tab><tab><tab>continue<tab><tab>symbol = getattr(module, symbol_name)<tab><tab>symbol_path = ""%s.%s"" % (module_path, symbol_name)<tab><tab>m[symbol] = symbol_path<tab><tab><IF-STMT><tab><tab><tab>m.update(get_module_map(symbol, symbol_path))<tab>return m",0,if inspect . ismodule ( symbol ) :,"if isinstance ( symbol , types . ModuleType ) :",0.041059843,13.13454947,0.238636364
"def build_properties(self):<tab>self.properties = set()<tab>if self.module.partial_scan == True:<tab><tab># For partial scans, only check the most common properties values<tab><tab>for prop in self.COMMON_PROPERTIES:<tab><tab><tab>self.properties.add(chr(prop))<tab>else:<tab><tab>for pb in range(0, 9):<tab><tab><tab>for lp in range(0, 5):<tab><tab><tab><tab>for lc in range(0, 5):<tab><tab><tab><tab><tab>prop = self.build_property(pb, lp, lc)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.properties.add(chr(prop))",1,if prop is not None :,if prop is not None :,0.75,100,1
"def getFileIdFromAlternateLink(altLink):<tab>loc = altLink.find(""/d/"")<tab><IF-STMT><tab><tab>fileId = altLink[loc + 3 :]<tab><tab>loc = fileId.find(""/"")<tab><tab>if loc != -1:<tab><tab><tab>return fileId[:loc]<tab>else:<tab><tab>loc = altLink.find(""/folderview?id="")<tab><tab>if loc > 0:<tab><tab><tab>fileId = altLink[loc + 15 :]<tab><tab><tab>loc = fileId.find(""&"")<tab><tab><tab>if loc != -1:<tab><tab><tab><tab>return fileId[:loc]<tab>controlflow.system_error_exit(<tab><tab>2, f""{altLink} is not a valid Drive File alternateLink""<tab>)",1,if loc > 0 :,if loc > 0 :,0.75,100,1
"def _coerce_trials_data(data, path):<tab>if not isinstance(data, list):<tab><tab>if not isinstance(data, dict):<tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path,<tab><tab><tab><tab>""invalid data type for trials: expected list or dict""<tab><tab><tab><tab>"", got %s"" % type(data).__name__,<tab><tab><tab>)<tab><tab>data = [data]<tab>for item in data:<tab><tab><IF-STMT><tab><tab><tab>raise BatchFileError(<tab><tab><tab><tab>path, ""invalid data type for trial %r: expected dict"" % item<tab><tab><tab>)<tab>return data",1,"if not isinstance ( item , dict ) :","if not isinstance ( item , dict ) :",0.75,100,1
"def remove(self, *objs):<tab>val = getattr(self.instance, attname)<tab>for obj in objs:<tab><tab># Is obj actually part of this descriptor set?<tab><tab><IF-STMT><tab><tab><tab>setattr(obj, rel_field.name, None)<tab><tab><tab>obj.save()<tab><tab>else:<tab><tab><tab>raise rel_field.rel.to.DoesNotExist(<tab><tab><tab><tab>""%r is not related to %r."" % (obj, self.instance)<tab><tab><tab>)",0,"if getattr ( obj , rel_field . attname ) == val :",if val == obj :,0.011816831,4.767030908,0.479166667
"def run(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.shell = os.name == ""nt""<tab><tab>if self.working_dir != """":<tab><tab><tab>os.chdir(self.working_dir)<tab><tab>proc = subprocess.Popen(<tab><tab><tab>self.command,<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab>shell=self.shell,<tab><tab><tab>env=self.env,<tab><tab>)<tab><tab>output = codecs.decode(proc.communicate()[0])<tab><tab>self.on_done(output)<tab>except subprocess.CalledProcessError as e:<tab><tab>self.on_done(e.returncode, error=True)<tab>except OSError as e:<tab><tab>self.on_done(e.message, error=True)",0,if not self . shell :,if self . shell is None :,0.104946328,27.77619034,0.257142857
"def filter_testsuite(suite, matcher, level=None):<tab>""""""Returns a flattened list of test cases that match the given matcher.""""""<tab>if not isinstance(suite, unittest.TestSuite):<tab><tab>raise TypeError(""not a TestSuite"", suite)<tab>results = []<tab>for test in suite._tests:<tab><tab>if level is not None and getattr(test, ""level"", 0) > level:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>testname = test.id()  # package.module.class.method<tab><tab><tab>if matcher(testname):<tab><tab><tab><tab>results.append(test)<tab><tab>else:<tab><tab><tab>filtered = filter_testsuite(test, matcher, level)<tab><tab><tab>results.extend(filtered)<tab>return results",0,"if isinstance ( test , unittest . TestCase ) :","if isinstance ( test , unittest . TestSuite ) :",0.604939981,70.71067812,0.714285714
"def propagate_touch_to_touchable_widgets(self, touch, touch_event, *args):<tab>triggered = False<tab>for i in self._touchable_widgets:<tab><tab>if i.collide_point(touch.x, touch.y):<tab><tab><tab>triggered = True<tab><tab><tab>if touch_event == ""down"":<tab><tab><tab><tab>i.on_touch_down(touch)<tab><tab><tab>elif touch_event == ""move"":<tab><tab><tab><tab>i.on_touch_move(touch, *args)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i.on_touch_up(touch)<tab>return triggered",1,"elif touch_event == ""up"" :","elif touch_event == ""up"" :",1,100,1
"def add_attributes(attributes, all_base64):<tab>lines = []<tab>oc_attr = None<tab># objectclass first, even if this is not specified in the RFC<tab>for attr in attributes:<tab><tab>if attr.lower() == ""objectclass"":<tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab><tab><tab>oc_attr = attr<tab><tab><tab>break<tab># remaining attributes<tab>for attr in attributes:<tab><tab><IF-STMT><tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab>return lines",0,if attr != oc_attr and attr in attributes :,"if attr . lower ( ) == ""oc_attr"" :",0.029848275,14.45892467,0.333333333
"def split_quality(quality):<tab>anyQualities = []<tab>bestQualities = []<tab>for curQual in Quality.qualityStrings.keys():<tab><tab><IF-STMT><tab><tab><tab>anyQualities.append(curQual)<tab><tab>if curQual << 16 & quality:<tab><tab><tab>bestQualities.append(curQual)<tab>return sorted(anyQualities), sorted(bestQualities)",0,if curQual & quality :,if curQual << 24 & quality :,0.13498424,25.8486577,0.571428571
"def check(dbdef):<tab>""database version must include required keys""<tab>for vnum, vdef in dbdef.items():<tab><tab>missing = set(required) - set(vdef)<tab><tab>if vnum == min(dbdef):<tab><tab><tab>missing -= set(initially_ok)<tab><tab><IF-STMT><tab><tab><tab>yield vnum, missing",1,if missing :,if missing :,0.531170663,1.00E-10,1
"def teardown_func():<tab>try:<tab><tab>yield<tab>finally:<tab><tab>""tear down test fixtures""<tab><tab>cache = os.path.join(here, ""data"", ""cache.db"")<tab><tab><IF-STMT><tab><tab><tab>os.remove(cache)",1,if os . path . exists ( cache ) :,if os . path . exists ( cache ) :,0.75,100,1
"def getCachedArt(albumid):<tab>from headphones import cache<tab>c = cache.Cache()<tab>artwork_path = c.get_artwork_from_cache(AlbumID=albumid)<tab>if not artwork_path:<tab><tab>return<tab>if artwork_path.startswith(""http://""):<tab><tab>artwork = request.request_content(artwork_path, timeout=20)<tab><tab><IF-STMT><tab><tab><tab>logger.warn(""Unable to open url: %s"", artwork_path)<tab><tab><tab>return<tab>else:<tab><tab>with open(artwork_path, ""r"") as fp:<tab><tab><tab>return fp.read()",0,if not artwork :,if artwork is None :,0.045150551,14.05853313,0.277777778
"def delete_volume(self, name, reraise=False):<tab>try:<tab><tab>self.k8s_api.delete_persistent_volume(<tab><tab><tab>name=name,<tab><tab><tab>body=client.V1DeleteOptions(api_version=constants.K8S_API_VERSION_V1),<tab><tab>)<tab><tab>logger.debug(""Volume `{}` Deleted"".format(name))<tab>except ApiException as e:<tab><tab><IF-STMT><tab><tab><tab>raise PolyaxonK8SError(""Connection error: %s"" % e) from e<tab><tab>else:<tab><tab><tab>logger.debug(""Volume `{}` was not found"".format(name))",1,if reraise :,if reraise :,0.531170663,1.00E-10,1
"def _hashable(self):<tab>hashes = [self.graph.md5()]<tab>for g in self.geometry.values():<tab><tab><IF-STMT><tab><tab><tab>hashes.append(g.md5())<tab><tab>elif hasattr(g, ""tostring""):<tab><tab><tab>hashes.append(str(hash(g.tostring())))<tab><tab>else:<tab><tab><tab># try to just straight up hash<tab><tab><tab># this may raise errors<tab><tab><tab>hashes.append(str(hash(g)))<tab>hashable = """".join(sorted(hashes)).encode(""utf-8"")<tab>return hashable",1,"if hasattr ( g , ""md5"" ) :","if hasattr ( g , ""md5"" ) :",0.75,100,1
"def get_history_data(self, guid, count=1):<tab>history = {}<tab>if count < 1:<tab><tab>return history<tab>key = self._make_key(guid)<tab>for i in range(0, self.db.llen(key)):<tab><tab>r = self.db.lindex(key, i)<tab><tab>c = msgpack.unpackb(r)<tab><tab><IF-STMT><tab><tab><tab>if c[""data""] not in history:<tab><tab><tab><tab>history[c[""data""]] = c[""timestamp""]<tab><tab><tab><tab>if len(history) >= count:<tab><tab><tab><tab><tab>break<tab>return history",0,"if c [ ""tries"" ] == 0 or c [ ""tries"" ] is None :","if c [ ""guid"" ] == guid :",0.066907392,21.32346573,0.308333333
"def renderable_events(self, date, hour):<tab>""Returns the number of renderable events""<tab>renderable_events = []<tab>for event in self.events:<tab><tab><IF-STMT><tab><tab><tab>renderable_events.append(event)<tab>if hour:<tab><tab>for current in renderable_events:<tab><tab><tab>for event in self.events:<tab><tab><tab><tab>if event not in renderable_events:<tab><tab><tab><tab><tab>for hour in range(self.start_hour, self.end_hour):<tab><tab><tab><tab><tab><tab>if current.covers(date, hour) and event.covers(date, hour):<tab><tab><tab><tab><tab><tab><tab>renderable_events.append(event)<tab><tab><tab><tab><tab><tab><tab>break<tab>return renderable_events",0,"if event . covers ( date , hour ) :",if event not in renderable_events :,0.026294073,9.519340818,0.363636364
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def _parseConfigFile(self, iniPath, createConfig=True):<tab>parser = SafeConfigParserUnicode(strict=False)<tab>if not os.path.isfile(iniPath):<tab><tab>if createConfig:<tab><tab><tab>open(iniPath, ""w"").close()<tab><tab>else:<tab><tab><tab>return<tab>parser.readfp(codecs.open(iniPath, ""r"", ""utf_8_sig""))<tab>for section, options in list(self._iniStructure.items()):<tab><tab><IF-STMT><tab><tab><tab>for option in options:<tab><tab><tab><tab>if parser.has_option(section, option):<tab><tab><tab><tab><tab>self._config[option] = parser.get(section, option)",1,if parser . has_section ( section ) :,if parser . has_section ( section ) :,0.75,100,1
"def get_block_id_at_height(store, height, descendant_id):<tab>if height is None:<tab><tab>return None<tab>while True:<tab><tab>block = store._load_block(descendant_id)<tab><tab><IF-STMT><tab><tab><tab>return descendant_id<tab><tab>descendant_id = block[<tab><tab><tab>""search_id""<tab><tab><tab>if util.get_search_height(block[""height""]) >= height<tab><tab><tab>else ""prev_id""<tab><tab>]",0,"if block [ ""height"" ] == height :",if block is None :,0.035401841,7.121297465,0.481481481
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None):<tab>readies = [0] * len(selectors)<tab>start_time = time.time()<tab>while True:<tab><tab>all_satisfy = True<tab><tab>for idx, selector in enumerate(selectors):<tab><tab><tab>if readies[idx] < min_counts[idx]:<tab><tab><tab><tab>all_satisfy = False<tab><tab><tab><tab>readies[idx] = count_fun(selector)<tab><tab><tab><tab>break<tab><tab>if all_satisfy:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise TimeoutError(""Wait cluster start timeout"")<tab><tab>time.sleep(1)",0,if timeout and timeout + start_time < time . time ( ) :,if timeout and time . time ( ) - start_time > timeout :,0.599402046,42.21068126,0.8
"def waitForNodes(self, expected, comparison=None, tag_filters={}):<tab>MAX_ITER = 50<tab>for i in range(MAX_ITER):<tab><tab>n = len(self.provider.non_terminated_nodes(tag_filters))<tab><tab>if comparison is None:<tab><tab><tab>comparison = self.assertEqual<tab><tab>try:<tab><tab><tab>comparison(n, expected)<tab><tab><tab>return<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>time.sleep(0.1)",1,if i == MAX_ITER - 1 :,if i == MAX_ITER - 1 :,0.75,100,1
"def _api_snapshot_delete(self, drbd_rsc_name, snap_name):<tab>with lin_drv(self.default_uri) as lin:<tab><tab><IF-STMT><tab><tab><tab>lin.connect()<tab><tab>snap_reply = lin.snapshot_delete(<tab><tab><tab>rsc_name=drbd_rsc_name, snapshot_name=snap_name<tab><tab>)<tab><tab>return snap_reply",1,if not lin . connected :,if not lin . connected :,0.75,100,1
"def response(resp):<tab>results = []<tab>search_results = loads(resp.text)<tab># return empty array if there are no results<tab>if not search_results.get(""query"", {}).get(""search""):<tab><tab>return []<tab># parse results<tab>for result in search_results[""query""][""search""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>url = (<tab><tab><tab>base_url.format(language=resp.search_params[""language""])<tab><tab><tab>+ ""wiki/""<tab><tab><tab>+ quote(result[""title""].replace("" "", ""_"").encode(""utf-8""))<tab><tab>)<tab><tab># append result<tab><tab>results.append({""url"": url, ""title"": result[""title""], ""content"": """"})<tab># return results<tab>return results",0,"if result . get ( ""snippet"" , """" ) . startswith ( ""#REDIRECT"" ) :","if ""title"" not in result :",0.008063669,1.626079048,0.285714286
"def getBody(self, path):<tab>if path == """":<tab><tab>return ""This server has "" + str(self.__fileProvider.count()) + "" files.""<tab>else:<tab><tab>downloadCounts = self.__fileProvider.get(path).downloadCount<tab><tab><IF-STMT><tab><tab><tab>return str(downloadCounts[path])<tab><tab>else:<tab><tab><tab>return ""0""",1,if path in downloadCounts :,if path in downloadCounts :,0.75,100,1
"def parse_entrypoints(self, content: str, root=None) -> RootDependency:<tab>if root is None:<tab><tab>root = RootDependency()<tab>entrypoints = []<tab>group = ""console_scripts""<tab>for line in content.split(""\n""):<tab><tab>line = line.strip()<tab><tab>if not line or line[0] in ""#;"":  # ignore comments<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>group = line[1:-1]<tab><tab>else:<tab><tab><tab>entrypoints.append(EntryPoint.parse(text=line, group=group))<tab>root.entrypoints = tuple(entrypoints)<tab>return root",0,"if line [ 0 ] == ""["" and line [ - 1 ] == ""]"" :","if line . startswith ( ""console_scripts"" ) :",0.014390918,3.701296069,0.362318841
"def _validate_callbacks(cls, callbacks):<tab>for callback in callbacks:<tab><tab><IF-STMT><tab><tab><tab>if issubclass(callback, Callback):<tab><tab><tab><tab>raise TypeError(""Make sure to instantiate the callbacks."")<tab><tab><tab>raise TypeError(""Only accepts a `callbacks` instance."")",1,"if not isinstance ( callback , Callback ) :","if not isinstance ( callback , Callback ) :",0.75,100,1
"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>newtext.append(line[markdown.TAB_LENGTH :])<tab><tab>elif not line.strip():<tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",0,"if line . startswith ( "" "" * markdown . TAB_LENGTH ) :",if line . startswith ( markdown .TAB_LENGTH ) :,0.215720036,64.98720967,1
"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab>if self._checking_num > 0:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab># Fail or unknown<tab><tab><tab>if time_now - self.last_check_time < 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>if time_now - self.last_check_time < 10:<tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",0,"if fail or self . network_stat != ""OK"" :",elif fail :,0.011074822,1.00E-10,0.305555556
"def wrapper(*args, **kwargs):<tab>if is_profiling_enabled(section):<tab><tab>global _profile_nesting<tab><tab>profile = get_global_profile()<tab><tab>_profile_nesting += 1<tab><tab><IF-STMT><tab><tab><tab>profile.enable()<tab><tab>result = func(*args, **kwargs)<tab><tab>_profile_nesting -= 1<tab><tab>if _profile_nesting == 0:<tab><tab><tab>profile.disable()<tab><tab>return result<tab>else:<tab><tab>return func(*args, **kwargs)",0,if _profile_nesting == 1 :,if _profile_nesting == 0 :,0.394778655,75.06238538,0.5
"def get_sequence_type_str(x: Sequence[Any]) -> str:<tab>container_type = type(x).__name__<tab>if not x:<tab><tab><IF-STMT><tab><tab><tab>return ""[]""<tab><tab>else:<tab><tab><tab>return container_type + ""([])""<tab>elem_type = get_type_str(x[0])<tab>if container_type == ""list"":<tab><tab>if len(x) == 1:<tab><tab><tab>return ""["" + elem_type + ""]""<tab><tab>else:<tab><tab><tab>return ""["" + elem_type + "", ...]""<tab>else:<tab><tab>if len(x) == 1:<tab><tab><tab>return f""{container_type}([{elem_type}])""<tab><tab>else:<tab><tab><tab>return f""{container_type}([{elem_type}, ...])""",0,"if container_type == ""list"" :",if len ( x ) == 1 :,0.02800146,10.14710401,0.345454545
"def attempts(self):<tab># We can cache as we deal with history server<tab>if not hasattr(self, ""_attempts""):<tab><tab>task_attempts = self.job.api.task_attempts(self.job.id, self.id)[""taskAttempts""]<tab><tab><IF-STMT><tab><tab><tab>self._attempts = [<tab><tab><tab><tab>Attempt(self, attempt) for attempt in task_attempts[""taskAttempt""]<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>self._attempts = []<tab>return self._attempts",1,if task_attempts :,if task_attempts :,0.531170663,1.00E-10,1
"def __call__(self, message, keyname):<tab>if keyname in self.keyring:<tab><tab>key = self.keyring[keyname]<tab><tab>if isinstance(key, Key) and key.algorithm == GSS_TSIG:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>GSSTSigAdapter.parse_tkey_and_step(key, message, keyname)<tab><tab>return key<tab>else:<tab><tab>return None",0,if message :,if message . get ( key . name ) == GSS_TSIG :,0.076444592,1.00E-10,0.470588235
"def location_dec(str):<tab>head = int(str[0])<tab>str = str[1:]<tab>rows = head<tab>cols = int(len(str) / rows) + 1<tab>out = """"<tab>full_row = len(str) % head<tab>for c in range(cols):<tab><tab>for r in range(rows):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if r < full_row:<tab><tab><tab><tab>char = str[r * cols + c]<tab><tab><tab>else:<tab><tab><tab><tab>char = str[cols * full_row + (r - full_row) * (cols - 1) + c]<tab><tab><tab>out += char<tab>return parse.unquote(out).replace(""^"", ""0"")",0,if c == ( cols - 1 ) and r >= full_row :,"if str [ r ] == """" :",0.011365276,5.240300995,0.227941176
"def request(self):<tab>if ""Cookie"" in self._req._headers:<tab><tab>c = self._req._headers[""Cookie""].split(""; "")<tab><tab><IF-STMT><tab><tab><tab>return cookies.cookie({x[0]: x[2] for x in [x.partition(""="") for x in c]})<tab>return cookies.cookie({})",0,if c [ 0 ] :,if len ( c ) == 3 :,0.023749772,6.274655311,0.314814815
"def bulk_enable_accounts(account_names):<tab>""""""Bulk enable accounts""""""<tab>for account_name in account_names:<tab><tab>account = Account.query.filter(Account.name == account_name).first()<tab><tab><IF-STMT><tab><tab><tab>app.logger.debug(""Enabling account %s"", account.name)<tab><tab><tab>account.active = True<tab><tab><tab>db.session.add(account)<tab>db.session.commit()<tab>db.session.close()",1,if account :,if account :,0.531170663,1.00E-10,1
"def acquire(self, blocking=True, timeout=None):<tab>if not blocking and timeout is not None:<tab><tab>raise ValueError(""can't specify timeout for non-blocking acquire"")<tab>rc = False<tab>endtime = None<tab>self._cond.acquire()<tab>while self._value == 0:<tab><tab>if not blocking:<tab><tab><tab>break<tab><tab>if timeout is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>endtime = _time() + timeout<tab><tab><tab>else:<tab><tab><tab><tab>timeout = endtime - _time()<tab><tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab><tab>break<tab><tab>self._cond.wait(timeout)<tab>else:<tab><tab>self._value = self._value - 1<tab><tab>rc = True<tab>self._cond.release()<tab>return rc",1,if endtime is None :,if endtime is None :,0.75,100,1
"def _sorted_layers(self, structure, top_layer_id):<tab>""""""Return the image layers sorted""""""<tab>sorted_layers = []<tab>next_layer = top_layer_id<tab>while next_layer:<tab><tab>sorted_layers.append(next_layer)<tab><tab>if ""json"" not in structure[""repolayers""][next_layer]:  # v2<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>next_layer = structure[""repolayers""][next_layer][""json""][""parent""]<tab><tab>if not next_layer:<tab><tab><tab>break<tab>return sorted_layers",1,"if ""parent"" not in structure [ ""repolayers"" ] [ next_layer ] [ ""json"" ] :","if ""parent"" not in structure [ ""repolayers"" ] [ next_layer ] [ ""json"" ] :",0.75,100,1
"def on_change(self, data):<tab># loop over tp_clipboard views<tab>for window in sublime.windows():<tab><tab>for view in window.views():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>file_name = view.file_name()<tab><tab><tab><tab># ammo<tab><tab><tab><tab>if view.settings().get(""tp_ammo"", False):<tab><tab><tab><tab><tab>self.update(view)<tab><tab><tab><tab>elif file_name and file_name.endswith(<tab><tab><tab><tab><tab>global_settings(""ammo_file_extension"", "".ammo"")<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>self.update(view)",0,"if view . get_status ( ""inactive"" ) and view . settings ( ) . get ( ""tp_append"" , False ) :","if view . settings ( ) . get ( ""tp_clipboard"" , False ) :",0.268662595,44.48724716,0.371428571
"def _maintain_pool(self):<tab>waiting = self._docker_interface.services_waiting_by_constraints()<tab>active = self._docker_interface.nodes_active_by_constraints()<tab>for constraints, needed_dict in self._state.slots_needed(waiting, active).items():<tab><tab>services = needed_dict[""services""]<tab><tab>nodes = needed_dict[""nodes""]<tab><tab>slots_needed = needed_dict[""slots_needed""]<tab><tab>if slots_needed > 0:<tab><tab><tab>self._spawn_nodes(constraints, services, slots_needed)<tab><tab><IF-STMT><tab><tab><tab>self._destroy_nodes(constraints, nodes, slots_needed)",0,elif slots_needed < 0 :,if nodes_needed > 0 :,0.056810968,18.575058,0.5
"def _update_vhosts_addrs_ssl(self, vhosts):<tab>""""""Update a list of raw parsed vhosts to include global address sslishness""""""<tab>addr_to_ssl = self._build_addr_to_ssl()<tab>for vhost in vhosts:<tab><tab>for addr in vhost.addrs:<tab><tab><tab>addr.ssl = addr_to_ssl[addr.normalized_tuple()]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vhost.ssl = True",0,if addr . ssl :,if not vhost . ssl :,0.127622275,32.46679155,0.3
"def gather_files(fileset):<tab>common_type = get_common_filetype(fileset)<tab>files = []<tab>for file in fileset.file:<tab><tab>filename = file.name<tab><tab><IF-STMT><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""is_include_file"": True}<tab><tab>if file.file_type != common_type:<tab><tab><tab>if type(filename) == str:<tab><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""file_type"": file.file_type}<tab><tab>files.append(filename)<tab>return files",0,if file . is_include_file == True :,if type ( filename ) == str :,0.021135836,8.125165711,0.26984127
"def _get_resource_group_name_of_staticsite(client, static_site_name):<tab>static_sites = client.list()<tab>for static_site in static_sites:<tab><tab><IF-STMT><tab><tab><tab>resource_group = _parse_resource_group_from_arm_id(static_site.id)<tab><tab><tab>if resource_group:<tab><tab><tab><tab>return resource_group<tab>raise CLIError(<tab><tab>""Static site was '{}' not found in subscription."".format(static_site_name)<tab>)",0,if static_site . name . lower ( ) == static_site_name . lower ( ) :,if static_site . name == static_site_name :,0.125410406,45.01794978,0.729166667
"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if fail or self.network_stat != ""OK"":<tab><tab><tab># Fail or unknown<tab><tab><tab>if time_now - self.last_check_time < 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>if time_now - self.last_check_time < 10:<tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",0,if self . _checking_num > 0 :,if time_now - self . last_check_time < 3 :,0.16213496,6.917184228,0.6
"def _gen():<tab>for i in dataset():<tab><tab>if isinstance(i, tuple) or isinstance(i, list):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i<tab><tab>else:<tab><tab><tab>if fn(i) is True:<tab><tab><tab><tab>yield i",0,if fn ( * i ) is True :,if fn is True :,0.076979974,22.46644821,0.481481481
"def _merge_dict(d1, d2):<tab># Modifies d1 in-place to take values from d2<tab># if the nested keys from d2 are present in d1.<tab># https://stackoverflow.com/a/10704003/4488789<tab>for k, v2 in d2.items():<tab><tab>v1 = d1.get(k)  # returns None if v1 has no such key<tab><tab>if v1 is None:<tab><tab><tab>raise Exception(""{} is not recognized by client_config"".format(k))<tab><tab><IF-STMT><tab><tab><tab>_merge_dict(v1, v2)<tab><tab>else:<tab><tab><tab>d1[k] = v2<tab>return d1",0,"if isinstance ( v1 , Mapping ) and isinstance ( v2 , Mapping ) :","if isinstance ( v2 , dict ) :",0.214886036,20.84310098,0.305555556
"def OnRelease(self, evt):<tab>if self.isDrag:<tab><tab>parent = self.GetParent()<tab><tab>DrawSash(parent, self.px, self.py, self.side)<tab><tab>self.ReleaseMouse()<tab><tab>self.isDrag = False<tab><tab><IF-STMT><tab><tab><tab>parent.AddLeaf(MV_VER, self.py)<tab><tab>else:<tab><tab><tab>parent.AddLeaf(MV_HOR, self.px)<tab>else:<tab><tab>evt.Skip()",0,if self . side == MV_HOR :,if self . side == 1 :,0.386613272,55.06953149,0.771428571
"def check_zookeeper_metrics():<tab>response = get_metrics_prom(dcos_api_session, dcos_api_session.masters[0])<tab>for family in text_string_to_metric_families(response.text):<tab><tab>for sample in family.samples:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert sample[1][""dcos_component_name""] == ""ZooKeeper""<tab><tab><tab><tab>return<tab>raise Exception(""Expected ZooKeeper zookeeper_avg_latency metric not found"")",0,"if sample [ 0 ] == ""zookeeper_avg_latency"" :","if sample [ 0 ] == ""Zookeeper_avg_latency"" :",0.605621306,80.03203204,1
"def scan_patterns(self, kind):<tab>""""""Parse the config section into a list of patterns, preserving order.""""""<tab>d = self.scan_d(kind)<tab>aList = []<tab>seen = set()<tab>for key in d:<tab><tab>value = d.get(key)<tab><tab><IF-STMT><tab><tab><tab>g.trace(""duplicate key"", key)<tab><tab>else:<tab><tab><tab>seen.add(key)<tab><tab><tab>aList.append(self.msf.Pattern(key, value))<tab>return aList",1,if key in seen :,if key in seen :,0.75,100,1
"def foundNestedPseudoClass(self):<tab>i = self.pos + 1<tab>openParen = 0<tab>while i < len(self.source_text):<tab><tab>ch = self.source_text[i]<tab><tab>if ch == ""{"":<tab><tab><tab>return True<tab><tab>elif ch == ""("":<tab><tab><tab># pseudoclasses can contain ()<tab><tab><tab>openParen += 1<tab><tab>elif ch == "")"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>openParen -= 1<tab><tab>elif ch == "";"" or ch == ""}"":<tab><tab><tab>return False<tab><tab>i += 1<tab>return False",1,if openParen == 0 :,if openParen == 0 :,0.75,100,1
"def append(self, child):<tab>if child not in (None, self):<tab><tab>tag = child_tag(self._tag)<tab><tab>if tag:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if child.tag != tag:<tab><tab><tab><tab><tab>child = Html(tag, child)<tab><tab><tab>elif not child.startswith(""<%s"" % tag):<tab><tab><tab><tab>child = Html(tag, child)<tab><tab>super().append(child)",0,"if isinstance ( child , Html ) :","if hasattr ( child , ""tag"" ) :",0.091668085,20.55668085,0.481481481
"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab>if layer == ""conv"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab>elif layer == ""norm"" and norm and self.with_norm:<tab><tab><tab>x = self.norm(x)<tab><tab>elif layer == ""act"" and activate and self.with_activation:<tab><tab><tab>x = self.activate(x)<tab>return x",0,if self . with_explicit_padding :,if self . with_padding :,0.394778655,59.76278945,1
"def get_tasks(self):<tab>for task in asyncio.all_tasks(loop=self.middleware.loop):<tab><tab>formatted = None<tab><tab>frame = None<tab><tab>frames = []<tab><tab>for frame in task.get_stack():<tab><tab><tab>cur_frame = get_frame_details(frame, self.logger)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>frames.append(cur_frame)<tab><tab>if frame:<tab><tab><tab>formatted = traceback.format_stack(frame)<tab><tab>yield {<tab><tab><tab>""stack"": formatted,<tab><tab><tab>""frames"": frames,<tab><tab>}",1,if cur_frame :,if cur_frame :,0.531170663,1.00E-10,1
"def _read_row_from_packet(self, packet):<tab>row = []<tab>for encoding, converter in self.converters:<tab><tab>try:<tab><tab><tab>data = packet.read_length_coded_string()<tab><tab>except IndexError:<tab><tab><tab># No more columns in this row<tab><tab><tab># See https://github.com/PyMySQL/PyMySQL/pull/434<tab><tab><tab>break<tab><tab>if data is not None:<tab><tab><tab>if encoding is not None:<tab><tab><tab><tab>data = data.decode(encoding)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""DEBUG: DATA = "", data)<tab><tab><tab>if converter is not None:<tab><tab><tab><tab>data = converter(data)<tab><tab>row.append(data)<tab>return tuple(row)",0,if DEBUG :,if self . debug :,0.051944023,1.00E-10,0.45
"def get_child(self, name):<tab>if self.isdir:<tab><tab>try:<tab><tab><tab>return self.data[name]<tab><tab>except:<tab><tab><tab>if not self.case_sensitive:<tab><tab><tab><tab>for childname, child in list(self.data.items()):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>return child<tab><tab><tab>raise",0,if childname . lower ( ) == name . lower ( ) :,if childname == name :,0.021880396,10.48155441,0.577777778
"def _line_generator(fh, skip_blanks=False, strip=True):<tab>for line in fh:<tab><tab>if strip:<tab><tab><tab>line = line.strip()<tab><tab>skip = False<tab><tab><IF-STMT><tab><tab><tab>skip = line.isspace() or not line<tab><tab>if not skip:<tab><tab><tab>yield line",0,if skip_blanks :,elif skip_blanks :,0.108673556,1.00E-10,0.333333333
"def atleast_3d(*arys):<tab>if len(arys) == 1:<tab><tab>arr = array(arys[0])<tab><tab>if ndim(arr) == 0:<tab><tab><tab>arr = expand_dims(arr, axis=(0, 1, 2))<tab><tab><IF-STMT><tab><tab><tab>arr = expand_dims(arr, axis=(0, 2))<tab><tab>elif ndim(arr) == 2:<tab><tab><tab>arr = expand_dims(arr, axis=2)<tab><tab>return arr<tab>else:<tab><tab>return [atleast_3d(arr) for arr in arys]",1,elif ndim ( arr ) == 1 :,elif ndim ( arr ) == 1 :,0.75,100,1
"def scan_resource_conf(self, conf):<tab>os_profile = conf.get(""os_profile"")<tab>if os_profile:<tab><tab>os_profile = os_profile[0]<tab><tab>custom_data = os_profile.get(""custom_data"")<tab><tab>if custom_data:<tab><tab><tab>custom_data = custom_data[0]<tab><tab><tab>if isinstance(custom_data, str):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return CheckResult.FAILED<tab>return CheckResult.PASSED",0,if string_has_secrets ( custom_data ) :,"if custom_data not in [ ""0.0.0.0"" , ""0.0.0"" ] :",0.021554939,10.34360301,0.46875
"def __call__(self, trainer):<tab>observation = trainer.observation<tab>if self.key in observation:<tab><tab>loss = observation[self.key]<tab><tab><IF-STMT><tab><tab><tab>self.min_loss = loss<tab><tab><tab>self.best_model = trainer.updater.epoch<tab><tab><tab>src = ""%s.%d"" % (self.prefix, self.best_model)<tab><tab><tab>dest = os.path.join(trainer.out, ""%s.%s"" % (self.prefix, self.suffix))<tab><tab><tab>if os.path.lexists(dest):<tab><tab><tab><tab>os.remove(dest)<tab><tab><tab>os.symlink(src, dest)<tab><tab><tab>logging.info(""best model is "" + src)",0,if self . best_model == - 1 or loss < self . min_loss :,if loss < self . min_loss :,0.172919661,29.26985561,0.307017544
"def dump_prefs(self):<tab>ret = """"<tab>for pref in self.prefs:<tab><tab><IF-STMT><tab><tab><tab>value = str(self.prefs[pref].value)<tab><tab>elif type(self.prefs[pref].value) == bool:<tab><tab><tab>value = ""true"" if self.prefs[pref].value == True else ""false""<tab><tab>else:<tab><tab><tab>value = '""%s""' % self.prefs[pref].value<tab><tab>ret += pref + "": "" + value + "" ("" + self.prefs[pref].anon_source + "")\n""<tab>return ret",0,if type ( self . prefs [ pref ] . value ) == int :,if type ( self . prefs [ pref ] . value ) == str :,0.580237697,87.61560783,0.777777778
"def translate_isinstance(<tab>builder: IRBuilder, expr: CallExpr, callee: RefExpr) -> Optional[Value]:<tab># Special case builtins.isinstance<tab>if (<tab><tab>len(expr.args) == 2<tab><tab>and expr.arg_kinds == [ARG_POS, ARG_POS]<tab><tab>and isinstance(expr.args[1], (RefExpr, TupleExpr))<tab>):<tab><tab>irs = builder.flatten_classes(expr.args[1])<tab><tab><IF-STMT><tab><tab><tab>return builder.builder.isinstance_helper(<tab><tab><tab><tab>builder.accept(expr.args[0]), irs, expr.line<tab><tab><tab>)<tab>return None",1,if irs is not None :,if irs is not None :,0.75,100,1
"def autoname(self):<tab>naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"")<tab>if not naming_method:<tab><tab>throw(_(""Please setup Employee Naming System in Human Resource > HR Settings""))<tab>else:<tab><tab><IF-STMT><tab><tab><tab>set_name_by_naming_series(self)<tab><tab>elif naming_method == ""Employee Number"":<tab><tab><tab>self.name = self.employee_number<tab><tab>elif naming_method == ""Full Name"":<tab><tab><tab>self.set_employee_name()<tab><tab><tab>self.name = self.employee_name<tab>self.employee = self.name",1,"if naming_method == ""Naming Series"" :","if naming_method == ""Naming Series"" :",0.75,100,1
"def search_expr(sheet, expr, reverse=False):<tab>for i in rotateRange(len(sheet.rows), sheet.cursorRowIndex, reverse=reverse):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sheet.cursorRowIndex = i<tab><tab><tab><tab>return<tab><tab>except Exception as e:<tab><tab><tab>vd.exceptionCaught(e)<tab>vd.fail(f""no {sheet.rowtype} where {expr}"")",0,"if sheet . evalExpr ( expr , sheet . rows [ i ] ) :",if expr in sheet . rows [ i ] :,0.262654408,34.70112581,0.242647059
"def _targets(self, urls, querystring):<tab>for input, output in urls:<tab><tab>response = self.client.get(u""/1/%s"" % input, follow=True)<tab><tab>if output == 404:<tab><tab><tab>eq_(404, response.status_code)<tab><tab><IF-STMT><tab><tab><tab>chain = [u[0] for u in response.redirect_chain]<tab><tab><tab>assert output in chain<tab><tab>else:<tab><tab><tab>r = response.redirect_chain<tab><tab><tab>r.reverse()<tab><tab><tab>final = urlparse(r[0][0])<tab><tab><tab>eq_(output, final.path)<tab><tab><tab>eq_(querystring, final.query)",0,"elif output . startswith ( ""http"" ) :",elif response . status_code == 302 :,0.060226795,5.522397784,0.333333333
"def get_local_cache(self, past, data, from_file, temp_id):<tab>""""""parse individual cached geometry if there is any""""""<tab>cache = []<tab>if self.accumulative:<tab><tab>if from_file and len(past) > 0:<tab><tab><tab>cache = past[temp_id]<tab><tab><IF-STMT><tab><tab><tab>cache = data.get(temp_id, [])<tab>return cache",0,if not from_file and len ( data ) > 0 :,elif len ( data ) > 0 :,0.470953523,45.00994165,0.104166667
"def _parse_abbrev_table(self):<tab>""""""Parse the abbrev table from the stream""""""<tab>map = {}<tab>self.stream.seek(self.offset)<tab>while True:<tab><tab>decl_code = struct_parse(<tab><tab><tab>struct=self.structs.Dwarf_uleb128(""""), stream=self.stream<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>declaration = struct_parse(<tab><tab><tab>struct=self.structs.Dwarf_abbrev_declaration, stream=self.stream<tab><tab>)<tab><tab>map[decl_code] = AbbrevDecl(decl_code, declaration)<tab>return map",1,if decl_code == 0 :,if decl_code == 0 :,0.75,100,1
"def mFRIDAY(<tab>self,):<tab>try:<tab><tab>_type = FRIDAY<tab><tab>_channel = DEFAULT_CHANNEL<tab><tab>pass<tab><tab>self.match(""fri"")<tab><tab>alt10 = 2<tab><tab>LA10_0 = self.input.LA(1)<tab><tab>if LA10_0 == 100:<tab><tab><tab>alt10 = 1<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab><tab>self.match(""day"")<tab><tab>self._state.type = _type<tab><tab>self._state.channel = _channel<tab>finally:<tab><tab>pass",1,if alt10 == 1 :,if alt10 == 1 :,0.75,100,1
"def __getattr__(self, key):<tab>from mongokit.schema_document import i18n<tab>if key in self:<tab><tab>if isinstance(self[key], i18n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self[key].get(self._doc._fallback_lang)<tab><tab><tab>return self[key][self._doc._current_lang]<tab><tab>return self[key]",0,if self . _doc . _current_lang not in self [ key ] :,if self . _doc . _fallback_lang is not None :,0.300359538,40.61212808,0.325
"def compact_repr(record):<tab>parts = []<tab>for key in record.__attributes__:<tab><tab>value = getattr(record, key)<tab><tab>if not value:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>value = HIDE_LIST<tab><tab>elif key == FEATS:<tab><tab><tab>value = format_feats(value)<tab><tab>else:<tab><tab><tab>value = repr(value)<tab><tab>value = capped_str(value)<tab><tab>parts.append(""%s=%s"" % (key, value))<tab>return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",0,"if isinstance ( value , list ) :",elif key == HIDE_LIST :,0.013646361,5.522397784,0.114285714
"def pre_validate(self, form):<tab>if self.data:<tab><tab>values = list(c[0] for c in self.choices)<tab><tab>for d in self.data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>self.gettext(u""'%(value)s' is not a valid choice for this field"")<tab><tab><tab><tab><tab>% dict(value=d)<tab><tab><tab><tab>)",1,if d not in values :,if d not in values :,0.75,100,1
"def _sql_like_to_regex(pattern, escape):<tab>cur_i = 0<tab>pattern_length = len(pattern)<tab>while cur_i < pattern_length:<tab><tab>nxt_i = cur_i + 1<tab><tab>cur = pattern[cur_i]<tab><tab>nxt = pattern[nxt_i] if nxt_i < pattern_length else None<tab><tab>skip = 1<tab><tab>if nxt is not None and escape is not None and cur == escape:<tab><tab><tab>yield nxt<tab><tab><tab>skip = 2<tab><tab><IF-STMT><tab><tab><tab>yield "".*""<tab><tab>elif cur == ""_"":<tab><tab><tab>yield "".""<tab><tab>else:<tab><tab><tab>yield cur<tab><tab>cur_i += skip",0,"elif cur == ""%"" :","if cur == ""*"" :",0.062871671,41.11336169,0.5
"def find_caller(stack):<tab>""""""Finds info about first non-sqlalchemy call in stack""""""<tab>for frame in stack:<tab><tab># We don't care about sqlalchemy internals<tab><tab>module = inspect.getmodule(frame[0])<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if module.__name__.startswith(""sqlalchemy""):<tab><tab><tab>continue<tab><tab>return (module.__name__,) + tuple(frame[2:4]) + (frame[4][0].strip(),)<tab>log.warning(""Transaction from unknown origin"")<tab>return None, None, None, None",0,"if not hasattr ( module , ""__name__"" ) :",if module is None :,0.079338046,1.902615563,0.285714286
"def _get_normal_median_depth(normal_counts):<tab>depths = []<tab>with open(normal_counts) as in_handle:<tab><tab>header = None<tab><tab>for line in in_handle:<tab><tab><tab>if header is None and not line.startswith(""@""):<tab><tab><tab><tab>header = line.strip().split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>n_vals = dict(zip(header, line.strip().split()))<tab><tab><tab><tab>depths.append(int(n_vals[""REF_COUNT""]) + int(n_vals[""ALT_COUNT""]))<tab>return np.median(depths)",1,elif header :,elif header :,0.514316131,1.00E-10,1
"def get_pool(self, *args, **kw):<tab>key = self._serialize(*args, **kw)<tab>try:<tab><tab>return self.pools[key]<tab>except KeyError:<tab><tab>self._create_pool_mutex.acquire()<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kw.pop(""sa_pool_key"", None)<tab><tab><tab><tab>pool = self.poolclass(<tab><tab><tab><tab><tab>lambda: self.module.connect(*args, **kw), **self.kw<tab><tab><tab><tab>)<tab><tab><tab><tab>self.pools[key] = pool<tab><tab><tab><tab>return pool<tab><tab><tab>else:<tab><tab><tab><tab>return self.pools[key]<tab><tab>finally:<tab><tab><tab>self._create_pool_mutex.release()",0,if key not in self . pools :,"if key == ""sa_pool_key"" :",0.035401841,7.495553473,0.357142857
"def add(self, field, value, boost=None):<tab>match = {""value"": value}<tab>if boost:<tab><tab><IF-STMT><tab><tab><tab>match[""boost""] = boost<tab><tab>else:<tab><tab><tab>match[""boost""] = float(boost)<tab><tab>self._values[field] = match<tab><tab>return<tab>self._values[field] = value",0,"if isinstance ( boost , ( float , int ) ) :","if isinstance ( boost , int ) :",0.269132464,43.58579201,0.655555556
"def get_shape(shape):<tab>""""""Convert the shape to correct dtype and vars.""""""<tab>ret = []<tab>for dim in shape:<tab><tab>if isinstance(dim, tvm.tir.IntImm):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(dim)<tab><tab><tab>else:<tab><tab><tab><tab>val = int(dim)<tab><tab><tab><tab>assert val <= np.iinfo(np.int32).max<tab><tab><tab><tab>ret.append(tvm.tir.IntImm(""int32"", val))<tab><tab>elif isinstance(dim, tvm.tir.Any):<tab><tab><tab>ret.append(te.var(""any_dim"", ""int32""))<tab><tab>else:<tab><tab><tab>ret.append(dim)<tab>return ret",0,"if libinfo ( ) [ ""INDEX_DEFAULT_I64"" ] == ""ON"" :",if dim == 0 :,0.014393213,2.211543563,0.386666667
"def _find_icacls_exe():<tab>if os.name == ""nt"":<tab><tab>paths = [<tab><tab><tab>os.path.expandvars(r""%windir%\{0}"").format(subdir)<tab><tab><tab>for subdir in (""system32"", ""SysWOW64"")<tab><tab>]<tab><tab>for path in paths:<tab><tab><tab>icacls_path = next(<tab><tab><tab><tab>iter(fn for fn in os.listdir(path) if fn.lower() == ""icacls.exe""), None<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>icacls_path = os.path.join(path, icacls_path)<tab><tab><tab><tab>return icacls_path<tab>return None",1,if icacls_path is not None :,if icacls_path is not None :,0.75,100,1
"def mlt_version_is_greater_correct(test_version):<tab>runtime_ver = mlt_version.split(""."")<tab>test_ver = test_version.split(""."")<tab>if runtime_ver[0] > test_ver[0]:<tab><tab>return True<tab>elif runtime_ver[0] == test_ver[0]:<tab><tab>if runtime_ver[1] > test_ver[1]:<tab><tab><tab>return True<tab><tab>elif runtime_ver[1] == test_ver[1]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",1,if runtime_ver [ 2 ] > test_ver [ 2 ] :,if runtime_ver [ 2 ] > test_ver [ 2 ] :,0.75,100,1
"def get_ready_conn(self, host):<tab>conn = None<tab>self._lock.acquire()<tab>try:<tab><tab>if host in self._hostmap:<tab><tab><tab>for c in self._hostmap[host]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._readymap[c] = 0<tab><tab><tab><tab><tab>conn = c<tab><tab><tab><tab><tab>break<tab>finally:<tab><tab>self._lock.release()<tab>return conn",0,if self . _readymap [ c ] :,if c in self . _readymap :,0.084094251,35.09119774,0.377777778
"def to_svc_hst_distinct_lists(ref, tab):<tab>r = {""hosts"": [], ""services"": []}<tab>for e in tab:<tab><tab>cls = e.__class__<tab><tab><IF-STMT><tab><tab><tab>name = e.get_dbg_name()<tab><tab><tab>r[""services""].append(name)<tab><tab>else:<tab><tab><tab>name = e.get_dbg_name()<tab><tab><tab>r[""hosts""].append(name)<tab>return r",0,"if cls . my_type == ""service"" :","if cls . __name__ == ""Service"" :",0.344478934,20.80375826,1
"def playerData(s):<tab>""""""Returns a list of tuples of original string and dict of values""""""<tab>p = []<tab>i = 0<tab>while True:<tab><tab>match = re_input.match(s, pos=i)<tab><tab>if match is None:<tab><tab><tab>return p<tab><tab>else:<tab><tab><tab>d = match.groupdict()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>d[""degree""], d[""kwargs""] = getArgs(d[""args""])<tab><tab><tab>else:<tab><tab><tab><tab>d[""degree""], d[""kwargs""] = """", {}<tab><tab><tab>del d[""args""]<tab><tab><tab>p.append((match.group().strip(), d))<tab><tab><tab>i = match.end()<tab>return",0,"if d [ ""args"" ] is not None :","if ""args"" in d :",0.017732313,16.41722369,0.257142857
"def _params_for_TXT(self, record):<tab>for value in record.values:<tab><tab>field_type = ""TXT""<tab><tab><IF-STMT><tab><tab><tab>field_type = ""DKIM""<tab><tab><tab>value = value.replace(""\\;"", "";"")<tab><tab>yield {<tab><tab><tab>""target"": value,<tab><tab><tab>""subDomain"": record.name,<tab><tab><tab>""ttl"": record.ttl,<tab><tab><tab>""fieldType"": field_type,<tab><tab>}",0,if self . _is_valid_dkim ( value ) :,"if isinstance ( value , str ) :",0.044942074,8.840282257,0.481481481
"def create(self, values):<tab>conn = self.get_connection()<tab>object_classes = self.structural_classes + [self.object_class]<tab>attrs = [(""objectClass"", object_classes)]<tab>for k, v in values.iteritems():<tab><tab>if k == ""id"" or k in self.attribute_ignore:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>attr_type = self.attribute_mapping.get(k, k)<tab><tab><tab>attrs.append((attr_type, [v]))<tab>if ""groupOfNames"" in object_classes and self.use_dumb_member:<tab><tab>attrs.append((""member"", [self.DUMB_MEMBER_DN]))<tab>conn.add_s(self._id_to_dn(values[""id""]), attrs)<tab>return values",0,if v is not None :,if k in self . attribute_mapping :,0.023878899,5.669791111,0.2
"def get_new_unlinked_nodes(<tab>before_inputted_nodes, before_input_sockets, input_sockets, nodes_dict):<tab>affected_nodes = []<tab>for node_id, socket in zip(before_inputted_nodes, before_input_sockets):<tab><tab>if not socket in input_sockets:<tab><tab><tab># if the node has been deleted it is not affected<tab><tab><tab>if node_id in nodes_dict:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>affected_nodes.append(node_id)<tab>return affected_nodes",0,if not node_id in affected_nodes :,if node_id not in nodes_dict [ node_id ] :,0.174523051,12.87433051,1
"def show_panel(panel_id):<tab># Iterate positions to find where panel is and bring it to front.<tab>for position in _positions_names:<tab><tab>pos_panel_ids = _get_position_panels(position)<tab><tab>if len(pos_panel_ids) == 0:<tab><tab><tab>continue<tab><tab>if len(pos_panel_ids) == 1:<tab><tab><tab>continue<tab><tab>panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id]<tab><tab>notebook = _position_notebooks[position]<tab><tab>for i in range(0, notebook.get_n_pages()):<tab><tab><tab>notebook_page = notebook.get_nth_page(i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>notebook.set_current_page(i)",0,if notebook_page == panel_widget :,if notebook_page is not None and notebook_page != 0 :,0.045891393,18.92240569,0.230769231
"def merge(self, abort=False, message=None):<tab>""""""Merge remote branch or reverts the merge.""""""<tab>if abort:<tab><tab>self.execute([""update"", ""--clean"", "".""])<tab>elif self.needs_merge():<tab><tab><IF-STMT><tab><tab><tab>self.execute([""update"", ""--clean"", ""remote(.)""])<tab><tab>else:<tab><tab><tab>self.configure_merge()<tab><tab><tab># Fallback to merge<tab><tab><tab>try:<tab><tab><tab><tab>self.execute([""merge"", ""-r"", ""remote(.)""])<tab><tab><tab>except RepositoryException as error:<tab><tab><tab><tab>if error.retcode == 255:<tab><tab><tab><tab><tab># Nothing to merge<tab><tab><tab><tab><tab>return<tab><tab><tab><tab>raise<tab><tab><tab>self.execute([""commit"", ""--message"", ""Merge""])",0,if self . needs_ff ( ) :,if message :,0.020447728,1.00E-10,0.5
"def runButtons(action):<tab>global sqlUpdate<tab>if action == ""Clear"":<tab><tab>app.text(LABS[""run""], replace=True)<tab><tab>app.message(LABS[""run""], """", bg=""grey"")<tab><tab>log(""SQL cleared"")<tab>elif action == ""Run"":<tab><tab>app.message(LABS[""run""], """")<tab><tab>sql = app.text(LABS[""run""]).strip()<tab><tab><IF-STMT><tab><tab><tab>runSql(sql)<tab><tab>else:<tab><tab><tab>app.message(LABS[""run""], """", bg=""grey"")<tab>app.text(LABS[""run""], focus=True)",0,if len ( sql ) > 0 :,if sql :,0.01726708,1.00E-10,0.36
"def receive_loop(self):<tab>while not self._stoped:<tab><tab>try:<tab><tab><tab>rd, _, _ = select.select([self.teredo_sock], [], [], 0.5)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.receive_ra_packet()<tab><tab>except Exception as e:<tab><tab><tab>logger.exception(""receive procedure fail once: %r"", e)<tab><tab><tab>pass",0,if rd and not self . _stoped :,if rd :,0.072372359,1.00E-10,0.444444444
"def add_items(self, model, objs):<tab>search_fields = model.get_search_fields()<tab>if not search_fields:<tab><tab>return<tab>indexers = [ObjectIndexer(obj, self.backend) for obj in objs]<tab># TODO: Delete unindexed objects while dealing with proxy models.<tab>if indexers:<tab><tab>content_type_pk = get_content_type_pk(model)<tab><tab>update_method = (<tab><tab><tab>self.add_items_upsert<tab><tab><tab><IF-STMT><tab><tab><tab>else self.add_items_update_then_create<tab><tab>)<tab><tab>update_method(content_type_pk, indexers)",0,if self . _enable_upsert,if content_type_pk in search_fields,0.045342154,5.522397784,0.5
"def __init__(self, service: RestClient, **k_args: Dict[str, str]):<tab>self.path: str = None<tab>self.httpMethod: str = None<tab>self.service: RestClient = service<tab>self.__dict__.update(k_args)<tab>self.path_args: List[str] = []<tab>self.query_args: List[str] = []<tab>if hasattr(self, ""parameters""):<tab><tab>for key, value in self.parameters.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.path_args.append(key)<tab><tab><tab>else:<tab><tab><tab><tab>self.query_args.append(key)",0,"if value [ ""location"" ] == ""path"" :","if isinstance ( value , str ) :",0.019345088,3.890218086,0.36
"def insertion_unsort(str, extended):<tab>""""""3.2 Insertion unsort coding""""""<tab>oldchar = 0x80<tab>result = []<tab>oldindex = -1<tab>for c in extended:<tab><tab>index = pos = -1<tab><tab>char = ord(c)<tab><tab>curlen = selective_len(str, char)<tab><tab>delta = (curlen + 1) * (char - oldchar)<tab><tab>while 1:<tab><tab><tab>index, pos = selective_find(str, c, index, pos)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>delta += index - oldindex<tab><tab><tab>result.append(delta - 1)<tab><tab><tab>oldindex = index<tab><tab><tab>delta = 0<tab><tab>oldchar = char<tab>return result",1,if index == - 1 :,if index == - 1 :,0.75,100,1
"def get_sorted_entry(field, bookid):<tab>if field == ""title"" or field == ""authors"":<tab><tab>book = calibre_db.get_filtered_book(bookid)<tab><tab>if book:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return json.dumps({""sort"": book.sort})<tab><tab><tab>elif field == ""authors"":<tab><tab><tab><tab>return json.dumps({""author_sort"": book.author_sort})<tab>return """"",1,"if field == ""title"" :","if field == ""title"" :",0.75,100,1
"def _convert_tstamp(out):<tab># Searches for top-level timestamp attributes or within dictionaries<tab>if ""timestamp"" in out:<tab><tab># Convert UNIX to datetime object<tab><tab>f = float(out[""timestamp""])<tab><tab>out[""timestamp""] = datetime.fromtimestamp(f / 1000)<tab>else:<tab><tab>for ticker, data in out.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f = float(data[""timestamp""])<tab><tab><tab><tab>data[""timestamp""] = datetime.fromtimestamp(f / 1000)<tab><tab><tab><tab>out[ticker] = data<tab>return out",1,"if ""timestamp"" in data :","if ""timestamp"" in data :",0.75,100,1
"def write_urls(self, person):<tab>""""""Write URL and EMAIL properties of a VCard.""""""<tab>url_list = person.get_url_list()<tab>for url in url_list:<tab><tab>href = url.get_path()<tab><tab><IF-STMT><tab><tab><tab>if url.get_type() == UrlType(UrlType.EMAIL):<tab><tab><tab><tab>if href.startswith(""mailto:""):<tab><tab><tab><tab><tab>href = href[len(""mailto:"") :]<tab><tab><tab><tab>self.writeln(""EMAIL:%s"" % self.esc(href))<tab><tab><tab>else:<tab><tab><tab><tab>self.writeln(""URL:%s"" % self.esc(href))",1,if href :,if href :,0.531170663,1.00E-10,1
"def get_range(min, max):<tab>if max < min:<tab><tab>min, max = max, min<tab>elif min == max:<tab><tab><IF-STMT><tab><tab><tab>min, max = 2 * min, 0<tab><tab>elif min > 0:<tab><tab><tab>min, max = 0, 2 * min<tab><tab>else:<tab><tab><tab>min, max = -1, 1<tab>return min, max",1,if min < 0 :,if min < 0 :,0.75,100,1
"def __init__(self, mapping=None):<tab>if isinstance(mapping, MultiDict):<tab><tab>dict.__init__(self, ((k, l[:]) for k, l in mapping.iterlists()))<tab>elif isinstance(mapping, dict):<tab><tab>tmp = {}<tab><tab>for key, value in mapping.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = list(value)<tab><tab><tab>else:<tab><tab><tab><tab>value = [value]<tab><tab><tab>tmp[key] = value<tab><tab>dict.__init__(self, tmp)<tab>else:<tab><tab>tmp = {}<tab><tab>for key, value in mapping or ():<tab><tab><tab>tmp.setdefault(key, []).append(value)<tab><tab>dict.__init__(self, tmp)",0,"if isinstance ( value , ( tuple , list ) ) :","if isinstance ( value , ( list , tuple ) ) :",0.535337289,57.06745777,0.666666667
"def modified_precision(candidate, references, n):<tab>candidate_ngrams = list(ngrams(candidate, n))<tab>if len(candidate_ngrams) == 0:<tab><tab>return 0<tab>c_words = set(candidate_ngrams)<tab>for word in c_words:<tab><tab>count_w = candidate_ngrams.count(word) + 1<tab><tab>count_max = 0<tab><tab>for reference in references:<tab><tab><tab>reference_ngrams = list(ngrams(reference, n))<tab><tab><tab>count = reference_ngrams.count(word) + 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>count_max = count<tab>return min(count_w, count_max) / (len(candidate) + len(c_words))",1,if count > count_max :,if count > count_max :,0.75,100,1
"def reverse_adjust_line_according_to_hunks(self, hunks, line):<tab>for hunk in reversed(hunks):<tab><tab>head_start = hunk.head_start<tab><tab>saved_start = hunk.saved_start<tab><tab>if hunk.saved_length == 0:<tab><tab><tab>saved_start += 1<tab><tab>elif hunk.head_length == 0:<tab><tab><tab>saved_start -= 1<tab><tab>head_end = head_start + hunk.head_length<tab><tab>saved_end = saved_start + hunk.saved_length<tab><tab>if saved_end <= line:<tab><tab><tab>return head_end + line - saved_end<tab><tab><IF-STMT><tab><tab><tab>return head_start<tab># fails to find matching<tab>return line",0,elif saved_start <= line :,elif saved_start >= line :,0.330342842,50,1
"def indent_xml(elem, level=0):<tab>""""""Do our pretty printing and make Matt very happy.""""""<tab>i = ""\n"" + level * ""  ""<tab>if elem:<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent_xml(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab>if level and (not elem.tail or not elem.tail.strip()):<tab><tab><tab>elem.tail = i",1,if not elem . tail or not elem . tail . strip ( ) :,if not elem . tail or not elem . tail . strip ( ) :,1,100,1
"def test_infer_shape_matrix(self):<tab># Testing the infer_shape with a matrix.<tab>x = theano.tensor.matrix()<tab>for op in self.ops:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if op.return_index:<tab><tab><tab>f = op(x)[2]<tab><tab>else:<tab><tab><tab>f = op(x)[1]<tab><tab>self._compile_and_check(<tab><tab><tab>[x],<tab><tab><tab>[f],<tab><tab><tab>[np.asarray(np.array([[2, 1], [3, 2], [2, 3]]), dtype=config.floatX)],<tab><tab><tab>self.op_class,<tab><tab>)",0,if not op . return_inverse :,"if not isinstance ( op , infer_shape ) :",0.041941062,9.425159511,0.581818182
"def drop_lists(value):<tab>out = {}<tab>for key, val in value.items():<tab><tab>val = val[0]<tab><tab>if isinstance(key, bytes):<tab><tab><tab>key = str(key, ""utf-8"")<tab><tab><IF-STMT><tab><tab><tab>val = str(val, ""utf-8"")<tab><tab>out[key] = val<tab>return out",1,"if isinstance ( val , bytes ) :","if isinstance ( val , bytes ) :",0.75,100,1
"def malloc(self, size):<tab># return a block of right size (possibly rounded up)<tab>assert 0 <= size < sys.maxsize<tab>if os.getpid() != self._lastpid:<tab><tab>self.__init__()  # reinitialize after fork<tab>with self._lock:<tab><tab>self._free_pending_blocks()<tab><tab>size = self._roundup(max(size, 1), self._alignment)<tab><tab>(arena, start, stop) = self._malloc(size)<tab><tab>new_stop = start + size<tab><tab><IF-STMT><tab><tab><tab>self._free((arena, new_stop, stop))<tab><tab>block = (arena, start, new_stop)<tab><tab>self._allocated_blocks.add(block)<tab><tab>return block",1,if new_stop < stop :,if new_stop < stop :,0.75,100,1
"def ContinueStatement(self, label, **kwargs):<tab>if label is None:<tab><tab>self.emit(""JUMP"", self.implicit_continues[-1])<tab>else:<tab><tab>label = label.get(""name"")<tab><tab><IF-STMT><tab><tab><tab>raise MakeError(""SyntaxError"", ""Undefined label '%s'"" % label)<tab><tab>else:<tab><tab><tab>self.emit(""JUMP"", self.declared_continue_labels[label])",1,if label not in self . declared_continue_labels :,if label not in self . declared_continue_labels :,0.75,100,1
"def parse_counter_style_name(tokens, counter_style):<tab>tokens = remove_whitespace(tokens)<tab>if len(tokens) == 1:<tab><tab>(token,) = tokens<tab><tab><IF-STMT><tab><tab><tab>if token.lower_value in (""decimal"", ""disc""):<tab><tab><tab><tab>if token.lower_value not in counter_style:<tab><tab><tab><tab><tab>return token.value<tab><tab><tab>elif token.lower_value != ""none"":<tab><tab><tab><tab>return token.value",0,"if token . type == ""ident"" :","if token . lower_type == ""counter"" :",0.344478934,34.17233408,0.722222222
"def __call__(self, data):<tab>num_points = data.pos.shape[0]<tab>new_data = Data()<tab>for key in data.keys:<tab><tab>if key == KDTREE_KEY:<tab><tab><tab>continue<tab><tab>item = data[key]<tab><tab><IF-STMT><tab><tab><tab>item = item[self._indices].clone()<tab><tab>elif torch.is_tensor(item):<tab><tab><tab>item = item.clone()<tab><tab>setattr(new_data, key, item)<tab>return new_data",0,if torch . is_tensor ( item ) and num_points == item . shape [ 0 ] :,if torch . is_tensor ( item ) :,0.22755772,27.21596934,0.5
"def HandleEvent(self, event):<tab>e_id = event.GetId()<tab>if e_id in self.handlers:<tab><tab>handler = self.handlers[e_id]<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return handler(event)<tab><tab>except RuntimeError:<tab><tab><tab>self.RemoveHandlerForID(e_id)<tab>else:<tab><tab>event.Skip()<tab>return False",0,if handler :,if handler is not None :,0.090364769,1.00E-10,0.4
"def try_append_extension(self, path):<tab>append_setting = self.get_append_extension_setting()<tab>if self.settings.get(append_setting, False):<tab><tab>if not self.is_copy_original_name(path):<tab><tab><tab>_, new_path_extension = os.path.splitext(path)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>argument_name = self.get_argument_name()<tab><tab><tab><tab>if argument_name is None:<tab><tab><tab><tab><tab>_, extension = os.path.splitext(self.view.file_name())<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>_, extension = os.path.splitext(argument_name)<tab><tab><tab><tab>path += extension<tab>return path",0,"if new_path_extension == """" :",if new_path_extension == self . view . file_name ( ) :,0.098405538,40.05274485,0.472222222
"def _get_namespace(self, gl_client, gl_namespace, lazy=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return gl_client.groups.get(gl_namespace.attributes[""id""], lazy=lazy)<tab><tab>if gl_namespace.attributes[""kind""] == ""user"":<tab><tab><tab>return gl_client.users.get(gl_client.user.attributes[""id""], lazy=lazy)<tab><tab># Note: This doesn't seem to work for IDs retrieved via the namespaces API; the IDs are<tab><tab># different.<tab><tab>return gl_client.users.get(gl_namespace.attributes[""id""], lazy=lazy)<tab>except gitlab.GitlabGetError:<tab><tab>return None",1,"if gl_namespace . attributes [ ""kind"" ] == ""group"" :","if gl_namespace . attributes [ ""kind"" ] == ""group"" :",0.75,100,1
"def removeReadOnly(self, files):<tab># Removes all read-on ly flags in a for all files<tab>for filepath in files:<tab><tab><IF-STMT><tab><tab><tab># Windows only needs S_IWRITE, but we bitwise-or with current perms to preserve other permission bits on Linux<tab><tab><tab>os.chmod(filepath, stat.S_IWRITE | os.stat(filepath).st_mode)",0,if os . path . isfile ( filepath ) :,"if os . path . exists ( filepath ) and os . access ( filepath , os . X_OK ) :",0.352533592,22.06773105,0.442386831
"def initiate_all_local_variables_instances(<tab>nodes, local_variables_instances, all_local_variables_instances):<tab>for node in nodes:<tab><tab><IF-STMT><tab><tab><tab>new_var = LocalIRVariable(node.variable_declaration)<tab><tab><tab>if new_var.name in all_local_variables_instances:<tab><tab><tab><tab>new_var.index = all_local_variables_instances[new_var.name].index + 1<tab><tab><tab>local_variables_instances[node.variable_declaration.name] = new_var<tab><tab><tab>all_local_variables_instances[node.variable_declaration.name] = new_var",0,if node . variable_declaration :,if node . variable_declaration not in local_variables_instances :,0.351498834,36.36227047,0.56
"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab><IF-STMT><tab><tab><tab>if instring:<tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None",0,"if char in ( '""' , ""'"" ) :","if char != ""#"" :",0.080686206,7.43376166,0.730769231
"def set_study_system_attr(self, study_id: int, key: str, value: Any) -> None:<tab>with _create_scoped_session(self.scoped_session, True) as session:<tab><tab>study = models.StudyModel.find_or_raise_by_id(study_id, session)<tab><tab>attribute = models.StudySystemAttributeModel.find_by_study_and_key(<tab><tab><tab>study, key, session<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>attribute = models.StudySystemAttributeModel(<tab><tab><tab><tab>study_id=study_id, key=key, value_json=json.dumps(value)<tab><tab><tab>)<tab><tab><tab>session.add(attribute)<tab><tab>else:<tab><tab><tab>attribute.value_json = json.dumps(value)",1,if attribute is None :,if attribute is None :,0.75,100,1
"def clear_doc(self, docname: str) -> None:<tab>for sChild in self._children:<tab><tab>sChild.clear_doc(docname)<tab><tab>if sChild.declaration and sChild.docname == docname:<tab><tab><tab>sChild.declaration = None<tab><tab><tab>sChild.docname = None<tab><tab><tab>sChild.line = None<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sChild.siblingAbove.siblingBelow = sChild.siblingBelow<tab><tab><tab>if sChild.siblingBelow is not None:<tab><tab><tab><tab>sChild.siblingBelow.siblingAbove = sChild.siblingAbove<tab><tab><tab>sChild.siblingAbove = None<tab><tab><tab>sChild.siblingBelow = None",1,if sChild . siblingAbove is not None :,if sChild . siblingAbove is not None :,0.75,100,1
"def test_sum_values_list_group_by(self):<tab>ret = (<tab><tab>await Book.annotate(sum=Sum(""rating""))<tab><tab>.group_by(""author_id"")<tab><tab>.values_list(""author_id"", ""sum"")<tab>)<tab>for item in ret:<tab><tab>author_id = item[0]<tab><tab>sum_ = item[1]<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(sum_, 45.0)<tab><tab>elif author_id == self.a2.pk:<tab><tab><tab>self.assertEqual(sum_, 10.0)",1,if author_id == self . a1 . pk :,if author_id == self . a1 . pk :,0.75,100,1
"def save_claims_for_resolve(self, claim_infos):<tab>to_save = {}<tab>for info in claim_infos:<tab><tab>if ""value"" in info:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_save[info[""claim_id""]] = info<tab><tab>else:<tab><tab><tab>for key in (""certificate"", ""claim""):<tab><tab><tab><tab>if info.get(key, {}).get(""value""):<tab><tab><tab><tab><tab>to_save[info[key][""claim_id""]] = info[key]<tab>return self.save_claims(to_save.values())",0,"if info [ ""value"" ] :","if info . get ( ""claim_id"" , None ) . get ( ""value"" ) :",0.035174593,8.896962873,0.573913043
"def utcoffset(self, dt):<tab>if not dst_only:<tab><tab>dt_n = dt.replace(tzinfo=None)<tab><tab><IF-STMT><tab><tab><tab>return timedelta(hours=-1)<tab>return timedelta(hours=0)",0,"if dt_start <= dt_n < dt_end and getattr ( dt_n , ""fold"" , 0 ) :",if dt_n . tzinfo is None :,0.007735099,3.59160365,0.25
"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None",1,if instring :,if instring :,0.531170663,1.00E-10,1
"def __subclasshook__(cls, C):<tab>if cls is Coroutine:<tab><tab>mro = get_mro(C)<tab><tab>for method in (""__await__"", ""send"", ""throw"", ""close""):<tab><tab><tab>for base in mro:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>return NotImplemented<tab><tab>return True<tab>return NotImplemented",0,if method in base . __dict__ :,if method in base :,0.314263598,21.29764697,1
"def GetFile(cls, session, sig, mode=""r""):<tab>sig = sig[: cls.HASH_LEN]<tab>while len(sig) > 0:<tab><tab>fn = cls.SaveFile(session, sig)<tab><tab>try:<tab><tab><tab>if os.path.exists(fn):<tab><tab><tab><tab>return (open(fn, mode), sig)<tab><tab>except (IOError, OSError):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>sig = sig[:-1]<tab><tab>else:<tab><tab><tab>if ""r"" in mode:<tab><tab><tab><tab>return (None, sig)<tab><tab><tab>else:<tab><tab><tab><tab>return (open(fn, mode), sig)<tab># Not reached<tab>return (None, None)",0,if len ( sig ) > 1 :,if fn . endswith ( cls . HASH_LEN ) :,0.018014535,4.789232204,0.25
"def _store_pickle_output(self, pickle_output):<tab>if pickle_output:<tab><tab>if self.output_options.output is None:<tab><tab><tab>self.error(""Can't use without --output"", ""pickle-output"")<tab><tab><IF-STMT><tab><tab><tab>self.error(<tab><tab><tab><tab>""Must specify %s file for --output"" % load_pytd.PICKLE_EXT,<tab><tab><tab><tab>""pickle-output"",<tab><tab><tab>)<tab>self.output_options.pickle_output = pickle_output",0,elif not load_pytd . is_pickle ( self . output_options . output ) :,elif not pickle_output . endswith ( load_pytd . PCKLE_EXT ) :,0.124503415,19.78069246,0.49122807
"def the_func(*args, **kwargs):<tab>try:<tab><tab># Grab API version from type of controller<tab><tab>controller = args[0]<tab><tab>version = controller.version<tab><tab>return func(*args, **kwargs)<tab>except Exception as e:<tab><tab><IF-STMT><tab><tab><tab># Version-specific behaviour<tab><tab><tab>quantum_error_class = quantum_error_dict[version]<tab><tab><tab>raise quantum_error_class(e)<tab><tab># otherwise just re-raise<tab><tab>raise",0,if errors is not None and type ( e ) in errors :,if version in quantum_error_dict :,0.145840945,4.02318593,0.132867133
"def publish_create(cls, payload):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>thread = eventlet.spawn(workflows.get_engine().process, payload)<tab><tab><tab>cls.threads.append(thread)<tab>except Exception:<tab><tab>traceback.print_exc()<tab><tab>print(payload)",0,"if isinstance ( payload , wf_ex_db . WorkflowExecutionDB ) :",if not cls . threads :,0.014786244,2.815790801,0.25
"def get_suggestion(self, buffer: ""Buffer"", document: Document) -> Optional[Suggestion]:<tab>history = buffer.history<tab># Consider only the last line for the suggestion.<tab>text = document.text.rsplit(""\n"", 1)[-1]<tab># Only create a suggestion when this is not an empty line.<tab>if text.strip():<tab><tab># Find first matching line in history.<tab><tab>for string in reversed(list(history.get_strings())):<tab><tab><tab>for line in reversed(string.splitlines()):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return Suggestion(line[len(text) :])<tab>return None",1,if line . startswith ( text ) :,if line . startswith ( text ) :,0.75,100,1
"def _get_parameter_scope(param, cmd_list):<tab>if not cmd_list:<tab><tab>return ""N/A (NOT FOUND)""<tab>test_list = cmd_list[0].split("" "")<tab>while len(test_list) > 0:<tab><tab>test_entry = "" "".join(test_list)<tab><tab>all_match = True<tab><tab>for entry in cmd_list[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_match = False<tab><tab><tab><tab>break<tab><tab>if not all_match:<tab><tab><tab>test_list.pop()<tab><tab>else:<tab><tab><tab>return test_entry<tab>return ""_ROOT_""",0,if test_entry not in entry :,if entry == test_entry :,0.030659398,27.05411345,0.333333333
"def __call__(self, params):<tab>for param in params:<tab><tab># If we've seen this parameter before, use the previously<tab><tab># constructed optimizer.<tab><tab><IF-STMT><tab><tab><tab>optim = self.optim_objs[param]<tab><tab># If we've never seen this parameter before, construct<tab><tab># an Adam optimizer and keep track of it.<tab><tab>else:<tab><tab><tab>optim = torch.optim.Adam([param], **self.optim_args)<tab><tab><tab>self.optim_objs[param] = optim<tab><tab># Take a gradient step for the parameter param.<tab><tab>optim.step()",1,if param in self . optim_objs :,if param in self . optim_objs :,0.75,100,1
"def filter_database(db, user, filter_name):<tab>""""""Returns a list of person handles""""""<tab>filt = MatchesFilter([filter_name])<tab>filt.requestprepare(db, user)<tab><IF-STMT><tab><tab>user.begin_progress(<tab><tab><tab>_(""Finding relationship paths""),<tab><tab><tab>_(""Retrieving all sub-filter matches""),<tab><tab><tab>db.get_number_of_people(),<tab><tab>)<tab>matches = []<tab>for handle in db.iter_person_handles():<tab><tab>person = db.get_person_from_handle(handle)<tab><tab>if filt.apply(db, person):<tab><tab><tab>matches.append(handle)<tab><tab>if user:<tab><tab><tab>user.step_progress()<tab>if user:<tab><tab>user.end_progress()<tab>filt.requestreset()<tab>return matches",1,if user :,if user :,0.531170663,1.00E-10,1
"def get_independence_days(self, year):<tab>""""""returns a possibly empty list of (date, holiday_name) tuples""""""<tab>days = []<tab>if year > 2004:<tab><tab>actual_date = date(year, 5, 4)<tab><tab>days = [(actual_date, ""Restoration of Independence Day"")]<tab><tab><IF-STMT><tab><tab><tab>days += [<tab><tab><tab><tab>(<tab><tab><tab><tab><tab>self.find_following_working_day(actual_date),<tab><tab><tab><tab><tab>""Restoration of Independence Observed"",<tab><tab><tab><tab>)<tab><tab><tab>]<tab>return days",0,if actual_date . weekday ( ) in self . get_weekend_days ( ) :,if self . is_working_independence ( actual_date ) :,0.026774398,12.17136169,0.38
"def on_mode_paused(result, mode, *args):<tab>from deluge.ui.console.widgets.popup import PopupsHandler<tab>if isinstance(mode, PopupsHandler):<tab><tab><IF-STMT><tab><tab><tab># If popups are not removed, they are still referenced in the memory<tab><tab><tab># which can cause issues as the popup's screen will not be destroyed.<tab><tab><tab># This can lead to the popup border being visible for short periods<tab><tab><tab># while the current modes' screen is repainted.<tab><tab><tab>log.error(<tab><tab><tab><tab>'Mode ""%s"" still has popups available after being paused.'<tab><tab><tab><tab>"" Ensure all popups are removed on pause!"",<tab><tab><tab><tab>mode.popup.title,<tab><tab><tab>)",1,if mode . popup is not None :,if mode . popup is not None :,0.75,100,1
def step(self):<tab>if not self.fully_grown:<tab><tab><IF-STMT><tab><tab><tab># Set as fully grown<tab><tab><tab>self.fully_grown = True<tab><tab><tab>self.countdown = self.model.grass_regrowth_time<tab><tab>else:<tab><tab><tab>self.countdown -= 1,0,if self . countdown <= 0 :,if self . countdown == 0 :,0.496272831,50,1
"def getOnlineBuilders(self):<tab>all_workers = yield self.master.data.get((""workers"",))<tab>online_builderids = set()<tab>for worker in all_workers:<tab><tab>connected = worker[""connected_to""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>builders = worker[""configured_on""]<tab><tab>builderids = [builder[""builderid""] for builder in builders]<tab><tab>online_builderids.update(builderids)<tab>defer.returnValue(list(online_builderids))",0,if not connected :,"if connected . startswith ( ""connected"" ) :",0.036611762,5.522397784,0.4
"def _latest_major(alternatives):<tab>max_major = -1<tab>for a in alternatives:<tab><tab><IF-STMT><tab><tab><tab>major, _, _, _ = components(a, strict=False)<tab><tab><tab>max_major = max(major, max_major)<tab>return max_major",0,"if is_version_identifier ( a , strict = False ) :",if len ( a ) > 0 :,0.029321109,6.56027164,0.285714286
"def getVar(self, name):<tab>value = self.tinfoil.run_command(""dataStoreConnectorFindVar"", self.dsindex, name)<tab>overrides = None<tab>if isinstance(value, dict):<tab><tab><IF-STMT><tab><tab><tab>value[""_content""] = self.tinfoil._reconvert_type(<tab><tab><tab><tab>value[""_content""], value[""_connector_origtype""]<tab><tab><tab>)<tab><tab><tab>del value[""_connector_origtype""]<tab><tab>if ""_connector_overrides"" in value:<tab><tab><tab>overrides = value[""_connector_overrides""]<tab><tab><tab>del value[""_connector_overrides""]<tab>return value, overrides",1,"if ""_connector_origtype"" in value :","if ""_connector_origtype"" in value :",0.75,100,1
"def initAbbrev(self):<tab>k = self<tab>c = k.c<tab>d = c.config.getAbbrevDict()<tab>if d:<tab><tab>for key in d:<tab><tab><tab>commandName = d.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass  # Must be done later in k.registerCommand.<tab><tab><tab>else:<tab><tab><tab><tab>self.initOneAbbrev(commandName, key)",0,"if commandName . startswith ( ""press-"" ) and commandName . endswith ( ""-button"" ) :",if commandName is None :,0.013264132,1.437765162,0.320833333
def restore_text(self):<tab>if self.source_is_console():<tab><tab>cb = self._last_console_cb<tab>else:<tab><tab>cb = self._last_editor_cb<tab>if cb is None:<tab><tab>if self.is_plain_text_mode():<tab><tab><tab>self.plain_text.clear()<tab><tab>else:<tab><tab><tab>self.rich_text.clear()<tab>else:<tab><tab>func = cb[0]<tab><tab>args = cb[1:]<tab><tab>func(*args)<tab><tab><IF-STMT><tab><tab><tab>self.switch_to_rich_text()<tab><tab>else:<tab><tab><tab>self.switch_to_plain_text(),0,if get_meth_class_inst ( func ) is self . rich_text :,if self . _rich_text_mode ( ) :,0.030311185,11.70899539,0.371428571
"def get_test_layer():<tab>layers = get_bb_var(""BBLAYERS"").split()<tab>testlayer = None<tab>for l in layers:<tab><tab><IF-STMT><tab><tab><tab>l = os.path.expanduser(l)<tab><tab>if ""/meta-selftest"" in l and os.path.isdir(l):<tab><tab><tab>testlayer = l<tab><tab><tab>break<tab>return testlayer",0,"if ""~"" in l :",if os . path . isfile ( l ) :,0.025806627,5.522397784,0.261904762
"def __parse_query(self, model, iter_, data):<tab>f, b = self.__filter, self.__bg_filter<tab>if f is None and b is None:<tab><tab>return True<tab>else:<tab><tab>album = model.get_album(iter_)<tab><tab>if album is None:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return f(album)<tab><tab>elif f is None:<tab><tab><tab>return b(album)<tab><tab>else:<tab><tab><tab>return b(album) and f(album)",1,elif b is None :,elif b is None :,0.75,100,1
"def iter(iterable, sentinel=None):<tab>if sentinel is None:<tab><tab>i = getattr(iterable, ""__iter__"", None)<tab><tab>if i is not None:<tab><tab><tab>return i()<tab><tab>i = getattr(iterable, ""__getitem__"", None)<tab><tab>if i is not None:<tab><tab><tab>return _iter_getitem(iterable)<tab><tab><IF-STMT><tab><tab><tab>return list(iterable).__iter__()<tab><tab>raise TypeError(""object is not iterable"")<tab>if callable(iterable):<tab><tab>return _iter_callable(iterable, sentinel)<tab>raise TypeError(""iter(v, w): v must be callable"")",0,"if JS ( ""@{{iterable}} instanceof Array"" ) :","if hasattr ( iterable , ""__iter__"" ) :",0.03492671,12.1644407,0.333333333
def run(self):<tab># Prime the coroutine.<tab>next(self.coro)<tab>try:<tab><tab>while True:<tab><tab><tab>with self.abort_lock:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return<tab><tab><tab># Get the message from the previous stage.<tab><tab><tab>msg = self.in_queue.get()<tab><tab><tab>if msg is POISON:<tab><tab><tab><tab>break<tab><tab><tab>with self.abort_lock:<tab><tab><tab><tab>if self.abort_flag:<tab><tab><tab><tab><tab>return<tab><tab><tab># Send to consumer.<tab><tab><tab>self.coro.send(msg)<tab>except:<tab><tab>self.abort_all(sys.exc_info())<tab><tab>return,1,if self . abort_flag :,if self . abort_flag :,0.75,100,1
"def get_name_from_types(types: Iterable[Union[Type, StrawberryUnion]]):<tab>names = []<tab>for type_ in types:<tab><tab><IF-STMT><tab><tab><tab>return type_.name<tab><tab>elif hasattr(type_, ""_type_definition""):<tab><tab><tab>name = capitalize_first(type_._type_definition.name)<tab><tab>else:<tab><tab><tab>name = capitalize_first(type_.__name__)<tab><tab>names.append(name)<tab>return """".join(names)",1,"if isinstance ( type_ , StrawberryUnion ) :","if isinstance ( type_ , StrawberryUnion ) :",0.75,100,1
"def _get_user_from_email(group, email):<tab>from sentry.models import User<tab># TODO(dcramer): we should encode the userid in emails so we can avoid this<tab>for user in User.objects.filter(email__iexact=email):<tab><tab># Make sure that the user actually has access to this project<tab><tab>context = access.from_user(user=user, organization=group.organization)<tab><tab><IF-STMT><tab><tab><tab>logger.warning(""User %r does not have access to group %r"", user, group)<tab><tab><tab>continue<tab><tab>return user",0,if not context . has_team ( group . project . team ) :,if not context . has_access ( user ) :,0.17169308,37.17809989,0.484375
"def _make_binary_stream(s, encoding):<tab>try:<tab><tab>if _py3k:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>else:<tab><tab><tab>if type(s) is not str:<tab><tab><tab><tab>s = s.encode(encoding)<tab><tab>from io import BytesIO<tab><tab>rv = BytesIO(s)<tab>except ImportError:<tab><tab>rv = StringIO(s)<tab>return rv",0,"if isinstance ( s , str ) :",if type ( s ) is not str :,0.036527439,12.54931062,0.34375
"def error_messages(file_list, files_removed):<tab>if files_removed is None:<tab><tab>return<tab>for remove_this, reason in files_removed:<tab><tab>if file_list is not None:<tab><tab><tab>file_list.remove(remove_this)<tab><tab>if reason == 0:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   is not PNG file format"")<tab><tab><IF-STMT><tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   already exists"")<tab><tab>elif reason == 2:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   file unreadable"")",1,elif reason == 1 :,elif reason == 1 :,1,100,1
"def _eyeAvailable(*args, **kwargs):<tab>try:<tab><tab>r = pylink.getEyeLink().eyeAvailable()<tab><tab><IF-STMT><tab><tab><tab>return EyeTrackerConstants.getName(EyeTrackerConstants.LEFT_EYE)<tab><tab>elif r == 1:<tab><tab><tab>return EyeTrackerConstants.getName(EyeTrackerConstants.RIGHT_EYE)<tab><tab>elif r == 2:<tab><tab><tab>return EyeTrackerConstants.getName(EyeTrackerConstants.BINOCULAR)<tab><tab>else:<tab><tab><tab>return EyeTrackerConstants.UNDEFINED<tab>except Exception as e:<tab><tab>printExceptionDetailsToStdErr()",1,if r == 0 :,if r == 0 :,0.75,100,1
"def ignore_callback_errors(self, ignore):<tab>EventEmitter.ignore_callback_errors.fset(self, ignore)<tab>for emitter in self._emitters.values():<tab><tab><IF-STMT><tab><tab><tab>emitter.ignore_callback_errors = ignore<tab><tab>elif isinstance(emitter, EmitterGroup):<tab><tab><tab>emitter.ignore_callback_errors_all(ignore)",0,"if isinstance ( emitter , EventEmitter ) :","if isinstance ( emitter , EmitterError ) :",0.549040681,59.46035575,0.666666667
"def test_empty_condition_node(cond_node):<tab>for node in [cond_node.true_node, cond_node.false_node]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if type(node) is CodeNode and BaseNode.test_empty_node(node.node):<tab><tab><tab>continue<tab><tab>if BaseNode.test_empty_node(node):<tab><tab><tab>continue<tab><tab>return False<tab>return True",0,if node is None :,"if not isinstance ( node , Node ) :",0.026752541,6.274655311,0.26984127
"def _confirm_deps(self, trans):<tab>if [pkgs for pkgs in trans.dependencies if pkgs]:<tab><tab>dia = AptConfirmDialog(trans, parent=self.parent)<tab><tab>res = dia.run()<tab><tab>dia.hide()<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Response is: %s"" % res)<tab><tab><tab>if self.finish_handler:<tab><tab><tab><tab>log.debug(""Finish_handler..."")<tab><tab><tab><tab>self.finish_handler(trans, 0, self.data)<tab><tab><tab>return<tab>self._run_transaction(trans)",0,if res != Gtk . ResponseType . OK :,if res :,0.024814633,1.00E-10,0.454545455
"def get_human_type(self, translate=True):<tab>""""""Returns prettified name of the object type""""""<tab>try:<tab><tab>obj_name = re.match("".*\.(?P<name>\w+)$"", self.object_type).group(""name"")<tab><tab>pattern = re.compile(""([A-Z][A-Z][a-z])|([a-z][A-Z])"")<tab><tab>human_type = pattern.sub(<tab><tab><tab>lambda m: m.group()[:1] + "" "" + m.group()[1:], obj_name<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>human_type = _(human_type)<tab><tab>return human_type<tab>except Exception:<tab><tab>return self.object_type",1,if translate :,if translate :,0.531170663,1.00E-10,1
"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",1,if n == 5 :,if n == 5 :,0.75,100,1
"def calculateModifiedAttributes(self, fit, runTime, forceProjected=False):<tab>if self.item:<tab><tab>for effect in self.item.effects.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>effect.handler(fit, self, (""module"",), None, effect=effect)",0,if effect . runTime == runTime and effect . activeByDefault :,if effect . handler :,0.099097371,10.53676785,0.333333333
"def loadHandler(self, human, values, strict):<tab>if values[0] == ""pose"":<tab><tab>poseFile = values[1]<tab><tab>poseFile = getpath.thoroughFindFile(poseFile, self.paths)<tab><tab>if not os.path.isfile(poseFile):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Could not load pose %s, file does not exist."" % poseFile<tab><tab><tab><tab>)<tab><tab><tab>log.warning(""Could not load pose %s, file does not exist."", poseFile)<tab><tab>else:<tab><tab><tab>self.loadPose(poseFile)<tab><tab>return",1,if strict :,if strict :,0.531170663,1.00E-10,1
"def get_outdated_docs(self) -> Iterator[str]:<tab>for docname in self.env.found_docs:<tab><tab><IF-STMT><tab><tab><tab>yield docname<tab><tab><tab>continue<tab><tab>targetname = path.join(self.outdir, docname + self.out_suffix)<tab><tab>try:<tab><tab><tab>targetmtime = path.getmtime(targetname)<tab><tab>except Exception:<tab><tab><tab>targetmtime = 0<tab><tab>try:<tab><tab><tab>srcmtime = path.getmtime(self.env.doc2path(docname))<tab><tab><tab>if srcmtime > targetmtime:<tab><tab><tab><tab>yield docname<tab><tab>except OSError:<tab><tab><tab># source doesn't exist anymore<tab><tab><tab>pass",0,if docname not in self . env . all_docs :,if docname . endswith ( self . out_suffix ) :,0.035704742,11.01679839,0.35
"def __init__(self, items=()):<tab>_dictEntries = []<tab>for name, value in items:<tab><tab><IF-STMT><tab><tab><tab>for item in name:<tab><tab><tab><tab>_dictEntries.append((item, value))<tab><tab>else:<tab><tab><tab>_dictEntries.append((name, value))<tab>dict.__init__(self, _dictEntries)<tab>assert len(self) == len(_dictEntries)<tab>self.default = None",0,"if isinstance ( name , ( list , tuple , frozenset , set ) ) :","if isinstance ( name , list ) :",0.127780925,22.61679221,0.607142857
"def ping_task():<tab>try:<tab><tab>if self._protocol.peer_manager.peer_is_good(peer):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._protocol.add_peer(peer)<tab><tab><tab>return<tab><tab>await self._protocol.get_rpc_peer(peer).ping()<tab>except (asyncio.TimeoutError, RemoteException):<tab><tab>pass",0,if peer not in self . _protocol . routing_table . get_peers ( ) :,if not self . _protocol . has_peer ( peer ) :,0.121685021,24.47987091,0.324561404
def get_resolved_dependencies(self):<tab>dependencies = []<tab>for dependency in self.envconfig.deps:<tab><tab>if dependency.indexserver is None:<tab><tab><tab>package = resolve_package(package_spec=dependency.name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dependency = dependency.__class__(package)<tab><tab>dependencies.append(dependency)<tab>return dependencies,0,if package != dependency . name :,if package is not None :,0.10482308,12.87263231,0.35
"def main(msg: func.QueueMessage, dashboard: func.Out[str]) -> None:<tab>body = msg.get_body()<tab>logging.info(""heartbeat: %s"", body)<tab>raw = json.loads(body)<tab>try:<tab><tab>entry = TaskHeartbeatEntry.parse_obj(raw)<tab><tab>task = Task.get_by_task_id(entry.task_id)<tab><tab><IF-STMT><tab><tab><tab>logging.error(task)<tab><tab><tab>return<tab><tab>if task:<tab><tab><tab>task.heartbeat = datetime.utcnow()<tab><tab><tab>task.save()<tab>except ValidationError:<tab><tab>logging.error(""invalid task heartbeat: %s"", raw)<tab>events = get_events()<tab>if events:<tab><tab>dashboard.set(events)",0,"if isinstance ( task , Error ) :",if task :,0.01726708,1.00E-10,0.36
"def testTlsServerServeForeverTwice(self):<tab>""""""Call on serve_forever() twice should result in a runtime error""""""<tab>with patch.object(ssl.SSLContext, ""load_cert_chain"") as mock_method:<tab><tab>server = yield from StartTlsServer(<tab><tab><tab>context=self.context, address=(""127.0.0.1"", 0), loop=self.loop<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>server_task = asyncio.create_task(server.serve_forever())<tab><tab>else:<tab><tab><tab>server_task = asyncio.ensure_future(server.serve_forever())<tab><tab>yield from server.serving<tab><tab>with self.assertRaises(RuntimeError):<tab><tab><tab>yield from server.serve_forever()<tab><tab>server.server_close()",0,"if PYTHON_VERSION >= ( 3 , 7 ) :","if mock_method == ""create"" :",0.015736078,4.858514172,0.464285714
"def getInstances_WithSource(self, instancesAmount, sourceObject, scenes):<tab>if sourceObject is None:<tab><tab>self.removeAllObjects()<tab><tab>return []<tab>else:<tab><tab>sourceHash = hash(sourceObject)<tab><tab>if self.identifier in lastSourceHashes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.removeAllObjects()<tab><tab>lastSourceHashes[self.identifier] = sourceHash<tab>return self.getInstances_Base(instancesAmount, sourceObject, scenes)",0,if lastSourceHashes [ self . identifier ] != sourceHash :,if sourceHash != lastSourceHashes [ self . identifier ] :,0.393697455,56.23413252,0.333333333
"def get_row(self, binary=False, columns=None, raw=None, prep_stmt=None):<tab>""""""Get the next rows returned by the MySQL server""""""<tab>try:<tab><tab>rows, eof = self.get_rows(<tab><tab><tab>count=1, binary=binary, columns=columns, raw=raw, prep_stmt=prep_stmt<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return (rows[0], eof)<tab><tab>return (None, eof)<tab>except IndexError:<tab><tab># No row available<tab><tab>return (None, None)",0,if rows :,if len ( rows ) == 1 :,0.0465226,1.00E-10,0.36
"def try_adjust_widgets(self):<tab>if hasattr(self.parent, ""adjust_widgets""):<tab><tab>self.parent.adjust_widgets()<tab>if hasattr(self.parent, ""parentApp""):<tab><tab>if hasattr(self.parent.parentApp, ""_internal_adjust_widgets""):<tab><tab><tab>self.parent.parentApp._internal_adjust_widgets()<tab><tab><IF-STMT><tab><tab><tab>self.parent.parentApp.adjust_widgets()",0,"if hasattr ( self . parent . parentApp , ""adjust_widgets"" ) :","elif hasattr ( self . parent . parentApp , ""adjust_widgets"" ) :",0.436124605,93.06048591,0.714285714
"def parseStatementList():<tab>list__py__ = []<tab>statement = None<tab>while index < length:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>statement = parseSourceElement()<tab><tab>if (<tab><tab><tab>""undefined"" if not ""statement"" in locals() else typeof(statement)<tab><tab>) == ""undefined"":<tab><tab><tab>break<tab><tab>list__py__.append(statement)<tab>return list__py__",0,"if match ( ""}"" ) :",if index == length - 1 :,0.023878899,6.567274736,0.291666667
"def forward(self, Z):<tab>losses = []<tab>context = self.context_cnn(Z)<tab>targets = self.target_cnn(Z)<tab>_, _, h, w = Z.shape<tab># future prediction<tab>preds = self.pred_cnn(context)<tab>for steps_to_ignore in range(h - 1):<tab><tab>for i in range(steps_to_ignore + 1, h):<tab><tab><tab>loss = self.compute_loss_h(targets, preds, i)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>losses.append(loss)<tab>loss = torch.stack(losses).sum()<tab>return loss",0,if not torch . isnan ( loss ) :,if loss is not None :,0.017951424,6.962210313,0.25
"def __run(self, command):<tab>sys.stdout, self.stdout = self.stdout, sys.stdout<tab>sys.stderr, self.stderr = self.stderr, sys.stderr<tab>try:<tab><tab>try:<tab><tab><tab>r = eval(command, self.namespace, self.namespace)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_(repr(r))<tab><tab>except SyntaxError:<tab><tab><tab>exec(command, self.namespace)<tab>except:<tab><tab>if hasattr(sys, ""last_type"") and sys.last_type == SystemExit:<tab><tab><tab>self.destroy()<tab><tab>else:<tab><tab><tab>traceback.print_exc()<tab>sys.stdout, self.stdout = self.stdout, sys.stdout<tab>sys.stderr, self.stderr = self.stderr, sys.stderr",1,if r is not None :,if r is not None :,0.75,100,1
"def prune(self):<tab>file = self.file<tab>if self.remain == 0:<tab><tab>read_pos = file.tell()<tab><tab>file.seek(0, 2)<tab><tab>sz = file.tell()<tab><tab>file.seek(read_pos)<tab><tab>if sz == 0:<tab><tab><tab># Nothing to prune.<tab><tab><tab>return<tab>nf = self.newfile()<tab>while True:<tab><tab>data = file.read(COPY_BYTES)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>nf.write(data)<tab>self.file = nf",1,if not data :,if not data :,0.75,100,1
"def reduce_inode(self, f, init):<tab>for x in range(0, len(self._array), 2):<tab><tab>key_or_none = self._array[x]<tab><tab>val_or_node = self._array[x + 1]<tab><tab><IF-STMT><tab><tab><tab>init = val_or_node.reduce_inode(f, init)<tab><tab>else:<tab><tab><tab>init = f.invoke([init, rt.map_entry(key_or_none, val_or_node)])<tab><tab>if rt.reduced_QMARK_(init):<tab><tab><tab>return init<tab>return init",0,if key_or_none is None and val_or_node is not None :,"if hasattr ( val_or_node , ""reduce_entry"" ) :",0.015007329,22.72311359,0.220779221
"def gen_topython_helper(cw):<tab>cw.enter_block(<tab><tab>""private static BaseException/*!*/ ToPythonHelper(System.Exception clrException)""<tab>)<tab>allExceps = get_all_exceps([], exceptionHierarchy)<tab>allExceps.sort(cmp=compare_exceptions)<tab>for x in allExceps:<tab><tab><IF-STMT><tab><tab><tab>cw.writeline(""#if !SILVERLIGHT"")<tab><tab>cw.writeline(<tab><tab><tab>""if (clrException is %s) return %s;""<tab><tab><tab>% (x.ExceptionMappingName, x.MakeNewException())<tab><tab>)<tab><tab>if not x.silverlightSupported:<tab><tab><tab>cw.writeline(""#endif"")<tab>cw.writeline(""return new BaseException(Exception);"")<tab>cw.exit_block()",0,if not x . silverlightSupported :,if not x .silverlightSupported :,0.365297827,100,0.76
"def file_versions(self, path):<tab>""""""Returns all commits where given file was modified""""""<tab>versions = []<tab>commits_info = self.commit_info()<tab>seen_shas = set()<tab>for commit in commits_info:<tab><tab>try:<tab><tab><tab>files = self.get_commit_files(commit[""sha""], paths=[path])<tab><tab><tab>file_path, file_data = files.items()[0]<tab><tab>except IndexError:<tab><tab><tab>continue<tab><tab>file_sha = file_data[""sha""]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>seen_shas.add(file_sha)<tab><tab># Add file info<tab><tab>commit[""file""] = file_data<tab><tab>versions.append(file_data)<tab>return versions",1,if file_sha in seen_shas :,if file_sha in seen_shas :,0.75,100,1
"def _append_fragment(self, ctx, frag_content):<tab>try:<tab><tab>ctx[""dest_stream""].write(frag_content)<tab><tab>ctx[""dest_stream""].flush()<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>self._write_ytdl_file(ctx)<tab><tab>if not self.params.get(""keep_fragments"", False):<tab><tab><tab>os.remove(encodeFilename(ctx[""fragment_filename_sanitized""]))<tab><tab>del ctx[""fragment_filename_sanitized""]",0,if self . __do_ytdl_file ( ctx ) :,"if self . params . get ( ""keep_ytdl"" , False ) :",0.074174296,13.83436846,0.410714286
"def gen_segs(glyph):<tab>bzs = glyph_to_bzs(glyph)<tab>for sp in bzs:<tab><tab>bks = segment_sp(sp)<tab><tab>for i in range(len(bks)):<tab><tab><tab>bk0, bk1 = bks[i], bks[(i + 1) % len(bks)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>segstr = seg_to_string(sp, bk0, bk1)<tab><tab><tab><tab>fn = seg_fn(segstr)<tab><tab><tab><tab>file(fn, ""w"").write(segstr)",0,if bk1 != ( bk0 + 1 ) % len ( sp ) or len ( sp [ bk0 ] ) != 2 :,if bk0 != bk1 :,0.003746331,0.762151691,0.196078431
"def matches(self, filepath):<tab>matched = False<tab>parent_path = os.path.dirname(filepath)<tab>parent_path_dirs = split_path(parent_path)<tab>for pattern in self.patterns:<tab><tab>negative = pattern.exclusion<tab><tab>match = pattern.match(filepath)<tab><tab>if not match and parent_path != """":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>match = pattern.match(<tab><tab><tab><tab><tab>os.path.sep.join(parent_path_dirs[: len(pattern.dirs)])<tab><tab><tab><tab>)<tab><tab>if match:<tab><tab><tab>matched = not negative<tab>return matched",0,if len ( pattern . dirs ) <= len ( parent_path_dirs ) :,if not negative :,0.008202464,0.573626238,0.26984127
"def __repr__(self):<tab>text = ""{}("".format(self.__class__.__name__)<tab>n = len(self)<tab>for i in range(n):<tab><tab><IF-STMT><tab><tab><tab>if i > 0:<tab><tab><tab><tab>text = text + "", ""<tab><tab><tab>text = text + ""{}={}"".format(fields[i], str(self[i]))<tab>text = text + "")""<tab>return text",0,if self [ i ] != None :,if fields [ i ] is not None :,0.147986894,23.35689889,0.34375
"def difference_matrix(samples, debug=True):<tab>""""""Calculate the difference matrix for the given set of samples.""""""<tab>diff_matrix = {}<tab>for x in samples:<tab><tab>if debug:<tab><tab><tab>print(""Calculating difference matrix for %s"" % x)<tab><tab><IF-STMT><tab><tab><tab>diff_matrix[x] = {}<tab><tab>for y in samples:<tab><tab><tab>if samples[x] != samples[y]:<tab><tab><tab><tab>d = difference(samples[x], samples[y])<tab><tab><tab><tab># print(""Difference between %s and %s: %d"" % (x, y, d))<tab><tab><tab><tab>diff_matrix[x][y] = d<tab><tab><tab>else:<tab><tab><tab><tab>diff_matrix[x][y] = 0<tab>return diff_matrix",1,if x not in diff_matrix :,if x not in diff_matrix :,0.75,100,1
"def load_config(self):<tab>try:<tab><tab>with open(CONFIG_PATH) as f:<tab><tab><tab>y = yaml.safe_load(f)<tab><tab>for key, value in y.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(self, key.upper(), value)<tab>except IOError:<tab><tab>logger.warning(<tab><tab><tab>f""No config file found at {CONFIG_PATH}, using defaults.\n""<tab><tab><tab>f""Set the CONFIG_PATH environment variable to point to a config file to override.""<tab><tab>)",0,"if hasattr ( self , key . upper ( ) ) and not os . getenv ( key . upper ( ) ) :","if hasattr ( self , key . upper ( ) ) :",0.346672479,36.78794412,0.514583333
"def checkout_branch(self, branch):<tab>if branch in self.remote_branches:<tab><tab>sickrage.app.log.debug(<tab><tab><tab>""Branch checkout: "" + self._find_installed_version() + ""->"" + branch<tab><tab>)<tab><tab>if not self.install_requirements(self.current_branch):<tab><tab><tab>return False<tab><tab># remove untracked files and performs a hard reset on git branch to avoid update issues<tab><tab><IF-STMT><tab><tab><tab>self.reset()<tab><tab># fetch all branches<tab><tab>self.fetch()<tab><tab>__, __, exit_status = self._git_cmd(self._git_path, ""checkout -f "" + branch)<tab><tab>if exit_status == 0:<tab><tab><tab>return True<tab>return False",0,if sickrage . app . config . git_reset :,"if self . current_branch == ""untracked"" :",0.017062029,4.789232204,0.305555556
"def upload(<tab>youtube_resource, video_path, body, chunksize=1024 * 1024, progress_callback=None):<tab>body_keys = "","".join(body.keys())<tab>media = MediaFileUpload(video_path, chunksize=chunksize, resumable=True)<tab>videos = youtube_resource.videos()<tab>request = videos.insert(part=body_keys, body=body, media_body=media)<tab>while 1:<tab><tab>status, response = request.next_chunk()<tab><tab>if response:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return response[""id""]<tab><tab><tab>else:<tab><tab><tab><tab>raise KeyError(""Response has no 'id' field"")<tab><tab>elif status and progress_callback:<tab><tab><tab>progress_callback(status.total_size, status.resumable_progress)",1,"if ""id"" in response :","if ""id"" in response :",0.75,100,1
def execute(self):<tab>with self._guard_sigpipe():<tab><tab>try:<tab><tab><tab>targets = (<tab><tab><tab><tab>self.get_targets()<tab><tab><tab><tab>if self.act_transitively<tab><tab><tab><tab>else self.context.target_roots<tab><tab><tab>)<tab><tab><tab>for value in self.console_output(targets) or tuple():<tab><tab><tab><tab>self._outstream.write(value.encode())<tab><tab><tab><tab>self._outstream.write(self._console_separator.encode())<tab><tab>finally:<tab><tab><tab>self._outstream.flush()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._outstream.close(),0,if self . get_options ( ) . output_file :,if self . _outstream is not None :,0.067176973,12.92936764,0.454545455
"def declare_var(<tab>self,<tab>type_name: Union[str, Tuple[str, str]],<tab>*,<tab>var_name: str = """",<tab>var_name_prefix: str = ""v"",<tab>shared: bool = False,) -> str:<tab>if shared:<tab><tab>if not var_name:<tab><tab><tab>var_name = var_name_prefix<tab><tab><IF-STMT><tab><tab><tab>self.declarations.append((var_name, type_name))<tab><tab><tab>self.shared_vars.add(var_name)<tab>else:<tab><tab>if not var_name:<tab><tab><tab>var_name = self.get_var_name(var_name_prefix)<tab><tab>self.declarations.append((var_name, type_name))<tab>return var_name",1,if var_name not in self . shared_vars :,if var_name not in self . shared_vars :,0.75,100,1
"def parse_counter_style_name(tokens, counter_style):<tab>tokens = remove_whitespace(tokens)<tab>if len(tokens) == 1:<tab><tab>(token,) = tokens<tab><tab>if token.type == ""ident"":<tab><tab><tab>if token.lower_value in (""decimal"", ""disc""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return token.value<tab><tab><tab>elif token.lower_value != ""none"":<tab><tab><tab><tab>return token.value",0,if token . lower_value not in counter_style :,"if counter_style in ( ""decimal"" , ""disc"" ) :",0.019030986,11.63327084,0.366666667
"def __init__(self, appName=""""):<tab>dlgappcore.AppDialog.__init__(self, win32ui.IDD_GENERAL_STATUS)<tab>self.timerAppName = appName<tab>self.argOff = 0<tab>if len(self.timerAppName) == 0:<tab><tab><IF-STMT><tab><tab><tab>self.timerAppName = sys.argv[1]<tab><tab><tab>self.argOff = 1",0,"if len ( sys . argv ) > 1 and sys . argv [ 1 ] [ 0 ] != ""/"" :",if sys . argv [ 1 ] :,0.113273014,8.731869066,0.225
"def tearDownClass(cls):<tab>for conn in settings.HAYSTACK_CONNECTIONS.values():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""STORAGE"" in conn and conn[""STORAGE""] != ""file"":<tab><tab><tab>continue<tab><tab># Start clean<tab><tab>if os.path.exists(conn[""PATH""]):<tab><tab><tab>shutil.rmtree(conn[""PATH""])<tab>super(WhooshTestCase, cls).tearDownClass()",0,"if conn [ ""ENGINE"" ] != ""haystack.backends.whoosh_backend.WhooshEngine"" :","if not isinstance ( conn , dict ) :",0.018096169,1.653981183,0.287878788
"def forward(self, x):<tab>if self.ffn_type in (1, 2):<tab><tab>x0 = self.wx0(x)<tab><tab>if self.ffn_type == 1:<tab><tab><tab>x1 = x<tab><tab><IF-STMT><tab><tab><tab>x1 = self.wx1(x)<tab><tab>out = self.output(x0 * x1)<tab>out = self.dropout(out)<tab>out = self.LayerNorm(out + x)<tab>return out",1,elif self . ffn_type == 2 :,elif self . ffn_type == 2 :,1,100,1
"def __call__(self, data, **params):<tab>p = param.ParamOverrides(self, params)<tab>if isinstance(data, (HoloMap, NdOverlay)):<tab><tab>ranges = {d.name: data.range(d) for d in data.dimensions()}<tab><tab>data = data.clone(<tab><tab><tab>{k: GridMatrix(self._process(p, v, ranges)) for k, v in data.items()}<tab><tab>)<tab><tab>data = Collator(data, merge_type=type(data))()<tab><tab><IF-STMT><tab><tab><tab>data = data.map(lambda x: x.overlay(p.overlay_dims), (HoloMap,))<tab><tab>return data<tab>elif isinstance(data, Element):<tab><tab>data = self._process(p, data)<tab><tab>return GridMatrix(data)",1,if p . overlay_dims :,if p . overlay_dims :,0.75,100,1
"def _update_model(self, events, msg, root, model, doc, comm=None):<tab>msg = dict(msg)<tab>if self._rename[""objects""] in msg:<tab><tab>old = events[""objects""].old<tab><tab>msg[self._rename[""objects""]] = self._get_objects(model, old, doc, root, comm)<tab>with hold(doc):<tab><tab>super(Panel, self)._update_model(events, msg, root, model, doc, comm)<tab><tab>from ..io import state<tab><tab>ref = root.ref[""id""]<tab><tab><IF-STMT><tab><tab><tab>state._views[ref][0]._preprocess(root)",1,if ref in state . _views :,if ref in state . _views :,0.75,100,1
"def reset_two_factor_hotp():<tab>otp_secret = request.form.get(""otp_secret"", None)<tab>if otp_secret:<tab><tab><IF-STMT><tab><tab><tab>return render_template(""account_edit_hotp_secret.html"")<tab><tab>g.user.set_hotp_secret(otp_secret)<tab><tab>db.session.commit()<tab><tab>return redirect(url_for(""account.new_two_factor""))<tab>else:<tab><tab>return render_template(""account_edit_hotp_secret.html"")",0,"if not validate_hotp_secret ( g . user , otp_secret ) :",if not g . user . has_hotp_secret ( otp_secret ) :,0.092466808,53.32900051,1
"def ETA(self):<tab>if self.done:<tab><tab>prefix = ""Done""<tab><tab>t = self.elapsed<tab><tab># import pdb; pdb.set_trace()<tab>else:<tab><tab>prefix = ""ETA ""<tab><tab><IF-STMT><tab><tab><tab>t = -1<tab><tab>elif self.elapsed == 0 or (self.cur == self.min):<tab><tab><tab>t = 0<tab><tab>else:<tab><tab><tab># import pdb; pdb.set_trace()<tab><tab><tab>t = float(self.max - self.min)<tab><tab><tab>t /= self.cur - self.min<tab><tab><tab>t = (t - 1) * self.elapsed<tab>return ""%s: %s"" % (prefix, self.format_duration(t))",0,if self . max is None :,if self . elapsed > 0 or ( self . cur == self . max ) :,0.084508423,11.95472658,0.23
"def add_property(self, key, value):  # type: (str, Any) -> None<tab>with self.secure() as config:<tab><tab>keys = key.split(""."")<tab><tab>for i, key in enumerate(keys):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config[key] = table()<tab><tab><tab>if i == len(keys) - 1:<tab><tab><tab><tab>config[key] = value<tab><tab><tab><tab>break<tab><tab><tab>config = config[key]",0,if key not in config and i < len ( keys ) - 1 :,if key not in config :,0.238305393,17.74488851,0.515151515
"def validate_against_domain(<tab>cls, ensemble: Optional[""PolicyEnsemble""], domain: Optional[Domain]) -> None:<tab>if ensemble is None:<tab><tab>return<tab>for p in ensemble.policies:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if domain is None or p.deny_suggestion_intent_name not in domain.intents:<tab><tab><tab>raise InvalidDomain(<tab><tab><tab><tab>""The intent '{0}' must be present in the ""<tab><tab><tab><tab>""domain file to use TwoStageFallbackPolicy. ""<tab><tab><tab><tab>""Either include the intent '{0}' in your domain ""<tab><tab><tab><tab>""or exclude the TwoStageFallbackPolicy from your ""<tab><tab><tab><tab>""policy configuration"".format(p.deny_suggestion_intent_name)<tab><tab><tab>)",0,"if not isinstance ( p , TwoStageFallbackPolicy ) :",if p . deny_suggestion_name is None :,0.017062029,4.932351569,0.236111111
"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = []<tab>kwspaces = self.kwspaces<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for idx, obj in enumerate(self.data):<tab><tab><IF-STMT><tab><tab><tab>sub_config = _strip_config_space(config, prefix=str(idx))<tab><tab><tab>ret.append(obj.sample(**sub_config))<tab><tab>elif isinstance(obj, SimpleSpace):<tab><tab><tab>ret.append(config[str(idx)])<tab><tab>else:<tab><tab><tab>ret.append(obj)<tab>return ret",0,"if isinstance ( obj , NestedSpace ) :","if isinstance ( obj , NestedSpace ) and str ( idx ) in stripped_keys :",0.445796466,36.00565854,0.530864198
"def init_weights(self):<tab>for module in self.decoder.modules():<tab><tab><IF-STMT><tab><tab><tab>module.weight.data.normal_(mean=0.0, std=0.02)<tab><tab>elif isinstance(module, nn.LayerNorm):<tab><tab><tab>module.bias.data.zero_()<tab><tab><tab>module.weight.data.fill_(1.0)<tab><tab>if isinstance(module, nn.Linear) and module.bias is not None:<tab><tab><tab>module.bias.data.zero_()<tab>for p in self.generator.parameters():<tab><tab>if p.dim() > 1:<tab><tab><tab>xavier_uniform_(p)<tab><tab>else:<tab><tab><tab>p.data.zero_()",0,"if isinstance ( module , ( nn . Linear , nn . Embedding ) ) :","if isinstance ( module , nn . Linear ) :",0.18121408,34.64082077,0.795238095
"def backfill_first_message_id(<tab>apps: StateApps, schema_editor: DatabaseSchemaEditor) -> None:<tab>Stream = apps.get_model(""zerver"", ""Stream"")<tab>Message = apps.get_model(""zerver"", ""Message"")<tab>for stream in Stream.objects.all():<tab><tab>first_message = Message.objects.filter(<tab><tab><tab>recipient__type_id=stream.id, recipient__type=2<tab><tab>).first()<tab><tab><IF-STMT><tab><tab><tab># No need to change anything if the outcome is the default of None<tab><tab><tab>continue<tab><tab>stream.first_message_id = first_message.id<tab><tab>stream.save()",1,if first_message is None :,if first_message is None :,0.75,100,1
"def commandComplete(self, cmd):<tab>if self.property:<tab><tab>if cmd.didFail():<tab><tab><tab>return<tab><tab>result = self.observer.getStdout()<tab><tab><IF-STMT><tab><tab><tab>result = result.strip()<tab><tab>propname = self.property<tab><tab>self.setProperty(propname, result, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes[propname] = result<tab>else:<tab><tab>new_props = self.extract_fn(<tab><tab><tab>cmd.rc, self.observer.getStdout(), self.observer.getStderr()<tab><tab>)<tab><tab>for k, v in iteritems(new_props):<tab><tab><tab>self.setProperty(k, v, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes = new_props",0,if self . strip :,if result :,0.03549272,1.00E-10,0.36
"def part(p, imaginary):<tab># Represent infinity as 1e1000 and NaN as 1e1000-1e1000.<tab>s = ""j"" if imaginary else """"<tab>try:<tab><tab>if math.isinf(p):<tab><tab><tab>if p < 0:<tab><tab><tab><tab>return ""-1e1000"" + s<tab><tab><tab>return ""1e1000"" + s<tab><tab><IF-STMT><tab><tab><tab>return ""(1e1000%s-1e1000%s)"" % (s, s)<tab>except OverflowError:<tab><tab># math.isinf will raise this when given an integer<tab><tab># that's too large to convert to a float.<tab><tab>pass<tab>return repr(p) + s",0,if math . isnan ( p ) :,elif math . isinf ( p ) :,0.195658694,41.11336169,0.428571429
"def _user_has_perm(user, perm, obj):<tab>anon = user.is_anonymous()<tab>for backend in auth.get_backends():<tab><tab>if not anon or backend.supports_anonymous_user:<tab><tab><tab>if hasattr(backend, ""has_perm""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if backend.supports_object_permissions and backend.has_perm(<tab><tab><tab><tab><tab><tab>user, perm, obj<tab><tab><tab><tab><tab>):<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if backend.has_perm(user, perm):<tab><tab><tab><tab><tab><tab>return True<tab>return False",1,if obj is not None :,if obj is not None :,0.75,100,1
"def check_backslashes(payload):<tab># Check for single quotes<tab>if payload.count(""\\"") >= 15:<tab><tab><IF-STMT><tab><tab><tab>if menu.options.tamper:<tab><tab><tab><tab>menu.options.tamper = menu.options.tamper + "",backslashes""<tab><tab><tab>else:<tab><tab><tab><tab>menu.options.tamper = ""backslashes""<tab><tab>from src.core.tamper import backslashes<tab><tab>payload = backslashes.tamper(payload)",0,"if not settings . TAMPER_SCRIPTS [ ""backslashes"" ] :",if menu . options . tamper :,0.017062029,3.66786283,0.272727273
"def _check_model(cls):<tab>errors = []<tab>if cls._meta.proxy:<tab><tab><IF-STMT><tab><tab><tab>errors.append(<tab><tab><tab><tab>checks.Error(<tab><tab><tab><tab><tab>""Proxy model '%s' contains model fields."" % cls.__name__,<tab><tab><tab><tab><tab>id=""models.E017"",<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return errors",0,if cls . _meta . local_fields or cls . _meta . local_many_to_many :,"if not isinstance ( cls . _meta . proxy , models . E017 ) :",0.216636868,16.62458504,0.278752437
"def _format_column_list(self, data):<tab># Now we have all lis of columns which we need<tab># to include in our create definition, Let's format them<tab>if ""columns"" in data:<tab><tab>for c in data[""columns""]:<tab><tab><tab>if ""attacl"" in c:<tab><tab><tab><tab>c[""attacl""] = parse_priv_to_db(c[""attacl""], self.column_acl)<tab><tab><tab># check type for '[]' in it<tab><tab><tab><IF-STMT><tab><tab><tab><tab>c[""cltype""], c[""hasSqrBracket""] = column_utils.type_formatter(<tab><tab><tab><tab><tab>c[""cltype""]<tab><tab><tab><tab>)",1,"if ""cltype"" in c :","if ""cltype"" in c :",0.75,100,1
"def _extract_constant_functions(slither: SlitherCore) -> Dict[str, List[str]]:<tab>ret: Dict[str, List[str]] = {}<tab>for contract in slither.contracts:<tab><tab>cst_functions = [<tab><tab><tab>_get_name(f) for f in contract.functions_entry_points if _is_constant(f)<tab><tab>]<tab><tab>cst_functions += [<tab><tab><tab>v.function_name<tab><tab><tab>for v in contract.state_variables<tab><tab><tab>if v.visibility in [""public""]<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>ret[contract.name] = cst_functions<tab>return ret",1,if cst_functions :,if cst_functions :,0.531170663,1.00E-10,1
"def safe_zip(*args):<tab>""""""Like zip, but ensures arguments are of same length""""""<tab>base = len(args[0])<tab>for i, arg in enumerate(args[1:]):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Argument 0 has length %d but argument %d has ""<tab><tab><tab><tab>""length %d"" % (base, i + 1, len(arg))<tab><tab><tab>)<tab>return zip(*args)",0,if len ( arg ) != base :,if len ( arg ) != len ( arg ) :,0.398814162,53.31675363,0.651282051
"def readMemory(self, va, size):<tab>ret = b""""<tab>while size:<tab><tab>pageva = va & self.pagemask<tab><tab>pageoff = va - pageva<tab><tab>chunksize = min(self.pagesize - pageoff, size)<tab><tab>page = self.pagecache.get(pageva)<tab><tab><IF-STMT><tab><tab><tab>page = self.mem.readMemory(pageva, self.pagesize)<tab><tab><tab>self.pagecache[pageva] = page<tab><tab>ret += page[pageoff : pageoff + chunksize]<tab><tab>va += chunksize<tab><tab>size -= chunksize<tab>return ret",0,if page is None :,if not page :,0.039449619,16.37226967,0.277777778
"def horizontal_neighbors_iter(self, ordered=True):<tab>n_horizontal_edges_per_y = self.x_dimension - (<tab><tab>self.x_dimension <= 2 or not self.periodic<tab>)<tab>for x in range(n_horizontal_edges_per_y):<tab><tab>for y in range(self.y_dimension):<tab><tab><tab>i = self.to_site_index((x, y))<tab><tab><tab>j = self.to_site_index(((x + 1) % self.x_dimension, y))<tab><tab><tab>yield (i, j)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (j, i)",1,if ordered :,if ordered :,0.531170663,1.00E-10,1
"def apply_ordering(self, query):<tab>ordering = request.args.get(""ordering"") or """"<tab>if ordering:<tab><tab>desc, column = ordering.startswith(""-""), ordering.lstrip(""-"")<tab><tab><IF-STMT><tab><tab><tab>field = self.model._meta.fields[column]<tab><tab><tab>query = query.order_by(field.asc() if not desc else field.desc())<tab>return query",1,if column in self . model . _meta . fields :,if column in self . model . _meta . fields :,0.75,100,1
"def check_hashes(self, string):<tab>for hash in self.hashes.copy():<tab><tab>ctext, hash = self.check_hash(hash, string)<tab><tab><IF-STMT><tab><tab><tab>yield ctext, hash<tab><tab><tab>self.found.add(hash)<tab><tab><tab>self.hashes.remove(hash)",1,if ctext is not None :,if ctext is not None :,0.75,100,1
"def undo_block_stop(self):<tab>if self.undoblock.bump_depth(-1) == 0:<tab><tab>cmd = self.undoblock<tab><tab>self.undoblock = 0<tab><tab>if len(cmd) > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># no need to wrap a single cmd<tab><tab><tab><tab>cmd = cmd.getcmd(0)<tab><tab><tab># this blk of cmds, or single cmd, has already<tab><tab><tab># been done, so don't execute it again<tab><tab><tab>self.addcmd(cmd, 0)",0,if len ( cmd ) == 1 :,"if isinstance ( cmd [ 0 ] , Command ) :",0.031857826,9.425159511,0.365384615
"def create_model_handler(ns, model_type):<tab>@route(f""/<provider>/{ns}/<model_id>"")<tab>@use_provider<tab>def handle(req, provider, model_id):<tab><tab># special cases:<tab><tab># fuo://<provider>/users/me -> show current logged user<tab><tab>if model_type == ModelType.user:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>user = getattr(provider, ""_user"", None)<tab><tab><tab><tab>if user is None:<tab><tab><tab><tab><tab>raise CmdException(f""log in provider:{provider.identifier} first"")<tab><tab><tab><tab>return user<tab><tab>model = get_model_or_raise(provider, model_type, model_id)<tab><tab>return model",1,"if model_id == ""me"" :","if model_id == ""me"" :",0.75,100,1
"def _remove_optional_none_type_hints(self, type_hints, defaults):<tab># If argument has None as a default, typing.get_type_hints adds<tab># optional None to the information it returns. We don't want that.<tab>for arg in defaults:<tab><tab>if defaults[arg] is None and arg in type_hints:<tab><tab><tab>type_ = type_hints[arg]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>types = type_.__args__<tab><tab><tab><tab>if len(types) == 2 and types[1] is type(None):<tab><tab><tab><tab><tab>type_hints[arg] = types[0]",0,if self . _is_union ( type_ ) :,if type_ is not type ( None ) :,0.035268169,12.36846477,0.246753247
"def set_billing_hours_and_amount(self):<tab>if not self.project:<tab><tab>for timesheet in self.timesheets:<tab><tab><tab>ts_doc = frappe.get_doc(""Timesheet"", timesheet.time_sheet)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>timesheet.billing_hours = ts_doc.total_billable_hours<tab><tab><tab>if not timesheet.billing_amount and ts_doc.total_billable_amount:<tab><tab><tab><tab>timesheet.billing_amount = ts_doc.total_billable_amount",1,if not timesheet . billing_hours and ts_doc . total_billable_hours :,if not timesheet . billing_hours and ts_doc . total_billable_hours :,0.75,100,1
"def _real_len(self, s):<tab>s_len = 0<tab>in_esc = False<tab>prev = "" ""<tab>for c in replace_all({""\0+"": """", ""\0-"": """", ""\0^"": """", ""\1"": """", ""\t"": "" ""}, s):<tab><tab>if in_esc:<tab><tab><tab>if c == ""m"":<tab><tab><tab><tab>in_esc = False<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>in_esc = True<tab><tab><tab><tab>s_len -= 1  # we counted prev when we shouldn't have<tab><tab><tab>else:<tab><tab><tab><tab>s_len += self._display_len(c)<tab><tab>prev = c<tab>return s_len",0,"if c == ""["" and prev == ""\033"" :",if c == prev :,0.069559259,10.62125568,0.581818182
"def _find_node_with_predicate(self, node, predicate):<tab>if node != self._tree._root and predicate(node):<tab><tab>return node<tab>item, cookie = self._tree.GetFirstChild(node)<tab>while item:<tab><tab>if predicate(item):<tab><tab><tab>return item<tab><tab>if self._tree.ItemHasChildren(item):<tab><tab><tab>result = self._find_node_with_predicate(item, predicate)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return result<tab><tab>item, cookie = self._tree.GetNextChild(node, cookie)<tab>return None",1,if result :,if result :,0.531170663,1.00E-10,1
"def main():<tab>parser = optparse.OptionParser()<tab>options, argv = parser.parse_args()<tab>counts = defaultdict(int)<tab>for line in fileinput.input(argv):<tab><tab>try:<tab><tab><tab>tweet = json.loads(line)<tab><tab>except:<tab><tab><tab>continue<tab><tab>if ""retweeted_status"" not in tweet:<tab><tab><tab>continue<tab><tab>rt = tweet[""retweeted_status""]<tab><tab>id = rt[""id_str""]<tab><tab>count = rt[""retweet_count""]<tab><tab><IF-STMT><tab><tab><tab>counts[id] = count<tab>for id in sorted(counts, key=counts.get, reverse=True):<tab><tab>print(""{},{}"".format(id, counts[id]))",0,if count > counts [ id ] :,if id not in counts :,0.020894909,8.224879649,0.265306122
"def to_get_select_object_meta(meta_param):<tab>if meta_param is not None and SelectParameters.Json_Type in meta_param:<tab><tab><IF-STMT><tab><tab><tab>raise SelectOperationClientError(<tab><tab><tab><tab>""Json_Type can only be 'LINES' for creating meta"", """"<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return to_get_select_json_object_meta(meta_param)<tab>else:<tab><tab>return to_get_select_csv_object_meta(meta_param)",0,if meta_param [ SelectParameters . Json_Type ] != SelectJsonTypes . LINES :,if SelectParameters . Json_Type in meta_param :,0.100294109,28.75683693,0.490196078
"def check_if_match(self, value, index, flags=0):<tab>pattern = self.get_pattern(index)<tab>if value:<tab><tab>if _is_iterable(value):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>if isinstance(value, (int, long)):<tab><tab><tab><tab>value = str(value)<tab><tab><tab>return bool(re.search(pattern, value, flags))<tab>return False",0,"if any ( [ bool ( re . search ( pattern , x , flags ) ) for x in value ] ) :",if pattern . search ( value ) :,0.020838268,3.934404674,0.145833333
"def assemble(<tab>self, multi_model_placement: Dict[Model, PhysicalDevice]) -> Tuple[Node, PhysicalDevice]:<tab>for node in self.origin_nodes:<tab><tab><IF-STMT><tab><tab><tab>new_node = Node(<tab><tab><tab><tab>node.original_graph,<tab><tab><tab><tab>node.id,<tab><tab><tab><tab>f""M_{node.original_graph.model.model_id}_{node.name}"",<tab><tab><tab><tab>node.operation,<tab><tab><tab>)<tab><tab><tab>return new_node, multi_model_placement[node.original_graph.model]<tab>raise ValueError(<tab><tab>f""DedupInputNode {self.name} does not contain nodes from multi_model""<tab>)",0,if node . original_graph . model in multi_model_placement :,if node . name in multi_model_placement :,0.186704445,48.77741105,0.666666667
"def doc_generator(self, imdb_dir, dataset, include_label=False):<tab>dirs = [<tab><tab>(os.path.join(imdb_dir, dataset, ""pos""), True),<tab><tab>(os.path.join(imdb_dir, dataset, ""neg""), False),<tab>]<tab>for d, label in dirs:<tab><tab>for filename in os.listdir(d):<tab><tab><tab>with tf.gfile.Open(os.path.join(d, filename)) as imdb_f:<tab><tab><tab><tab>doc = imdb_f.read().strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield doc, label<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>yield doc",1,if include_label :,if include_label :,0.531170663,1.00E-10,1
"def test_empty_condition_node(cond_node):<tab>for node in [cond_node.true_node, cond_node.false_node]:<tab><tab>if node is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if BaseNode.test_empty_node(node):<tab><tab><tab>continue<tab><tab>return False<tab>return True",0,if type ( node ) is CodeNode and BaseNode . test_empty_node ( node . node ) :,"if isinstance ( node , BaseNode ) :",0.017719396,3.403822943,0.251322751
"def rewrite_imports(package_dir, vendored_libs, vendor_dir):<tab>for item in package_dir.iterdir():<tab><tab>if item.is_dir():<tab><tab><tab>rewrite_imports(item, vendored_libs, vendor_dir)<tab><tab><IF-STMT><tab><tab><tab>rewrite_file_imports(item, vendored_libs, vendor_dir)",0,"elif item . name . endswith ( "".py"" ) :",elif item . is_file ( ) :,0.111074209,14.9759855,0.571428571
"def ageToDays(self, age_str):<tab>age = 0<tab>age_str = age_str.replace(""&nbsp;"", "" "")<tab>regex = ""(\d*.?\d+).(sec|hour|day|week|month|year)+""<tab>matches = re.findall(regex, age_str)<tab>for match in matches:<tab><tab>nr, size = match<tab><tab>mult = 1<tab><tab>if size == ""week"":<tab><tab><tab>mult = 7<tab><tab><IF-STMT><tab><tab><tab>mult = 30.5<tab><tab>elif size == ""year"":<tab><tab><tab>mult = 365<tab><tab>age += tryInt(nr) * mult<tab>return tryInt(age)",0,"elif size == ""month"" :","elif size == ""hour"" :",0.642872021,59.46035575,1
"def _validate_zone(self):<tab>availability_zone = self.availability_zone<tab>if availability_zone:<tab><tab>zone = self.ec2.get_zone(availability_zone)<tab><tab>if not zone:<tab><tab><tab>raise exception.ClusterValidationError(<tab><tab><tab><tab>""availability_zone = %s does not exist"" % availability_zone<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>log.warn(<tab><tab><tab><tab>""The availability_zone = %s "" % zone + ""is not available at this time""<tab><tab><tab>)<tab>return True",0,"if zone . state != ""available"" :",if not self . _is_available_at_time ( zone ) :,0.020882523,3.657015913,0.318181818
"def addnoise(line):<tab>noise = fillers<tab>ratio = len(line) // len(noise)<tab>res = """"<tab>while line and noise:<tab><tab><IF-STMT><tab><tab><tab>c, line = line[0], line[1:]<tab><tab>else:<tab><tab><tab>c, noise = noise[0], noise[1:]<tab><tab>res += c<tab>return res + noise + line",0,if len ( line ) // len ( noise ) > ratio :,if len ( line ) % ratio == 0 :,0.286470649,29.05374199,0.514285714
"def cwr1(iterable, r):<tab>""Pure python version shown in the docs""<tab># number items returned:  (n+r-1)! / r! / (n-1)! when n>0<tab>pool = tuple(iterable)<tab>n = len(pool)<tab>if not n and r:<tab><tab>return<tab>indices = [0] * r<tab>yield tuple(pool[i] for i in indices)<tab>while 1:<tab><tab>for i in reversed(range(r)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return<tab><tab>indices[i:] = [indices[i] + 1] * (r - i)<tab><tab>yield tuple(pool[i] for i in indices)",0,if indices [ i ] != n - 1 :,if indices [ i ] >= n - r :,0.335600785,48.32697831,0.714285714
"def subscribe(self, params) -> bool:<tab>emit_data = {""method"": ""eth_subscribe"", ""params"": params}<tab>nonce = await self._send(emit_data)<tab>raw_message = await self._client.recv()<tab>if raw_message is not None:<tab><tab>resp = ujson.loads(raw_message)<tab><tab><IF-STMT><tab><tab><tab>self._node_address = resp.get(""result"")<tab><tab><tab>return True<tab>return False",0,"if resp . get ( ""id"" , None ) == nonce :","if ""result"" in resp :",0.010805043,3.1317792,0.267857143
"def _(node):<tab>for __ in dir(node):<tab><tab><IF-STMT><tab><tab><tab>candidate = getattr(node, __)<tab><tab><tab>if isinstance(candidate, str):<tab><tab><tab><tab>if ""\\"" in candidate:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>re.compile(candidate)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>errMsg = ""smoke test failed at compiling '%s'"" % candidate<tab><tab><tab><tab><tab><tab>logger.error(errMsg)<tab><tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>_(candidate)",0,"if not __ . startswith ( ""_"" ) :","if __ . startswith ( ""test_"" ) :",0.18845666,64.9335831,0.480769231
"def get_field_values(self, fields):<tab>field_values = []<tab>for field in fields:<tab><tab># Title is special case<tab><tab>if field == ""title"":<tab><tab><tab>value = self.get_title_display()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>value = self.country.printable_name<tab><tab><tab>except exceptions.ObjectDoesNotExist:<tab><tab><tab><tab>value = """"<tab><tab>elif field == ""salutation"":<tab><tab><tab>value = self.salutation<tab><tab>else:<tab><tab><tab>value = getattr(self, field)<tab><tab>field_values.append(value)<tab>return field_values",1,"elif field == ""country"" :","elif field == ""country"" :",1,100,1
"def __str__(self):<tab>s = """"<tab>for k, v in self._members.items():<tab><tab>if isinstance(v.get(""type""), list):<tab><tab><tab>s += k + "" : "" + "";"".join(getattr(self, item)) + ""\n""<tab><tab><IF-STMT><tab><tab><tab>s += k + "" : "" + getattr(self, k) + ""\n""<tab>return s",0,"elif isinstance ( v . get ( ""type"" ) , str ) :","elif v . get ( ""type"" ) == ""member"" :",0.267625576,50.31747627,0.314814815
"def _merge(self, a, b, path=None):<tab>""""""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge""""""<tab>if path is None:<tab><tab>path = []<tab>for key in b:<tab><tab>if key in a:<tab><tab><tab>if isinstance(a[key], dict) and isinstance(b[key], dict):<tab><tab><tab><tab>self._merge(a[key], b[key], path + [str(key)])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass  # same leaf value<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)]))<tab><tab>else:<tab><tab><tab>a[key] = b[key]<tab>return a",1,elif a [ key ] == b [ key ] :,elif a [ key ] == b [ key ] :,1,100,1
"def get_child_nodes(node):<tab>if isinstance(node, _ast.Module):<tab><tab>return node.body<tab>result = []<tab>if node._fields is not None:<tab><tab>for name in node._fields:<tab><tab><tab>child = getattr(node, name)<tab><tab><tab>if isinstance(child, list):<tab><tab><tab><tab>for entry in child:<tab><tab><tab><tab><tab>if isinstance(entry, _ast.AST):<tab><tab><tab><tab><tab><tab>result.append(entry)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(child)<tab>return result",0,"if isinstance ( child , _ast . AST ) :","elif isinstance ( child , _ast . AST ) :",0.422304612,89.31539818,0.666666667
def _handle_enter(self) -> None:<tab>if self.multiple_selection:<tab><tab>val = self.values[self._selected_index][0]<tab><tab><IF-STMT><tab><tab><tab>self.current_values.remove(val)<tab><tab>else:<tab><tab><tab>self.current_values.append(val)<tab>else:<tab><tab>self.current_value = self.values[self._selected_index][0],1,if val in self . current_values :,if val in self . current_values :,0.75,100,1
"def close_all(map=None, ignore_all=False):<tab>if map is None:  # pragma: no cover<tab><tab>map = socket_map<tab>for x in list(map.values()):  # list() FBO py3<tab><tab>try:<tab><tab><tab>x.close()<tab><tab>except OSError as x:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>elif not ignore_all:<tab><tab><tab><tab>raise<tab><tab>except _reraised_exceptions:<tab><tab><tab>raise<tab><tab>except:<tab><tab><tab>if not ignore_all:<tab><tab><tab><tab>raise<tab>map.clear()",0,if x . args [ 0 ] == EBADF :,if x . errno == errno . ENOTCONN :,0.11176253,18.60045402,0.375
"def _get_spawn_property(self, constraints, constraint_name, services):<tab>if services:<tab><tab># this isn't very nice<tab><tab>if constraint_name == IMAGE_CONSTRAINT:<tab><tab><tab>return services[0].image<tab><tab>elif constraint_name == CPUS_CONSTRAINT:<tab><tab><tab>return services[0].cpus<tab>for constraint in constraints:<tab><tab><IF-STMT><tab><tab><tab>return constraint.value<tab>return None",1,if constraint . name == constraint_name :,if constraint . name == constraint_name :,0.75,100,1
"def _handle_children(self, removed, added):<tab># Stop all the removed children.<tab>for obj in removed:<tab><tab>obj.stop()<tab># Process the new objects.<tab>for obj in added:<tab><tab>obj.set(scene=self.scene, parent=self)<tab><tab>if isinstance(obj, ModuleManager):<tab><tab><tab>obj.source = self<tab><tab><IF-STMT><tab><tab><tab>obj.inputs.append(self)<tab><tab>if self.running:<tab><tab><tab>try:<tab><tab><tab><tab>obj.start()<tab><tab><tab>except:<tab><tab><tab><tab>exception()",0,elif is_filter ( obj ) :,"elif isinstance ( obj , Input ) :",0.154233868,16.51582159,0.36
"def _get_cols_width(self, values):<tab>width = 14<tab>for row in values:<tab><tab>for header in self.headers:<tab><tab><tab>header_len = len(header)<tab><tab><tab>if header_len > width:<tab><tab><tab><tab>width = header_len<tab><tab><tab>value_len = len(unicode(row.get(header, """")))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>width = value_len<tab>width += 2<tab>return width",1,if value_len > width :,if value_len > width :,0.75,100,1
"def crawl(self, *args, **kwargs):<tab>assert not self.crawling, ""Crawling already taking place""<tab>self.crawling = True<tab>try:<tab><tab>self.spider = self._create_spider(*args, **kwargs)<tab><tab>self.engine = self._create_engine()<tab><tab><IF-STMT><tab><tab><tab>start_requests = iter(self.spider.start_requests())<tab><tab>else:<tab><tab><tab>start_requests = ()<tab><tab>yield self.engine.open_spider(self.spider, start_requests)<tab><tab>yield defer.maybeDeferred(self.engine.start)<tab>except Exception:<tab><tab>self.crawling = False<tab><tab>raise",0,if self . start_requests :,if self . spider . start_requests :,0.255827832,57.73502692,0.722222222
"def _copy_files(self, files, src, dest, message=""""):<tab>for filepath in files:<tab><tab>srcpath = os.path.join(src, filepath)<tab><tab>destpath = os.path.join(dest, filepath)<tab><tab><IF-STMT><tab><tab><tab>print(""{}: {}"".format(message, destpath))<tab><tab>if os.path.exists(srcpath):<tab><tab><tab>destdir = os.path.dirname(destpath)<tab><tab><tab>if not os.path.isdir(destdir):<tab><tab><tab><tab>os.makedirs(destdir)<tab><tab><tab>shutil.copy(srcpath, destpath)<tab><tab>elif os.path.exists(destpath):<tab><tab><tab>os.remove(destpath)",0,if message :,if self . verbose :,0.051944023,1.00E-10,0.36
"def describe_tags(self):<tab>resource_arns = self._get_multi_param(""ResourceArns.member"")<tab>resources = []<tab>for arn in resource_arns:<tab><tab><IF-STMT><tab><tab><tab>resource = self.elbv2_backend.target_groups.get(arn)<tab><tab><tab>if not resource:<tab><tab><tab><tab>raise TargetGroupNotFoundError()<tab><tab>elif "":loadbalancer"" in arn:<tab><tab><tab>resource = self.elbv2_backend.load_balancers.get(arn)<tab><tab><tab>if not resource:<tab><tab><tab><tab>raise LoadBalancerNotFoundError()<tab><tab>else:<tab><tab><tab>raise LoadBalancerNotFoundError()<tab><tab>resources.append(resource)<tab>template = self.response_template(DESCRIBE_TAGS_TEMPLATE)<tab>return template.render(resources=resources)",1,"if "":targetgroup"" in arn :","if "":targetgroup"" in arn :",0.75,100,1
def iterator():<tab>try:<tab><tab>while True:<tab><tab><tab>yield from pullparser.read_events()<tab><tab><tab># load event buffer<tab><tab><tab>data = source.read(16 * 1024)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>pullparser.feed(data)<tab><tab>root = pullparser._close_and_return_root()<tab><tab>yield from pullparser.read_events()<tab><tab>it.root = root<tab>finally:<tab><tab>if close_source:<tab><tab><tab>source.close(),1,if not data :,if not data :,0.75,100,1
"def __repr__(self):<tab>data = """"<tab>for c in self.children:<tab><tab>data += c.shortrepr()<tab><tab><IF-STMT><tab><tab><tab>data = data[:56] + "" ...""<tab><tab><tab>break<tab>if self[""names""]:<tab><tab>return '<%s ""%s"": %s>' % (<tab><tab><tab>self.__class__.__name__,<tab><tab><tab>""; "".join([ensure_str(n) for n in self[""names""]]),<tab><tab><tab>data,<tab><tab>)<tab>else:<tab><tab>return ""<%s: %s>"" % (self.__class__.__name__, data)",0,if len ( data ) > 60 :,if len ( data ) > 57 :,0.605621306,70.71067812,0.666666667
"def __exit__(self, exc_type, exc_value, traceback):<tab>template_rendered.disconnect(self.on_template_render)<tab>if exc_type is not None:<tab><tab>return<tab>if not self.test():<tab><tab>message = self.message()<tab><tab><IF-STMT><tab><tab><tab>message += "" No template was rendered.""<tab><tab>else:<tab><tab><tab>message += "" Following templates were rendered: %s"" % (<tab><tab><tab><tab>"", "".join(self.rendered_template_names)<tab><tab><tab>)<tab><tab>self.test_case.fail(message)",0,if len ( self . rendered_templates ) == 0 :,if not self . rendered_template_names :,0.027684848,21.5367242,0.487179487
"def _match(self, byte_chunk):<tab>quote_character = None<tab>data = byte_chunk.nhtml<tab>open_angle_bracket = data.rfind(""<"")<tab># We are inside <...<tab>if open_angle_bracket <= data.rfind("">""):<tab><tab>return False<tab>for s in data[open_angle_bracket + 1 :]:<tab><tab>if s in ATTR_DELIMITERS:<tab><tab><tab>if quote_character and s == quote_character:<tab><tab><tab><tab>quote_character = None<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>quote_character = s<tab><tab><tab><tab>continue<tab>if quote_character == self.quote_character:<tab><tab>return True<tab>return False",0,elif not quote_character :,if quote_character and s != quote_character :,0.182634776,21.20062676,0.148148148
"def recent_events(self, events):<tab>try:<tab><tab>frame = self.get_frame()<tab>except EndofVideoFileError:<tab><tab>logger.info(""Video has ended."")<tab><tab>self.notify_all(<tab><tab><tab>{""subject"": ""file_source.video_finished"", ""source_path"": self.source_path}<tab><tab>)<tab><tab>self.play = False<tab>else:<tab><tab>self._recent_frame = frame<tab><tab>events[""frame""] = frame<tab><tab><IF-STMT><tab><tab><tab>self.wait(frame)",0,if self . timed_playback :,if self . play :,0.394778655,28.64190458,0.7
"def _prune(self):<tab>if self.over_threshold():<tab><tab>now = time.time()<tab><tab>for idx, (key, (expires, _)) in enumerate(self._cache.items()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with self._mutex:<tab><tab><tab><tab><tab>self._cache.pop(key, None)",0,if expires is not None and expires <= now or idx % 3 == 0 :,if expires <= now :,0.030226734,8.177973903,0.178104575
"def dict_path(d, path):<tab>if not isinstance(path, (list, tuple)):<tab><tab>raise ValueError()<tab>for keys in path:<tab><tab>if type(keys) is not list:<tab><tab><tab>keys = [keys]<tab><tab>value = None<tab><tab>for key in keys:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>value = d[key]<tab><tab>if value is None:<tab><tab><tab>value = {}<tab><tab>for key in keys:<tab><tab><tab>d[key] = value<tab><tab>d = value<tab>return d",1,if key not in d :,if key not in d :,0.75,100,1
"def span_tokenize(self, string):<tab>if self.__tokenizer == ""nltk"":<tab><tab>raw_tokens = nltk.word_tokenize(string)<tab><tab><IF-STMT><tab><tab><tab>matched = [m.group() for m in re.finditer(r""``|'{2}|\"""", string)]<tab><tab><tab>tokens = [<tab><tab><tab><tab>matched.pop(0) if tok in ['""', ""``"", ""''""] else tok<tab><tab><tab><tab>for tok in raw_tokens<tab><tab><tab>]<tab><tab>else:<tab><tab><tab>tokens = raw_tokens<tab><tab>spans = align_tokens(tokens, string)<tab>return spans",0,"if ( '""' in string ) or ( ""''"" in string ) :","if self . __tokenizer == ""regex"" :",0.009852387,3.157256457,0.296296296
"def literal(self):<tab>if self.peek('""'):<tab><tab>lit, lang, dtype = self.eat(r_literal).groups()<tab><tab>if lang:<tab><tab><tab>lang = lang<tab><tab>else:<tab><tab><tab>lang = None<tab><tab>if dtype:<tab><tab><tab>dtype = dtype<tab><tab>else:<tab><tab><tab>dtype = None<tab><tab><IF-STMT><tab><tab><tab>raise ParseError(""Can't have both a language and a datatype"")<tab><tab>lit = unquote(lit)<tab><tab>return Literal(lit, lang, dtype)<tab>return False",1,if lang and dtype :,if lang and dtype :,0.75,100,1
"def get():<tab>result = []<tab>for b in self.key_bindings:<tab><tab>if len(keys) < len(b.keys):<tab><tab><tab>match = True<tab><tab><tab>for i, j in zip(b.keys, keys):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>match = False<tab><tab><tab><tab><tab>break<tab><tab><tab>if match:<tab><tab><tab><tab>result.append(b)<tab>return result",0,if i != j and i != Keys . Any :,if i != j :,0.119722816,24.76498688,0.476190476
"def _compileRules(rulesList, maxLength=4):<tab>ruleChecking = collections.defaultdict(list)<tab>for ruleIndex in range(len(rulesList)):<tab><tab>args = []<tab><tab>if len(rulesList[ruleIndex]) == maxLength:<tab><tab><tab>args = rulesList[ruleIndex][-1]<tab><tab><IF-STMT><tab><tab><tab>(shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, isCorrect, args))<tab><tab>elif maxLength == 3:<tab><tab><tab>(shouldRunMethod, method) = rulesList[ruleIndex][0:2]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, args))<tab>return ruleChecking",0,if maxLength == 4 :,if maxLength == 1 :,0.394778655,53.72849659,0.6
def parents_in_pipfile(self):<tab>if not self._parents_in_pipfile:<tab><tab>self._parents_in_pipfile = [<tab><tab><tab>p<tab><tab><tab>for p in self.flattened_parents<tab><tab><tab><IF-STMT><tab><tab>]<tab>return self._parents_in_pipfile,0,if p . normalized_name in self . pipfile_packages,if p . is_dir and not p . is_dir ( ),0.243318727,11.63327084,0.36996337
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_content(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_blob_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_width(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 32:<tab><tab><tab>self.set_height(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100,1
"def base64_encode_image_mapper(self, tag, url):<tab>if tag == ""img"":<tab><tab><IF-STMT><tab><tab><tab>image_data = base64.b64encode(self.kp_images[url])<tab><tab><tab>image_mimetype = mimetypes.guess_type(url)[0]<tab><tab><tab>if image_mimetype is not None:<tab><tab><tab><tab>return ""data:{};base64, "".format(image_mimetype) + image_data.decode(<tab><tab><tab><tab><tab>""utf-8""<tab><tab><tab><tab>)<tab>return None",1,if url in self . kp_images :,if url in self . kp_images :,0.75,100,1
"def get_args_from_ref_args(handler, ref_args):<tab>args = []<tab>for ref_arg in ref_args:<tab><tab><IF-STMT><tab><tab><tab>temp = handler.create_from_numpy(ref_arg)<tab><tab><tab>args.append(temp)<tab><tab>else:<tab><tab><tab>args.append(ref_arg)<tab>return args",0,if type ( ref_arg ) is ref . array_type :,"if isinstance ( ref_arg , np . ndarray ) :",0.03002399,21.34144323,0.25
"def _get_cols_width(self, values):<tab>width = 14<tab>for row in values:<tab><tab>for header in self.headers:<tab><tab><tab>header_len = len(header)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>width = header_len<tab><tab><tab>value_len = len(unicode(row.get(header, """")))<tab><tab><tab>if value_len > width:<tab><tab><tab><tab>width = value_len<tab>width += 2<tab>return width",1,if header_len > width :,if header_len > width :,0.75,100,1
"def OnLeaveWindow(self, event):<tab>if self.start_drag and not self.dragging:<tab><tab>self.dragging = False<tab><tab>self.start_drag = False<tab><tab>self.dragged_tab = None<tab><tab>self.drag_trigger = self.drag_trail<tab><tab><IF-STMT><tab><tab><tab>self.ReleaseMouse()<tab>if self.preview_wnd:<tab><tab>self.preview_wnd.Show(False)<tab><tab>del self.preview_wnd<tab><tab>self.preview_wnd = None<tab>event.Skip()",0,if self . HasCapture ( ) :,if self . dragging :,0.094532291,28.64190458,0.6
"def _checkPid(self, pid):<tab>retval = False<tab>if self.settings.windows:<tab><tab>PROCESS_TERMINATE = 1<tab><tab>p = ctypes.windll.kernel32.OpenProcess(PROCESS_TERMINATE, 0, pid)<tab><tab>retval = p != 0<tab><tab><IF-STMT><tab><tab><tab>ctypes.windll.kernel32.CloseHandle(p)<tab>else:<tab><tab># https://stackoverflow.com/questions/568271/how-to-check-if-there-exists-a-process-with-a-given-pid-in-python<tab><tab>try:<tab><tab><tab>os.kill(pid, 0)<tab><tab>except OSError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>retval = True<tab>return retval",0,if p :,if retval :,0.319750449,1.00E-10,0.5
"def concat_index_value(index_values, store_data=False):<tab>result = pd.Index([])<tab>if not isinstance(index_values, (list, tuple)):<tab><tab>index_values = [index_values]<tab>for index_value in index_values:<tab><tab><IF-STMT><tab><tab><tab>result = result.append(index_value)<tab><tab>else:<tab><tab><tab>result = result.append(index_value.to_pandas())<tab>return parse_index(result, store_data=store_data)",0,"if isinstance ( index_value , pd . Index ) :","if isinstance ( index_value , pd . Series ) :",0.604939981,76.91605673,0.666666667
"def apply(self, db, family):<tab>if self.rtype:<tab><tab>if self.rtype.is_custom() and self.use_regex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>elif self.rtype != family.get_relationship():<tab><tab><tab>return False<tab>return True",0,if self . regex [ 0 ] . search ( str ( family . get_relationship ( ) ) ) is None :,if not self . regex . search ( family . get_relationship ( ) ) :,0.240901984,43.24138123,0.263322884
"def get_child_nodes(node):<tab>if isinstance(node, _ast.Module):<tab><tab>return node.body<tab>result = []<tab>if node._fields is not None:<tab><tab>for name in node._fields:<tab><tab><tab>child = getattr(node, name)<tab><tab><tab>if isinstance(child, list):<tab><tab><tab><tab>for entry in child:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>result.append(entry)<tab><tab><tab>if isinstance(child, _ast.AST):<tab><tab><tab><tab>result.append(child)<tab>return result",0,"if isinstance ( entry , _ast . AST ) :",if entry not in result :,0.014786244,4.642454187,0.238636364
"def output(self):<tab>""""""Transform self into a list of (name, value) tuples.""""""<tab>header_list = []<tab>for k, v in self.items():<tab><tab>if isinstance(k, unicodestr):<tab><tab><tab>k = self.encode(k)<tab><tab>if not isinstance(v, basestring):<tab><tab><tab>v = str(v)<tab><tab><IF-STMT><tab><tab><tab>v = self.encode(v)<tab><tab># See header_translate_* constants above.<tab><tab># Replace only if you really know what you're doing.<tab><tab>k = k.translate(header_translate_table, header_translate_deletechars)<tab><tab>v = v.translate(header_translate_table, header_translate_deletechars)<tab><tab>header_list.append((k, v))<tab>return header_list",1,"if isinstance ( v , unicodestr ) :","if isinstance ( v , unicodestr ) :",0.75,100,1
"def check_valid_emoji_name(emoji_name: str) -> None:<tab>if emoji_name:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>raise JsonableError(_(""Invalid characters in emoji name""))<tab>raise JsonableError(_(""Emoji name is missing""))",0,"if re . match ( r""^[0-9a-z.\-_]+(?<![.\-_])$"" , emoji_name ) :","if str ( emoji_name ) . lower ( ) . startswith ( ""emoji_"" ) :",0.029178416,7.529704629,0.279503106
"def cache_subscriptions(self, region: str):<tab>async with self.regional_subscriptions_cache_locks.setdefault(<tab><tab>region, asyncio.Lock()<tab>):<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.subscriptions_cache[region] = await AWSFacadeUtils.get_all_pages(<tab><tab><tab>""sns"", region, self.session, ""list_subscriptions"", ""Subscriptions""<tab><tab>)<tab><tab>for subscription in self.subscriptions_cache[region]:<tab><tab><tab>topic_arn = subscription.pop(""TopicArn"")<tab><tab><tab>subscription[""topic_name""] = topic_arn.split("":"")[-1]",1,if region in self . subscriptions_cache :,if region in self . subscriptions_cache :,0.75,100,1
"def AdjustArg(arg, break_chars, argv_out):<tab># type: (str, List[str], List[str]) -> None<tab>end_indices = []  # stores the end of each span<tab>state = ST_Begin<tab>for i, c in enumerate(arg):<tab><tab>ch = CH_Break if c in break_chars else CH_Other<tab><tab>state, emit_span = _TRANSITIONS[state, ch]<tab><tab><IF-STMT><tab><tab><tab>end_indices.append(i)<tab># Always emit a span at the end (even for empty string)<tab>end_indices.append(len(arg))<tab>begin = 0<tab>for end in end_indices:<tab><tab>argv_out.append(arg[begin:end])<tab><tab>begin = end",1,if emit_span :,if emit_span :,0.531170663,1.00E-10,1
"def load_model(<tab>self, model_name: str, path: str = None, model_type=None) -> AbstractModel:<tab>if isinstance(model_name, AbstractModel):<tab><tab>return model_name<tab>if model_name in self.models.keys():<tab><tab>return self.models[model_name]<tab>else:<tab><tab>if path is None:<tab><tab><tab>path = self.get_model_attribute(model=model_name, attribute=""path"")<tab><tab><IF-STMT><tab><tab><tab>model_type = self.get_model_attribute(model=model_name, attribute=""type"")<tab><tab>return model_type.load(path=path, reset_paths=self.reset_paths)",1,if model_type is None :,if model_type is None :,0.75,100,1
"def find_config(pipeline_config_path: Union[str, Path]) -> Path:<tab>if not Path(pipeline_config_path).is_file():<tab><tab>configs = [<tab><tab><tab>c<tab><tab><tab>for c in Path(__file__).parent.parent.parent.glob(<tab><tab><tab><tab>f""configs/**/{pipeline_config_path}.json""<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab>]  # a simple way to not allow * and ?<tab><tab>if configs:<tab><tab><tab>log.info(f""Interpreting '{pipeline_config_path}' as '{configs[0]}'"")<tab><tab><tab>pipeline_config_path = configs[0]<tab>return Path(pipeline_config_path)",0,"if str ( c . with_suffix ( """" ) ) . endswith ( pipeline_config_path )","if c . name . endswith ( "".json"" )",0.075694679,9.066286755,0.5
"def __init__(self, bounds, channel_axis, preprocess=None):<tab>assert len(bounds) == 2<tab>assert channel_axis in [0, 1, 2, 3]<tab>self._bounds = bounds<tab>self._channel_axis = channel_axis<tab># Make self._preprocess to be (0,1) if possible, so that don't need<tab># to do substract or divide.<tab>if preprocess is not None:<tab><tab>sub, div = np.array(preprocess)<tab><tab>if not np.any(sub):<tab><tab><tab>sub = 0<tab><tab><IF-STMT><tab><tab><tab>div = 1<tab><tab>assert (div is None) or np.all(div)<tab><tab>self._preprocess = (sub, div)<tab>else:<tab><tab>self._preprocess = (0, 1)",0,if np . all ( div == 1 ) :,if not np . any ( div ) :,0.041096027,13.74443828,0.25
"def iter_imports(path):<tab>""""""Yield imports in *path*""""""<tab>for node in ast.parse(open(path, ""rb"").read()).body:<tab><tab>if isinstance(node, ast.ImportFrom):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prefix = ()<tab><tab><tab>else:<tab><tab><tab><tab>prefix = tuple(node.module.split("".""))<tab><tab><tab>for snode in node.names:<tab><tab><tab><tab>yield (node.level, prefix + (snode.name,))<tab><tab>elif isinstance(node, ast.Import):<tab><tab><tab>for node in node.names:<tab><tab><tab><tab>yield (0, tuple(node.name.split(""."")))",1,if node . module is None :,if node . module is None :,0.75,100,1
"def __init__(self, spec=None, add_book=True, xl=None, visible=None):<tab># visible is only required on mac<tab>if spec is not None:<tab><tab>warn(""spec is ignored on Windows."")<tab>if xl is None:<tab><tab># new instance<tab><tab>self._xl = COMRetryObjectWrapper(DispatchEx(""Excel.Application""))<tab><tab><IF-STMT><tab><tab><tab>self._xl.Workbooks.Add()<tab><tab>self._hwnd = None<tab>elif isinstance(xl, int):<tab><tab>self._xl = None<tab><tab>self._hwnd = xl<tab>else:<tab><tab>self._xl = xl<tab><tab>self._hwnd = None",1,if add_book :,if add_book :,0.531170663,1.00E-10,1
"def _find_split():<tab>""""""Find the first = sign to split on (that isn't in [brackets])""""""<tab>key = []<tab>value = []<tab>brackets = False<tab>chars = list(expression)<tab>while chars:<tab><tab>c = chars.pop(0)<tab><tab>if c == ""="" and not brackets:<tab><tab><tab># keys done the rest is value<tab><tab><tab>value = chars<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>brackets = True<tab><tab><tab>key += c<tab><tab>elif c == ""]"" and brackets:<tab><tab><tab>brackets = False<tab><tab><tab>key += c<tab><tab>else:<tab><tab><tab># normal character<tab><tab><tab>key += c<tab>return """".join(key), """".join(value)",0,"elif c == ""["" :","elif c == ""["" and brackets :",0.660456913,66.06328636,0.55
"def _ApplySizeLimit(<tab>regions: Iterable[rdf_memory.ProcessMemoryRegion], size_limit: int) -> List[rdf_memory.ProcessMemoryRegion]:<tab>""""""Truncates regions so that the total size stays in size_limit.""""""<tab>total_size = 0<tab>regions_in_limit = []<tab>for region in regions:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>region.dumped_size = min(region.size, size_limit - total_size)<tab><tab>regions_in_limit.append(region)<tab><tab>total_size += region.dumped_size<tab>return regions_in_limit",1,if total_size >= size_limit :,if total_size >= size_limit :,0.75,100,1
"def _get_matched_files(input_path):<tab>""""""Returns all files that matches the input_path.""""""<tab>input_patterns = input_path.strip().split("","")<tab>all_matched_files = []<tab>for input_pattern in input_patterns:<tab><tab>input_pattern = input_pattern.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>matched_files = tf.io.gfile.glob(input_pattern)<tab><tab>if not matched_files:<tab><tab><tab>raise ValueError(""%s does not match any files."" % input_pattern)<tab><tab>else:<tab><tab><tab>all_matched_files.extend(matched_files)<tab>return sorted(all_matched_files)",1,if not input_pattern :,if not input_pattern :,0.75,100,1
"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab>if type(x) in (type([]), type(())):<tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kids[key] = x1<tab><tab>elif isinstance(x, TVTKBase):<tab><tab><tab>if hasattr(x, ""__iter__""):<tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x",0,if x1 :,if len ( x1 ) > 0 :,0.0465226,1.00E-10,0.36
"def _read_info(self, field):<tab>fs.File._read_info(self, field)<tab>if field == ""dimensions"":<tab><tab>self.dimensions = self._plat_get_dimensions()<tab><tab><IF-STMT><tab><tab><tab>self.dimensions = (self.dimensions[1], self.dimensions[0])<tab>elif field == ""exif_timestamp"":<tab><tab>self.exif_timestamp = self._get_exif_timestamp()",0,"if self . _get_orientation ( ) in { 5 , 6 , 7 , 8 } :",if self . dimensions :,0.023732168,2.12733674,0.314814815
"def process_timeline(self, info):<tab>children = info.get(""_children"", [])<tab>if not children:<tab><tab>return False<tab>for entry in children:<tab><tab>state = TIMELINE_STATES.get(entry.get(""state""))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self.emit(""%s.timeline.%s"" % (self.name, state), entry)<tab>return True",0,if not state :,if state is None :,0.045150551,14.05853313,0.277777778
"def from_chx(self):<tab>if self.array is not None:<tab><tab>device = backend.get_device_from_array(self.array)<tab>else:<tab><tab>device = self._initial_device<tab>if device.xp is chainerx:<tab><tab>backend_name = device.device.backend.name<tab><tab>if backend_name == ""native"":<tab><tab><tab>self._initial_device = backend.CpuDevice()<tab><tab><IF-STMT><tab><tab><tab>self._initial_device = backend.GpuDevice.from_device_id(device.device.index)<tab>super(Parameter, self)._from_chx(allow_unchaining=True)",0,"elif backend_name == ""cuda"" :","elif backend_name == ""gpu"" :",0.642872021,70.71067812,1
"def get_title_extensions(self, title=None):<tab>extensions = []<tab>for extension in self.title_extensions:<tab><tab><IF-STMT><tab><tab><tab>extensions.extend(list(extension.objects.filter(extended_object=title)))<tab><tab>else:<tab><tab><tab>extensions.extend(list(extension.objects.all()))<tab>return extensions",0,if title :,if title is not None :,0.090364769,1.00E-10,0.4
"def tag(vs, push=False):<tab>""""""Make the tagged release commit""""""<tab>patch_version(vs, repo_root)<tab>with cd(repo_root):<tab><tab>run('git commit -a -m ""release {}""'.format(vs))<tab><tab>run('git tag -a -m ""release {0}"" {0}'.format(vs))<tab><tab><IF-STMT><tab><tab><tab>run(""git push"")<tab><tab><tab>run(""git push --tags"")",1,if push :,if push :,0.531170663,1.00E-10,1
"def parse_bismark_report(self, report, regexes):<tab>""""""Search a bismark report with a set of regexes""""""<tab>parsed_data = {}<tab>for k, r in regexes.items():<tab><tab>r_search = re.search(r, report, re.MULTILINE)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>parsed_data[k] = float(r_search.group(1))<tab><tab><tab>except ValueError:<tab><tab><tab><tab>parsed_data[k] = r_search.group(1)  # NaN<tab>if len(parsed_data) == 0:<tab><tab>return None<tab>return parsed_data",1,if r_search :,if r_search :,0.531170663,1.00E-10,1
"def _scroll_delete(dirname, max_num_checkpoints=3):<tab>dirs = os.listdir(dirname)<tab>serial_map = {}<tab>for serial in dirs:<tab><tab>serial_num = _get_dir_serial(serial)<tab><tab>serial_map[serial_num] = serial<tab>if len(list(serial_map.keys())) <= max_num_checkpoints:<tab><tab>return<tab>serials = list(serial_map.keys())<tab>serials.sort(reverse=True)<tab>serials = serials[max_num_checkpoints:]<tab>for serial in serials:<tab><tab>cur_dir = _get_serial_dir(dirname, serial)<tab><tab>try:<tab><tab><tab>shutil.rmtree(cur_dir)<tab><tab>except OSError as err:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise err",0,if err . errno != errno . ENOENT :,if err . errno != errno . EEXIST :,0.877090855,78.254229,0.666666667
"def _lookup(self, key, dicts=None, filters=()):<tab>if dicts is None:<tab><tab>dicts = self.dicts<tab>key_len = len(key)<tab>if key_len > self.longest_key:<tab><tab>return None<tab>for d in dicts:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if key_len > d.longest_key:<tab><tab><tab>continue<tab><tab>value = d.get(key)<tab><tab>if value:<tab><tab><tab>for f in filters:<tab><tab><tab><tab>if f(key, value):<tab><tab><tab><tab><tab>return None<tab><tab><tab>return value",0,if not d . enabled :,if key_len > d . longest_key :,0.047631794,8.913765521,0.35
"def get_preset(self, unit):<tab>for line in self._lines:<tab><tab>m = re.match(r""(enable|disable)\s+(\S+)"", line)<tab><tab><IF-STMT><tab><tab><tab>status, pattern = m.group(1), m.group(2)<tab><tab><tab>if fnmatch.fnmatchcase(unit, pattern):<tab><tab><tab><tab>logg.debug(""%s %s => %s [%s]"", status, pattern, unit, self.filename())<tab><tab><tab><tab>return status<tab>return None",1,if m :,if m :,0.531170663,1.00E-10,1
"def gen_cpu_name(cpu):<tab>if cpu == ""simple"":<tab><tab>return event_download.get_cpustr()<tab>for j in known_cpus:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(j[1][0], tuple):<tab><tab><tab><tab>return ""GenuineIntel-6-%02X-%d"" % j[1][0]<tab><tab><tab>else:<tab><tab><tab><tab>return ""GenuineIntel-6-%02X"" % j[1][0]<tab>assert False",0,if cpu == j [ 0 ] :,if j [ 0 ] == cpu :,0.268066808,39.28146509,0.4
"def allow_request(self, request, view):<tab>if settings.API_THROTTLING:<tab><tab>request_allowed = super(GranularUserRateThrottle, self).allow_request(<tab><tab><tab>request, view<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>user = getattr(request, ""user"", None)<tab><tab><tab>if user and request.user.is_authenticated:<tab><tab><tab><tab>log.info(""User %s throttled for scope %s"", request.user, self.scope)<tab><tab><tab><tab>ActivityLog.create(amo.LOG.THROTTLED, self.scope, user=user)<tab><tab>return request_allowed<tab>else:<tab><tab>return True",0,if not request_allowed :,if request_allowed :,0.096488528,1.00E-10,0.6
"def __getitem__(self, tagSet):<tab>try:<tab><tab>return self.__presentTypes[tagSet]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>raise KeyError()<tab><tab>elif tagSet in self.__skipTypes:<tab><tab><tab>raise error.PyAsn1Error(""Key in negative map"")<tab><tab>else:<tab><tab><tab>return self.__defaultType",0,if self . __defaultType is None :,if tagSet in self . __negativeTypes :,0.142825693,33.03164318,0.285714286
"def _media(self):<tab># Get the media property of the superclass, if it exists<tab>sup_cls = super(cls, self)<tab>try:<tab><tab>base = sup_cls.media<tab>except AttributeError:<tab><tab>base = Media()<tab># Get the media definition for this class<tab>definition = getattr(cls, ""Media"", None)<tab>if definition:<tab><tab>extend = getattr(definition, ""extend"", True)<tab><tab>if extend:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>m = base<tab><tab><tab>else:<tab><tab><tab><tab>m = Media()<tab><tab><tab><tab>for medium in extend:<tab><tab><tab><tab><tab>m = m + base[medium]<tab><tab><tab>return m + Media(definition)<tab><tab>else:<tab><tab><tab>return Media(definition)<tab>else:<tab><tab>return base",1,if extend == True :,if extend == True :,0.75,100,1
"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab><IF-STMT><tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",0,"elif c == ""~"" :","elif c == ""a"" :",0.642872021,59.46035575,1
"def get_max_shape(data):<tab>if isinstance(data, dict):<tab><tab>max = 0<tab><tab>val = None<tab><tab>for k, v in data.items():<tab><tab><tab>tmp = reduce(lambda x, y: x * y, v.shape)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>val = v.shape<tab><tab><tab><tab>max = tmp<tab><tab>return val<tab>else:<tab><tab>return data[0].shape",1,if tmp > max :,if tmp > max :,0.75,100,1
"def _subscribe_core(<tab>self, observer: typing.Observer, scheduler: Optional[typing.Scheduler] = None) -> typing.Disposable:<tab>with self.lock:<tab><tab>self.check_disposed()<tab><tab><IF-STMT><tab><tab><tab>self.observers.append(observer)<tab><tab><tab>return InnerSubscription(self, observer)<tab><tab>ex = self.exception<tab><tab>has_value = self.has_value<tab><tab>value = self.value<tab>if ex:<tab><tab>observer.on_error(ex)<tab>elif has_value:<tab><tab>observer.on_next(value)<tab><tab>observer.on_completed()<tab>else:<tab><tab>observer.on_completed()<tab>return Disposable()",0,if not self . is_stopped :,if self . has_value :,0.054520976,14.31720073,0.464285714
"def ratio(self, outevent, inevent):<tab>assert outevent not in self<tab>assert inevent in self<tab>for function in compat_itervalues(self.functions):<tab><tab>assert outevent not in function<tab><tab>assert inevent in function<tab><tab>function[outevent] = ratio(function[inevent], self[inevent])<tab><tab>for call in compat_itervalues(function.calls):<tab><tab><tab>assert outevent not in call<tab><tab><tab><IF-STMT><tab><tab><tab><tab>call[outevent] = ratio(call[inevent], self[inevent])<tab>self[outevent] = 1.0",1,if inevent in call :,if inevent in call :,0.75,100,1
"def _format_changelog(self, changelog):<tab>""""""Format the changelog correctly and convert it to a list of strings""""""<tab>if not changelog:<tab><tab>return changelog<tab>new_changelog = []<tab>for line in changelog.strip().split(""\n""):<tab><tab>line = line.strip()<tab><tab>if line[0] == ""*"":<tab><tab><tab>new_changelog.extend(["""", line])<tab><tab><IF-STMT><tab><tab><tab>new_changelog.append(line)<tab><tab>else:<tab><tab><tab>new_changelog.append(""  "" + line)<tab># strip trailing newline inserted by first changelog entry<tab>if not new_changelog[0]:<tab><tab>del new_changelog[0]<tab>return new_changelog",1,"elif line [ 0 ] == ""-"" :","elif line [ 0 ] == ""-"" :",1,100,1
"def _set_base64md5(self, value):<tab>if value:<tab><tab><IF-STMT><tab><tab><tab>value = value.decode(""utf-8"")<tab><tab>self.local_hashes[""md5""] = binascii.a2b_base64(value)<tab>elif ""md5"" in self.local_hashes:<tab><tab>del self.local_hashes[""md5""]",0,"if not isinstance ( value , six . string_types ) :","if isinstance ( value , bytes ) :",0.148528651,22.87102534,0.274725275
"def setGeometry(self, rect):<tab>""""""Set the window geometry, but only once when using the qttabs gui.""""""<tab>if g.app.qt_use_tabs:<tab><tab>m = self.leo_master<tab><tab>assert self.leo_master<tab><tab># Only set the geometry once, even for new files.<tab><tab><IF-STMT><tab><tab><tab>m.leo_geom_inited = True<tab><tab><tab>self.leo_master.setGeometry(rect)<tab><tab><tab>QtWidgets.QMainWindow.setGeometry(self, rect)<tab>else:<tab><tab>QtWidgets.QMainWindow.setGeometry(self, rect)",0,"if not hasattr ( m , ""leo_geom_inited"" ) :",if m :,0.076454293,1.00E-10,0.366666667
"def _get_extension_suppressions(mod_loaders):<tab>res = []<tab>for m in mod_loaders:<tab><tab>suppressions = getattr(m, ""suppress_extension"", None)<tab><tab>if suppressions:<tab><tab><tab>suppressions = (<tab><tab><tab><tab>suppressions if isinstance(suppressions, list) else [suppressions]<tab><tab><tab>)<tab><tab><tab>for sup in suppressions:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>res.append(sup)<tab>return res",0,"if isinstance ( sup , ModExtensionSuppress ) :",if sup is not None :,0.019830745,7.654112967,0.232142857
"def _check_positional(results):<tab>positional = None<tab>for name, char in results:<tab><tab>if positional is None:<tab><tab><tab>positional = name is None<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TranslationError(<tab><tab><tab><tab><tab>""format string mixes positional "" ""and named placeholders""<tab><tab><tab><tab>)<tab>return bool(positional)",0,if ( name is None ) != positional :,if char not in positional :,0.07197202,9.223644101,0.333333333
"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab><IF-STMT><tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",0,"elif c == ""z"" :","elif c == ""-"" :",0.642872021,59.46035575,1
"def __getattr__(self, name):<tab># if the aval property raises an AttributeError, gets caught here<tab>assert skip_checks or name != ""aval""<tab>try:<tab><tab>attr = getattr(self.aval, name)<tab>except KeyError as err:<tab><tab>raise AttributeError(<tab><tab><tab>""{} has no attribute {}"".format(self.__class__.__name__, name)<tab><tab>) from err<tab>else:<tab><tab>t = type(attr)<tab><tab><IF-STMT><tab><tab><tab>return attr.fget(self)<tab><tab>elif t is aval_method:<tab><tab><tab>return types.MethodType(attr.fun, self)<tab><tab>else:<tab><tab><tab>return attr",0,if t is aval_property :,if t is callable :,0.394778655,28.64190458,0.733333333
"def build_vocab(self, filename):<tab>EOS = ""</eos>""<tab>vocab_dict = {}<tab>ids = 0<tab>vocab_dict[EOS] = ids<tab>ids += 1<tab>with open(filename, ""r"") as f:<tab><tab>for line in f.readlines():<tab><tab><tab>for w in line.strip().split():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>vocab_dict[w] = ids<tab><tab><tab><tab><tab>ids += 1<tab>self.vocab_size = ids<tab>return vocab_dict",1,if w not in vocab_dict :,if w not in vocab_dict :,0.75,100,1
"def eval_dummy_genomes_iznn(genomes, config):<tab>for genome_id, genome in genomes:<tab><tab>net = neat.iznn.IZNN.create(genome, config)<tab><tab>if genome_id < 10:<tab><tab><tab>net.reset()<tab><tab><tab>genome.fitness = 0.0<tab><tab><IF-STMT><tab><tab><tab>genome.fitness = 0.5<tab><tab>else:<tab><tab><tab>genome.fitness = 1.0",0,elif genome_id <= 150 :,elif genome_id == 10 :,0.062871671,38.26029416,0.5
"def _add_csrf(self, without_csrf, explicit_csrf=None):<tab>parts = urlparse(without_csrf)<tab>query = parse_qs(parts[4])<tab>with self.app.session_transaction() as sess:<tab><tab><IF-STMT><tab><tab><tab>query[CSRF_TOKEN_KEY] = explicit_csrf<tab><tab>else:<tab><tab><tab>sess[CSRF_TOKEN_KEY] = ""something""<tab><tab><tab>query[CSRF_TOKEN_KEY] = sess[CSRF_TOKEN_KEY]<tab>return urlunparse(list(parts[0:4]) + [urlencode(query)] + list(parts[5:]))",0,if explicit_csrf is not None :,if explicit_csrf :,0.050438393,1.00E-10,0.314285714
"def test_confirm_extension_is_yml(self):<tab>files_with_incorrect_extensions = []<tab>for file in self.yield_next_rule_file_path(self.path_to_rules):<tab><tab>file_name_and_extension = os.path.splitext(file)<tab><tab><IF-STMT><tab><tab><tab>extension = file_name_and_extension[1]<tab><tab><tab>if extension != "".yml"":<tab><tab><tab><tab>files_with_incorrect_extensions.append(file)<tab>self.assertEqual(<tab><tab>files_with_incorrect_extensions,<tab><tab>[],<tab><tab>Fore.RED + ""There are rule files with extensions other than .yml"",<tab>)",0,if len ( file_name_and_extension ) == 2 :,"if file_name_and_extension [ 0 ] == "".yml"" :",0.020373037,38.05371079,0.381818182
"def _handle_eof(self, m):<tab>self.lock.acquire()<tab>try:<tab><tab>if not self.eof_received:<tab><tab><tab>self.eof_received = True<tab><tab><tab>self.in_buffer.close()<tab><tab><tab>self.in_stderr_buffer.close()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._pipe.set_forever()<tab>finally:<tab><tab>self.lock.release()<tab>self._log(DEBUG, ""EOF received ({})"".format(self._name))",1,if self . _pipe is not None :,if self . _pipe is not None :,0.75,100,1
"def do_close(self):<tab>if self.flags is not None and (self.flags == ""c"" or self.flags == ""w""):<tab><tab><IF-STMT><tab><tab><tab>insert = self.table.insert()<tab><tab><tab>self.bind.execute(<tab><tab><tab><tab>insert,<tab><tab><tab><tab>namespace=self.namespace,<tab><tab><tab><tab>data=self.hash,<tab><tab><tab><tab>accessed=datetime.now(),<tab><tab><tab><tab>created=datetime.now(),<tab><tab><tab>)<tab><tab><tab>self._is_new = False<tab><tab>else:<tab><tab><tab>update = self.table.update(self.table.c.namespace == self.namespace)<tab><tab><tab>self.bind.execute(update, data=self.hash, accessed=datetime.now())<tab>self.flags = None",1,if self . _is_new :,if self . _is_new :,0.75,100,1
"def __init__(self, sh_cmd, title=None, env=None, d=None):<tab>self.command = d and d.getVar(""OE_TERMINAL_CUSTOMCMD"")<tab>if self.command:<tab><tab><IF-STMT><tab><tab><tab>self.command += "" {command}""<tab><tab>Terminal.__init__(self, sh_cmd, title, env, d)<tab><tab>logger.warn(""Custom terminal was started."")<tab>else:<tab><tab>logger.debug(1, ""No custom terminal (OE_TERMINAL_CUSTOMCMD) set"")<tab><tab>raise UnsupportedTerminal(""OE_TERMINAL_CUSTOMCMD not set"")",0,"if not ""{command}"" in self . command :","if not self . command . endswith ( "" "" ) :",0.074174296,17.82753104,0.428571429
"def __code_color(self, code):<tab>if code in self.last_dist.keys():<tab><tab><IF-STMT><tab><tab><tab>return self.screen.markup.GREEN<tab><tab>elif int(code) == 314:<tab><tab><tab>return self.screen.markup.MAGENTA<tab><tab>else:<tab><tab><tab>return self.screen.markup.RED<tab>else:<tab><tab>return """"",1,if int ( code ) == 0 :,if int ( code ) == 0 :,0.75,100,1
"def _calc_benchmark_stat(self, f):<tab>timer = Timer()<tab>i = 0<tab>while True:<tab><tab>f()<tab><tab>i += 1<tab><tab>if i >= self.min_run:<tab><tab><tab>_, elapsed = timer.lap()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return BenchmarkStat(elapsed / i, i)",0,if elapsed > self . min_time :,if elapsed >= self . max_run :,0.303129409,21.36435032,1
"def _get_user_call_site():<tab>import traceback<tab>stack = traceback.extract_stack(sys._getframe())<tab>for i in range(1, len(stack)):<tab><tab>callee_path = stack[i][STACK_FILE_NAME]<tab><tab><IF-STMT><tab><tab><tab>caller_path = stack[i - 1][STACK_FILE_NAME]<tab><tab><tab>caller_lineno = stack[i - 1][STACK_LINE_NUM]<tab><tab><tab>dpark_func_name = stack[i][STACK_FUNC_NAME]<tab><tab><tab>user_call_site = ""%s:%d "" % (caller_path, caller_lineno)<tab><tab><tab>return dpark_func_name, user_call_site<tab>return ""<func>"", "" <root>""",0,if src_dir == os . path . dirname ( os . path . abspath ( callee_path ) ) :,"if callee_path == """" :",0.005236645,4.584877553,0.3
"def compact_repr(record):<tab>parts = []<tab>for key in record.__attributes__:<tab><tab>value = getattr(record, key)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(value, list):<tab><tab><tab>value = HIDE_LIST<tab><tab>elif key == FEATS:<tab><tab><tab>value = format_feats(value)<tab><tab>else:<tab><tab><tab>value = repr(value)<tab><tab>value = capped_str(value)<tab><tab>parts.append(""%s=%s"" % (key, value))<tab>return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",0,if not value :,if value is None :,0.045150551,14.05853313,0.277777778
"def get_tools(self, found_files):<tab>self.configured_by = {}<tab>runners = []<tab>for tool_name in self.tools_to_run:<tab><tab>tool = tools.TOOLS[tool_name]()<tab><tab>config_result = tool.configure(self, found_files)<tab><tab><IF-STMT><tab><tab><tab>configured_by = None<tab><tab><tab>messages = []<tab><tab>else:<tab><tab><tab>configured_by, messages = config_result<tab><tab><tab>if messages is None:<tab><tab><tab><tab>messages = []<tab><tab>self.configured_by[tool_name] = configured_by<tab><tab>self.messages += messages<tab><tab>runners.append(tool)<tab>return runners",1,if config_result is None :,if config_result is None :,0.75,100,1
"def erase_previous(self):<tab>if self.prev:<tab><tab>length = len(self.prev)<tab><tab><IF-STMT><tab><tab><tab>length = length - 1<tab><tab>self.write("" "" * length + ""\r"")<tab><tab>self.prev = """"",0,"if self . prev [ - 1 ] in ( ""\n"" , ""\r"" ) :",if length > 1 :,0.00745897,0.573056795,0.272727273
"def __demo_mode_pause_if_active(self, tiny=False):<tab>if self.demo_mode:<tab><tab>wait_time = settings.DEFAULT_DEMO_MODE_TIMEOUT<tab><tab><IF-STMT><tab><tab><tab>wait_time = float(self.demo_sleep)<tab><tab>if not tiny:<tab><tab><tab>time.sleep(wait_time)<tab><tab>else:<tab><tab><tab>time.sleep(wait_time / 3.4)<tab>elif self.slow_mode:<tab><tab>self.__slow_mode_pause_if_active()",1,if self . demo_sleep :,if self . demo_sleep :,0.75,100,1
"def pack_remaining_length(remaining_length):<tab>s = """"<tab>while True:<tab><tab>byte = remaining_length % 128<tab><tab>remaining_length = remaining_length // 128<tab><tab># If there are more digits to encode, set the top bit of this digit<tab><tab>if remaining_length > 0:<tab><tab><tab>byte = byte | 0x80<tab><tab>s = s + struct.pack(""!B"", byte)<tab><tab><IF-STMT><tab><tab><tab>return s",1,if remaining_length == 0 :,if remaining_length == 0 :,0.75,100,1
"def _get_definitions(self, schema, query):<tab>results, error = self.run_query(query, None)<tab>if error is not None:<tab><tab>raise Exception(""Failed getting schema."")<tab>results = json_loads(results)<tab>for row in results[""rows""]:<tab><tab>if row[""TABLE_SCHEMA""] != ""public"":<tab><tab><tab>table_name = ""{}.{}"".format(row[""TABLE_SCHEMA""], row[""TABLE_NAME""])<tab><tab>else:<tab><tab><tab>table_name = row[""TABLE_NAME""]<tab><tab><IF-STMT><tab><tab><tab>schema[table_name] = {""name"": table_name, ""columns"": []}<tab><tab>schema[table_name][""columns""].append(row[""COLUMN_NAME""])",1,if table_name not in schema :,if table_name not in schema :,0.75,100,1
def _parsed_config_to_dict(config):<tab>config_dict = {}<tab>for section in config.keys():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>config_dict[section] = {}<tab><tab>for option in config[section].keys():<tab><tab><tab>config_dict[section][option] = config[section][option]<tab>return config_dict,0,"if section == ""DEFAULT"" :","if section . startswith ( ""_"" ) :",0.04979442,10.55267032,0.727272727
"def escape_string(self, value):<tab>value = EscapedString.promote(value)<tab>value = value.expanduser()<tab>result = """"<tab>for is_literal, txt in value.strings:<tab><tab>if is_literal:<tab><tab><tab>txt = pipes.quote(txt)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>txt = ""'%s'"" % txt<tab><tab>else:<tab><tab><tab>txt = txt.replace(""\\"", ""\\\\"")<tab><tab><tab>txt = txt.replace('""', '\\""')<tab><tab><tab>txt = '""%s""' % txt<tab><tab>result += txt<tab>return result",0,"if not txt . startswith ( ""'"" ) :",elif is_literal :,0.009312779,1.00E-10,0.128205128
"def sendMessage(self, text, meta=None):<tab>if self.account.client is None:<tab><tab>raise locals.OfflineError<tab>for line in text.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>self.account.client.ctcpMakeQuery(self.name, [(""ACTION"", line)])<tab><tab>else:<tab><tab><tab>self.account.client.msg(self.name, line)<tab>return succeed(text)",0,"if meta and meta . get ( ""style"" , None ) == ""emote"" :","if ""ACTION"" in line :",0.007888856,1.672612572,0.230263158
"def clean_email(self):<tab>email = self.cleaned_data.get(""email"")<tab>if self.instance.id:<tab><tab><IF-STMT><tab><tab><tab>if not User.objects.filter(email=self.cleaned_data.get(""email"")).exists():<tab><tab><tab><tab>return self.cleaned_data.get(""email"")<tab><tab><tab>raise forms.ValidationError(""Email already exists"")<tab><tab>else:<tab><tab><tab>return self.cleaned_data.get(""email"")<tab>else:<tab><tab>if not User.objects.filter(email=self.cleaned_data.get(""email"")).exists():<tab><tab><tab>return self.cleaned_data.get(""email"")<tab><tab>raise forms.ValidationError(""User already exists with this email"")",0,if self . instance . email != email :,if email in self . instance . email :,0.266643501,47.49549533,0.30952381
"def render_checks(cr, size, nchecks):<tab>""""""Render a checquerboard pattern to a cairo surface""""""<tab>cr.set_source_rgb(*gui.style.ALPHA_CHECK_COLOR_1)<tab>cr.paint()<tab>cr.set_source_rgb(*gui.style.ALPHA_CHECK_COLOR_2)<tab>for i in xrange(0, nchecks):<tab><tab>for j in xrange(0, nchecks):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>cr.rectangle(i * size, j * size, size, size)<tab><tab><tab>cr.fill()",0,if ( i + j ) % 2 == 0 :,if i == j :,0.055269805,7.859505257,0.642857143
"def seek(self, timestamp, log=True):<tab>""""""Seek to a particular timestamp in the movie.""""""<tab>if self.status in [PLAYING, PAUSED]:<tab><tab>player = self._player<tab><tab><IF-STMT><tab><tab><tab>player.set_time(int(timestamp * 1000.0))<tab><tab><tab>self._vlc_clock.reset(timestamp)<tab><tab><tab>if self.status == PAUSED:<tab><tab><tab><tab>self._pause_time = timestamp<tab><tab>if log:<tab><tab><tab>logAttrib(self, log, ""seek"", timestamp)",0,if player and player . is_seekable ( ) :,if player is not None :,0.13744821,8.389861811,0.365079365
"def class_results_to_node(key, elements):<tab>title = attributetabletitle(key, key)<tab>ul = nodes.bullet_list("""")<tab>for element in elements:<tab><tab>ref = nodes.reference(<tab><tab><tab>"""",<tab><tab><tab>"""",<tab><tab><tab>internal=True,<tab><tab><tab>refuri=""#"" + element.fullname,<tab><tab><tab>anchorname="""",<tab><tab><tab>*[nodes.Text(element.label)]<tab><tab>)<tab><tab>para = addnodes.compact_paragraph("""", """", ref)<tab><tab><IF-STMT><tab><tab><tab>ul.append(attributetable_item("""", element.badge, para))<tab><tab>else:<tab><tab><tab>ul.append(attributetable_item("""", para))<tab>return attributetablecolumn("""", title, ul)",0,if element . badge is not None :,if element . badge :,0.234334509,38.80684295,0.510204082
"def parse_function(self, l):<tab>bracket = l.find(""("")<tab>fname = l[8:bracket]<tab>if self.properties:<tab><tab>if self.properties[0] == ""propget"":<tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propget[fname] = 1<tab><tab><IF-STMT><tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propput[fname] = 1<tab><tab>else:<tab><tab><tab>self.functions[fname] = 1<tab>self.properties = None",1,"elif self . properties [ 0 ] == ""propput"" :","elif self . properties [ 0 ] == ""propput"" :",1,100,1
"def _slurp_from_queue(self, task_id, accept, limit=1000, no_ack=False):<tab>with self.app.pool.acquire_channel(block=True) as (_, channel):<tab><tab>binding = self._create_binding(task_id)(channel)<tab><tab>binding.declare()<tab><tab>for _ in range(limit):<tab><tab><tab>msg = binding.get(accept=accept, no_ack=no_ack)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield msg<tab><tab>else:<tab><tab><tab>raise self.BacklogLimitExceeded(task_id)",0,if not msg :,if msg is None :,0.045150551,14.05853313,0.277777778
"def analyse_text(text):<tab>if re.search(r""^\s*model\s*\{"", text, re.M):<tab><tab>if re.search(r""^\s*data\s*\{"", text, re.M):<tab><tab><tab>return 0.9<tab><tab><IF-STMT><tab><tab><tab>return 0.9<tab><tab>else:<tab><tab><tab>return 0.3<tab>else:<tab><tab>return 0",0,"elif re . search ( r""^\s*var"" , text , re . M ) :","elif re . search ( r""^\s*data\s*$"" , text , re . M ) :",0.791271145,71.78970818,1
"def wait_for_step(self, error_buffer=None, timeout=None):<tab># TODO: this might be cleaner using channels<tab>with self.cv:<tab><tab>start = time.time()<tab><tab>while True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>elif timeout is not None and time.time() - start > timeout:<tab><tab><tab><tab>raise error.Error(""No rewards received in {}s"".format(timeout))<tab><tab><tab>if error_buffer:<tab><tab><tab><tab>error_buffer.check()<tab><tab><tab>self.cv.wait(timeout=0.5)",0,if self . count != 0 :,if error_buffer is None :,0.022250825,6.770186229,0.265306122
"def TestDictAgainst(dict, check):<tab>for key, value in check.iteritems():<tab><tab><IF-STMT><tab><tab><tab>raise error(<tab><tab><tab><tab>""Indexing for '%s' gave the incorrect value - %s/%s""<tab><tab><tab><tab>% (repr(key), repr(dict[key]), repr(check[key]))<tab><tab><tab>)",0,if dict ( key ) != value :,"if not isinstance ( value , dict [ key ] ) :",0.018353598,5.508399197,0.408163265
"def callback(username, password, msg):<tab>self.add_channel()<tab>if hasattr(self, ""_closed"") and not self._closed:<tab><tab>self.attempted_logins += 1<tab><tab><IF-STMT><tab><tab><tab>msg += "" Disconnecting.""<tab><tab><tab>self.respond(""530 "" + msg)<tab><tab><tab>self.close_when_done()<tab><tab>else:<tab><tab><tab>self.respond(""530 "" + msg)<tab><tab>self.log(""USER '%s' failed login."" % username)<tab>self.on_login_failed(username, password)",0,if self . attempted_logins >= self . max_login_attempts :,if self . attempted_logins % 10 == 0 :,0.224761549,32.12486948,0.515151515
"def handle_disconnect(self):<tab>""""""Socket gets disconnected""""""<tab># signal disconnected terminal with control lines<tab>try:<tab><tab>self.serial.rts = False<tab><tab>self.serial.dtr = False<tab>finally:<tab><tab># restore original port configuration in case it was changed<tab><tab>self.serial.apply_settings(self.serial_settings_backup)<tab><tab># stop RFC 2217 state machine<tab><tab>self.rfc2217 = None<tab><tab># clear send buffer<tab><tab>self.buffer_ser2net = bytearray()<tab><tab># close network connection<tab><tab><IF-STMT><tab><tab><tab>self.socket.close()<tab><tab><tab>self.socket = None<tab><tab><tab>if self.log is not None:<tab><tab><tab><tab>self.log.warning(""{}: Disconnected"".format(self.device))",1,if self . socket is not None :,if self . socket is not None :,0.75,100,1
"def select_invitation_id_for_network(invitations, networkid, status=None):<tab># Get invitations based on network and maybe status<tab>invitationsfornetwork = []<tab>for invitation in invitations:<tab><tab><IF-STMT><tab><tab><tab>if status is None or invitation[""Status""] == status:<tab><tab><tab><tab>invitationsfornetwork.append(invitation[""InvitationId""])<tab>return invitationsfornetwork",0,"if invitation [ ""NetworkSummary"" ] [ ""Id"" ] == networkid :","if invitation [ ""NetworkId"" ] == networkid :",0.223804315,44.53868897,1
"def fit(self, refstring, subpipes):<tab>if not isinstance(subpipes, list):<tab><tab>subpipes = [subpipes]<tab>for subpipe in subpipes:<tab><tab><IF-STMT><tab><tab><tab>substring = subpipe.transform(None)<tab><tab>else:<tab><tab><tab>substring = subpipe<tab><tab>self._scores.append(<tab><tab><tab>(<tab><tab><tab><tab>self.base_aligner.fit_transform(refstring, substring, get_score=True),<tab><tab><tab><tab>subpipe,<tab><tab><tab>)<tab><tab>)<tab>return self",1,"if hasattr ( subpipe , ""transform"" ) :","if hasattr ( subpipe , ""transform"" ) :",0.75,100,1
"def build_priorities(self, _iter, priorities):<tab>while _iter is not None:<tab><tab><IF-STMT><tab><tab><tab>self.build_priorities(self.files_treestore.iter_children(_iter), priorities)<tab><tab>elif not self.files_treestore.get_value(_iter, 1).endswith(os.path.sep):<tab><tab><tab>priorities[<tab><tab><tab><tab>self.files_treestore.get_value(_iter, 3)<tab><tab><tab>] = self.files_treestore.get_value(_iter, 0)<tab><tab>_iter = self.files_treestore.iter_next(_iter)<tab>return priorities",0,if self . files_treestore . iter_has_child ( _iter ) :,if self . files_treestore . iter_children ( _iter ) :,0.580308871,70.04189911,1
"def __init__(self, fileobj, info):<tab>pages = []<tab>complete = False<tab>while not complete:<tab><tab>page = OggPage(fileobj)<tab><tab><IF-STMT><tab><tab><tab>pages.append(page)<tab><tab><tab>complete = page.complete or (len(page.packets) > 1)<tab>packets = OggPage.to_packets(pages)<tab>if not packets:<tab><tab>raise error(""Missing metadata packet"")<tab>data = packets[0][7:]<tab>super(OggTheoraCommentDict, self).__init__(data, framing=False)<tab>self._padding = len(data) - self._size",0,if page . serial == info . serial :,if page . info == info :,0.393392266,27.98263238,0.711111111
"def _run_interface(self, runtime):<tab>mel_icas = []<tab>for item in self.inputs.mel_icas_in:<tab><tab><IF-STMT><tab><tab><tab>mel_icas.append(item)<tab>if len(mel_icas) == 0:<tab><tab>raise Exception(<tab><tab><tab>""%s did not find any hand_labels_noise.txt files in the following directories: %s""<tab><tab><tab>% (self.__class__.__name__, mel_icas)<tab><tab>)<tab>return runtime",0,"if os . path . exists ( os . path . join ( item , ""hand_labels_noise.txt"" ) ) :","if ""hand_labels_noise.txt"" in item :",0.005236645,23.71641604,0.226851852
"def download_file(url, file):<tab>try:<tab><tab>xlog.info(""download %s to %s"", url, file)<tab><tab>req = opener.open(url)<tab><tab>CHUNK = 16 * 1024<tab><tab>with open(file, ""wb"") as fp:<tab><tab><tab>while True:<tab><tab><tab><tab>chunk = req.read(CHUNK)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>fp.write(chunk)<tab><tab>return True<tab>except:<tab><tab>xlog.info(""download %s to %s fail"", url, file)<tab><tab>return False",1,if not chunk :,if not chunk :,0.75,100,1
"def check_sales_order_on_hold_or_close(self, ref_fieldname):<tab>for d in self.get(""items""):<tab><tab>if d.get(ref_fieldname):<tab><tab><tab>status = frappe.db.get_value(""Sales Order"", d.get(ref_fieldname), ""status"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>frappe.throw(<tab><tab><tab><tab><tab>_(""Sales Order {0} is {1}"").format(d.get(ref_fieldname), status)<tab><tab><tab><tab>)",0,"if status in ( ""Closed"" , ""On Hold"" ) :","if status != ""Closed"" :",0.02693381,12.77945831,0.733333333
"def iterstack(sources, missing, trim, pad):<tab>its = [iter(t) for t in sources]<tab>hdrs = [next(it) for it in its]<tab>hdr = hdrs[0]<tab>n = len(hdr)<tab>yield tuple(hdr)<tab>for it in its:<tab><tab>for row in it:<tab><tab><tab>outrow = tuple(row)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>outrow = outrow[:n]<tab><tab><tab>if pad and len(outrow) < n:<tab><tab><tab><tab>outrow += (missing,) * (n - len(outrow))<tab><tab><tab>yield outrow",0,if trim :,if trim and len ( outrow ) > n :,0.078827156,1.00E-10,0.380952381
"def __call__(self, response_headers):<tab>rates = get_rates_from_response_headers(response_headers)<tab>if rates:<tab><tab>time.sleep(<tab><tab><tab>self._get_wait_time(<tab><tab><tab><tab>rates.short_usage,<tab><tab><tab><tab>rates.long_usage,<tab><tab><tab><tab>get_seconds_until_next_quarter(),<tab><tab><tab><tab>get_seconds_until_next_day(),<tab><tab><tab>)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.short_limit = rates.short_limit<tab><tab><tab>self.long_limit = rates.long_limit",0,if not self . force_limits :,if self . short_limit and self . long_limit :,0.041941062,7.768562846,0.381818182
"def main(self):<tab>self.model.clear()<tab>self.callman.unregister_all()<tab>active_handle = self.get_active(""Place"")<tab>if active_handle:<tab><tab>active = self.dbstate.db.get_place_from_handle(active_handle)<tab><tab><IF-STMT><tab><tab><tab>self.display_place(active, None, [active_handle], DateRange())<tab><tab>else:<tab><tab><tab>self.set_has_data(False)<tab>else:<tab><tab>self.set_has_data(False)",1,if active :,if active :,0.531170663,1.00E-10,1
"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab>if jid is None:<tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab>if node is None:<tab><tab><tab>node = """"<tab><tab><IF-STMT><tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab>ifrom = ifrom.full<tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",1,if ifrom is None :,if ifrom is None :,0.75,100,1
"def append_to(project_url, destination):<tab>url = (""%smagic/%s"" % (project_url, destination)).replace(""\\"", ""/"")<tab>response = urllib2.urlopen(url)<tab>if response.getcode() == 200:<tab><tab>with open(destination, ""r"") as dest:<tab><tab><tab>lines = """".join(dest.readlines())<tab><tab><tab>content = response.read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_out(""IGNORED"", destination)<tab><tab><tab><tab>return<tab><tab>with open(destination, ""a"") as dest:<tab><tab><tab>dest.write(content)<tab><tab><tab>print_out(""APPEND"", destination)",0,if content in lines :,if not lines :,0.070152444,27.53476575,0.277777778
"def close(self, invalidate=False):<tab>self.session.transaction = self._parent<tab>if self._parent is None:<tab><tab>for connection, transaction, autoclose in set(self._connections.values()):<tab><tab><tab>if invalidate:<tab><tab><tab><tab>connection.invalidate()<tab><tab><tab>if autoclose:<tab><tab><tab><tab>connection.close()<tab><tab><tab>else:<tab><tab><tab><tab>transaction.close()<tab>self._state = CLOSED<tab>self.session.dispatch.after_transaction_end(self.session, self)<tab>if self._parent is None:<tab><tab><IF-STMT><tab><tab><tab>self.session.begin()<tab>self.session = None<tab>self._connections = None",0,if not self . session . autocommit :,if self . session . begin ( ) :,0.180782771,33.03164318,0.26984127
"def list_local_packages(path):<tab>""""""Lists all local packages below a path that could be installed.""""""<tab>rv = []<tab>try:<tab><tab>for filename in os.listdir(path):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.append(""@"" + filename)<tab>except OSError:<tab><tab>pass<tab>return rv",0,"if os . path . isfile ( os . path . join ( path , filename , ""setup.py"" ) ) :","if os . path . isfile ( os . path . join ( path , filename ) ) :",0.720908347,66.14772391,1
"def walk_dir(templates, dest, filter=None):<tab>l = []<tab>for root, folders, files in os.walk(templates):<tab><tab>for filename in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>relative_dir = "".{0}"".format(<tab><tab><tab><tab>os.path.split(os.path.join(root, filename).replace(templates, """"))[0]<tab><tab><tab>)<tab><tab><tab>l.append((os.path.join(root, filename), os.path.join(dest, relative_dir)))<tab>return l",0,"if filename . endswith ( "".pyc"" ) or ( filter and filename not in filter ) :",if filter and filter ( filename ) :,0.018754178,4.144655666,0.192982456
"def selectItemHelper(self, item, scroll):<tab>if self.frame.lockout:<tab><tab>return<tab>w = self.treeWidget<tab>if item and item.IsOk():<tab><tab>self.frame.lockout = True<tab><tab>try:<tab><tab><tab>w.SelectItem(item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>w.ScrollTo(item)<tab><tab>finally:<tab><tab><tab>self.frame.lockout = False",1,if scroll :,if scroll :,0.531170663,1.00E-10,1
"def validate_external(self, field):<tab>if hasattr(self, ""forum""):<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""You cannot convert a forum that ""<tab><tab><tab><tab><tab>""contains topics into an ""<tab><tab><tab><tab><tab>""external link.""<tab><tab><tab><tab>)<tab><tab><tab>)",0,if self . forum . topics . count ( ) > 0 :,if not self . forum . topics :,0.157585055,30.0999621,0.241666667
"def add_help(self):<tab>""Attach help functions for each of the parsed token handlers.""<tab>for attrname, func in list(shell.BQLShell.__dict__.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>command_name = attrname[3:]<tab><tab>setattr(<tab><tab><tab>self.__class__,<tab><tab><tab>""help_{}"".format(command_name.lower()),<tab><tab><tab>lambda _, fun=func: print(<tab><tab><tab><tab>textwrap.dedent(fun.__doc__).strip(), file=self.outfile<tab><tab><tab>),<tab><tab>)",0,"if attrname [ : 3 ] != ""on_"" :","if not attrname . startswith ( ""help_"" ) :",0.016784919,8.201060181,0.318181818
"def createFields(self):<tab>yield UInt8(self, ""tag"")<tab>yield UInt24(self, ""size"", ""Content size"")<tab>yield UInt24(self, ""timestamp"", ""Timestamp in millisecond"")<tab>yield NullBytes(self, ""reserved"", 4)<tab>size = self[""size""].value<tab>if size:<tab><tab><IF-STMT><tab><tab><tab>for field in self.parser(self, size):<tab><tab><tab><tab>yield field<tab><tab>else:<tab><tab><tab>yield RawBytes(self, ""content"", size)",1,if self . parser :,if self . parser :,0.75,100,1
"def migrate_model_field_data(Model):<tab>queryset = Model.objects.all().order_by(""pk"")<tab>for batch_pks in queryset_in_batches(queryset):<tab><tab>instances = []<tab><tab>batch = Model.objects.filter(pk__in=batch_pks)<tab><tab>for instance in batch:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>instance.content_json = parse_to_editorjs(instance.content_json)<tab><tab><tab><tab>instances.append(instance)<tab><tab>Model.objects.bulk_update(instances, [""content_json""])",1,if instance . content_json :,if instance . content_json :,0.75,100,1
"def _add_account(cfg, which):<tab>username = self._get_account(cfg)<tab>if (<tab><tab>username<tab><tab>and ((username == only) or only is None)<tab><tab>and cfg.auth_type == ""password""<tab>):<tab><tab><IF-STMT><tab><tab><tab>accounts[username][which] = cfg.host<tab><tab>else:<tab><tab><tab>fingerprint = self._user_fingerprint(username)<tab><tab><tab>accounts[username] = {<tab><tab><tab><tab>which: cfg.host,<tab><tab><tab><tab>""username"": username,<tab><tab><tab><tab>""policy"": self._get_policy(fingerprint),<tab><tab><tab>}<tab><tab><tab>if accounts[username][""policy""] is None:<tab><tab><tab><tab>del accounts[username][""policy""]",1,if username in accounts :,if username in accounts :,0.75,100,1
"def update_msg_tags(self, msg_idx_pos, msg_info):<tab>tags = set(self.get_tags(msg_info=msg_info))<tab>with self._lock:<tab><tab>for tid in set(self.TAGS.keys()) - tags:<tab><tab><tab>self.TAGS[tid] -= set([msg_idx_pos])<tab><tab>for tid in tags:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.TAGS[tid] = set()<tab><tab><tab>self.TAGS[tid].add(msg_idx_pos)",0,if tid not in self . TAGS :,if tid not in self .TAGS :,0.528331023,100,0.828571429
"def close(self, reason=""protocol closed, reason unspecified""):<tab>if self.connection:<tab><tab>self.logger.debug(reason, self.connection.session())<tab><tab># must be first otherwise we could have a loop caused by the raise in the below<tab><tab>self.connection.close()<tab><tab>self.connection = None<tab><tab>self.peer.stats[""down""] = self.peer.stats.get(""down"", 0) + 1<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.peer.reactor.processes.down(self.peer.neighbor, reason)<tab><tab>except ProcessError:<tab><tab><tab>self.logger.debug(<tab><tab><tab><tab>""could not send notification of neighbor close to API"",<tab><tab><tab><tab>self.connection.session(),<tab><tab><tab>)",0,"if self . peer . neighbor . api [ ""neighbor-changes"" ] :",if self . peer . reactor . processes :,0.176793542,27.85525648,0.5
"def check_objects_exist(self, compare_id, raise_exc=True):<tab>for uid in convert_compare_id_to_list(compare_id):<tab><tab><IF-STMT><tab><tab><tab>if raise_exc:<tab><tab><tab><tab>raise FactCompareException(""{} not found in database"".format(uid))<tab><tab><tab>return True<tab>return False",0,if not self . existence_quick_check ( uid ) :,if uid not in self . objects :,0.096848431,7.780436171,0.25
"def on_double_click(self, event):<tab># self.save_current_folder()<tab>path = self.get_selected_path()<tab>if path:<tab><tab>kind = self.get_selected_kind()<tab><tab><IF-STMT><tab><tab><tab>self.focus_into(path)<tab><tab>else:<tab><tab><tab>self.log_frame.load_log(path)<tab>return ""break""  # avoid default action of opening the node",0,"if kind == ""dir"" :","if kind == ""focus"" :",0.394778655,59.46035575,1
"def resolve_cloudtrail_payload(self, payload):<tab>sources = self.data.get(""sources"", [])<tab>events = []<tab>for e in self.data.get(""events""):<tab><tab><IF-STMT><tab><tab><tab>events.append(e)<tab><tab><tab>event_info = CloudWatchEvents.get(e)<tab><tab><tab>if event_info is None:<tab><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>event_info = e<tab><tab><tab>events.append(e[""event""])<tab><tab>sources.append(event_info[""source""])<tab>payload[""detail""] = {""eventSource"": list(set(sources)), ""eventName"": events}",0,"if not isinstance ( e , dict ) :","if isinstance ( e , CloudtrailEvent ) :",0.18845666,37.70794597,0.26984127
"def load_graph_session_from_ckpt(ckpt_path, sess_config, print_op=False):<tab>""""""load graph and session from checkpoint file""""""<tab>graph = tf.Graph()<tab>with graph.as_default():  # pylint: disable=not-context-manager<tab><tab>sess = get_session(sess_config)<tab><tab>with sess.as_default():  # pylint: disable=not-context-manager<tab><tab><tab># Load the saved meta graph and restore variables<tab><tab><tab>saver = tf.train.import_meta_graph(""{}.meta"".format(ckpt_path))<tab><tab><tab>saver.restore(sess, ckpt_path)<tab><tab><IF-STMT><tab><tab><tab>print_ops(graph, prefix=""load_graph_session_from_ckpt"")<tab>return graph, sess",1,if print_op :,if print_op :,0.531170663,1.00E-10,1
"def _parseConfigFile(self, iniPath, createConfig=True):<tab>parser = SafeConfigParserUnicode(strict=False)<tab>if not os.path.isfile(iniPath):<tab><tab>if createConfig:<tab><tab><tab>open(iniPath, ""w"").close()<tab><tab>else:<tab><tab><tab>return<tab>parser.readfp(codecs.open(iniPath, ""r"", ""utf_8_sig""))<tab>for section, options in list(self._iniStructure.items()):<tab><tab>if parser.has_section(section):<tab><tab><tab>for option in options:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._config[option] = parser.get(section, option)",1,"if parser . has_option ( section , option ) :","if parser . has_option ( section , option ) :",0.75,100,1
"def parse(self):<tab>while 1:<tab><tab>l = self.f.readline()<tab><tab>if not l:<tab><tab><tab>return<tab><tab>l = l.strip()<tab><tab>if l.startswith(""[""):<tab><tab><tab>self.parse_uuid(l)<tab><tab><IF-STMT><tab><tab><tab>self.parse_interface(l)<tab><tab>elif l.startswith(""coclass""):<tab><tab><tab>self.parse_coclass(l)",0,"elif l . startswith ( ""interface"" ) or l . startswith ( ""dispinterface"" ) :","elif l . startswith ( ""interface"" ) :",0.406214813,39.119948,0.638095238
"def encode(self):<tab>if not isinstance(self.expr, m2_expr.ExprInt):<tab><tab>return False<tab>if not test_set_sf(self.parent, self.expr.size):<tab><tab>return False<tab>value = int(self.expr)<tab>if value < 1 << self.l:<tab><tab>self.parent.shift.value = 0<tab>else:<tab><tab>if value & 0xFFF:<tab><tab><tab>return False<tab><tab>value >>= 12<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.parent.shift.value = 1<tab>self.value = value<tab>return True",0,if value >= 1 << self . l :,if not ( value & 0x80 ) :,0.016959991,4.995138898,0.236111111
"def _func_runner(self):<tab>_locals.thread = self<tab>try:<tab><tab>self._final_result = self.target(*self.args, **self.kwargs)<tab><tab>self._final_exc = None<tab>except BaseException as e:<tab><tab>self._final_result = None<tab><tab>self._final_exc = e<tab><tab><IF-STMT><tab><tab><tab>log.warning(""Unexpected exception in cancelled async thread"", exc_info=True)<tab>finally:<tab><tab>self._request.set_result(None)",0,"if not isinstance ( e , errors . CancelledError ) :",if self . _cancelled :,0.012417879,4.642454187,0.214285714
"def _set_dialect(self, value):<tab>if value is None:<tab><tab>self._dialect = mac_eui48<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._dialect = value<tab><tab>else:<tab><tab><tab>raise TypeError(""custom dialects should subclass mac_eui48!"")",0,"if hasattr ( value , ""word_size"" ) and hasattr ( value , ""word_fmt"" ) :","if isinstance ( value , mac_eui48 ) :",0.041907392,5.8224647,0.420634921
"def fixup_namespace_packages(path_item, parent=None):<tab>""""""Ensure that previously-declared namespace packages include path_item""""""<tab>imp.acquire_lock()<tab>try:<tab><tab>for package in _namespace_packages.get(parent, ()):<tab><tab><tab>subpath = _handle_ns(package, path_item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fixup_namespace_packages(subpath, package)<tab>finally:<tab><tab>imp.release_lock()",0,if subpath :,if subpath is not None :,0.090364769,1.00E-10,0.4
"def close_file_descriptor(self, fd):<tab>""""""Attempt to close a file descriptor.""""""<tab>start_timer = time.time()<tab>error = """"<tab>while True:<tab><tab>try:<tab><tab><tab>fd.close()<tab><tab><tab>break<tab><tab>except OSError as e:<tab><tab><tab># Undoubtedly close() was called during a concurrent operation on the same file object.<tab><tab><tab>log.debug(""Error closing file descriptor: %s"" % str(e))<tab><tab><tab>time.sleep(0.5)<tab><tab><tab>current_wait_time = time.time() - start_timer<tab><tab><tab><IF-STMT><tab><tab><tab><tab>error = ""Error closing file descriptor: %s"" % str(e)<tab><tab><tab><tab>break<tab>return error",0,if current_wait_time >= 600 :,if current_wait_time > MAX_WAIT_TIME :,0.064978772,48.63383168,0.619047619
"def p_constant(self, p):<tab>""""""constant : PP_NUMBER""""""<tab>value = p[1].rstrip(""LlUu"")<tab>try:<tab><tab>if value[:2] == ""0x"":<tab><tab><tab>value = int(value[2:], 16)<tab><tab><IF-STMT><tab><tab><tab>value = int(value, 8)<tab><tab>else:<tab><tab><tab>value = int(value)<tab>except ValueError:<tab><tab>value = value.rstrip(""eEfF"")<tab><tab>try:<tab><tab><tab>value = float(value)<tab><tab>except ValueError:<tab><tab><tab>value = 0<tab>p[0] = ConstantExpressionNode(value)",0,"elif value [ 0 ] == ""0"" :","elif value [ : 2 ] == ""0x"" :",0.584279689,34.17233408,0.6
"def set_add_delete_state(self):<tab>""Toggle the state for the help list buttons based on list entries.""<tab>if self.helplist.size() < 1:  # No entries in list.<tab><tab>self.button_helplist_edit.state((""disabled"",))<tab><tab>self.button_helplist_remove.state((""disabled"",))<tab>else:  # Some entries.<tab><tab><IF-STMT>  # There currently is a selection.<tab><tab><tab>self.button_helplist_edit.state((""!disabled"",))<tab><tab><tab>self.button_helplist_remove.state((""!disabled"",))<tab><tab>else:  # There currently is not a selection.<tab><tab><tab>self.button_helplist_edit.state((""disabled"",))<tab><tab><tab>self.button_helplist_remove.state((""disabled"",))",0,if self . helplist . curselection ( ) :,if self . helplist . size ( ) == 1 :,0.388257233,37.70063805,0.56043956
def _erase_status():<tab>CodeintelHandler.status_lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>view.erase_status(lid)<tab><tab><tab>CodeintelHandler.status_msg[lid][1] = None<tab><tab><tab>if lid in CodeintelHandler.status_lineno:<tab><tab><tab><tab>del CodeintelHandler.status_lineno[lid]<tab>finally:<tab><tab>CodeintelHandler.status_lock.release(),0,"if msg == CodeintelHandler . status_msg . get ( lid , [ None , None , 0 ] ) [ 1 ] :",if lid in CodeintelHandler . status_msg :,0.073801238,7.591818891,0.184848485
"def PARSE_TWO_PARAMS(x, y):<tab>""""""used to convert different possible x/y params to a tuple""""""<tab>if y is not None:<tab><tab>return (x, y)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return (x[0], x[1])<tab><tab>else:<tab><tab><tab>if isinstance(x, UNIVERSAL_STRING):<tab><tab><tab><tab>x = x.strip()<tab><tab><tab><tab>if "","" in x:<tab><tab><tab><tab><tab>return [int(w.strip()) for w in x.split("","")]<tab><tab><tab>return (x, x)",0,"if isinstance ( x , ( list , tuple ) ) :","if isinstance ( x , tuple ) :",0.222424677,43.58579201,0.655555556
"def cancel_spot_fleet_requests(self, spot_fleet_request_ids, terminate_instances):<tab>spot_requests = []<tab>for spot_fleet_request_id in spot_fleet_request_ids:<tab><tab>spot_fleet = self.spot_fleet_requests[spot_fleet_request_id]<tab><tab><IF-STMT><tab><tab><tab>spot_fleet.target_capacity = 0<tab><tab><tab>spot_fleet.terminate_instances()<tab><tab>spot_requests.append(spot_fleet)<tab><tab>del self.spot_fleet_requests[spot_fleet_request_id]<tab>return spot_requests",1,if terminate_instances :,if terminate_instances :,0.531170663,1.00E-10,1
"def pop(self, key, default=_MISSING):<tab># NB: hit/miss counts are bypassed for pop()<tab>with self._lock:<tab><tab>try:<tab><tab><tab>ret = super(LRI, self).pop(key)<tab><tab>except KeyError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>ret = default<tab><tab>else:<tab><tab><tab>self._remove_from_ll(key)<tab><tab>return ret",1,if default is _MISSING :,if default is _MISSING :,0.75,100,1
"def _remove_optional_none_type_hints(self, type_hints, defaults):<tab># If argument has None as a default, typing.get_type_hints adds<tab># optional None to the information it returns. We don't want that.<tab>for arg in defaults:<tab><tab>if defaults[arg] is None and arg in type_hints:<tab><tab><tab>type_ = type_hints[arg]<tab><tab><tab>if self._is_union(type_):<tab><tab><tab><tab>types = type_.__args__<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>type_hints[arg] = types[0]",0,if len ( types ) == 2 and types [ 1 ] is type ( None ) :,if len ( types ) == 1 :,0.180755458,25.4484343,0.339393939
"def reader(self, myself):<tab>ok = True<tab>line = """"<tab>while True:<tab><tab>line = sys.stdin.readline().strip()<tab><tab>if ok:<tab><tab><tab>if not line:<tab><tab><tab><tab>ok = False<tab><tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.Q.append(line)<tab>os.kill(myself, signal.SIGTERM)",0,elif not line :,"elif line == """" :",0.04267767,8.643019616,0.45
"def checkout_branch(self, branch):<tab>if branch in self.remote_branches:<tab><tab>sickrage.app.log.debug(<tab><tab><tab>""Branch checkout: "" + self._find_installed_version() + ""->"" + branch<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab># remove untracked files and performs a hard reset on git branch to avoid update issues<tab><tab>if sickrage.app.config.git_reset:<tab><tab><tab>self.reset()<tab><tab># fetch all branches<tab><tab>self.fetch()<tab><tab>__, __, exit_status = self._git_cmd(self._git_path, ""checkout -f "" + branch)<tab><tab>if exit_status == 0:<tab><tab><tab>return True<tab>return False",0,if not self . install_requirements ( self . current_branch ) :,if not self . remote_branches [ branch ] :,0.12965657,18.75883058,0.733333333
"def last_ok(nodes):<tab>for i in range(len(nodes) - 1, -1, -1):<tab><tab>if ok_node(nodes[i]):<tab><tab><tab>node = nodes[i]<tab><tab><tab>if isinstance(node, ast.Starred):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return node.value<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>return nodes[i]<tab>return None",0,if ok_node ( node . value ) :,if node . value is not None :,0.079919566,18.19037114,0.510204082
"def restart():<tab>""""""Restart application.""""""<tab>popen_list = [sys.executable, app.MY_FULLNAME]<tab>if not app.NO_RESTART:<tab><tab>popen_list += app.MY_ARGS<tab><tab><IF-STMT><tab><tab><tab>popen_list += [""--nolaunch""]<tab><tab>logger.info(""Restarting Medusa with {options}"", options=popen_list)<tab><tab># shutdown the logger to make sure it's released the logfile BEFORE it restarts Medusa.<tab><tab>logging.shutdown()<tab><tab>print(popen_list)<tab><tab>subprocess.Popen(popen_list, cwd=os.getcwd())",0,"if ""--nolaunch"" not in popen_list :","if ""--nolaunch"" in popen_list :",0.133190283,66.90484409,0.464285714
"def StopBackgroundWorkload(self):<tab>""""""Stop the background workoad.""""""<tab>for workload in background_workload.BACKGROUND_WORKLOADS:<tab><tab>if workload.IsEnabled(self):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise NotImplementedError()<tab><tab><tab>workload.Stop(self)",0,if self . OS_TYPE in workload . EXCLUDED_OS_TYPES :,if not workload . IsRunning ( self ) :,0.032785198,6.155947439,0.26984127
"def __init__(self, token):<tab>self._convert_to_ascii = False<tab>self._find = None<tab>if token.search is None:<tab><tab>return<tab>flags = 0<tab>self._match_this_many = 1<tab>if token.options:<tab><tab>if ""g"" in token.options:<tab><tab><tab>self._match_this_many = 0<tab><tab><IF-STMT><tab><tab><tab>flags |= re.IGNORECASE<tab><tab>if ""a"" in token.options:<tab><tab><tab>self._convert_to_ascii = True<tab>self._find = re.compile(token.search, flags | re.DOTALL)<tab>self._replace = _CleverReplace(token.replace)",0,"if ""i"" in token . options :","if token . options . startswith ( ""a"" ) :",0.077712302,15.5801057,0.333333333
"def _draw_nodes(self, cr, bounding, highlight_items):<tab>highlight_nodes = []<tab>for element in highlight_items:<tab><tab><IF-STMT><tab><tab><tab>highlight_nodes.append(element.src)<tab><tab><tab>highlight_nodes.append(element.dst)<tab><tab>else:<tab><tab><tab>highlight_nodes.append(element)<tab>for node in self.nodes:<tab><tab>if bounding is None or node._intersects(bounding):<tab><tab><tab>node._draw(cr, highlight=(node in highlight_nodes), bounding=bounding)",0,"if isinstance ( element , Edge ) :",if bounding is None or element . _intersects ( bounding ) :,0.03064982,7.768562846,0.196581197
"def _removeCachedRFInfo(self, cache_key, path, removeChildPaths):<tab>log.debug(""_removeCachedRFInfo: cache_key %r, path %r"", cache_key, path)<tab>if self._cachedFiles.has_key(cache_key):<tab><tab>cache = self._cachedFiles[cache_key]<tab><tab>if cache.has_key(path):<tab><tab><tab>del cache[path]<tab><tab><IF-STMT><tab><tab><tab># Remove all cached paths that are under this directory<tab><tab><tab>from remotefilelib import addslash<tab><tab><tab>dirPath = addslash(path)<tab><tab><tab>for keypath in cache.keys():<tab><tab><tab><tab>if keypath.startswith(dirPath):<tab><tab><tab><tab><tab>del cache[keypath]",1,if removeChildPaths :,if removeChildPaths :,0.531170663,1.00E-10,1
"def write_row(xf, worksheet, row, row_idx, max_column):<tab>attrs = {""r"": ""%d"" % row_idx, ""spans"": ""1:%d"" % max_column}<tab>dims = worksheet.row_dimensions<tab>if row_idx in dims:<tab><tab>row_dimension = dims[row_idx]<tab><tab>attrs.update(dict(row_dimension))<tab>with xf.element(""row"", attrs):<tab><tab>for col, cell in row:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>el = write_cell(xf, worksheet, cell, cell.has_style)",0,if cell . _value is None and not cell . has_style and not cell . _comment :,if col in dims :,0.112861066,0.517815268,0.17
"def reset_feature_range(data, column_max_value, column_min_value, scale_column_idx):<tab>_data = copy.deepcopy(data)<tab>for i in scale_column_idx:<tab><tab>value = _data.features[i]<tab><tab><IF-STMT><tab><tab><tab>_data.features[i] = column_max_value[i]<tab><tab>elif value < column_min_value[i]:<tab><tab><tab>_data.features[i] = column_min_value[i]<tab>return _data",1,if value > column_max_value [ i ] :,if value > column_max_value [ i ] :,0.75,100,1
"def test_listing_all_frameworks_and_check_frameworks_by_order(self):<tab>""""""List all frameworks and check if frameworks appear by order""""""<tab>result = subprocess.check_output(self.command_as_list([UMAKE, ""--list""]))<tab>previous_framework = None<tab>for element in result.split(b""\n""):<tab><tab>if element.startswith(b""\t""):<tab><tab><tab>current_framework = element[: element.find(b"":"")]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.assertTrue(previous_framework < current_framework)<tab><tab><tab>previous_framework = current_framework<tab><tab>else:<tab><tab><tab>previous_framework = None",0,if previous_framework :,if previous_framework is not None :,0.090364769,1.00E-10,0.314285714
"def merge(module_name, tree1, tree2):<tab>for child in tree2.node:<tab><tab><IF-STMT><tab><tab><tab>replaceFunction(tree1, child.name, child)<tab><tab>elif isinstance(child, ast.Assign):<tab><tab><tab>replaceAssign(tree1, child.nodes[0].name, child)<tab><tab>elif isinstance(child, ast.Class):<tab><tab><tab>replaceClassMethods(tree1, child.name, child)<tab><tab>else:<tab><tab><tab>raise TranslationError(<tab><tab><tab><tab>""Do not know how to merge %s"" % child, child, module_name<tab><tab><tab>)<tab>return tree1",1,"if isinstance ( child , ast . Function ) :","if isinstance ( child , ast . Function ) :",0.75,100,1
def _filter_supported_drivers():<tab>global supported_drivers<tab>with Env() as gdalenv:<tab><tab>ogrdrv_names = gdalenv.drivers().keys()<tab><tab>supported_drivers_copy = supported_drivers.copy()<tab><tab>for drv in supported_drivers.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del supported_drivers_copy[drv]<tab>supported_drivers = supported_drivers_copy,0,if drv not in ogrdrv_names :,if drv in ogrdrv_names :,0.233190283,61.29752414,0.56
"def serialize(self, cassette_dict):<tab>for interaction in cassette_dict[""interactions""]:<tab><tab>response = interaction[""response""]<tab><tab>headers = response[""headers""]<tab><tab><IF-STMT><tab><tab><tab>rg, size, filename = self._parse_headers(headers)<tab><tab><tab>content = response[""body""][""string""]<tab><tab><tab>if rg[0] == 0 and rg[1] + 1 == size:<tab><tab><tab><tab>with open(join(self.directory, filename), ""wb"") as f:<tab><tab><tab><tab><tab>f.write(content)<tab><tab><tab>del response[""body""][""string""]<tab>return self.base_serializer.serialize(cassette_dict)",0,"if ""Content-Range"" in headers and ""Content-Disposition"" in headers :",if headers :,0.024814633,1.00E-10,0.32
"def verify_software_token(self, access_token, user_code):<tab>for user_pool in self.user_pools.values():<tab><tab>if access_token in user_pool.access_tokens:<tab><tab><tab>_, username = user_pool.access_tokens[access_token]<tab><tab><tab>user = user_pool.users.get(username)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise UserNotFoundError(username)<tab><tab><tab>user.token_verified = True<tab><tab><tab>return {""Status"": ""SUCCESS""}<tab>else:<tab><tab>raise NotAuthorizedError(access_token)",0,if not user :,if user . code != user_code :,0.038340903,5.522397784,0.4
"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab><IF-STMT><tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if start is None:<tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab>elif key[:4] == ""end_"":<tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if end is None:<tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)",1,"if key [ : 6 ] == ""start_"" :","if key [ : 6 ] == ""start_"" :",0.75,100,1
"def generate_playlist(sourcefile):<tab>""""""Generate a playlist from video titles in sourcefile""""""<tab># Hooks into this, check if the argument --description is present<tab>if ""--description"" in sourcefile or ""-d"" in sourcefile:<tab><tab>description_generator(sourcefile)<tab><tab>return<tab>expanded_sourcefile = path.expanduser(sourcefile)<tab>if not check_sourcefile(expanded_sourcefile):<tab><tab>g.message = util.F(""mkp empty"") % expanded_sourcefile<tab>else:<tab><tab>queries = read_sourcefile(expanded_sourcefile)<tab><tab>g.message = util.F(""mkp parsed"") % (len(queries), sourcefile)<tab><tab><IF-STMT><tab><tab><tab>create_playlist(queries)<tab><tab><tab>g.message = util.F(""pl help"")<tab><tab><tab>g.content = content.playlists_display()",1,if queries :,if queries :,0.531170663,1.00E-10,1
"def flush(self):<tab>for record in self._unique_ordered_records:<tab><tab>record.message = self._format_string.format(<tab><tab><tab>message=record.message, count=self._message_to_count[record.message]<tab><tab>)<tab><tab># record.dispatcher is the logger who created the message,<tab><tab># it's sometimes supressed (by logbook.info for example)<tab><tab><IF-STMT><tab><tab><tab>dispatch = record.dispatcher.call_handlers<tab><tab>else:<tab><tab><tab>dispatch = dispatch_record<tab><tab>dispatch(record)<tab>self.clear()",0,if record . dispatcher is not None :,if record . dispatcher :,0.234334509,38.80684295,0.510204082
"def __init__(self, name, contents):<tab>self.name = name<tab>self.all_entries = []<tab>self.attr = []<tab>self.child = []<tab>self.seq_child = []<tab>for entry in contents:<tab><tab>clean_entry = entry.rstrip(""*"")<tab><tab>self.all_entries.append(clean_entry)<tab><tab><IF-STMT><tab><tab><tab>self.seq_child.append(clean_entry)<tab><tab>elif entry.endswith(""*""):<tab><tab><tab>self.child.append(clean_entry)<tab><tab>else:<tab><tab><tab>self.attr.append(entry)",0,"if entry . endswith ( ""**"" ) :","if entry . endswith ( ""*"" ) :",0.549040681,80.4526875,1
"def test_empty_condition_node(cond_node):<tab>for node in [cond_node.true_node, cond_node.false_node]:<tab><tab>if node is None:<tab><tab><tab>continue<tab><tab>if type(node) is CodeNode and BaseNode.test_empty_node(node.node):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>return False<tab>return True",0,if BaseNode . test_empty_node ( node ) :,"if type ( node ) is TupleNode and node . node . value in ( ""true"" , ""false"" ) :",0.124618938,8.010360497,0.224074074
"def test_deprecated_format_string(obj, fmt_str, should_raise_warning):<tab>if sys.version_info[0] == 3 and sys.version_info[1] >= 4:<tab><tab><IF-STMT><tab><tab><tab>self.assertRaises(TypeError, format, obj, fmt_str)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>format(obj, fmt_str)<tab><tab><tab>except TypeError:<tab><tab><tab><tab>self.fail(""object.__format__ raised TypeError unexpectedly"")<tab>else:<tab><tab>with warnings.catch_warnings(record=True) as w:<tab><tab><tab>warnings.simplefilter(""always"", DeprecationWarning)<tab><tab><tab>format(obj, fmt_str)",1,if should_raise_warning :,if should_raise_warning :,0.531170663,1.00E-10,1
"def get_queryset(self):<tab>if self.queryset is not None:<tab><tab>return self.queryset._clone()<tab>elif self.model is not None:<tab><tab>qs = self.model._default_manager<tab><tab><IF-STMT><tab><tab><tab>access_class = access_registry[self.model]<tab><tab><tab>if access_class.select_related:<tab><tab><tab><tab>qs = qs.select_related(*access_class.select_related)<tab><tab><tab>if access_class.prefetch_related:<tab><tab><tab><tab>qs = qs.prefetch_related(*access_class.prefetch_related)<tab><tab>return qs<tab>else:<tab><tab>return super(GenericAPIView, self).get_queryset()",1,if self . model in access_registry :,if self . model in access_registry :,0.75,100,1
"def ping_task():<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if peer not in self._protocol.routing_table.get_peers():<tab><tab><tab><tab>self._protocol.add_peer(peer)<tab><tab><tab>return<tab><tab>await self._protocol.get_rpc_peer(peer).ping()<tab>except (asyncio.TimeoutError, RemoteException):<tab><tab>pass",0,if self . _protocol . peer_manager . peer_is_good ( peer ) :,if self . _protocol . routing_table . get_peers ( ) :,0.280452022,31.09048972,0.736842105
"def _validate_usage(schema_argument, variable_used):<tab>if isinstance(schema_argument.gql_type, GraphQLNonNull) and not isinstance(<tab><tab>variable_used.type, NonNullTypeNode<tab>):<tab><tab>has_variable_a_df = not isinstance(<tab><tab><tab>variable_used.default_value, (NullValueNode, type(None))<tab><tab>)<tab><tab>has_argument_a_df = schema_argument.default_value is not None<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>return _validate_type_compatibility(<tab><tab><tab>variable_used.type, schema_argument.gql_type.gql_type<tab><tab>)<tab>return _validate_type_compatibility(variable_used.type, schema_argument.gql_type)",0,if not has_variable_a_df and not has_argument_a_df :,if has_variable_a_df :,0.021851197,1.00E-10,0.416666667
"def _add_kid(key, x):<tab>if x is None:<tab><tab>kids[key] = None<tab>else:<tab><tab>if type(x) in (type([]), type(())):<tab><tab><tab>x1 = [i for i in x if isinstance(i, TVTKBase)]<tab><tab><tab>if x1:<tab><tab><tab><tab>kids[key] = x1<tab><tab>elif isinstance(x, TVTKBase):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Don't add iterable objects that contain non<tab><tab><tab><tab># acceptable nodes<tab><tab><tab><tab>if len(list(x)) and isinstance(list(x)[0], TVTKBase):<tab><tab><tab><tab><tab>kids[key] = x<tab><tab><tab>else:<tab><tab><tab><tab>kids[key] = x",0,"if hasattr ( x , ""__iter__"" ) :",if type ( x ) == type ( [ ] ) :,0.036448984,8.554426802,0.588235294
"def postCreate(node, menu):<tab>with node.scriptNode().context():<tab><tab><IF-STMT><tab><tab><tab>cropFormat = node[""in""][""format""].getValue()<tab><tab>else:<tab><tab><tab>cropFormat = GafferImage.FormatPlug.getDefaultFormat(<tab><tab><tab><tab>node.scriptNode().context()<tab><tab><tab>)<tab>node[""area""].setValue(cropFormat.getDisplayWindow())",1,"if node [ ""in"" ] . getInput ( ) :","if node [ ""in"" ] . getInput ( ) :",0.75,100,1
"def normalize_stroke(stroke):<tab>letters = set(stroke)<tab>if letters & _NUMBERS:<tab><tab><IF-STMT><tab><tab><tab>stroke = stroke.replace(system.NUMBER_KEY, """")<tab><tab># Insert dash when dealing with 'explicit' numbers<tab><tab>m = _IMPLICIT_NUMBER_RX.search(stroke)<tab><tab>if m is not None:<tab><tab><tab>start = m.start(2)<tab><tab><tab>return stroke[:start] + ""-"" + stroke[start:]<tab>if ""-"" in letters:<tab><tab>if stroke.endswith(""-""):<tab><tab><tab>stroke = stroke[:-1]<tab><tab>elif letters & system.IMPLICIT_HYPHENS:<tab><tab><tab>stroke = stroke.replace(""-"", """")<tab>return stroke",0,if system . NUMBER_KEY in letters :,if system . NUMBER_KEY in stroke :,0.574113272,75.06238538,0.666666667
"def vim_k(self):<tab>""""""Cursor up N lines.""""""<tab>if self.is_text_wrapper(self.w):<tab><tab>for z in range(self.n1 * self.n):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.do(""previous-line-extend-selection"")<tab><tab><tab>else:<tab><tab><tab><tab>self.do(""previous-line"")<tab><tab>self.done()<tab>elif self.in_tree(self.w):<tab><tab>self.do(""goto-prev-visible"")<tab><tab>self.done()<tab>else:<tab><tab>self.quit()",0,"if self . state == ""visual"" :",if self . in_tree ( self . w ) :,0.137208413,13.54599427,0.517948718
"def parseTime(timeStr):<tab>regex = re.compile(constants.PARSE_TIME_REGEX)<tab>parts = regex.match(timeStr)<tab>if not parts:<tab><tab>return<tab>parts = parts.groupdict()<tab>time_params = {}<tab>for (name, param) in parts.items():<tab><tab>if param:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>time_params[""microseconds""] = int(param) * 1000<tab><tab><tab>else:<tab><tab><tab><tab>time_params[name] = int(param)<tab>return datetime.timedelta(**time_params).total_seconds()",0,"if name == ""miliseconds"" :","if name == ""microsecond"" :",0.394778655,59.46035575,1
"def update(self, other=None, **kwargs):<tab>if other is not None:<tab><tab>if hasattr(other, ""items""):<tab><tab><tab>other = other.items()<tab><tab>for key, value in other:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TensorforceError.value(<tab><tab><tab><tab><tab>name=""NestedDict.update"",<tab><tab><tab><tab><tab>argument=""key"",<tab><tab><tab><tab><tab>value=key,<tab><tab><tab><tab><tab>condition=""specified twice"",<tab><tab><tab><tab>)<tab><tab><tab>self[key] = value<tab>for key, value in kwargs.items():<tab><tab>self[key] = value",0,if key in kwargs :,"if isinstance ( value , dict ) :",0.026407399,6.567274736,0.25
"def to_string(self, ostream=None, verbose=None, precedence=0):<tab>""""""Print this expression""""""<tab>if ostream is None:<tab><tab>ostream = sys.stdout<tab>_verbose = (<tab><tab>pyomo.core.base.expr_common.TO_STRING_VERBOSE if verbose is None else verbose<tab>)<tab>ostream.write(self.cname() + ""( "")<tab>first = True<tab>for arg in self._args:<tab><tab>if first:<tab><tab><tab>first = False<tab><tab><IF-STMT><tab><tab><tab>ostream.write("" , "")<tab><tab>else:<tab><tab><tab>ostream.write("", "")<tab><tab>arg.to_string(ostream=ostream, precedence=self._precedence(), verbose=verbose)<tab>ostream.write("" )"")",0,elif _verbose :,if _verbose :,0.112938849,1.00E-10,0.333333333
"def apply_gradient_for_batch(inputs, labels, weights, loss):<tab>with tf.GradientTape() as tape:<tab><tab>outputs = self.model(inputs, training=True)<tab><tab>if isinstance(outputs, tf.Tensor):<tab><tab><tab>outputs = [outputs]<tab><tab><IF-STMT><tab><tab><tab>outputs = [outputs[i] for i in self._loss_outputs]<tab><tab>batch_loss = loss(outputs, labels, weights)<tab>if variables is None:<tab><tab>vars = self.model.trainable_variables<tab>else:<tab><tab>vars = variables<tab>grads = tape.gradient(batch_loss, vars)<tab>self._tf_optimizer.apply_gradients(zip(grads, vars))<tab>self._global_step.assign_add(1)<tab>return batch_loss",0,if self . _loss_outputs is not None :,elif self . _loss_outputs is not None :,0.441849692,89.31539818,0.714285714
"def check_all(self, strict=False):<tab>""""""run sanity check on all keys, issue warning if out of sync""""""<tab>same = self._is_same_value<tab>for path, (orig, expected) in iteritems(self._state):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>msg = ""another library has patched resource: %r"" % path<tab><tab>if strict:<tab><tab><tab>raise RuntimeError(msg)<tab><tab>else:<tab><tab><tab>warn(msg, PasslibRuntimeWarning)",0,"if same ( self . _get_path ( path ) , expected ) :",if orig != expected :,0.009477309,2.017602273,0.26984127
"def setup_child(self, child):<tab>child.parent = self<tab>if self.document:<tab><tab>child.document = self.document<tab><tab>if child.source is None:<tab><tab><tab>child.source = self.document.current_source<tab><tab><IF-STMT><tab><tab><tab>child.line = self.document.current_line",1,if child . line is None :,if child . line is None :,0.75,100,1
"def shift_expr(self, nodelist):<tab># shift_expr ('<<'|'>>' shift_expr)*<tab>node = self.com_node(nodelist[0])<tab>for i in range(2, len(nodelist), 2):<tab><tab>right = self.com_node(nodelist[i])<tab><tab>if nodelist[i - 1][0] == token.LEFTSHIFT:<tab><tab><tab>node = LeftShift([node, right], lineno=nodelist[1][2])<tab><tab><IF-STMT><tab><tab><tab>node = RightShift([node, right], lineno=nodelist[1][2])<tab><tab>else:<tab><tab><tab>raise ValueError(""unexpected token: %s"" % nodelist[i - 1][0])<tab>return node",1,elif nodelist [ i - 1 ] [ 0 ] == token . RIGHTSHIFT :,elif nodelist [ i - 1 ] [ 0 ] == token . RIGHTSHIFT :,0.75,100,1
"def styleRow(self, row, selected):<tab>if row != -1:<tab><tab><IF-STMT><tab><tab><tab>self.getRowFormatter().addStyleName(row, ""midpanel-SelectedRow"")<tab><tab>else:<tab><tab><tab>self.getRowFormatter().removeStyleName(row, ""midpanel-SelectedRow"")",1,if selected :,if selected :,0.531170663,1.00E-10,1
"def __call__(self, img):<tab>img = self.topil(img)<tab>ops = random.choices(self.augment_list, k=self.n)<tab>for op, minval, maxval in ops:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>val = (float(self.m) / 30) * float(maxval - minval) + minval<tab><tab>img = op(img, val)<tab>return img",0,"if random . random ( ) > random . uniform ( 0.2 , 0.8 ) :",if random . random ( ) < random . random ( ) :,0.514478729,38.2443134,0.714285714
"def run(self, **inputs):<tab>if self.inputs.copy_inputs:<tab><tab>self.inputs.subjects_dir = os.getcwd()<tab><tab><IF-STMT><tab><tab><tab>inputs[""subjects_dir""] = self.inputs.subjects_dir<tab><tab>copy2subjdir(self, self.inputs.surface, ""surf"")<tab><tab>copy2subjdir(self, self.inputs.curvfile1, ""surf"")<tab><tab>copy2subjdir(self, self.inputs.curvfile2, ""surf"")<tab>return super(CurvatureStats, self).run(**inputs)",0,"if ""subjects_dir"" in inputs :",if self . inputs . subjects_dir :,0.029730601,21.10534063,0.6
"def get_func_name(obj):<tab>if inspect.ismethod(obj):<tab><tab>match = RE_BOUND_METHOD.match(repr(obj))<tab><tab>if match:<tab><tab><tab>cls = match.group(""class"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return match.group(""name"")<tab><tab><tab>return ""%s.%s"" % (match.group(""class""), match.group(""name""))<tab>return None",0,if not cls :,"if cls == obj and match . group ( ""name"" ) :",0.033077115,3.458592114,0.225
"def local_path_export(at_start=True, env_cmd=None):<tab>""""""Retrieve paths to local install, also including environment paths if env_cmd included.""""""<tab>paths = [get_bcbio_bin()]<tab>if env_cmd:<tab><tab>env_path = os.path.dirname(get_program_python(env_cmd))<tab><tab><IF-STMT><tab><tab><tab>paths.insert(0, env_path)<tab>if at_start:<tab><tab>return 'export PATH=%s:""$PATH"" && ' % ("":"".join(paths))<tab>else:<tab><tab>return 'export PATH=""$PATH"":%s && ' % ("":"".join(paths))",0,if env_path not in paths :,if os . path . exists ( env_path ) :,0.021554939,14.32314508,0.25
"def copystat(src, dst):<tab>""""""Copy all stat info (mode bits, atime, mtime, flags) from src to dst""""""<tab>st = os.stat(src)<tab>mode = stat.S_IMODE(st.st_mode)<tab>if hasattr(os, ""utime""):<tab><tab>os.utime(dst, (st.st_atime, st.st_mtime))<tab>if hasattr(os, ""chmod""):<tab><tab>os.chmod(dst, mode)<tab>if hasattr(os, ""chflags"") and hasattr(st, ""st_flags""):<tab><tab>try:<tab><tab><tab>os.chflags(dst, st.st_flags)<tab><tab>except OSError as why:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",0,"if not hasattr ( errno , ""EOPNOTSUPP"" ) or why . errno != errno . EOPNOTSUPP :",if why . errno != errno . EPERM :,0.465759016,25.02959503,0.244444444
"def _asdict(self, *, to_string: bool = False) -> dict:<tab>res = []<tab>for key in self._keys:<tab><tab>value = getattr(self, key)<tab><tab>if isinstance(value, Struct):<tab><tab><tab>value = value._asdict(to_string=to_string)<tab><tab><IF-STMT><tab><tab><tab>value = str(value)<tab><tab>res.append((key, value))<tab>return dict(res)",0,elif to_string :,elif not to_string :,0.105516222,1.00E-10,0.6
"def _SI(size, K=1024, i=""i""):<tab>""""""Return size as SI string.""""""<tab>if 1 < K <= size:<tab><tab>f = float(size)<tab><tab>for si in iter(""KMGPTE""):<tab><tab><tab>f /= K<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return "" or %.1f %s%sB"" % (f, si, i)<tab>return """"",0,if f < K :,if f > i :,0.064978772,23.64354023,0.6
"def _flatten(*args):<tab>arglist = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>if arg.vhdl_code is not None:<tab><tab><tab><tab>arglist.append(arg.vhdl_code)<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>arg = arg.subs<tab><tab>if id(arg) in _userCodeMap[""vhdl""]:<tab><tab><tab>arglist.append(_userCodeMap[""vhdl""][id(arg)])<tab><tab>elif isinstance(arg, (list, tuple, set)):<tab><tab><tab>for item in arg:<tab><tab><tab><tab>arglist.extend(_flatten(item))<tab><tab>else:<tab><tab><tab>arglist.append(arg)<tab>return arglist",0,"if isinstance ( arg , _Block ) :","if isinstance ( arg , _userCodeMap [ ""vhdl"" ] ) :",0.251271758,39.34995962,1
"def new_token(self):<tab>data = '{{""username"": ""{}"", ""password"": ""{}""}}'.format(self.username, self.password)<tab>try:<tab><tab>resp = requests.post(<tab><tab><tab>""https://api.zoomeye.org/user/login"",<tab><tab><tab>data=data,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>content = resp.json()<tab><tab><tab>self.token = content[""access_token""]<tab><tab><tab>self.headers = {""Authorization"": ""JWT %s"" % self.token}<tab><tab><tab>return True<tab>except Exception as ex:<tab><tab>logger.error(str(ex))<tab>return False",0,"if resp . status_code != 401 and ""access_token"" in resp . json ( ) :",if resp . status_code == 200 :,0.117855982,16.73205552,0.308333333
"def finalize_computation(<tab>self, transaction: SignedTransactionAPI, computation: ComputationAPI) -> ComputationAPI:<tab>computation = super().finalize_computation(transaction, computation)<tab>#<tab># EIP161 state clearing<tab>#<tab>touched_accounts = collect_touched_accounts(computation)<tab>for account in touched_accounts:<tab><tab>should_delete = self.vm_state.account_exists(<tab><tab><tab>account<tab><tab>) and self.vm_state.account_is_empty(account)<tab><tab><IF-STMT><tab><tab><tab>self.vm_state.logger.debug2(<tab><tab><tab><tab>""CLEARING EMPTY ACCOUNT: %s"",<tab><tab><tab><tab>encode_hex(account),<tab><tab><tab>)<tab><tab><tab>self.vm_state.delete_account(account)<tab>return computation",1,if should_delete :,if should_delete :,0.531170663,1.00E-10,1
"def send_messages(self, text, user_ids):<tab>broken_items = []<tab>if not user_ids:<tab><tab>self.logger.info(""User must be at least one."")<tab><tab>return broken_items<tab>self.logger.info(""Going to send %d messages."" % (len(user_ids)))<tab>for user in tqdm(user_ids):<tab><tab><IF-STMT><tab><tab><tab>self.error_delay()<tab><tab><tab>broken_items = user_ids[user_ids.index(user) :]<tab><tab><tab>break<tab>return broken_items",1,"if not self . send_message ( text , user ) :","if not self . send_message ( text , user ) :",0.75,100,1
"def editable_cpp_info(self):<tab>if self._layout_file:<tab><tab><IF-STMT><tab><tab><tab>return EditableLayout(self._layout_file)<tab><tab>else:<tab><tab><tab>raise ConanException(""Layout file not found: %s"" % self._layout_file)",1,if os . path . isfile ( self . _layout_file ) :,if os . path . isfile ( self . _layout_file ) :,0.75,100,1
"def to_python(self, value):<tab>if isinstance(value, list) and len(value) == 2 and isinstance(value[0], str):<tab><tab>filename, payload = value<tab><tab>try:<tab><tab><tab>payload = base64.b64decode(payload)<tab><tab>except TypeError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.storage.delete(filename)<tab><tab><tab>self.storage.save(filename, ContentFile(payload))<tab><tab><tab>return filename<tab>return value",1,if self . storage . exists ( filename ) :,if self . storage . exists ( filename ) :,0.75,100,1
"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab>if type(value) == dict:<tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab><IF-STMT><tab><tab><tab>self.__defaults_from_module(value)<tab><tab>elif isinstance(value, str):<tab><tab><tab>if os.path.exists(value):<tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)",0,"elif isinstance ( value , types . ModuleType ) :","elif isinstance ( value , module ) :",0.312053013,46.30777162,0.558441558
"def __getitem__(self, item: str) -> Any:<tab>try:<tab><tab>return self.data[item]<tab>except KeyError:<tab><tab>for g in self.extended_groups():<tab><tab><tab>try:<tab><tab><tab><tab>r = g.data[item]<tab><tab><tab><tab>return r<tab><tab><tab>except KeyError:<tab><tab><tab><tab>continue<tab><tab>r = self.defaults.data.get(item)<tab><tab><IF-STMT><tab><tab><tab>return r<tab><tab>raise",1,if r is not None :,if r is not None :,0.75,100,1
"def _parse_arguments(self, handler_method):<tab>spec = DynamicArgumentParser().parse(self._argspec, self.longname)<tab>if not self._supports_kwargs:<tab><tab>if spec.kwargs:<tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for **kwargs ""<tab><tab><tab><tab>""support."" % self._run_keyword_method_name<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for ""<tab><tab><tab><tab>""keyword-only arguments support."" % self._run_keyword_method_name<tab><tab><tab>)<tab>spec.types = GetKeywordTypes(self.library.get_instance())(self._handler_name)<tab>return spec",0,if spec . kwonlyargs :,if spec . keyword_only :,0.394778655,26.26909894,0.7
"def test_orphans_match(self):<tab>""""""api handles last three chars match query""""""<tab>response = self.client.get(""%s?q=%s"" % (self.api_link, self.user.username[-3:]))<tab>self.assertEqual(response.status_code, 200)<tab>response_json = response.json()<tab>self.assertIn(""users"", [p[""id""] for p in response_json])<tab>for provider in response_json:<tab><tab><IF-STMT><tab><tab><tab>results = provider[""results""][""results""]<tab><tab><tab>self.assertEqual(len(results), 1)<tab><tab><tab>self.assertEqual(results[0][""id""], self.user.id)",0,"if provider [ ""id"" ] == ""users"" :","if provider [ ""type"" ] == ""users"" :",0.501462237,76.11606003,1
"def test_costs_1D_noisy_names(signal_bkps_1D_noisy, cost_name):<tab>signal, bkps = signal_bkps_1D_noisy<tab>cost = cost_factory(cost_name)<tab>cost.fit(signal)<tab>cost.fit(signal.flatten())<tab>cost.error(0, 100)<tab>cost.error(100, signal.shape[0])<tab>cost.error(10, 50)<tab>cost.sum_of_costs(bkps)<tab>with pytest.raises(NotEnoughPoints):<tab><tab><IF-STMT><tab><tab><tab>cost.min_size = 4<tab><tab><tab>cost.error(1, 2)<tab><tab>else:<tab><tab><tab>cost.error(1, 2)",1,"if cost_name == ""cosine"" :","if cost_name == ""cosine"" :",0.75,100,1
"def _delete_access_key(self, params):<tab>sys.stdout.write(""Deleting the IAM user access keys... "")<tab>list_access_keys = self.iam.get_paginator(""list_access_keys"")<tab>try:<tab><tab>for response in list_access_keys.paginate(UserName=params.user_name):<tab><tab><tab>for access_key in response[""AccessKeyMetadata""]:<tab><tab><tab><tab>self.iam.delete_access_key(<tab><tab><tab><tab><tab>UserName=params.user_name, AccessKeyId=access_key[""AccessKeyId""]<tab><tab><tab><tab>)<tab>except ClientError as e:<tab><tab><IF-STMT><tab><tab><tab>raise e<tab>sys.stdout.write(""DONE\n"")",0,"if e . response . get ( ""Error"" , { } ) . get ( ""Code"" ) != ""NoSuchEntity"" :","if e . response [ ""Error"" ] [ ""Code"" ] != ""AccessDeniedException"" :",0.102485186,19.97036449,0.7875
"def run_pending(self, now=None):<tab>""""""Runs the command if scheduled""""""<tab>now = now or datetime.now()<tab>if self.is_enabled():<tab><tab>if self.last_run is None:<tab><tab><tab>self.last_run = now<tab><tab>next_time = self.schedule(self.last_run).get_next()<tab><tab><IF-STMT><tab><tab><tab>self.last_run = now<tab><tab><tab>return self.run()<tab>return -1",0,if next_time < now :,if next_time is None :,0.064978772,43.47208719,0.36
"def parse_row(cls, doc_row):<tab>row = {}<tab>for field_name, field in FIELD_MAP.items():<tab><tab><IF-STMT><tab><tab><tab>field_value = doc_row[field[1]]<tab><tab>else:<tab><tab><tab>field_value = """"<tab><tab>if len(field) >= 3 and callable(field[2]):<tab><tab><tab>field_value = field[2](field_value)<tab><tab>row[field_name] = field_value<tab>return row",0,if len ( doc_row ) > field [ 1 ] :,if field [ 1 ] in doc_row :,0.179888151,29.97004972,0.333333333
"def list(self, items, columns=4, width=80):<tab>items = list(sorted(items))<tab>colw = width // columns<tab>rows = (len(items) + columns - 1) // columns<tab>for row in range(rows):<tab><tab>for col in range(columns):<tab><tab><tab>i = col * rows + row<tab><tab><tab>if i < len(items):<tab><tab><tab><tab>self.output.write(items[i])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.output.write("" "" + "" "" * (colw - 1 - len(items[i])))<tab><tab>self.output.write(""\n"")",0,if col < columns - 1 :,elif col < columns - 1 :,0.382940898,80.91067116,0.666666667
"def _on_message(self, storage, data):<tab>if ""_meta"" in data and ""session_id"" in data[""_meta""]:<tab><tab>self.session_id = data[""_meta""][""session_id""]<tab>if is_blacklisted(data.get(""url"", """")):<tab><tab>blacklist_error(data, self)<tab><tab>return<tab>command = data[""_command""]<tab>command = self._handlers.get(command, command)<tab>with data_store_context():<tab><tab>commands = Commands(data, self, storage)<tab><tab>result = getattr(commands, command, lambda: None)()<tab>if result:<tab><tab>result.setdefault(""_command"", data.get(""_callback"", command))<tab><tab><IF-STMT><tab><tab><tab>result[""id""] = data[""_meta""][""id""]<tab>return result",0,"if ""_meta"" in data and ""id"" in data [ ""_meta"" ] :","if ""_meta"" in data :",0.104001319,19.39986756,0.626666667
"def get_model_params(problem_type: str, hyperparameters):<tab>penalty = hyperparameters.get(""penalty"", L2)<tab>handle_text = hyperparameters.get(""handle_text"", IGNORE)<tab>if problem_type == REGRESSION:<tab><tab><IF-STMT><tab><tab><tab>model_class = Ridge<tab><tab>elif penalty == L1:<tab><tab><tab>model_class = Lasso<tab><tab>else:<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""Unknown value for penalty {} - supported types are [l1, l2] - falling back to l2"".format(<tab><tab><tab><tab><tab>penalty<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>penalty = L2<tab><tab><tab>model_class = Ridge<tab>else:<tab><tab>model_class = LogisticRegression<tab>return model_class, penalty, handle_text",0,if penalty == L2 :,if penalty == Ridge :,0.394778655,53.72849659,0.6
"def get_queryset(self):<tab>if self.queryset is not None:<tab><tab>return self.queryset._clone()<tab>elif self.model is not None:<tab><tab>qs = self.model._default_manager<tab><tab>if self.model in access_registry:<tab><tab><tab>access_class = access_registry[self.model]<tab><tab><tab>if access_class.select_related:<tab><tab><tab><tab>qs = qs.select_related(*access_class.select_related)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>qs = qs.prefetch_related(*access_class.prefetch_related)<tab><tab>return qs<tab>else:<tab><tab>return super(GenericAPIView, self).get_queryset()",1,if access_class . prefetch_related :,if access_class . prefetch_related :,0.75,100,1
"def map_package(shutit_pexpect_session, package, install_type):<tab>""""""If package mapping exists, then return it, else return package.""""""<tab>if package in PACKAGE_MAP.keys():<tab><tab>for itype in PACKAGE_MAP[package].keys():<tab><tab><tab>if itype == install_type:<tab><tab><tab><tab>ret = PACKAGE_MAP[package][install_type]<tab><tab><tab><tab>if isinstance(ret, str):<tab><tab><tab><tab><tab>return ret<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>ret(shutit_pexpect_session)<tab><tab><tab><tab><tab>return """"<tab># Otherwise, simply return package<tab>return package",0,if callable ( ret ) :,elif callable ( ret ) :,0.357143998,75.98356857,0.6
"def find_missing_cache_files(<tab>self, modules: Dict[str, str], manager: build.BuildManager) -> Set[str]:<tab>ignore_errors = True<tab>missing = {}<tab>for id, path in modules.items():<tab><tab>meta = build.find_cache_meta(id, path, manager)<tab><tab><IF-STMT><tab><tab><tab>missing[id] = path<tab>return set(missing.values())",0,"if not build . validate_meta ( meta , id , path , ignore_errors , manager ) :",if not ignore_errors :,0.010116394,3.263989834,0.35
"def parse_percent_formats(data, tree):<tab>percent_formats = data.setdefault(""percent_formats"", {})<tab>for elem in tree.findall("".//percentFormats/percentFormatLength""):<tab><tab>type = elem.attrib.get(""type"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pattern = text_type(elem.findtext(""percentFormat/pattern""))<tab><tab>percent_formats[type] = numbers.parse_pattern(pattern)",0,"if _should_skip_elem ( elem , type , percent_formats ) :","if type == ""percent"" :",0.014393213,2.535487021,0.483333333
"def nan2none(l):<tab>for idx, val in enumerate(l):<tab><tab><IF-STMT><tab><tab><tab>l[idx] = nan2none(l[idx])<tab><tab>elif isnum(val) and math.isnan(val):<tab><tab><tab>l[idx] = None<tab>return l",0,"if isinstance ( val , Sequence ) :",if isnan ( val ) and math . isnan ( val ) :,0.035266244,9.23843021,0.308333333
"def process(self, message: Message, **kwargs: Any) -> None:<tab>for attribute in DENSE_FEATURIZABLE_ATTRIBUTES:<tab><tab><IF-STMT><tab><tab><tab>message.set(<tab><tab><tab><tab>SPACY_DOCS[attribute], self.doc_for_text(message.get(attribute))<tab><tab><tab>)",0,if message . get ( attribute ) :,if attribute in SENSE_FEATURIZABLE_ATTRIBUTES :,0.019907918,6.274655311,0.314814815
"def accessSlice(self, node):<tab>self.visit(node.value)<tab>node.obj = self.getObj(node.value)<tab>self.access = _access.INPUT<tab>lower, upper = node.slice.lower, node.slice.upper<tab>if lower:<tab><tab>self.visit(lower)<tab><IF-STMT><tab><tab>self.visit(upper)<tab>if isinstance(node.obj, intbv):<tab><tab>if self.kind == _kind.DECLARATION:<tab><tab><tab>self.require(lower, ""Expected leftmost index"")<tab><tab><tab>leftind = self.getVal(lower)<tab><tab><tab>if upper:<tab><tab><tab><tab>rightind = self.getVal(upper)<tab><tab><tab>else:<tab><tab><tab><tab>rightind = 0<tab><tab><tab>node.obj = node.obj[leftind:rightind]",1,if upper :,if upper :,0.531170663,1.00E-10,1
"def forg(x, prec=3):<tab>if prec == 3:<tab><tab># for 3 decimals<tab><tab><IF-STMT><tab><tab><tab>return ""%9.3g"" % x<tab><tab>else:<tab><tab><tab>return ""%9.3f"" % x<tab>elif prec == 4:<tab><tab>if (abs(x) >= 1e4) or (abs(x) < 1e-4):<tab><tab><tab>return ""%10.4g"" % x<tab><tab>else:<tab><tab><tab>return ""%10.4f"" % x<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>""`prec` argument must be either 3 or 4, not {prec}"".format(prec=prec)<tab><tab>)",0,if ( abs ( x ) >= 1e4 ) or ( abs ( x ) < 1e-4 ) :,if abs ( x ) >= 3e3 or abs ( x ) < 3e-3 :,0.544664128,43.90008584,0.714285714
"def pseudo_raw_input(self, prompt):<tab>""""""copied from cmd's cmdloop; like raw_input, but accounts for changed stdin, stdout""""""<tab>if self.use_rawinput:<tab><tab>try:<tab><tab><tab>line = raw_input(prompt)<tab><tab>except EOFError:<tab><tab><tab>line = ""EOF""<tab>else:<tab><tab>self.stdout.write(prompt)<tab><tab>self.stdout.flush()<tab><tab>line = self.stdin.readline()<tab><tab><IF-STMT><tab><tab><tab>line = ""EOF""<tab><tab>else:<tab><tab><tab>if line[-1] == ""\n"":  # this was always true in Cmd<tab><tab><tab><tab>line = line[:-1]<tab>return line",0,if not len ( line ) :,if not line :,0.045918745,17.94604817,0.571428571
"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab>if pos == -1:<tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab><IF-STMT>  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab>if c == ""\\"":<tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab>if not escaped:<tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos",0,"elif pos > 1 and dn [ pos - 1 ] == ""\\"" :","if dn [ pos - 2 : ] == ""\\"" :",0.213915523,53.0164631,0.102941176
"def update_user(username):<tab>permission = UserAdminPermission(username)<tab>if permission.can():<tab><tab>update_request = request.get_json()<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""Updating user password"")<tab><tab><tab>model.user.change_password(<tab><tab><tab><tab>get_authenticated_user(), update_request[""password""]<tab><tab><tab>)<tab><tab>return jsonify(<tab><tab><tab>{<tab><tab><tab><tab>""username"": get_authenticated_user().username,<tab><tab><tab><tab>""email"": get_authenticated_user().email,<tab><tab><tab>}<tab><tab>)<tab>abort(403)",0,"if ""password"" in update_request :","if update_request . get ( ""password"" ) :",0.029323261,22.78155605,0.5
"def pages(self):<tab>if hasattr(self, ""_pages""):<tab><tab>return self._pages<tab>doctop = 0<tab>pp = self.pages_to_parse<tab>self._pages = []<tab>for i, page in enumerate(PDFPage.create_pages(self.doc)):<tab><tab>page_number = i + 1<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>p = Page(self, page, page_number=page_number, initial_doctop=doctop)<tab><tab>self._pages.append(p)<tab><tab>doctop += p.height<tab>return self._pages",0,if pp is not None and page_number not in pp :,if page_number >= pp :,0.023216713,14.48102341,0.253787879
"def image_size(img_data, pure_python=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return imgsize.get_size(PeekableStringIO(img_data))<tab><tab>if Image is not None and not pure_python:<tab><tab><tab>return Image.open(cStringIO.StringIO(img_data)).size<tab>except (ValueError, imgsize.UnknownSize):<tab><tab>pass<tab>return None",0,if imgsize is not None :,"if isinstance ( img_data , str ) :",0.022316444,4.990049702,0.21875
"def email_csv_query(request, query_id):<tab>if request.is_ajax():<tab><tab>email = request.POST.get(""email"", None)<tab><tab><IF-STMT><tab><tab><tab>execute_query.delay(query_id, email)<tab><tab><tab>return HttpResponse(content={""message"": ""message was sent successfully""})<tab>return HttpResponse(status=403)",1,if email :,if email :,0.531170663,1.00E-10,1
"def _groups_args_split(self, kwargs):<tab>groups_args_split = []<tab>groups = kwargs[""groups""]<tab>for key, group in groups.iteritems():<tab><tab>mykwargs = kwargs.copy()<tab><tab>del mykwargs[""groups""]<tab><tab>if ""group_name"" in group:<tab><tab><tab>mykwargs[""source_security_group_name""] = group[""group_name""]<tab><tab><IF-STMT><tab><tab><tab>mykwargs[""source_security_group_owner_id""] = group[""user_id""]<tab><tab>if ""group_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_id""] = group[""group_id""]<tab><tab>groups_args_split.append(mykwargs)<tab>return groups_args_split",1,"if ""user_id"" in group :","if ""user_id"" in group :",0.75,100,1
"def get_subnet_groups(self, region: str, vpc: str):<tab>try:<tab><tab>await self._cache_subnet_groups(region)<tab><tab>return [<tab><tab><tab>subnet_group<tab><tab><tab>for subnet_group in self._subnet_groups_cache[region]<tab><tab><tab><IF-STMT><tab><tab>]<tab>except Exception as e:<tab><tab>print_exception(f""Failed to get RDS subnet groups: {e}"")<tab><tab>return []",1,"if subnet_group [ ""VpcId"" ] == vpc","if subnet_group [ ""VpcId"" ] == vpc",0.75,100,1
def on_state_update(self) -> None:<tab>if self.road:<tab><tab>self.lane_index = self.road.network.get_closest_lane_index(self.position)<tab><tab>self.lane = self.road.network.get_lane(self.lane_index)<tab><tab><IF-STMT><tab><tab><tab>self.history.appendleft(self.create_from(self)),0,if self . road . record_history :,if self . history :,0.157032291,22.46644821,0.6
"def delete_old_post_save(<tab>sender, instance, raw, created, update_fields, using, **kwargs):<tab>""""""Post_save on all models with file fields, deletes old files""""""<tab>if raw or created:<tab><tab>return<tab>for field_name, new_file in cache.fields_for_model_instance(instance):<tab><tab>if update_fields is None or field_name in update_fields:<tab><tab><tab>old_file = cache.get_field_attr(instance, field_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>delete_file(instance, field_name, old_file, using)<tab># reset cache<tab>cache.make_cleanup_cache(instance)",0,if old_file != new_file :,if old_file is not None :,0.057429006,28.46946938,0.314285714
"def i2h(self, pkt, x):<tab>if x is not None:<tab><tab>if x < 0:<tab><tab><tab>warning(""Fixed3_6: Internal value too negative: %d"" % x)<tab><tab><tab>x = 0<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_6: Internal value too positive: %d"" % x)<tab><tab><tab>x = 999999999<tab><tab>x = x * 1e-6<tab>return x",1,elif x > 999999999 :,elif x > 999999999 :,0.75,100,1
"def quick_main(self):<tab>if self.actions.pressed(""cancel""):<tab><tab>self.previs_timer.stop()<tab><tab>return ""main""<tab>if self.actions.mousemove_stop:<tab><tab>self.hovering_edge, _ = self.rfcontext.accel_nearest2D_edge(<tab><tab><tab>max_dist=options[""action dist""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.hovering_edge = None<tab>if self.hovering_edge and self.rfcontext.actions.pressed(""quick insert""):<tab><tab>return self.insert_edge_loop_strip()",0,if self . hovering_edge and not self . hovering_edge . is_valid :,if self . hovering_edge is not None :,0.262893284,25.70722628,0.523809524
def check_status(self) -> None:<tab>join_requested = False<tab>while not join_requested:<tab><tab>status_response = self._interface.communicate_status(check_stop_req=True)<tab><tab>if status_response and status_response.run_should_stop:<tab><tab><tab># TODO(frz): This check is required<tab><tab><tab># until WB-3606 is resolved on server side.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>thread.interrupt_main()<tab><tab><tab><tab>return<tab><tab>join_requested = self._join_event.wait(self._polling_interval),0,if not wandb . agents . pyagent . is_running ( ) :,if not self . _loop . is_alive ( ) :,0.121778572,20.95398071,0.410714286
"def listed(output, pool):<tab>for line in output.splitlines():<tab><tab>name, mountpoint, refquota = line.split(b""\t"")<tab><tab>name = name[len(pool) + 1 :]<tab><tab><IF-STMT><tab><tab><tab>refquota = int(refquota.decode(""ascii""))<tab><tab><tab>if refquota == 0:<tab><tab><tab><tab>refquota = None<tab><tab><tab>yield _DatasetInfo(dataset=name, mountpoint=mountpoint, refquota=refquota)",0,if name :,"if isinstance ( refquota , bytes ) :",0.044228356,1.00E-10,0.3
"def defined_properties(cls, aliases=True, properties=True, rels=True):<tab>from .relationship_manager import RelationshipDefinition<tab>props = {}<tab>for baseclass in reversed(cls.__mro__):<tab><tab>props.update(<tab><tab><tab>dict(<tab><tab><tab><tab>(name, property)<tab><tab><tab><tab>for name, property in vars(baseclass).items()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>or (<tab><tab><tab><tab><tab>properties<tab><tab><tab><tab><tab>and isinstance(property, Property)<tab><tab><tab><tab><tab>and not isinstance(property, AliasProperty)<tab><tab><tab><tab>)<tab><tab><tab><tab>or (rels and isinstance(property, RelationshipDefinition))<tab><tab><tab>)<tab><tab>)<tab>return props",0,"if ( aliases and isinstance ( property , AliasProperty ) )","if not name . startswith ( ""_"" )",0.013374522,4.996872152,0.183333333
"def _mock_manager(self, *args, **kwargs):<tab>if kwargs and ""normalize"" not in kwargs:<tab><tab>device_params = kwargs[""device_params""]<tab><tab>device_handler = make_device_handler(device_params)<tab><tab>session = SSHSession(device_handler)<tab><tab>return Manager(session, device_handler)<tab>if args:<tab><tab>if args[0].tag == ""request-pfe-execute"":<tab><tab><tab>file_name = (args[0].findtext(""command"")).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")<tab><tab><IF-STMT><tab><tab><tab>file_name = (args[0].text).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")",0,"elif args [ 0 ] . tag == ""command"" :","elif args [ 0 ] . tag == ""request-pfe-parse"" :",0.641271145,79.10665072,1
"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab>if self._checking_num > 0:<tab><tab><tab>return<tab><tab>if fail or self.network_stat != ""OK"":<tab><tab><tab># Fail or unknown<tab><tab><tab>if time_now - self.last_check_time < 3:<tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",0,if time_now - self . last_check_time < 10 :,if time_now - self . last_check_time < 3 :,0.627090855,86.66415731,0.6
"def delete(self):<tab>if not self.force and not self.exists():<tab><tab>return []<tab>cmd = [""delete""]<tab>if self.filename:<tab><tab>cmd.append(""--filename="" + self.filename)<tab>else:<tab><tab>if not self.resource:<tab><tab><tab>self.module.fail_json(msg=""resource required to delete without filename"")<tab><tab>cmd.append(self.resource)<tab><tab>if self.name:<tab><tab><tab>cmd.append(self.name)<tab><tab>if self.label:<tab><tab><tab>cmd.append(""--selector="" + self.label)<tab><tab><IF-STMT><tab><tab><tab>cmd.append(""--all"")<tab><tab>if self.force:<tab><tab><tab>cmd.append(""--ignore-not-found"")<tab>return self._execute(cmd)",1,if self . all :,if self . all :,0.75,100,1
"def load(self):<tab>""""""load a custom filter""""""<tab>try:<tab><tab><IF-STMT><tab><tab><tab>parser = make_parser()<tab><tab><tab>parser.setContentHandler(FilterParser(self))<tab><tab><tab>with open(self.file, ""r"", encoding=""utf8"") as the_file:<tab><tab><tab><tab>parser.parse(the_file)<tab>except (IOError, OSError):<tab><tab>print(""IO/OSError in _filterlist.py"")<tab>except SAXParseException:<tab><tab>print(""Parser error"")",0,if os . path . isfile ( self . file ) :,if self . file :,0.044438412,11.14127554,0.257142857
"def exitFullscreen(self, container=None):<tab>""""""turns off fullscreen mode for the specified window""""""<tab>if container is None or isinstance(container, UNIVERSAL_STRING):<tab><tab>try:<tab><tab><tab>container = self.widgetManager.get(WIDGET_NAMES.SubWindow, container)<tab><tab>except:<tab><tab><tab>container = self._getTopLevel()<tab>if container.isFullscreen:<tab><tab>container.isFullscreen = False<tab><tab>container.attributes(""-fullscreen"", False)<tab><tab><IF-STMT><tab><tab><tab>container.unbind(""<Escape>"", container.escapeBindId)<tab><tab>with PauseLogger():<tab><tab><tab>self._doTitleBar()<tab><tab>return True<tab>else:<tab><tab>return False",0,if container . escapeBindId is not None :,if container . escapeBindId :,0.234334509,38.80684295,0.510204082
"def __get__(self, instance: Any, owner: Type) -> Any:<tab># class attribute accessed<tab>if instance is None:<tab><tab>return self<tab>field = self.field<tab>instance_dict = instance.__dict__<tab>to_python = self._to_python<tab>value = instance_dict[field]<tab>if self.lazy_coercion and to_python is not None:<tab><tab>evaluated_fields: Set[str]<tab><tab>evaluated_fields = instance.__evaluated_fields__<tab><tab><IF-STMT><tab><tab><tab>if value is not None or self.required:<tab><tab><tab><tab>value = instance_dict[field] = to_python(value)<tab><tab><tab>evaluated_fields.add(field)<tab>return value",1,if field not in evaluated_fields :,if field not in evaluated_fields :,0.75,100,1
"def ip_list(_):<tab>ips = []<tab>for ip in _.split("" ""):<tab><tab>if not ip:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>ips.append(IP.create(ip))<tab><tab>else:<tab><tab><tab>raise TypeError(""ip %s is invalid"" % ip)<tab>return ips",0,elif isip ( ip ) :,"elif isinstance ( ip , str ) :",0.154233868,16.51582159,0.481481481
"def _parse_fields(line, legacy=False):<tab>""""""Removes '\n' from fields line and returns fields as a list (columns).""""""<tab>line = line.rstrip(""\n"")<tab>if legacy:<tab><tab>fields = line.split("","")<tab>else:<tab><tab>line = line.split(""# Fields: "")[1]<tab><tab>fields = line.split("", "")<tab>columns = []<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>raise BLAST7FormatError(<tab><tab><tab><tab>""Unrecognized field (%r).""<tab><tab><tab><tab>"" Supported fields: %r"" % (field, set(column_converter.keys()))<tab><tab><tab>)<tab><tab>columns.append(column_converter[field])<tab>return columns",1,if field not in column_converter :,if field not in column_converter :,0.75,100,1
"def _resolve_plugin_path(path):<tab>if not os.path.isabs(path):<tab><tab>p = os.path.normpath(os.path.join(sublime.packages_path(), ""User"", path))<tab><tab><IF-STMT><tab><tab><tab>p = os.path.normpath(<tab><tab><tab><tab>os.path.join(sublime.packages_path(), ""LaTeXTools"", path)<tab><tab><tab>)<tab><tab>return p<tab>return path",0,if not os . path . exists ( p ) :,if not os . path . isfile ( p ) :,0.602001933,70.16879391,0.75
"def _deep_copy_dict(source, dest):<tab>for key, value in source.items():<tab><tab><IF-STMT><tab><tab><tab>dest[key] = {}<tab><tab><tab>TqApi._deep_copy_dict(value, dest[key])<tab><tab>else:<tab><tab><tab>dest[key] = value",0,"if isinstance ( value , Entity ) :","if isinstance ( dest [ key ] , dict ) :",0.077133295,18.36028135,0.365384615
"def encode(self):<tab>if not isinstance(self.expr, m2_expr.ExprInt):<tab><tab>return False<tab>if not test_set_sf(self.parent, self.expr.size):<tab><tab>return False<tab>value = int(self.expr)<tab>if value < 1 << self.l:<tab><tab>self.parent.shift.value = 0<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>value >>= 12<tab><tab>if value >= 1 << self.l:<tab><tab><tab>return False<tab><tab>self.parent.shift.value = 1<tab>self.value = value<tab>return True",0,if value & 0xFFF :,if value & 0x80 :,0.394778655,42.72870064,0.6
"def test_read_audio_properties(self):<tab>mediafile = self._mediafile_fixture(""full"")<tab>for key, value in self.audio_properties.items():<tab><tab><IF-STMT><tab><tab><tab>self.assertAlmostEqual(getattr(mediafile, key), value, delta=0.1)<tab><tab>else:<tab><tab><tab>self.assertEqual(getattr(mediafile, key), value)",0,"if isinstance ( value , float ) :","if hasattr ( mediafile , key ) :",0.036450472,13.88809517,0.25
"def get_all_fix_names(fixer_pkg, remove_prefix=True):<tab>""""""Return a sorted list of all available fix names in the given package.""""""<tab>pkg = __import__(fixer_pkg, [], [], [""*""])<tab>fixer_dir = os.path.dirname(pkg.__file__)<tab>fix_names = []<tab>for name in sorted(os.listdir(fixer_dir)):<tab><tab><IF-STMT><tab><tab><tab>if remove_prefix:<tab><tab><tab><tab>name = name[4:]<tab><tab><tab>fix_names.append(name[:-3])<tab>return fix_names",0,"if name . startswith ( ""fix_"" ) and name . endswith ( "".py"" ) :","if name . startswith ( ""__init__"" ) :",0.219956625,30.01110956,0.587301587
"def _get_arg(self, f_name, args, kws, arg_no, arg_name, default=None, err_msg=None):<tab>arg = None<tab>if len(args) > arg_no:<tab><tab>arg = args[arg_no]<tab>elif arg_name in kws:<tab><tab>arg = kws[arg_name]<tab>if arg is None:<tab><tab>if default is not None:<tab><tab><tab>return default<tab><tab><IF-STMT><tab><tab><tab>err_msg = ""{} requires '{}' argument"".format(f_name, arg_name)<tab><tab>raise ValueError(err_msg)<tab>return arg",1,if err_msg is None :,if err_msg is None :,0.75,100,1
"def get_satellite_list(self, daemon_type=""""):<tab>res = {}<tab>for t in [""arbiter"", ""scheduler"", ""poller"", ""reactionner"", ""receiver"", ""broker""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>satellite_list = []<tab><tab>res[t] = satellite_list<tab><tab>daemon_name_attr = t + ""_name""<tab><tab>daemons = self.app.get_daemons(t)<tab><tab>for dae in daemons:<tab><tab><tab>if hasattr(dae, daemon_name_attr):<tab><tab><tab><tab>satellite_list.append(getattr(dae, daemon_name_attr))<tab>return res",0,if daemon_type and daemon_type != t :,if t == daemon_type :,0.108470868,15.40990455,0.472222222
"def do_upload(file: Path, metadata: Metadata, repo_name=None):<tab>""""""Upload a file to an index server.""""""<tab>repo = get_repository(repo_name)<tab>upload_file(file, metadata, repo)<tab>if repo[""is_warehouse""]:<tab><tab>domain = urlparse(repo[""url""]).netloc<tab><tab><IF-STMT><tab><tab><tab>domain = domain[7:]<tab><tab>log.info(""Package is at https://%s/project/%s/"", domain, metadata.name)<tab>else:<tab><tab>log.info(""Package is at %s/%s"", repo[""url""], metadata.name)",0,"if domain . startswith ( ""upload."" ) :","if domain . startswith ( ""https://"" ) :",0.549040681,48.44273238,1
"def __next__(self):<tab>for res in self._execution_context:<tab><tab>for item in res:<tab><tab><tab>for operator in self._local_aggregators:<tab><tab><tab><tab>if isinstance(item, dict) and item:<tab><tab><tab><tab><tab>operator.aggregate(item[""item""])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>operator.aggregate(item)<tab>if self._results is None:<tab><tab>self._results = []<tab><tab>for operator in self._local_aggregators:<tab><tab><tab>self._results.append(operator.get_result())<tab>if self._result_index < len(self._results):<tab><tab>res = self._results[self._result_index]<tab><tab>self._result_index += 1<tab><tab>return res<tab>raise StopIteration",0,"elif isinstance ( item , numbers . Number ) :","elif isinstance ( item , list ) :",0.312053013,46.30777162,0.558441558
"def __iter__(self):<tab>yield pd.Timestamp.utcnow(), SESSION_START<tab>while True:<tab><tab>current_time = pd.Timestamp.utcnow()<tab><tab>current_minute = current_time.floor(""1 min"")<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if self._last_emit is None or current_minute > self._last_emit:<tab><tab><tab>log.debug(""emitting minutely bar: {}"".format(current_minute))<tab><tab><tab>self._last_emit = current_minute<tab><tab><tab>yield current_minute, BAR<tab><tab>else:<tab><tab><tab>sleep(1)<tab>yield current_minute, SESSION_END",0,if self . end is not None and current_minute >= self . end :,if current_minute == 0 :,0.008376751,7.936503279,0.176470588
"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)",1,"if ""&"" in text :","if ""&"" in text :",0.75,100,1
"def _read_row_from_packet(self, packet):<tab>row = []<tab>for encoding, converter in self.converters:<tab><tab>try:<tab><tab><tab>data = packet.read_length_coded_string()<tab><tab>except IndexError:<tab><tab><tab># No more columns in this row<tab><tab><tab># See https://github.com/PyMySQL/PyMySQL/pull/434<tab><tab><tab>break<tab><tab>if data is not None:<tab><tab><tab>if encoding is not None:<tab><tab><tab><tab>data = data.decode(encoding)<tab><tab><tab>if DEBUG:<tab><tab><tab><tab>print(""DEBUG: DATA = "", data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data = converter(data)<tab><tab>row.append(data)<tab>return tuple(row)",1,if converter is not None :,if converter is not None :,0.75,100,1
"def dumpMenuTree(self, aList, level=0, path=""""):<tab>for z in aList:<tab><tab>kind, val, val2 = z<tab><tab><IF-STMT><tab><tab><tab>name = self.getName(val, val2)<tab><tab><tab>g.es_print(<tab><tab><tab><tab>""%s %s (%s) [%s]"" % (""<tab>"" * (level + 0), val, val2, path + ""/"" + name)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>name = self.getName(kind.replace(""@menu "", """"))<tab><tab><tab>g.es_print(""%s %s... [%s]"" % (""<tab>"" * (level), kind, path + ""/"" + name))<tab><tab><tab>self.dumpMenuTree(val, level + 1, path=path + ""/"" + name)",0,"if kind == ""@item"" :","if kind == ""@menu"" :",0.394778655,66.06328636,1
"def startElement(self, name, attrs, connection):<tab>if name == ""SecurityGroups"":<tab><tab>return self.security_groups<tab>elif name == ""ClassicLinkVPCSecurityGroups"":<tab><tab>return self.classic_link_vpc_security_groups<tab>elif name == ""BlockDeviceMappings"":<tab><tab><IF-STMT><tab><tab><tab>self.block_device_mappings = BDM()<tab><tab>else:<tab><tab><tab>self.block_device_mappings = ResultSet([(""member"", BlockDeviceMapping)])<tab><tab>return self.block_device_mappings<tab>elif name == ""InstanceMonitoring"":<tab><tab>self.instance_monitoring = InstanceMonitoring(self)<tab><tab>return self.instance_monitoring",0,if self . use_block_device_types :,if self . block_device_mappings is None :,0.200593991,35.08439696,0.55
"def __get_dev_and_disk(topology):<tab>rv = []<tab>for values in topology.values():<tab><tab>values = values.copy()<tab><tab>while values:<tab><tab><tab>value = values.pop()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rv.append((value[""path""].replace(""/dev/"", """"), value[""disk""]))<tab><tab><tab>values += value.get(""children"") or []<tab>return rv",0,"if value [ ""type"" ] == ""DISK"" :","if ""path"" in value and ""disk"" in value :",0.018096169,5.024584978,0.32
"def _process_events(self, event_list):<tab>for key, mask in event_list:<tab><tab>fileobj, (reader, writer) = key.fileobj, key.data<tab><tab>if mask & selectors.EVENT_READ and reader is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.remove_reader(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(reader)<tab><tab>if mask & selectors.EVENT_WRITE and writer is not None:<tab><tab><tab>if writer._cancelled:<tab><tab><tab><tab>self.remove_writer(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(writer)",1,if reader . _cancelled :,if reader . _cancelled :,0.75,100,1
"def colourLabels(self):<tab>if self.showAttr and self.hasAttr:<tab><tab>self.canvas.itemconfigure(self.attrId, fill=self.fgColour)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.label.config(background=self.bgColour, fg=self.fgColour)<tab><tab>else:<tab><tab><tab>self.label.config(background=self.bgHColour, fg=self.fgHColour)<tab>except:<tab><tab>pass",0,if not self . selected :,if self . hasAttr :,0.054520976,20.80119538,0.3
"def validate_char_lengths(self):<tab>for field in self._meta.get_fields():<tab><tab><IF-STMT><tab><tab><tab>if (<tab><tab><tab><tab>isinstance(getattr(self, field.name), basestring)<tab><tab><tab><tab>and len(getattr(self, field.name)) > field.max_length<tab><tab><tab>):<tab><tab><tab><tab>raise Exception(<tab><tab><tab><tab><tab>""Role %s value exceeeds max length of %s.""<tab><tab><tab><tab><tab>% (field.name, field.max_length)<tab><tab><tab><tab>)",0,"if not field . is_relation and field . get_internal_type ( ) == ""CharField"" :","if field . __class__ . __name__ == ""CharField"" :",0.048701726,25.7809273,0.371428571
"def _render_lang_List(self, element):<tab>with self.buffer.foldable_lines():<tab><tab>self.buffer.write(""["", style=self.styles.bracket)<tab><tab>item_count = len(element.items)<tab><tab><IF-STMT><tab><tab><tab>with self.buffer.indent():<tab><tab><tab><tab>for idx, item in enumerate(element.items):<tab><tab><tab><tab><tab>self._render(item)<tab><tab><tab><tab><tab>if idx < (item_count - 1):<tab><tab><tab><tab><tab><tab>self.buffer.write("","")<tab><tab><tab><tab><tab><tab>self.buffer.mark_line_break()<tab><tab>if element.trimmed:<tab><tab><tab>self.buffer.write(""..."")<tab><tab>self.buffer.write(""]"", style=self.styles.bracket)",0,if item_count :,if item_count > 0 :,0.097914534,1.00E-10,0.619047619
"def do_dialog():<tab>""""""Post dialog and handle user interaction until quit""""""<tab>my_dlg = Dlg.GetNewDialog(ID_MAIN, -1)<tab>while 1:<tab><tab>n = Dlg.ModalDialog(None)<tab><tab>if n == ITEM_LOOKUP_BUTTON:<tab><tab><tab>tp, h, rect = my_dlg.GetDialogItem(ITEM_LOOKUP_ENTRY)<tab><tab><tab>txt = Dlg.GetDialogItemText(h)<tab><tab><tab>tp, h, rect = my_dlg.GetDialogItem(ITEM_RESULT)<tab><tab><tab>Dlg.SetDialogItemText(h, dnslookup(txt))<tab><tab><IF-STMT><tab><tab><tab>break",0,elif n == ITEM_QUIT_BUTTON :,elif n == ITEM_RESULT :,0.642872021,55.06953149,1
"def _extract_more_comments(tree):<tab>""""""Return a list of MoreComments objects removed from tree.""""""<tab>more_comments = []<tab>queue = [(None, x) for x in tree]<tab>while len(queue) > 0:<tab><tab>parent, comm = queue.pop(0)<tab><tab><IF-STMT><tab><tab><tab>heappush(more_comments, comm)<tab><tab><tab>if parent:<tab><tab><tab><tab>parent.replies.remove(comm)<tab><tab><tab>else:<tab><tab><tab><tab>tree.remove(comm)<tab><tab>else:<tab><tab><tab>for item in comm.replies:<tab><tab><tab><tab>queue.append((comm, item))<tab>return more_comments",1,"if isinstance ( comm , MoreComments ) :","if isinstance ( comm , MoreComments ) :",0.75,100,1
"def run(self):<tab>while True:<tab><tab>self.finished.wait(self.interval)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self.function(*self.args, **self.kwargs)<tab><tab>except Exception:<tab><tab><tab>if self.bus:<tab><tab><tab><tab>self.bus.log(<tab><tab><tab><tab><tab>""Error in perpetual timer thread function %r."" % self.function,<tab><tab><tab><tab><tab>level=40,<tab><tab><tab><tab><tab>traceback=True,<tab><tab><tab><tab>)<tab><tab><tab># Quit on first error to avoid massive logs.<tab><tab><tab>raise",0,if self . finished . isSet ( ) :,if self . finished . is_set ( ) :,0.549889319,46.92470064,0.781818182
"def emit_classattribs(self, typebld):<tab>if hasattr(self, ""_clrclassattribs""):<tab><tab>for attrib_info in self._clrclassattribs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ci = clr.GetClrType(attrib_info).GetConstructor(())<tab><tab><tab><tab>cab = CustomAttributeBuilder(ci, ())<tab><tab><tab>elif isinstance(attrib_info, CustomAttributeDecorator):<tab><tab><tab><tab>cab = attrib_info.GetBuilder()<tab><tab><tab>else:<tab><tab><tab><tab>make_decorator = attrib_info()<tab><tab><tab><tab>cab = make_decorator.GetBuilder()<tab><tab><tab>typebld.SetCustomAttribute(cab)",0,"if isinstance ( attrib_info , type ) :","if isinstance ( attrib_info , str ) :",0.549040681,70.71067812,0.6
"def wrapper(fn):<tab>if debug_run_test_calls:<tab><tab>ret = str(fn(*args, *kwargs))<tab><tab>print(""TEST: %s()"" % fn.__name__)<tab><tab>if args:<tab><tab><tab>print(""  arg:"", args)<tab><tab><IF-STMT><tab><tab><tab>print(""  kwa:"", kwargs)<tab><tab>print(""  ret:"", ret)<tab>return fn",1,if kwargs :,if kwargs :,0.531170663,1.00E-10,1
"def _prune(self):<tab>with self.lock:<tab><tab>entries = self._list_dir()<tab><tab><IF-STMT><tab><tab><tab>now = time.time()<tab><tab><tab>try:<tab><tab><tab><tab>for i, fpath in enumerate(entries):<tab><tab><tab><tab><tab>remove = False<tab><tab><tab><tab><tab>f = LockedFile(fpath, ""rb"")<tab><tab><tab><tab><tab>exp = pickle.load(f.file)<tab><tab><tab><tab><tab>f.close()<tab><tab><tab><tab><tab>remove = exp <= now or i % 3 == 0<tab><tab><tab><tab><tab>if remove:<tab><tab><tab><tab><tab><tab>self._del_file(fpath)<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",0,if len ( entries ) > self . _threshold :,if entries :,0.011515134,1.00E-10,0.371428571
"def delete_if_forked(ghrequest):<tab>FORKED = False<tab>query = ""/user/repos""<tab>r = utils.query_request(query)<tab>for repo in r.json():<tab><tab><IF-STMT><tab><tab><tab>if ghrequest.target_repo_fullname in repo[""description""]:<tab><tab><tab><tab>FORKED = True<tab><tab><tab><tab>url = f""/repos/{repo['full_name']}""<tab><tab><tab><tab>utils.query_request(url, method=""DELETE"")<tab>return FORKED",0,"if repo [ ""description"" ] :","if repo [ ""name"" ] == ghrequest . target_repo_fullname :",0.171513029,17.69497515,0.733333333
"def _feed_data_to_buffered_proto(proto, data):<tab>data_len = len(data)<tab>while data_len:<tab><tab>buf = proto.get_buffer(data_len)<tab><tab>buf_len = len(buf)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""get_buffer() returned an empty buffer"")<tab><tab>if buf_len >= data_len:<tab><tab><tab>buf[:data_len] = data<tab><tab><tab>proto.buffer_updated(data_len)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>buf[:buf_len] = data[:buf_len]<tab><tab><tab>proto.buffer_updated(buf_len)<tab><tab><tab>data = data[buf_len:]<tab><tab><tab>data_len = len(data)",0,if not buf_len :,if buf_len == 0 :,0.045150551,23.35689889,0.5
"def _plugin_get_requirements(self, requirements_iter):<tab>plugin_requirements = {""platform"": [], ""python"": [], ""network"": [], ""native"": []}<tab># parse requirements<tab>for requirement in requirements_iter:<tab><tab>key = requirement[0]<tab><tab>values = requirement[1]<tab><tab>if isinstance(values, str) or isinstance(values, bool):<tab><tab><tab>values = [values]<tab><tab><IF-STMT><tab><tab><tab>plugin_requirements[key].extend(values)<tab><tab>else:<tab><tab><tab>warning(""{}={}: No supported requirement"".format(key, values))<tab>return plugin_requirements",1,if key in plugin_requirements :,if key in plugin_requirements :,0.75,100,1
"def setCurrentModelIndexes(self, indexes):<tab>self._indexes = []<tab>self._index = None<tab>for i in indexes:<tab><tab>if i.isValid():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i = i.sibling(i.row(), self._column)<tab><tab><tab>self._indexes.append(i)<tab>self.updateItems()<tab>self.updateSelectedItem()",1,if i . column ( ) != self . _column :,if i . column ( ) != self . _column :,0.75,100,1
"def _publish(self, data):<tab>retry = True<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._redis_connect()<tab><tab><tab>return self.redis.publish(self.channel, pickle.dumps(data))<tab><tab>except redis.exceptions.ConnectionError:<tab><tab><tab>if retry:<tab><tab><tab><tab>logger.error(""Cannot publish to redis... retrying"")<tab><tab><tab><tab>retry = False<tab><tab><tab>else:<tab><tab><tab><tab>logger.error(""Cannot publish to redis... giving up"")<tab><tab><tab><tab>break",0,if not retry :,if not self . _redis_connected :,0.072740529,10.55267032,0.6
"def write_pad_and_flush(self, data, pad="" ""):<tab>if self.encryptor and (data or self.encode_buffer):<tab><tab><IF-STMT><tab><tab><tab>remainder = len(self.encode_buffer) + len(data)<tab><tab><tab>remainder %= self.encode_batches<tab><tab><tab>padding = self.encode_batches - remainder<tab><tab><tab>data += pad * padding<tab>self.write(data)<tab>self.flush()",0,if self . encode_batches :,if self . encode_batches > 0 :,0.285456913,61.04735836,0.722222222
"def dump_metrics(self):<tab>metrics = self._registry.dump_metrics()<tab># Filter out min and max if there have been no samples.<tab>for metric in metrics.itervalues():<tab><tab><IF-STMT><tab><tab><tab>if ""min"" in metric:<tab><tab><tab><tab>metric[""min""] = 0.0<tab><tab><tab>if ""max"" in metric:<tab><tab><tab><tab>metric[""max""] = 0.0<tab>return metrics",0,"if metric . get ( ""count"" ) == 0 :",if len ( metric ) == 0 :,0.155167168,32.18548744,0.5
"def demo():<tab>d = StatusProgressDialog(""A Demo"", ""Doing something..."")<tab>import win32api<tab>for i in range(100):<tab><tab>if i == 50:<tab><tab><tab>d.SetText(""Getting there..."")<tab><tab><IF-STMT><tab><tab><tab>d.SetText(""Nearly done..."")<tab><tab>win32api.Sleep(20)<tab><tab>d.Tick()<tab>d.Close()",0,if i == 90 :,elif i == 50 :,0.058575651,32.46679155,0.333333333
"def get_file_contents(app_name: str, app_version: str, file_path: str):<tab>full_path = f""{app_name}/{app_version}/{file_path}""<tab>success, contents = await MinioApi.get_file(app_name, app_version, file_path)<tab>if success:<tab><tab>return contents<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise DoesNotExistException(""read"", ""file"", full_path)<tab><tab>else:<tab><tab><tab>raise InvalidInputException(<tab><tab><tab><tab>""read"", ""file"", full_path, errors={""error"": contents}<tab><tab><tab>)",0,if contents is None :,"if app_version == ""1.0"" :",0.034123066,4.990049702,0.28
"def _sashMark(self, event):<tab>self._sashIndex = -1<tab>try:<tab><tab>self._sashIndex, which = self.paneframe.identify(event.x, event.y)<tab><tab><IF-STMT><tab><tab><tab>self._sashx = [<tab><tab><tab><tab>self.paneframe.sash_coord(i)[0] for i in range(len(self._lists) - 1)<tab><tab><tab>]<tab><tab><tab>self._sashdx = self._sashx[self._sashIndex] - event.x<tab><tab><tab>self._sashDrag(event)<tab><tab>else:<tab><tab><tab>self._sashIndex = -1<tab>except:<tab><tab>return<tab>return ""break""",0,"if which == ""sash"" :","if which == ""wheel"" :",0.394778655,59.46035575,1
"def emptyTree(self):<tab>for child in self:<tab><tab>childObj = child.getObject()<tab><tab>del childObj[NameObject(""/Parent"")]<tab><tab><IF-STMT><tab><tab><tab>del childObj[NameObject(""/Next"")]<tab><tab>if NameObject(""/Prev"") in childObj:<tab><tab><tab>del childObj[NameObject(""/Prev"")]<tab>if NameObject(""/Count"") in self:<tab><tab>del self[NameObject(""/Count"")]<tab>if NameObject(""/First"") in self:<tab><tab>del self[NameObject(""/First"")]<tab>if NameObject(""/Last"") in self:<tab><tab>del self[NameObject(""/Last"")]",1,"if NameObject ( ""/Next"" ) in childObj :","if NameObject ( ""/Next"" ) in childObj :",0.75,100,1
"def contractIfNotCurrent(c, p, leaveOpen):<tab>if p == leaveOpen or not p.isAncestorOf(leaveOpen):<tab><tab>p.contract()<tab>for child in p.children():<tab><tab><IF-STMT><tab><tab><tab>contractIfNotCurrent(c, child, leaveOpen)<tab><tab>else:<tab><tab><tab>for p2 in child.self_and_subtree():<tab><tab><tab><tab>p2.contract()",0,if child != leaveOpen and child . isAncestorOf ( leaveOpen ) :,if child . isAncestorOf ( c ) :,0.224009907,24.18316496,0.347985348
"def test_cat(shape, cat_dim, split, dim):<tab>assert sum(split) == shape[cat_dim]<tab>gaussian = random_gaussian(shape, dim)<tab>parts = []<tab>end = 0<tab>for size in split:<tab><tab>beg, end = end, end + size<tab><tab>if cat_dim == -1:<tab><tab><tab>part = gaussian[..., beg:end]<tab><tab>elif cat_dim == -2:<tab><tab><tab>part = gaussian[..., beg:end, :]<tab><tab><IF-STMT><tab><tab><tab>part = gaussian[:, beg:end]<tab><tab>else:<tab><tab><tab>raise ValueError<tab><tab>parts.append(part)<tab>actual = Gaussian.cat(parts, cat_dim)<tab>assert_close_gaussian(actual, gaussian)",0,elif cat_dim == 1 :,elif cat_dim == - 3 :,0.438215641,61.04735836,0.5
"def _remove_timeout(self, key):<tab>if key in self.waiting:<tab><tab>request, callback, timeout_handle = self.waiting[key]<tab><tab><IF-STMT><tab><tab><tab>self.io_loop.remove_timeout(timeout_handle)<tab><tab>del self.waiting[key]",1,if timeout_handle is not None :,if timeout_handle is not None :,0.75,100,1
"def gyro(self, mapper, *pyr):<tab>for i in (0, 1, 2):<tab><tab>axis = self.axes[i]<tab><tab># 'gyro' cannot map to mouse, but 'mouse' does that.<tab><tab><IF-STMT><tab><tab><tab>mapper.gamepad.axisEvent(<tab><tab><tab><tab>axis, AxisAction.clamp_axis(axis, pyr[i] * self.speed[i] * -10)<tab><tab><tab>)<tab><tab><tab>mapper.syn_list.add(mapper.gamepad)",0,if axis in Axes or type ( axis ) == int :,if mapper . gamepad . axisEvent is not None :,0.086002841,3.696719741,0.134920635
"def check_enums_ATLAS_MACHTYPE(lines):<tab>for i, mach_type in enumerate(ATLAS_MACHTYPE):<tab><tab>got = lines.pop(0).strip()<tab><tab>expect = ""{0} = '{1}'"".format(i, mach_type)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""ATLAS_MACHTYPE mismatch at position ""<tab><tab><tab><tab>+ str(i)<tab><tab><tab><tab>+ "": got >>""<tab><tab><tab><tab>+ got<tab><tab><tab><tab>+ ""<<, expected >>""<tab><tab><tab><tab>+ expect<tab><tab><tab><tab>+ ""<<""<tab><tab><tab>)",1,if got != expect :,if got != expect :,0.75,100,1
"def readArgs(self, node):<tab>res = {}<tab>for c in self.getChildrenOf(node):<tab><tab>val = c.getAttribute(""val"")<tab><tab>if val in self.modules:<tab><tab><tab>res[str(c.nodeName)] = self.modules[val]<tab><tab><IF-STMT><tab><tab><tab>res[str(c.nodeName)] = self.mothers[val]<tab><tab>elif val != """":<tab><tab><tab>res[str(c.nodeName)] = eval(val)<tab>return res",1,elif val in self . mothers :,elif val in self . mothers :,0.75,100,1
"def submit_events(self, events):<tab>headers = {""Content-Type"": ""application/json""}<tab>event_chunk_size = self.event_chunk_size<tab>for chunk in chunks(events, event_chunk_size):<tab><tab>payload = {<tab><tab><tab>""apiKey"": self.api_key,<tab><tab><tab>""events"": {""api"": chunk},<tab><tab><tab>""uuid"": get_uuid(),<tab><tab><tab>""internalHostname"": get_hostname(),<tab><tab>}<tab><tab>params = {}<tab><tab><IF-STMT><tab><tab><tab>params[""api_key""] = self.api_key<tab><tab>url = ""%s/intake?%s"" % (self.api_host, urlencode(params))<tab><tab>self.submit_http(url, json.dumps(payload), headers)",1,if self . api_key :,if self . api_key :,0.75,100,1
"def rewrite_urls_mygpo(self):<tab># Check if we have to rewrite URLs since the last add<tab>rewritten_urls = self.mygpo_client.get_rewritten_urls()<tab>changed = False<tab>for rewritten_url in rewritten_urls:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for channel in self.channels:<tab><tab><tab>if channel.url == rewritten_url.old_url:<tab><tab><tab><tab>logger.info(""Updating URL of %s to %s"", channel, rewritten_url.new_url)<tab><tab><tab><tab>channel.url = rewritten_url.new_url<tab><tab><tab><tab>channel.save()<tab><tab><tab><tab>changed = True<tab><tab><tab><tab>break<tab>if changed:<tab><tab>util.idle_add(self.update_episode_list_model)",0,if not rewritten_url . new_url :,if rewritten_url . new_url == rewritten_url . old_url :,0.092221463,37.87954736,0.644444444
"def validate_hostname(hostname):<tab>if hostname is None or len(hostname) == 0:<tab><tab>return False, ""Empty hostname or domain is not allowed""<tab>fields = hostname.split(""."")<tab>for field in fields:<tab><tab>if not field:<tab><tab><tab>return False, ""Empty hostname or domain is not allowed""<tab><tab><IF-STMT><tab><tab><tab>return False, ""Hostname or domain should not start or end with '-'""<tab>machinename = fields[0]<tab>if len(machinename) > 64 or not machinename[0].isalpha():<tab><tab>return False, ""Hostname should start with alpha char and <= 64 chars""<tab>return True, None",0,"if field [ 0 ] == ""-"" or field [ - 1 ] == ""-"" :","if fields [ 0 ] . startswith ( ""-"" ) :",0.068304555,10.39902837,0.363636364
"def apply_to(cls, lexer):<tab># Apply a font for all styles<tab>lexer.setFont(Font().load())<tab>for name, font in cls.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if hasattr(lexer, name):<tab><tab><tab>style_num = getattr(lexer, name)<tab><tab><tab>lexer.setColor(QColor(font.color), style_num)<tab><tab><tab>lexer.setEolFill(True, style_num)<tab><tab><tab>lexer.setPaper(QColor(font.paper), style_num)<tab><tab><tab>lexer.setFont(font.load(), style_num)",0,"if not isinstance ( font , Font ) :","if name . startswith ( ""_"" ) :",0.031766029,9.980099404,0.257142857
"def dr_relation(self, C, trans, nullable):<tab>state, N = trans<tab>terms = []<tab>g = self.lr0_goto(C[state], N)<tab>for p in g:<tab><tab>if p.lr_index < p.len - 1:<tab><tab><tab>a = p.prod[p.lr_index + 1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if a not in terms:<tab><tab><tab><tab><tab>terms.append(a)<tab># This extra bit is to handle the start state<tab>if state == 0 and N == self.grammar.Productions[0].prod[0]:<tab><tab>terms.append(""$end"")<tab>return terms",0,if a in self . grammar . Terminals :,if not nullable :,0.015402161,5.442414219,0.185185185
"def process_module(name, module, parent):<tab>if parent:<tab><tab>modules[parent][""items""].append(name)<tab><tab>mg = module_groups.setdefault(name, [])<tab><tab>mg.append(parent)<tab><tab><IF-STMT><tab><tab><tab>module["".group""] = parent<tab># check module content<tab>for k, v in list(module.items()):<tab><tab>if k.startswith(""on_click""):<tab><tab><tab># on_click event<tab><tab><tab>process_onclick(k, v, name)<tab><tab><tab># on_click should not be passed to the module via the config.<tab><tab><tab>del module[k]<tab><tab>if isinstance(v, ModuleDefinition):<tab><tab><tab># we are a container<tab><tab><tab>module[""items""] = []<tab>return module",0,"if get_module_type ( name ) == ""py3status"" :",if mg :,0.016200585,1.00E-10,0.5
"def GetQualifiedWsdlName(type):<tab>with _lazyLock:<tab><tab>wsdlNSAndName = _wsdlNameMap.get(type)<tab><tab><IF-STMT><tab><tab><tab>return wsdlNSAndName<tab><tab>else:<tab><tab><tab>if issubclass(type, list):<tab><tab><tab><tab>ns = GetWsdlNamespace(type.Item._version)<tab><tab><tab><tab>return (ns, ""ArrayOf"" + Capitalize(type.Item._wsdlName))<tab><tab><tab>else:<tab><tab><tab><tab>ns = GetWsdlNamespace(type._version)<tab><tab><tab><tab>return (ns, type._wsdlName)",1,if wsdlNSAndName :,if wsdlNSAndName :,0.531170663,1.00E-10,1
"def assert_tensors_equal(sess, t1, t2, n):<tab>""""""Compute tensors `n` times and ensure that they are equal.""""""<tab>for _ in range(n):<tab><tab>v1, v2 = sess.run([t1, t2])<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if not np.all(v1 == v2):<tab><tab><tab>return False<tab>return True",0,if v1 . shape != v2 . shape :,if not np . all ( v1 != v2 ) :,0.030408813,15.5801057,0.238636364
"def _lxml_default_loader(href, parse, encoding=None, parser=None):<tab>if parse == ""xml"":<tab><tab>data = etree.parse(href, parser).getroot()<tab>else:<tab><tab>if ""://"" in href:<tab><tab><tab>f = urlopen(href)<tab><tab>else:<tab><tab><tab>f = open(href, ""rb"")<tab><tab>data = f.read()<tab><tab>f.close()<tab><tab><IF-STMT><tab><tab><tab>encoding = ""utf-8""<tab><tab>data = data.decode(encoding)<tab>return data",0,if not encoding :,if encoding is None :,0.045150551,14.05853313,0.277777778
"def range_f(begin, end, step):<tab># like range, but works on non-integer too<tab>seq = []<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if step < 0 and begin < end:<tab><tab><tab>break<tab><tab>seq.append(begin)<tab><tab>begin = begin + step<tab>return seq",1,if step > 0 and begin > end :,if step > 0 and begin > end :,0.75,100,1
"def _get_seccomp_whitelist(self):<tab>whitelist = [False] * MAX_SYSCALL_NUMBER<tab>index = _SYSCALL_INDICIES[NATIVE_ABI]<tab>for i in range(SYSCALL_COUNT):<tab><tab># Ensure at least one syscall traps.<tab><tab># Otherwise, a simple assembly program could terminate without ever trapping.<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>handler = self._security.get(i, DISALLOW)<tab><tab>for call in translator[i][index]:<tab><tab><tab>if call is None:<tab><tab><tab><tab>continue<tab><tab><tab>if isinstance(handler, int):<tab><tab><tab><tab>whitelist[call] = handler == ALLOW<tab>return whitelist",0,"if i in ( sys_exit , sys_exit_group ) :",if len ( translator [ i ] ) < 1 :,0.016518695,3.895748804,0.265306122
"def add_custom_versions(versions):<tab>""""""create custom versions strings""""""<tab>versions_dict = {}<tab>for tech, version in versions.items():<tab><tab># clean up ""-"" from version<tab><tab>if ""-"" in version:<tab><tab><tab>version = version.split(""-"")[0]<tab><tab><IF-STMT><tab><tab><tab>version = version[1:]  # Remove the 'v' prefix<tab><tab><tab>versions_dict[tech + ""_numeric""] = version.split(""+"")[0]<tab><tab><tab># ""3.3.0.33"" is what we have, we want ""3.3""<tab><tab><tab>versions_dict[tech + ""_short""] = ""{}.{}"".format(*version.split("".""))<tab>return versions_dict",0,"if version . startswith ( ""v"" ) :","if version [ 0 ] == ""v"" :",0.036228951,18.36028135,0.6
"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>newtext.append(line[self.tab_length :])<tab><tab>elif not line.strip():<tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",0,"if line . startswith ( "" "" * self . tab_length ) :",if line . startswith ( self . tab_length ) :,0.334244725,64.98720967,1
"def ignore_module(module):<tab>result = False<tab>for check in ignore_these:<tab><tab>if ""/*"" in check:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab>if (os.getcwd() + ""/"" + check + "".py"") == module:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_warning(""Ignoring module: "" + module)<tab>return result",0,if check [ : - 1 ] in module :,"if os . path . isfile ( check + "".py"" ) :",0.013494195,3.458592114,0.222222222
def load_previous_values(self):<tab>ReportOptions.load_previous_values(self)<tab># Pass the loaded values to the menu options so they will be displayed<tab># properly.<tab>for optname in self.options_dict:<tab><tab>menu_option = self.menu.get_option_by_name(optname)<tab><tab><IF-STMT><tab><tab><tab>menu_option.set_value(self.options_dict[optname]),1,if menu_option :,if menu_option :,0.531170663,1.00E-10,1
"def dequeue(self):<tab>with self.db(commit=True) as curs:<tab><tab>curs.execute(<tab><tab><tab>""select id, data from task where queue = ? ""<tab><tab><tab>""order by priority desc, id limit 1"",<tab><tab><tab>(self.name,),<tab><tab>)<tab><tab>result = curs.fetchone()<tab><tab><IF-STMT><tab><tab><tab>tid, data = result<tab><tab><tab>curs.execute(""delete from task where id = ?"", (tid,))<tab><tab><tab>if curs.rowcount == 1:<tab><tab><tab><tab>return to_bytes(data)",0,if result is not None :,if result :,0.050438393,1.00E-10,0.4
"def _collect_sublayers_attr(self, attr):<tab>if attr not in [""trainable_weights"", ""nontrainable_weights""]:<tab><tab>raise ValueError(<tab><tab><tab>""Only support to collect some certain attributes of nested layers,""<tab><tab><tab>""e.g. 'trainable_weights', 'nontrainable_weights', but got {}"".format(attr)<tab><tab>)<tab>if self._layers is None:<tab><tab>return []<tab>nested = []<tab>for layer in self._layers:<tab><tab>value = getattr(layer, attr)<tab><tab><IF-STMT><tab><tab><tab>nested.extend(value)<tab>return nested",0,if value is not None :,"if isinstance ( value , list ) :",0.023749772,7.267884212,0.232142857
"def DeleteTab(self, tab):<tab>tab_renderer = self.tabs[tab]<tab>was_selected = tab_renderer.GetSelected()<tab>self.tabs.remove(tab_renderer)<tab>if tab_renderer:<tab><tab>del tab_renderer<tab># determine our new selection<tab>if was_selected and self.GetTabsCount() > 0:<tab><tab><IF-STMT><tab><tab><tab>self.tabs[self.GetTabsCount() - 1].SetSelected(True)<tab><tab>else:<tab><tab><tab>self.tabs[tab].SetSelected(True)<tab>self.AdjustTabsSize()<tab>self.Refresh()",0,if tab > self . GetTabsCount ( ) - 1 :,if self . GetTabsCount ( ) > 1 :,0.301741475,43.7709134,0.320512821
"def _show_warnings(self):<tab>if self._warnings_handled:<tab><tab>return<tab>self._warnings_handled = True<tab>if self._result and (self._result.has_next or not self._result.warning_count):<tab><tab>return<tab>ws = self._get_db().show_warnings()<tab>if ws is None:<tab><tab>return<tab>for w in ws:<tab><tab>msg = w[-1]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(msg, unicode):<tab><tab><tab><tab>msg = msg.encode(""utf-8"", ""replace"")<tab><tab>warnings.warn(err.Warning(*w[1:3]), stacklevel=4)",0,if PY2 :,if msg is not None :,0.048107739,1.00E-10,0.2
"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ not in content:<tab><tab>content = retrieve_content(__backup__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>retval[line] = (__info__, __reference__)<tab>return retval",0,"if not line or line . startswith ( ""#"" ) or ""."" not in line :","if not line or line . startswith ( ""#"" ) :",0.664314485,54.3143318,0.697619048
"def findUserByAttr(self, identifier, attr_type, attr_data):<tab>for uid in self.users_info:<tab><tab>attrs = self.users_info[uid]<tab><tab>for attr in attrs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return defer.succeed(uid)<tab>uid = self.nextId()<tab>self.db.insertTestData([User(uid=uid, identifier=identifier)])<tab>self.db.insertTestData(<tab><tab>[UserInfo(uid=uid, attr_type=attr_type, attr_data=attr_data)]<tab>)<tab>return defer.succeed(uid)",0,"if attr_type == attr [ ""attr_type"" ] and attr_data == attr [ ""attr_data"" ] :",if attr . identifier == identifier :,0.008962882,1.196402103,0.533333333
"def order_note_added_event(*, order: Order, user: UserType, message: str) -> OrderEvent:<tab>kwargs = {}<tab>if user is not None and not user.is_anonymous:<tab><tab><IF-STMT><tab><tab><tab>account_events.customer_added_to_note_order_event(<tab><tab><tab><tab>user=user, order=order, message=message<tab><tab><tab>)<tab><tab>kwargs[""user""] = user<tab>return OrderEvent.objects.create(<tab><tab>order=order,<tab><tab>type=OrderEvents.NOTE_ADDED,<tab><tab>parameters={""message"": message},<tab><tab>**kwargs,<tab>)",0,if order . user is not None and order . user . pk == user . pk :,"if account_events . has_customer_added_to_note_event ( order = order , message = message ) :",0.133461371,2.349721593,0.213157895
"def __str__(self):<tab>if self.team:<tab><tab><IF-STMT><tab><tab><tab>return ""(%s, %s, Q%d, %d and %d) %s"" % (<tab><tab><tab><tab>self.team,<tab><tab><tab><tab>self.data[""yrdln""],<tab><tab><tab><tab>self.time.qtr,<tab><tab><tab><tab>self.down,<tab><tab><tab><tab>self.yards_togo,<tab><tab><tab><tab>self.desc,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return ""(%s, %s, Q%d) %s"" % (<tab><tab><tab><tab>self.team,<tab><tab><tab><tab>self.data[""yrdln""],<tab><tab><tab><tab>self.time.qtr,<tab><tab><tab><tab>self.desc,<tab><tab><tab>)<tab>return self.desc",0,if self . down != 0 :,if self . yards_togo :,0.094532291,22.77210132,0.55
"def write(self, stream):<tab>self.write1(stream)<tab>i = 0<tab>n = 0<tab>for name, offset, value, bsize in self.variables:<tab><tab>stream.write(self.body[i:offset])<tab><tab><IF-STMT><tab><tab><tab>write_uint(stream, value)<tab><tab>elif bsize == 8:<tab><tab><tab>write_ulong(stream, value)<tab><tab>else:<tab><tab><tab>raise NotImplementedError()<tab><tab>n += offset - i + bsize<tab><tab>i = offset + bsize<tab>stream.write(self.body[i:])<tab>n += len(self.body) - i<tab>assert n == len(self.body)",1,if bsize == 4 :,if bsize == 4 :,0.75,100,1
"def __setattr__(self, attr, val):<tab>if hasattr(self, attr):<tab><tab>old = getattr(self, attr)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(val, Setting):<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""Attempting to reassign setting %s with %s"" % (old, val)<tab><tab><tab><tab>)<tab><tab><tab>log.warn(""Setting attr %s via __setattr__ instead of set()!"", attr)<tab><tab><tab>return old.set(val)<tab>log.debug(""Setting {%s => %s}"" % (attr, val))<tab>return object.__setattr__(self, attr, val)",0,"if isinstance ( old , Setting ) :",if old is not None :,0.019830745,7.654112967,0.232142857
"def setup_release_cwd_hook(prompter, history, completer, bindings, **kw):<tab>if ON_WINDOWS and not ON_CYGWIN and not ON_MSYS:<tab><tab>prompter.prompt = _cwd_release_wrapper(prompter.prompt)<tab><tab><IF-STMT><tab><tab><tab># Temporarily restore cwd for callbacks to the completer<tab><tab><tab>completer.completer.complete = _cwd_restore_wrapper(<tab><tab><tab><tab>completer.completer.complete<tab><tab><tab>)",0,if completer . completer :,if ON_WINDOWS and not ON_MSYS :,0.030286783,4.990049702,0.4
"def nested_update(org_dict, upd_dict):<tab>for key, value in upd_dict.items():<tab><tab><IF-STMT><tab><tab><tab>if key in org_dict:<tab><tab><tab><tab>if not isinstance(org_dict[key], dict):<tab><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab><tab>""Mismatch between org_dict and upd_dict at node {}"".format(key)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>nested_update(org_dict[key], value)<tab><tab><tab>else:<tab><tab><tab><tab>org_dict[key] = value<tab><tab>else:<tab><tab><tab>org_dict[key] = value",1,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",0.75,100,1
"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab>if not f:<tab><tab><tab>continue<tab><tab>if f == ""->"":<tab><tab><tab>obj = obj.dereference()<tab><tab>elif f == ""."":<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj",1,"elif f . startswith ( ""["" ) :","elif f . startswith ( ""["" ) :",0.75,100,1
"def check_sum(self, x, gpu=False):<tab>total = 0<tab>for i in range(5):<tab><tab>t = numpy.array([i], dtype=numpy.int32)<tab><tab><IF-STMT><tab><tab><tab>t = cuda.to_gpu(t)<tab><tab>loss = self.link(chainer.Variable(x), chainer.Variable(t)).data<tab><tab>self.assertEqual(loss.dtype, self.dtype)<tab><tab>self.assertEqual(loss.shape, ())<tab><tab>total += numpy.exp(-cuda.to_cpu(loss))<tab>self.assertAlmostEqual(1.0, float(total), **self.check_sum_options)",1,if gpu :,if gpu :,0.531170663,1.00E-10,1
"def find_node_by_link(node_group, to_node, inp):<tab>for link in node_group.links:<tab><tab>if link.to_node == to_node and link.to_socket == inp:<tab><tab><tab><IF-STMT>  # Step through reroutes<tab><tab><tab><tab>return find_node_by_link(<tab><tab><tab><tab><tab>node_group, link.from_node, link.from_node.inputs[0]<tab><tab><tab><tab>)<tab><tab><tab>return link.from_node",0,"if link . from_node . bl_idname == ""NodeReroute"" :",if link . from_node . inputs :,0.241924303,34.48559826,0.730769231
"def _gen_opnds(ii):  # generator<tab># filter out write-mask operands and suppressed operands<tab>for op in ii.parsed_operands:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if op.visibility == ""SUPPRESSED"":<tab><tab><tab>continue<tab><tab>if op.name == ""BCAST"":<tab><tab><tab>continue<tab><tab>yield op",0,"if op . lookupfn_name in [ ""MASK1"" , ""MASKNOT0"" ] :","if op . name == ""MASK"" :",0.052382556,9.586514612,0.6
"def contains_trained_model(self):<tab>if not hasattr(self, ""_contains_trained_model""):<tab><tab>for f in self._files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._contains_trained_model = True<tab><tab><tab><tab>self._model_name = f<tab><tab><tab><tab>return self._contains_trained_model<tab><tab>self._contains_trained_model = False<tab><tab>return self._contains_trained_model<tab>else:<tab><tab>return self._contains_trained_model",0,"if "".pt"" in f :","if f . endswith ( "".py"" ) :",0.02800146,9.864703139,0.4
"def _call(self, name, *args, **kwargs):<tab>data = self._get_data(name, *args, **kwargs)<tab>is_ascii = self._encoding == ""ascii""<tab>body = json.dumps(data, ensure_ascii=is_ascii).encode(self._encoding)<tab>resp = await self._http.post(self._url, data=body)<tab>if self._full_response:<tab><tab>return resp<tab>else:<tab><tab>content = resp.json()<tab><tab>if resp.is_error:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>resp.raise_for_status()<tab><tab>return self.loads(content)",0,"if ""error"" not in content :",if resp . status != 200 :,0.023878899,6.567274736,0.25
"def get_classif_name(classifier_config, usepytorch):<tab>if not usepytorch:<tab><tab>modelname = ""sklearn-LogReg""<tab>else:<tab><tab>nhid = classifier_config[""nhid""]<tab><tab>optim = (<tab><tab><tab>""adam"" if ""optim"" not in classifier_config else classifier_config[""optim""]<tab><tab>)<tab><tab>bs = (<tab><tab><tab>64<tab><tab><tab><IF-STMT><tab><tab><tab>else classifier_config[""batch_size""]<tab><tab>)<tab><tab>modelname = ""pytorch-MLP-nhid%s-%s-bs%s"" % (nhid, optim, bs)<tab>return modelname",1,"if ""batch_size"" not in classifier_config","if ""batch_size"" not in classifier_config",0.75,100,1
"def on_fill(self, order: Order, exchange: ""Exchange"", trade: ""Trade""):<tab>if trade.order_id in self._executed and trade not in self._trades:<tab><tab>self._trades[trade.order_id] = self._trades.get(trade.order_id, [])<tab><tab>self._trades[trade.order_id] += [trade]<tab><tab>if order.is_complete():<tab><tab><tab>next_order = order.complete(exchange)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.submit(next_order)",1,if next_order :,if next_order :,0.531170663,1.00E-10,1
"def _create_examples(cls, lines, set_type):<tab>examples = []<tab>for (i, line) in enumerate(lines):<tab><tab># Skip the header (first line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>segments = line.strip().split(""\t"")<tab><tab>idx, text_a, text_b, label = segments<tab><tab>examples.append(<tab><tab><tab>Example(<tab><tab><tab><tab>guid=""%s-%s"" % (set_type, idx),<tab><tab><tab><tab>text_a=text_a,<tab><tab><tab><tab>text_b=text_b,<tab><tab><tab><tab>label=label,<tab><tab><tab>)<tab><tab>)<tab>return examples",1,if i == 0 :,if i == 0 :,0.75,100,1
"def split_path_info(path):<tab># suitable for splitting an already-unquoted-already-decoded (unicode)<tab># path value<tab>path = path.strip(""/"")<tab>clean = []<tab>for segment in path.split(""/""):<tab><tab>if not segment or segment == ""."":<tab><tab><tab>continue<tab><tab>elif segment == "".."":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del clean[-1]<tab><tab>else:<tab><tab><tab>clean.append(segment)<tab>return tuple(clean)",0,if clean :,if len ( clean ) > 1 :,0.0465226,1.00E-10,0.36
"def _mock_manager(self, *args, **kwargs):<tab>if kwargs and ""normalize"" not in kwargs:<tab><tab>device_params = kwargs[""device_params""]<tab><tab>device_handler = make_device_handler(device_params)<tab><tab>session = SSHSession(device_handler)<tab><tab>return Manager(session, device_handler)<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>file_name = (args[0].findtext(""command"")).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")<tab><tab>elif args[0].tag == ""command"":<tab><tab><tab>file_name = (args[0].text).replace("" "", ""_"")<tab><tab><tab>return self._read_file(file_name + "".xml"")",0,"if args [ 0 ] . tag == ""request-pfe-execute"" :","if args [ 0 ] . tag == ""command"" :",0.642805659,79.10665072,1
"def update_loan_status(self, cancel=0):<tab>if cancel:<tab><tab>loan_status = frappe.get_value(""Loan"", self.loan, ""status"")<tab><tab><IF-STMT><tab><tab><tab>frappe.db.set_value(""Loan"", self.loan, ""status"", ""Loan Closure Requested"")<tab>else:<tab><tab>pledged_qty = 0<tab><tab>current_pledges = get_pledged_security_qty(self.loan)<tab><tab>for security, qty in iteritems(current_pledges):<tab><tab><tab>pledged_qty += qty<tab><tab>if not pledged_qty:<tab><tab><tab>frappe.db.set_value(""Loan"", self.loan, ""status"", ""Closed"")",0,"if loan_status == ""Closed"" :","if loan_status == ""Completed"" :",0.394778655,70.71067812,1
"def _wrapped_view(request, *args, **kwargs):<tab>if flag_name.startswith(""!""):<tab><tab>active = not flag_is_active(request, flag_name[1:])<tab>else:<tab><tab>active = flag_is_active(request, flag_name)<tab>if not active:<tab><tab>response_to_redirect_to = get_response_to_redirect(redirect_to, *args, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>return response_to_redirect_to<tab><tab>else:<tab><tab><tab>raise Http404<tab>return view(request, *args, **kwargs)",1,if response_to_redirect_to :,if response_to_redirect_to :,0.531170663,1.00E-10,1
"def process_stroke_filter(stroke, min_distance=1.0, max_distance=2.0):<tab>""""""filter stroke to pts that are at least min_distance apart""""""<tab>nstroke = stroke[:1]<tab>for p in stroke[1:]:<tab><tab>v = p - nstroke[-1]<tab><tab>l = v.length<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>d = v / l<tab><tab>while l > 0:<tab><tab><tab>q = nstroke[-1] + d * min(l, max_distance)<tab><tab><tab>nstroke.append(q)<tab><tab><tab>l -= max_distance<tab>return nstroke",1,if l < min_distance :,if l < min_distance :,0.75,100,1
"def _fix_break_node(self, node: Node):<tab>end_node = self._find_end_loop(node, [], 0)<tab><IF-STMT><tab><tab># If there is not end condition on the loop<tab><tab># The exploration will reach a STARTLOOP before reaching the endloop<tab><tab># We start with -1 as counter to catch this corner case<tab><tab>end_node = self._find_end_loop(node, [], -1)<tab><tab>if not end_node:<tab><tab><tab>raise ParsingError(""Break in no-loop context {}"".format(node.function))<tab>for son in node.sons:<tab><tab>son.remove_father(node)<tab>node.set_sons([end_node])<tab>end_node.add_father(node)",1,if not end_node :,if not end_node :,0.75,100,1
"def _Append(cls, session, word, mail_ids, compact=True):<tab>super(GlobalPostingList, cls)._Append(session, word, mail_ids, compact=compact)<tab>with GLOBAL_GPL_LOCK:<tab><tab>global GLOBAL_GPL<tab><tab>sig = cls.WordSig(word, session.config)<tab><tab><IF-STMT><tab><tab><tab>GLOBAL_GPL = {}<tab><tab>if sig not in GLOBAL_GPL:<tab><tab><tab>GLOBAL_GPL[sig] = set()<tab><tab>for mail_id in mail_ids:<tab><tab><tab>GLOBAL_GPL[sig].add(mail_id)",1,if GLOBAL_GPL is None :,if GLOBAL_GPL is None :,0.75,100,1
"def __saveComment(self):<tab>""""""Saves the new or selected comment""""""<tab>if self.__btnSave.text() == SAVE_NEW:<tab><tab># If saving a new comment<tab><tab>self.__addComment(self.__textSubject.text(), self.__textMessage.toPlainText())<tab><tab>self.refreshComments()<tab>else:<tab><tab># If saving a modified comment<tab><tab><IF-STMT><tab><tab><tab>comment = self.__treeSubjects.currentItem().getInstance()<tab><tab><tab>comment.setSubject(str(self.__textSubject.text()))<tab><tab><tab>comment.setMessage(str(self.__textMessage.toPlainText()))<tab><tab><tab>self.__treeSubjects.currentItem().getInstance().save()<tab><tab><tab>self.refreshComments()",0,if self . __treeSubjects . currentItem ( ) :,if self . __treeSubjects . currentIndex ( ) . isChecked ( ) :,0.397344681,49.20274515,0.49122807
"def verify_random_objects():<tab>resources = [Node, Registration, QuickFilesNode]<tab>for resource in resources:<tab><tab>for i in range(1, 10):<tab><tab><tab>random_resource = _get_random_object(resource)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_verify_contributor_perms(random_resource)",0,if random_resource :,if random_resource is not None :,0.090364769,1.00E-10,0.314285714
"def apply_gradient_modifiers(self):<tab>for layer_name, views in self.gradient_modifiers.items():<tab><tab>for view_name, gradient_mods in views.items():<tab><tab><tab>for gm in gradient_mods:<tab><tab><tab><tab>gm.rnd.set_seed(self.rnd.generate_seed())<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>gm(<tab><tab><tab><tab><tab><tab>self.handler,<tab><tab><tab><tab><tab><tab>self.buffer[layer_name].parameters[view_name],<tab><tab><tab><tab><tab><tab>self.buffer[layer_name].gradients[view_name],<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>gm(self.handler, self.buffer[layer_name].gradients[view_name])",0,"if isinstance ( gm , GradientModifier ) :",if view_name in self . buffer :,0.018333425,5.669791111,0.25
"def _split_auth_string(auth_string):<tab>""""""split a digest auth string into individual key=value strings""""""<tab>prev = None<tab>for item in auth_string.split("",""):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prev = ""%s,%s"" % (prev, item)<tab><tab><tab><tab>continue<tab><tab>except AttributeError:<tab><tab><tab>if prev == None:<tab><tab><tab><tab>prev = item<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>raise StopIteration<tab><tab>yield prev.strip()<tab><tab>prev = item<tab>yield prev.strip()<tab>raise StopIteration",0,"if prev . count ( '""' ) == 1 :",if prev != None :,0.025595153,6.011598679,0.487179487
"def checkUnchangedIvars(obj, d, exceptions=None):<tab>if not exceptions:<tab><tab>exceptions = []<tab>ok = True<tab>for key in d:<tab><tab><IF-STMT><tab><tab><tab>if getattr(obj, key) != d.get(key):<tab><tab><tab><tab>g.trace(<tab><tab><tab><tab><tab>""changed ivar: %s old: %s new: %s""<tab><tab><tab><tab><tab>% (key, repr(d.get(key)), repr(getattr(obj, key)))<tab><tab><tab><tab>)<tab><tab><tab><tab>ok = False<tab>return ok",1,if key not in exceptions :,if key not in exceptions :,0.75,100,1
def checkChildren(item):<tab>for c in item.children():<tab><tab>_id = c.data(Outline.ID.value)<tab><tab><IF-STMT><tab><tab><tab>c.getUniqueID()<tab><tab>checkChildren(c),0,"if not _id or _id == ""0"" :",if _id is not None and _id != c . getUniqueID ( ) :,0.159064918,7.692375026,0.197530864
"def main():<tab>if len(sys.argv) > 1:<tab><tab>g = globals().copy()<tab><tab>r = g[""test_"" + sys.argv[1]]()<tab><tab><IF-STMT><tab><tab><tab>for func_and_args in r:<tab><tab><tab><tab>func, args = func_and_args[0], func_and_args[1:]<tab><tab><tab><tab>func(*args)<tab>else:<tab><tab>run_all()",0,if r is not None :,if len ( r ) == 2 :,0.023749772,6.274655311,0.232142857
"def _create_entities(<tab>parsed_entities: Dict[Text, Union[Text, List[Text]]], sidx: int, eidx: int) -> List[Dict[Text, Any]]:<tab>entities = []<tab>for k, vs in parsed_entities.items():<tab><tab><IF-STMT><tab><tab><tab>vs = [vs]<tab><tab>for value in vs:<tab><tab><tab>entities.append(<tab><tab><tab><tab>{<tab><tab><tab><tab><tab>""entity"": k,<tab><tab><tab><tab><tab>""start"": sidx,<tab><tab><tab><tab><tab>""end"": eidx,  # can't be more specific<tab><tab><tab><tab><tab>""value"": value,<tab><tab><tab><tab>}<tab><tab><tab>)<tab>return entities",1,"if not isinstance ( vs , list ) :","if not isinstance ( vs , list ) :",0.75,100,1
"def _group_stacks(stacks: Stacks) -> List[dict]:<tab>stacks_by_client: dict = {}<tab>for stack in stacks:<tab><tab>client = stack.client<tab><tab><IF-STMT><tab><tab><tab>stacks_by_client[client] = {""Client"": client, ""Stacks"": []}<tab><tab>stacks_by_client[client][""Stacks""].append(stack)<tab>return [stacks_by_client[r] for r in stacks_by_client]",1,if client not in stacks_by_client :,if client not in stacks_by_client :,0.75,100,1
"def append(self, labels):<tab>if isinstance(labels, list):<tab><tab>for label in labels:<tab><tab><tab>if not label in self.__menuLabels:<tab><tab><tab><tab>self.__menuLabels.append(label)<tab><tab><tab><tab>self.__enabledLabels.append(label)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.__menuLabels.append(labels)<tab><tab><tab>self.__enabledLabels.append(labels)",0,if not labels in self . __menuLabels :,if labels not in self . __menuLabels :,0.540715368,69.85342057,0.666666667
"def _json_to_flat_metrics(self, prefix, data):<tab>for key, value in data.items():<tab><tab><IF-STMT><tab><tab><tab>for k, v in self._json_to_flat_metrics(""%s.%s"" % (prefix, key), value):<tab><tab><tab><tab>yield k, v<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>int(value)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>value = None<tab><tab><tab>finally:<tab><tab><tab><tab>yield (""%s.%s"" % (prefix, key), value)",1,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",0.75,100,1
"def _rename(src, dst):<tab>src = to_unicode(src, sys.getfilesystemencoding())<tab>dst = to_unicode(dst, sys.getfilesystemencoding())<tab>if _rename_atomic(src, dst):<tab><tab>return True<tab>retry = 0<tab>rv = False<tab>while not rv and retry < 100:<tab><tab>rv = _MoveFileEx(src, dst, _MOVEFILE_REPLACE_EXISTING | _MOVEFILE_WRITE_THROUGH)<tab><tab><IF-STMT><tab><tab><tab>time.sleep(0.001)<tab><tab><tab>retry += 1<tab>return rv",1,if not rv :,if not rv :,0.75,100,1
"def expect_stream_start(self):<tab>if isinstance(self.event, StreamStartEvent):<tab><tab><IF-STMT><tab><tab><tab>self.encoding = self.event.encoding<tab><tab>self.write_stream_start()<tab><tab>self.state = self.expect_first_document_start<tab>else:<tab><tab>raise EmitterError(""expected StreamStartEvent, but got %s"" % self.event)",0,"if self . event . encoding and not getattr ( self . stream , ""encoding"" , None ) :",if self . event . encoding is not None :,0.264890131,19.04438163,0.502164502
"def _doWait(self):<tab>doit = True<tab>while doit:<tab><tab># A wrapper method for wait() and the wait thread to use<tab><tab>self.setMeta(""SignalInfo"", None)<tab><tab>self.setMeta(""PendingSignal"", None)<tab><tab>event = self.platformWait()<tab><tab>self.running = False<tab><tab>self.platformProcessEvent(event)<tab><tab>doit = self.shouldRunAgain()<tab><tab><IF-STMT><tab><tab><tab>self._doRun()",1,if doit :,if doit :,0.531170663,1.00E-10,1
"def get_source(self, environment, template):<tab>if self._sep in template:<tab><tab>prefix, name = template.split(self._sep, 1)<tab><tab><IF-STMT><tab><tab><tab>raise TemplateNotFound(template)<tab><tab>return self._mapping[prefix].get_source(environment, name)<tab>return self._default.get_source(environment, template)",1,if prefix not in self . _mapping :,if prefix not in self . _mapping :,0.75,100,1
"def find_child_processes_that_send_spans(pants_result_stderr):<tab>child_processes = set()<tab>for line in pants_result_stderr.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>i = line.rindex("":"")<tab><tab><tab>child_process_pid = line[i + 1 :]<tab><tab><tab>child_processes.add(int(child_process_pid))<tab>return child_processes",0,"if ""Sending spans to Zipkin server from pid:"" in line :","if "":"" in line :",0.299097371,26.01300475,0.171717172
"def list_dependencies_modules(self, *modules):<tab>""""""[UNIT]... show the dependency tree"" """"""<tab>found_all = True<tab>units = []<tab>for module in modules:<tab><tab>matched = self.match_units([module])<tab><tab>if not matched:<tab><tab><tab>logg.error(""no such service '%s'"", module)<tab><tab><tab>found_all = False<tab><tab><tab>continue<tab><tab>for unit in matched:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>units += [unit]<tab>return self.list_dependencies_units(units)  # and found_all",1,if unit not in units :,if unit not in units :,0.75,100,1
"def getCommitFromFile(short=True):<tab>global _gitdir<tab>branch = getBranchFromFile()<tab>commit = None<tab>if _gitdir and branch:<tab><tab><IF-STMT><tab><tab><tab>commitFile = os.path.join(_gitdir, ""HEAD"")<tab><tab>else:<tab><tab><tab>commitFile = os.path.join(_gitdir, ""refs"", ""heads"", branch)<tab><tab>if os.path.isfile(commitFile):<tab><tab><tab>with open(commitFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>commit = f.readline().strip()<tab>if short and commit:<tab><tab>return commit[:8]<tab>else:<tab><tab>return commit",0,"if branch == ""HEAD"" :",if short :,0.03549272,1.00E-10,0.5
"def _node_for(pvector_like, i):<tab>if 0 <= i < pvector_like._count:<tab><tab><IF-STMT><tab><tab><tab>return pvector_like._tail<tab><tab>node = pvector_like._root<tab><tab>for level in range(pvector_like._shift, 0, -SHIFT):<tab><tab><tab>node = node[(i >> level) & BIT_MASK]  # >>><tab><tab>return node<tab>raise IndexError(""Index out of range: %s"" % (i,))",0,if i >= pvector_like . _tail_offset :,if pvector_like . _tail :,0.128034894,39.13352216,0.636363636
"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab>if mysql_user:<tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab><IF-STMT><tab><tab><tab>args[""host""] = mysql_host<tab><tab>if mysql_port:<tab><tab><tab>args[""port""] = mysql_port<tab><tab>if mysql_socket:<tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",1,if mysql_host :,if mysql_host :,0.531170663,1.00E-10,1
"def flatten(self, d, parent_key="""", sep="".""):<tab>items = []<tab>for k, v in d.items():<tab><tab>new_key = parent_key + sep + k if parent_key else k<tab><tab><IF-STMT><tab><tab><tab>items.extend(self.flatten(v, new_key, sep=sep).items())<tab><tab>else:<tab><tab><tab>items.append((new_key, v))<tab>return dict(items)",0,"if isinstance ( v , MutableMapping ) :","if isinstance ( v , dict ) :",0.549040681,59.46035575,0.666666667
"def get_item(type_, preference):<tab>items = {}<tab>for item in playlist.findall(""./info/%s/item"" % type_):<tab><tab>lang, label = xpath_text(item, ""lg"", default=None), xpath_text(<tab><tab><tab>item, ""label"", default=None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>items[lang] = label.strip()<tab>for p in preference:<tab><tab>if items.get(p):<tab><tab><tab>return items[p]",0,if lang and label :,if lang :,0.067674239,1.00E-10,0.5
"def test_lxml():<tab>try:<tab><tab>from lxml.etree import LXML_VERSION, __version__<tab><tab><IF-STMT><tab><tab><tab>return True, __version__<tab><tab>else:<tab><tab><tab>return False, __version__<tab>except ImportError:<tab><tab>return None, None",0,"if LXML_VERSION >= ( 2 , 1 , 4 , 0 ) :",if LXML_VERSION < LXML_VERSION :,0.016853304,14.49940798,0.3
"def send(self, data, flags=0, timeout=timeout_default):<tab>if timeout is timeout_default:<tab><tab>timeout = self.timeout<tab>try:<tab><tab>return self._sock.send(data, flags)<tab>except error as ex:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>sys.exc_clear()<tab><tab>self._wait(self._write_event)<tab><tab>try:<tab><tab><tab>return self._sock.send(data, flags)<tab><tab>except error as ex2:<tab><tab><tab>if ex2.args[0] == EWOULDBLOCK:<tab><tab><tab><tab>return 0<tab><tab><tab>raise",0,if ex . args [ 0 ] not in _socketcommon . GSENDAGAIN or timeout == 0.0 :,if ex . args [ 0 ] != EWOULDBLOCK or timeout <= 0.0 :,0.257794084,41.74441729,0.444444444
def blob_from_lang(self):<tab>self.acquire_lock()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self._load_buf_data_once()<tab><tab><tab>except NotFoundInDatabase:<tab><tab><tab><tab>self.release_lock()<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.scan()<tab><tab><tab><tab>finally:<tab><tab><tab><tab><tab>self.acquire_lock()<tab><tab><tab><tab>self._load_buf_data_once(True)<tab><tab>return self._blob_from_lang_cache<tab>finally:<tab><tab>self.release_lock(),1,if self . _blob_from_lang_cache is None :,if self . _blob_from_lang_cache is None :,0.75,100,1
"def processElem(elem, keyList):<tab>for k, v in elem.items():<tab><tab>prefix = ""."".join(keyList)<tab><tab><IF-STMT><tab><tab><tab>k = makeSane(k)<tab><tab><tab>self.publish(""%s.%s"" % (prefix, k), v)",0,if k not in self . IGNORE_ELEMENTS and self . NUMVAL_MATCH . match ( v ) :,if not k . startswith ( prefix ) :,0.038690108,3.437931802,0.163636364
"def __conform__(self, interface, registry=None, default=None):<tab>for providedInterface in self.provided:<tab><tab>if providedInterface.isOrExtends(interface):<tab><tab><tab>return self.load()<tab><tab><IF-STMT><tab><tab><tab>return interface(self.load(), default)<tab>return default",0,"if getAdapterFactory ( providedInterface , interface , None ) is not None :",elif providedInterface . isOrExtends ( interface ) :,0.011525669,4.420141129,0.171428571
"def restrict(points):<tab>result = []<tab>for p in points:<tab><tab><IF-STMT><tab><tab><tab>result.append(p)<tab><tab>else:<tab><tab><tab>loc, normal, index, distance = bvh.find_nearest(p)<tab><tab><tab>if loc is not None:<tab><tab><tab><tab>result.append(tuple(loc))<tab>return result",0,"if point_inside_mesh ( bvh , p ) :","if isinstance ( p , tuple ) :",0.289168582,8.816389212,0.481481481
"def __iter__(self):<tab>buffer = [b""""]<tab>for chunk in self.stream(decode_content=True):<tab><tab>if b""\n"" in chunk:<tab><tab><tab>chunk = chunk.split(b""\n"")<tab><tab><tab>yield b"""".join(buffer) + chunk[0] + b""\n""<tab><tab><tab>for x in chunk[1:-1]:<tab><tab><tab><tab>yield x + b""\n""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>buffer = [chunk[-1]]<tab><tab><tab>else:<tab><tab><tab><tab>buffer = []<tab><tab>else:<tab><tab><tab>buffer.append(chunk)<tab>if buffer:<tab><tab>yield b"""".join(buffer)",1,if chunk [ - 1 ] :,if chunk [ - 1 ] :,0.75,100,1
"def clear_doc(self, docname: str) -> None:<tab>for sChild in self._children:<tab><tab>sChild.clear_doc(docname)<tab><tab>if sChild.declaration and sChild.docname == docname:<tab><tab><tab>sChild.declaration = None<tab><tab><tab>sChild.docname = None<tab><tab><tab>sChild.line = None<tab><tab><tab>if sChild.siblingAbove is not None:<tab><tab><tab><tab>sChild.siblingAbove.siblingBelow = sChild.siblingBelow<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sChild.siblingBelow.siblingAbove = sChild.siblingAbove<tab><tab><tab>sChild.siblingAbove = None<tab><tab><tab>sChild.siblingBelow = None",1,if sChild . siblingBelow is not None :,if sChild . siblingBelow is not None :,0.75,100,1
"def _get_current_weight(self, policy, fw):<tab>weights = policy.get_weights()<tab>if fw == ""torch"":<tab><tab># DQN model.<tab><tab><IF-STMT><tab><tab><tab>return weights[""_hidden_layers.0._model.0.weight""][0][0]<tab><tab># DDPG model.<tab><tab>else:<tab><tab><tab>return weights[""policy_model.action_0._model.0.weight""][0][0]<tab>key = 0 if fw in [""tf2"", ""tfe""] else list(weights.keys())[0]<tab>return weights[key][0][0]",0,"if ""_hidden_layers.0._model.0.weight"" in weights :",if _hidden_layers . get_active ( ) :,0.027969855,19.89677777,0.45
"def add_unit(self, name, value, aliases=tuple(), **modifiers):<tab>""""""Add unit to the registry.""""""<tab>if not isinstance(value, self.Quantity):<tab><tab>value = self.Quantity(value, **modifiers)<tab>self._UNITS[name] = value<tab>for ndx, alias in enumerate(aliases):<tab><tab><IF-STMT><tab><tab><tab>logger.warn(""Alias cannot contain a space "" + alias)<tab><tab>self._UNITS.add_alias(alias.strip(), name, not ndx)",0,"if "" "" in alias :","if not alias . startswith ( ""_"" ) :",0.022500853,5.604233375,0.484848485
"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab>if keyPressed == Constants.UP_KEY:<tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab>elif keyPressed == Constants.DOWN_KEY:<tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab><IF-STMT><tab><tab><tab>self.tabPressed()<tab><tab>if self.completerStrings:<tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",0,elif keyPressed == Constants . TAB_KEY and self . completerStrings :,elif keyPressed == Constants . TAB_KEY :,0.338686913,60.57025367,0.538461538
"def _add_bookmark_breakpoint(self):<tab>""""""Add a bookmark or breakpoint to the current file in the editor.""""""<tab>editorWidget = self.ide.mainContainer.get_actual_editor()<tab>if editorWidget and editorWidget.hasFocus():<tab><tab><IF-STMT><tab><tab><tab>editorWidget._sidebarWidget.set_bookmark(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)<tab><tab>elif self.ide.mainContainer.actualTab.navigator.operation == 2:<tab><tab><tab>editorWidget._sidebarWidget.set_breakpoint(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)",1,if self . ide . mainContainer . actualTab . navigator . operation == 1 :,if self . ide . mainContainer . actualTab . navigator . operation == 1 :,0.75,100,1
"def list_generator(pages, num_results):<tab>result = []<tab># get first page items<tab>page = list(next(pages))<tab>result += page<tab>while True:<tab><tab>if not pages.continuation_token:<tab><tab><tab>break<tab><tab># handle num results<tab><tab>if num_results is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>page = list(next(pages))<tab><tab>result += page<tab>return result",0,if num_results == len ( result ) :,if num_results > num_results :,0.035401841,25.27114863,0.458333333
"def _print_handles(self, text, handle_list):<tab>for handle in handle_list:<tab><tab>source, citation = self.get_source_or_citation(handle, False)<tab><tab>_LOG.debug(""\n\n\n"")<tab><tab>if source:<tab><tab><tab>_LOG.debug(""---- %s -- source %s"" % (text, source.get_title()))<tab><tab><IF-STMT><tab><tab><tab>_LOG.debug(""---- %s -- citation %s"" % (text, citation.get_page()))<tab><tab>else:<tab><tab><tab>_LOG.debug(""---- %s -- handle %s"" % (text, handle))",0,elif citation :,if citation :,0.112938849,1.00E-10,0.5
"def _parse_whois(self, txt):<tab>asn, desc = None, b""""<tab>for l in txt.splitlines():<tab><tab>if not asn and l.startswith(b""origin:""):<tab><tab><tab>asn = l[7:].strip().decode(""utf-8"")<tab><tab>if l.startswith(b""descr:""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>desc += br""\n""<tab><tab><tab>desc += l[6:].strip()<tab><tab>if asn is not None and desc.strip():<tab><tab><tab>desc = desc.strip().decode(""utf-8"")<tab><tab><tab>break<tab>return asn, desc",1,if desc :,if desc :,0.531170663,1.00E-10,1
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""multiwoz_v20"")<tab>version = ""1.0""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100,1
"def _global_pool2d_shape_func(data_shape, height_axis, width_axis):<tab>out = output_tensor((data_shape.shape[0],), ""int64"")<tab>for i in const_range(out.shape[0]):<tab><tab><IF-STMT><tab><tab><tab>out[i] = int64(1)<tab><tab>else:<tab><tab><tab>out[i] = data_shape[i]<tab>return out",0,if i == height_axis or i == width_axis :,if i == width_axis :,0.193594386,41.68620197,0.625
"def post_mortem(t=None):<tab># handling the default<tab><IF-STMT><tab><tab># sys.exc_info() returns (type, value, traceback) if an exception is<tab><tab># being handled, otherwise it returns None<tab><tab>t = sys.exc_info()[2]<tab><tab>if t is None:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""A valid traceback must be passed if no "" ""exception is being handled""<tab><tab><tab>)<tab>p = Pdb()<tab>p.reset()<tab>p.interaction(None, t)",1,if t is None :,if t is None :,0.75,100,1
"def clear(self, purge=False, delete_dataset=True):<tab>self.deleted = True<tab>if self.dataset:<tab><tab><IF-STMT><tab><tab><tab>self.dataset.deleted = True<tab><tab>if purge:<tab><tab><tab>self.dataset.purged = True<tab>if purge and self.dataset.deleted:  # do something with purging<tab><tab>self.purged = True<tab><tab>try:<tab><tab><tab>os.unlink(self.file_name)<tab><tab>except Exception as e:<tab><tab><tab>log.error(<tab><tab><tab><tab>""Failed to purge associated file ({}) from disk: {}"".format(<tab><tab><tab><tab><tab>self.file_name, unicodify(e)<tab><tab><tab><tab>)<tab><tab><tab>)",1,if delete_dataset :,if delete_dataset :,0.531170663,1.00E-10,1
"def scan_resource_conf(self, conf):<tab>if ""properties"" in conf:<tab><tab><IF-STMT><tab><tab><tab>if str(conf[""properties""][""supportsHttpsTrafficOnly""]).lower() == ""true"":<tab><tab><tab><tab>return CheckResult.PASSED<tab><tab><tab>else:<tab><tab><tab><tab>return CheckResult.FAILED<tab># Use default if supportsHttpsTrafficOnly is not set<tab>if ""apiVersion"" in conf:<tab><tab># Default for apiVersion 2019 and newer is supportsHttpsTrafficOnly = True<tab><tab>year = int(conf[""apiVersion""][0:4])<tab><tab>if year < 2019:<tab><tab><tab>return CheckResult.FAILED<tab><tab>else:<tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",1,"if ""supportsHttpsTrafficOnly"" in conf [ ""properties"" ] :","if ""supportsHttpsTrafficOnly"" in conf [ ""properties"" ] :",0.75,100,1
"def connect(self):<tab>while True:<tab><tab>errno = self.sock.connect_ex(self.addr)<tab><tab>if not errno:<tab><tab><tab># connected immediately.<tab><tab><tab>break<tab><tab>elif errno == EINPROGRESS:<tab><tab><tab># will be connected.<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># no such socket file.<tab><tab><tab>self.create_connection(self.failover_interval)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected socket errno: %d"" % errno)<tab>self.event_loop.watch_file(self.sock.fileno(), self.handle)",0,elif errno == ENOENT :,elif errno == ENOTCONN :,0.642872021,53.72849659,0.6
"def _get_commands():<tab>proc = Popen([""react-native"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab>if ""Commands:"" in line:<tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield line.split("" "")[0]",1,if should_yield :,if should_yield :,0.531170663,1.00E-10,1
"def getintdict(self, section):<tab>try:<tab><tab># Exclude keys from [DEFAULT] section because in general they do not hold int values<tab><tab>return dict(<tab><tab><tab>(key, int(value))<tab><tab><tab>for key, value in self.items(section)<tab><tab><tab><IF-STMT><tab><tab>)<tab>except NoSectionError:<tab><tab>return {}",0,"if key not in { k for k , _ in self . items ( ""DEFAULT"" ) }","if not key . startswith ( ""_"" )",0.069994321,5.347410365,0.172727273
"def _gen_opnds(ii):  # generator<tab># filter out write-mask operands and suppressed operands<tab>for op in ii.parsed_operands:<tab><tab>if op.lookupfn_name in [""MASK1"", ""MASKNOT0""]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if op.name == ""BCAST"":<tab><tab><tab>continue<tab><tab>yield op",0,"if op . visibility == ""SUPPRESSED"" :","if op . lookupfn_name in [ ""MASK1"" , ""MASKNOT0"" ] :",0.071710195,10.12373487,0.6
"def do_definition(tag):<tab>w.end_para()<tab>macro("".TP"")<tab>w.started = True<tab>split = 0<tab>pre = []<tab>post = []<tab>for typ, text in _bitlist(tag):<tab><tab>if split:<tab><tab><tab>post.append((typ, text))<tab><tab><IF-STMT><tab><tab><tab>split = 1<tab><tab><tab>post.append((typ, text.lstrip()[2:].lstrip()))<tab><tab>else:<tab><tab><tab>pre.append((typ, text))<tab>_boldline(pre)<tab>w.write(_text(post))<tab>w.started = False",0,"elif text . lstrip ( ) . startswith ( "": "" ) :","elif typ . endswith ( "".TP"" ) :",0.113962615,15.02000463,0.278195489
"def EvalInScriptedSection(self, codeBlock, globals, locals=None):<tab>if locals is None:<tab><tab>locals = globals<tab>assert not codeBlock.beenExecuted, ""This code block should not have been executed""<tab>codeBlock.beenExecuted = 1<tab>self.BeginScriptedSection()<tab>try:<tab><tab>try:<tab><tab><tab>return self._EvalInScriptedSection(codeBlock.codeObject, globals, locals)<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.debugManager.OnLeaveScript()<tab><tab><tab>self.EndScriptedSection()<tab>except:<tab><tab>self.HandleException(codeBlock)",1,if self . debugManager :,if self . debugManager :,0.75,100,1
"def OSError__str__(self):<tab>if self.filename:<tab><tab><IF-STMT><tab><tab><tab>return ""[Errno %s] %s: %s -> %s"" % (<tab><tab><tab><tab>self.errno,<tab><tab><tab><tab>self.strerror,<tab><tab><tab><tab>self.filename,<tab><tab><tab><tab>self.filename2,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return ""[Errno %s] %s: %s"" % (self.errno, self.strerror, self.filename)<tab>if self.errno and self.strerror:<tab><tab>return ""[Errno %s] %s"" % (self.errno, self.strerror)<tab>return BaseException.__str__(self)",1,if self . filename2 :,if self . filename2 :,0.75,100,1
"def save(self, *args, **kwargs):<tab>if not self.identifier:<tab><tab>charset = list(""ABCDEFGHJKLMNPQRSTUVWXYZ3789"")<tab><tab>while True:<tab><tab><tab>code = get_random_string(length=8, allowed_chars=charset)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.identifier = code<tab><tab><tab><tab>break<tab>super().save(*args, **kwargs)<tab>if self.event:<tab><tab>self.event.cache.clear()",0,"if not Question . objects . filter ( event = self . event , identifier = code ) . exists ( ) :",if code != self . identifier :,0.039877851,3.896234037,0.161290323
"def malloc(self, size):<tab># return a block of right size (possibly rounded up)<tab>assert 0 <= size < sys.maxint<tab>if os.getpid() != self._lastpid:<tab><tab>self.__init__()  # reinitialize after fork<tab>self._lock.acquire()<tab>try:<tab><tab>size = self._roundup(max(size, 1), self._alignment)<tab><tab>(arena, start, stop) = self._malloc(size)<tab><tab>new_stop = start + size<tab><tab><IF-STMT><tab><tab><tab>self._free((arena, new_stop, stop))<tab><tab>block = (arena, start, new_stop)<tab><tab>self._allocated_blocks.add(block)<tab><tab>return block<tab>finally:<tab><tab>self._lock.release()",0,if new_stop < stop :,if arena != stop :,0.064978772,15.20721822,0.45
"def commit(cache):<tab>assert cache.is_alive<tab>try:<tab><tab>if cache.modified:<tab><tab><tab>cache.flush()<tab><tab><IF-STMT><tab><tab><tab>assert cache.connection is not None<tab><tab><tab>cache.database.provider.commit(cache.connection, cache)<tab><tab>cache.for_update.clear()<tab><tab>cache.query_results.clear()<tab><tab>cache.max_id_cache.clear()<tab><tab>cache.immediate = True<tab>except:<tab><tab>cache.rollback()<tab><tab>raise",0,if cache . in_transaction :,if not cache . immediate :,0.060348848,16.34121945,0.333333333
"def __get_tasks(cls, task_ids=None, project_name=None, task_name=None, **kwargs):<tab>if task_ids:<tab><tab><IF-STMT><tab><tab><tab>task_ids = [task_ids]<tab><tab>return [<tab><tab><tab>cls(private=cls.__create_protection, task_id=task_id, log_to_backend=False)<tab><tab><tab>for task_id in task_ids<tab><tab>]<tab>return [<tab><tab>cls(private=cls.__create_protection, task_id=task.id, log_to_backend=False)<tab><tab>for task in cls._query_tasks(<tab><tab><tab>project_name=project_name, task_name=task_name, **kwargs<tab><tab>)<tab>]",0,"if isinstance ( task_ids , six . string_types ) :","if not isinstance ( task_ids , list ) :",0.166070317,40.71631883,0.320512821
"def _VarRefOrWord(node, dynamic_arith):<tab># type: (arith_expr_t, bool) -> bool<tab>with tagswitch(node) as case:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif case(arith_expr_e.Word):<tab><tab><tab>if dynamic_arith:<tab><tab><tab><tab>return True<tab>return False",1,if case ( arith_expr_e . VarRef ) :,if case ( arith_expr_e . VarRef ) :,0.75,100,1
"def fit(self, data_instances, suffix):<tab>if self.statics_obj is None:<tab><tab>self.statics_obj = MultivariateStatisticalSummary(data_instances)<tab>quantile_points = self.statics_obj.get_quantile_point(self.percentile)<tab>for col_name in self.selection_properties.select_col_names:<tab><tab>quantile_value = quantile_points.get(col_name)<tab><tab><IF-STMT><tab><tab><tab>self.selection_properties.add_left_col_name(col_name)<tab><tab>self.selection_properties.add_feature_value(col_name, quantile_value)<tab>self._keep_one_feature(pick_high=True)<tab>return self",0,if quantile_value < self . upper_threshold :,if quantile_value is not None :,0.04155306,25.12421855,0.291666667
"def predict_dict(self, words):<tab>""""""Predict a list of expansions given words.""""""<tab>expansions = []<tab>for w in words:<tab><tab>if w in self.expansion_dict:<tab><tab><tab>expansions += [self.expansion_dict[w]]<tab><tab><IF-STMT><tab><tab><tab>expansions += [self.expansion_dict[w.lower()]]<tab><tab>else:<tab><tab><tab>expansions += [w]<tab>return expansions",1,elif w . lower ( ) in self . expansion_dict :,elif w . lower ( ) in self . expansion_dict :,0.75,100,1
"def connect(self, host, port, ssl, helo, starttls, timeout):<tab>if ssl == ""0"":<tab><tab><IF-STMT><tab><tab><tab>port = 25<tab><tab>fp = SMTP(timeout=int(timeout))<tab>else:<tab><tab>if not port:<tab><tab><tab>port = 465<tab><tab>fp = SMTP_SSL(timeout=int(timeout))<tab>resp = fp.connect(host, int(port))<tab>if helo:<tab><tab>cmd, name = helo.split("" "", 1)<tab><tab>if cmd.lower() == ""ehlo"":<tab><tab><tab>resp = fp.ehlo(name)<tab><tab>else:<tab><tab><tab>resp = fp.helo(name)<tab>if not starttls == ""0"":<tab><tab>resp = fp.starttls()<tab>return TCP_Connection(fp, resp)",1,if not port :,if not port :,0.75,100,1
"def _init_from_text(self, text):<tab>parts = text.split(""; "")<tab>for part in parts:<tab><tab>key, val = part.split(""="")<tab><tab>if key == ""CLONE"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.is_image = True<tab><tab><tab><tab>self.image = val[6:]<tab><tab>setattr(self, key.lower(), val)",0,"if val [ : 5 ] == ""IMAGE"" :","if val . startswith ( ""image"" ) :",0.030159603,8.639795715,0.6
"def to_laid_out_tensor(self):<tab>if not self._reduced:<tab><tab>self._reduced = self.mesh_impl.allreduce(<tab><tab><tab>self.laid_out_input, self.mesh_axes, ""SUM""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._add_counter_fn()<tab>return self._reduced",1,if self . _add_counter_fn :,if self . _add_counter_fn :,0.75,100,1
"def platformGetThreads(self):<tab>ret = {}<tab>self._sendPkt(""qfThreadInfo"")<tab>tbytes = self._recvPkt()<tab>while tbytes.startswith(""m""):<tab><tab><IF-STMT><tab><tab><tab>for bval in tbytes[1:].split("",""):<tab><tab><tab><tab>ret[int(bval, 16)] = 0<tab><tab>else:<tab><tab><tab>ret[int(tbytes[1:], 16)] = 0<tab><tab>self._sendPkt(""qsThreadInfo"")<tab><tab>tbytes = self._recvPkt()<tab>return ret",0,"if tbytes . find ( "","" ) :","if tbytes [ 0 ] == ""b"" :",0.034400971,9.425159511,0.6
"def _generate_patterns(self, intent, intent_utterances, entity_placeholders):<tab>unique_patterns = set()<tab>patterns = []<tab>stop_words = self._get_intent_stop_words(intent)<tab>for utterance in intent_utterances:<tab><tab>pattern = self._utterance_to_pattern(utterance, stop_words, entity_placeholders)<tab><tab><IF-STMT><tab><tab><tab>unique_patterns.add(pattern)<tab><tab><tab>patterns.append(pattern)<tab>return patterns",1,if pattern not in unique_patterns :,if pattern not in unique_patterns :,0.75,100,1
"def generator():<tab>try:<tab><tab>_resp_data = DataHelper.flow2origin(self.flow[""response""]) or """"<tab><tab>length = len(_resp_data)<tab><tab>size = self.response_chunk_size<tab><tab>bandwidth = config.bandwidth<tab><tab><IF-STMT><tab><tab><tab>sleep_time = self.response_chunk_size / (bandwidth * 1024)<tab><tab>else:<tab><tab><tab>sleep_time = 0<tab><tab>for i in range(int(length / size) + 1):<tab><tab><tab>time.sleep(sleep_time)<tab><tab><tab>self.server_resp_time = time.time()<tab><tab><tab>yield _resp_data[i * size : (i + 1) * size]<tab>finally:<tab><tab>self.update_client_resp_time()",0,if bandwidth > 0 :,ifbandwidth :,0.019937926,1.00E-10,0.133333333
"def generateMapItemListNode(self, key, value):<tab>itemslist = list()<tab>for item in value:<tab><tab><IF-STMT><tab><tab><tab>itemslist.append(""%s = %s"" % (key, self.generateValueNode(item, key)))<tab><tab>else:<tab><tab><tab>itemslist.append(""%s"" % (self.generateValueNode(item)))<tab>return ""("" + "" OR "".join(itemslist) + "")""",0,if key in self . allowedFieldsList :,"if isinstance ( item , dict ) :",0.019801327,6.567274736,0.206349206
"def _underscore_dict(dictionary):<tab>new_dictionary = {}<tab>for key, value in dictionary.items():<tab><tab><IF-STMT><tab><tab><tab>value = _underscore_dict(value)<tab><tab>if isinstance(key, str):<tab><tab><tab>key = underscore(key)<tab><tab>new_dictionary[key] = value<tab>return new_dictionary",1,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) :",0.75,100,1
"def offsetToRva(self, offset):<tab>if self.inmem:<tab><tab>return offset<tab>for s in self.sections:<tab><tab>sbase = s.PointerToRawData<tab><tab><IF-STMT><tab><tab><tab># SizeOfRawData can be misleading.<tab><tab><tab>ssize = s.VirtualSize<tab><tab>else:<tab><tab><tab>ssize = max(s.SizeOfRawData, s.VirtualSize)<tab><tab>if sbase <= offset and offset < sbase + ssize:<tab><tab><tab>return offset - s.PointerToRawData + s.VirtualAddress<tab>return 0",0,if s . SizeOfRawData + s . PointerToRawData > self . getMaxRva ( ) :,if s . SizeOfRawData is None :,0.082141696,13.86353367,0.395061728
"def func():<tab>end_received = False<tab>while True:<tab><tab>for idx, q in enumerate(self._local_out_queues):<tab><tab><tab>data = q.get()<tab><tab><tab>q.task_done()<tab><tab><tab>if isinstance(data, EndSignal):<tab><tab><tab><tab>end_received = True<tab><tab><tab><tab>if idx > 0:<tab><tab><tab><tab><tab>continue<tab><tab><tab>self._out_queue.put(data)<tab><tab><IF-STMT><tab><tab><tab>break",1,if end_received :,if end_received :,0.531170663,1.00E-10,1
"def unwrap_assert_methods() -> None:<tab>for patcher in _mock_module_patches:<tab><tab>try:<tab><tab><tab>patcher.stop()<tab><tab>except RuntimeError as e:<tab><tab><tab># a patcher might have been stopped by user code (#137)<tab><tab><tab># so we need to catch this error here and ignore it;<tab><tab><tab># unfortunately there's no public API to check if a patch<tab><tab><tab># has been started, so catching the error it is<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab>raise<tab>_mock_module_patches[:] = []<tab>_mock_module_originals.clear()",0,"if str ( e ) == ""stop called on unstarted patcher"" :",if e . args [ 0 ] == e . args [ 0 ] :,0.011337844,6.150343144,0.215686275
"def run(self):<tab>queue = self.queue<tab>while True:<tab><tab>if not self.running:<tab><tab><tab>break<tab><tab># Grab our data<tab><tab>callback, requests, fetchTimeout, validityOverride = queue.get()<tab><tab># Grab prices, this is the time-consuming part<tab><tab><IF-STMT><tab><tab><tab>Price.fetchPrices(requests, fetchTimeout, validityOverride)<tab><tab>wx.CallAfter(callback)<tab><tab>queue.task_done()<tab><tab># After we fetch prices, go through the list of waiting items and call their callbacks<tab><tab>for price in requests:<tab><tab><tab>callbacks = self.wait.pop(price.typeID, None)<tab><tab><tab>if callbacks:<tab><tab><tab><tab>for callback in callbacks:<tab><tab><tab><tab><tab>wx.CallAfter(callback)",0,if len ( requests ) > 0 :,if requests :,0.01726708,1.00E-10,0.36
"def loadGCodeData(self, dataStream):<tab>if self._printing:<tab><tab>return False<tab>self._lineCount = 0<tab>for line in dataStream:<tab><tab># Strip out comments, we do not need to send comments<tab><tab><IF-STMT><tab><tab><tab>line = line[: line.index("";"")]<tab><tab># Strip out whitespace at the beginning/end this saves data to send.<tab><tab>line = line.strip()<tab><tab>if len(line) < 1:<tab><tab><tab>continue<tab><tab>self._lineCount += 1<tab>self._doCallback()<tab>return True",1,"if "";"" in line :","if "";"" in line :",0.75,100,1
"def _prepare_work_root(self):<tab>if os.path.exists(self.work_root):<tab><tab>for f in os.listdir(self.work_root):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shutil.rmtree(os.path.join(self.work_root, f))<tab><tab><tab>else:<tab><tab><tab><tab>os.remove(os.path.join(self.work_root, f))<tab>else:<tab><tab>os.makedirs(self.work_root)",0,"if os . path . isdir ( os . path . join ( self . work_root , f ) ) :","if f . endswith ( "".py"" ) :",0.010718979,3.44385549,0.2
"def _parse(self):<tab>for factory in self._sub_factories():<tab><tab><IF-STMT><tab><tab><tab>node, self.token_pos = factory(**self._initializer_args())._parse_with_pos()<tab><tab><tab>return node<tab>self.raise_unexpected_token()",0,if factory . is_possible_start ( self . get_next_token ( ) ) :,if self . token_pos is None :,0.02201809,3.841954346,0.323529412
"def run(self):<tab>try:<tab><tab>if not self.shell:<tab><tab><tab>self.shell = os.name == ""nt""<tab><tab><IF-STMT><tab><tab><tab>os.chdir(self.working_dir)<tab><tab>proc = subprocess.Popen(<tab><tab><tab>self.command,<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab>shell=self.shell,<tab><tab><tab>env=self.env,<tab><tab>)<tab><tab>output = codecs.decode(proc.communicate()[0])<tab><tab>self.on_done(output)<tab>except subprocess.CalledProcessError as e:<tab><tab>self.on_done(e.returncode, error=True)<tab>except OSError as e:<tab><tab>self.on_done(e.message, error=True)",0,"if self . working_dir != """" :",if not os . path . exists ( self . working_dir ) :,0.069884209,26.76032276,0.253968254
"def is_filtered_inherited_member(name: str, obj: Any) -> bool:<tab>if inspect.isclass(self.object):<tab><tab>for cls in self.object.__mro__:<tab><tab><tab>if cls.__name__ == self.options.inherited_members and cls != self.object:<tab><tab><tab><tab># given member is a member of specified *super class*<tab><tab><tab><tab>return True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif name in self.get_attr(cls, ""__annotations__"", {}):<tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(obj, ObjectMember) and obj.class_ is cls:<tab><tab><tab><tab>return False<tab>return False",0,elif name in cls . __dict__ :,"elif name in self . get_attr ( cls , ""__members__"" , { } ) :",0.218052364,9.849349469,0.658730159
"def _connect(s, address):<tab>try:<tab><tab>s.connect(address)<tab>except socket.error:<tab><tab>(ty, v) = sys.exc_info()[:2]<tab><tab>if hasattr(v, ""errno""):<tab><tab><tab>v_err = v.errno<tab><tab>else:<tab><tab><tab>v_err = v[0]<tab><tab><IF-STMT><tab><tab><tab>raise v",0,"if v_err not in [ errno . EINPROGRESS , errno . EWOULDBLOCK , errno . EALREADY ] :",if v_err != errno . ECONNRESET :,0.039832882,11.94386513,0.194444444
"def _send_file(self, conn, path):<tab>""""""Method for a file PUT coro""""""<tab>while True:<tab><tab>chunk = conn.queue.get()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>with ChunkWriteTimeout(self.app.node_timeout):<tab><tab><tab><tab><tab>conn.send(chunk)<tab><tab><tab>except (Exception, ChunkWriteTimeout):<tab><tab><tab><tab>conn.failed = True<tab><tab><tab><tab>self.exception_occurred(<tab><tab><tab><tab><tab>conn.node, _(""Object""), _(""Trying to write to %s"") % path<tab><tab><tab><tab>)<tab><tab>conn.queue.task_done()",0,if not conn . failed :,if chunk :,0.109818835,1.00E-10,0.277777778
"def get_http_auth(self, name):<tab>auth = self._config.get(""http-basic.{}"".format(name))<tab>if not auth:<tab><tab>username = self._config.get(""http-basic.{}.username"".format(name))<tab><tab>password = self._config.get(""http-basic.{}.password"".format(name))<tab><tab><IF-STMT><tab><tab><tab>return None<tab>else:<tab><tab>username, password = auth[""username""], auth.get(""password"")<tab><tab>if password is None:<tab><tab><tab>password = self.keyring.get_password(name, username)<tab>return {<tab><tab>""username"": username,<tab><tab>""password"": password,<tab>}",0,if not username and not password :,if username is None or password is None :,0.187549189,6.74255593,0.277777778
"def _do_analyze(self, action_ref, rule_links=None, processed=None, depth=0):<tab>if processed is None:<tab><tab>processed = set()<tab>if rule_links is None:<tab><tab>rule_links = []<tab>processed.add(action_ref)<tab>for rule_link in self._rules.get(action_ref, []):<tab><tab>rule_links.append((depth, rule_link))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._do_analyze(<tab><tab><tab>rule_link._dest_action_ref,<tab><tab><tab>rule_links=rule_links,<tab><tab><tab>processed=processed,<tab><tab><tab>depth=depth + 1,<tab><tab>)<tab>return rule_links",1,if rule_link . _dest_action_ref in processed :,if rule_link . _dest_action_ref in processed :,0.75,100,1
"def _mock_manager_nfx(self, *args, **kwargs):<tab>if args:<tab><tab>if args[0].tag == ""command"":<tab><tab><tab>raise RpcError()<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return self._read_file(""sw_info_nfx_"" + args[0].tag + "".xml"")",0,"elif args [ 0 ] . tag == ""get-software-information"" and args [ 0 ] . find ( ""./*"" ) is None :","elif args [ 0 ] . tag == ""return"" :",0.326952701,22.50387668,0.459259259
"def test_url_invalid_set():<tab>for line in URL_INVALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip over comments<tab><tab>match = COMMENT.match(line)<tab><tab>if match:<tab><tab><tab>continue<tab><tab>mbox = address.parse(line, strict=True)<tab><tab>assert_equal(mbox, None)",0,"if line == """" :",if not line :,0.039449619,9.930283522,0.45
"def _monitor_thread_function(main_process_pid):<tab>while True:<tab><tab>logger.debug(""Monitor thread monitoring pid: %d"", main_process_pid)<tab><tab>main_process_alive = any(<tab><tab><tab>[<tab><tab><tab><tab>process.pid<tab><tab><tab><tab>for process in process_iter()<tab><tab><tab><tab>if process.pid == main_process_pid<tab><tab><tab>]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>logger.debug(<tab><tab><tab><tab>""Main process with pid %d is dead. Killing worker"", main_process_pid<tab><tab><tab>)<tab><tab><tab>os._exit(0)<tab><tab>sleep(1)",0,if not main_process_alive :,if main_process_alive :,0.096488528,1.00E-10,0.6
"def OnInsertCells(self, event=None):<tab># TODO remove below workaround for double actions<tab>if self._counter == 1:<tab><tab><IF-STMT><tab><tab><tab>self._counter = 0<tab><tab><tab>self._icells = None<tab><tab><tab>return<tab>else:<tab><tab>self._counter = 1<tab>self._icells = (self.selection.topleft, self.selection.bottomright)<tab>self._execute(InsertCells(self.selection.topleft, self.selection.bottomright))<tab>self._resize_grid()<tab>self._skip_except_on_mac(event)",0,"if self . _icells == ( self . selection . topleft , self . selection . bottomright ) :",if self . selection . topleft == self . selection . bottomright :,0.537487586,38.54898487,0.392753623
"def get_scripts():<tab>""""""Get custom npm scripts.""""""<tab>proc = Popen([""npm"", ""run-script""], stdout=PIPE)<tab>should_yeild = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode()<tab><tab>if ""available via `npm run-script`:"" in line:<tab><tab><tab>should_yeild = True<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield line.strip().split("" "")[0]",0,"if should_yeild and re . match ( r""^  [^ ]+"" , line ) :",if should_yeild :,0.042649193,1.00E-10,0.303030303
"def get_netloc(url):<tab>""""""Get Domain.""""""<tab>try:<tab><tab>domain = """"<tab><tab>parse_uri = urlparse(url)<tab><tab>if not parse_uri.scheme:<tab><tab><tab>url = ""//"" + url<tab><tab><tab>parse_uri = urlparse(url)<tab><tab>domain = ""{uri.netloc}"".format(uri=parse_uri)<tab><tab><IF-STMT><tab><tab><tab>return domain<tab>except Exception:<tab><tab>logger.exception(""[ERROR] Extracting Domain form URL"")",0,if verify_domain ( domain ) :,if parse_uri . netloc :,0.027136592,7.492442692,0.5
"def initiate_all_local_variables_instances(<tab>nodes, local_variables_instances, all_local_variables_instances):<tab>for node in nodes:<tab><tab>if node.variable_declaration:<tab><tab><tab>new_var = LocalIRVariable(node.variable_declaration)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_var.index = all_local_variables_instances[new_var.name].index + 1<tab><tab><tab>local_variables_instances[node.variable_declaration.name] = new_var<tab><tab><tab>all_local_variables_instances[node.variable_declaration.name] = new_var",1,if new_var . name in all_local_variables_instances :,if new_var . name in all_local_variables_instances :,0.75,100,1
"def _disconnect(self, sync):<tab>if self._connection:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self._connection.send_all()<tab><tab><tab><tab>self._connection.fetch_all()<tab><tab><tab>except (WorkspaceError, ServiceUnavailable):<tab><tab><tab><tab>pass<tab><tab>if self._connection:<tab><tab><tab>self._connection.in_use = False<tab><tab><tab>self._connection = None<tab><tab>self._connection_access_mode = None",1,if sync :,if sync :,0.531170663,1.00E-10,1
"def init(self):<tab>""""""Initialize a booster from the database and validate""""""<tab>self.__item = None<tab>if self.itemID:<tab><tab>self.__item = eos.db.getItem(self.itemID)<tab><tab><IF-STMT><tab><tab><tab>pyfalog.error(""Item (id: {0}) does not exist"", self.itemID)<tab><tab><tab>return<tab>if self.isInvalid:<tab><tab>pyfalog.error(""Item (id: {0}) is not a Booster"", self.itemID)<tab><tab>return<tab>self.build()",1,if self . __item is None :,if self . __item is None :,0.75,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_limit(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def _match_greater_than_or_equal(search_base, attribute, value, candidates):<tab>matches = list()<tab>for entry in candidates:<tab><tab>dn = entry.get(""dn"")<tab><tab>if not dn.endswith(search_base):<tab><tab><tab>continue<tab><tab>value_from_directory = entry.get(""attributes"").get(attribute)<tab><tab><IF-STMT><tab><tab><tab>entry[""type""] = ""searchResEntry""<tab><tab><tab>matches.append(entry)<tab>return matches",0,if str ( value_from_directory ) >= str ( value ) :,if str ( value_from_directory ) > str ( value ) :,0.852001933,81.96501312,1
"def list_target_unit_files(self, *modules):  # -> [ (unit,enabled) ]<tab>""""""show all the target units and the enabled status""""""<tab>result = {}<tab>enabled = {}<tab>for unit in _all_common_targets:<tab><tab>result[unit] = None<tab><tab>enabled[unit] = ""static""<tab><tab><IF-STMT><tab><tab><tab>enabled[unit] = ""enabled""<tab><tab>if unit in _all_common_disabled:<tab><tab><tab>enabled[unit] = ""enabled""<tab>return [(unit, enabled[unit]) for unit in sorted(result)]",1,if unit in _all_common_enabled :,if unit in _all_common_enabled :,0.75,100,1
"def handle_data(self, data):<tab>if self.in_span or self.in_div:<tab><tab><IF-STMT><tab><tab><tab>self.no_user = True<tab><tab>elif data == ""Invalid password"":<tab><tab><tab>self.bad_pw = True<tab><tab>elif data == ""User with that email already exists"":<tab><tab><tab>self.already_exists = True",0,"if data == ""No such user (please note that login is case sensitive)"" :","if data == ""Invalid username"" :",0.284479307,16.89895901,0.258823529
"def walk_tree(<tab>root: Element,<tab>processor: Callable[[Element], Optional[_T]],<tab>stop_after_first: bool = False,) -> List[_T]:<tab>results = []<tab>queue = deque([root])<tab>while queue:<tab><tab>currElement = queue.popleft()<tab><tab>for child in currElement:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>queue.append(child)<tab><tab><tab>result = processor(child)<tab><tab><tab>if result is not None:<tab><tab><tab><tab>results.append(result)<tab><tab><tab><tab>if stop_after_first:<tab><tab><tab><tab><tab>return results<tab>return results",0,if child :,if processor is not None :,0.048107739,1.00E-10,0.2
"def characters(self, ch):<tab>if self._inside_fuzzable:<tab><tab>modified_value = self._fuzzed_parameters[self._fuzzable_index][1]<tab><tab>if isinstance(modified_value, DataToken):<tab><tab><tab>modified_value = modified_value.get_value()<tab><tab><IF-STMT><tab><tab><tab>enc_val = base64.b64encode(modified_value)<tab><tab>else:<tab><tab><tab>enc_val = cgi.escape(modified_value).encode(""ascii"", ""xmlcharrefreplace"")<tab><tab>self.fuzzed_xml_string += enc_val<tab>else:<tab><tab>self.fuzzed_xml_string += ch",0,"if self . _fuzzed_parameters [ self . _fuzzable_index ] [ 0 ] == ""base64"" :","if isinstance ( modified_value , bytes ) :",0.008317428,1.361806527,0.326086957
"def when_the_task_has_started(context):<tab># 120 * 0.5 = 60 seconds<tab>for _ in range(120):<tab><tab>app = context.marathon_clients.current[0].get_app(APP_ID)<tab><tab>happy_count = app.tasks_running<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>time.sleep(0.5)<tab>raise Exception(""timed out waiting for task to start"")",0,if happy_count >= 3 :,if happy_count :,0.067674239,1.00E-10,0.619047619
"def _sock_send(self, msg):<tab>try:<tab><tab>if isinstance(msg, str):<tab><tab><tab>msg = msg.encode(""ascii"")<tab><tab># http://docs.datadoghq.com/guides/dogstatsd/#datagram-format<tab><tab><IF-STMT><tab><tab><tab>msg = msg + b""|#"" + self.dogstatsd_tags.encode(""ascii"")<tab><tab>if self.sock:<tab><tab><tab>self.sock.send(msg)<tab>except Exception:<tab><tab>Logger.warning(self, ""Error sending message to statsd"", exc_info=True)",0,if self . dogstatsd_tags :,if self .dogstatsd_tags :,0.320152444,100,1
"def __init__(<tab>self, constraints=None, preferences=None, platforms=None, maxreplicas=None):<tab>if constraints is not None:<tab><tab>self[""Constraints""] = constraints<tab>if preferences is not None:<tab><tab>self[""Preferences""] = []<tab><tab>for pref in preferences:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pref = PlacementPreference(*pref)<tab><tab><tab>self[""Preferences""].append(pref)<tab>if maxreplicas is not None:<tab><tab>self[""MaxReplicas""] = maxreplicas<tab>if platforms:<tab><tab>self[""Platforms""] = []<tab><tab>for plat in platforms:<tab><tab><tab>self[""Platforms""].append({""Architecture"": plat[0], ""OS"": plat[1]})",1,"if isinstance ( pref , tuple ) :","if isinstance ( pref , tuple ) :",0.75,100,1
def start(self):<tab>if not self._active:<tab><tab>self._active = True<tab><tab><IF-STMT><tab><tab><tab>self.exit = threading.Event()<tab><tab><tab>self.thread = threading.Thread(target=self.check)<tab><tab><tab>self.thread.daemon = True<tab><tab><tab>self.thread.start(),0,if self . thread is None :,if self . exit :,0.144532291,28.64190458,0.380952381
"def on_player_state_changed(self, state):<tab>if state == State.playing:<tab><tab>self._toggle_player_action.setText(TOGGLE_PLAYER_TEXT[1])<tab><tab>self._toggle_player_action.setIcon(QIcon.fromTheme(""media-pause""))<tab><tab>self._toggle_player_action.setEnabled(True)<tab>else:<tab><tab>self._toggle_player_action.setText(TOGGLE_PLAYER_TEXT[0])<tab><tab>self._toggle_player_action.setIcon(QIcon.fromTheme(""media-play""))<tab><tab><IF-STMT><tab><tab><tab>self._toggle_player_action.setEnabled(False)<tab><tab>else:<tab><tab><tab>self._toggle_player_action.setEnabled(True)",0,if state == State . stopped :,if state == State . paused :,0.574113272,70.71067812,0.6
"def __init__(self, el):<tab>self.elements = list(el)<tab>parameters = {}<tab>tokens = []<tab>token_quote = ""@""<tab>for key, value in el.attrib.items():<tab><tab>if key == ""token_quote"":<tab><tab><tab>token_quote = value<tab><tab>if key == ""tokens"":<tab><tab><tab>for token in value.split("",""):<tab><tab><tab><tab>tokens.append((token, REQUIRED_PARAMETER))<tab><tab><IF-STMT><tab><tab><tab>token = key[len(""token_"") :]<tab><tab><tab>tokens.append((token, value))<tab>for name, default in tokens:<tab><tab>parameters[name] = (token_quote, default)<tab>self.parameters = parameters",1,"elif key . startswith ( ""token_"" ) :","elif key . startswith ( ""token_"" ) :",0.75,100,1
"def create(self):<tab>if self.mode == ""INDICES"":<tab><tab>self.newInput(""Integer List"", ""Indices"", ""indices"")<tab><tab>self.newOutput(""Polygon Indices"", ""Polygon Indices"", ""polygonIndices"")<tab>elif self.mode == ""VERTEX_AMOUNT"":<tab><tab><IF-STMT><tab><tab><tab>self.newInput(""Integer List"", ""Vertex Amounts"", ""vertexAmounts"")<tab><tab><tab>self.newOutput(<tab><tab><tab><tab>""Polygon Indices List"", ""Polygon Indices List"", ""polygonIndicesList""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self.newInput(<tab><tab><tab><tab>""Integer"", ""Vertex Amount"", ""vertexAmount"", value=3, minValue=3<tab><tab><tab>)<tab><tab><tab>self.newOutput(""Polygon Indices"", ""Polygon Indices"", ""polygonIndices"")",0,if self . useList :,if self . num == 1 :,0.117260658,22.08959113,0.476190476
"def _chroot_pids(chroot):<tab>pids = []<tab>for root in glob.glob(""/proc/[0-9]*/root""):<tab><tab>try:<tab><tab><tab>link = os.path.realpath(root)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pids.append(int(os.path.basename(os.path.dirname(root))))<tab><tab>except OSError:<tab><tab><tab>pass<tab>return pids",0,if link . startswith ( chroot ) :,if link == chroot :,0.037304456,13.83254363,0.577777778
"def to_word_end(view, s):<tab>if mode == modes.NORMAL:<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(pt)<tab>elif mode in (modes.VISUAL, modes.VISUAL_BLOCK):<tab><tab>if s.a < s.b:<tab><tab><tab>pt = word_end_reverse(view, s.b - 1, count)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return sublime.Region(s.a, pt + 1)<tab><tab><tab>return sublime.Region(s.a + 1, pt)<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(s.a, pt)<tab>return s",0,if pt > s . a :,if s . a > s . b :,0.194684376,27.77619034,0.314814815
"def torch_sparse_Tensor(coords, feats, size=None):<tab>if size is None:<tab><tab><IF-STMT><tab><tab><tab>return torch.sparse.DoubleTensor(coords, feats)<tab><tab>elif feats.dtype == torch.float32:<tab><tab><tab>return torch.sparse.FloatTensor(coords, feats)<tab><tab>else:<tab><tab><tab>raise ValueError(""Feature type not supported."")<tab>else:<tab><tab>if feats.dtype == torch.float64:<tab><tab><tab>return torch.sparse.DoubleTensor(coords, feats, size)<tab><tab>elif feats.dtype == torch.float32:<tab><tab><tab>return torch.sparse.FloatTensor(coords, feats, size)<tab><tab>else:<tab><tab><tab>raise ValueError(""Feature type not supported."")",1,if feats . dtype == torch . float64 :,if feats . dtype == torch . float64 :,0.75,100,1
"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab>if line.startswith("" "" * markdown.TAB_LENGTH):<tab><tab><tab>newtext.append(line[markdown.TAB_LENGTH :])<tab><tab><IF-STMT><tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",0,elif not line . strip ( ) :,"elif line . endswith ( ""\n"" ) :",0.087632802,11.73117516,0.314814815
"def iter_input(input, filename, parser, line_by_line):<tab>if isinstance(input, basestring):<tab><tab>with open(input, ""rb"") as f:<tab><tab><tab>for tree in iter_input(f, filename, parser, line_by_line):<tab><tab><tab><tab>yield tree<tab>else:<tab><tab>try:<tab><tab><tab>if line_by_line:<tab><tab><tab><tab>for line in input:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>yield et.ElementTree(et.fromstring(line, parser))<tab><tab><tab>else:<tab><tab><tab><tab>yield et.parse(input, parser)<tab><tab>except IOError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>error(""parsing %r failed: %s: %s"", filename, e.__class__.__name__, e)",1,if line :,if line :,0.531170663,1.00E-10,1
"def find_xsubpp():<tab>for var in (""privlib"", ""vendorlib""):<tab><tab>xsubpp = cfg_lst(""$Config{%s}/ExtUtils/xsubpp$Config{exe_ext}"" % var)<tab><tab><IF-STMT><tab><tab><tab>return xsubpp<tab>return self.find_program(""xsubpp"")",0,if xsubpp and os . path . isfile ( xsubpp [ 0 ] ) :,if xsubpp is not None :,0.09767279,4.008579202,0.226381462
"def apply_list(self, expr, rules, evaluation):<tab>""ReplaceRepeated[expr_, rules_]""<tab>try:<tab><tab>rules, ret = create_rules(rules, expr, ""ReplaceRepeated"", evaluation)<tab>except PatternError:<tab><tab>evaluation.message(""Replace"", ""reps"", rules)<tab><tab>return None<tab>if ret:<tab><tab>return rules<tab>while True:<tab><tab>evaluation.check_stopped()<tab><tab>result, applied = expr.apply_rules(rules, evaluation)<tab><tab><IF-STMT><tab><tab><tab>result = result.evaluate(evaluation)<tab><tab>if applied and not result.same(expr):<tab><tab><tab>expr = result<tab><tab>else:<tab><tab><tab>break<tab>return result",0,if applied :,if result is not None :,0.048107739,1.00E-10,0.2
"def __init__(<tab>self,<tab>lambda_val: Optional[Union[torch.Tensor, Tuple[float, float]]] = None,<tab>same_on_batch: bool = False,<tab>p: float = 1.0,) -> None:<tab>super(RandomMixUp, self).__init__(p=1.0, p_batch=p, same_on_batch=same_on_batch)<tab>if lambda_val is None:<tab><tab>self.lambda_val = torch.tensor([0, 1.0])<tab>else:<tab><tab>self.lambda_val = (<tab><tab><tab>cast(torch.Tensor, lambda_val)<tab><tab><tab><IF-STMT><tab><tab><tab>else torch.tensor(lambda_val)<tab><tab>)",0,"if isinstance ( lambda_val , torch . Tensor )",if lambda_val is not None,0.015736078,14.83463622,0.25
"def run_sync(self):<tab>count = 0<tab>while count < self.args.num_messages:<tab><tab>batch = self.receiver.receive_messages(<tab><tab><tab>max_message_count=self.args.num_messages - count,<tab><tab><tab>max_wait_time=self.args.max_wait_time or None,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>for msg in batch:<tab><tab><tab><tab>self.receiver.complete_message(msg)<tab><tab>count += len(batch)",0,if self . args . peeklock :,if len ( batch ) > 0 :,0.019801327,6.567274736,0.25
"def ns_to_timespec(self, nsec):<tab>""""""Transforms nanoseconds to a timespec.""""""<tab># http://elixir.free-electrons.com/linux/v4.13.5/source/kernel/time/time.c#L486<tab>ts = self.timespec()<tab>if not nsec:<tab><tab>ts.tv_sec = 0<tab><tab>ts.tv_nsec = 0<tab>else:<tab><tab>ts.tv_sec, rem = divmod(nsec, timespec.NSEC_PER_SEC)<tab><tab><IF-STMT><tab><tab><tab>ts.tv_sec -= 1<tab><tab><tab>rem += timespec.NSEC_PER_SEC<tab><tab>ts.tv_nsec = rem<tab>return ts",0,if rem < 0 :,if ts . tv_sec > 0 :,0.052869316,10.55267032,0.6
"def fixFunctionDocTag(funcnode):<tab>doctext = funcnode.get(""doc"")<tab>if doctext:<tab><tab>if funcnode.attrib[""name""] == ""eval"":<tab><tab><tab># Update the doc for this function call, more user friendly.<tab><tab><tab>funcnode.attrib[""doc""] = doctext.replace(""ECMAScript"", ""JavaScript"")<tab><tab>sp = doctext.rsplit(""Return Type: "", 1)<tab><tab><IF-STMT><tab><tab><tab>funcnode.attrib[""doc""] = sp[0].rstrip()<tab><tab><tab>returnType = standardizeJSType(sp[1].split(None, 1)[0])<tab><tab><tab>addCixReturns(funcnode, returnType)<tab><tab><tab>return returnType<tab>return None",0,if len ( sp ) == 2 :,if len ( sp ) == 1 :,0.605621306,75.06238538,0.666666667
"def check_engine(engine):<tab>if engine == ""auto"":<tab><tab><IF-STMT><tab><tab><tab>return ""pyarrow""<tab><tab>elif fastparquet is not None:  # pragma: no cover<tab><tab><tab>return ""fastparquet""<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install either pyarrow or fastparquet."")<tab>elif engine == ""pyarrow"":<tab><tab>if pa is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install pyarrow fisrt."")<tab><tab>return engine<tab>elif engine == ""fastparquet"":<tab><tab>if fastparquet is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install fastparquet first."")<tab><tab>return engine<tab>else:  # pragma: no cover<tab><tab>raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",1,if pa is not None :,if pa is not None :,0.75,100,1
"def addInt(self, intval, width, nodeinfo):<tab>node = self.basenode<tab>for sh in range(width - 1, -1, -1):<tab><tab>choice = (intval >> sh) & 1<tab><tab><IF-STMT><tab><tab><tab>node[choice] = [None, None, None]<tab><tab>node = node[choice]<tab>node[2] = nodeinfo",0,if node [ choice ] is None :,if choice not in node :,0.020894909,8.224879649,0.25
"def add_cand(cands):<tab>cands = [cand.creator for cand in cands if cand.creator is not None]<tab>for x in cands:<tab><tab>if x in seen_set:<tab><tab><tab>continue<tab><tab>order = 1<tab><tab><IF-STMT><tab><tab><tab>order = -len(seen_set)<tab><tab># Negate since heapq is min-heap<tab><tab># `len(seen_set)` is in order to avoid comparing `x`<tab><tab>heapq.heappush(cand_funcs, (order, -x.rank, -len(seen_set), x))<tab><tab>seen_set.add(x)",0,if fan_out [ x ] == 1 and len ( cands ) == 1 :,if x . rank < 0 :,0.008532441,1.556541387,0.315789474
"def indentSelection(self, howFar=4):<tab># Indent or outdent current selection by 'howFar' spaces<tab># (which could be positive or negative int).<tab>startLineNum = self.LineFromPosition(self.GetSelectionStart())<tab>endLineNum = self.LineFromPosition(self.GetSelectionEnd())<tab># go through line-by-line<tab>self.BeginUndoAction()<tab>for lineN in range(startLineNum, endLineNum + 1):<tab><tab>newIndent = self.GetLineIndentation(lineN) + howFar<tab><tab><IF-STMT><tab><tab><tab>newIndent = 0<tab><tab>self.SetLineIndentation(lineN, newIndent)<tab>self.EndUndoAction()",0,if newIndent < 0 :,if newIndent > 0 :,0.331415021,30.21375397,1
"def request(self, host, handler, request_body, verbose=False):<tab># retry request once if cached connection has gone cold<tab>for i in (0, 1):<tab><tab>try:<tab><tab><tab>return self.single_request(host, handler, request_body, verbose)<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>except http_client.BadStatusLine:  # close after we sent request<tab><tab><tab>if i:<tab><tab><tab><tab>raise",0,"if i or e . errno not in ( errno . ECONNRESET , errno . ECONNABORTED , errno . EPIPE ) :",if i or e . errno != errno . ECONNRESET :,0.211360587,23.69633311,0.462121212
"def update_data(self, change):<tab>self.mark.x = self.state.x_centers<tab>y0 = self.state.grid<tab><IF-STMT><tab><tab>y0 = y0 / np.sum(y0)<tab>if self.state.grid_sliced is not None:<tab><tab>y1 = self.state.grid_sliced<tab><tab>if self.normalize:<tab><tab><tab>y1 = y1 / np.sum(y1)<tab><tab>self.mark.y = np.array([y0, y1])<tab><tab>self.mark.colors = [C0, C1]<tab><tab>self.mark.type = ""grouped""<tab>else:<tab><tab>self.mark.y = y0<tab><tab>self.mark.colors = [C0]",1,if self . normalize :,if self . normalize :,0.75,100,1
"def visit_body(self, nodes):<tab>new_nodes = []<tab>count = 0<tab>for node in nodes:<tab><tab>rewriter = IfExpRewriter(count)<tab><tab>possibly_transformed_node = rewriter.visit(node)<tab><tab><IF-STMT><tab><tab><tab>new_nodes.extend(rewriter.assignments)<tab><tab><tab>count += len(rewriter.assignments)<tab><tab>new_nodes.append(possibly_transformed_node)<tab>return new_nodes",0,if rewriter . assignments :,if rewriter . assignments is not None :,0.351498834,36.55552229,0.510204082
"def byteRegOffset(self, val, prefixes=0):<tab># NOTE: Override this because there is no AH etc in 64 bit mode<tab>if prefixes & PREFIX_REX:  # the parse_modrm function deals with register index adds<tab><tab>val |= e_i386.RMETA_LOW8<tab>else:  # not using REX, revert to old split-registers (low/high)<tab><tab><IF-STMT><tab><tab><tab>val |= e_i386.RMETA_LOW8<tab><tab>else:<tab><tab><tab>val |= e_i386.RMETA_HIGH8<tab><tab><tab>val -= 4<tab>return val",0,if val < 4 :,if val & 0x80 :,0.064978772,23.64354023,0.6
"def gprv_immv(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab><IF-STMT><tab><tab><tab>if op.name == ""REG0"" and op_luf_start(op, ""GPRv""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab>if op_immv(op):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",1,if i == 0 :,if i == 0 :,0.75,100,1
"def normalize(self):<tab>self.pairs.sort()<tab>i = 1<tab>while i < len(self.pairs):<tab><tab>alo, ahi = self.pairs[i - 1]<tab><tab>blo, bhi = self.pairs[i]<tab><tab><IF-STMT><tab><tab><tab>self.pairs[i - 1 : i + 1] = [(alo, max(ahi, bhi))]<tab><tab>else:<tab><tab><tab>i = i + 1",0,if ahi >= blo - 1 :,if blo < ahi < bhi :,0.024082657,8.051153633,0.333333333
"def __substitute_composite_key(self, key, composite_file, dataset=None):<tab>if composite_file.substitute_name_with_metadata:<tab><tab><IF-STMT><tab><tab><tab>meta_value = str(<tab><tab><tab><tab>dataset.metadata.get(composite_file.substitute_name_with_metadata)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>meta_value = self.spec[composite_file.substitute_name_with_metadata].default<tab><tab>return key % meta_value<tab>return key",1,if dataset :,if dataset :,0.531170663,1.00E-10,1
"def cb(definition):<tab>if len(definition.strip()) == 0:<tab><tab><IF-STMT><tab><tab><tab>dialog = wx.MessageDialog(<tab><tab><tab><tab>self,<tab><tab><tab><tab>_(""Do you want to erase the macro?""),<tab><tab><tab><tab>style=wx.YES_NO | wx.YES_DEFAULT | wx.ICON_QUESTION,<tab><tab><tab>)<tab><tab><tab>if dialog.ShowModal() == wx.ID_YES:<tab><tab><tab><tab>self.delete_macro(macro_name)<tab><tab><tab><tab>return<tab><tab>self.log(_(""Cancelled.""))<tab><tab>return<tab>self.cur_macro_name = macro_name<tab>self.cur_macro_def = definition<tab>self.end_macro()",0,"if old_macro_definition != """" :",if macro_name in self . macro_names :,0.027969855,9.425159511,0.45
"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>body = (<tab><tab><tab><tab><tab>str(request.body, ""utf-8"")<tab><tab><tab><tab><tab>if isinstance(request.body, bytes)<tab><tab><tab><tab><tab>else str(request.body)<tab><tab><tab><tab>)<tab><tab><tab>except TypeError:  # python 2 doesn't allow decoding through str<tab><tab><tab><tab>body = str(request.body)<tab><tab><tab>if old in body:<tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",0,if is_text_payload ( request ) and request . body :,"if isinstance ( request . body , bytes ) :",0.072482521,14.32095229,0.285714286
"def writeLibraryControllers(fp, human, meshes, skel, config, shapes=None):<tab>progress = Progress(len(meshes), None)<tab>fp.write(""\n  <library_controllers>\n"")<tab>for mIdx, mesh in enumerate(meshes):<tab><tab>subprog = Progress()(0, 0.5)<tab><tab><IF-STMT><tab><tab><tab>writeSkinController(fp, human, mesh, skel, config)<tab><tab>subprog(0.5, 1)<tab><tab>if shapes is not None:<tab><tab><tab>writeMorphController(fp, mesh, shapes[mIdx], config)<tab><tab>progress.step()<tab>fp.write(""  </library_controllers>\n"")",0,if skel :,if skel is not None :,0.090364769,1.00E-10,0.4
def checkpoint():<tab>if checkpoint_asserts:<tab><tab>self.assert_integrity_idxs_take()<tab><tab><IF-STMT><tab><tab><tab>toposort(self.idxs_memo[node])<tab><tab>if node in self.take_memo:<tab><tab><tab>for take in self.take_memo[node]:<tab><tab><tab><tab>toposort(take),0,if node in self . idxs_memo :,if node in self .idxs_memo :,0.476133778,100,1
"def __virtual__():  # pylint: disable=expected-2-blank-lines-found-0<tab>try:<tab><tab>global __salt__  # pylint: disable=global-statement<tab><tab><IF-STMT><tab><tab><tab>__salt__ = salt.loader.minion_mods(__opts__)<tab><tab><tab>return True<tab>except Exception as e:  # pylint: disable=broad-except<tab><tab>log.error(""Could not load __salt__: %s"", e)<tab><tab>return False",0,if not __salt__ :,if __salt__ is None :,0.045150551,48.54917717,0.36
"def annotate_disk_for_smart(middleware, devices, disk):<tab>args = await get_smartctl_args(middleware, devices, disk)<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>args.extend([""-a""])<tab><tab><tab>args.extend([""-d"", ""removable""])<tab><tab><tab>return disk, dict(smartctl_args=args)",0,if await ensure_smart_enabled ( args ) :,"if args [ 0 ] == ""smart"" :",0.021135836,5.30015669,0.4
"def make_connection(self, host):<tab>h, eh, kwargs = self.get_host_info(host)<tab>if not kwargs:<tab><tab>kwargs = {}<tab>kwargs[""timeout""] = self.timeout<tab>if _ver_info == (2, 6):<tab><tab>result = HTTPS(host, None, **kwargs)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self._extra_headers = eh<tab><tab><tab>self._connection = host, httplib.HTTPSConnection(h, None, **kwargs)<tab><tab>result = self._connection[1]<tab>return result",0,if not self . _connection or host != self . _connection [ 0 ] :,if self . _extra_headers :,0.013887229,7.003939561,0.25170068
"def get_base_types(self, cdef: ClassDef) -> List[str]:<tab>""""""Get list of base classes for a class.""""""<tab>base_types = []  # type: List[str]<tab>for base in cdef.base_type_exprs:<tab><tab>if isinstance(base, NameExpr):<tab><tab><tab>if base.name != ""object"":<tab><tab><tab><tab>base_types.append(base.name)<tab><tab><IF-STMT><tab><tab><tab>modname = get_qualified_name(base.expr)<tab><tab><tab>base_types.append(""%s.%s"" % (modname, base.name))<tab><tab>elif isinstance(base, IndexExpr):<tab><tab><tab>p = AliasPrinter(self)<tab><tab><tab>base_types.append(base.accept(p))<tab>return base_types",0,"elif isinstance ( base , MemberExpr ) :",elif base . is_qualified ( ) :,0.087501027,11.99014838,0.36
"def add_entry(self, entry):<tab># type: (...) -> None<tab>version = entry.as_python  # type: PythonVersion<tab>if version:<tab><tab>_ = self.versions[version.version_tuple]<tab><tab>paths = {p.path for p in self.versions.get(version.version_tuple, [])}<tab><tab><IF-STMT><tab><tab><tab>self.versions[version.version_tuple].append(entry)",0,if entry . path not in paths :,if any ( [ p . path for p in paths ] ) :,0.118748638,8.889175589,0.185714286
"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab>if mysql_user:<tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab>if mysql_host:<tab><tab><tab>args[""host""] = mysql_host<tab><tab>if mysql_port:<tab><tab><tab>args[""port""] = mysql_port<tab><tab><IF-STMT><tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",1,if mysql_socket :,if mysql_socket :,0.531170663,1.00E-10,1
"def findsection(self, key):<tab>to_return = copy.deepcopy(self)<tab>for subsection in to_return:<tab><tab>try:<tab><tab><tab>value = list(ConfigObj.find_key(to_return[subsection], key))[0]<tab><tab>except Exception:<tab><tab><tab>value = None<tab><tab>if not value:<tab><tab><tab>del to_return[subsection]<tab><tab>else:<tab><tab><tab>for category in to_return[subsection]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del to_return[subsection][category]<tab># cleanout empty sections and subsections<tab>for key in [k for (k, v) in to_return.items() if not v]:<tab><tab>del to_return[key]<tab>return to_return",0,if category != key :,if value == category :,0.286540249,11.47874423,0.4
"def get_ready_conn(self, host):<tab>conn = None<tab>self._lock.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>for c in self._hostmap[host]:<tab><tab><tab><tab>if self._readymap[c]:<tab><tab><tab><tab><tab>self._readymap[c] = 0<tab><tab><tab><tab><tab>conn = c<tab><tab><tab><tab><tab>break<tab>finally:<tab><tab>self._lock.release()<tab>return conn",1,if host in self . _hostmap :,if host in self . _hostmap :,0.75,100,1
"def assign_set_scope(<tab>ir_set: irast.Set,<tab>scope: Optional[irast.ScopeTreeNode],<tab>*,<tab>ctx: context.ContextLevel) -> irast.Set:<tab>if scope is None:<tab><tab>ir_set.path_scope_id = None<tab>else:<tab><tab><IF-STMT><tab><tab><tab>scope.unique_id = ctx.scope_id_ctr.nextval()<tab><tab>ir_set.path_scope_id = scope.unique_id<tab><tab>if scope.find_child(ir_set.path_id):<tab><tab><tab>raise RuntimeError(""scoped set must not contain itself"")<tab>return ir_set",1,if scope . unique_id is None :,if scope . unique_id is None :,0.75,100,1
"def _flatten(*args):<tab>arglist = []<tab>for arg in args:<tab><tab>if isinstance(arg, _Block):<tab><tab><tab>if arg.vhdl_code is not None:<tab><tab><tab><tab>arglist.append(arg.vhdl_code)<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>arg = arg.subs<tab><tab><IF-STMT><tab><tab><tab>arglist.append(_userCodeMap[""vhdl""][id(arg)])<tab><tab>elif isinstance(arg, (list, tuple, set)):<tab><tab><tab>for item in arg:<tab><tab><tab><tab>arglist.extend(_flatten(item))<tab><tab>else:<tab><tab><tab>arglist.append(arg)<tab>return arglist",1,"if id ( arg ) in _userCodeMap [ ""vhdl"" ] :","if id ( arg ) in _userCodeMap [ ""vhdl"" ] :",0.75,100,1
"def _prepare_expected(data, lags, trim=""front""):<tab>t, k = data.shape<tab>expected = np.zeros((t + lags, (lags + 1) * k))<tab>for col in range(k):<tab><tab>for i in range(lags + 1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>expected[i : -lags + i, (lags + 1) * col + i] = data[:, col]<tab><tab><tab>else:<tab><tab><tab><tab>expected[i:, (lags + 1) * col + i] = data[:, col]<tab>if trim == ""front"":<tab><tab>expected = expected[:-lags]<tab>return expected",0,if i < lags :,"if trim == ""front"" :",0.034123066,6.567274736,0.36
"def test_class_based_views_inherit_from_acl_gateway_class(self):<tab>for urlpattern in self.urlpatterns_to_test:<tab><tab>callback_name = urlpattern.callback.__name__<tab><tab>module_name = urlpattern.callback.__module__<tab><tab>if (callback_name, module_name) in self.excluded_callbacks:<tab><tab><tab>continue<tab><tab>imported_module = __import__(module_name, fromlist=[callback_name])<tab><tab>found_callback = getattr(imported_module, callback_name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>msg = ""Class '{}' does not inherit from 'ACLGateway' "" ""class."".format(<tab><tab><tab>found_callback<tab><tab>)<tab><tab>self.assertTrue(issubclass(found_callback, ACLGateway), msg)",0,if not inspect . isclass ( found_callback ) :,if not callable ( found_callback ) :,0.267156052,52.89934435,0.484848485
"def generateMapItemTypedNode(self, key, value):<tab>if type(value) == SigmaRegularExpressionModifier:<tab><tab>regex = str(value)<tab><tab># Regular Expressions have to match the full value in QRadar<tab><tab><IF-STMT><tab><tab><tab>regex = "".*"" + regex<tab><tab>if not (regex.endswith(""$"") or regex.endswith("".*"")):<tab><tab><tab>regex = regex + "".*""<tab><tab>return ""%s MATCHES %s"" % (self.cleanKey(key), self.generateValueNode(regex))<tab>else:<tab><tab>raise NotImplementedError(<tab><tab><tab>""Type modifier '{}' is not supported by backend"".format(value.identifier)<tab><tab>)",0,"if not ( regex . startswith ( ""^"" ) or regex . startswith ( "".*"" ) ) :","if not ( regex . endswith ( "".*"" ) or regex . endswith ( "".*"" ) ) :",0.774989537,60.67337732,0.714285714
"def __str__(self):<tab>_outicalfile = self._icalfile<tab>for unit in self.units:<tab><tab>for location in unit.getlocations():<tab><tab><tab>match = re.match(""\\[(?P<uid>.+)\\](?P<property>.+)"", location)<tab><tab><tab>for component in self._icalfile.components():<tab><tab><tab><tab>if component.name != ""VEVENT"":<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>for property in component.getChildren():<tab><tab><tab><tab><tab>if property.name == match.groupdict()[""property""]:<tab><tab><tab><tab><tab><tab>property.value = unit.target<tab>if _outicalfile:<tab><tab>return str(_outicalfile.serialize())<tab>else:<tab><tab>return """"",0,"if component . uid . value != match . groupdict ( ) [ ""uid"" ] :",if match is None :,0.006689343,0.85490028,0.212121212
"def __init__(self, items):<tab>self._format = string.join(map(lambda item: item[0], items), """")<tab>self._items = items<tab>self._buffer_ = win32wnet.NCBBuffer(struct.calcsize(self._format))<tab>for format, name in self._items:<tab><tab><IF-STMT><tab><tab><tab>if format == ""c"":<tab><tab><tab><tab>val = ""\0""<tab><tab><tab>else:<tab><tab><tab><tab>val = 0<tab><tab>else:<tab><tab><tab>l = int(format[:-1])<tab><tab><tab>val = ""\0"" * l<tab><tab>self.__dict__[name] = val",0,if len ( format ) == 1 :,"if format . endswith ( ""c"" ) :",0.021251795,6.274655311,0.314814815
"def __init__(self, learners, names=None):<tab>self.learners = learners<tab>for i, learner in enumerate(learners):<tab><tab>self.update_set_reward(learner)<tab><tab>learner.accumulated_rewards = []<tab><tab>learner.known_states = []<tab><tab>learner.temperatures = []<tab><tab><IF-STMT><tab><tab><tab>learner.name = ""Learner %d"" % i<tab><tab>else:<tab><tab><tab>learner.name = names[i]",1,if names is None :,if names is None :,0.75,100,1
"def __init__(self, *args, **kwargs):<tab>self.default_currency = kwargs.pop(""default_currency"", None)<tab>super().__init__(*args, **kwargs)<tab># Rest Framework converts `min_value` / `max_value` to validators, that are not aware about `Money` class<tab># We need to adjust them<tab>for idx, validator in enumerate(self.validators):<tab><tab><IF-STMT><tab><tab><tab>self.validators[idx] = MinMoneyValidator(self.min_value)<tab><tab>elif isinstance(validator, MaxValueValidator):<tab><tab><tab>self.validators[idx] = MaxMoneyValidator(self.max_value)",1,"if isinstance ( validator , MinValueValidator ) :","if isinstance ( validator , MinValueValidator ) :",0.75,100,1
"def add_line_taxes(self, lines):<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>continue  # Cannot have taxes, since not in source<tab><tab>for (index, line_tax) in enumerate(line.source_line.taxes, 1):<tab><tab><tab>line.taxes.create(<tab><tab><tab><tab>tax=line_tax.tax,<tab><tab><tab><tab>name=line_tax.name,<tab><tab><tab><tab>amount_value=line_tax.amount.value,<tab><tab><tab><tab>base_amount_value=line_tax.base_amount.value,<tab><tab><tab><tab>ordering=index,<tab><tab><tab>)",1,if not line . source_line :,if not line . source_line :,0.75,100,1
"def linesub(match):<tab>line = match.group()<tab>for token in TOKEN_RE.findall(line):<tab><tab>if token in names:<tab><tab><tab>targets = names[token]<tab><tab><tab>fdist.inc(token)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.warning(<tab><tab><tab><tab><tab>""%s is ambiguous: %s""<tab><tab><tab><tab><tab>% (token, "", "".join(str(v.canonical_name) for v in names[token]))<tab><tab><tab><tab>)<tab><tab><tab>line += INDEXTERM % token<tab><tab><tab># line += INDEXTERM % names[token][0].canonical_name<tab>return line",1,if len ( targets ) > 1 :,if len ( targets ) > 1 :,0.75,100,1
"def ask(self) -> Dict[str, Any]:<tab>params = {}<tab>param_values = self._optimizer.ask()<tab>for (name, distribution), value in zip(<tab><tab>sorted(self._search_space.items()), param_values<tab>):<tab><tab>if isinstance(distribution, distributions.DiscreteUniformDistribution):<tab><tab><tab>value = value * distribution.q + distribution.low<tab><tab><IF-STMT><tab><tab><tab>value = value * distribution.step + distribution.low<tab><tab>if isinstance(distribution, distributions.IntLogUniformDistribution):<tab><tab><tab>value = int(np.round(value))<tab><tab><tab>value = min(max(value, distribution.low), distribution.high)<tab><tab>params[name] = value<tab>return params",0,"if isinstance ( distribution , distributions . IntUniformDistribution ) :","if isinstance ( distribution , distributions . LinearDistribution ) :",0.604939981,70.71067812,0.714285714
"def fetcher():<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.fetch()<tab><tab><tab>self._cluster.handler.sleep(0.01)<tab><tab>except ReferenceError:<tab><tab><tab>break<tab><tab>except Exception:<tab><tab><tab># surface all exceptions to the main thread<tab><tab><tab>self._worker_exception = sys.exc_info()<tab><tab><tab>break<tab>try:<tab><tab>self.cleanup()<tab>except ReferenceError as e:<tab><tab>log.debug(""Attempt to cleanup consumer failed with ReferenceError"")<tab>log.debug(""Fetcher thread exiting"")",0,if not self . _running :,if self . _cluster . handler is None :,0.041941062,17.74740528,0.257142857
"def write_text(self, text):<tab>""""""Writes re-indented text into the buffer.""""""<tab>should_indent = False<tab>rows = []<tab>for row in text.split(""\n""):<tab><tab>if should_indent:<tab><tab><tab>row = ""<tab>{}"".format(row)<tab><tab><IF-STMT><tab><tab><tab>row = row.replace(""\b"", """", 1)<tab><tab><tab>should_indent = True<tab><tab>elif not len(row.strip()):<tab><tab><tab>should_indent = False<tab><tab>rows.append(row)<tab>self.write(""{}\n"".format(""\n"".join(rows)))",1,"if ""\b"" in row :","if ""\b"" in row :",0.75,100,1
"def test_kafka_consumer(self):<tab>self.send_messages(0, range(0, 100))<tab>self.send_messages(1, range(100, 200))<tab># Start a consumer<tab>consumer = self.kafka_consumer(auto_offset_reset=""earliest"")<tab>n = 0<tab>messages = {0: set(), 1: set()}<tab>for m in consumer:<tab><tab>logging.debug(""Consumed message %s"" % repr(m))<tab><tab>n += 1<tab><tab>messages[m.partition].add(m.offset)<tab><tab><IF-STMT><tab><tab><tab>break<tab>self.assertEqual(len(messages[0]), 100)<tab>self.assertEqual(len(messages[1]), 100)",0,if n >= 200 :,if n >= 100 :,0.394778655,53.72849659,0.6
"def get_command(scaffolding, command_path):<tab>path, _, command_name = command_path.rpartition(""."")<tab>if path not in scaffolding:<tab><tab>raise KeyError('Ingredient for command ""%s"" not found.' % command_path)<tab>if command_name in scaffolding[path].commands:<tab><tab>return scaffolding[path].commands[command_name]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise KeyError(<tab><tab><tab><tab>'Command ""%s"" not found in ingredient ""%s""' % (command_name, path)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise KeyError('Command ""%s"" not found' % command_name)",0,if path :,if command_name in scaffolding :,0.051944023,1.00E-10,0.36
"def build_extension(self, ext):<tab>ext._convert_pyx_sources_to_lang()<tab>_compiler = self.compiler<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.compiler = self.shlib_compiler<tab><tab>_build_ext.build_extension(self, ext)<tab><tab>if ext._needs_stub:<tab><tab><tab>cmd = self.get_finalized_command(""build_py"").build_lib<tab><tab><tab>self.write_stub(cmd, ext)<tab>finally:<tab><tab>self.compiler = _compiler",0,"if isinstance ( ext , Library ) :",if self . compiler is None :,0.018333425,6.770186229,0.206349206
"def _send_payload(self, payload):<tab>req = eventlet_urllib2.Request(self._url, headers=payload[1])<tab>try:<tab><tab><IF-STMT><tab><tab><tab>response = eventlet_urllib2.urlopen(req, payload[0]).read()<tab><tab>else:<tab><tab><tab>response = eventlet_urllib2.urlopen(req, payload[0], self.timeout).read()<tab><tab>return response<tab>except Exception as err:<tab><tab>return err",0,"if sys . version_info < ( 2 , 6 ) :",if self . timeout == 0.0 :,0.054897503,3.890218086,0.276190476
"def get_access_token(self, callback):<tab>if not self.is_authorized():<tab><tab>callback(None)<tab>else:<tab><tab>access_token = config.persist[""oauth_access_token""]<tab><tab>access_token_expires = config.persist[""oauth_access_token_expires""]<tab><tab><IF-STMT><tab><tab><tab>callback(access_token)<tab><tab>else:<tab><tab><tab>self.forget_access_token()<tab><tab><tab>self.refresh_access_token(callback)",0,if access_token and time . time ( ) < access_token_expires :,if access_token and access_token_expires < time . time ( ) :,0.660316374,66.2687734,1
"def mark_first_parents(event):<tab>""""""Mark the node and all its parents.""""""<tab>c = event.get(""c"")<tab>if not c:<tab><tab>return<tab>changed = []<tab>for parent in c.p.self_and_parents():<tab><tab><IF-STMT><tab><tab><tab>parent.v.setMarked()<tab><tab><tab>parent.setAllAncestorAtFileNodesDirty()<tab><tab><tab>changed.append(parent.copy())<tab>if changed:<tab><tab># g.es(""marked: "" + ', '.join([z.h for z in changed]))<tab><tab>c.setChanged()<tab><tab>c.redraw()<tab>return changed",0,if not parent . isMarked ( ) :,if parent . v . isMarked ( ) :,0.278726054,51.3345048,0.5
"def normalize_reg_path(self, path):<tab>new = path<tab>if path:<tab><tab>roots = (""\\registry\\machine\\"", ""hklm\\"")<tab><tab>for r in roots:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new = ""HKEY_LOCAL_MACHINE\\"" + path[len(r) :]<tab><tab><tab><tab>return new<tab>return path",0,if path . lower ( ) . startswith ( r ) :,if path . startswith ( r ) :,0.301942165,51.00294575,0.488888889
"def extract_labels(filename, one_hot=False):<tab>""""""Extract the labels into a 1D uint8 numpy array [index].""""""<tab>print(""Extracting"", filename)<tab>with gzip.open(filename) as bytestream:<tab><tab>magic = _read32(bytestream)<tab><tab>if magic != 2049:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Invalid magic number %d in MNIST label file: %s"" % (magic, filename)<tab><tab><tab>)<tab><tab>num_items = _read32(bytestream)<tab><tab>buf = bytestream.read(num_items)<tab><tab>labels = numpy.frombuffer(buf, dtype=numpy.uint8)<tab><tab><IF-STMT><tab><tab><tab>return dense_to_one_hot(labels)<tab><tab>return labels",1,if one_hot :,if one_hot :,0.531170663,1.00E-10,1
"def on_change(self, data):<tab># loop over tp_clipboard views<tab>for window in sublime.windows():<tab><tab>for view in window.views():<tab><tab><tab>if view.get_status(""inactive"") and view.settings().get(""tp_append"", False):<tab><tab><tab><tab>file_name = view.file_name()<tab><tab><tab><tab># ammo<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.update(view)<tab><tab><tab><tab>elif file_name and file_name.endswith(<tab><tab><tab><tab><tab>global_settings(""ammo_file_extension"", "".ammo"")<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>self.update(view)",0,"if view . settings ( ) . get ( ""tp_ammo"" , False ) :","if file_name and file_name . endswith ( "".ammo"" ) :",0.019733842,8.487192117,0.2375
"def list(self, items, columns=4, width=80):<tab>items = list(sorted(items))<tab>colw = width // columns<tab>rows = (len(items) + columns - 1) // columns<tab>for row in range(rows):<tab><tab>for col in range(columns):<tab><tab><tab>i = col * rows + row<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.output.write(items[i])<tab><tab><tab><tab>if col < columns - 1:<tab><tab><tab><tab><tab>self.output.write("" "" + "" "" * (colw - 1 - len(items[i])))<tab><tab>self.output.write(""\n"")",0,if i < len ( items ) :,if len ( items [ i ] ) > 0 :,0.071799408,17.24222129,0.320512821
"def test_dynamic_section_solaris(self):<tab>""""""Verify that we can parse relocations from the .dynamic section""""""<tab>test_dir = os.path.join(""test"", ""testfiles_for_unittests"")<tab>with open(os.path.join(test_dir, ""exe_solaris32_cc.elf""), ""rb"") as f:<tab><tab>elff = ELFFile(f)<tab><tab>for sect in elff.iter_sections():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>relos = sect.get_relocation_tables()<tab><tab><tab><tab>self.assertEqual(set(relos), {""JMPREL"", ""REL""})",0,"if isinstance ( sect , DynamicSection ) :","if sect . get_name ( ) == ""dynamic"" :",0.019832749,4.246549373,0.366666667
"def close(self, checkcount=False):<tab>self.mutex.acquire()<tab>try:<tab><tab>if checkcount:<tab><tab><tab>self.openers -= 1<tab><tab><tab>if self.openers == 0:<tab><tab><tab><tab>self.do_close()<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.do_close()<tab><tab><tab>self.openers = 0<tab>finally:<tab><tab>self.mutex.release()",0,if self . openers > 0 :,if self .eners == 0 :,0.302069442,25.8486577,0.571428571
def subcommand_table(self):<tab>if self._subcommand_table is None:<tab><tab><IF-STMT><tab><tab><tab>self._topic_tag_db = TopicTagDB()<tab><tab>self._topic_tag_db.load_json_index()<tab><tab>self._subcommand_table = self._create_subcommand_table()<tab>return self._subcommand_table,1,if self . _topic_tag_db is None :,if self . _topic_tag_db is None :,0.75,100,1
"def layer_init(self):<tab>for layer in self.cnn:  # type: ignore<tab><tab>if isinstance(layer, (nn.Conv2d, nn.Linear)):<tab><tab><tab>nn.init.kaiming_normal_(layer.weight, nn.init.calculate_gain(""relu""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nn.init.constant_(layer.bias, val=0)",0,if layer . bias is not None :,"elif isinstance ( layer , nn . BatchNorm2d ) :",0.056868625,5.522397784,0.080808081
"def _append_modifier(code, modifier):<tab>if modifier == ""euro"":<tab><tab>if ""."" not in code:<tab><tab><tab>return code + "".ISO8859-15""<tab><tab>_, _, encoding = code.partition(""."")<tab><tab>if encoding in (""ISO8859-15"", ""UTF-8""):<tab><tab><tab>return code<tab><tab><IF-STMT><tab><tab><tab>return _replace_encoding(code, ""ISO8859-15"")<tab>return code + ""@"" + modifier",0,"if encoding == ""ISO8859-1"" :","elif encoding == ""UTF-8"" :",0.058575651,32.01911828,0.5
"def set_mean(self, mean):<tab>if mean is not None:<tab><tab># mean value, may be one value per channel<tab><tab><IF-STMT><tab><tab><tab>mean = mean[:, np.newaxis, np.newaxis]<tab><tab>else:<tab><tab><tab># elementwise mean<tab><tab><tab>if self.is_color:<tab><tab><tab><tab>assert len(mean.shape) == 3<tab>self.mean = mean",0,if mean . ndim == 1 :,if self . is_color :,0.023846651,7.492442692,0.291666667
"def _set_state(self, value):<tab>if self._pwm:<tab><tab>try:<tab><tab><tab>value = int(value * self._connection.get_PWM_range(self._number))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._connection.set_PWM_dutycycle(self._number, value)<tab><tab>except pigpio.error:<tab><tab><tab>raise PinInvalidState('invalid state ""%s"" for pin %r' % (value, self))<tab>elif self.function == ""input"":<tab><tab>raise PinSetInput(""cannot set state of pin %r"" % self)<tab>else:<tab><tab># write forces pin to OUTPUT, hence the check above<tab><tab>self._connection.write(self._number, bool(value))",0,if value != self . _connection . get_PWM_dutycycle ( self . _number ) :,"if self . function == ""dutycycle"" :",0.089097696,3.67649307,0.39047619
"def do_stop(self):<tab>logger.info(""[%s] Stopping all workers"", self.name)<tab>for w in self.workers.values():<tab><tab>try:<tab><tab><tab>w.terminate()<tab><tab><tab>w.join(timeout=1)<tab><tab># A already dead worker or in a worker<tab><tab>except (AttributeError, AssertionError):<tab><tab><tab>pass<tab># Close the server socket if it was opened<tab>if self.http_daemon:<tab><tab>if self.brok_interface:<tab><tab><tab>self.http_daemon.unregister(self.brok_interface)<tab><tab><IF-STMT><tab><tab><tab>self.http_daemon.unregister(self.scheduler_interface)<tab># And then call our master stop from satellite code<tab>super(Satellite, self).do_stop()",1,if self . scheduler_interface :,if self . scheduler_interface :,0.75,100,1
"def iter_input(input, filename, parser, line_by_line):<tab>if isinstance(input, basestring):<tab><tab>with open(input, ""rb"") as f:<tab><tab><tab>for tree in iter_input(f, filename, parser, line_by_line):<tab><tab><tab><tab>yield tree<tab>else:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for line in input:<tab><tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab><tab>yield et.ElementTree(et.fromstring(line, parser))<tab><tab><tab>else:<tab><tab><tab><tab>yield et.parse(input, parser)<tab><tab>except IOError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>error(""parsing %r failed: %s: %s"", filename, e.__class__.__name__, e)",1,if line_by_line :,if line_by_line :,0.531170663,1.00E-10,1
"def debug_print(data: json):<tab>try:<tab><tab>print(""[+] ---Debug info---"")<tab><tab>for i, v in data.items():<tab><tab><tab>if i == ""outline"":<tab><tab><tab><tab>print(""[+]  -"", i, ""<tab>:"", len(v), ""characters"")<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>print(""[+]  -"", ""%-11s"" % i, "":"", v)<tab><tab>print(""[+] ---Debug info---"")<tab>except:<tab><tab>pass",0,"if i == ""actor_photo"" or i == ""year"" :",if len ( v ) < 11 :,0.015846268,2.132081947,0.285714286
"def deliver_event(self):<tab>while True:<tab><tab>client = self._client()<tab><tab><IF-STMT><tab><tab><tab>return  # weakref is dead, nothing to deliver<tab><tab>diff = self._due - client.loop.time()<tab><tab>if diff <= 0:<tab><tab><tab># We've hit our due time, deliver event. It won't respect<tab><tab><tab># sequential updates but fixing that would just worsen this.<tab><tab><tab>await client._dispatch_event(self._event)<tab><tab><tab>return<tab><tab>del client  # Clear ref and sleep until our due time<tab><tab>await asyncio.sleep(diff)",1,if client is None :,if client is None :,0.75,100,1
"def pluginload(bot, event, *args):<tab>""""""loads a previously unloaded plugin, requires plugins. prefix""""""<tab>if args:<tab><tab>module_path = args[0]<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>message = ""<b><pre>{}</pre>: loaded</b>"".format(module_path)<tab><tab><tab>else:<tab><tab><tab><tab>message = ""<b><pre>{}</pre>: failed</b>"".format(module_path)<tab><tab>except RuntimeError as e:<tab><tab><tab>message = ""<b><pre>{}</pre>: <pre>{}</pre></b>"".format(module_path, str(e))<tab>else:<tab><tab>message = ""<b>module path required</b>""<tab>yield from bot.coro_send_message(event.conv_id, message)",0,"if plugins . load ( bot , module_path ) :","if module_path . endswith ( "".py"" ) :",0.030390517,16.26170172,0.30952381
"def validate_prompt_lb(hostname):<tab># Run the standard hostname check first:<tab>hostname = validate_prompt_hostname(hostname)<tab># Make sure this host wasn't already specified:<tab>for host in hosts:<tab><tab><IF-STMT><tab><tab><tab>raise click.BadParameter(<tab><tab><tab><tab>'Cannot re-use ""%s"" as a load balancer, '<tab><tab><tab><tab>""please specify a separate host"" % hostname<tab><tab><tab>)<tab>return hostname",0,if host . connect_to == hostname and ( host . is_master ( ) or host . is_node ( ) ) :,if hostname . startswith ( host ) :,0.013123147,1.474673877,0.271889401
"def alter_inventory(session, resource, amount):<tab>""""""Alters the inventory of each settlement.""""""<tab># NOTE avoid circular import<tab>from horizons.component.storagecomponent import StorageComponent<tab>for settlement in session.world.settlements:<tab><tab><IF-STMT><tab><tab><tab>settlement.warehouse.get_component(StorageComponent).inventory.alter(<tab><tab><tab><tab>resource, amount<tab><tab><tab>)",0,if settlement . owner == session . world . player and settlement . warehouse :,if settlement . settlement_id == settlement . id :,0.401587536,13.72653931,0.220588235
"def _(value):<tab>if kb.customInjectionMark in (value or """"):<tab><tab><IF-STMT><tab><tab><tab>value = value.replace(kb.customInjectionMark, """")<tab><tab>else:<tab><tab><tab>value = re.sub(r""\w*%s"" % re.escape(kb.customInjectionMark), payload, value)<tab>return value",0,if payload is None :,if value :,0.03549272,1.00E-10,0.25
"def __call__(self, target):<tab>if ""weights"" not in target.temp:<tab><tab>return True<tab>targets = target.temp[""weights""]<tab>for cname in target.children:<tab><tab>if cname in targets:<tab><tab><tab>c = target.children[cname]<tab><tab><tab>deviation = abs((c.weight - targets[cname]) / targets[cname])<tab><tab><tab>if deviation > self.tolerance:<tab><tab><tab><tab>return True<tab>if ""cash"" in target.temp:<tab><tab>cash_deviation = abs(<tab><tab><tab>(target.capital - targets.value) / targets.value - target.temp[""cash""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",1,if cash_deviation > self . tolerance :,if cash_deviation > self . tolerance :,0.75,100,1
"def splitroot(self, part, sep=sep):<tab>if part and part[0] == sep:<tab><tab>stripped_part = part.lstrip(sep)<tab><tab># According to POSIX path resolution:<tab><tab># http://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap04.html#tag_04_11<tab><tab># ""A pathname that begins with two successive slashes may be<tab><tab># interpreted in an implementation-defined manner, although more<tab><tab># than two leading slashes shall be treated as a single slash"".<tab><tab><IF-STMT><tab><tab><tab>return """", sep * 2, stripped_part<tab><tab>else:<tab><tab><tab>return """", sep, stripped_part<tab>else:<tab><tab>return """", """", part",0,if len ( part ) - len ( stripped_part ) == 2 :,if len ( stripped_part ) > 2 :,0.296365129,36.11383661,0.511111111
"def _Determine_Do(self):<tab>self.applicable = 1<tab>method = ""moz-src""<tab>method_arg = None<tab>for opt, optarg in self.chosenOptions:<tab><tab><IF-STMT><tab><tab><tab>method = ""moz-src""<tab><tab>elif opt == ""--moz-objdir"":<tab><tab><tab>method = ""moz-objdir""<tab><tab><tab>method_arg = optarg<tab>if method == ""moz-src"":<tab><tab>self.value = self._get_mozilla_objdir()<tab>elif method == ""moz-objdir"":<tab><tab>self.value = self._use_mozilla_objdir(method_arg)<tab>else:<tab><tab>raise black.configure.ConfigureError(""bogus method: %r"" % method)<tab>self.determined = 1",1,"if opt == ""--moz-src"" :","if opt == ""--moz-src"" :",0.75,100,1
"def is_filtered_inherited_member(name: str, obj: Any) -> bool:<tab>if inspect.isclass(self.object):<tab><tab>for cls in self.object.__mro__:<tab><tab><tab>if cls.__name__ == self.options.inherited_members and cls != self.object:<tab><tab><tab><tab># given member is a member of specified *super class*<tab><tab><tab><tab>return True<tab><tab><tab>elif name in cls.__dict__:<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>elif isinstance(obj, ObjectMember) and obj.class_ is cls:<tab><tab><tab><tab>return False<tab>return False",0,"elif name in self . get_attr ( cls , ""__annotations__"" , { } ) :",elif obj is cls :,0.113884219,0.384131457,0.244047619
"def _remove_all_greasemonkey_scripts(self):<tab>page_scripts = self._widget.page().scripts()<tab>for script in page_scripts.toList():<tab><tab><IF-STMT><tab><tab><tab>log.greasemonkey.debug(""Removing script: {}"".format(script.name()))<tab><tab><tab>removed = page_scripts.remove(script)<tab><tab><tab>assert removed, script.name()",0,"if script . name ( ) . startswith ( ""GM-"" ) :","if script . name ( ) . startswith ( ""greasemonkey"" ) :",0.635663651,78.254229,1
"def merge_intervals(intervals):<tab>""""""Merge intervals in the form of a list.""""""<tab>if intervals is None:<tab><tab>return None<tab>intervals.sort(key=lambda i: i[0])<tab>out = [intervals.pop(0)]<tab>for i in intervals:<tab><tab><IF-STMT><tab><tab><tab>out[-1][-1] = max(out[-1][-1], i[-1])<tab><tab>else:<tab><tab><tab>out.append(i)<tab>return out",0,if out [ - 1 ] [ - 1 ] >= i [ 0 ] :,if len ( out ) > 1 :,0.008503899,2.680951115,0.367965368
"def __setattr__(self, key, val):<tab>self.__dict__[key] = val<tab>self.__dict__[key.upper()] = val<tab>levels = key.split(""."")<tab>last_level = len(levels) - 1<tab>pointer = self._pointer<tab>if len(levels) > 1:<tab><tab>for i, l in enumerate(levels):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>setattr(getattr(self, l), ""."".join(levels[i:]), val)<tab><tab><tab>if l == last_level:<tab><tab><tab><tab>pointer[l] = val<tab><tab><tab>else:<tab><tab><tab><tab>pointer = pointer[l]",0,"if hasattr ( self , l ) and isinstance ( getattr ( self , l ) , Config ) :",if l != last_level :,0.004621595,1.621684168,0.19047619
"def get_menu_title(self):<tab>handle = self.obj.get_handle()<tab>if handle:<tab><tab>who = get_participant_from_event(self.db, handle)<tab><tab>desc = self.obj.get_description()<tab><tab>event_name = self.obj.get_type()<tab><tab><IF-STMT><tab><tab><tab>event_name = ""%s - %s"" % (event_name, desc)<tab><tab>if who:<tab><tab><tab>event_name = ""%s - %s"" % (event_name, who)<tab><tab>dialog_title = _(""Event: %s"") % event_name<tab>else:<tab><tab>dialog_title = _(""New Event"")<tab>return dialog_title",1,if desc :,if desc :,0.531170663,1.00E-10,1
"def perform_initialization(m):<tab>if isinstance(m, self.initialize_layers):<tab><tab><IF-STMT><tab><tab><tab>initialization_method(m.weight.data, **initialization_kwargs)<tab><tab>if (<tab><tab><tab>m.bias is not None<tab><tab><tab>and self.initialize_bias != ""No""<tab><tab><tab>and initialization_method_bias is not None<tab><tab>):<tab><tab><tab>try:<tab><tab><tab><tab>initialization_method_bias(m.bias.data, **initialization_kwargs_bias)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>pass",1,if initialization_method is not None :,if initialization_method is not None :,0.75,100,1
"def forward(self, inputs):<tab>x = inputs[""image""]<tab>out = self.conv0(x)<tab>out = self.downsample0(out)<tab>blocks = []<tab>for i, conv_block_i in enumerate(self.darknet_conv_block_list):<tab><tab>out = conv_block_i(out)<tab><tab>if i == self.freeze_at:<tab><tab><tab>out.stop_gradient = True<tab><tab><IF-STMT><tab><tab><tab>blocks.append(out)<tab><tab>if i < self.num_stages - 1:<tab><tab><tab>out = self.downsample_list[i](out)<tab>return blocks",0,if i in self . return_idx :,elif i == self . num_blocks - 1 :,0.03362543,8.516593019,0.285714286
"def _urlvars__set(self, value):<tab>environ = self.environ<tab>if ""wsgiorg.routing_args"" in environ:<tab><tab>environ[""wsgiorg.routing_args""] = (environ[""wsgiorg.routing_args""][0], value)<tab><tab><IF-STMT><tab><tab><tab>del environ[""paste.urlvars""]<tab>elif ""paste.urlvars"" in environ:<tab><tab>environ[""paste.urlvars""] = value<tab>else:<tab><tab>environ[""wsgiorg.routing_args""] = ((), value)",1,"if ""paste.urlvars"" in environ :","if ""paste.urlvars"" in environ :",0.75,100,1
"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab>if layer == ""conv"":<tab><tab><tab>if self.with_explicit_padding:<tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab>elif layer == ""norm"" and norm and self.with_norm:<tab><tab><tab>x = self.norm(x)<tab><tab><IF-STMT><tab><tab><tab>x = self.activate(x)<tab>return x",0,"elif layer == ""act"" and activate and self . with_activation :",elif activate and self . with_activate :,0.254149256,28.99881595,0.416666667
"def add(self, entry):<tab>if not self._find_entry(entry, filters=False):<tab><tab>show = self.add_show(entry)<tab><tab><IF-STMT><tab><tab><tab>self._shows = None<tab><tab><tab>log.verbose(""Successfully added show %s to Sonarr"", show[""title""])<tab>else:<tab><tab>log.debug(""entry %s already exists in Sonarr list"", entry)",1,if show :,if show :,0.531170663,1.00E-10,1
"def __eq__(self, other):<tab>if not isinstance(other, Result):<tab><tab>return False<tab>equal = self.info == other.info<tab>equal &= self.stats == other.stats<tab>equal &= self.trajectories == other.trajectories<tab>for k in self.np_arrays:<tab><tab>if k not in other.np_arrays:<tab><tab><tab>equal &= False<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>equal &= all([np.array_equal(self.np_arrays[k], other.np_arrays[k])])<tab>return equal",0,if not equal :,if k not in self . np_arrays :,0.036611762,5.522397784,0.25
"def handle_server_api(output, kwargs):<tab>""""""Special handler for API-call 'set_config' [servers]""""""<tab>name = kwargs.get(""keyword"")<tab>if not name:<tab><tab>name = kwargs.get(""name"")<tab>if name:<tab><tab>server = config.get_config(""servers"", name)<tab><tab><IF-STMT><tab><tab><tab>server.set_dict(kwargs)<tab><tab><tab>old_name = name<tab><tab>else:<tab><tab><tab>config.ConfigServer(name, kwargs)<tab><tab><tab>old_name = None<tab><tab>sabnzbd.Downloader.update_server(old_name, name)<tab>return name",1,if server :,if server :,0.531170663,1.00E-10,1
"def extractNames(self, names):<tab>offset = names[""offset""].value<tab>for header in names.array(""header""):<tab><tab>key = header[""nameID""].value<tab><tab>foffset = offset + header[""offset""].value<tab><tab>field = names.getFieldByAddress(foffset * 8)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = field.value<tab><tab>if key not in self.NAMEID_TO_ATTR:<tab><tab><tab>continue<tab><tab>key = self.NAMEID_TO_ATTR[key]<tab><tab>if key == ""version"" and value.startswith(u""Version ""):<tab><tab><tab># ""Version 1.2"" => ""1.2""<tab><tab><tab>value = value[8:]<tab><tab>setattr(self, key, value)",0,if not field or not isString ( field ) :,if field is None :,0.125504324,5.171845311,0.208333333
"def api_read(self):<tab>files = []<tab>files.append(""/bin/netcat"")<tab>files.append(""/etc/alternative/netcat"")<tab>files.append(""/bin/nc"")<tab>#<tab> init variables<tab>installed = False<tab>support = False<tab>path = None<tab>for _file in files:<tab><tab>file_content = self.shell.read(_file)<tab><tab>if file_content:<tab><tab><tab>installed = True<tab><tab><tab>path = _file<tab><tab><tab><IF-STMT><tab><tab><tab><tab>support = True<tab><tab><tab>break<tab>result = {<tab><tab>""netcat_installed"": installed,<tab><tab>""supports_shell_bind"": support,<tab><tab>""path"": path,<tab>}<tab>return result",0,"if ""-e filename"" in file_content :",if os . path . isfile ( path ) :,0.020333188,4.990049702,0.294871795
"def _get_iscsi_portal(self, netspace):<tab>for netpsace_interface in netspace.get_ips():<tab><tab><IF-STMT><tab><tab><tab>port = netspace.get_properties().iscsi_tcp_port<tab><tab><tab>return ""%s:%s"" % (netpsace_interface.ip_address, port)<tab># if we get here it means there are no enabled ports<tab>msg = _(""No available interfaces in iSCSI network space %s"") % netspace.get_name()<tab>raise exception.VolumeDriverException(message=msg)",0,if netpsace_interface . enabled :,if netpsace_interface . is_tcp :,0.394778655,46.71379777,0.619047619
"def show(self):<tab>if len(self.figures.keys()) == 0:<tab><tab>return<tab>if not SETTINGS.plot_split:<tab><tab>if SETTINGS.plot_backend.lower() == ""qt4agg"":<tab><tab><tab>self.tabbed_qt4_window()<tab><tab>elif SETTINGS.plot_backend.lower() == ""qt5agg"":<tab><tab><tab>self.tabbed_qt5_window()<tab><tab><IF-STMT><tab><tab><tab>self.tabbed_tk_window()<tab><tab>else:<tab><tab><tab>plt.show()<tab>else:<tab><tab>plt.show()",0,"elif SETTINGS . plot_backend . lower ( ) == ""tkagg"" :","elif SETTINGS . plot_backend . lower ( ) == ""tk"" :",0.653527864,83.71170099,1
"def _update_decommissioned_icon(self):<tab>""""""Add or remove decommissioned icon.""""""<tab>if not self.instance.has_status_icon:<tab><tab>return<tab>if self.is_active() is not self.__active:<tab><tab>self.__active = not self.__active<tab><tab><IF-STMT><tab><tab><tab>RemoveStatusIcon.broadcast(self, self.instance, DecommissionedStatus)<tab><tab>else:<tab><tab><tab>self._add_status_icon(DecommissionedStatus(self.instance))",1,if self . __active :,if self . __active :,0.75,100,1
"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab><IF-STMT><tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",0,"if isinstance ( child , six . string_types ) :","if isinstance ( child , Text ) :",0.232029036,36.0645288,0.666666667
"def test_read_lazy(self):<tab>want = b""x"" * 100<tab>telnet = test_telnet([want])<tab>self.assertEqual(b"""", telnet.read_lazy())<tab>data = b""""<tab>while True:<tab><tab>try:<tab><tab><tab>read_data = telnet.read_lazy()<tab><tab><tab>data += read_data<tab><tab><tab><IF-STMT><tab><tab><tab><tab>telnet.fill_rawq()<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab>self.assertTrue(want.startswith(data))<tab>self.assertEqual(data, want)",1,if not read_data :,if not read_data :,0.75,100,1
"def getprefs(path=PREFSFILENAME):<tab>if not os.path.exists(path):<tab><tab>f = open(path, ""w"")<tab><tab>f.write(default_prefs)<tab><tab>f.close()<tab>f = open(path)<tab>lines = f.readlines()<tab>prefs = {}<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>line = line[:-1]<tab><tab>try:<tab><tab><tab>name, value = re.split("":"", line, 1)<tab><tab><tab>prefs[string.strip(name)] = eval(value)<tab><tab>except:<tab><tab><tab>pass<tab>return prefs",0,"if line [ - 1 : ] == ""\n"" :","if line . endswith ( ""\n"" ) :",0.028107316,22.07606996,0.6
"def connect(self):<tab>while True:<tab><tab>errno = self.sock.connect_ex(self.addr)<tab><tab><IF-STMT><tab><tab><tab># connected immediately.<tab><tab><tab>break<tab><tab>elif errno == EINPROGRESS:<tab><tab><tab># will be connected.<tab><tab><tab>break<tab><tab>elif errno == ENOENT:<tab><tab><tab># no such socket file.<tab><tab><tab>self.create_connection(self.failover_interval)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>raise ValueError(""Unexpected socket errno: %d"" % errno)<tab>self.event_loop.watch_file(self.sock.fileno(), self.handle)",0,if not errno :,if errno == ECONNRESET :,0.045150551,10.68217516,0.4
"def set_enabled_addons(file_path, addons, comment=None):<tab>with codecs.open(file_path, ""w"", ""utf-8"") as f:<tab><tab><IF-STMT><tab><tab><tab>f.write(""# %s\n\n"" % comment)<tab><tab>for addon in addons:<tab><tab><tab>f.write(""%s\n"" % addon)",1,if comment :,if comment :,0.531170663,1.00E-10,1
"def check_interfaceinNetWorkManager(self, interface):<tab>""""""check if interface is already in file config""""""<tab>mac = Refactor.get_interface_mac(interface)<tab>if mac != None:<tab><tab>if mac in open(self.mn_path, ""r"").read():<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,"if interface in open ( self . mn_path , ""r"" ) . read ( ) :","elif mac in open ( self . mn_path , ""a"" ) . read ( ) :",0.356425873,74.83293841,0.555555556
"def spaceless(writer, node):<tab>original = writer.spaceless<tab>writer.spaceless = True<tab>writer.warn(""entering spaceless mode with different semantics"", node)<tab># do the initial stripping<tab>nodelist = list(node.nodelist)<tab>if nodelist:<tab><tab><IF-STMT><tab><tab><tab>nodelist[0] = TextNode(nodelist[0].s.lstrip())<tab><tab>if isinstance(nodelist[-1], TextNode):<tab><tab><tab>nodelist[-1] = TextNode(nodelist[-1].s.rstrip())<tab>writer.body(nodelist)<tab>writer.spaceless = original",1,"if isinstance ( nodelist [ 0 ] , TextNode ) :","if isinstance ( nodelist [ 0 ] , TextNode ) :",0.75,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_queue_name(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_pause(d.getBoolean())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100,1
"def group_re(self):<tab>""""""Return a regexp pattern with named groups""""""<tab>out = """"<tab>for token, data in self.tokens():<tab><tab>if token == ""TXT"":<tab><tab><tab>out += re.escape(data)<tab><tab><IF-STMT><tab><tab><tab>out += ""(?P<%s>%s)"" % (data[1], data[0])<tab><tab>elif token == ""ANON"":<tab><tab><tab>out += ""(?:%s)"" % data<tab>return out",0,"elif token == ""VAR"" :","elif token == ""GROUP"" :",0.642872021,59.46035575,1
"def wrap_in(input):<tab>if isinstance(input, (SymbolicInput)):<tab><tab>return input<tab>elif isinstance(input, gof.Variable):<tab><tab># r -> SymbolicInput(variable=r)<tab><tab>return SymbolicInput(input)<tab>elif isinstance(input, (list, tuple)):<tab><tab># (r, u) -> SymbolicInput(variable=r, update=u)<tab><tab><IF-STMT><tab><tab><tab>return SymbolicInput(input[0], update=input[1])<tab><tab>else:<tab><tab><tab>raise TypeError(""Expected two elements in the list or tuple."", input)<tab>else:<tab><tab>raise TypeError(<tab><tab><tab>""Unknown input type: %s (%s), expected Variable "" ""instance"",<tab><tab><tab>type(input),<tab><tab><tab>input,<tab><tab>)",1,if len ( input ) == 2 :,if len ( input ) == 2 :,0.75,100,1
"def _remove_event(self, event):<tab># Find event according to its timestamp.<tab># Index returned should be one behind.<tab>i = bisect.bisect(self._eventq, event)<tab># Having two events with identical timestamp is unlikely but possible.<tab># I am going to move forward and compare timestamp AND object address<tab># to make sure the correct object is found.<tab>while i > 0:<tab><tab>i -= 1<tab><tab>e = self._eventq[i]<tab><tab><IF-STMT><tab><tab><tab>raise exception.EventNotFound(event)<tab><tab>elif id(e) == id(event):<tab><tab><tab>self._eventq.pop(i)<tab><tab><tab>return<tab>raise exception.EventNotFound(event)",0,if e . timestamp != event . timestamp :,if e is None :,0.029942751,8.697972365,0.412698413
"def cron_starter(*args: Any) -> None:<tab>_tz = self.conf.timezone if timezone is None else timezone<tab>while not self.should_stop:<tab><tab>await self.sleep(cron.secs_for_next(cron_format, _tz))<tab><tab>if not self.should_stop:<tab><tab><tab>should_run = not on_leader or self.is_leader()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with self.trace(shortlabel(fun), trace_enabled=traced):<tab><tab><tab><tab><tab>await fun(*args)",1,if should_run :,if should_run :,0.531170663,1.00E-10,1
"def _find_boundary(self):<tab>ct_info = tuple(x.strip() for x in self.content_type.split("";""))<tab>mimetype = ct_info[0]<tab>if mimetype.split(""/"")[0].lower() != ""multipart"":<tab><tab>raise NonMultipartContentTypeException(<tab><tab><tab>""Unexpected mimetype in content-type: '{0}'"".format(mimetype)<tab><tab>)<tab>for item in ct_info[1:]:<tab><tab>attr, value = _split_on_find(item, ""="")<tab><tab><IF-STMT><tab><tab><tab>self.boundary = encode_with(value.strip('""'), self.encoding)",0,"if attr . lower ( ) == ""boundary"" :","if attr == ""boundary"" :",0.076979974,46.41208292,0.730769231
"def get_kwarg_or_param(request, kwargs, key):<tab>value = None<tab>try:<tab><tab>value = kwargs[key]<tab>except KeyError:<tab><tab>if request.method == ""GET"":<tab><tab><tab>value = request.GET.get(key)<tab><tab><IF-STMT><tab><tab><tab>value = request.POST.get(key)<tab>return value",1,"elif request . method == ""POST"" :","elif request . method == ""POST"" :",1,100,1
"def _gather_async_results(self, result: Result, source: typing.Any) -> None:<tab>try:<tab><tab>context = result[""context""]<tab><tab>context[""is_refresh""] = False<tab><tab>context[""vars""] = self._vim.vars<tab><tab>async_candidates = source.gather_candidates(context)<tab><tab>context[""vars""] = None<tab><tab>result[""is_async""] = context[""is_async""]<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>context[""candidates""] += convert2candidates(async_candidates)<tab>except Exception as exc:<tab><tab>self._handle_source_exception(source, exc)",0,if async_candidates is None :,if not async_candidates :,0.039449619,29.05925408,0.36
"def _check_session(self, session, action):<tab>if session is None:<tab><tab><IF-STMT><tab><tab><tab>key = self[0].key<tab><tab>else:<tab><tab><tab>key = self.key<tab><tab>raise ValueError(<tab><tab><tab>f""Tileable object {key} must be executed first before {action}""<tab><tab>)",0,"if isinstance ( self , tuple ) :","if isinstance ( self [ 0 ] , Tileable ) :",0.180565952,28.99784415,0.56043956
"def update(self, dict=None, **kwargs):<tab>if self._pending_removals:<tab><tab>self._commit_removals()<tab>d = self.data<tab>if dict is not None:<tab><tab><IF-STMT><tab><tab><tab>dict = type({})(dict)<tab><tab>for key, o in dict.items():<tab><tab><tab>d[key] = KeyedRef(o, self._remove, key)<tab>if len(kwargs):<tab><tab>self.update(kwargs)",0,"if not hasattr ( dict , ""items"" ) :","if not isinstance ( dict , dict ) :",0.088147983,20.88702937,0.592592593
"def get_sigma(self):<tab>if self.wants_automatic_sigma.value:<tab><tab>#<tab><tab># Constants here taken from FindEdges.m<tab><tab>#<tab><tab>if self.method == M_CANNY:<tab><tab><tab>return 1.0<tab><tab><IF-STMT><tab><tab><tab>return 2.0<tab><tab>else:<tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""Automatic sigma not supported for method %s."" % self.method.value<tab><tab><tab>)<tab>else:<tab><tab>return self.sigma.value",0,elif self . method == M_LOG :,elif self . method == M_CANNY :,0.821729442,78.254229,1
"def forward(self, x, activate=True, norm=True):<tab>for layer in self.order:<tab><tab><IF-STMT><tab><tab><tab>if self.with_explicit_padding:<tab><tab><tab><tab>x = self.padding_layer(x)<tab><tab><tab>x = self.conv(x)<tab><tab>elif layer == ""norm"" and norm and self.with_norm:<tab><tab><tab>x = self.norm(x)<tab><tab>elif layer == ""act"" and activate and self.with_activation:<tab><tab><tab>x = self.activate(x)<tab>return x",0,"if layer == ""conv"" :","if layer == ""conv"" and norm and self . with_norm :",0.322131066,38.50322887,0.452380952
"def _grouping_intervals(grouping):<tab>last_interval = None<tab>for interval in grouping:<tab><tab># if grouping is -1, we are done<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab># 0: re-use last group ad infinitum<tab><tab>if interval == 0:<tab><tab><tab>if last_interval is None:<tab><tab><tab><tab>raise ValueError(""invalid grouping"")<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_interval<tab><tab>yield interval<tab><tab>last_interval = interval",0,if interval == CHAR_MAX :,if interval == - 1 :,0.127622275,37.68499164,0.714285714
"def iterRelativeExportCFiles(basepath):<tab>for root, dirs, files in os.walk(basepath, topdown=True):<tab><tab>for directory in dirs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dirs.remove(directory)<tab><tab>for filename in files:<tab><tab><tab>if not isExportCFileIgnored(filename):<tab><tab><tab><tab>fullpath = os.path.join(root, filename)<tab><tab><tab><tab>yield os.path.relpath(fullpath, basepath)",0,if isAddonDirectoryIgnored ( directory ) :,if not isExportCFileIgnored ( directory ) :,0.245610857,43.47208719,0.30952381
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.add_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100,1
"def _get_future_trading_minutes(self, trading_date):<tab>trading_minutes = set()<tab>universe = self._get_universe()<tab>for order_book_id in universe:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>trading_minutes.update(<tab><tab><tab>self._env.data_proxy.get_trading_minutes_for(order_book_id, trading_date)<tab><tab>)<tab>return set([convert_int_to_datetime(minute) for minute in trading_minutes])",0,if self . _env . get_account_type ( order_book_id ) == DEFAULT_ACCOUNT_TYPE . STOCK :,if self . _env . data_proxy . has_trading_minutes_for_order_book ( order_book_id ) :,0.274225026,38.98507944,0.739130435
"def helper(chunk: Any) -> Any:<tab>nonlocal counter<tab>if not isinstance(chunk, dict):<tab><tab>return chunk<tab>if len(chunk) <= 2:<tab><tab>return chunk<tab>id = hash(str(chunk))<tab>if id in cache:<tab><tab>return cache[id]<tab>else:<tab><tab>cache[id] = {"".id"": counter}<tab><tab>chunk["".cache_id""] = counter<tab><tab>counter += 1<tab>for name in sorted(chunk.keys()):<tab><tab>value = chunk[name]<tab><tab><IF-STMT><tab><tab><tab>chunk[name] = [helper(child) for child in value]<tab><tab>elif isinstance(value, dict):<tab><tab><tab>chunk[name] = helper(value)<tab>return chunk",1,"if isinstance ( value , list ) :","if isinstance ( value , list ) :",0.75,100,1
"def _render_lang_List(self, element):<tab>with self.buffer.foldable_lines():<tab><tab>self.buffer.write(""["", style=self.styles.bracket)<tab><tab>item_count = len(element.items)<tab><tab>if item_count:<tab><tab><tab>with self.buffer.indent():<tab><tab><tab><tab>for idx, item in enumerate(element.items):<tab><tab><tab><tab><tab>self._render(item)<tab><tab><tab><tab><tab>if idx < (item_count - 1):<tab><tab><tab><tab><tab><tab>self.buffer.write("","")<tab><tab><tab><tab><tab><tab>self.buffer.mark_line_break()<tab><tab><IF-STMT><tab><tab><tab>self.buffer.write(""..."")<tab><tab>self.buffer.write(""]"", style=self.styles.bracket)",0,if element . trimmed :,elif item_count > 0 :,0.025028614,6.567274736,0.133333333
"def test_parse_query_params_matchable_field(self):<tab>query_params = {<tab><tab>""filter[string_field][contains]"": ""foo"",<tab><tab>""filter[string_field][icontains]"": ""bar"",<tab>}<tab>fields = self.view.parse_query_params(query_params)<tab>for key, field_name in fields.items():<tab><tab>if field_name[""string_field""][""op""] == ""contains"":<tab><tab><tab>assert_equal(field_name[""string_field""][""value""], ""foo"")<tab><tab><IF-STMT><tab><tab><tab>assert_equal(field_name[""string_field""][""value""], ""bar"")<tab><tab>else:<tab><tab><tab>self.fail()",1,"elif field_name [ ""string_field"" ] [ ""op"" ] == ""icontains"" :","elif field_name [ ""string_field"" ] [ ""op"" ] == ""icontains"" :",1,100,1
"def on_www_authenticate(data=None):<tab>io_loop.remove_timeout(timeout[0])<tab>if data:<tab><tab>scheme = re.findall(""WWW-Authenticate: ([^\s]+)"", data)[0].strip()<tab><tab>logging.debug(""rtsp netcam auth scheme: %s"" % scheme)<tab><tab><IF-STMT><tab><tab><tab>send_auth[0] = True<tab><tab><tab>connect()<tab><tab>else:<tab><tab><tab>logging.debug(<tab><tab><tab><tab>""rtsp auth scheme digest not supported, considering credentials ok""<tab><tab><tab>)<tab><tab><tab>handle_success(""(unknown) "")<tab>else:<tab><tab>logging.error(""timeout waiting for rtsp auth scheme"")<tab><tab>handle_error(""timeout waiting for rtsp netcam response"")",0,"if scheme . lower ( ) == ""basic"" :","if scheme == ""ok"" :",0.031533007,18.32556813,0.730769231
"def receive(debug=debug):<tab>if should_shutdown and should_shutdown():<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_OK)<tab>try:<tab><tab>ready, req = _receive(1.0)<tab><tab><IF-STMT><tab><tab><tab>return None<tab>except (EOFError, IOError) as exc:<tab><tab>if get_errno(exc) == errno.EINTR:<tab><tab><tab>return None  # interrupted, maybe by gdb<tab><tab>debug(""worker got %s -- exiting"", type(exc).__name__)<tab><tab>raise SystemExit(EX_FAILURE)<tab>if req is None:<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_FAILURE)<tab>return req",1,if not ready :,if not ready :,0.75,100,1
"def test_all(self):<tab>raw = [r for r in self.map._revision_map.values() if r is not None]<tab>revs = [rev for rev in self.map.iterate_revisions(""heads"", ""base"")]<tab>eq_(set(raw), set(revs))<tab>for idx, rev in enumerate(revs):<tab><tab>ancestors = set(self.map._get_ancestor_nodes([rev])).difference([rev])<tab><tab>descendants = set(self.map._get_descendant_nodes([rev])).difference([rev])<tab><tab>assert not ancestors.intersection(descendants)<tab><tab>remaining = set(revs[idx + 1 :])<tab><tab><IF-STMT><tab><tab><tab>assert remaining.intersection(ancestors)",0,if remaining :,if len ( ancestors ) != len ( remaining ) :,0.043585823,1.00E-10,0.36
"def is_issue(self, node):<tab>first = node.children[0]<tab>if first.type == ""string"" and self._normalizer.version >= (3, 0):<tab><tab>first_is_bytes = self._is_bytes_literal(first)<tab><tab>for string in node.children[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True",0,if first_is_bytes != self . _is_bytes_literal ( string ) :,"if first_is_bytes and string . type == ""bytes"" :",0.029205697,27.30497014,0.487179487
"def elements(registry):<tab>""""""Given a resource registry return sorted de-aliased values.""""""<tab>seen = {}<tab>for k, v in registry.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v in seen:<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>seen[ElementSchema.name(v)] = v<tab>return [seen[k] for k in sorted(seen)]",0,"if k in ( ""and"" , ""or"" , ""not"" ) :","if k . startswith ( ""_"" ) :",0.031065767,11.40035138,0.6
"def make_pattern(wtree):<tab>subpattern = []<tab>for part in wtree[1:-1]:<tab><tab>if isinstance(part, list):<tab><tab><tab>part = make_pattern(part)<tab><tab>elif wtree[0] != """":<tab><tab><tab>for c in part:<tab><tab><tab><tab># Meta-characters cannot be quoted<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise GlobError()<tab><tab>subpattern.append(part)<tab>return """".join(subpattern)",0,if c in special_chars :,"if c == ""\\"" or c == ""\\"" :",0.047573492,5.061867435,0.515151515
"def check_if_list_contain_duplicates(item: list, depth: int) -> None:<tab>try:<tab><tab>if len(item) != len(set(item)):<tab><tab><tab>print(Fore.RED + ""Rule {} has duplicate filters"".format(file))<tab><tab><tab>files_with_duplicate_filters.append(file)<tab>except:<tab><tab># unhashable types like dictionaries<tab><tab>for sub_item in item:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>check_list_or_recurse_on_dict(sub_item, depth + 1)",0,if type ( sub_item ) == dict and depth <= MAX_DEPTH :,"if isinstance ( sub_item , dict ) :",0.024253488,14.03676696,0.410714286
"def PrintHighlighted(self, out):<tab>from doctools import make_help<tab>pos = self.start_pos<tab>for line_end in Lines(self.s, self.start_pos, self.end_pos):<tab><tab># NOTE: HighlightLine accepts an HTML ESCAPED line.  It's valid to just<tab><tab># add tags and leave everything alone.<tab><tab>line = self.s[pos:line_end]<tab><tab>html_line = make_help.HighlightLine(self.lang, line)<tab><tab><IF-STMT><tab><tab><tab>out.PrintUntil(pos)<tab><tab><tab>out.Print(html_line)<tab><tab><tab>out.SkipTo(line_end)<tab><tab>pos = line_end",0,if html_line is not None :,if html_line :,0.050438393,1.00E-10,0.314285714
"def closeEvent(self, e=None):<tab>""""""Save settings and remove registered logging handler""""""<tab>if self.editor.isModified():<tab><tab># ask if user wants to save<tab><tab><IF-STMT><tab><tab><tab>if self.save():<tab><tab><tab><tab>e.accept()<tab><tab><tab>else:<tab><tab><tab><tab># saving error or user canceled<tab><tab><tab><tab>e.ignore()<tab><tab>else:<tab><tab><tab># discard changes<tab><tab><tab>e.accept()<tab>else:<tab><tab># unchanged<tab><tab>e.accept()",0,if self . wants_save ( ) :,if e is not None :,0.021817414,5.854497694,0.224489796
"def readlines(self, hint=None):<tab>if self.chunked_input:<tab><tab>lines = []<tab><tab>for line in iter(self.readline, b""""):<tab><tab><tab>lines.append(line)<tab><tab><tab>if hint and hint > 0:<tab><tab><tab><tab>hint -= len(line)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab>return lines<tab>else:<tab><tab>return self._do_read(self.rfile.readlines, hint)",0,if hint <= 0 :,if not lines :,0.036751978,11.52159099,0.333333333
"def test_prod(self):<tab>with gpytorch.settings.fast_computations(covar_root_decomposition=False):<tab><tab>lazy_tensor = self.create_lazy_tensor()<tab><tab>evaluated = self.evaluate_lazy_tensor(lazy_tensor)<tab><tab><IF-STMT><tab><tab><tab>self.assertAllClose(<tab><tab><tab><tab>lazy_tensor.prod(-3).evaluate(),<tab><tab><tab><tab>evaluated.prod(-3),<tab><tab><tab><tab>**self.tolerances[""prod""]<tab><tab><tab>)<tab><tab>if lazy_tensor.ndimension() > 3:<tab><tab><tab>self.assertAllClose(<tab><tab><tab><tab>lazy_tensor.prod(-4).evaluate(),<tab><tab><tab><tab>evaluated.prod(-4),<tab><tab><tab><tab>**self.tolerances[""prod""]<tab><tab><tab>)",0,if lazy_tensor . ndimension ( ) > 2 :,if lazy_tensor . ndim ( ) > 3 :,0.354826209,48.32697831,0.333333333
"def make_module_translation_map(names: List[str]) -> Dict[str, str]:<tab>num_instances = {}  # type: Dict[str, int]<tab>for name in names:<tab><tab>for suffix in candidate_suffixes(name):<tab><tab><tab>num_instances[suffix] = num_instances.get(suffix, 0) + 1<tab>result = {}<tab>for name in names:<tab><tab>for suffix in candidate_suffixes(name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result[name] = suffix<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>assert False, names<tab>return result",0,if num_instances [ suffix ] == 1 :,if num_instances . get ( suffix ) == num_instances [ suffix ] :,0.230324063,37.15770153,0.389473684
"def output(self):<tab>""""""Transform self into a list of (name, value) tuples.""""""<tab>header_list = []<tab>for k, v in self.items():<tab><tab>if isinstance(k, unicodestr):<tab><tab><tab>k = self.encode(k)<tab><tab><IF-STMT><tab><tab><tab>v = str(v)<tab><tab>if isinstance(v, unicodestr):<tab><tab><tab>v = self.encode(v)<tab><tab># See header_translate_* constants above.<tab><tab># Replace only if you really know what you're doing.<tab><tab>k = k.translate(header_translate_table, header_translate_deletechars)<tab><tab>v = v.translate(header_translate_table, header_translate_deletechars)<tab><tab>header_list.append((k, v))<tab>return header_list",0,"if not isinstance ( v , basestring ) :","if isinstance ( v , unicodestr ) :",0.18845666,37.70794597,0.26984127
"def get_errors(self, attacked_text, use_cache=False):<tab>text = attacked_text.text<tab>if use_cache:<tab><tab><IF-STMT><tab><tab><tab>self.grammar_error_cache[text] = len(self.lang_tool.check(text))<tab><tab>return self.grammar_error_cache[text]<tab>else:<tab><tab>return len(self.lang_tool.check(text))",1,if text not in self . grammar_error_cache :,if text not in self . grammar_error_cache :,0.75,100,1
"def gen():<tab>for _ in range(256):<tab><tab>if seq:<tab><tab><tab>yield self.tb.dut.i.eq(seq.pop(0))<tab><tab>i = yield self.tb.dut.i<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(i, 0)<tab><tab>else:<tab><tab><tab>o = yield self.tb.dut.o<tab><tab><tab>if o > 0:<tab><tab><tab><tab>self.assertEqual(i & 1 << (o - 1), 0)<tab><tab><tab>self.assertGreaterEqual(i, 1 << o)<tab><tab>yield",1,if ( yield self . tb . dut . n ) :,if ( yield self . tb . dut . n ) :,0.75,100,1
"def _register_builtin_handlers(self, events):<tab>for spec in handlers.BUILTIN_HANDLERS:<tab><tab><IF-STMT><tab><tab><tab>event_name, handler = spec<tab><tab><tab>self.register(event_name, handler)<tab><tab>else:<tab><tab><tab>event_name, handler, register_type = spec<tab><tab><tab>if register_type is handlers.REGISTER_FIRST:<tab><tab><tab><tab>self._events.register_first(event_name, handler)<tab><tab><tab>elif register_type is handlers.REGISTER_LAST:<tab><tab><tab><tab>self._events.register_last(event_name, handler)",0,if len ( spec ) == 2 :,"if isinstance ( spec , tuple ) :",0.037791629,12.25620097,0.428571429
"def is_checked_sls_template(template):<tab>if template.__contains__(""provider""):<tab><tab># Case provider is a dictionary<tab><tab><IF-STMT><tab><tab><tab>if template[""provider""].get(""name"").lower() not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab># Case provider is direct provider name<tab><tab>if isinstance(template[""provider""], str_node):<tab><tab><tab>if template[""provider""] not in SUPPORTED_PROVIDERS:<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",0,"if isinstance ( template [ ""provider"" ] , dict_node ) :","if isinstance ( template [ ""provider"" ] , dict ) :",0.622196729,75.46112524,0.786666667
"def decode_body(self, response):<tab>if response is None:<tab><tab>return response<tab>if six.PY2:<tab><tab>return response<tab>if response.body:<tab><tab># Decode it<tab><tab><IF-STMT><tab><tab><tab>response._body = response.body.decode(""utf-8"")<tab><tab>else:<tab><tab><tab>response._body = salt.ext.tornado.escape.native_str(response.body)<tab>return response",0,"if response . headers . get ( ""Content-Type"" ) == ""application/json"" :","if isinstance ( response . body , bytes ) :",0.06622107,4.490478776,0.241666667
"def get_active_project_path():<tab>window = sublime.active_window()<tab>folders = window.folders()<tab>if len(folders) == 1:<tab><tab>return folders[0]<tab>else:<tab><tab>active_view = window.active_view()<tab><tab>active_file_name = active_view.file_name() if active_view else None<tab><tab>if not active_file_name:<tab><tab><tab>return folders[0] if len(folders) else os.path.expanduser(""~"")<tab><tab>for folder in folders:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return folder<tab><tab>return os.path.dirname(active_file_name)",0,if active_file_name . startswith ( folder ) :,if os . path . dirname ( folder ) == active_file_name :,0.131520599,31.00712007,0.267857143
"def pop(self, *a):<tab>lists = self.lists<tab>if len(lists) == 1 and not a:<tab><tab>return self.lists[0].pop()<tab>index = a and a[0]<tab>if index == () or index is None or index == -1:<tab><tab>ret = lists[-1].pop()<tab><tab>if len(lists) > 1 and not lists[-1]:<tab><tab><tab>lists.pop()<tab>else:<tab><tab>list_idx, rel_idx = self._translate_index(index)<tab><tab><IF-STMT><tab><tab><tab>raise IndexError()<tab><tab>ret = lists[list_idx].pop(rel_idx)<tab><tab>self._balance_list(list_idx)<tab>return ret",0,if list_idx is None :,if list_idx >= len ( lists ) :,0.04979442,24.808415,0.333333333
"def setup(self, gen):<tab>Node.setup(self, gen)<tab>try:<tab><tab>self.target = gen.rules[self.name]<tab><tab><IF-STMT><tab><tab><tab>self.accepts_epsilon = self.target.accepts_epsilon<tab><tab><tab>gen.changed()<tab>except KeyError:  # Oops, it's nonexistent<tab><tab>print >>sys.stderr, ""Error: no rule <%s>"" % self.name<tab><tab>self.target = self",0,if self . accepts_epsilon != self . target . accepts_epsilon :,if self . target is not None :,0.122704685,11.30839611,0.357142857
"def match(self, userargs):<tab># Early skip if command or number of args don't match<tab>if len(self.args) != len(userargs):<tab><tab># DENY: argument numbers don't match<tab><tab>return False<tab># Compare each arg (anchoring pattern explicitly at end of string)<tab>for (pattern, arg) in zip(self.args, userargs):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>except re.error:<tab><tab><tab># DENY: Badly-formed filter<tab><tab><tab>return False<tab>else:<tab><tab># ALLOW: All arguments matched<tab><tab>return True<tab># DENY: Some arguments did not match<tab>return False",0,"if not re . match ( pattern + ""$"" , arg ) :","if re . search ( pattern , arg ) :",0.136674066,22.17204505,0.241666667
"def broadcast(self, msg, eid):<tab>for s in self.subs:<tab><tab>if type(self.subs[s].eid) is list:<tab><tab><tab>if eid in self.subs[s].eid:<tab><tab><tab><tab>self.subs[s].write_message(msg)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.subs[s].write_message(msg)",0,if self . subs [ s ] . eid == eid :,if eid in self . subs [ s ] . eid :,0.469261589,63.16924187,0.272727273
"def apply_transformation(self, ti: TransformationInput) -> Transformation:<tab>fragments = ti.fragments<tab># Walk through all te fragments.<tab>if fragments and fragment_list_to_text(fragments).startswith("" ""):<tab><tab>t = (self.style, self.get_char())<tab><tab>fragments = explode_text_fragments(fragments)<tab><tab>for i in range(len(fragments)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fragments[i] = t<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>return Transformation(fragments)",0,"if fragments [ i ] [ 1 ] == "" "" :",if t [ i ] == self . style :,0.107465833,20.33038389,0.366666667
"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>iterable = sdict()<tab>for key, values in obj.items():<tab><tab><IF-STMT><tab><tab><tab>values = [values]<tab><tab>iterable[key] = values<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, values in iterable.items():<tab><tab>for value in values:<tab><tab><tab>if value is None:<tab><tab><tab><tab>continue<tab><tab><tab>if not isinstance(key, bytes):<tab><tab><tab><tab>key = str(key).encode(charset)<tab><tab><tab>if not isinstance(value, bytes):<tab><tab><tab><tab>value = str(value).encode(charset)<tab><tab><tab>yield url_quote_plus(key) + ""="" + url_quote_plus(value)",1,"if not isinstance ( values , list ) :","if not isinstance ( values , list ) :",0.75,100,1
"def get_objects(self) -> Iterator[Tuple[str, str, str, str, str, int]]:<tab>rootSymbol = self.data[""root_symbol""]<tab>for symbol in rootSymbol.get_all_symbols():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>assert symbol.docname<tab><tab>fullNestedName = symbol.get_full_nested_name()<tab><tab>name = str(fullNestedName).lstrip(""."")<tab><tab>dispname = fullNestedName.get_display_string().lstrip(""."")<tab><tab>objectType = symbol.declaration.objectType<tab><tab>docname = symbol.docname<tab><tab>newestId = symbol.declaration.get_newest_id()<tab><tab>yield (name, dispname, objectType, docname, newestId, 1)",1,if symbol . declaration is None :,if symbol . declaration is None :,0.75,100,1
"def _delete_duplicates(l, keep_last):<tab>""""""Delete duplicates from a sequence, keeping the first or last.""""""<tab>seen = {}<tab>result = []<tab>if keep_last:  # reverse in & out, then keep first<tab><tab>l.reverse()<tab>for i in l:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(i)<tab><tab><tab><tab>seen[i] = 1<tab><tab>except TypeError:<tab><tab><tab># probably unhashable.  Just keep it.<tab><tab><tab>result.append(i)<tab>if keep_last:<tab><tab>result.reverse()<tab>return result",1,if i not in seen :,if i not in seen :,0.75,100,1
"def combine_logs(audit_logs, statement_text_logs):<tab>for audit_transaction in audit_logs:<tab><tab>for audit_query in audit_logs[audit_transaction]:<tab><tab><tab>matching_statement_text_logs = statement_text_logs.get(hash(audit_query))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>statement_text_log = matching_statement_text_logs.pop()<tab><tab><tab><tab>if statement_text_log:<tab><tab><tab><tab><tab>if statement_text_log.start_time:<tab><tab><tab><tab><tab><tab>audit_query.start_time = statement_text_log.start_time<tab><tab><tab><tab><tab>if statement_text_log.end_time:<tab><tab><tab><tab><tab><tab>audit_query.end_time = statement_text_log.end_time",1,if matching_statement_text_logs :,if matching_statement_text_logs :,0.531170663,1.00E-10,1
"def free(self, addr, ban=0):<tab>with self.lock:<tab><tab>if ban != 0:<tab><tab><tab>self.ban.append({""addr"": addr, ""counter"": ban})<tab><tab>else:<tab><tab><tab>base, bit, is_allocated = self.locate(addr)<tab><tab><tab>if len(self.addr_map) <= base:<tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise KeyError(""address is not allocated"")<tab><tab><tab>self.allocated -= 1<tab><tab><tab>self.addr_map[base] ^= 1 << bit",0,if self . addr_map [ base ] & ( 1 << bit ) :,if not is_allocated :,0.00720913,1.707863452,0.265306122
"def _assertParseMethod(test, code_str, method, expect_success=True):<tab>arena, c_parser = InitCommandParser(code_str)<tab>m = getattr(c_parser, method)<tab>node = m()<tab>if node:<tab><tab>ast_lib.PrettyPrint(node)<tab><tab>if not expect_success:<tab><tab><tab>test.fail(""Expected %r to fail "" % code_str)<tab>else:<tab><tab># TODO: Could copy PrettyPrintError from pysh.py<tab><tab>err = c_parser.Error()<tab><tab>print(err)<tab><tab>ui.PrintErrorStack(err, arena, sys.stdout)<tab><tab><IF-STMT><tab><tab><tab>test.fail(""%r failed"" % code_str)<tab>return node",0,if expect_success :,if not expect_success :,0.113486237,1.00E-10,0.6
"def _gen():<tab>while True:<tab><tab>try:<tab><tab><tab>loop_val = it.next()  # e.g. x<tab><tab>except StopIteration:<tab><tab><tab>break<tab><tab>self.mem.SetValue(<tab><tab><tab>lvalue.Named(iter_name), value.Obj(loop_val), scope_e.LocalOnly<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>b = self.EvalExpr(comp.cond)<tab><tab>else:<tab><tab><tab>b = True<tab><tab>if b:<tab><tab><tab>item = self.EvalExpr(node.elt)  # e.g. x*2<tab><tab><tab>yield item",0,if comp . cond :,if comp . cond is not None :,0.351498834,36.55552229,0.510204082
"def _build_default_obj_recursive(self, _properties, res):<tab>""""""takes disparate and nested default keys, and builds up a default object""""""<tab>for key, prop in _properties.items():<tab><tab><IF-STMT><tab><tab><tab>res[key] = copy(prop[""default""])<tab><tab>elif prop.get(""type"") == ""object"" and ""properties"" in prop:<tab><tab><tab>res.setdefault(key, {})<tab><tab><tab>res[key] = self._build_default_obj_recursive(prop[""properties""], res[key])<tab>return res",0,"if ""default"" in prop and key not in res :","if ""default"" in prop :",0.138975808,41.16538266,0.388888889
"def mean(self):<tab>""""""Compute the mean of the value_field in the window.""""""<tab>if len(self.data) > 0:<tab><tab>datasum = 0<tab><tab>datalen = 0<tab><tab>for dat in self.data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>datasum += dat[1]<tab><tab><tab><tab>datalen += 1<tab><tab>if datalen > 0:<tab><tab><tab>return datasum / float(datalen)<tab><tab>return None<tab>else:<tab><tab>return None",0,"if ""placeholder"" not in dat [ 0 ] :",if len ( dat ) == 2 :,0.016959991,5.024351198,0.236111111
"def addNames(self, import_names, node_names):<tab>for names in node_names:<tab><tab><IF-STMT><tab><tab><tab>name = names<tab><tab>elif names[1] is None:<tab><tab><tab>name = names[0]<tab><tab>else:<tab><tab><tab>name = names[1]<tab><tab>import_names[name] = True",0,"if isinstance ( names , basestring ) :",if len ( names ) == 1 :,0.037791629,11.99014838,0.428571429
"def set(sensor_spec: dict, **kwargs):<tab>for key, value in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>sensor_spec[""transform""] = SensorSpecs.get_position(value)<tab><tab>elif key == ""attachment_type"":<tab><tab><tab>sensor_spec[key] = SensorSpecs.ATTACHMENT_TYPE[value]<tab><tab>elif key == ""color_converter"":<tab><tab><tab>sensor_spec[key] = SensorSpecs.COLOR_CONVERTER[value]",0,"if key == ""position"" :","if key == ""transform"" :",0.394778655,59.46035575,1
"def delete_session(self):<tab>cookie = self.headers.get(HTTP_HEADER.COOKIE)<tab>if cookie:<tab><tab>match = re.search(r""%s=(.+)"" % SESSION_COOKIE_NAME, cookie)<tab><tab>if match:<tab><tab><tab>session = match.group(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del SESSIONS[session]",1,if session in SESSIONS :,if session in SESSIONS :,0.75,100,1
"def rename_var(block: paddle.device.framework.Block, old_name: str, new_name: str):<tab>"""""" """"""<tab>for op in block.ops:<tab><tab>for input_name in op.input_arg_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>op._rename_input(old_name, new_name)<tab><tab>for output_name in op.output_arg_names:<tab><tab><tab>if output_name == old_name:<tab><tab><tab><tab>op._rename_output(old_name, new_name)<tab>block._rename_var(old_name, new_name)",1,if input_name == old_name :,if input_name == old_name :,0.75,100,1
"def updateParticle(part, best, phi1, phi2):<tab>u1 = numpy.random.uniform(0, phi1, len(part))<tab>u2 = numpy.random.uniform(0, phi2, len(part))<tab>v_u1 = u1 * (part.best - part)<tab>v_u2 = u2 * (best - part)<tab>part.speed += v_u1 + v_u2<tab>for i, speed in enumerate(part.speed):<tab><tab><IF-STMT><tab><tab><tab>part.speed[i] = math.copysign(part.smin, speed)<tab><tab>elif abs(speed) > part.smax:<tab><tab><tab>part.speed[i] = math.copysign(part.smax, speed)<tab>part += part.speed",1,if abs ( speed ) < part . smin :,if abs ( speed ) < part . smin :,0.75,100,1
"def acquire(self, blocking=True, timeout=None):<tab>if not blocking and timeout is not None:<tab><tab>raise ValueError(""can't specify timeout for non-blocking acquire"")<tab>rc = False<tab>endtime = None<tab>self._cond.acquire()<tab>while self._value == 0:<tab><tab>if not blocking:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>if endtime is None:<tab><tab><tab><tab>endtime = _time() + timeout<tab><tab><tab>else:<tab><tab><tab><tab>timeout = endtime - _time()<tab><tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab><tab>break<tab><tab>self._cond.wait(timeout)<tab>else:<tab><tab>self._value = self._value - 1<tab><tab>rc = True<tab>self._cond.release()<tab>return rc",1,if timeout is not None :,if timeout is not None :,0.75,100,1
"def test_ESPnetDataset_text_float(text_float):<tab>dataset = IterableESPnetDataset(<tab><tab>path_name_type_list=[(text_float, ""data8"", ""text_float"")],<tab><tab>preprocess=preprocess,<tab>)<tab>for key, data in dataset:<tab><tab><IF-STMT><tab><tab><tab>assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))<tab><tab>if key == ""b"":<tab><tab><tab>assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))",1,"if key == ""a"" :","if key == ""a"" :",0.75,100,1
"def __eq__(self, other):<tab>if isinstance(other, OrderedDict):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>for p, q in zip(list(self.items()), list(other.items())):<tab><tab><tab>if p != q:<tab><tab><tab><tab>return False<tab><tab>return True<tab>return dict.__eq__(self, other)",1,if len ( self ) != len ( other ) :,if len ( self ) != len ( other ) :,1,100,1
"def exec_command(command, cwd=None, stdout=None, env=None):<tab>""""""Returns True in the command was executed successfully""""""<tab>try:<tab><tab>command_list = command if isinstance(command, list) else command.split()<tab><tab>env_vars = os.environ.copy()<tab><tab><IF-STMT><tab><tab><tab>env_vars.update(env)<tab><tab>subprocess.check_call(command_list, stdout=stdout, cwd=cwd, env=env_vars)<tab><tab>return True<tab>except subprocess.CalledProcessError as err:<tab><tab>print(err, file=sys.stderr)<tab><tab>return False",1,if env :,if env :,0.531170663,1.00E-10,1
"def _get_lun_details(self, lun_id):<tab>""""""Given the ID of a LUN, get the details about that LUN""""""<tab>server = self.client.service<tab>res = server.LunListInfoIterStart(ObjectNameOrId=lun_id)<tab>tag = res.Tag<tab>try:<tab><tab>res = server.LunListInfoIterNext(Tag=tag, Maximum=1)<tab><tab><IF-STMT><tab><tab><tab>return res.Luns.LunInfo[0]<tab>finally:<tab><tab>server.LunListInfoIterEnd(Tag=tag)",0,"if hasattr ( res , ""Luns"" ) and res . Luns . LunInfo :",if res . Luns . LunInfo :,0.172919661,23.24683759,0.260504202
"def _process_events(self, event_list):<tab>for key, mask in event_list:<tab><tab>fileobj, (reader, writer) = key.fileobj, key.data<tab><tab>if mask & selectors.EVENT_READ and reader is not None:<tab><tab><tab>if reader._cancelled:<tab><tab><tab><tab>self.remove_reader(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(reader)<tab><tab><IF-STMT><tab><tab><tab>if writer._cancelled:<tab><tab><tab><tab>self.remove_writer(fileobj)<tab><tab><tab>else:<tab><tab><tab><tab>self._add_callback(writer)",1,if mask & selectors . EVENT_WRITE and writer is not None :,if mask & selectors . EVENT_WRITE and writer is not None :,0.75,100,1
"def process_doc(self, docstrings: List[List[str]]) -> Iterator[str]:<tab>""""""Let the user process the docstrings before adding them.""""""<tab>for docstringlines in docstrings:<tab><tab>if self.env.app:<tab><tab><tab># let extensions preprocess docstrings<tab><tab><tab>self.env.app.emit(<tab><tab><tab><tab>""autodoc-process-docstring"",<tab><tab><tab><tab>self.objtype,<tab><tab><tab><tab>self.fullname,<tab><tab><tab><tab>self.object,<tab><tab><tab><tab>self.options,<tab><tab><tab><tab>docstringlines,<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab># append a blank line to the end of the docstring<tab><tab><tab><tab>docstringlines.append("""")<tab><tab>yield from docstringlines",0,"if docstringlines and docstringlines [ - 1 ] != """" :","if docstringlines . endswith ( ""\n"" ) :",0.023783637,7.858254246,0.420634921
"def vectorize(self, doc, vocab, char_vocab):<tab>words = np.asarray(<tab><tab>[vocab[w.lower()] if w.lower() in vocab else 1 for w in doc]<tab>).reshape(1, -1)<tab>sentence_chars = []<tab>for w in doc:<tab><tab>word_chars = []<tab><tab>for c in w:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_cid = char_vocab[c]<tab><tab><tab>else:<tab><tab><tab><tab>_cid = 1<tab><tab><tab>word_chars.append(_cid)<tab><tab>sentence_chars.append(word_chars)<tab>sentence_chars = np.expand_dims(<tab><tab>pad_sentences(sentence_chars, self.model.word_length), axis=0<tab>)<tab>return words, sentence_chars",1,if c in char_vocab :,if c in char_vocab :,0.75,100,1
"def runtestenv(venv, config, redirect=False):<tab>if venv.status == 0 and config.option.notest:<tab><tab>venv.status = ""skipped tests""<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>config.pluginmanager.hook.tox_runtest_pre(venv=venv)<tab><tab>if venv.status == 0:<tab><tab><tab>config.pluginmanager.hook.tox_runtest(venv=venv, redirect=redirect)<tab><tab>config.pluginmanager.hook.tox_runtest_post(venv=venv)",0,if venv . status :,if redirect :,0.03549272,1.00E-10,0.36
"def _import_config_module(self, name):<tab>try:<tab><tab>self.find_module(name)<tab>except NotAPackage:<tab><tab><IF-STMT><tab><tab><tab>reraise(<tab><tab><tab><tab>NotAPackage,<tab><tab><tab><tab>NotAPackage(CONFIG_WITH_SUFFIX.format(module=name, suggest=name[:-3])),<tab><tab><tab><tab>sys.exc_info()[2],<tab><tab><tab>)<tab><tab>reraise(<tab><tab><tab>NotAPackage,<tab><tab><tab>NotAPackage(CONFIG_INVALID_NAME.format(module=name)),<tab><tab><tab>sys.exc_info()[2],<tab><tab>)<tab>else:<tab><tab>return self.import_from_cwd(name)",1,"if name . endswith ( "".py"" ) :","if name . endswith ( "".py"" ) :",0.75,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 8 :,if tt == 8 :,0.75,100,1
"def get(self, request, *args, **kwargs):<tab># Generate sidebar forms<tab>self.sidebar_forms = []<tab>for form_id, (plugin, Form) in self.get_sidebar_form_classes().items():<tab><tab><IF-STMT><tab><tab><tab>form = Form(self.article, self.request.user)<tab><tab><tab>setattr(form, ""form_id"", form_id)<tab><tab>else:<tab><tab><tab>form = None<tab><tab>self.sidebar.append((plugin, form))<tab>return super().get(request, *args, **kwargs)",0,if Form :,if form_id :,0.319750449,1.00E-10,0.555555556
"def check_click(self):<tab>if not isinstance(self, SwiDebugView):<tab><tab>return<tab>cursor = self.sel()[0].a<tab>index = 0<tab>click_regions = self.get_regions(""swi_log_clicks"")<tab>for callback in click_regions:<tab><tab>if cursor > callback.a and cursor < callback.b:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>callback = self.callbacks[index]<tab><tab><tab><tab>callback[""callback""](*callback[""args""])<tab><tab>index += 1",1,if index < len ( self . callbacks ) :,if index < len ( self . callbacks ) :,0.75,100,1
"def get_sock(port):<tab>sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)<tab>while True:<tab><tab>try:<tab><tab><tab>_port = port or random.randint(1025, 5000)<tab><tab><tab>print((""try bind local port:"", _port))<tab><tab><tab>sock.bind((""0.0.0.0"", _port))<tab><tab><tab>return sock<tab><tab>except socket.error as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print((""bind local port %d fail: %r"" % (_port, e)))<tab><tab><tab><tab>return<tab><tab><tab>if e.args[0] == errno.EADDRINUSE:<tab><tab><tab><tab>pass",0,if port :,if e . args [ 0 ] == errno . EADDRNOTAVAIL :,0.041034442,1.00E-10,0.21875
"def ParsePlacemark(self, node):<tab>ret = Placemark()<tab>for child in node.childNodes:<tab><tab>if child.nodeName == ""name"":<tab><tab><tab>ret.name = self.ExtractText(child)<tab><tab><IF-STMT><tab><tab><tab>ret.coordinates = self.ExtractCoordinates(child)<tab>return ret",0,"if child . nodeName == ""Point"" or child . nodeName == ""LineString"" :","elif child . nodeType == ""coordinates"" :",0.219336877,9.333818274,0.212885154
"def _load_library(self):<tab>if self.library is not None:<tab><tab><IF-STMT><tab><tab><tab>name, mod_path = self.library<tab><tab>else:<tab><tab><tab>name = mod_path = self.library<tab><tab>try:<tab><tab><tab>module = importlib.import_module(mod_path)<tab><tab>except ImportError:<tab><tab><tab>raise ValueError(""Couldn't load %s password algorithm "" ""library"" % name)<tab><tab>return module<tab>raise ValueError(""Hasher '%s' doesn't specify a library attribute"" % self.__class__)",0,"if isinstance ( self . library , ( tuple , list ) ) :","if isinstance ( self . library , tuple ) :",0.309634477,48.66386314,0.848739496
"def check(self):<tab>for r in self.results:<tab><tab><IF-STMT><tab><tab><tab>assert r.backend.name == self.target.path.k8s, (<tab><tab><tab><tab>r.backend.name,<tab><tab><tab><tab>self.target.path.k8s,<tab><tab><tab>)<tab><tab><tab>assert r.backend.request.headers[""x-envoy-original-path""][0] in (<tab><tab><tab><tab>f""/{self.name}/"",<tab><tab><tab><tab>f""/{self.name}-nested/"",<tab><tab><tab>)",1,if r . backend :,if r . backend :,0.75,100,1
"def eval(self, code, eval=True, raw=False):<tab>self._engine._append_source(code)<tab>try:<tab><tab>result = self._context.eval(code)<tab>except quickjs.JSException as e:<tab><tab>raise ProgramError(*e.args)<tab>else:<tab><tab>if eval:<tab><tab><tab>if raw or not isinstance(result, quickjs.Object):<tab><tab><tab><tab>return result<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.Function(self, result)<tab><tab><tab>else:<tab><tab><tab><tab>return json.loads(result.json())",0,"elif callable ( result ) and self . typeof ( result ) == u""function"" :","elif isinstance ( result , quickjs . Function ) :",0.093103734,4.490478776,0.255555556
"def __truediv__(self, val):<tab>if isinstance(val, Vector3):<tab><tab><IF-STMT><tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_vector(self._gd_ptr, val._gd_ptr)<tab>else:<tab><tab>if val is 0:<tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_scalar(self._gd_ptr, val)<tab>return Vector3.build_from_gdobj(gd_obj)",0,if val . x == 0 or val . y == 0 or val . z == 0 :,if val . _gd_ptr is None :,0.023258212,5.055382089,0.213636364
"def set_peek(self, dataset, is_multi_byte=False):<tab>if not dataset.dataset.purged:<tab><tab>dataset.peek = data.get_file_peek(dataset.file_name)<tab><tab><IF-STMT><tab><tab><tab>dataset.blurb = ""%s sequences"" % util.commaify(<tab><tab><tab><tab>str(dataset.metadata.sequences)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>dataset.blurb = nice_size(dataset.get_size())<tab>else:<tab><tab>dataset.peek = ""file does not exist""<tab><tab>dataset.blurb = ""file purged from disk""",1,if dataset . metadata . sequences :,if dataset . metadata . sequences :,0.75,100,1
"def _get_plugin_src_dirs(base_dir):<tab>plug_in_base_path = Path(get_src_dir(), base_dir)<tab>plugin_dirs = get_dirs_in_dir(str(plug_in_base_path))<tab>plugins = []<tab>for plugin_path in plugin_dirs:<tab><tab>plugin_code_dir = Path(plugin_path, ""code"")<tab><tab><IF-STMT><tab><tab><tab>plugins.append(str(plugin_code_dir))<tab><tab>else:<tab><tab><tab>logging.warning(""Plugin has no code directory: {}"".format(plugin_path))<tab>return plugins",0,if plugin_code_dir . is_dir ( ) :,if os . path . exists ( plugin_code_dir ) :,0.038008523,33.42866122,0.36
"def _format_privilege_data(self, data):<tab>for key in [""spcacl""]:<tab><tab>if key in data and data[key] is not None:<tab><tab><tab>if ""added"" in data[key]:<tab><tab><tab><tab>data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl)<tab><tab><tab>if ""changed"" in data[key]:<tab><tab><tab><tab>data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)",1,"if ""deleted"" in data [ key ] :","if ""deleted"" in data [ key ] :",0.75,100,1
"def __init__(self, methodName=""runTest""):<tab>unittest.TestCase.__init__(self, methodName)<tab># We expect files to be relative to this test script.<tab>test_dir = dirname(dirname(__file__))<tab>self._dir = normpath(join(test_dir, ""stuff/charsets/www.kostis.net/charsets""))<tab>self._enc = {}<tab># get all the utf-8 files in this dir, and well recode them<tab>names = os.listdir(self._dir)<tab>for name in names:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>enc = name.split(""."")[0]<tab><tab>if decoderAvailable(enc):<tab><tab><tab>self._enc[enc] = name",0,"if not os . path . isfile ( os . path . join ( self . _dir , name ) ) :","if not name . endswith ( "".utf"" ) :",0.01288656,4.554598656,0.28
"def get_actions_on_list(self, actions, modelview_name):<tab>res_actions = dict()<tab>for action_key in actions:<tab><tab>action = actions[action_key]<tab><tab><IF-STMT><tab><tab><tab>res_actions[action_key] = action<tab>return res_actions",0,"if self . is_item_visible ( action . name , modelview_name ) and action . multiple :","if isinstance ( action , modelview_name ) :",0.039336088,14.49038514,0.310606061
"def triger_check_network(self, fail=False, force=False):<tab>time_now = time.time()<tab>if not force:<tab><tab>if self._checking_num > 0:<tab><tab><tab>return<tab><tab>if fail or self.network_stat != ""OK"":<tab><tab><tab># Fail or unknown<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>else:<tab><tab><tab>if time_now - self.last_check_time < 10:<tab><tab><tab><tab>return<tab>self.last_check_time = time_now<tab>threading.Thread(target=self._simple_check_worker).start()",0,if time_now - self . last_check_time < 3 :,if time_now - self . last_check_time < 10 :,0.627090855,86.66415731,0.6
"def write(self, root):<tab>""""""Write all the *descendants* of an .dart node.""""""<tab>root_level = root.level()<tab>for p in root.subtree():<tab><tab>indent = p.level() - root_level<tab><tab>self.put(""%s %s"" % (""*"" * indent, p.h))<tab><tab>for s in p.b.splitlines(False):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.put(s)<tab>root.setVisited()<tab>return True",0,if not g . isDirective ( s ) :,if s :,0.076454293,1.00E-10,0.287878788
"def characters(self, ch):<tab>if self.Text_tag:<tab><tab><IF-STMT><tab><tab><tab>self.Summary_ch += ch<tab><tab>elif self.Attack_Prerequisite_tag:<tab><tab><tab>self.Attack_Prerequisite_ch += ch<tab><tab>elif self.Solution_or_Mitigation_tag:<tab><tab><tab>self.Solution_or_Mitigation_ch += ch<tab>elif self.CWE_ID_tag:<tab><tab>self.CWE_ID_ch += ch",1,if self . Summary_tag :,if self . Summary_tag :,0.75,100,1
"def _handle_function(self, addr):<tab>if self.arch.name == ""X86"":<tab><tab>try:<tab><tab><tab>b = self._project.loader.memory.load(addr, 4)<tab><tab>except KeyError:<tab><tab><tab>return<tab><tab>except TypeError:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab># getpc:<tab><tab><tab>#   mov ebx, [esp]<tab><tab><tab>#   ret<tab><tab><tab>ebx_offset = self.arch.registers[""ebx""][0]<tab><tab><tab>self.state.store_register(ebx_offset, 4, self.block.addr + self.block.size)",0,"if b == b""\x8b\x1c\x24\xc3"" :",if b . addr == addr :,0.305449142,6.075831217,0.6875
"def safe_makedir(dname):<tab>""""""Make a directory if it doesn't exist, handling concurrent race conditions.""""""<tab>if not dname:<tab><tab>return dname<tab>num_tries = 0<tab>max_tries = 5<tab>while not os.path.exists(dname):<tab><tab># we could get an error here if multiple processes are creating<tab><tab># the directory at the same time. Grr, concurrency.<tab><tab>try:<tab><tab><tab>os.makedirs(dname)<tab><tab>except OSError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>num_tries += 1<tab><tab><tab>time.sleep(2)<tab>return dname",1,if num_tries > max_tries :,if num_tries > max_tries :,0.75,100,1
"def _setup_data(self, path):<tab>with PathManager.open(path) as data_file:<tab><tab><IF-STMT><tab><tab><tab>line = data_file.readline()<tab><tab><tab># trim corrupted JSON<tab><tab><tab>line = line[: line.rfind(""{"")]<tab><tab><tab>line = line[: line.rfind("","")] + ""]""<tab><tab><tab>self.data = json.loads(line)<tab><tab>else:<tab><tab><tab>self.data = json.load(data_file)",0,"if ""extra"" in path and ""train"" in path :",if data_file . exists ( ) :,0.01593847,3.635358867,0.266666667
"def _end_delimiter(state, token):<tab>py = state[""pymode""]<tab>s = token.string<tab>l, c = token.start<tab>if len(py) > 1:<tab><tab>mode, orig, match, pos = py.pop()<tab><tab><IF-STMT><tab><tab><tab>e = '""{}"" at {} ends ""{}"" at {} (expected ""{}"")'<tab><tab><tab>return e.format(s, (l, c), orig, pos, match)<tab>else:<tab><tab>return 'Unmatched ""{}"" at line {}, column {}'.format(s, l, c)",0,if s != match :,"if mode == ""end"" :",0.034123066,7.267884212,0.36
"def onLeftDoubleClick(self, event):<tab>row, _ = self.HitTest(event.Position)<tab>if row != -1:<tab><tab>col = self.getColumn(event.Position)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>booster = self.boosters[row]<tab><tab><tab>except IndexError:<tab><tab><tab><tab>return<tab><tab><tab>self.removeBoosters([booster])",0,if col != self . getColIndex ( State ) :,if col != self . getColIndex ( ) :,0.35789812,75.16501148,0.818181818
"def get_instance_userdata(<tab>version=""latest"",<tab>sep=None,<tab>url=""http://169.254.169.254"",<tab>timeout=None,<tab>num_retries=5,):<tab>ud_url = _build_instance_metadata_url(url, version, ""user-data"")<tab>user_data = retry_url(<tab><tab>ud_url, retry_on_404=False, num_retries=num_retries, timeout=timeout<tab>)<tab>if user_data:<tab><tab><IF-STMT><tab><tab><tab>l = user_data.split(sep)<tab><tab><tab>user_data = {}<tab><tab><tab>for nvpair in l:<tab><tab><tab><tab>t = nvpair.split(""="")<tab><tab><tab><tab>user_data[t[0].strip()] = t[1].strip()<tab>return user_data",1,if sep :,if sep :,0.531170663,1.00E-10,1
def parts(self):<tab>klass = self.__class__<tab>this = list()<tab>for token in self:<tab><tab>if token.startswith_fws():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield this[0] if len(this) == 1 else klass(this)<tab><tab><tab><tab>this.clear()<tab><tab>end_ws = token.pop_trailing_ws()<tab><tab>this.append(token)<tab><tab>if end_ws:<tab><tab><tab>yield klass(this)<tab><tab><tab>this = [end_ws]<tab>if this:<tab><tab>yield this[0] if len(this) == 1 else klass(this),1,if this :,if this :,0.531170663,1.00E-10,1
"def run(self):<tab>while True:<tab><tab>self._trigger.wait()<tab><tab>self._trigger.clear()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>for url in self.urls:<tab><tab><tab>logger.info(""Pinging for problem update: %s"", url)<tab><tab><tab>try:<tab><tab><tab><tab>with closing(urlopen(url, data="""")) as f:<tab><tab><tab><tab><tab>f.read()<tab><tab><tab>except Exception:<tab><tab><tab><tab>logger.exception(""Failed to ping for problem update: %s"", url)",0,if self . _terminate :,if self . _trigger . is_set ( ) :,0.105226223,22.4169335,1
"def _get_trading_minutes(self, trading_date):<tab>trading_minutes = set()<tab>for account_type in self._config.base.accounts:<tab><tab>if account_type == DEFAULT_ACCOUNT_TYPE.STOCK:<tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_stock_trading_minutes(trading_date)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>trading_minutes = trading_minutes.union(<tab><tab><tab><tab>self._get_future_trading_minutes(trading_date)<tab><tab><tab>)<tab>return sorted(list(trading_minutes))",0,elif account_type == DEFAULT_ACCOUNT_TYPE . FUTURE :,elif account_type == DEFAULT_ACCOUNT_TYPE . COMPLETED :,0.571729442,85.55261859,0.5
"def make_tree(self, node):<tab>if node is self.root:<tab><tab>node.code = """"<tab>children = []<tab>for bit in ""01"":<tab><tab>next_code = node.code + bit<tab><tab><IF-STMT><tab><tab><tab>child = Node(char=self.codes[next_code])<tab><tab>else:<tab><tab><tab>child = Node()<tab><tab>child.code = next_code<tab><tab>children.append(child)<tab>node.add(children)<tab>for child in children:<tab><tab>if not child.is_leaf:<tab><tab><tab>self.make_tree(child)",1,if next_code in self . codes :,if next_code in self . codes :,0.75,100,1
"def _merge(self, a, b, path=None):<tab>""""""Merge two dictionaries, from http://stackoverflow.com/questions/7204805/dictionaries-of-dictionaries-merge""""""<tab>if path is None:<tab><tab>path = []<tab>for key in b:<tab><tab>if key in a:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._merge(a[key], b[key], path + [str(key)])<tab><tab><tab>elif a[key] == b[key]:<tab><tab><tab><tab>pass  # same leaf value<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""Conflict at %s"" % ""."".join(path + [str(key)]))<tab><tab>else:<tab><tab><tab>a[key] = b[key]<tab>return a",1,"if isinstance ( a [ key ] , dict ) and isinstance ( b [ key ] , dict ) :","if isinstance ( a [ key ] , dict ) and isinstance ( b [ key ] , dict ) :",1,100,1
"def _append_value(generator, val=None):<tab>for example in generator:<tab><tab>example = list(example)<tab><tab><IF-STMT><tab><tab><tab>for key, value in val.items():<tab><tab><tab><tab>example[key] = np.append(example[key], value, -1)<tab><tab>yield tuple(example)",1,if val is not None :,if val is not None :,0.75,100,1
"def run(self):<tab>to_delete = set()<tab>for k, v in iteritems(self.objs):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if v[""_class""] == ""SubmissionFormatElement"":<tab><tab><tab>to_delete.add(k)<tab><tab>if v[""_class""] == ""Task"":<tab><tab><tab>v[""submission_format""] = list(<tab><tab><tab><tab>self.objs[k][""filename""] for k in v.get(""submission_format"", list())<tab><tab><tab>)<tab>for k in to_delete:<tab><tab>del self.objs[k]<tab>return self.objs",1,"if k . startswith ( ""_"" ) :","if k . startswith ( ""_"" ) :",0.75,100,1
"def service_destroy(context, service_id):<tab>session = get_session()<tab>with session.begin():<tab><tab>service_ref = service_get(context, service_id, session=session)<tab><tab>service_ref.delete(session=session)<tab><tab><IF-STMT><tab><tab><tab>for c in service_ref.compute_node:<tab><tab><tab><tab>c.delete(session=session)",0,"if service_ref . topic == ""compute"" and service_ref . compute_node :",if service_ref . compute_node :,0.142375225,29.45748283,0.472222222
"def wiki(self, query):<tab>res = []<tab>for entry in g.current_wiki.get_index():<tab><tab>name = filename_to_cname(entry[""name""])<tab><tab>name = re.sub(r""//+"", ""/"", name)<tab><tab><IF-STMT><tab><tab><tab>page = g.current_wiki.get_page(name)<tab><tab><tab># this can be None, not sure how<tab><tab><tab>if page:<tab><tab><tab><tab>res.append(dict(name=name, content=page.data))<tab>return res",0,"if set ( query . split ( ) ) . intersection ( name . replace ( ""/"" , ""-"" ) . split ( ""-"" ) ) :",if name :,0.002754702,1.00E-10,0.232954545
"def numericalize(self, arr, device=None):<tab>if isinstance(arr[0][0], list):<tab><tab>tmp = [<tab><tab><tab>super(BABI20Field, self).numericalize(x, device=device).data for x in arr<tab><tab>]<tab><tab>arr = torch.stack(tmp)<tab><tab><IF-STMT><tab><tab><tab>arr = arr.contiguous()<tab><tab>return arr<tab>else:<tab><tab>return super(BABI20Field, self).numericalize(arr, device=device)",0,if self . sequential :,if device is not None :,0.030286783,9.652434877,0.1875
def validate_and_handle(self):<tab>valid = self.validate(set_cursor=True)<tab>if valid:<tab><tab>if self.accept_handler:<tab><tab><tab>keep_text = self.accept_handler(self)<tab><tab>else:<tab><tab><tab>keep_text = False<tab><tab><IF-STMT><tab><tab><tab>self.reset(),0,if not keep_text :,if keep_text :,0.096488528,1.00E-10,0.6
"def headerData(self, section, orientation, role=Qt.DisplayRole):<tab>if role == Qt.TextAlignmentRole:<tab><tab>if orientation == Qt.Horizontal:<tab><tab><tab>return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))<tab><tab>return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))<tab>if role != Qt.DisplayRole:<tab><tab>return to_qvariant()<tab>if orientation == Qt.Horizontal:<tab><tab><IF-STMT><tab><tab><tab>return to_qvariant(""Name"")<tab><tab>elif section == VERSION:<tab><tab><tab>return to_qvariant(""Version"")<tab><tab>elif section == ACTION:<tab><tab><tab>return to_qvariant(""Action"")<tab><tab>elif section == DESCRIPTION:<tab><tab><tab>return to_qvariant(""Description"")<tab>return to_qvariant()",1,if section == NAME :,if section == NAME :,0.75,100,1
"def replace(self, state):<tab>if state.key in self._dict:<tab><tab>try:<tab><tab><tab>existing = self._dict[state.key]<tab><tab>except KeyError:<tab><tab><tab># catch gc removed the key after we just checked for it<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._manage_removed_state(existing)<tab><tab><tab>else:<tab><tab><tab><tab>return<tab>self._dict[state.key] = state<tab>self._manage_incoming_state(state)",0,if existing is not state :,if existing :,0.050438393,1.00E-10,0.4
"def _line_generator(fh, skip_blanks=False, strip=True):<tab>for line in fh:<tab><tab><IF-STMT><tab><tab><tab>line = line.strip()<tab><tab>skip = False<tab><tab>if skip_blanks:<tab><tab><tab>skip = line.isspace() or not line<tab><tab>if not skip:<tab><tab><tab>yield line",1,if strip :,if strip :,0.531170663,1.00E-10,1
"def _get_workers_with_max_size(worker_to_size):<tab>""""""Get workers with maximal size""""""<tab>max_workers = set()<tab>max_size = 0<tab>for w, size in worker_to_size.items():<tab><tab><IF-STMT><tab><tab><tab>max_size = size<tab><tab><tab>max_workers = {w}<tab><tab>elif size == max_size:<tab><tab><tab>max_workers.add(w)<tab>max_workers.difference_update([None])<tab>return max_size, list(max_workers)",1,if size > max_size :,if size > max_size :,0.75,100,1
"def parse(self):<tab>while 1:<tab><tab>l = self.f.readline()<tab><tab>if not l:<tab><tab><tab>return<tab><tab>l = l.strip()<tab><tab>if l.startswith(""[""):<tab><tab><tab>self.parse_uuid(l)<tab><tab>elif l.startswith(""interface"") or l.startswith(""dispinterface""):<tab><tab><tab>self.parse_interface(l)<tab><tab><IF-STMT><tab><tab><tab>self.parse_coclass(l)",1,"elif l . startswith ( ""coclass"" ) :","elif l . startswith ( ""coclass"" ) :",0.75,100,1
"def check_source_unit(self, source, unit):<tab>""""""Check source string.""""""<tab>rules = [FLAG_RULES[flag] for flag in unit.all_flags if flag in FLAG_RULES]<tab>if not rules:<tab><tab>return False<tab>found = set()<tab>for regexp, is_position_based in rules:<tab><tab>for match in regexp.finditer(source[0]):<tab><tab><tab>if is_position_based(match[1]):<tab><tab><tab><tab>found.add((match.start(0), match.end(0)))<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return True<tab>return False",0,if len ( found ) >= 2 :,if found :,0.01726708,1.00E-10,0.36
"def parse_exprlist(self):<tab>list = []<tab>while TRUE:<tab><tab>self.reader.skip_white()<tab><tab>c = self.reader.peek()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>node = self.parse_expr()<tab><tab>viml_add(list, node)<tab>return list",0,"if c != '""' and self . ends_excmds ( c ) :","if c == ""\n"" :",0.019214386,4.929297364,0.498039216
"def can_see_ban_details(request, profile):<tab>if request.user.is_authenticated:<tab><tab><IF-STMT><tab><tab><tab>from .bans import get_user_ban<tab><tab><tab>return bool(get_user_ban(profile, request.cache_versions))<tab><tab>return False<tab>return False",0,"if request . user_acl [ ""can_see_ban_details"" ] :",if request . cache_versions :,0.078889319,5.770453189,1
"def mouse_move(self, ips, x, y, btn, **key):<tab>if ips.roi == None:<tab><tab>return<tab>lim = 5.0 / key[""canvas""].get_scale()<tab>if btn == None:<tab><tab>self.cursor = wx.CURSOR_CROSS<tab><tab><IF-STMT><tab><tab><tab>self.cursor = wx.CURSOR_HAND<tab>elif btn == 1:<tab><tab>if self.curobj:<tab><tab><tab>ips.roi.draged(self.odx, self.ody, x, y, ips.cur, self.curobj)<tab><tab>ips.update()<tab>self.odx, self.ody = x, y",0,"if ips . roi . snap ( x , y , ips . cur , lim ) != None :","elif ips . roi . snapped ( x , y , ips . cur , lim ) :",0.567740086,61.59692777,0.579365079
"def evex_mask_dest_reg_only(ii):  # optional imm8<tab>i, m, xyz = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_mask_reg(op):<tab><tab><tab>m += 1<tab><tab><IF-STMT><tab><tab><tab>xyz += 1<tab><tab>elif op_imm8(op):<tab><tab><tab>i += 1<tab><tab>else:<tab><tab><tab>return False<tab>return m == 1 and xyz > 0 and i <= 1",0,elif op_xmm ( op ) or op_ymm ( op ) or op_zmm ( op ) :,elif op_xyz ( op ) :,0.190841539,8.688697173,0.583333333
"def encode_datetime(self, dt, state):<tab>fmt = self.options.datetime_format<tab>is_iso = not fmt or fmt == ""iso""<tab>if is_iso:<tab><tab><IF-STMT><tab><tab><tab>fmt = ""%Y-%m-%dT%H:%M:%S%z""<tab><tab>else:<tab><tab><tab>fmt = ""%Y-%m-%dT%H:%M:%S.%f%z""<tab>s = dt.strftime(fmt)<tab>if is_iso and s.endswith(""-00:00"") or s.endswith(""+00:00""):<tab><tab>s = s[:-6] + ""Z""  # Change UTC to use 'Z' notation<tab>self.encode_string(s, state)",0,if dt . microsecond == 0 :,if dt . tzinfo is None :,0.090565314,22.77210132,0.35
"def main(config):<tab>with PathManager.open(config[""infile""], ""r"") as fin, PathManager.open(<tab><tab>config[""outfile""], ""w""<tab>) as fout:<tab><tab>for line in fin.readlines():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>first_space = line.index("" "")<tab><tab><tab>first_tab = line.index(""\t"")<tab><tab><tab>candidate = line[first_space + 1 : first_tab]<tab><tab><tab>fout.write(candidate + ""\n"")",0,"if ""persona"" in line :",if not line :,0.070152444,16.70067963,0.6
"def compact_repr(record):<tab>parts = []<tab>for key in record.__attributes__:<tab><tab>value = getattr(record, key)<tab><tab>if not value:<tab><tab><tab>continue<tab><tab>if isinstance(value, list):<tab><tab><tab>value = HIDE_LIST<tab><tab><IF-STMT><tab><tab><tab>value = format_feats(value)<tab><tab>else:<tab><tab><tab>value = repr(value)<tab><tab>value = capped_str(value)<tab><tab>parts.append(""%s=%s"" % (key, value))<tab>return ""%s(%s)"" % (record.__class__.__name__, "", "".join(parts))",0,elif key == FEATS :,"elif isinstance ( value , dict ) :",0.024231488,6.567274736,0.26984127
"def make_chain(word):<tab>which = 1<tab>while True:<tab><tab>songs = find_songs_that_start_with_word(word)<tab><tab><IF-STMT><tab><tab><tab>song = random.choice(songs)<tab><tab><tab>print(which, song[""name""] + "" by "" + song[""artists""][0][""name""])<tab><tab><tab>which += 1<tab><tab><tab>word = song[""name""].lower().split()[-1]<tab><tab>else:<tab><tab><tab>break",0,if len ( songs ) > 0 :,if len ( song ) > 0 :,0.501462237,50,0.666666667
"def set_break(self, filename, lineno, temporary=False, cond=None, funcname=None):<tab>if isinstance(funcname, str):<tab><tab><IF-STMT><tab><tab><tab>globals_ = globals()<tab><tab>else:<tab><tab><tab>module = importlib.import_module(filename[:-3])<tab><tab><tab>globals_ = module.__dict__<tab><tab>func = eval(funcname, globals_)<tab><tab>code = func.__code__<tab><tab>filename = code.co_filename<tab><tab>lineno = code.co_firstlineno<tab><tab>funcname = code.co_name<tab>res = super(Bdb, self).set_break(<tab><tab>filename, lineno, temporary=temporary, cond=cond, funcname=funcname<tab>)<tab>if isinstance(res, str):<tab><tab>raise BdbError(res)<tab>return res",0,if filename == __file__ :,"if filename . endswith ( "".py"" ) :",0.04979442,8.295193507,0.727272727
"def __init__(self, shapefile=None, shapeType=POINT, autoBalance=1):<tab>self.autoBalance = autoBalance<tab>if not shapefile:<tab><tab>Writer.__init__(self, shapeType)<tab>elif is_string(shapefile):<tab><tab>base = os.path.splitext(shapefile)[0]<tab><tab><IF-STMT><tab><tab><tab>r = Reader(base)<tab><tab><tab>Writer.__init__(self, r.shapeType)<tab><tab><tab>self._shapes = r.shapes()<tab><tab><tab>self.fields = r.fields<tab><tab><tab>self.records = r.records()",0,"if os . path . isfile ( ""%s.shp"" % base ) :",if base :,0.008307009,1.00E-10,0.303921569
"def test_env_not_set(self):<tab>with mock.patch.dict(""os.environ""):<tab><tab><IF-STMT><tab><tab><tab>del os.environ[self.env_name]<tab><tab>self.assertEqual(helper.get_xdg_env(self.env_name, self.default), self.default)",1,if self . env_name in os . environ :,if self . env_name in os . environ :,0.75,100,1
"def selection_only(self):<tab>selection_only = False<tab>sel = self.sel()<tab>if (self.context == ""selection"" or self.context == ""both"") and len(sel):<tab><tab># if multiple lines, always true<tab><tab>if len(sel) > 1:<tab><tab><tab>selection_only = True<tab><tab># check threshold<tab><tab>elif self.threshold and not sel[0].empty():<tab><tab><tab>text = self.view.substr(sel[0])<tab><tab><tab>match = re.search(self.threshold, text)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>selection_only = True<tab><tab># no valid selection<tab><tab>else:<tab><tab><tab>selection_only = False<tab>return selection_only",1,if match :,if match :,0.531170663,1.00E-10,1
"def __call__(self, rule, param):<tab>p, g = param.data, param.grad<tab>if p is None or g is None:<tab><tab>return<tab>with chainer.using_device(param.device):<tab><tab>xp = param.device.xp<tab><tab>sign = xp.sign(p)<tab><tab><IF-STMT><tab><tab><tab>kernel = cuda.elementwise(""T s, T decay"", ""T g"", ""g += decay * s"", ""lasso"")<tab><tab><tab>kernel(sign, self.rate, g)<tab><tab>else:<tab><tab><tab>g += self.rate * sign",0,if xp is cuda . cupy :,if xp . is_cuda :,0.044701561,17.28603923,0.428571429
"def map_packages(shutit_pexpect_session, package_str, install_type):<tab>res = """"<tab>for package in package_str.split():<tab><tab>map_package_res = map_package(shutit_pexpect_session, package, install_type)<tab><tab><IF-STMT><tab><tab><tab>return res<tab><tab>res += "" "" + map_package_res<tab>return res",1,"if map_package_res == """" :","if map_package_res == """" :",0.75,100,1
"def get_opnd_types_short(ii):<tab>types = []<tab>for op in _gen_opnds(ii):<tab><tab>if op.oc2:<tab><tab><tab>types.append(op.oc2)<tab><tab>elif op_luf_start(op, ""GPRv""):<tab><tab><tab>types.append(""v"")<tab><tab>elif op_luf_start(op, ""GPRz""):<tab><tab><tab>types.append(""z"")<tab><tab><IF-STMT><tab><tab><tab>types.append(""y"")<tab><tab>else:<tab><tab><tab>die(""Unhandled op type {}"".format(op))<tab>return types",1,"elif op_luf_start ( op , ""GPRy"" ) :","elif op_luf_start ( op , ""GPRy"" ) :",0.75,100,1
"def _process_archive(self, archive_stream, subtitle):<tab>for file_name in archive_stream.namelist():<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Found subtitle file %r"", file_name)<tab><tab><tab>subtitle.content = fix_line_ending(archive_stream.read(file_name))<tab><tab><tab>if subtitle.is_valid():<tab><tab><tab><tab>return",0,"if file_name . lower ( ) . endswith ( ( "".srt"" , "".sub"" ) ) :",if subtitle . is_valid ( ) :,0.080371948,2.818728402,0.392592593
"def truncate(self, size=None):<tab># type: (Optional[int]) -> int<tab># Inefficient, but I don't know if truncate is possible with ftp<tab>with self._lock:<tab><tab>if size is None:<tab><tab><tab>size = self.tell()<tab><tab>with self.fs.openbin(self.path) as f:<tab><tab><tab>data = f.read(size)<tab><tab>with self.fs.openbin(self.path, ""w"") as f:<tab><tab><tab>f.write(data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>f.write(b""\0"" * (size - len(data)))<tab>return size",0,if len ( data ) < size :,if size > 0 :,0.019907918,7.715486568,0.314814815
def wakeup(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.wm_withdraw()<tab><tab><tab>self.wm_deiconify()<tab><tab>self.tkraise()<tab><tab>self.focused_widget.focus_set()<tab>except TclError:<tab><tab># This can happen when the window menu was torn off.<tab><tab># Simply ignore it.<tab><tab>pass,0,"if self . wm_state ( ) == ""iconic"" :",if self . focused_widget is None :,0.067589311,11.56970651,0.566666667
"def locus_parser(self):<tab>line = self.stream.readline()<tab>while line != """":<tab><tab>line = line.rstrip()<tab><tab>match = re.match("" Locus: (.+)"", line)<tab><tab><IF-STMT><tab><tab><tab>locus = match.group(1)<tab><tab><tab>alleles, table = _read_allele_freq_table(self.stream)<tab><tab><tab>return locus, alleles, table<tab><tab>line = self.stream.readline()<tab>self.done = True<tab>raise StopIteration",0,if match is not None :,if match :,0.050438393,1.00E-10,0.4
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_content(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_blob_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_width(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_height(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 32 :,if tt == 32 :,0.75,100,1
"def concat_kernel_sources(self):<tab>func_sources = OrderedDict()<tab>for kernel in self.kernels:<tab><tab>for func_name, source in kernel.func_sources.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert func_sources[func_name] == source<tab><tab><tab>else:<tab><tab><tab><tab>func_sources[func_name] = source<tab>self.generate_top_source()<tab>self.generate_exec_source()<tab>self.generate_init_source()<tab>combined_source = (<tab><tab>"""".join(self.header_sources.values())<tab><tab>+ ""\n"".join(func_sources.values())<tab><tab>+ """".join(self.footer_sources.values())<tab>)<tab>return combined_source",1,if func_name in func_sources :,if func_name in func_sources :,0.75,100,1
"def parseUnderindentTag(self, s):<tab>tag = self.underindentEscapeString<tab>s2 = s[len(tag) :]<tab># To be valid, the escape must be followed by at least one digit.<tab>i = 0<tab>while i < len(s2) and s2[i].isdigit():<tab><tab>i += 1<tab>if i > 0:<tab><tab>n = int(s2[:i])<tab><tab># Bug fix: 2012/06/05: remove any period following the count.<tab><tab># This is a new convention.<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab>return n, s2[i:]<tab>else:<tab><tab>return 0, s",0,"if i < len ( s2 ) and s2 [ i ] == ""."" :",if n < tag :,0.00745897,1.04417756,0.225
"def load(self, data):<tab>ckey = None<tab>for key, val in _rx_cookie.findall(data):<tab><tab>if key.lower() in _c_keys:<tab><tab><tab>if ckey:<tab><tab><tab><tab>self[ckey][key] = _unquote(val)<tab><tab><IF-STMT><tab><tab><tab># RFC2109: NAMEs that begin with $ are reserved for other uses<tab><tab><tab># and must not be used by applications.<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>self[key] = _unquote(val)<tab><tab><tab>ckey = key",0,"elif key [ 0 ] == ""$"" :","elif ""_"" in key :",0.018840591,5.545738799,0.4
"def load_cases(full_path):<tab>all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict)<tab>for test_data in all_test_data:<tab><tab>given = test_data[""given""]<tab><tab>for case in test_data[""cases""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>test_type = ""result""<tab><tab><tab>elif ""error"" in case:<tab><tab><tab><tab>test_type = ""error""<tab><tab><tab>elif ""bench"" in case:<tab><tab><tab><tab>test_type = ""bench""<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""Unknown test type: %s"" % json.dumps(case))<tab><tab><tab>yield (given, test_type, case)",1,"if ""result"" in case :","if ""result"" in case :",0.75,100,1
"def delete(self):<tab>if not self.force and not self.exists():<tab><tab>return []<tab>cmd = [""delete""]<tab>if self.filename:<tab><tab>cmd.append(""--filename="" + self.filename)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.module.fail_json(msg=""resource required to delete without filename"")<tab><tab>cmd.append(self.resource)<tab><tab>if self.name:<tab><tab><tab>cmd.append(self.name)<tab><tab>if self.label:<tab><tab><tab>cmd.append(""--selector="" + self.label)<tab><tab>if self.all:<tab><tab><tab>cmd.append(""--all"")<tab><tab>if self.force:<tab><tab><tab>cmd.append(""--ignore-not-found"")<tab>return self._execute(cmd)",1,if not self . resource :,if not self . resource :,0.75,100,1
"def validate_latex_theme_options(app: Sphinx, config: Config) -> None:<tab>for key in list(config.latex_theme_options):<tab><tab><IF-STMT><tab><tab><tab>msg = __(""Unknown theme option: latex_theme_options[%r], ignored."")<tab><tab><tab>logger.warning(msg % (key,))<tab><tab><tab>config.latex_theme_options.pop(key)",0,if key not in Theme . UPDATABLE_KEYS :,"if key not in [ ""latex"" , ""theme"" ] :",0.290091211,18.79831765,0.818181818
"def connectionLost(self, reason):<tab><IF-STMT><tab><tab>self.log.info(<tab><tab><tab>""WampRawSocketProtocol: connection lost: reason = '{0}'"".format(reason)<tab><tab>)<tab>try:<tab><tab>wasClean = isinstance(reason.value, ConnectionDone)<tab><tab>self._session.onClose(wasClean)<tab>except Exception as e:<tab><tab># silently ignore exceptions raised here ..<tab><tab>if self.factory.debug:<tab><tab><tab>self.log.info(<tab><tab><tab><tab>""WampRawSocketProtocol: ApplicationSession.onClose raised ({0})"".format(<tab><tab><tab><tab><tab>e<tab><tab><tab><tab>)<tab><tab><tab>)<tab>self._session = None",1,if self . factory . debug :,if self . factory . debug :,0.75,100,1
"def parse(filename):<tab>dead_links = []<tab>with open(filename, ""r"") as file_:<tab><tab>for line in file_.readlines():<tab><tab><tab>res = reference_line.search(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not exists(res.group(1)):<tab><tab><tab><tab><tab>dead_links.append(res.group(1))<tab>return dead_links",1,if res :,if res :,0.531170663,1.00E-10,1
"def is_speaker_at_session(self, session_id):<tab>try:<tab><tab>session = (<tab><tab><tab>Session.query.filter(Session.speakers.any(Speaker.user_id == self.id))<tab><tab><tab>.filter(Session.id == session_id)<tab><tab><tab>.one()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except MultipleResultsFound:<tab><tab>return False<tab>except NoResultFound:<tab><tab>return False",1,if session :,if session :,0.531170663,1.00E-10,1
"def _validate_deployment_name(namespace):<tab># If missing,try come out with a name associated with the template name<tab>if namespace.deployment_name is None:<tab><tab>template_filename = None<tab><tab><IF-STMT><tab><tab><tab>template_filename = namespace.template_file<tab><tab>if namespace.template_uri and urlparse(namespace.template_uri).scheme:<tab><tab><tab>template_filename = urlsplit(namespace.template_uri).path<tab><tab>if template_filename:<tab><tab><tab>template_filename = os.path.basename(template_filename)<tab><tab><tab>namespace.deployment_name = os.path.splitext(template_filename)[0]<tab><tab>else:<tab><tab><tab>namespace.deployment_name = ""deployment1""",0,if namespace . template_file and os . path . isfile ( namespace . template_file ) :,if namespace . template_file :,0.08892176,13.12791047,0.34989648
"def mro(cls):<tab>if self.ready:<tab><tab>if cls.__name__ == ""B1"":<tab><tab><tab>B2.__bases__ = (B1,)<tab><tab><IF-STMT><tab><tab><tab>B1.__bases__ = (B2,)<tab>return type.mro(cls)",0,"if cls . __name__ == ""B2"" :","elif cls . __name__ == ""B2"" :",0.382940898,91.93227152,0.5
"def mark_shard_complete():<tab>try:<tab><tab>marker.refresh_from_db()<tab>except DeferIterationMarker.DoesNotExist:<tab><tab>logger.warning(<tab><tab><tab>""TaskMarker with ID: %s has vanished, cancelling task"", marker_id<tab><tab>)<tab><tab>return<tab>marker.shards_complete += 1<tab>marker.save()<tab>if marker.shards_complete == marker.shard_count:<tab><tab># Delete the marker if we were asked to<tab><tab><IF-STMT><tab><tab><tab>marker.delete()<tab><tab>defer(finalize, *args, _transactional=True, _queue=task_queue_name(), **kwargs)",0,if marker . delete_on_completion :,if not marker . exists ( ) :,0.052144951,11.59119923,0.36
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_public_certificate_list().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_max_client_cache_time_in_second(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 16 :,if tt == 16 :,0.75,100,1
"def check_free(self, payload):<tab># free_list: 'host=10.0.0.1', 'user=anonymous', 'host=10.0.0.7,user=test', ...<tab>for m in self.free_list:<tab><tab>args = m.split("","", 1)<tab><tab>for arg in args:<tab><tab><tab>k, v = arg.split(""="", 1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>return True<tab>return False",0,if payload [ k ] != v :,"if k == ""user"" and v == ""test"" :",0.019030986,3.929719341,0.5
"def getInnerText(element):<tab># To mimic IE's 'innerText' property in the W3C DOM, we need to recursively<tab># concatenate all child text nodes (depth first).<tab>text = """"<tab>child = element.firstChild<tab>while child:<tab><tab><IF-STMT><tab><tab><tab>text += getInnerText(child)<tab><tab>elif child.nodeValue:<tab><tab><tab>text += child.nodeValue<tab><tab>child = child.nextSibling<tab>return text",0,if child . nodeType == 1 :,if child . nodeType == ELEMENT_NODE :,0.386613272,53.72849659,0.771428571
"def get_complete_http(self):<tab>finished = []<tab>c = self.connection.cursor()<tab>rows = c.execute(""SELECT * FROM http WHERE complete=1"").fetchall()<tab>for row in rows:<tab><tab>o = pickle.loads(row[""object""])<tab><tab>uadat = c.execute(""SELECT * FROM ua WHERE parent_id=?"", (o.id,)).fetchall()<tab><tab>for ua in uadat:<tab><tab><tab>uao = pickle.loads(ua[""object""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>o.add_ua_data(uao)<tab><tab>finished.append(o)<tab>c.close()<tab>return finished",0,if uao is not None and uao . source_code is not None and o . source_code :,if uao :,0.025181765,1.00E-10,0.270833333
"def get_tools(self, found_files):<tab>self.configured_by = {}<tab>runners = []<tab>for tool_name in self.tools_to_run:<tab><tab>tool = tools.TOOLS[tool_name]()<tab><tab>config_result = tool.configure(self, found_files)<tab><tab>if config_result is None:<tab><tab><tab>configured_by = None<tab><tab><tab>messages = []<tab><tab>else:<tab><tab><tab>configured_by, messages = config_result<tab><tab><tab><IF-STMT><tab><tab><tab><tab>messages = []<tab><tab>self.configured_by[tool_name] = configured_by<tab><tab>self.messages += messages<tab><tab>runners.append(tool)<tab>return runners",0,if messages is None :,if not messages :,0.039449619,16.37226967,0.277777778
"def _yield_batches(self, keys):<tab>while self._shuffling_buffer.can_retrieve():<tab><tab>post_shuffled_row = self._shuffling_buffer.retrieve()<tab><tab>if not isinstance(post_shuffled_row, dict):<tab><tab><tab># This is for the case of batched reads. Here we restore back the<tab><tab><tab># dictionary format of records<tab><tab><tab>post_shuffled_row = dict(zip(keys, post_shuffled_row))<tab><tab>self._batch_acc.append(post_shuffled_row)<tab><tab># Batch is ready? Collate and emmit<tab><tab><IF-STMT><tab><tab><tab>yield self.collate_fn(self._batch_acc)<tab><tab><tab>self._batch_acc = []",0,if len ( self . _batch_acc ) == self . batch_size :,if self . collate_fn is not None :,0.064110238,4.741620422,0.276190476
"def action_open_file_filtered_dialog(self, widget):<tab>try:<tab><tab>fname = self.main_window.open_file_dialog(<tab><tab><tab>title=""Open file with Toga"",<tab><tab><tab>multiselect=False,<tab><tab><tab>file_types=[""doc"", ""txt""],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.label.text = ""File to open:"" + fname<tab><tab>else:<tab><tab><tab>self.label.text = ""No file selected!""<tab>except ValueError:<tab><tab>self.label.text = ""Open file dialog was canceled""",1,if fname is not None :,if fname is not None :,0.75,100,1
"def validate_vars(env):<tab>""""""Validate the PCH and PCHSTOP construction variables.""""""<tab>if ""PCH"" in env and env[""PCH""]:<tab><tab><IF-STMT><tab><tab><tab>raise SCons.Errors.UserError(<tab><tab><tab><tab>""The PCHSTOP construction must be defined if PCH is defined.""<tab><tab><tab>)<tab><tab>if not SCons.Util.is_String(env[""PCHSTOP""]):<tab><tab><tab>raise SCons.Errors.UserError(<tab><tab><tab><tab>""The PCHSTOP construction variable must be a string: %r""<tab><tab><tab><tab>% env[""PCHSTOP""]<tab><tab><tab>)",0,"if ""PCHSTOP"" not in env :","if not SCons . Util . is_defined ( env [ ""PCH"" ] ) :",0.020156904,3.361318394,0.421052632
"def page_func(page_num):<tab>playlist = self._call_api(<tab><tab>""product/playlist"",<tab><tab>show_id,<tab><tab>{<tab><tab><tab>""playListId"": playlist_id,<tab><tab><tab>""pageNumber"": page_num,<tab><tab><tab>""pageSize"": 30,<tab><tab><tab>""sorts"": [{""order"": ""DESC"", ""type"": ""SORTDATE""}],<tab><tab>},<tab>)<tab>for product in playlist.get(""productList"", {}).get(""products"", []):<tab><tab>product_url = product.get(""productUrl"", []).get(""url"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield self.url_result(<tab><tab><tab>product_url, ""Shahid"", str_or_none(product.get(""id"")), product.get(""title"")<tab><tab>)",0,if not product_url :,if product_url is None :,0.045150551,27.77619034,0.36
"def forward(self, x):<tab>for rproj, conv in zip(self.residual_proj, self.conv_layers):<tab><tab>residual = x<tab><tab>x = conv(x)<tab><tab>if self.skip_connections:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>residual = rproj(residual)<tab><tab><tab>x = (x + residual) * self.residual_scale<tab>return x",1,if rproj is not None :,if rproj is not None :,0.75,100,1
"def _make_results_dir(self):<tab>r""""""Makes directory for saving eqa-cnn-pretrain eval results.""""""<tab>for s_type in [""rgb"", ""seg"", ""depth""]:<tab><tab>dir_name = self.config.RESULTS_DIR.format(split=""val"", type=s_type)<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(dir_name)",0,if not os . path . isdir ( dir_name ) :,if not os . path . exists ( dir_name ) :,0.602001933,76.11606003,0.714285714
"def ignore_callback_errors(self, ignore):<tab>EventEmitter.ignore_callback_errors.fset(self, ignore)<tab>for emitter in self._emitters.values():<tab><tab>if isinstance(emitter, EventEmitter):<tab><tab><tab>emitter.ignore_callback_errors = ignore<tab><tab><IF-STMT><tab><tab><tab>emitter.ignore_callback_errors_all(ignore)",0,"elif isinstance ( emitter , EmitterGroup ) :","elif isinstance ( emitter , CallbackError ) :",0.547301779,59.46035575,0.666666667
"def cron_starter(*args: Any) -> None:<tab>_tz = self.conf.timezone if timezone is None else timezone<tab>while not self.should_stop:<tab><tab>await self.sleep(cron.secs_for_next(cron_format, _tz))<tab><tab><IF-STMT><tab><tab><tab>should_run = not on_leader or self.is_leader()<tab><tab><tab>if should_run:<tab><tab><tab><tab>with self.trace(shortlabel(fun), trace_enabled=traced):<tab><tab><tab><tab><tab>await fun(*args)",0,if not self . should_stop :,if not on_leader or not on_leader :,0.045308626,8.913765521,0.504761905
def rotateafter(self):<tab>if self.i != self.previ:<tab><tab>i = self.parent.l.GetSelection()<tab><tab><IF-STMT><tab><tab><tab>self.parent.models[self.parent.l.GetString(i)].rot -= 5 * (<tab><tab><tab><tab>self.i - self.previ<tab><tab><tab>)<tab><tab>self.previ = self.i<tab><tab>self.Refresh(),0,if i != wx . NOT_FOUND :,if i != self . i :,0.344478934,29.79714705,0.504761905
"def select(model, path, iter_, paths_):<tab>(paths, first) = paths_<tab>value = model.get_value(iter_)<tab>if value is None:<tab><tab>return not bool(paths)<tab>value = normalize_path(value)<tab>if value in paths:<tab><tab>self.get_child().get_selection().select_path(path)<tab><tab>paths.remove(value)<tab><tab>if not first:<tab><tab><tab>self.get_child().set_cursor(path)<tab><tab><tab># copy treepath, gets invalid after the callback<tab><tab><tab>first.append(path.copy())<tab>else:<tab><tab>for fpath in paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.get_child().expand_row(path, False)<tab>return not bool(paths)",0,if fpath . startswith ( value ) :,if fpath != path :,0.035401841,12.87263231,0.481481481
"def read_logs_file(logs_path) -> List[V1Log]:<tab>if not os.path.exists(logs_path):<tab><tab>return []<tab>async with aiofiles.open(logs_path, mode=""r"") as f:<tab><tab>contents = await f.read()<tab><tab>if contents:<tab><tab><tab># Version handling<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return V1Logs.read_csv(contents).logs<tab><tab><tab># Legacy logs<tab><tab><tab>logs = V1Logs.read(contents)<tab><tab><tab>return logs.logs<tab>return []",0,"if "".plx"" in logs_path :",if V1Logs . is_csv ( contents ) :,0.026407399,5.93420261,0.381818182
"def adjust_sockets(self):<tab>variables = self.get_variables()<tab>for key in self.inputs.keys():<tab><tab><IF-STMT><tab><tab><tab>self.debug(<tab><tab><tab><tab>""Input {} not in variables {}, remove it"".format(key, str(variables))<tab><tab><tab>)<tab><tab><tab>self.inputs.remove(self.inputs[key])<tab>for v in variables:<tab><tab>if v not in self.inputs:<tab><tab><tab>self.debug(<tab><tab><tab><tab>""Variable {} not in inputs {}, add it"".format(<tab><tab><tab><tab><tab>v, str(self.inputs.keys())<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>self.inputs.new(""SvStringsSocket"", v)",0,"if key not in variables and key not in [ ""Field"" ] :",if key not in variables :,0.30139987,17.74488851,0.666666667
"def run(self):<tab>while self.running:<tab><tab>cmd = self.cmds.get()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif cmd == ""clear"":<tab><tab><tab>dead_tasks = []<tab><tab><tab>for task in self.tasks:<tab><tab><tab><tab>if task.status == Task.FINISH or task.status == Task.ERROR:<tab><tab><tab><tab><tab>dead_tasks.append(task)<tab><tab><tab>for dead_task in dead_tasks:<tab><tab><tab><tab>self.tasks.remove(dead_task)",1,"if cmd == ""stop"" :","if cmd == ""stop"" :",0.75,100,1
"def process(self, node):<tab>self.vars = []<tab>for child in node.childNodes:<tab><tab>if child.nodeType == node.ELEMENT_NODE:<tab><tab><tab>child_text = get_xml_text(child)<tab><tab><tab>if child_text == """":  # pragma:nocover<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for val in re.split(""[\t ]+"", child_text):<tab><tab><tab><tab><tab>self.vars.append(1.0 * eval(val))<tab>return self",0,"if child . nodeName == ""Real"" :","elif child_text . startswith ( ""["" ) :",0.01702901,5.063996507,0.151515152
"def drain(self, fd):<tab>""""""Make `fd` unreadable.""""""<tab>while True:<tab><tab>try:<tab><tab><tab>if not os.read(fd, 4096):<tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>raise",0,if e . args [ 0 ] == errno . EAGAIN :,if e . errno == errno . EINTR :,0.175541583,29.10042507,0.365384615
"def parse(s):<tab>""""""Parse the output below to create a new StopWatch.""""""<tab>stopwatch = StopWatch()<tab>for line in s.splitlines():<tab><tab><IF-STMT><tab><tab><tab>parts = line.split(None)<tab><tab><tab>name = parts[0]<tab><tab><tab>if name != ""%"":  # ie not the header line<tab><tab><tab><tab>rest = (float(v) for v in parts[2:])<tab><tab><tab><tab>stopwatch.times[parts[0]].merge(Stat.build(*rest))<tab>return stopwatch",0,if line . strip ( ) :,if line :,0.038857533,1.00E-10,0.722222222
"def delete(identifier, filenames=None, **kwargs):<tab>item = get_item(identifier)<tab>if filenames:<tab><tab><IF-STMT><tab><tab><tab>filenames = [filenames]<tab><tab>for f in item.iter_files():<tab><tab><tab>if f.name not in filenames:<tab><tab><tab><tab>continue<tab><tab><tab>f.delete(**kwargs)",0,"if not isinstance ( filenames , ( set , list ) ) :","if not isinstance ( filenames , list ) :",0.252287517,49.56678178,0.704761905
"def _get_absolute_timeout(self, timeout):<tab>if timeout is Timeout.DEFAULT_TIMEOUT:<tab><tab>return 5  # 5s is the default timeout for URLFetch.<tab>if isinstance(timeout, Timeout):<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""URLFetch does not support granular timeout settings, ""<tab><tab><tab><tab>""reverting to total timeout."",<tab><tab><tab><tab>AppEnginePlatformWarning,<tab><tab><tab>)<tab><tab>return timeout.total<tab>return timeout",0,if timeout . read is not timeout . connect :,if timeout . total is not None :,0.237791031,21.06976474,0.502645503
"def _add_annotation_to_imports(<tab>self, annotation: cst.Attribute) -> Union[cst.Name, cst.Attribute]:<tab>key = get_full_name_for_node(annotation.value)<tab>if key is not None:<tab><tab># Don't attempt to re-import existing imports.<tab><tab>if key in self.existing_imports:<tab><tab><tab>return annotation<tab><tab>import_name = get_full_name_for_node(annotation.attr)<tab><tab><IF-STMT><tab><tab><tab>AddImportsVisitor.add_needed_import(self.context, key, import_name)<tab>return annotation.attr",1,if import_name is not None :,if import_name is not None :,0.75,100,1
"def unique_definitions(cls, defns):<tab>""""""Takes a collection of defns and returns the unique list of defns.""""""<tab>unique_defns = []<tab>for defn in defns:<tab><tab>for unique_defn in unique_defns:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># defn is already in the unique_defn list.<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>unique_defns.append(defn)<tab>return unique_defns",0,if unique_defn . path == defn . path and unique_defn == defn :,if defn in defn :,0.017683241,1.544979212,0.3125
"def store_data(self, store_loc, **kwargs):<tab>""""""Put arrays to store""""""<tab># print(store_loc)<tab>g = self.store.create_group(store_loc)<tab>for (<tab><tab>k,<tab><tab>v,<tab>) in kwargs.items():<tab><tab># print(type(v[0]))<tab><tab># print(k)<tab><tab><IF-STMT><tab><tab><tab>if len(v) != 0:<tab><tab><tab><tab>if type(v[0]) is np.str_ or type(v[0]) is str:<tab><tab><tab><tab><tab>v = [a.encode(""utf8"") for a in v]<tab><tab>g.create_dataset(k, data=v, compression=self.clib, compression_opts=self.clev)",0,if type ( v ) == list :,"if k != ""data"" :",0.018586852,6.413885306,0.3
"def connect_to_uri(self, uri, autoconnect=None, do_start=True):<tab>try:<tab><tab>conn = self._check_conn(uri)<tab><tab>if not conn:<tab><tab><tab># Unknown connection, add it<tab><tab><tab>conn = self.add_conn(uri)<tab><tab><IF-STMT><tab><tab><tab>conn.set_autoconnect(bool(autoconnect))<tab><tab>self.show_manager()<tab><tab>if do_start:<tab><tab><tab>conn.open()<tab><tab>return conn<tab>except Exception:<tab><tab>logging.exception(""Error connecting to %s"", uri)<tab><tab>return None",0,if autoconnect is not None :,if autoconnect :,0.050438393,1.00E-10,0.4
"def fn(n):<tab>while n < 3:<tab><tab>if n < 0:<tab><tab><tab>yield ""less than zero""<tab><tab><IF-STMT><tab><tab><tab>yield ""zero""<tab><tab>elif n == 1:<tab><tab><tab>yield ""one""<tab><tab>else:<tab><tab><tab>yield ""more than one""<tab><tab>n += 1",1,elif n == 0 :,elif n == 0 :,1,100,1
"def closeEvent(self, e):<tab>self.common.log(""MainWindow"", ""closeEvent"")<tab>if self.tabs.are_tabs_active():<tab><tab># Open the warning dialog<tab><tab>self.common.log(""MainWindow"", ""closeEvent, opening warning dialog"")<tab><tab>self.close_dialog.exec_()<tab><tab># Close<tab><tab><IF-STMT><tab><tab><tab>self.system_tray.hide()<tab><tab><tab>e.accept()<tab><tab># Cancel<tab><tab>else:<tab><tab><tab>e.ignore()<tab><tab>return<tab>self.system_tray.hide()<tab>e.accept()",0,if self . close_dialog . clickedButton ( ) == self . close_dialog . accept_button :,if self . close_dialog . is_visible ( ) :,0.251567776,27.3895848,0.645833333
"def _stop_child_activities(self, name=None):<tab>""""""Stop all child activities spawn by this activity.""""""<tab># Makes a list copy of items() to avoid dictionary size changed<tab># during iteration<tab>for child_name, child in list(self._child_activity_map.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>LOG.debug(""%s: Stopping child activity %s "", self.name, child_name)<tab><tab>if child.started:<tab><tab><tab>child.stop()<tab><tab>self._child_activity_map.pop(child_name, None)",0,if name is not None and name != child_name :,if name is not None and child . name == name :,0.440881846,46.35023864,0.76875
"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab>if not dir:<tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab>if os.path.isdir(dir):<tab><tab><tab>if not dir in self.library_dirs:<tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab><IF-STMT><tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",1,elif fatal :,elif fatal :,0.514316131,1.00E-10,1
"def _serialize_list(array, previous):<tab>array = array or []<tab>previous = previous or []<tab>params = {}<tab>for i, v in enumerate(array):<tab><tab>previous_item = previous[i] if len(previous) > i else None<tab><tab><IF-STMT><tab><tab><tab>params[str(i)] = v.serialize(previous_item)<tab><tab>else:<tab><tab><tab>params[str(i)] = _compute_diff(v, previous_item)<tab>return params",1,"if hasattr ( v , ""serialize"" ) :","if hasattr ( v , ""serialize"" ) :",0.75,100,1
"def list_bucket(self, prefix="""", delimiter="""", headers=None, all_versions=False):<tab>self._check_bucket_uri(""list_bucket"")<tab>bucket = self.get_bucket(headers=headers)<tab>if all_versions:<tab><tab>return (<tab><tab><tab>v<tab><tab><tab>for v in bucket.list_versions(<tab><tab><tab><tab>prefix=prefix, delimiter=delimiter, headers=headers<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab>)<tab>else:<tab><tab>return bucket.list(prefix=prefix, delimiter=delimiter, headers=headers)",0,"if not isinstance ( v , DeleteMarker )",if v,0.012033749,1.00E-10,0.277777778
"def writeattr(stream, text):<tab>countdouble = text.count('""')<tab>if countdouble:<tab><tab>countsingle = text.count(""'"")<tab><tab><IF-STMT><tab><tab><tab>entities = {'""': ""&quot;""}<tab><tab><tab>quote = '""'<tab><tab>else:<tab><tab><tab>entities = {""'"": ""&apos;""}<tab><tab><tab>quote = ""'""<tab>else:<tab><tab>entities = {}<tab><tab>quote = '""'<tab>stream.write(quote)<tab>writetext(stream, text, entities)<tab>stream.write(quote)",0,if countdouble <= countsingle :,if countsingle > 1 :,0.036540249,11.51015342,0.4
"def __gt__(self, other):<tab>if not isinstance(other, self.__class__):<tab><tab>other = self.__class__(other)<tab>for part, value in self.parts:<tab><tab>other_value = other[part]<tab><tab>if part in LETTERS:<tab><tab><tab>cmp = self._cmp_part(value or ""z"", other_value or ""z"")<tab><tab>else:<tab><tab><tab>cmp = self._cmp_part(value, other_value)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>return cmp == 1<tab>return False",0,if cmp == 0 :,if cmp is None :,0.064978772,19.35769349,0.444444444
"def _concretize(self, n_cls, t1, t2, join_or_meet, translate):<tab>ptr_class = self._pointer_class()<tab>if n_cls is ptr_class:<tab><tab>if isinstance(t1, ptr_class) and isinstance(t2, ptr_class):<tab><tab><tab># we need to merge them<tab><tab><tab>return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate))<tab><tab><IF-STMT><tab><tab><tab>return t1<tab><tab>elif isinstance(t2, ptr_class):<tab><tab><tab>return t2<tab><tab>else:<tab><tab><tab># huh?<tab><tab><tab>return ptr_class(BottomType())<tab>return n_cls()",0,"if isinstance ( t1 , ptr_class ) :","elif isinstance ( t1 , ptr_class ) :",0.400183025,88.01117368,0.6
"def __init__(self, items=None):<tab>super().__init__()<tab>self.include_dirs = []<tab>self._add_member(""src_files"", FileList, ""C source files for VPI library"")<tab>self._add_member(""include_files"", FileList, ""C include files for VPI library"")<tab>self._add_member(<tab><tab>""libs"", StringList, ""External libraries linked with the VPI library""<tab>)<tab>if items:<tab><tab>self.load_dict(items)<tab><tab><IF-STMT><tab><tab><tab>self.include_dirs += unique_dirs(self.include_files)<tab><tab>self.export_files = self.src_files + self.include_files",0,if self . include_files :,if len ( self . include_files ) > 0 :,0.105205398,34.48444258,0.371428571
"def __init__(self, parent_element):<tab>if parent_element.items():<tab><tab>self.update(dict(parent_element.items()))<tab>for element in parent_element:<tab><tab>if len(element) > 0:<tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>aDict = ListParser(element)<tab><tab><tab>else:<tab><tab><tab><tab>aDict = DictParser(element)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>aDict.update(dict(element.items()))<tab><tab><tab>self.update({element.tag: aDict})<tab><tab>elif element.items():<tab><tab><tab>self.update({element.tag: dict(element.items())})<tab><tab>else:<tab><tab><tab>self.update({element.tag: element.text})",1,if element . items ( ) :,if element . items ( ) :,0.75,100,1
"def _shares_in_results(data):<tab>shares_in_device, shares_in_subdevice = False, False<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab>if ""disk_shares"" in plugin_result[""device""]:<tab><tab><tab>shares_in_device = True<tab><tab>for subdevice in plugin_result[""device""].get(""subdevices"", []):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shares_in_subdevice = True<tab><tab><tab><tab>break<tab>return shares_in_device, shares_in_subdevice",1,"if ""disk_shares"" in subdevice :","if ""disk_shares"" in subdevice :",0.75,100,1
"def decorator(self, command, *args, **kwargs):<tab>if required_keys:<tab><tab>missing_keys = diff_keys(required_keys, command)<tab><tab><IF-STMT><tab><tab><tab>raise InvalidCommand(<tab><tab><tab><tab>""Command missing %s of required""<tab><tab><tab><tab>"" keys %s"" % (missing_keys, required_keys)<tab><tab><tab>)<tab>return func(self, command, *args, **kwargs)",1,if missing_keys :,if missing_keys :,0.531170663,1.00E-10,1
"def xml(self):<tab>out = [""<spreadsheet>""]<tab>for (x, y), cell in self.cells.items():<tab><tab><IF-STMT><tab><tab><tab>cellxml = cell.xml()<tab><tab>else:<tab><tab><tab>cellxml = ""<value>%s</value>"" % escape(cell)<tab><tab>out.append('<cell row=""%s"" col=""%s"">\n  %s\n</cell>' % (y, x, cellxml))<tab>out.append(""</spreadsheet>"")<tab>return ""\n"".join(out)",1,"if hasattr ( cell , ""xml"" ) :","if hasattr ( cell , ""xml"" ) :",0.75,100,1
"def speed_tester_d(self, uid):<tab>if uid not in self._speed_tester_d:<tab><tab><IF-STMT>  # TODO<tab><tab><tab>self._speed_tester_d[uid] = SpeedTester(<tab><tab><tab><tab>self._config.get(""speed_limit_per_user"", 0)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>self._speed_tester_d[uid] = SpeedTester(<tab><tab><tab><tab>self._config.get(""speed_limit_per_user"", 0)<tab><tab><tab>)<tab>return self._speed_tester_d[uid]",0,if self . mu :,if self . _speed_tester_d [ uid ] is None :,0.101403756,10.51184684,0.404761905
"def process_error(self, data):<tab>error = data.get(""error"")<tab>if error:<tab><tab><IF-STMT><tab><tab><tab>raise AuthCanceled(self)<tab><tab>else:<tab><tab><tab>raise AuthUnknownError(self, ""Jawbone error was {0}"".format(error))<tab>return super().process_error(data)",0,"if error == ""access_denied"" :","if data . get ( ""cancel"" ) :",0.026407399,5.93420261,0.381818182
"def _do_test_fetch_result(self, results, remote):<tab># self._print_fetchhead(remote.repo)<tab>self.assertGreater(len(results), 0)<tab>self.assertIsInstance(results[0], FetchInfo)<tab>for info in results:<tab><tab>self.assertIsInstance(info.note, string_types)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(info.flags)<tab><tab># END reference type flags handling<tab><tab>self.assertIsInstance(info.ref, (SymbolicReference, Reference))<tab><tab>if info.flags & (info.FORCED_UPDATE | info.FAST_FORWARD):<tab><tab><tab>self.assertIsInstance(info.old_commit, Commit)<tab><tab>else:<tab><tab><tab>self.assertIsNone(info.old_commit)",1,"if isinstance ( info . ref , Reference ) :","if isinstance ( info . ref , Reference ) :",0.75,100,1
"def init_ftp_server(self):<tab>if self.get_config(""ftpd"", ""enabled"", False, boolean=True):<tab><tab>accountfile = from_utf8_or_none(self.get_config(""ftpd"", ""accounts.file"", None))<tab><tab><IF-STMT><tab><tab><tab>accountfile = abspath_expanduser_unicode(accountfile, base=self.basedir)<tab><tab>accounturl = self.get_config(""ftpd"", ""accounts.url"", None)<tab><tab>ftp_portstr = self.get_config(""ftpd"", ""port"", ""8021"")<tab><tab>from allmydata.frontends import ftpd<tab><tab>s = ftpd.FTPServer(self, accountfile, accounturl, ftp_portstr)<tab><tab>s.setServiceParent(self)",1,if accountfile :,if accountfile :,0.531170663,1.00E-10,1
"def configured_request_log_handlers(config, prefix=""query_log"", default_logger=None):<tab>""""""Returns configured query loggers as defined in the `config`.""""""<tab>handlers = []<tab>for section in config.sections():<tab><tab>if section.startswith(prefix):<tab><tab><tab>options = dict(config.items(section))<tab><tab><tab>type_ = options.pop(""type"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger = default_logger or get_logger()<tab><tab><tab><tab>handler = ext.request_log_handler(""default"", logger)<tab><tab><tab>else:<tab><tab><tab><tab>handler = ext.request_log_handler(type_, **options)<tab><tab><tab>handlers.append(handler)<tab>return handlers",1,"if type_ == ""default"" :","if type_ == ""default"" :",0.75,100,1
"def string(self):<tab>""""""Returns a PlayString in string format from the Patterns values""""""<tab>string = """"<tab>for item in self.data:<tab><tab>if isinstance(item, (PGroup, GeneratorPattern)):<tab><tab><tab>string += item.string()<tab><tab><IF-STMT><tab><tab><tab>string += (<tab><tab><tab><tab>""(""<tab><tab><tab><tab>+ """".join(<tab><tab><tab><tab><tab>[<tab><tab><tab><tab><tab><tab>(s.string() if hasattr(s, ""string"") else str(s))<tab><tab><tab><tab><tab><tab>for s in item.data<tab><tab><tab><tab><tab>]<tab><tab><tab><tab>)<tab><tab><tab><tab>+ "")""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>string += str(item)<tab>return string",0,"elif isinstance ( item , Pattern ) :","elif isinstance ( item , PlayString ) :",0.547301779,59.46035575,0.666666667
"def locked_deps(package, poetry):<tab>reqs = []<tab>packages = poetry.locker.locked_repository(False).packages<tab>for p in packages:<tab><tab>dep = p.to_dependency()<tab><tab>line = ""{}=={}"".format(p.name, p.version)<tab><tab>requirement = dep.to_pep_508()<tab><tab><IF-STMT><tab><tab><tab>line += ""; {}"".format(requirement.split("";"")[1].strip())<tab><tab>reqs.append(line)<tab>return reqs, defaultdict(list)",0,"if "";"" in requirement :",if requirement :,0.067674239,1.00E-10,0.45
"def _paste_columns(self, topleft_corner, columns):<tab>starting_column = topleft_corner[1]<tab>number_of_columns = self.number_of_columns()<tab>for index, column in enumerate(columns):<tab><tab>set_index = starting_column + index<tab><tab><IF-STMT><tab><tab><tab>self.set_column_at(set_index, column, starting=topleft_corner[0])<tab><tab>else:<tab><tab><tab>real_column = [constants.DEFAULT_NA] * topleft_corner[0]<tab><tab><tab>real_column += column<tab><tab><tab>self.extend_columns([real_column])<tab>self.__width, self.__array = uniform(self.__array)",1,if set_index < number_of_columns :,if set_index < number_of_columns :,0.75,100,1
"def check_objects_exist(self, compare_id, raise_exc=True):<tab>for uid in convert_compare_id_to_list(compare_id):<tab><tab>if not self.existence_quick_check(uid):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise FactCompareException(""{} not found in database"".format(uid))<tab><tab><tab>return True<tab>return False",1,if raise_exc :,if raise_exc :,0.531170663,1.00E-10,1
"def __add__(self, other):<tab>if hasattr(other, ""unit_type""):<tab><tab><IF-STMT><tab><tab><tab>raise UnitError(""Adding different types of units is"" "" not allowed"")<tab><tab>if other.unit != self.unit:<tab><tab><tab>other = other.to(self.unit)<tab>return self.__class__(<tab><tab>np.array(self) + np.array(other), unit_type=self.unit_type, unit=self.unit<tab>)",1,if other . unit_type != self . unit_type :,if other . unit_type != self . unit_type :,1,100,1
"def extract(self, tar):<tab>max_nb = maxNbFile(self)<tab>for index, field in enumerate(tar.array(""file"")):<tab><tab><IF-STMT><tab><tab><tab>self.warning(<tab><tab><tab><tab>""TAR archive contains many files, but only first %s files are processed""<tab><tab><tab><tab>% max_nb<tab><tab><tab>)<tab><tab><tab>break<tab><tab>meta = Metadata(self)<tab><tab>self.extractFile(field, meta)<tab><tab>if meta.has(""filename""):<tab><tab><tab>title = _('File ""%s""') % meta.getText(""filename"")<tab><tab>else:<tab><tab><tab>title = _(""File"")<tab><tab>self.addGroup(field.name, meta, title)",0,if max_nb is not None and max_nb <= index :,if index >= max_nb :,0.015145995,10.59106218,0.238095238
"def task_management_menu(activation, request):<tab>""""""Available tasks actions.""""""<tab>actions = []<tab>if request.user.has_perm(activation.flow_class._meta.manage_permission_name):<tab><tab>for transition in activation.get_available_transitions():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>url = activation.flow_task.get_task_url(<tab><tab><tab><tab><tab>activation.task,<tab><tab><tab><tab><tab>transition.name,<tab><tab><tab><tab><tab>user=request.user,<tab><tab><tab><tab><tab>namespace=request.resolver_match.namespace,<tab><tab><tab><tab>)<tab><tab><tab><tab>if url:<tab><tab><tab><tab><tab>actions.append((transition.name.replace(""_"", "" "").title(), url))<tab>return {""actions"": actions, ""request"": request}",0,if transition . can_proceed ( activation ) :,if transition . name :,0.078889319,15.71901051,0.6
"def handle_default_mac_address(facts):<tab>for suffix in ("""", ""_eth0"", ""_igb0"", ""_bnx0"", ""_bge0"", ""_nfo0"", ""_nge0""):<tab><tab>mac = facts.get(""macaddress{}"".format(suffix))<tab><tab>if mac:<tab><tab><tab>try:<tab><tab><tab><tab>result = MACAddressField.normalize(mac)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>return result",0,if result [ : 6 ] in MAC_PREFIX_BLACKLIST :,if not result :,0.016468506,2.215745753,0.318181818
"def run(self):<tab>consumer = KafkaConsumer(<tab><tab>bootstrap_servers=""localhost:9092"", auto_offset_reset=""earliest""<tab>)<tab>consumer.subscribe([""my-topic""])<tab>self.valid = 0<tab>self.invalid = 0<tab>for message in consumer:<tab><tab><IF-STMT><tab><tab><tab>self.valid += 1<tab><tab>else:<tab><tab><tab>self.invalid += 1<tab><tab>if consumer_stop.is_set():<tab><tab><tab>break<tab>consumer.close()",0,if len ( message . value ) == msg_size :,"if message == ""my-topic"" :",0.015145995,7.43376166,0.371428571
"def createFields(self, fields):<tab>self.destroyFields()<tab>for name, label, args in fields:<tab><tab>kwargs = dict(validator=_TransferValidator(name))<tab><tab><IF-STMT><tab><tab><tab>kwargs.update(args)<tab><tab>stxt = wx.StaticText(self, -1, label)<tab><tab>txt = wx.TextCtrl(self, **kwargs)<tab><tab>self._contentSizer.Add(stxt, 0, wx.ALIGN_CENTER_VERTICAL | wx.ALIGN_RIGHT)<tab><tab>self._contentSizer.Add(txt, 0, wx.EXPAND)<tab><tab>self.__dict__[name] = """"<tab><tab>self._fields[name] = (stxt, txt)",1,if args :,if args :,0.531170663,1.00E-10,1
def poll_kafka(self):<tab>while True:<tab><tab>val = self.do_poll()<tab><tab>if val:<tab><tab><tab>yield self._emit(val)<tab><tab>else:<tab><tab><tab>yield gen.sleep(self.poll_interval)<tab><tab><IF-STMT><tab><tab><tab>break<tab>self._close_consumer(),0,if self . stopped :,if self . _closed :,0.394778655,32.46679155,0.7
"def _generate_toc(line):<tab>while 1:<tab><tab>if line.startswith(""2""):<tab><tab><tab>line = 5<tab><tab><tab>while 1:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>line = 6<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>elif not line:<tab><tab><tab><tab><tab>line = 7<tab><tab><tab><tab><tab>break<tab><tab>elif not line:<tab><tab><tab>break<tab>return 1",0,if line :,"if line . startswith ( ""3"" ) :",0.082730182,1.00E-10,0.727272727
"def find_script(scriptId_or_file_or_url):<tab># sha = hashlib.sha1(scriptId_or_file_or_url.encode('utf-8')).hexdigest()<tab>for item in file_to_scriptId:<tab><tab>if item[""scriptId""].lower() == scriptId_or_file_or_url.lower():<tab><tab><tab>return item[""file""]<tab><tab><IF-STMT><tab><tab><tab>return item[""scriptId""]<tab><tab>if item[""url""].lower() == scriptId_or_file_or_url.lower():<tab><tab><tab>return item[""scriptId""]<tab>return None",0,"if item [ ""file"" ] . lower ( ) == scriptId_or_file_or_url . lower ( ) :","if item [ ""url"" ] . lower ( ) == scriptId_or_file_or_url . lower ( ) :",0.908353643,89.85396083,1
"def __get_impute_number(some_data):<tab>impute_num_list = None<tab>data_size = None<tab>for line in some_data:<tab><tab>processed_data = line[1][0]<tab><tab>index_list = line[1][1]<tab><tab><IF-STMT><tab><tab><tab>data_size = len(processed_data)<tab><tab><tab># data_size + 1, the last element of impute_num_list used to count the number of ""some_data""<tab><tab><tab>impute_num_list = [0 for _ in range(data_size + 1)]<tab><tab>impute_num_list[data_size] += 1<tab><tab>for index in index_list:<tab><tab><tab>impute_num_list[index] += 1<tab>return np.array(impute_num_list)",0,if not data_size :,if data_size is None :,0.045150551,27.77619034,0.36
"def get_shipping_address(self):<tab>""""""Returns Address object from shipping address fields if present""""""<tab># shipping address fields can be `shipping_address_name` or `shipping_address`<tab># try getting value from both<tab>for fieldname in (""shipping_address_name"", ""shipping_address""):<tab><tab>shipping_field = self.meta.get_field(fieldname)<tab><tab>if shipping_field and shipping_field.fieldtype == ""Link"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return frappe.get_doc(""Address"", self.get(fieldname))<tab>return {}",1,if self . get ( fieldname ) :,if self . get ( fieldname ) :,0.75,100,1
"def _get_spawn_property(self, constraints, constraint_name, services):<tab>if services:<tab><tab># this isn't very nice<tab><tab><IF-STMT><tab><tab><tab>return services[0].image<tab><tab>elif constraint_name == CPUS_CONSTRAINT:<tab><tab><tab>return services[0].cpus<tab>for constraint in constraints:<tab><tab>if constraint.name == constraint_name:<tab><tab><tab>return constraint.value<tab>return None",1,if constraint_name == IMAGE_CONSTRAINT :,if constraint_name == IMAGE_CONSTRAINT :,0.75,100,1
"def latest_extra_data(self, extra_dirs=None):<tab>base_name = os.path.splitext(os.path.basename(self.file_name))[0]<tab>extra_dirs.append(self.board.GetPlotOptions().GetOutputDirectory())<tab>file_dir_name = os.path.dirname(self.file_name)<tab>directories = [<tab><tab>file_dir_name,<tab>]<tab>for dir in extra_dirs:<tab><tab>if not os.path.isabs(dir):<tab><tab><tab>dir = os.path.join(file_dir_name, dir)<tab><tab><IF-STMT><tab><tab><tab>directories.append(dir)<tab>return find_latest_schematic_data(base_name, directories)",0,if os . path . exists ( dir ) :,if os . path . isdir ( dir ) :,0.580308871,65.80370065,0.714285714
"def _checkForLeftRightModifiers(cls, mod_state):<tab>mod_value = 0<tab>mod_strs = []<tab>for k, v in cls._OS_MODIFIERS:<tab><tab><IF-STMT><tab><tab><tab>mod_value += KeyboardConstants._modifierCodes.getID(v)<tab><tab><tab>mod_strs.append(modifier_name_mappings.get(v, ""MISSING_MOD_NAME""))<tab>return mod_value, mod_strs",0,if mod_state & k > 0 :,"if modifier_name_mappings . get ( k , None ) is None :",0.017601189,3.458592114,0.257142857
"def _decode_pattern_list(data):<tab>rv = []<tab>contains_dict = False<tab>for item in data:<tab><tab><IF-STMT><tab><tab><tab>item = _decode_pattern_list(item)<tab><tab>elif isinstance(item, dict):<tab><tab><tab>item = _decode_pattern_dict(item)<tab><tab><tab>contains_dict = True<tab><tab>rv.append(item)<tab># avoid sorting if any element in the list is a dict<tab>if not contains_dict:<tab><tab>rv = sorted(rv)<tab>return rv",1,"if isinstance ( item , list ) :","if isinstance ( item , list ) :",0.75,100,1
"def get_blob(self, blobname, ctlr=None, specific_dir=None):<tab>self._acquire_lock()<tab>try:<tab><tab>dbsubpath = self._dbsubpath_from_blobname(<tab><tab><tab>blobname, ctlr=ctlr, specific_dir=specific_dir<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return self.lang_zone.load_blob(dbsubpath)<tab><tab>else:<tab><tab><tab>return None<tab>finally:<tab><tab>self._release_lock()",0,if dbsubpath is not None :,if dbsubpath :,0.050438393,1.00E-10,0.4
"def get_tasks(self):<tab>for task in asyncio.all_tasks(loop=self.middleware.loop):<tab><tab>formatted = None<tab><tab>frame = None<tab><tab>frames = []<tab><tab>for frame in task.get_stack():<tab><tab><tab>cur_frame = get_frame_details(frame, self.logger)<tab><tab><tab>if cur_frame:<tab><tab><tab><tab>frames.append(cur_frame)<tab><tab><IF-STMT><tab><tab><tab>formatted = traceback.format_stack(frame)<tab><tab>yield {<tab><tab><tab>""stack"": formatted,<tab><tab><tab>""frames"": frames,<tab><tab>}",0,if frame :,if formatted is None :,0.051944023,1.00E-10,0.25
"def main(args):<tab>optim = Adam({""lr"": args.lr})<tab>elbo = JitTrace_ELBO() if args.jit else Trace_ELBO()<tab>svi = SVI(model, guide, optim, loss=elbo)<tab>pyro.clear_param_store()<tab>for j in range(args.num_epochs):<tab><tab>loss = svi.step(data)<tab><tab><IF-STMT><tab><tab><tab>logging.info(""[epoch %04d] loss: %.4f"" % (j + 1, loss))<tab>for name, value in pyro.get_param_store().items():<tab><tab>logging.info(name)<tab><tab>logging.info(value.detach().cpu().numpy())",1,if j % 100 == 0 :,if j % 100 == 0 :,0.75,100,1
"def create_var_list(scope, var_lists, shape):<tab>vars = []<tab>for idx, v in enumerate(var_lists):<tab><tab>name = ""{}_{}"".format(scope, idx)<tab><tab><IF-STMT><tab><tab><tab>var = fluid.data(name, shape=v.shape)<tab><tab>else:<tab><tab><tab>var = fluid.data(name, shape=shape + list(v[0].shape))<tab><tab>var.stop_gradient = False<tab><tab>vars.append(var)<tab>return vars",0,if shape is None :,if v [ 0 ] . shape == shape :,0.025806627,4.932351569,0.272727273
"def dr_relation(self, C, trans, nullable):<tab>dr_set = {}<tab>state, N = trans<tab>terms = []<tab>g = self.lr0_goto(C[state], N)<tab>for p in g:<tab><tab>if p.lr_index < p.len - 1:<tab><tab><tab>a = p.prod[p.lr_index + 1]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if a not in terms:<tab><tab><tab><tab><tab>terms.append(a)<tab># This extra bit is to handle the start state<tab>if state == 0 and N == self.grammar.Productions[0].prod[0]:<tab><tab>terms.append(""$end"")<tab>return terms",0,if a in self . grammar . Terminals :,if a is not None :,0.030305353,10.896448,0.285714286
"def get_field_values(self, fields):<tab>field_values = []<tab>for field in fields:<tab><tab># Title is special case<tab><tab><IF-STMT><tab><tab><tab>value = self.get_title_display()<tab><tab>elif field == ""country"":<tab><tab><tab>try:<tab><tab><tab><tab>value = self.country.printable_name<tab><tab><tab>except exceptions.ObjectDoesNotExist:<tab><tab><tab><tab>value = """"<tab><tab>elif field == ""salutation"":<tab><tab><tab>value = self.salutation<tab><tab>else:<tab><tab><tab>value = getattr(self, field)<tab><tab>field_values.append(value)<tab>return field_values",1,"if field == ""title"" :","if field == ""title"" :",0.75,100,1
"def run(self, event, lambda_context):<tab>self.setup_exec_environment(event)<tab>resource_sets = self.get_resource_sets(event)<tab>result_sets = {}<tab>for (account_id, region), rarns in resource_sets.items():<tab><tab>self.assume_member({""account"": account_id, ""region"": region})<tab><tab>resources = self.resolve_resources(event)<tab><tab>rset = result_sets.setdefault((account_id, region), [])<tab><tab><IF-STMT><tab><tab><tab>rset.extend(self.run_resource_set(event, resources))<tab>return result_sets",0,if resources :,if rarns :,0.319750449,1.00E-10,0.5
"def read(self, sock):<tab>data = self.sock.recv(64 * 1024)<tab>ready_to_read, ready_to_write, in_error = select.select(<tab><tab>[self.sock], [], [], self.timeout<tab>)<tab>while len(ready_to_read) == 1:<tab><tab>more_data = self.sock.recv(64 * 1024)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>data = data + more_data<tab><tab>ready_to_read, ready_to_write, in_error = select.select(<tab><tab><tab>[self.sock], [], [], self.timeout<tab><tab>)<tab>return data",0,if len ( more_data ) == 0 :,if not more_data :,0.019930836,14.91951851,0.381818182
"def _check_ids(el, filename, parent_id):<tab>""""""Recursively walks through tree and check if every object has ID""""""<tab>for child in el:<tab><tab><IF-STMT><tab><tab><tab>msg = ""Widget has no ID in %s; class %s; Parent id: %s"" % (<tab><tab><tab><tab>filename,<tab><tab><tab><tab>child.attrib[""class""],<tab><tab><tab><tab>parent_id,<tab><tab><tab>)<tab><tab><tab>assert ""id"" in child.attrib and child.attrib[""id""], msg<tab><tab><tab>for subel in child:<tab><tab><tab><tab>if subel.tag == ""child"":<tab><tab><tab><tab><tab>_check_ids(subel, filename, child.attrib[""id""])",0,"if child . tag == ""object"" :","if ""id"" not in child . attrib :",0.039521502,11.04479557,0.25
"def get(self, request, *args, **kwargs):<tab>url = self.get_redirect_url(**kwargs)<tab>if url:<tab><tab><IF-STMT><tab><tab><tab>return http.HttpResponsePermanentRedirect(url)<tab><tab>else:<tab><tab><tab>return http.HttpResponseRedirect(url)<tab>else:<tab><tab>logger.warning(<tab><tab><tab>""Gone: %s"" % self.request.path,<tab><tab><tab>extra={""status_code"": 410, ""request"": self.request},<tab><tab>)<tab><tab>return http.HttpResponseGone()",0,if self . permanent :,if self . request . status_code == 302 :,0.105226223,13.54599427,0.484848485
"def test_representation(self):<tab># Test that the state space representation in the measurement error<tab># case is correct<tab>for name in self.model.ssm.shapes.keys():<tab><tab>if name == ""obs"":<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>actual = self.results2.filter_results.obs_cov<tab><tab><tab>desired = np.diag(self.true_measurement_error_variances)[:, :, np.newaxis]<tab><tab><tab>assert_equal(actual, desired)<tab><tab>else:<tab><tab><tab>assert_equal(<tab><tab><tab><tab>getattr(self.results2.filter_results, name),<tab><tab><tab><tab>getattr(self.results.filter_results, name),<tab><tab><tab>)",1,"elif name == ""obs_cov"" :","elif name == ""obs_cov"" :",1,100,1
"def process_formdata(self, valuelist):<tab>if valuelist:<tab><tab>date_str = "" "".join(valuelist)<tab><tab><IF-STMT><tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Please input a date/time value""))<tab><tab>parse_kwargs = self.parse_kwargs.copy()<tab><tab>if ""default"" not in parse_kwargs:<tab><tab><tab>try:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default()<tab><tab><tab>except TypeError:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default<tab><tab>try:<tab><tab><tab>self.data = parser.parse(date_str, **parse_kwargs)<tab><tab>except ValueError:<tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Invalid date/time input""))",1,if not date_str :,if not date_str :,0.75,100,1
"def get_bounding_box(self):<tab>for key in self.h5f[""Data_Products""].keys():<tab><tab><IF-STMT><tab><tab><tab>lats = self.h5f[""Data_Products""][key][key + ""_Gran_0""].attrs[<tab><tab><tab><tab>""G-Ring_Latitude""<tab><tab><tab>]<tab><tab><tab>lons = self.h5f[""Data_Products""][key][key + ""_Gran_0""].attrs[<tab><tab><tab><tab>""G-Ring_Longitude""<tab><tab><tab>]<tab><tab><tab>break<tab>else:<tab><tab>raise KeyError(""Cannot find bounding coordinates!"")<tab>return lons.ravel(), lats.ravel()",0,"if key . startswith ( ""VIIRS"" ) and key . endswith ( ""GEO"" ) :","if key in self . h5f [ ""Data_Products"" ] [ key ] :",0.018450007,5.561750405,0.277777778
"def _get_doc_contents(self, attr_name):<tab>value = getattr(self, attr_name)<tab>if isinstance(value, BasicCommand.FROM_FILE):<tab><tab><IF-STMT><tab><tab><tab>trailing_path = value.filename<tab><tab>else:<tab><tab><tab>trailing_path = os.path.join(self.name, attr_name + "".rst"")<tab><tab>root_module = value.root_module<tab><tab>doc_path = os.path.join(<tab><tab><tab>os.path.abspath(os.path.dirname(root_module.__file__)),<tab><tab><tab>""examples"",<tab><tab><tab>trailing_path,<tab><tab>)<tab><tab>with _open(doc_path) as f:<tab><tab><tab>return f.read()<tab>else:<tab><tab>return value",0,if value . filename is not None :,if value . filename :,0.234334509,38.80684295,0.510204082
"def __truediv__(self, val):<tab>if isinstance(val, Vector3):<tab><tab>if val.x == 0 or val.y == 0 or val.z == 0:<tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_vector(self._gd_ptr, val._gd_ptr)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ZeroDivisionError()<tab><tab>gd_obj = lib.godot_vector3_operator_divide_scalar(self._gd_ptr, val)<tab>return Vector3.build_from_gdobj(gd_obj)",0,if val is 0 :,if val . y != 0 or val . z != 0 :,0.052860311,7.432998185,0.380952381
"def _get_all_plugin_configs(self):<tab>with opentracing.global_tracer().start_active_span(""_get_all_plugin_configs""):<tab><tab><IF-STMT><tab><tab><tab>self._plugin_configs = {<tab><tab><tab><tab>pc.identifier: pc for pc in PluginConfiguration.objects.all()<tab><tab><tab>}<tab><tab>return self._plugin_configs",0,"if not hasattr ( self , ""_plugin_configs"" ) :",if self . _plugin_configs is None :,0.017062029,20.25288495,0.285714286
"def msg(self, module, level, msg, *args, **kwargs):<tab>if self.level < level or level > len(LEVELS):<tab><tab>return<tab>msg = str(msg).format(*args, **kwargs)<tab>with self.lock:<tab><tab>self.output.write(FORMAT.format(module=module, level=LEVELS[level], msg=msg))<tab><tab><IF-STMT><tab><tab><tab>self.output.flush()",0,"if hasattr ( self . output , ""flush"" ) :",if self . output :,0.059382557,11.14127554,0.384615385
"def opentemplatefile(self, options, fulltemplatepath):<tab>""""""Opens the template file (if required).""""""<tab>if fulltemplatepath is not None:<tab><tab><IF-STMT><tab><tab><tab>return open(fulltemplatepath, ""r"")<tab><tab>else:<tab><tab><tab>self.warning(""missing template file %s"" % fulltemplatepath)<tab>return None",1,if os . path . isfile ( fulltemplatepath ) :,if os . path . isfile ( fulltemplatepath ) :,0.75,100,1
"def b58(args, parser):<tab>for arg in args.input:<tab><tab>blob, is_hex_input = parse_arg(arg, args.b)<tab><tab><IF-STMT><tab><tab><tab>print(b2h(blob))<tab><tab><tab>print(b2a_base58(blob))<tab><tab><tab>print(b2a_hashed_base58(blob))<tab><tab>else:<tab><tab><tab>print(b2h(blob))<tab><tab><tab>print(b2a_base58(blob))<tab><tab><tab>try:<tab><tab><tab><tab>blob = a2b_hashed_base58(arg)<tab><tab><tab><tab>print(""valid hashed b58"")<tab><tab><tab><tab>print(""contents: "", b2h(blob))<tab><tab><tab>except Exception:<tab><tab><tab><tab>print(""not hashed b58"")",1,if is_hex_input :,if is_hex_input :,0.531170663,1.00E-10,1
"def edit_file(self, filename):<tab>import subprocess<tab>editor = self.get_editor()<tab>if self.env:<tab><tab>environ = os.environ.copy()<tab><tab>environ.update(self.env)<tab>else:<tab><tab>environ = None<tab>try:<tab><tab>c = subprocess.Popen(<tab><tab><tab>""{} {}"".format(shlex_quote(editor), shlex_quote(filename)),<tab><tab><tab>env=environ,<tab><tab><tab>shell=True,<tab><tab>)<tab><tab>exit_code = c.wait()<tab><tab><IF-STMT><tab><tab><tab>raise ClickException(""{}: Editing failed!"".format(editor))<tab>except OSError as e:<tab><tab>raise ClickException(""{}: Editing failed: {}"".format(editor, e))",1,if exit_code != 0 :,if exit_code != 0 :,0.75,100,1
"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab>if n:<tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",0,"if ""!"" <= c and c <= ""u"" :",if ord ( c ) > 33 :,0.016959991,3.029704891,0.333333333
"def channel_to_netid(channel_name_or_id):<tab>try:<tab><tab>channel = int(channel_name_or_id)<tab>except ValueError:<tab><tab>netid = ""NETID_{}"".format(channel_name_or_id.upper())<tab><tab><IF-STMT><tab><tab><tab>channel = getattr(ics, netid)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""channel must be an integer or "" ""a valid ICS channel name""<tab><tab><tab>)<tab>return channel",1,"if hasattr ( ics , netid ) :","if hasattr ( ics , netid ) :",0.75,100,1
"def _find_this_and_next_frame(self, stack):<tab>for i in range(len(stack)):<tab><tab><IF-STMT><tab><tab><tab>if i == len(stack) - 1:  # last frame<tab><tab><tab><tab>return stack[i], None<tab><tab><tab>else:<tab><tab><tab><tab>return stack[i], stack[i + 1]<tab>raise AssertionError(""Frame doesn't exist anymore"")",0,if stack [ i ] . id == self . _frame_id :,if stack [ i ] is not None :,0.221390739,21.46152504,0.435897436
"def nested_update(org_dict, upd_dict):<tab>for key, value in upd_dict.items():<tab><tab>if isinstance(value, dict):<tab><tab><tab>if key in org_dict:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab><tab>""Mismatch between org_dict and upd_dict at node {}"".format(key)<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>nested_update(org_dict[key], value)<tab><tab><tab>else:<tab><tab><tab><tab>org_dict[key] = value<tab><tab>else:<tab><tab><tab>org_dict[key] = value",0,"if not isinstance ( org_dict [ key ] , dict ) :",if key not in org_dict :,0.012478273,12.00124573,0.276190476
"def __myreduce(self, elements):<tab>first = elements[0]<tab>for i in range(1, len(elements), 2):<tab><tab><IF-STMT><tab><tab><tab>first = first and elements[i + 1]<tab><tab>elif elements[i] == ""or"":<tab><tab><tab>first = first or elements[i + 1]<tab>self.stack = []<tab>if isinstance(first, list):<tab><tab>return [first]<tab>return first",1,"if elements [ i ] == ""and"" :","if elements [ i ] == ""and"" :",0.75,100,1
"def test_to_json_na(self):<tab># Set a value as nan and make sure it's written<tab>self.df.loc[self.df[""BoroName""] == ""Queens"", ""Shape_Area""] = np.nan<tab>text = self.df.to_json()<tab>data = json.loads(text)<tab>self.assertTrue(len(data[""features""]) == 5)<tab>for f in data[""features""]:<tab><tab>props = f[""properties""]<tab><tab>self.assertEqual(len(props), 4)<tab><tab><IF-STMT><tab><tab><tab>self.assertTrue(props[""Shape_Area""] is None)",0,"if props [ ""BoroName"" ] == ""Queens"" :","if ""Shape_Area"" in props :",0.019907918,4.571221768,0.477272727
"def process(self, resources):<tab>resources = self.filter_resources(resources, ""TableStatus"", self.valid_status)<tab>if not len(resources):<tab><tab>return<tab>futures = []<tab>client = local_session(self.manager.session_factory).client(""dynamodb"")<tab>with self.executor_factory(max_workers=2) as w:<tab><tab>for table_set in chunks(resources, 20):<tab><tab><tab>futures.append(w.submit(self.delete_table, client, table_set))<tab><tab>for f in as_completed(futures):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.error(<tab><tab><tab><tab><tab>""Exception deleting dynamodb table set \n %s"" % (f.exception())<tab><tab><tab><tab>)",1,if f . exception ( ) :,if f . exception ( ) :,0.75,100,1
"def skip_loss_scaling(self, backend_config=None):<tab>if self.loss_scaling is not False:<tab><tab><IF-STMT><tab><tab><tab>msg = ""loss_scaling is tested when dtype is float16.""<tab><tab><tab>return True, msg<tab><tab>if backend_config is not None and not backend_config.use_cuda:<tab><tab><tab>msg = ""loss_scaling is tested when use_cuda is True.""<tab><tab><tab>return True, msg<tab>return False, None",0,if self . dtype != numpy . float16 :,if backend_config is not None and not backend_config . dtype is float16 :,0.094813477,6.839596062,0.166666667
"def writeLibraryControllers(fp, human, meshes, skel, config, shapes=None):<tab>progress = Progress(len(meshes), None)<tab>fp.write(""\n  <library_controllers>\n"")<tab>for mIdx, mesh in enumerate(meshes):<tab><tab>subprog = Progress()(0, 0.5)<tab><tab>if skel:<tab><tab><tab>writeSkinController(fp, human, mesh, skel, config)<tab><tab>subprog(0.5, 1)<tab><tab><IF-STMT><tab><tab><tab>writeMorphController(fp, mesh, shapes[mIdx], config)<tab><tab>progress.step()<tab>fp.write(""  </library_controllers>\n"")",0,if shapes is not None :,if shapes :,0.050438393,1.00E-10,0.4
"def doit():<tab>recipes_path = expanduser(""recipes.pprint"")<tab>recipe_dicts = eval(open(recipes_path).read())<tab>for r in recipe_dicts:<tab><tab>for key in r.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del r[key]<tab><tab>for c in r[""comments""]:<tab><tab><tab>for key in c.keys():<tab><tab><tab><tab>if key not in (""comment"", ""title""):<tab><tab><tab><tab><tab>del c[key]<tab>f = open(""stripped.pprint"", ""w"")<tab>f.write(pformat(recipe_dicts))<tab>f.close()",0,"if key not in ( ""desc"" , ""comments"" ) :","if key not in ( ""comment"" , ""title"" ) :",0.485600785,53.33505354,1
"def _dispatchBubblingEvent(self, tag, evtType, evtObject):<tab>for node in tag.parents:<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>break<tab><tab>if not node._listeners:<tab><tab><tab>continue<tab><tab>if evtObject._stoppedPropagation:  # pragma: no cover<tab><tab><tab>continue<tab><tab>capture_listeners, bubbling_listeners = self._get_listeners(<tab><tab><tab>node, evtType<tab><tab>)  # pylint:disable=unused-variable<tab><tab>for c in bubbling_listeners:<tab><tab><tab>evtObject.currentTarget = node._node<tab><tab><tab>self.do_dispatch(c, evtObject)",0,if node is None :,if node . _node == evtType :,0.052869316,10.55267032,0.476190476
"def connect(self):<tab>if self.session is None:<tab><tab>self.session = requests.Session()<tab><tab><IF-STMT><tab><tab><tab>self.session.mount(""httpsds8k://"", requests.adapters.HTTPAdapter())<tab><tab>else:<tab><tab><tab>self.session.mount(""https://"", requests.adapters.HTTPAdapter())<tab><tab>self.session.verify = self.verify",0,"if isinstance ( self . verify , six . string_types ) :","if sys . platform == ""win32"" :",0.095099466,3.701773936,0.234375
"def get_latest_tasks(cls, tasks):<tab>tasks_group = {}<tab>for task in tasks:<tab><tab>task_key = cls.task_key(<tab><tab><tab>task_id=task.f_task_id, role=task.f_role, party_id=task.f_party_id<tab><tab>)<tab><tab>if task_key not in tasks_group:<tab><tab><tab>tasks_group[task_key] = task<tab><tab><IF-STMT><tab><tab><tab># update new version task<tab><tab><tab>tasks_group[task_key] = task<tab>return tasks_group",0,elif task . f_task_version > tasks_group [ task_key ] . f_task_version :,elif task_key in tasks_group :,0.01070647,6.405387599,0.5
"def wrapper(cached=True, reset=False):<tab>nonlocal cached_venv_dir<tab>if not cached or not cached_venv_dir or reset:<tab><tab>venv_dir = os.environ.get(""_VENV_DIR_"") or load_settings(lazy=True).get(<tab><tab><tab>""venv_dir""<tab><tab>)<tab><tab>if venv_dir:  # no cov<tab><tab><tab><IF-STMT><tab><tab><tab><tab>venv_dir = VENV_DIR_ISOLATED<tab><tab><tab>elif venv_dir == ""shared"":<tab><tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>else:  # no cov<tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>cached_venv_dir = venv_dir<tab>return cached_venv_dir",1,"if venv_dir == ""isolated"" :","if venv_dir == ""isolated"" :",0.75,100,1
"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab>if os.path.isfile(current) and f.endswith(""py""):<tab><tab><tab>if self.module_registrant:<tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab>elif os.path.isdir(current):<tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",1,if ret :,if ret :,0.531170663,1.00E-10,1
"def read_ansible_config(project_path, variables_of_interest):<tab>fnames = [""/etc/ansible/ansible.cfg""]<tab>if project_path:<tab><tab>fnames.append(os.path.join(project_path, ""ansible.cfg""))<tab>values = {}<tab>try:<tab><tab>parser = ConfigParser()<tab><tab>parser.read(fnames)<tab><tab><IF-STMT><tab><tab><tab>for var in variables_of_interest:<tab><tab><tab><tab>if var in parser[""defaults""]:<tab><tab><tab><tab><tab>values[var] = parser[""defaults""][var]<tab>except Exception:<tab><tab>logger.exception(""Failed to read ansible configuration(s) {}"".format(fnames))<tab>return values",0,"if ""defaults"" in parser :",if variables_of_interest :,0.03549272,1.00E-10,0.416666667
"def inference(self, x_all, data_loader):<tab>for i in range(len(self.convs)):<tab><tab>output = []<tab><tab>for src_id, edge_index, size in data_loader:<tab><tab><tab>x = x_all[src_id].to(self.device)<tab><tab><tab>edge_index = edge_index.to(self.device)<tab><tab><tab>x = self.convs[i](x, edge_index)<tab><tab><tab>x = x[: size[1]]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = F.relu(x)<tab><tab><tab>output.append(x.cpu())<tab><tab>x_all = torch.cat(output, dim=0)<tab>return F.log_softmax(x_all, dim=-1)",0,if i != self . num_layers - 1 :,if i != len ( self . convs ) - 1 :,0.147507874,31.17090652,0.408163265
"def guard_transform(transform):<tab>""""""Return an Affine transformation instance.""""""<tab>if not isinstance(transform, Affine):<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""GDAL-style transforms have been deprecated.  This ""<tab><tab><tab><tab>""exception will be raised for a period of time to highlight ""<tab><tab><tab><tab>""potentially confusing errors, but will eventually be removed.""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>transform = Affine(*transform)<tab>return transform",0,if tastes_like_gdal ( transform ) :,"if isinstance ( transform , dict ) :",0.054860857,12.86253479,0.36
"def _tokenize(self, text):<tab>if tf.is_tensor(text):<tab><tab>rank = len(text.shape)<tab><tab><IF-STMT><tab><tab><tab>return self._tokenize_tensor(text)<tab><tab>elif rank == 1:<tab><tab><tab>return self._tokenize_batch_tensor(text)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unsupported tensor rank %d for tokenization"" % rank)<tab>elif isinstance(text, list):<tab><tab>return list(map(self.tokenize, text))<tab>else:<tab><tab>text = tf.compat.as_text(text)<tab><tab>return self._tokenize_string(text)",1,if rank == 0 :,if rank == 0 :,0.75,100,1
"def validate_export(namespace):<tab>destination = namespace.destination<tab>if destination == ""file"":<tab><tab>if namespace.path is None or namespace.format_ is None:<tab><tab><tab>raise CLIError(""usage error: --path PATH --format FORMAT"")<tab>elif destination == ""appconfig"":<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(""usage error: --config-name NAME | --connection-string STR"")<tab>elif destination == ""appservice"":<tab><tab>if namespace.appservice_account is None:<tab><tab><tab>raise CLIError(""usage error: --appservice-account NAME_OR_ID"")",0,if ( namespace . dest_name is None ) and ( namespace . dest_connection_string is None ) :,if namespace . connection_string is None :,0.072363494,11.53788751,0.636363636
"def dispatch(self, request, *args, **kwargs):<tab>settings = self.get_settings(self.form_class.settings)<tab>initial = self.get_initial_form_data(settings)<tab>form = self.form_class(request=request, initial=initial)<tab>if request.method == ""POST"":<tab><tab>form = self.form_class(<tab><tab><tab>request.POST, request.FILES, request=request, initial=initial<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>form.save(settings)<tab><tab><tab>messages.success(request, _(""Settings have been saved.""))<tab><tab><tab>return redirect(request.path_info)<tab>return self.render(request, {""form"": form, ""form_settings"": settings})",1,if form . is_valid ( ) :,if form . is_valid ( ) :,0.75,100,1
"def get_modules(path):<tab>modules = set()<tab>for dirpath, dirnames, filenames in os.walk(path):<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cutoff = len(path) + 1<tab><tab><tab><tab>fullpath = os.path.join(dirpath[cutoff:], filename)<tab><tab><tab><tab>modules.add(fullpath)<tab>return modules",1,"if filename . endswith ( "".py"" ) :","if filename . endswith ( "".py"" ) :",0.75,100,1
"def _make_input_layers(self, rebuild=False):<tab>for name, layer in self.layer_map.items():<tab><tab>layer.left_in_edges = len(layer.in_edges)<tab><tab>if len(layer.in_edges) == 0:<tab><tab><tab>if rebuild:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.input_layers.append(name)<tab><tab><tab>else:<tab><tab><tab><tab>self.input_layers.append(name)",0,"if not layer . get_attr ( ""scope"" ) :",if name not in self . input_layers :,0.080363351,4.648378983,0.257142857
"def _get_status(self):<tab>connection_errors_allowed = 10<tab>while True:<tab><tab>try:<tab><tab><tab>content = requests.get(self.__status_details_url).json()<tab><tab>except (requests.ConnectionError, requests.HTTPError) as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield e<tab><tab><tab>content = {""processed"": False, ""code"": ""being_processed""}<tab><tab><tab>connection_errors_allowed -= 1<tab><tab>yield content",0,if not connection_errors_allowed :,if connection_errors_allowed == 0 :,0.045150551,42.72870064,0.5
"def show(self):<tab>if len(self.figures.keys()) == 0:<tab><tab>return<tab>if not SETTINGS.plot_split:<tab><tab>if SETTINGS.plot_backend.lower() == ""qt4agg"":<tab><tab><tab>self.tabbed_qt4_window()<tab><tab><IF-STMT><tab><tab><tab>self.tabbed_qt5_window()<tab><tab>elif SETTINGS.plot_backend.lower() == ""tkagg"":<tab><tab><tab>self.tabbed_tk_window()<tab><tab>else:<tab><tab><tab>plt.show()<tab>else:<tab><tab>plt.show()",1,"elif SETTINGS . plot_backend . lower ( ) == ""qt5agg"" :","elif SETTINGS . plot_backend . lower ( ) == ""qt5agg"" :",0.75,100,1
"def emit(self, record):<tab>msg = self.format(record)<tab>self.lock.acquire()<tab>try:<tab><tab>msg = self.encode(msg)<tab><tab><IF-STMT><tab><tab><tab>self.perform_rollover()<tab><tab>self.write(msg)<tab><tab>self.flush()<tab>finally:<tab><tab>self.lock.release()",0,"if self . should_rollover ( record , len ( msg ) ) :",if self . auto_rollover and self . auto_rollover :,0.043415944,12.97528097,0.37254902
"def install(self, unicode=False, names=None):<tab>import __builtin__<tab>__builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext<tab>if hasattr(names, ""__contains__""):<tab><tab><IF-STMT><tab><tab><tab>__builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""]<tab><tab>if ""ngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""ngettext""] = (<tab><tab><tab><tab>unicode and self.ungettext or self.ngettext<tab><tab><tab>)<tab><tab>if ""lgettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lgettext""] = self.lgettext<tab><tab>if ""lngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lngettext""] = self.lngettext",1,"if ""gettext"" in names :","if ""gettext"" in names :",0.75,100,1
"def test_simulate_moment_steps_set_state(dtype):<tab>q0, q1 = cirq.LineQubit.range(2)<tab>circuit = cirq.Circuit(cirq.H(q0), cirq.H(q1), cirq.H(q0), cirq.H(q1))<tab>simulator = cirq.Simulator(dtype=dtype)<tab>for i, step in enumerate(simulator.simulate_moment_steps(circuit)):<tab><tab>np.testing.assert_almost_equal(step.state_vector(), np.array([0.5] * 4))<tab><tab><IF-STMT><tab><tab><tab>step.set_state_vector(np.array([1, 0, 0, 0], dtype=dtype))",1,if i == 0 :,if i == 0 :,0.75,100,1
"def get_config_settings():<tab>config = {}<tab>for plugin in extension_loader.MANAGER.plugins:<tab><tab>fn_name = plugin.name<tab><tab>function = plugin.plugin<tab><tab># if a function takes config...<tab><tab><IF-STMT><tab><tab><tab>fn_module = importlib.import_module(function.__module__)<tab><tab><tab># call the config generator if it exists<tab><tab><tab>if hasattr(fn_module, ""gen_config""):<tab><tab><tab><tab>config[fn_name] = fn_module.gen_config(function._takes_config)<tab>return yaml.safe_dump(config, default_flow_style=False)",1,"if hasattr ( function , ""_takes_config"" ) :","if hasattr ( function , ""_takes_config"" ) :",0.75,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_queue_name(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_pause(d.getBoolean())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab>if pyv == 2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab>if pyv == 3:<tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY3:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",1,if self . PY2 == SKIP :,if self . PY2 == SKIP :,0.75,100,1
"def to_dict(self) -> JSONDict:<tab>data = dict()<tab>for key in iter(self.__dict__):<tab><tab>if key == ""bot"" or key.startswith(""_""):<tab><tab><tab>continue<tab><tab>value = self.__dict__[key]<tab><tab><IF-STMT><tab><tab><tab>if hasattr(value, ""to_dict""):<tab><tab><tab><tab>data[key] = value.to_dict()<tab><tab><tab>else:<tab><tab><tab><tab>data[key] = value<tab>if data.get(""from_user""):<tab><tab>data[""from""] = data.pop(""from_user"", None)<tab>return data",0,if value is not None :,"if isinstance ( value , dict ) :",0.023749772,7.267884212,0.232142857
"def _resolve_result(self, f=None):<tab>try:<tab><tab>if f:<tab><tab><tab>results = f.result()<tab><tab>else:<tab><tab><tab>results = list(map(self._client.results.get, self.msg_ids))<tab><tab>if self._single_result:<tab><tab><tab>r = results[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise r<tab><tab>else:<tab><tab><tab>results = error.collect_exceptions(results, self._fname)<tab><tab>self._success = True<tab><tab>self.set_result(self._reconstruct_result(results))<tab>except Exception as e:<tab><tab>self._success = False<tab><tab>self.set_exception(e)",1,"if isinstance ( r , Exception ) :","if isinstance ( r , Exception ) :",0.75,100,1
"def print_monitor(args):<tab>from pylearn2.utils import serial<tab>import gc<tab>for model_path in args:<tab><tab>if len(args) > 1:<tab><tab><tab>print(model_path)<tab><tab>model = serial.load(model_path)<tab><tab>monitor = model.monitor<tab><tab>del model<tab><tab>gc.collect()<tab><tab>channels = monitor.channels<tab><tab><IF-STMT><tab><tab><tab>print(""old file, not all fields parsed correctly"")<tab><tab>else:<tab><tab><tab>print(""epochs seen: "", monitor._epochs_seen)<tab><tab>print(""time trained: "", max(channels[key].time_record[-1] for key in channels))<tab><tab>for key in sorted(channels.keys()):<tab><tab><tab>print(key, "":"", channels[key].val_record[-1])",0,"if not hasattr ( monitor , ""_epochs_seen"" ) :",if len ( channels ) == 0 :,0.017863351,3.868564529,0.25
"def apply(self, **kwargs: Any) -> None:<tab>for node in self.document.traverse(addnodes.index):<tab><tab><IF-STMT><tab><tab><tab>msg = (<tab><tab><tab><tab>__(<tab><tab><tab><tab><tab>""4 column based index found. ""<tab><tab><tab><tab><tab>""It might be a bug of extensions you use: %r""<tab><tab><tab><tab>)<tab><tab><tab><tab>% node[""entries""]<tab><tab><tab>)<tab><tab><tab>logger.warning(msg, location=node)<tab><tab><tab>for i, entry in enumerate(node[""entries""]):<tab><tab><tab><tab>if len(entry) == 4:<tab><tab><tab><tab><tab>node[""entries""][i] = entry + (None,)",0,"if ""entries"" in node and any ( len ( entry ) == 4 for entry in node [ ""entries"" ] ) :","if ""entries"" in node :",0.036537405,4.829488366,0.302298851
"def cleanup_empty_directories(path: str):<tab>""""""Remove all empty folders inside (and including) 'path'""""""<tab>path = os.path.normpath(path)<tab>while 1:<tab><tab>repeat = False<tab><tab>for root, dirs, files in os.walk(path, topdown=False):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>remove_dir(root)<tab><tab><tab><tab><tab>repeat = True<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab>if not repeat:<tab><tab><tab>break<tab># Only remove if main folder is now also empty<tab>if not os.listdir(path):<tab><tab>try:<tab><tab><tab>remove_dir(path)<tab><tab>except:<tab><tab><tab>pass",0,if not dirs and not files and root != path :,if not os . listdir ( root ) :,0.02511494,8.125165711,0.216666667
"def expect_flow_sequence_item(self):<tab>if isinstance(self.event, SequenceEndEvent):<tab><tab>self.indent = self.indents.pop()<tab><tab>self.flow_level -= 1<tab><tab><IF-STMT><tab><tab><tab>self.write_indicator(u"","", False)<tab><tab><tab>self.write_indent()<tab><tab>self.write_indicator(u""]"", False)<tab><tab>self.state = self.states.pop()<tab>else:<tab><tab>self.write_indicator(u"","", False)<tab><tab>if self.canonical or self.column > self.best_width:<tab><tab><tab>self.write_indent()<tab><tab>self.states.append(self.expect_flow_sequence_item)<tab><tab>self.expect_node(sequence=True)",0,if self . canonical :,if self . canonical or self . column > self . best_width :,0.311230047,17.39579738,0.541666667
"def test_loss_diff(self):<tab>losses = []<tab>for use_cuda in [True, False]:<tab><tab>for use_py_func_op in [True, False]:<tab><tab><tab>L = test_main(use_cuda, use_py_func_op, self.use_parallel_executor)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>losses.append(L)<tab>for idx in six.moves.range(len(losses) - 1):<tab><tab>max_diff = np.max(np.abs(losses[idx] - losses[0]))<tab><tab>self.assertAlmostEqual(max_diff, 0, delta=1e-3)",1,if L is not None :,if L is not None :,0.75,100,1
"def check_file(f, path):<tab>if not (ignore_substring and ignore_substring in f):<tab><tab>if substring in f:<tab><tab><tab>compl_path = os.path.join(path, f)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return compl_path<tab>return False",1,if os . path . isfile ( compl_path ) :,if os . path . isfile ( compl_path ) :,0.75,100,1
"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.y + j < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",0,if self . block . pos . x + i < 0 :,"if self . block . get ( i , j ) is None :",0.190344058,28.91784933,0.326923077
"def is_fail_state(state):<tab>if type(<tab><tab>state.addr<tab>) == SootAddressDescriptor and state.addr.method == SootMethodDescriptor.from_soot_method(<tab><tab>onclick_method<tab>):<tab><tab>sols = state.solver.eval_upto(state.memory_soot.stack.load(""$z0""), 2)<tab><tab>assert len(sols) == 1<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",0,if sols [ 0 ] == 0 :,if len ( sols ) == 1 :,0.020373037,11.99014838,0.333333333
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.add_delete_status(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def _init_weight(self):<tab>for m in self.modules():<tab><tab><IF-STMT><tab><tab><tab>n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels<tab><tab><tab>m.weight.data.normal_(0, math.sqrt(2.0 / n))<tab><tab>elif isinstance(m, SyncBatchNorm):<tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()<tab><tab>elif isinstance(m, nn.BatchNorm2d):<tab><tab><tab>m.weight.data.fill_(1)<tab><tab><tab>m.bias.data.zero_()",1,"if isinstance ( m , nn . Conv2d ) :","if isinstance ( m , nn . Conv2d ) :",0.75,100,1
"def wrapper(*args, **kwargs):<tab>global _exception<tab>try:<tab><tab>fn(*args, **kwargs)<tab>except Exception:<tab><tab>_exception = sys.exc_info()<tab><tab>et, ev, tb = _exception<tab><tab>if getattr(ev, ""filename"", None) is None:<tab><tab><tab># get the filename from the last item in the stack<tab><tab><tab>filename = traceback.extract_tb(tb)[-1][0]<tab><tab>else:<tab><tab><tab>filename = ev.filename<tab><tab><IF-STMT><tab><tab><tab>_error_files.append(filename)<tab><tab>raise",1,if filename not in _error_files :,if filename not in _error_files :,0.75,100,1
"def purge_messages(self):<tab>with self.app.connection_for_write() as connection:<tab><tab>count = self.app.control.purge(connection=connection)<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>print(<tab><tab><tab><tab>""purge: Erased {0} {1} from the queue.\n"".format(<tab><tab><tab><tab><tab>count, pluralize(count, ""message"")<tab><tab><tab><tab>)<tab><tab><tab>)",0,if count :,if count > 0 :,0.097914534,1.00E-10,0.7
"def read_series(rec):<tab>found = []<tab>for tag in (""440"", ""490"", ""830""):<tab><tab>fields = rec.get_fields(tag)<tab><tab>if not fields:<tab><tab><tab>continue<tab><tab>for f in fields:<tab><tab><tab>this = []<tab><tab><tab>for k, v in f.get_subfields([""a"", ""v""]):<tab><tab><tab><tab>if k == ""v"" and v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>v = v.rstrip("".,; "")<tab><tab><tab><tab>if v:<tab><tab><tab><tab><tab>this.append(v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found += ["" -- "".join(this)]<tab>return found",1,if this :,if this :,0.531170663,1.00E-10,1
def calc_position_values(positions):<tab>values = []<tab>for position in positions:<tab><tab><IF-STMT><tab><tab><tab># Futures don't have an inherent position value.<tab><tab><tab>values.append(0.0)<tab><tab>else:<tab><tab><tab>values.append(position.last_sale_price * position.amount)<tab>return values,0,"if isinstance ( position . asset , Future ) :","if isinstance ( position . last_sale_price , float ) :",0.285600785,31.61487584,0.558441558
"def _loc(obj):<tab>try:<tab><tab>fn = getattr(obj, ""__file__"", None)<tab><tab>if fn is not None:<tab><tab><tab>return "" @%s"" % (fn,)<tab><tab>obj = getattr(obj, ""im_func"", obj)<tab><tab>code = getattr(obj, ""__code__"", None)<tab><tab><IF-STMT><tab><tab><tab>return "" @%s:%s"" % (code.co_filename, code.co_firstlineno)<tab>except Exception:<tab><tab>pass<tab>return """"",1,if code is not None :,if code is not None :,0.75,100,1
"def _convert_user_into_remote(self, username, exclude=[""all""]):<tab># builds a ref with an username and a branch<tab># this method parses the repository's remotes to find the url matching username<tab># and containing the given branch and returns the corresponding ref<tab>remotes = {remote.name: list(remote.urls) for remote in self.repository.remotes}<tab>for name in (self.name, ""upstream"") + tuple(remotes.keys()):<tab><tab>if name in remotes and name not in exclude:<tab><tab><tab>for url in remotes[name]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield name",0,"if self . fqdn in url and username == url . split ( ""/"" ) [ - 2 ] . split ( "":"" ) [ - 1 ] :",if url . startswith ( username ) :,0.00652825,0.585757188,0.150793651
"def _render_ib_interfaces(cls, network_state, iface_contents, flavor):<tab>ib_filter = renderer.filter_by_type(""infiniband"")<tab>for iface in network_state.iter_interfaces(ib_filter):<tab><tab><IF-STMT><tab><tab>iface_cfg = iface_contents[iface_name]<tab><tab>iface_cfg.kind = ""infiniband""<tab><tab>iface_subnets = iface.get(""subnets"", [])<tab><tab>route_cfg = iface_cfg.routes<tab><tab>cls._render_subnets(<tab><tab><tab>iface_cfg, iface_subnets, network_state.has_default_route, flavor<tab><tab>)<tab><tab>cls._render_subnet_routes(iface_cfg, route_cfg, iface_subnets, flavor)",0,"iface_name = iface [ ""name"" ]",iface_name = iface . name,0.104941043,41.91742491,0.62962963
"def _extract_level(self):<tab>""""""Extract level and component if available (lazy).""""""<tab>if self._level is None:<tab><tab>split_tokens = self.split_tokens<tab><tab>if not split_tokens:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False<tab><tab><tab>return<tab><tab>x = (<tab><tab><tab>self.log_levels.index(split_tokens[1])<tab><tab><tab>if split_tokens[1] in self.log_levels<tab><tab><tab>else None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self._level = split_tokens[1]<tab><tab><tab>self._component = split_tokens[2]<tab><tab>else:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False",1,if x is not None :,if x is not None :,0.75,100,1
"def addnode(self, parent, data):<tab>print(""aaa"", data)<tab>for i in data:<tab><tab>print(i)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if isinstance(i, tuple):<tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])<tab><tab><tab>self.addnode(item, i[1])<tab><tab>else:<tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])",0,"if i == ""-"" :",if not i :,0.039449619,7.733712583,0.45
"def getdsturl(tcpdata):<tab>import logging<tab>log = logging.getLogger(""getdsturl"")<tab>p = parseHeader(tcpdata, type=""request"")<tab>if p is None:<tab><tab>log.warn(""parseHeader returned None"")<tab><tab>return<tab>if p.has_key(""uri"") and p.has_key(""headers""):<tab><tab><IF-STMT><tab><tab><tab>r = ""http://%s%s"" % (p[""headers""][""host""][0], p[""uri""])<tab><tab><tab>return r<tab><tab>else:<tab><tab><tab>log.warn(""seems like no host header was set"")<tab>else:<tab><tab>log.warn(""parseHeader did not give us a nice return %s"" % p)",0,"if p [ ""headers"" ] . has_key ( ""host"" ) :","if ""host"" in p [ ""headers"" ] :",0.138221484,36.81165573,0.485294118
"def assert_not_none(obj, msg=None, values=True):<tab>""""""Fail the test if given object is None.""""""<tab>_msg = ""is None""<tab>if obj is None:<tab><tab>if msg is None:<tab><tab><tab>msg = _msg<tab><tab><IF-STMT><tab><tab><tab>msg = ""%s: %s"" % (msg, _msg)<tab><tab>_report_failure(msg)",0,elif values is True :,elif values :,0.128067138,1.00E-10,0.5
"def sort(self):<tab>sorted_models = []<tab>concrete_models = set()<tab>models = list(self.data)<tab>while len(sorted_models) < len(models):<tab><tab>found = False<tab><tab>for model in models:<tab><tab><tab>if model in sorted_models:<tab><tab><tab><tab>continue<tab><tab><tab>dependencies = self.dependencies.get(model._meta.concrete_model)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sorted_models.append(model)<tab><tab><tab><tab>concrete_models.add(model._meta.concrete_model)<tab><tab><tab><tab>found = True<tab><tab>if not found:<tab><tab><tab>return<tab>self.data = OrderedDict((model, self.data[model]) for model in sorted_models)",0,if not ( dependencies and dependencies . difference ( concrete_models ) ) :,if dependencies is not None and model not in concrete_models :,0.012608699,12.59878429,0.172727273
"def load_vocab_dict(vocab_file_path):<tab>""""""Load vocabs, vocab: {""word"": 1, ...}""""""<tab>logging.info(""Loading vocab from {}"".format(vocab_file_path))<tab>with open(vocab_file_path, encoding=""utf-8"") as in_f:<tab><tab>vocabs = {}<tab><tab>for line in in_f:<tab><tab><tab>parts = line.rstrip().split(""\t"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>vocabs[parts[0]] = parts[1]<tab>logging.info(""Loded {} vocabs from {}"".format(len(vocabs), vocab_file_path))<tab>return vocabs",1,if len ( parts ) < 2 :,if len ( parts ) < 2 :,0.75,100,1
"def get_layers_from_suite(self, suite, suiteClass):<tab>top_layer = suiteClass()<tab>layers_dict = OrderedDict()<tab>for test in self.flatten_suite(suite):<tab><tab>layer = getattr(test, ""layer"", None)<tab><tab><IF-STMT><tab><tab><tab>if layer not in layers_dict:<tab><tab><tab><tab>layers_dict[layer] = LayerSuite(self.session, layer=layer)<tab><tab><tab>layers_dict[layer].addTest(test)<tab><tab>else:<tab><tab><tab>top_layer.addTest(test)<tab>self.get_parent_layers(layers_dict)<tab>return top_layer, layers_dict",0,if layer :,if layer is not None :,0.090364769,1.00E-10,0.4
"def team_scores(self, team_scores, time):<tab>""""""Store output of team scores to a JSON file""""""<tab>data = []<tab>for score in team_scores[""fixtures""]:<tab><tab><IF-STMT><tab><tab><tab>item = {<tab><tab><tab><tab>""date"": score[""date""].split(""T"")[0],<tab><tab><tab><tab>""homeTeamName"": score[""homeTeamName""],<tab><tab><tab><tab>""goalsHomeTeam"": score[""result""][""goalsHomeTeam""],<tab><tab><tab><tab>""goalsAwayTeam"": score[""result""][""goalsAwayTeam""],<tab><tab><tab><tab>""awayTeamName"": score[""awayTeamName""],<tab><tab><tab>}<tab><tab><tab>data.append(item)<tab>self.generate_output({""team_scores"": data})",0,"if score [ ""status"" ] == ""FINISHED"" :","if score [ ""time"" ] >= time :",0.142419566,24.99775832,0.727272727
"def run(self, root):<tab>footnotesDiv = self.footnotes.makeFootnotesDiv(root)<tab>if footnotesDiv is not None:<tab><tab>result = self.footnotes.findFootnotesPlaceholder(root)<tab><tab>if result:<tab><tab><tab>child, parent, isText = result<tab><tab><tab>ind = list(parent).index(child)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>parent.remove(child)<tab><tab><tab><tab>parent.insert(ind, footnotesDiv)<tab><tab><tab>else:<tab><tab><tab><tab>parent.insert(ind + 1, footnotesDiv)<tab><tab><tab><tab>child.tail = None<tab><tab>else:<tab><tab><tab>root.append(footnotesDiv)",1,if isText :,if isText :,0.531170663,1.00E-10,1
"def delete_target_group(self, target_group_arn):<tab>if target_group_arn not in self.target_groups:<tab><tab>raise TargetGroupNotFoundError()<tab>target_group = self.target_groups[target_group_arn]<tab>if target_group:<tab><tab><IF-STMT><tab><tab><tab>raise ResourceInUseError(<tab><tab><tab><tab>""The target group '{}' is currently in use by a listener or a rule"".format(<tab><tab><tab><tab><tab>target_group_arn<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>del self.target_groups[target_group_arn]<tab><tab>return target_group",0,if self . _any_listener_using ( target_group_arn ) :,if target_group . is_available ( ) :,0.038362157,11.77644607,0.641025641
"def run_pending(self, now=None):<tab>""""""Runs the command if scheduled""""""<tab>now = now or datetime.now()<tab>if self.is_enabled():<tab><tab><IF-STMT><tab><tab><tab>self.last_run = now<tab><tab>next_time = self.schedule(self.last_run).get_next()<tab><tab>if next_time < now:<tab><tab><tab>self.last_run = now<tab><tab><tab>return self.run()<tab>return -1",0,if self . last_run is None :,if now > self . last_run :,0.144478934,48.54917717,0.30952381
"def _fix_exception_context(new_exc, old_exc):<tab># Context may not be correct, so find the end of the chain<tab>while 1:<tab><tab>exc_context = new_exc.__context__<tab><tab><IF-STMT><tab><tab><tab># Context is already set correctly (see issue 20317)<tab><tab><tab>return<tab><tab>if exc_context is None or exc_context is frame_exc:<tab><tab><tab>break<tab><tab>new_exc = exc_context<tab># Change the end of the chain to point to the exception<tab># we expect it to reference<tab>new_exc.__context__ = old_exc",1,if exc_context is old_exc :,if exc_context is old_exc :,0.75,100,1
"def delete_backend(<tab>self, backend_tag: BackendTag, force_kill: bool = False) -> Optional[GoalId]:<tab>async with self.write_lock:<tab><tab># Check that the specified backend isn't used by any endpoints.<tab><tab>for endpoint, info in self.endpoint_state.get_endpoints().items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""Backend '{}' is used by endpoint '{}' ""<tab><tab><tab><tab><tab>""and cannot be deleted. Please remove ""<tab><tab><tab><tab><tab>""the backend from all endpoints and try ""<tab><tab><tab><tab><tab>""again."".format(backend_tag, endpoint)<tab><tab><tab><tab>)<tab><tab>return self.backend_state.delete_backend(backend_tag, force_kill)",0,"if backend_tag in info [ ""traffic"" ] or backend_tag in info [ ""shadows"" ] :","if info [ ""backend_id"" ] == backend_tag :",0.042906484,12.70203857,0.363636364
"def lint(self, request):<tab>try:<tab><tab>html_linter = UnwrapObject(self._koLintService.getLinterForLanguage(""HTML""))<tab><tab>return html_linter.lint(request, TPLInfo=self._tplPatterns)<tab>except:<tab><tab><IF-STMT><tab><tab><tab>self._checkValidVersion_complained[""lint""] = True<tab><tab><tab>log.exception(""Problem in koPHPLinter.lint"")<tab><tab>return koLintResults()",1,"if ""lint"" not in self . _checkValidVersion_complained :","if ""lint"" not in self . _checkValidVersion_complained :",0.75,100,1
"def get_commit(self, rev):<tab>""""""Get commit object identified by `rev` (SHA or branch or tag name).""""""<tab>for prefix in [""refs/heads/"", ""refs/tags/"", """"]:<tab><tab>key = prefix + rev<tab><tab>try:<tab><tab><tab>obj = self[encode_for_git(key)]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>obj = self[obj.object[1]]<tab><tab><tab>return obj<tab><tab>except KeyError:<tab><tab><tab>pass<tab>raise KeyError(rev)",0,"if isinstance ( obj , dulwich . objects . Tag ) :",if obj . object [ 0 ] == rev :,0.054440519,4.83957687,0.192307692
"def get_host_metadata(self):<tab>meta = {}<tab>if self.agent_url:<tab><tab>try:<tab><tab><tab>resp = requests.get(self.agent_url, timeout=1).json().get(""config"", {})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>meta[""nomad_version""] = resp.get(""Version"")<tab><tab><tab>if ""Region"" in resp:<tab><tab><tab><tab>meta[""nomad_region""] = resp.get(""Region"")<tab><tab><tab>if ""Datacenter"" in resp:<tab><tab><tab><tab>meta[""nomad_datacenter""] = resp.get(""Datacenter"")<tab><tab>except Exception as ex:<tab><tab><tab>self.log.debug(""Error getting Nomad version: %s"" % str(ex))<tab>return meta",1,"if ""Version"" in resp :","if ""Version"" in resp :",0.75,100,1
"def _waitFakenetStopped(self, timeoutsec=None):<tab>retval = False<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>retval = True<tab><tab><tab>break<tab><tab>time.sleep(1)<tab><tab>if timeoutsec is not None:<tab><tab><tab>timeoutsec -= 1<tab><tab><tab>if timeoutsec <= 0:<tab><tab><tab><tab>break<tab>return retval",0,if self . _confirmFakenetStopped ( ) :,if self . _isFakenetStopped ( ) :,0.38848939,50,1
"def send_message(self, message):<tab>smtp = smtplib.SMTP(self.smtp_host, self.smtp_port)<tab>try:<tab><tab>smtp.ehlo()<tab><tab>if self.smtp_tls:<tab><tab><tab>smtp.starttls()<tab><tab><IF-STMT><tab><tab><tab>smtp.login(self.smtp_user, self.smtp_password)<tab><tab>smtp.sendmail(self.from_user, self.recipients, message.as_string())<tab>finally:<tab><tab>smtp.close()",0,if self . smtp_user :,if self . smtp_password :,0.394778655,64.34588842,1
"def set_tracker_icon(tracker_icon, cell):<tab>if tracker_icon:<tab><tab>pixbuf = tracker_icon.get_cached_icon()<tab><tab><IF-STMT><tab><tab><tab>pixbuf = get_pixbuf_at_size(tracker_icon.get_filename(), 16)<tab><tab><tab>tracker_icon.set_cached_icon(pixbuf)<tab>else:<tab><tab>pixbuf = create_blank_pixbuf()<tab># Suppress Warning: g_object_set_qdata: assertion `G_IS_OBJECT (object)' failed<tab>with warnings.catch_warnings():<tab><tab>warnings.simplefilter(""ignore"")<tab><tab>cell.set_property(""pixbuf"", pixbuf)",1,if pixbuf is None :,if pixbuf is None :,0.75,100,1
"def __create_index(self, collection, index, unique):<tab>doc = collection.find_one(projection={""_id"": 1})<tab>if doc is None:<tab><tab>try:<tab><tab><tab>indexes = list(collection.list_indexes())<tab><tab>except OperationFailure:<tab><tab><tab>indexes = []<tab><tab><IF-STMT><tab><tab><tab>collection.create_index(index, unique=unique)",0,if index not in indexes :,if len ( indexes ) > 0 :,0.023749772,7.267884212,0.232142857
"def read_oclc(fields):<tab>if ""035"" not in fields:<tab><tab>return {}<tab>found = []<tab>for line in fields[""035""]:<tab><tab>for v in get_subfield_values(line, [""a""]):<tab><tab><tab>m = re_oclc.match(v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>oclc = m.group(1)<tab><tab><tab>if oclc not in found:<tab><tab><tab><tab>found.append(oclc)<tab>return {""oclc_number"": found} if found else {}",1,if not m :,if not m :,0.75,100,1
"def closest_enemy_ant(self, row1, col1, filter=None):<tab># find the closest enemy ant from this row/col<tab>min_dist = maxint<tab>closest_ant = None<tab>for ant in self.enemy_ants():<tab><tab><IF-STMT><tab><tab><tab>dist = self.distance(row1, col1, ant[0][0], ant[0][1])<tab><tab><tab>if dist < min_dist:<tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab>closest_ant = ant[0]<tab>return closest_ant",0,if filter is None or ant not in filter :,if filter and ant [ 0 ] in filter :,0.236933231,20.55668085,0.181818182
"def fromVariant(variant):<tab>if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant):<tab><tab>t = variant.type()<tab><tab>if t == QtCore.QVariant.String:<tab><tab><tab>return str(variant.toString())<tab><tab><IF-STMT><tab><tab><tab>return variant.toDouble()[0]<tab><tab>elif t == QtCore.QVariant.Int:<tab><tab><tab>return variant.toInt()[0]<tab><tab>elif t == QtCore.QVariant.Bool:<tab><tab><tab>return variant.toBool()<tab><tab>elif t == QtCore.QVariant.Invalid:<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName())<tab>else:<tab><tab>return variant",1,elif t == QtCore . QVariant . Double :,elif t == QtCore . QVariant . Double :,0.75,100,1
"def _check_old_with_state(self):<tab>add_vec = False<tab>for op in self.ops:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>op.get_coeff(0.0, self.args)<tab><tab><tab>except TypeError as e:<tab><tab><tab><tab>nfunc = _StateAsArgs(self.coeff)<tab><tab><tab><tab>op = EvoElement((op.qobj, nfunc, nfunc, ""func""))<tab><tab><tab><tab>add_vec = True<tab>if add_vec:<tab><tab>self.dynamics_args += [(""_state_vec"", ""vec"", None)]",0,"if op . type == ""func"" :","if hasattr ( op , ""get_coeff"" ) :",0.021135836,5.063996507,0.4
"def _read_readable(self, readable):<tab>blocksize = 8192<tab>if self.debuglevel > 0:<tab><tab>print(""sendIng a read()able"")<tab>encode = self._is_textIO(readable)<tab>if encode and self.debuglevel > 0:<tab><tab>print(""encoding file using iso-8859-1"")<tab>while True:<tab><tab>datablock = readable.read(blocksize)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if encode:<tab><tab><tab>datablock = datablock.encode(""iso-8859-1"")<tab><tab>yield datablock",1,if not datablock :,if not datablock :,0.75,100,1
"def read_chat_forever(reader, pub_socket):<tab>line = reader.readline()<tab>who = ""someone""<tab>while line:<tab><tab>print(""Chat:"", line.strip())<tab><tab>if line.startswith(""name:""):<tab><tab><tab>who = line.split("":"")[-1].strip()<tab><tab>try:<tab><tab><tab>pub_socket.send_pyobj((who, line))<tab><tab>except socket.error as e:<tab><tab><tab># ignore broken pipes, they just mean the participant<tab><tab><tab># closed its connection already<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>line = reader.readline()<tab>print(""Participant left chat."")",0,if e [ 0 ] != 32 :,if e . errno != errno . EBADF :,0.03384241,12.54931062,0.412698413
"def _wrapped() -> None:<tab>should_run = app.is_leader() if on_leader else True<tab>if should_run:<tab><tab>with self.trace(shortlabel(fun), trace_enabled=traced):<tab><tab><tab># pass app only if decorated function takes an argument<tab><tab><tab><IF-STMT><tab><tab><tab><tab>task_takes_app = cast(Callable[[AppT], Awaitable], fun)<tab><tab><tab><tab>return await task_takes_app(app)<tab><tab><tab>else:<tab><tab><tab><tab>task = cast(Callable[[], Awaitable], fun)<tab><tab><tab><tab>return await task()",0,if inspect . signature ( fun ) . parameters :,if on_leader :,0.010867398,1.00E-10,0.285714286
"def Decode(self, filedesc):<tab>while True:<tab><tab>chunk = filedesc.Read(4)<tab><tab>if not chunk:<tab><tab><tab>return<tab><tab>if chunk == b""QUUX"":<tab><tab><tab>yield b""NORF""<tab><tab><IF-STMT><tab><tab><tab>yield b""BLARGH""",0,"if chunk == b""THUD"" :","elif chunk == b""BLARGH"" :",0.121075651,51.3345048,0.5
"def _get_modules(fn):<tab>finder = modulefinder.ModuleFinder()<tab>finder.run_script(fn)<tab>all = []<tab>for m in finder.modules.values():<tab><tab>if not isinstance(m, modulefinder.Module):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># skip shared object files<tab><tab>if m.__file__.endswith("".so""):<tab><tab><tab>continue<tab><tab># skip mac system stuff...<tab><tab># FIXME: would need to augment with  other OS's system stuff<tab><tab>if m.__file__.startswith(""/Library/Frameworks""):<tab><tab><tab>continue<tab><tab>all.append(m)<tab>return all",0,if not m . __file__ :,"if m . __name__ . startswith ( ""__init__"" ) :",0.040133529,15.31682455,0.4
"def _read(self, size):<tab>""""""Return size bytes from the stream.""""""<tab>if self.comptype == ""tar"":<tab><tab>return self.__read(size)<tab>c = len(self.dbuf)<tab>while c < size:<tab><tab>buf = self.__read(self.bufsize)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>try:<tab><tab><tab>buf = self.cmp.decompress(buf)<tab><tab>except IOError:<tab><tab><tab>raise ReadError(""invalid compressed data"")<tab><tab>self.dbuf += buf<tab><tab>c += len(buf)<tab>buf = self.dbuf[:size]<tab>self.dbuf = self.dbuf[size:]<tab>return buf",1,if not buf :,if not buf :,0.75,100,1
"def cluster_list(tokeniser):<tab>clusterids = []<tab>value = tokeniser()<tab>try:<tab><tab>if value == ""["":<tab><tab><tab>while True:<tab><tab><tab><tab>value = tokeniser()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>clusterids.append(ClusterID(value))<tab><tab>else:<tab><tab><tab>clusterids.append(ClusterID(value))<tab><tab>if not clusterids:<tab><tab><tab>raise ValueError(""no cluster-id in the cluster list"")<tab><tab>return ClusterList(clusterids)<tab>except ValueError:<tab><tab>raise ValueError(""invalud cluster list"")",1,"if value == ""]"" :","if value == ""]"" :",0.75,100,1
"def from_data(cls, value, currency, includes_tax=None):<tab>if includes_tax is None:<tab><tab><IF-STMT><tab><tab><tab>msg = ""Missing includes_tax argument for %s.from_data""<tab><tab><tab>raise TypeError(msg % (cls.__name__,))<tab><tab>includes_tax = cls.includes_tax<tab>if includes_tax:<tab><tab>return TaxfulPrice(value, currency)<tab>else:<tab><tab>return TaxlessPrice(value, currency)",1,if cls . includes_tax is None :,if cls . includes_tax is None :,0.75,100,1
"def THUMB(image, nx=120, ny=120, gae=False, name=""thumb""):<tab>if image:<tab><tab><IF-STMT><tab><tab><tab>request = current.request<tab><tab><tab>from PIL import Image<tab><tab><tab>import os<tab><tab><tab>img = Image.open(os.path.join(request.folder, ""uploads"", image))<tab><tab><tab>img.thumbnail((nx, ny), Image.ANTIALIAS)<tab><tab><tab>root, ext = os.path.splitext(image)<tab><tab><tab>thumb = ""%s_%s%s"" % (root, name, ext)<tab><tab><tab>img.save(request.folder + ""uploads/"" + thumb)<tab><tab><tab>return thumb<tab><tab>else:<tab><tab><tab>return image",0,if not gae :,if gae :,0.096488528,1.00E-10,0.416666667
"def _get_two_devices(self, require_same_type=False):<tab>tpus = extensions.tpu_devices()<tab>if FLAGS.requires_tpu:<tab><tab>if len(tpus) == 2:<tab><tab><tab>res = tpus<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""This test requires 2 TPU cores but %s are found"" % len(tpus)<tab><tab><tab>)<tab>else:<tab><tab>if len(tpus) == 2:<tab><tab><tab>res = tpus<tab><tab><IF-STMT><tab><tab><tab>res = (""CPU:0"", ""GPU:0"")<tab><tab>else:<tab><tab><tab>res = (""CPU:0"", ""CPU:1"")<tab>return res",0,elif self . _hasGPU ( ) and not require_same_type :,elif require_same_type :,0.018795027,1.00E-10,0.36
"def _format_repos(self, value):<tab>result = {}<tab>if value:<tab><tab>for path, config in iteritems(value):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># assume its a module<tab><tab><tab><tab>path = os.path.abspath(__import__(path).__file__)<tab><tab><tab>result[path] = config<tab>return result",0,"if path [ 0 ] != ""/"" :",if not os . path . isabs ( path ) :,0.016408311,4.932351569,0.252747253
"def skipIndent(self, s, i, width):<tab>ws = 0<tab>n = len(s)<tab>while i < n and ws < width:<tab><tab><IF-STMT><tab><tab><tab>ws += abs(self.tab_width) - (ws % abs(self.tab_width))<tab><tab>elif s[i] == "" "":<tab><tab><tab>ws += 1<tab><tab>else:<tab><tab><tab>break<tab><tab>i += 1<tab>return i",1,"if s [ i ] == ""\t"" :","if s [ i ] == ""\t"" :",0.75,100,1
"def get_assets_historical_range_close_price(<tab>self, start_dt, end_dt, asset_symbols, adjusted=False):<tab>"""""" """"""<tab>prices_df = None<tab>for ds in self.data_sources:<tab><tab>try:<tab><tab><tab>prices_df = ds.get_assets_historical_closes(<tab><tab><tab><tab>start_dt, end_dt, asset_symbols, adjusted=adjusted<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return prices_df<tab><tab>except Exception:<tab><tab><tab>raise<tab>return prices_df",1,if prices_df is not None :,if prices_df is not None :,0.75,100,1
"def matchBrackets(string):<tab>rest = string[1:]<tab>inside = ""(""<tab>while rest != """" and not rest.startswith("")""):<tab><tab><IF-STMT><tab><tab><tab>(part, rest) = matchBrackets(rest)<tab><tab><tab>inside = inside + part<tab><tab>else:<tab><tab><tab>inside = inside + rest[0]<tab><tab><tab>rest = rest[1:]<tab>if rest.startswith("")""):<tab><tab>return (inside + "")"", rest[1:])<tab>raise AssertionError(""Unmatched bracket in string '"" + string + ""'"")",0,"if rest . startswith ( ""("" ) :",if len ( rest ) == 2 :,0.021251795,6.379653897,0.314814815
"def is_different(item, seen):<tab>is_diff = True<tab>if item not in seen:<tab><tab>for value in other:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>is_diff = False<tab><tab><tab><tab>break<tab><tab>if is_diff:<tab><tab><tab>seen.append(item)<tab>return is_diff",0,"if comparator ( iteratee ( item ) , iteratee ( value ) ) :",if item != value :,0.008779817,3.025764129,0.307017544
"def write_conditional_formatting(worksheet):<tab>""""""Write conditional formatting to xml.""""""<tab>wb = worksheet.parent<tab>for range_string, rules in iteritems(worksheet.conditional_formatting.cf_rules):<tab><tab>cf = Element(""conditionalFormatting"", {""sqref"": range_string})<tab><tab>for rule in rules:<tab><tab><tab>if rule.dxf is not None:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>rule.dxfId = len(wb._differential_styles)<tab><tab><tab><tab><tab>wb._differential_styles.append(rule.dxf)<tab><tab><tab>cf.append(rule.to_tree())<tab><tab>yield cf",0,if rule . dxf != DifferentialStyle ( ) :,if rule . dxfId is None :,0.067589311,17.11271706,0.361111111
"def checkForFinishedThreads(self):<tab>""Mark terminated threads with endTime.""<tab>for t in self.unfinishedThreads:<tab><tab><IF-STMT><tab><tab><tab>t.endTime = time.process_time()<tab><tab><tab>if getattr(t, ""status"", None) is None:<tab><tab><tab><tab>t.status = ""ended""",0,if not t . is_alive ( ) :,"if getattr ( t , ""endTime"" , None ) is None :",0.01723566,4.444587795,0.4
"def _process_dispatch_entries(self, dispatch_info_external):<tab>path_only_entries = []<tab>hostname_entries = []<tab>for entry in dispatch_info_external.dispatch:<tab><tab>parsed_url = dispatchinfo.ParsedURL(entry.url)<tab><tab><IF-STMT><tab><tab><tab>hostname_entries.append(entry)<tab><tab>else:<tab><tab><tab>path_only_entries.append((parsed_url, entry.server))<tab>if hostname_entries:<tab><tab>logging.warning(<tab><tab><tab>""Hostname routing is not supported by the development server. The ""<tab><tab><tab>""following dispatch entries will not match any requests:\n%s"",<tab><tab><tab>""\n\t"".join(str(entry) for entry in hostname_entries),<tab><tab>)<tab>self._entries = path_only_entries",0,if parsed_url . host :,if parsed_url is None :,0.064978772,43.47208719,0.36
"def iter_ReassignParameters(self, inputNode, variables, nodeByID):<tab>for node in inputNode.getReassignParameterNodes(nodeByID):<tab><tab>yield from iterNodeCommentLines(node)<tab><tab>yield from iterInputConversionLines(node, variables)<tab><tab>socket = node.inputs[0]<tab><tab><IF-STMT><tab><tab><tab>expression = getCopyExpression(socket, variables)<tab><tab>else:<tab><tab><tab>expression = variables[socket]<tab><tab>if node.conditionSocket is None:<tab><tab><tab>conditionPrefix = """"<tab><tab>else:<tab><tab><tab>conditionPrefix = ""if {}: "".format(variables[node.conditionSocket])<tab><tab>yield ""{}{} = {}"".format(<tab><tab><tab>conditionPrefix, variables[node.linkedParameterSocket], expression<tab><tab>)",0,if socket . isUnlinked and socket . isCopyable ( ) :,if node . linkedParameterSocket is None :,0.106980836,4.880869806,0.190909091
"def _feed_data(self, data_pair: types.Sequence, type_: str) -> types.Sequence:<tab>result = []<tab>type_list = [ChartType.LINES, ChartType.CUSTOM]<tab>if type_ in type_list:<tab><tab>result = data_pair<tab>else:<tab><tab>for n, v in data_pair:<tab><tab><tab>try:<tab><tab><tab><tab>lng, lat = self.get_coordinate(n)<tab><tab><tab><tab>result.append({""name"": n, ""value"": [lng, lat, v]})<tab><tab><tab>except TypeError as err:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise NonexistentCoordinatesException(err, (n, v))<tab>return result",0,if self . _is_ignore_nonexistent_coord is not True :,if n not in type_list :,0.061497411,3.255629779,0.232142857
"def _parse_whois(self, txt):<tab>asn, desc = None, b""""<tab>for l in txt.splitlines():<tab><tab>if not asn and l.startswith(b""origin:""):<tab><tab><tab>asn = l[7:].strip().decode(""utf-8"")<tab><tab>if l.startswith(b""descr:""):<tab><tab><tab>if desc:<tab><tab><tab><tab>desc += br""\n""<tab><tab><tab>desc += l[6:].strip()<tab><tab><IF-STMT><tab><tab><tab>desc = desc.strip().decode(""utf-8"")<tab><tab><tab>break<tab>return asn, desc",0,if asn is not None and desc . strip ( ) :,"if l . startswith ( b""description:"" ) :",0.046132689,8.516593019,0.146853147
"def _resolve_result(self, f=None):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>results = f.result()<tab><tab>else:<tab><tab><tab>results = list(map(self._client.results.get, self.msg_ids))<tab><tab>if self._single_result:<tab><tab><tab>r = results[0]<tab><tab><tab>if isinstance(r, Exception):<tab><tab><tab><tab>raise r<tab><tab>else:<tab><tab><tab>results = error.collect_exceptions(results, self._fname)<tab><tab>self._success = True<tab><tab>self.set_result(self._reconstruct_result(results))<tab>except Exception as e:<tab><tab>self._success = False<tab><tab>self.set_exception(e)",1,if f :,if f :,0.531170663,1.00E-10,1
"def new_org(type=ORG_DEFAULT, block=True, **kwargs):<tab>if type == ORG_DEFAULT:<tab><tab>org = reserve_pooled(type=type, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>org = queue.reserve(""queued_org"", block=block, type=type, **kwargs)<tab><tab>if org:<tab><tab><tab>new_pooled()<tab><tab><tab>return org<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.initialize()<tab><tab>org.commit()<tab><tab>return org<tab>else:<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.queue_initialize(block=block)<tab><tab>return org",1,if not org :,if not org :,0.75,100,1
"def _compileRules(rulesList, maxLength=4):<tab>ruleChecking = collections.defaultdict(list)<tab>for ruleIndex in range(len(rulesList)):<tab><tab>args = []<tab><tab><IF-STMT><tab><tab><tab>args = rulesList[ruleIndex][-1]<tab><tab>if maxLength == 4:<tab><tab><tab>(shouldRunMethod, method, isCorrect) = rulesList[ruleIndex][0:3]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, isCorrect, args))<tab><tab>elif maxLength == 3:<tab><tab><tab>(shouldRunMethod, method) = rulesList[ruleIndex][0:2]<tab><tab><tab>ruleChecking[shouldRunMethod].append((method, args))<tab>return ruleChecking",0,if len ( rulesList [ ruleIndex ] ) == maxLength :,if len ( rulesList [ ruleIndex ] ) > 1 :,0.476998399,63.81941797,0.714285714
"def setHighlightedItem(self, item):<tab>if item != None:<tab><tab>for listItem in self.children.getItems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.children.setCurrentItem(listItem)<tab><tab><tab><tab>return<tab>else:<tab><tab>self.children.setCurrentItem(None)",0,"if self . loadHandler . matchesItem ( listItem , item ) :",if listItem . getHighlightedItem ( ) == item :,0.014204096,5.588084775,0.232142857
"def getForts(location):<tab>global forts<tab>lforts = []<tab>for i in forts:<tab><tab>f = (i[""latitude""], i[""longitude""])<tab><tab>d = vincenty(location, f).meters<tab><tab><IF-STMT><tab><tab><tab>lforts.append(i)<tab>return lforts",0,if d < 900 :,if d > 0 :,0.314978772,23.64354023,0.6
"def page_file(self, page):<tab>if page.isroot:<tab><tab>raise PathLookupError(""Can not export: %s"", page)<tab>elif self.namespace:<tab><tab><IF-STMT><tab><tab><tab>name = page.relname(self.namespace)<tab><tab>else:<tab><tab><tab># This layout can not store page == namespace !<tab><tab><tab>raise PathLookupError(""%s not a child of %s"" % (page, self.namespace))<tab>else:<tab><tab>name = page.name<tab>return self.dir.file(encode_filename(name) + ""."" + self.ext)",1,if page . ischild ( self . namespace ) :,if page . ischild ( self . namespace ) :,0.75,100,1
"def to_json_dict(self):<tab>d = super().to_json_dict()<tab>if self.header is not None:<tab><tab>if isinstance(self.header, RenderedContent):<tab><tab><tab>d[""header""] = self.header.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""header""] = self.header<tab>if self.subheader is not None:<tab><tab><IF-STMT><tab><tab><tab>d[""subheader""] = self.subheader.to_json_dict()<tab><tab>else:<tab><tab><tab>d[""subheader""] = self.subheader<tab>d[""text""] = RenderedContent.rendered_content_list_to_json(self.text)<tab>return d",1,"if isinstance ( self . subheader , RenderedContent ) :","if isinstance ( self . subheader , RenderedContent ) :",0.75,100,1
"def fixfunnychars(addr):<tab>i = 0<tab>while i < len(addr):<tab><tab>c = addr[i]<tab><tab><IF-STMT><tab><tab><tab>c = ""-""<tab><tab><tab>addr = addr[:i] + c + addr[i + 1 :]<tab><tab>i = i + len(c)<tab>return addr",0,if c not in goodchars :,"if c == ""-"" :",0.051719732,12.22307556,0.4
"def refactor_stdin(self, doctests_only=False):<tab>input = sys.stdin.read()<tab>if doctests_only:<tab><tab>self.log_debug(""Refactoring doctests in stdin"")<tab><tab>output = self.refactor_docstring(input, ""<stdin>"")<tab><tab><IF-STMT><tab><tab><tab>self.processed_file(output, ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No doctest changes in stdin"")<tab>else:<tab><tab>tree = self.refactor_string(input, ""<stdin>"")<tab><tab>if self.write_unchanged_files or (tree and tree.was_changed):<tab><tab><tab>self.processed_file(str(tree), ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No changes in stdin"")",0,if self . write_unchanged_files or output != input :,if self . write_unchanged_files :,0.198507111,51.01469473,0.454545455
"def test_compute_gradient(self):<tab>for y, y_pred in zip(self.y_list, self.predict_list):<tab><tab>lse_grad = self.lae_loss.compute_grad(y, y_pred)<tab><tab>diff = y_pred - y<tab><tab><IF-STMT><tab><tab><tab>grad = 1<tab><tab>elif diff < consts.FLOAT_ZERO:<tab><tab><tab>grad = -1<tab><tab>else:<tab><tab><tab>grad = 0<tab><tab>self.assertTrue(np.fabs(lse_grad - grad) < consts.FLOAT_ZERO)",1,if diff > consts . FLOAT_ZERO :,if diff > consts . FLOAT_ZERO :,0.75,100,1
"def restart(self):<tab>try:<tab><tab># remove old pidfile first<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.daemon.stop()<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>pass<tab><tab>except:<tab><tab><tab>self.log.critical(traceback.format_exc())<tab><tab># Release log files and shutdown logger<tab><tab>logging.shutdown()<tab><tab>args = (<tab><tab><tab>[sys.executable]<tab><tab><tab>+ [os.path.join(base_path, os.path.basename(__file__))]<tab><tab><tab>+ sys.argv[1:]<tab><tab>)<tab><tab>subprocess.Popen(args)<tab>except:<tab><tab>self.log.critical(traceback.format_exc())",0,if self . runAsDaemon ( ) :,if self . daemon is not None :,0.083577801,22.08959113,0.321428571
"def classifyws(s, tabwidth):<tab>raw = effective = 0<tab>for ch in s:<tab><tab><IF-STMT><tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = effective + 1<tab><tab>elif ch == ""\t"":<tab><tab><tab>raw = raw + 1<tab><tab><tab>effective = (effective // tabwidth + 1) * tabwidth<tab><tab>else:<tab><tab><tab>break<tab>return raw, effective",1,"if ch == "" "" :","if ch == "" "" :",0.75,100,1
"def code_match(code, select, ignore):<tab>if ignore:<tab><tab>assert not isinstance(ignore, unicode)<tab><tab>for ignored_code in [c.strip() for c in ignore]:<tab><tab><tab>if mutual_startswith(code.lower(), ignored_code.lower()):<tab><tab><tab><tab>return False<tab>if select:<tab><tab>assert not isinstance(select, unicode)<tab><tab>for selected_code in [c.strip() for c in select]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab>return False<tab>return True",0,"if mutual_startswith ( code . lower ( ) , selected_code . lower ( ) ) :","if mutual_starts ( code . lower ( ) , selected_code . lower ( ) ) :",0.938804547,85.78928093,1
"def get_tokens_unprocessed(self, text):<tab>from pygments.lexers._asy_builtins import ASYFUNCNAME, ASYVARNAME<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab><IF-STMT><tab><tab><tab>token = Name.Function<tab><tab>elif token is Name and value in ASYVARNAME:<tab><tab><tab>token = Name.Variable<tab><tab>yield index, token, value",1,if token is Name and value in ASYFUNCNAME :,if token is Name and value in ASYFUNCNAME :,0.75,100,1
"def makeDataURI(data=None, mimetype=None, filename=None):<tab>import base64<tab>if not mimetype:<tab><tab><IF-STMT><tab><tab><tab>import mimetypes<tab><tab><tab>mimetype = mimetypes.guess_type(filename)[0].split("";"")[0]<tab><tab>else:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""You need to provide a mimetype or a filename for makeDataURI""<tab><tab><tab>)<tab>return ""data:"" + mimetype + "";base64,"" + """".join(base64.encodestring(data).split())",1,if filename :,if filename :,0.531170663,1.00E-10,1
"def add_attributes(attributes, all_base64):<tab>lines = []<tab>oc_attr = None<tab># objectclass first, even if this is not specified in the RFC<tab>for attr in attributes:<tab><tab><IF-STMT><tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab><tab><tab>oc_attr = attr<tab><tab><tab>break<tab># remaining attributes<tab>for attr in attributes:<tab><tab>if attr != oc_attr and attr in attributes:<tab><tab><tab>for val in attributes[attr]:<tab><tab><tab><tab>lines.append(_convert_to_ldif(attr, val, all_base64))<tab>return lines",0,"if attr . lower ( ) == ""objectclass"" :",if attr != oc_attr and attr in attributes :,0.029848275,8.054496385,0.333333333
"def read_optional_seed(fill, base="""", ext="""", timeout=5):<tab>try:<tab><tab>(md, ud, vd) = read_seeded(base, ext, timeout)<tab><tab>fill[""user-data""] = ud<tab><tab>fill[""vendor-data""] = vd<tab><tab>fill[""meta-data""] = md<tab><tab>return True<tab>except url_helper.UrlError as e:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>raise",0,if e . code == url_helper . NOT_FOUND :,if e . errno != errno . ENOENT :,0.319332252,12.45123373,0.466666667
"def _get_spawn_property(self, constraints, constraint_name, services):<tab>if services:<tab><tab># this isn't very nice<tab><tab>if constraint_name == IMAGE_CONSTRAINT:<tab><tab><tab>return services[0].image<tab><tab><IF-STMT><tab><tab><tab>return services[0].cpus<tab>for constraint in constraints:<tab><tab>if constraint.name == constraint_name:<tab><tab><tab>return constraint.value<tab>return None",0,elif constraint_name == CPUS_CONSTRAINT :,elif constraint_name == CPU_CONSTRAINT :,0.642872021,65.80370065,1
def delete_api(self):<tab>retries = 0<tab>while retries < 10:<tab><tab>try:<tab><tab><tab>self.client.delete_rest_api(restApiId=self.api_id)<tab><tab><tab>break<tab><tab>except exceptions.ClientError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retries += 1<tab><tab><tab><tab>time.sleep(5)<tab><tab><tab>else:<tab><tab><tab><tab>raise,0,"if e . response [ ""Error"" ] [ ""Code"" ] == ""TooManyRequestsException"" :","if e . response [ ""Error"" ] [ ""Code"" ] == ""AccessDeniedException"" :",0.67220614,87.39351325,1
"def GetSelected(self):<tab>if self.GetStyleL(""style"") & self.Style.LBS_MULTIPLESEL:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETSELCOUNT, 0, 0)<tab><tab><IF-STMT><tab><tab><tab>return self.SendMessage(self.Hwnd, self.Msg.LB_GETANCHORINDEX, 0, 0)<tab>else:<tab><tab>result = self.SendMessage(self.Hwnd, self.Msg.LB_GETCURSEL, 0, 0)<tab><tab>if result != LB_ERR:<tab><tab><tab>return result",0,if result :,if result != LB_ERR :,0.097914534,1.00E-10,1
"def compare_objects(left, right):<tab>left_fields = left.map_value.fields<tab>right_fields = right.map_value.fields<tab>for left_key, right_key in zip(sorted(left_fields), sorted(right_fields)):<tab><tab>keyCompare = Order._compare_to(left_key, right_key)<tab><tab>if keyCompare != 0:<tab><tab><tab>return keyCompare<tab><tab>value_compare = Order.compare(left_fields[left_key], right_fields[right_key])<tab><tab><IF-STMT><tab><tab><tab>return value_compare<tab>return Order._compare_to(len(left_fields), len(right_fields))",1,if value_compare != 0 :,if value_compare != 0 :,0.75,100,1
"def get_opnd_types_short(ii):<tab>types = []<tab>for op in _gen_opnds(ii):<tab><tab>if op.oc2:<tab><tab><tab>types.append(op.oc2)<tab><tab><IF-STMT><tab><tab><tab>types.append(""v"")<tab><tab>elif op_luf_start(op, ""GPRz""):<tab><tab><tab>types.append(""z"")<tab><tab>elif op_luf_start(op, ""GPRy""):<tab><tab><tab>types.append(""y"")<tab><tab>else:<tab><tab><tab>die(""Unhandled op type {}"".format(op))<tab>return types",0,"elif op_luf_start ( op , ""GPRv"" ) :","elif op_luf_start ( op , ""v"" ) :",0.547301779,78.254229,1
"def _iter_indented_subactions(self, action):<tab>try:<tab><tab>get_subactions = action._get_subactions<tab>except AttributeError:<tab><tab>pass<tab>else:<tab><tab>self._indent()<tab><tab><IF-STMT><tab><tab><tab>for subaction in sorted(get_subactions(), key=lambda x: x.dest):<tab><tab><tab><tab>yield subaction<tab><tab>else:<tab><tab><tab>for subaction in get_subactions():<tab><tab><tab><tab>yield subaction<tab><tab>self._dedent()",0,"if isinstance ( action , argparse . _SubParsersAction ) :",if get_subactions :,0.010867398,1.00E-10,0.36
"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if type(value) in (bool, int, float, complex, range_type, Markup) + string_types:<tab><tab>return True<tab>if type(value) in (tuple, list, set, frozenset):<tab><tab>for item in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>elif type(value) is dict:<tab><tab>for key, value in iteritems(value):<tab><tab><tab>if not has_safe_repr(key):<tab><tab><tab><tab>return False<tab><tab><tab>if not has_safe_repr(value):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",1,if not has_safe_repr ( item ) :,if not has_safe_repr ( item ) :,0.75,100,1
"def _compute_missing_fields_error(context, field_defs, incoming_fields):<tab>missing_fields = []<tab>for field_name, field_def in field_defs.items():<tab><tab><IF-STMT><tab><tab><tab>missing_fields.append(field_name)<tab>if missing_fields:<tab><tab>if len(missing_fields) == 1:<tab><tab><tab>return create_missing_required_field_error(context, missing_fields[0])<tab><tab>else:<tab><tab><tab>return create_missing_required_fields_error(context, missing_fields)",0,if not field_def . is_optional and field_name not in incoming_fields :,if field_def not in incoming_fields :,0.268240044,27.46784936,0.504761905
"def _list(self):<tab>data_sources = self.mkt_contract.functions.getAllProviders().call()<tab>data = []<tab>for index, data_source in enumerate(data_sources):<tab><tab><IF-STMT><tab><tab><tab>if ""test"" not in Web3.toText(data_source).lower():<tab><tab><tab><tab>data.append(dict(dataset=self.to_text(data_source)))<tab>return pd.DataFrame(data)",0,if index > 0 :,if index == 0 :,0.331415021,22.95748847,1
"def close_file_in_all_editorstacks(self, editorstack_id_str, index):<tab>for editorstack in self.editorstacks:<tab><tab><IF-STMT><tab><tab><tab>editorstack.blockSignals(True)<tab><tab><tab>editorstack.close_file(index, force=True)<tab><tab><tab>editorstack.blockSignals(False)",0,if str ( id ( editorstack ) ) != editorstack_id_str :,if editorstack . id == editorstack_id_str :,0.025832773,40.39488481,0.586666667
"def _remove_custom_marker_object_instances(self):<tab>for id, obj in list(self._objects.items()):<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Removing CustomObject instance: id %s = obj '%s'"", id, obj)<tab><tab><tab>del self._objects[id]",0,"if isinstance ( obj , objects . CustomObject ) :","if isinstance ( obj , CustomObject ) :",0.26825443,53.84952356,0.651515152
"def append(self, labels):<tab>if isinstance(labels, list):<tab><tab>for label in labels:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__menuLabels.append(label)<tab><tab><tab><tab>self.__enabledLabels.append(label)<tab>else:<tab><tab>if not labels in self.__menuLabels:<tab><tab><tab>self.__menuLabels.append(labels)<tab><tab><tab>self.__enabledLabels.append(labels)",0,if not label in self . __menuLabels :,if label not in self . __menuLabels :,0.540715368,69.85342057,0.666666667
"def _close_tree(view: View, defx: Defx, context: Context) -> None:<tab>for target in context.targets:<tab><tab><IF-STMT><tab><tab><tab>view.close_tree(target[""action__path""], defx._index)<tab><tab>else:<tab><tab><tab>view.close_tree(target[""action__path""].parent, defx._index)<tab><tab><tab>view.search_file(target[""action__path""].parent, defx._index)",0,"if target [ ""is_directory"" ] and target [ ""is_opened_tree"" ] :","if isinstance ( target , dict ) :",0.013374522,1.431131255,0.333333333
"def FirstFetch(self):<tab>q = collections.deque([""buddy"", ""group"", ""discuss""])<tab>while q:<tab><tab>tinfo = q.popleft()<tab><tab><IF-STMT><tab><tab><tab>cl = self.List(tinfo)<tab><tab><tab>if cl:<tab><tab><tab><tab>q.extend(cl)<tab><tab>time.sleep(1.0)",0,"if self . Update ( tinfo ) and tinfo in ( ""group"" , ""discuss"" ) :",if tinfo :,0.005221215,1.00E-10,0.254658385
"def _sort_values_jobconf(self):<tab>""""""Jobconf dictionary to enable sorting by value.""""""<tab>if not self._sort_values:<tab><tab>return {}<tab># translate _SORT_VALUES_JOBCONF to the correct Hadoop version,<tab># without logging a warning<tab>hadoop_version = self.get_hadoop_version()<tab>jobconf = {}<tab>for k, v in _SORT_VALUES_JOBCONF.items():<tab><tab><IF-STMT><tab><tab><tab>jobconf[translate_jobconf(k, hadoop_version)] = v<tab><tab>else:<tab><tab><tab>for j in translate_jobconf_for_all_versions(k):<tab><tab><tab><tab>jobconf[j] = v<tab>return jobconf",1,if hadoop_version :,if hadoop_version :,0.531170663,1.00E-10,1
"def list(self):<tab>for fname in os.listdir(self.path):<tab><tab>fpath = os.path.join(self.path, fname)<tab><tab><IF-STMT><tab><tab><tab>yield fname, get_etag_from_file(fpath)",0,if os . path . isfile ( fpath ) and fname . endswith ( self . fileext ) :,if os . path . isfile ( fpath ) :,0.318131696,37.83557009,0.5256917
"def get_environment_variable_value(val):<tab>env_val = val<tab>if val is not None and isinstance(val, str):<tab><tab>match = re.search(r""^\${(?P<environment_key_name>\w+)*}$"", val)<tab><tab><IF-STMT><tab><tab><tab>env_val = os.environ.get(match.group(""environment_key_name""))<tab>return env_val",0,if match is not None :,if match :,0.050438393,1.00E-10,0.4
"def L_op(self, inputs, outputs, grads):<tab>(x,) = inputs<tab>(gz,) = grads<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>cst = np.asarray(np.sqrt(np.pi) / 2.0, dtype=upcast(x.type.dtype, gz.type.dtype))<tab>return (gz * cst * exp(erfinv(x) ** 2),)",1,if x . type in discrete_types :,if x . type in discrete_types :,0.75,100,1
"def is_test_finished(self):<tab>retcode = self.process.poll()<tab>if retcode is not None:<tab><tab>logger.info(""Phantom done its work with exit code: %s"", retcode)<tab><tab>self.phout_finished.set()<tab><tab>return abs(retcode)<tab>else:<tab><tab>info = self.get_info()<tab><tab><IF-STMT><tab><tab><tab>eta = int(info.duration) - (int(time.time()) - int(self.start_time))<tab><tab><tab>self.publish(""eta"", eta)<tab><tab>return -1",0,if info :,if info is not None :,0.090364769,1.00E-10,0.4
"def icon(display_icon):<tab>""""""returns empty dict if show_icons is False, else the icon passed""""""<tab>kws = {}<tab>if get_icon_switch():<tab><tab><IF-STMT><tab><tab><tab>kws = {""icon_value"": custom_icon(display_icon)}<tab><tab>elif display_icon != ""OUTLINER_OB_EMPTY"":<tab><tab><tab>kws = {""icon"": display_icon}<tab>return kws",0,"if display_icon . startswith ( ""SV_"" ) :","if display_icon != ""INLINER_OB_EMPTY"" :",0.035401841,21.14214171,0.641025641
"def raise_to_cubic(bzs):<tab>result = []<tab>for sp in bzs:<tab><tab>r = []<tab><tab>for bz in sp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>r.append(<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>bz[0],<tab><tab><tab><tab><tab><tab>lerppt(2.0 / 3, bz[0], bz[1]),<tab><tab><tab><tab><tab><tab>lerppt(2.0 / 3, bz[2], bz[1]),<tab><tab><tab><tab><tab><tab>bz[2],<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>r.append(bz)<tab><tab>result.append(r)<tab>return result",1,if len ( bz ) == 3 :,if len ( bz ) == 3 :,0.75,100,1
def readline(self):<tab>while 1:<tab><tab>line = self._readline()<tab><tab>if line:<tab><tab><tab>self._filelineno += 1<tab><tab><tab>return line<tab><tab><IF-STMT><tab><tab><tab>return line<tab><tab>self.nextfile(),0,if not self . _file :,elif self . _filelineno == self . _maxline :,0.1183863,13.54599427,0.333333333
"def readlines(self):<tab>""""""Returns a list of all lines (optionally parsed) in the file.""""""<tab>if self.grammar:<tab><tab>tot = []<tab><tab># Used this way instead of a 'for' loop against<tab><tab># self.file.readlines() so that there wasn't two copies of the file<tab><tab># in memory.<tab><tab>while 1:<tab><tab><tab>line = self.file.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>tot.append(line)<tab><tab>return tot<tab>return self.file.readlines()",1,if not line :,if not line :,0.75,100,1
"def visit_return(self, node):<tab># TODO: pythoncile.py handled (a) spliting CITDL (scoperef), (b)<tab>#<tab>  excluding ""None"" and ""NoneType"", (c) True/False -> bool.<tab>#<tab>  pythoncile.py also gather all return's and picked the most<tab>#<tab>  common guess.<tab># TODO:XXX Evaluate the necessity of multiple return statement analysis.<tab>scope = self._peek_scope()<tab>assert scope.ilk == ""function""<tab>if not scope.get(""returns""):<tab><tab>citdl = self._citdl_from_node(node.children[1])<tab><tab><IF-STMT><tab><tab><tab>scope.attrs[""returns""] = citdl",0,"if citdl and citdl is not ""None"" :",if citdl is not None :,0.215742068,20.41528032,0.352380952
"def load_json_file(file_path):<tab>""""""load a file into a json object""""""<tab>try:<tab><tab>with open(file_path) as small_file:<tab><tab><tab>return json.load(small_file)<tab>except OSError as e:<tab><tab>print(e)<tab><tab>print(""trying to read file in blocks"")<tab><tab>with open(file_path) as big_file:<tab><tab><tab>json_string = """"<tab><tab><tab>while True:<tab><tab><tab><tab>block = big_file.read(64 * (1 << 20))  # Read 64 MB at a time;<tab><tab><tab><tab>json_string = json_string + block<tab><tab><tab><tab><IF-STMT>  # Reached EOF<tab><tab><tab><tab><tab>break<tab><tab><tab>return json.loads(json_string)",1,if not block :,if not block :,0.75,100,1
"def rotate(cls, axis, theta):<tab>""""""Prepare a quaternion that represents a rotation on a given axis.""""""<tab>if isinstance(axis, str):<tab><tab>if axis in (""x"", ""X""):<tab><tab><tab>axis = V.X<tab><tab><IF-STMT><tab><tab><tab>axis = V.Y<tab><tab>elif axis in (""z"", ""Z""):<tab><tab><tab>axis = V.Z<tab>axis = axis.normalize()<tab>s = math.sin(theta / 2.0)<tab>c = math.cos(theta / 2.0)<tab>return Q(axis._v[0] * s, axis._v[1] * s, axis._v[2] * s, c)",1,"elif axis in ( ""y"" , ""Y"" ) :","elif axis in ( ""y"" , ""Y"" ) :",0.75,100,1
"def is_valid_block(self):<tab>""""""check wheter the block is valid in the current position""""""<tab>for i in range(self.block.x):<tab><tab>for j in range(self.block.x):<tab><tab><tab>if self.block.get(i, j):<tab><tab><tab><tab>if self.block.pos.x + i < 0:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.block.pos.x + i >= COLUMNS:<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if self.map.get((self.block.pos.x + i, self.block.pos.y + j), False):<tab><tab><tab><tab><tab>return False<tab>return True",0,if self . block . pos . y + j < 0 :,if self . block . pos . y + j >= COLUMNS :,0.486088195,69.30977286,0.777777778
def dump_token_list(tokens):<tab>for token in tokens:<tab><tab>if token.token_type == TOKEN_TEXT:<tab><tab><tab>writer.write(token.contents)<tab><tab><IF-STMT><tab><tab><tab>writer.print_expr(token.contents)<tab><tab><tab>touch_var(token.contents),1,elif token . token_type == TOKEN_VAR :,elif token . token_type == TOKEN_VAR :,1,100,1
"def encode(name, value):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>value, params = value<tab><tab><tab>return _encode_parametrized(name, value, params)<tab><tab>return _encode_unstructured(name, value)<tab>except Exception:<tab><tab>_log.exception(""Failed to encode %s %s"" % (name, value))<tab><tab>raise",0,"if parametrized . is_parametrized ( name , value ) :","if isinstance ( value , tuple ) :",0.092890517,8.816389212,0.285714286
"def conversation_to_fb_format(conversation):<tab>assert len(conversation) > 1<tab>lines = []<tab>for i in range(0, len(conversation), 2):<tab><tab><IF-STMT><tab><tab><tab>lines.append(<tab><tab><tab><tab>""%d %s\t%s"" % (i / 2 + 1, conversation[i], conversation[i + 1])<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>lines.append(""%d %s"" % (i / 2 + 1, conversation[i]))<tab>return ""\n"".join(lines)",0,if i + 1 < len ( conversation ) :,if i % 2 == 0 :,0.026620514,9.519340818,0.363636364
"def _handle_js_events(self, change):<tab>if self.js_events:<tab><tab><IF-STMT><tab><tab><tab>for event in self.js_events:<tab><tab><tab><tab>event_name = event[""name""]<tab><tab><tab><tab>if event_name in self.event_handlers:<tab><tab><tab><tab><tab>self.event_handlers[event_name](event[""detail""])<tab><tab># clears the event queue.<tab><tab>self.js_events = []",0,if self . event_handlers :,if self . js_events :,0.394778655,27.77619034,1
"def escapeall(self, lines):<tab>""Escape all lines in an array according to the output options.""<tab>result = []<tab>for line in lines:<tab><tab>if Options.html:<tab><tab><tab>line = self.escape(line, EscapeConfig.html)<tab><tab>if Options.iso885915:<tab><tab><tab>line = self.escape(line, EscapeConfig.iso885915)<tab><tab><tab>line = self.escapeentities(line)<tab><tab><IF-STMT><tab><tab><tab>line = self.escape(line, EscapeConfig.nonunicode)<tab><tab>result.append(line)<tab>return result",0,elif not Options . unicode :,if Options . nonunicode :,0.149623555,19.35769349,0.114285714
"def filter_testsuite(suite, matcher, level=None):<tab>""""""Returns a flattened list of test cases that match the given matcher.""""""<tab>if not isinstance(suite, unittest.TestSuite):<tab><tab>raise TypeError(""not a TestSuite"", suite)<tab>results = []<tab>for test in suite._tests:<tab><tab>if level is not None and getattr(test, ""level"", 0) > level:<tab><tab><tab>continue<tab><tab>if isinstance(test, unittest.TestCase):<tab><tab><tab>testname = test.id()  # package.module.class.method<tab><tab><tab><IF-STMT><tab><tab><tab><tab>results.append(test)<tab><tab>else:<tab><tab><tab>filtered = filter_testsuite(test, matcher, level)<tab><tab><tab>results.extend(filtered)<tab>return results",1,if matcher ( testname ) :,if matcher ( testname ) :,0.75,100,1
"def _close_brackets(self, fragment):<tab># If there any unclosed brackets in the text we try to close them<tab># and we return part with closing brackets if they are ""closable""<tab>stack = []<tab>for char in fragment:<tab><tab>if char in self._PARENS.keys():<tab><tab><tab>stack.append(char)<tab><tab><IF-STMT><tab><tab><tab>if stack and self._PARENS[stack[-1]] == char:<tab><tab><tab><tab>stack.pop()<tab><tab><tab>else:<tab><tab><tab><tab>return """"<tab>return """".join(self._PARENS[paren] for paren in reversed(stack))",0,elif char in self . _PARENS . values ( ) :,elif char in self . _PARENS . keys ( ) :,0.602001933,73.48889201,0.714285714
"def restrict(points):<tab>result = []<tab>for p in points:<tab><tab>if point_inside_mesh(bvh, p):<tab><tab><tab>result.append(p)<tab><tab>else:<tab><tab><tab>loc, normal, index, distance = bvh.find_nearest(p)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result.append(tuple(loc))<tab>return result",1,if loc is not None :,if loc is not None :,0.75,100,1
"def _check_ids(el, filename, parent_id):<tab>""""""Recursively walks through tree and check if every object has ID""""""<tab>for child in el:<tab><tab>if child.tag == ""object"":<tab><tab><tab>msg = ""Widget has no ID in %s; class %s; Parent id: %s"" % (<tab><tab><tab><tab>filename,<tab><tab><tab><tab>child.attrib[""class""],<tab><tab><tab><tab>parent_id,<tab><tab><tab>)<tab><tab><tab>assert ""id"" in child.attrib and child.attrib[""id""], msg<tab><tab><tab>for subel in child:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>_check_ids(subel, filename, child.attrib[""id""])",0,"if subel . tag == ""child"" :","if subel . tag == ""object"" :",0.574113272,70.71067812,1
"def _checkIfSuccessfulCallback(self, result, error=False, **kwargs):<tab>if error:<tab><tab>connection_error = kwargs.get(""connection_error"", False)<tab><tab><IF-STMT><tab><tab><tab>log.debug(<tab><tab><tab><tab>""During direct file upload compute is not visible. Fallback to upload via controller.""<tab><tab><tab>)<tab><tab><tab># there was an issue with connection, probably we don't have a direct access to compute<tab><tab><tab># we need to fallback to uploading files via controller<tab><tab><tab>self._fileUploadToController()<tab><tab>else:<tab><tab><tab>if ""message"" in result:<tab><tab><tab><tab>log.error(<tab><tab><tab><tab><tab>""Error while direct file upload: {}"".format(result[""message""])<tab><tab><tab><tab>)<tab><tab>return<tab>self._callback(result, error, **kwargs)",1,if connection_error :,if connection_error :,0.531170663,1.00E-10,1
"def getCellPropertyNames_aux(self, col_id):<tab>if col_id == ""name"":<tab><tab><IF-STMT><tab><tab><tab>return [""places_busy""]<tab><tab>baseName = self.image_icon<tab><tab>if self.isOpen:<tab><tab><tab>return [baseName + ""_open""]<tab><tab>else:<tab><tab><tab>return [baseName + ""_closed""]<tab>return []",0,"if self . image_icon == ""places_busy"" :",if self . places_busy :,0.094532291,15.71901051,1
"def delete_volume(self, volume_id):<tab>if volume_id in self.volumes:<tab><tab>volume = self.volumes[volume_id]<tab><tab><IF-STMT><tab><tab><tab>raise VolumeInUseError(volume_id, volume.attachment.instance.id)<tab><tab>return self.volumes.pop(volume_id)<tab>raise InvalidVolumeIdError(volume_id)",0,if volume . attachment :,if volume . attachment . instance . id == volume . attachment . instance . id :,0.297956315,14.21664591,0.51010101
"def dashboards(self):<tab>dashboards = OrderedDict()<tab>for slug, path in enumerate(app_settings.DASHBOARDS):<tab><tab><IF-STMT><tab><tab><tab>slug, path = path<tab><tab>pk = str(slug)<tab><tab>klass = import_string(path)<tab><tab>dashboards[pk] = klass(pk=pk)<tab>if not dashboards:<tab><tab>raise ImproperlyConfigured(""No dashboards found."")<tab>return dashboards",0,"if isinstance ( path , ( list , tuple ) ) :","if isinstance ( path , tuple ) :",0.222424677,43.58579201,0.655555556
"def test_reader(config, device, logger):<tab>loader = build_dataloader(config, ""Train"", device, logger)<tab>import time<tab>starttime = time.time()<tab>count = 0<tab>try:<tab><tab>for data in loader():<tab><tab><tab>count += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>batch_time = time.time() - starttime<tab><tab><tab><tab>starttime = time.time()<tab><tab><tab><tab>logger.info(<tab><tab><tab><tab><tab>""reader: {}, {}, {}"".format(count, len(data[0]), batch_time)<tab><tab><tab><tab>)<tab>except Exception as e:<tab><tab>logger.info(e)<tab>logger.info(""finish reader: {}, Success!"".format(count))",0,if count % 1 == 0 :,if len ( data ) > 0 :,0.037585422,12.22307556,0.428571429
"def on_adapter_selected(self, menuitem, adapter_path):<tab>if menuitem.props.active:<tab><tab><IF-STMT><tab><tab><tab>logging.info(""selected %s"", adapter_path)<tab><tab><tab>self.blueman.Config[""last-adapter""] = adapter_path_to_name(adapter_path)<tab><tab><tab>self.blueman.List.set_adapter(adapter_path)",0,if adapter_path != self . blueman . List . Adapter . get_object_path ( ) :,if self . blueman . List . get_adapter ( adapter_path ) is None :,0.253203913,34.15140037,0.618421053
"def set_note_pinned(self, key, pinned):<tab>n = self.notes[key]<tab>old_pinned = utils.note_pinned(n)<tab>if pinned != old_pinned:<tab><tab><IF-STMT><tab><tab><tab>n[""systemtags""] = []<tab><tab>systemtags = n[""systemtags""]<tab><tab>if pinned:<tab><tab><tab># which by definition means that it was NOT pinned<tab><tab><tab>systemtags.append(""pinned"")<tab><tab>else:<tab><tab><tab>systemtags.remove(""pinned"")<tab><tab>n[""modifydate""] = time.time()<tab><tab>self.notify_observers(<tab><tab><tab>""change:note-status"",<tab><tab><tab>events.NoteStatusChangedEvent(what=""modifydate"", key=key),<tab><tab>)",1,"if ""systemtags"" not in n :","if ""systemtags"" not in n :",0.75,100,1
"def setMinCores(self, rpcObjects=None):<tab>tasks = self._getSelected(rpcObjects)<tab>if tasks:<tab><tab>current = max([task.data.min_cores for task in tasks])<tab><tab>title = ""Set Minimum Cores""<tab><tab>body = ""Please enter the new minimum cores value:""<tab><tab>(value, choice) = QtWidgets.QInputDialog.getDouble(<tab><tab><tab>self._caller, title, body, current, 0, 50000, 0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>for task in tasks:<tab><tab><tab><tab>task.setMinCores(float(value))<tab><tab><tab>self._update()",1,if choice :,if choice :,0.531170663,1.00E-10,1
"def _1_0_cloud_ips_cip_jsjc5(self, method, url, body, headers):<tab>if method == ""DELETE"":<tab><tab>return self.test_response(httplib.OK, """")<tab>elif method == ""PUT"":<tab><tab>body = json.loads(body)<tab><tab><IF-STMT><tab><tab><tab>return self.test_response(httplib.OK, """")<tab><tab>else:<tab><tab><tab>return self.test_response(<tab><tab><tab><tab>httplib.BAD_REQUEST, '{""error_name"":""bad dns"", ""errors"": [""Bad dns""]}'<tab><tab><tab>)",0,"if body . get ( ""reverse_dns"" , None ) == ""fred.co.uk"" :","if body [ ""status"" ] == ""ok"" :",0.022443571,8.339041344,0.577777778
"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None:<tab>child: xml.etree.ElementTree.Element<tab>for child in news_entry:<tab><tab>if ""title"" in child.tag:<tab><tab><tab>title = str(child.text)<tab><tab><IF-STMT><tab><tab><tab>pub_date = str(child.text)<tab><tab>if ""description"" in child.tag:<tab><tab><tab>description = str(child.text)<tab>print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"")<tab>print_stdout(format_paragraph(strip_tags(description)))<tab>print_stdout()",0,"if ""pubDate"" in child . tag :","if ""pub_date"" in child . tag :",0.574113272,51.93071779,1
"def oregon_battery(self, offset):<tab>nib = self.decoded_nibbles<tab>batt = ""OK""<tab>if nib[offset][3] != """":<tab><tab><IF-STMT><tab><tab><tab>batt = ""Low""<tab><tab>self.put(<tab><tab><tab>nib[offset][0], nib[offset][1], self.out_ann, [2, [""Batt "" + batt, batt]]<tab><tab>)",0,"if ( int ( nib [ offset ] [ 3 ] , 16 ) >> 2 ) & 0x1 == 1 :","if nib [ offset ] [ 3 ] == ""Batt"" :",0.171404491,24.63250084,0.183870968
"def body_stream() -> typing.AsyncGenerator[bytes, None]:<tab>while True:<tab><tab>message = await queue.get()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>assert message[""type""] == ""http.response.body""<tab><tab>yield message.get(""body"", b"""")<tab>task.result()",1,if message is None :,if message is None :,0.75,100,1
"def _wait_for_reboot():<tab>try:<tab><tab>state = self._conn.reboot_domain(instance[""name""])<tab><tab><IF-STMT><tab><tab><tab>LOG.debug(_(""instance %s: rebooted""), instance[""name""])<tab><tab><tab>timer.stop()<tab>except Exception:<tab><tab>LOG.exception(_(""_wait_for_reboot failed""))<tab><tab>timer.stop()",0,if state == power_state . RUNNING :,"if state == ""reboot"" :",0.094532291,28.46946938,0.722222222
"def _get_sequence_vector(<tab>sequence,<tab>tokenizer,<tab>format_dtype,<tab>unit_to_id,<tab>lowercase=True,<tab>unknown_symbol=UNKNOWN_SYMBOL,):<tab>unit_sequence = tokenizer(sequence.lower() if lowercase else sequence)<tab>unit_indices_vector = np.empty(len(unit_sequence), dtype=format_dtype)<tab>for i in range(len(unit_sequence)):<tab><tab>curr_unit = unit_sequence[i]<tab><tab><IF-STMT><tab><tab><tab>unit_indices_vector[i] = unit_to_id[curr_unit]<tab><tab>else:<tab><tab><tab>unit_indices_vector[i] = unit_to_id[unknown_symbol]<tab>return unit_indices_vector",1,if curr_unit in unit_to_id :,if curr_unit in unit_to_id :,0.75,100,1
"def forward(self, x: Tensor, edge_index: Adj) -> Tensor:<tab>""""""""""""<tab>if self.add_self_loops:<tab><tab>if isinstance(edge_index, Tensor):<tab><tab><tab>edge_index, _ = remove_self_loops(edge_index)<tab><tab><tab>edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(self.node_dim))<tab><tab><IF-STMT><tab><tab><tab>edge_index = set_diag(edge_index)<tab>x_norm = F.normalize(x, p=2.0, dim=-1)<tab># propagate_type: (x: Tensor, x_norm: Tensor)<tab>return self.propagate(edge_index, x=x, x_norm=x_norm, size=None)",0,"elif isinstance ( edge_index , SparseTensor ) :","elif isinstance ( edge_index , Tensor ) :",0.547301779,70.71067812,0.6
"def _init_req_settings(self, **kwargs):<tab>for req_attr in self._req_settings:<tab><tab>req_attr_value = kwargs.get(req_attr)<tab><tab><IF-STMT><tab><tab><tab>raise MissingRequiredConf(conf_name=req_attr_value)<tab><tab># Validate attribute value<tab><tab>req_attr_value = get_validator(req_attr)(req_attr_value)<tab><tab>self._settings[req_attr] = req_attr_value",1,if req_attr_value is None :,if req_attr_value is None :,0.75,100,1
"def delete(identifier, filenames=None, **kwargs):<tab>item = get_item(identifier)<tab>if filenames:<tab><tab>if not isinstance(filenames, (set, list)):<tab><tab><tab>filenames = [filenames]<tab><tab>for f in item.iter_files():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>f.delete(**kwargs)",0,if f . name not in filenames :,if f . identifier in filenames :,0.24392723,35.64026463,0.35
"def visit_decorator(self, o: Decorator) -> None:<tab>if self.is_private_name(o.func.name, o.func.fullname):<tab><tab>return<tab>is_abstract = False<tab>for decorator in o.original_decorators:<tab><tab>if isinstance(decorator, NameExpr):<tab><tab><tab>if self.process_name_expr_decorator(decorator, o):<tab><tab><tab><tab>is_abstract = True<tab><tab>elif isinstance(decorator, MemberExpr):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>is_abstract = True<tab>self.visit_func_def(o.func, is_abstract=is_abstract)",1,"if self . process_member_expr_decorator ( decorator , o ) :","if self . process_member_expr_decorator ( decorator , o ) :",0.75,100,1
"def split_trading_pair(trading_pair: str) -> Optional[Tuple[str, str]]:<tab>try:<tab><tab>m = RE_4_LETTERS_QUOTE.match(trading_pair)<tab><tab><IF-STMT><tab><tab><tab>m = RE_3_LETTERS_QUOTE.match(trading_pair)<tab><tab><tab>if m is None:<tab><tab><tab><tab>m = RE_2_LETTERS_QUOTE.match(trading_pair)<tab><tab>return m.group(1), m.group(2)<tab># Exceptions are now logged as warnings in trading pair fetcher<tab>except Exception:<tab><tab>return None",1,if m is None :,if m is None :,0.75,100,1
"def traverse_states(root):<tab>todo = [root]<tab>model = self.model<tab>while len(todo):<tab><tab>iter = todo.pop(0)<tab><tab># print model.value_path(iter, treeindex), model.get_state(iter, treeindex)<tab><tab>yield model.get_state(iter, treeindex)<tab><tab>path = model.get_path(iter)<tab><tab><IF-STMT><tab><tab><tab>children = []<tab><tab><tab>child = model.iter_children(iter)<tab><tab><tab>while child:<tab><tab><tab><tab>children.append(child)<tab><tab><tab><tab>child = model.iter_next(child)<tab><tab><tab>todo = children + todo<tab>yield None  # end marker",0,if treeview . row_expanded ( path ) :,if path == root :,0.019907918,5.484411596,0.4
"def as_list(<tab>self, compact=True, storage_to_dict=True, datetime_to_str=False, custom_types=None):<tab>if storage_to_dict:<tab><tab>items = []<tab><tab>for row in self:<tab><tab><tab>item = row.as_dict(datetime_to_str, custom_types)<tab><tab><tab>for jdata in self._joins_:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>item[jdata[0]] = row[jdata[0]].as_list()<tab><tab><tab>items.append(item)<tab>else:<tab><tab>items = [item for item in self]<tab>return items",0,if not jdata [ 2 ] :,if jdata [ 0 ] in item :,0.041182573,13.88809517,0.232142857
"def zip(target, source, env):<tab>compression = env.get(""ZIPCOMPRESSION"", 0)<tab>zf = zipfile.ZipFile(str(target[0]), ""w"", compression)<tab>for s in source:<tab><tab>if s.isdir():<tab><tab><tab>for dirpath, dirnames, filenames in os.walk(str(s)):<tab><tab><tab><tab>for fname in filenames:<tab><tab><tab><tab><tab>path = os.path.join(dirpath, fname)<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>zf.write(path)<tab><tab>else:<tab><tab><tab>zf.write(str(s))<tab>zf.close()",1,if os . path . isfile ( path ) :,if os . path . isfile ( path ) :,1,100,1
def remove_PBA_files():<tab>if monkey_island.cc.services.config.ConfigService.get_config():<tab><tab>windows_filename = (<tab><tab><tab>monkey_island.cc.services.config.ConfigService.get_config_value(<tab><tab><tab><tab>PBA_WINDOWS_FILENAME_PATH<tab><tab><tab>)<tab><tab>)<tab><tab>linux_filename = (<tab><tab><tab>monkey_island.cc.services.config.ConfigService.get_config_value(<tab><tab><tab><tab>PBA_LINUX_FILENAME_PATH<tab><tab><tab>)<tab><tab>)<tab><tab>if linux_filename:<tab><tab><tab>remove_file(linux_filename)<tab><tab><IF-STMT><tab><tab><tab>remove_file(windows_filename),1,if windows_filename :,if windows_filename :,0.531170663,1.00E-10,1
"def test_takewhile(self):<tab>for s in (range(10), range(0), range(1000), (7, 11), range(2000, 2200, 5)):<tab><tab>for g in (G, I, Ig, S, L, R):<tab><tab><tab>tgt = []<tab><tab><tab>for elem in g(s):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>tgt.append(elem)<tab><tab><tab>self.assertEqual(list(takewhile(isEven, g(s))), tgt)<tab><tab>self.assertRaises(TypeError, takewhile, isEven, X(s))<tab><tab>self.assertRaises(TypeError, takewhile, isEven, N(s))<tab><tab>self.assertRaises(ZeroDivisionError, list, takewhile(isEven, E(s)))",0,if not isEven ( elem ) :,if elem is None :,0.023846651,9.423716575,0.285714286
"def find_defined_variables(board_config_mks):<tab>re_def = re.compile(""^[\s]*([\w\d_]*)[\s]*:="")<tab>variables = dict()<tab>for board_config_mk in board_config_mks:<tab><tab>for line in open(board_config_mk, encoding=""latin1""):<tab><tab><tab>mo = re_def.search(line)<tab><tab><tab>if mo is None:<tab><tab><tab><tab>continue<tab><tab><tab>variable = mo.group(1)<tab><tab><tab>if variable in white_list:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>variables[variable] = set()<tab><tab><tab>variables[variable].add(board_config_mk[len(TOP) + 1 :])<tab>return variables",1,if variable not in variables :,if variable not in variables :,0.75,100,1
"def download_file(url, file):<tab>try:<tab><tab>xlog.info(""download %s to %s"", url, file)<tab><tab>opener = get_opener()<tab><tab>req = opener.open(url, cafile="""")<tab><tab>CHUNK = 16 * 1024<tab><tab>with open(file, ""wb"") as fp:<tab><tab><tab>while True:<tab><tab><tab><tab>chunk = req.read(CHUNK)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>fp.write(chunk)<tab><tab>return True<tab>except:<tab><tab>xlog.info(""download %s to %s fail"", url, file)<tab><tab>return False",1,if not chunk :,if not chunk :,0.75,100,1
"def set_preferred_lane(self, preferred_lane: int = None) -> ""AbstractEnv"":<tab>env_copy = copy.deepcopy(self)<tab>if preferred_lane:<tab><tab>for v in env_copy.road.vehicles:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v.route = [(lane[0], lane[1], preferred_lane) for lane in v.route]<tab><tab><tab><tab># Vehicle with lane preference are also less cautious<tab><tab><tab><tab>v.LANE_CHANGE_MAX_BRAKING_IMPOSED = 1000<tab>return env_copy",0,"if isinstance ( v , IDMVehicle ) :",if len ( v . route ) > 0 :,0.033356935,10.55267032,0.363636364
"def resolve(self, value: Optional[T]) -> T:<tab>v: Optional[Any] = value<tab>if value is None:<tab><tab>t = os.environ.get(self.envvar)<tab><tab>if self.type is bool and t:<tab><tab><tab>v = t in [""true"", ""True"", ""1"", ""yes""]<tab><tab><IF-STMT><tab><tab><tab>v = t<tab><tab>elif t:<tab><tab><tab>v = ast.literal_eval(t) if t is not None else None<tab>if v is None:<tab><tab>v = self.default<tab>return v",0,elif self . type is str and t :,elif self . type is ast . literal_eval :,0.233568989,36.7205627,0.518518519
"def test_read_lazy_A(self):<tab>want = [""x"" * 100, EOF_sigil]<tab>self.dataq.put(want)<tab>telnet = telnetlib.Telnet(HOST, self.port)<tab>self.dataq.join()<tab>time.sleep(self.block_short)<tab>self.assertEqual("""", telnet.read_lazy())<tab>data = """"<tab>while True:<tab><tab>try:<tab><tab><tab>read_data = telnet.read_lazy()<tab><tab><tab>data += read_data<tab><tab><tab><IF-STMT><tab><tab><tab><tab>telnet.fill_rawq()<tab><tab>except EOFError:<tab><tab><tab>break<tab><tab>self.assertTrue(want[0].startswith(data))<tab>self.assertEqual(data, want[0])",1,if not read_data :,if not read_data :,0.75,100,1
"def request_put_json(url, headers):<tab>""""""Makes a PUT request and returns the JSON response""""""<tab>try:<tab><tab>response = requests.put(url, headers=headers)<tab><tab><IF-STMT><tab><tab><tab>return response.json()<tab><tab>else:<tab><tab><tab>raise RadarrRequestError(<tab><tab><tab><tab>""Invalid response received from Radarr: %s"" % response.content<tab><tab><tab>)<tab>except RequestException as e:<tab><tab>raise RadarrRequestError(<tab><tab><tab>""Unable to connect to Radarr at %s. Error: %s"" % (url, e)<tab><tab>)",1,if response . status_code == 200 :,if response . status_code == 200 :,0.75,100,1
"def firebase_analysis(urls):<tab># Detect Firebase URL<tab>firebase_db = []<tab>logger.info(""Detecting Firebase URL(s)"")<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>returl, is_open = open_firebase(url)<tab><tab><tab>fbdic = {""url"": returl, ""open"": is_open}<tab><tab><tab>if fbdic not in firebase_db:<tab><tab><tab><tab>firebase_db.append(fbdic)<tab>return firebase_db",0,"if ""firebaseio.com"" in url :","if url . startswith ( ""firebase"" ) :",0.02800146,6.567274736,0.4
"def logprob(self, sample):<tab>if self._log:<tab><tab>return self._prob_dict.get(sample, _NINF)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return _NINF<tab><tab>elif self._prob_dict[sample] == 0:<tab><tab><tab>return _NINF<tab><tab>else:<tab><tab><tab>return math.log(self._prob_dict[sample], 2)",0,if sample not in self . _prob_dict :,if self . _prob_dict [ sample ] == 1 :,0.073015874,38.72015705,0.272727273
"def is_image(self, input):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif isinstance(input, str):<tab><tab><tab>if not os.path.isfile(input):<tab><tab><tab><tab>raise ValueError(""input must be a file"")<tab><tab><tab>img = Image.open(input)<tab><tab><tab>_ = img.size<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except:<tab><tab>return False",0,"if isinstance ( input , ( np . ndarray , Image . Image ) ) :","if isinstance ( input , int ) :",0.124391634,21.87424245,0.482142857
"def extract(self):<tab>for battery in self.vars:<tab><tab>for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines():<tab><tab><tab>l = line.split()<tab><tab><tab>if len(l) < 3:<tab><tab><tab><tab>continue<tab><tab><tab>if l[0:2] == [""remaining"", ""capacity:""]:<tab><tab><tab><tab>remaining = int(l[2])<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rate = int(l[2])<tab><tab><tab><tab>continue<tab><tab>if rate and remaining:<tab><tab><tab>self.val[battery] = remaining * 60 / rate<tab><tab>else:<tab><tab><tab>self.val[battery] = -1",0,"elif l [ 0 : 2 ] == [ ""present"" , ""rate:"" ] :","if l [ 0 : 2 ] == [ ""remaining"" , ""capacity:"" ] :",0.329545448,65.14613449,0.666666667
"def get_app_module(module_name, raise_on_failure=True):<tab>try:<tab><tab>__import__(module_name)<tab>except ImportError:<tab><tab>if sys.exc_info()[-1].tb_next:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""While importing '{module_name}', an ImportError was raised:""<tab><tab><tab><tab>f""\n\n{traceback.format_exc()}""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(f""Could not import '{module_name}'."")<tab><tab>else:<tab><tab><tab>return<tab>return sys.modules[module_name]",0,elif raise_on_failure :,if raise_on_failure :,0.112938849,1.00E-10,0.333333333
"def process_shutdown_hooks(self):<tab>for plugin_name in self.DISCOVERED.keys():<tab><tab>try:<tab><tab><tab>package = ""mailpile.plugins.%s"" % plugin_name<tab><tab><tab>_, manifest = self.DISCOVERED[plugin_name]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for method_name in self._mf_path(manifest, ""lifecycle"", ""shutdown""):<tab><tab><tab><tab><tab>method = self._get_method(package, method_name)<tab><tab><tab><tab><tab>method(self.config)<tab><tab>except:<tab><tab><tab># ignore exceptions here as mailpile is going to shut down<tab><tab><tab>traceback.print_exc(file=sys.stderr)",0,if package in sys . modules :,if manifest :,0.082086488,1.00E-10,0.224489796
"def _check_arch(self, arch):<tab>if arch is None:<tab><tab>return<tab>try:<tab><tab>from pycuda.driver import Context<tab><tab>capability = Context.get_device().compute_capability()<tab><tab><IF-STMT><tab><tab><tab>from warnings import warn<tab><tab><tab>warn(<tab><tab><tab><tab>""trying to compile for a compute capability "" ""higher than selected GPU""<tab><tab><tab>)<tab>except Exception:<tab><tab>pass",0,"if tuple ( map ( int , tuple ( arch . split ( ""_"" ) [ 1 ] ) ) ) > capability :",if not capability . is_higher ( arch ) :,0.009237477,2.710809235,0.185714286
"def phpinfo_ext(content):<tab>indexes = SubstrFind(content, ""AbracadabrA"")<tab>found = len(indexes) > 0<tab>got = """"<tab>if found:<tab><tab>start = indexes[0] + 11<tab><tab>for x in range(start, len(content)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>got += content[x]<tab>return got",0,"if content [ x ] == ""<"" :","if content [ x ] == ""A"" :",0.605621306,74.19446627,1
"def update_leaderboard(wait_time):<tab>conn = get_connection()<tab>cursor = conn.cursor(MySQLdb.cursors.DictCursor)<tab>while True:<tab><tab>try:<tab><tab><tab>if use_log:<tab><tab><tab><tab>log.info(""Updating leaderboard and adding some sigma"")<tab><tab><tab>cursor.execute(""call generate_leaderboard;"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>for s in range(wait_time):<tab><tab><tab><tab># allow for a [Ctrl]+C during the sleep cycle<tab><tab><tab><tab>time.sleep(1)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>break<tab><tab>except:<tab><tab><tab># log error<tab><tab><tab>log.error(traceback.format_exc())<tab><tab><tab>break<tab>cursor.close()<tab>conn.close()",1,if wait_time == 0 :,if wait_time == 0 :,0.75,100,1
"def writeBit(self, state, endian):<tab>if self._bit_pos == 7:<tab><tab>self._bit_pos = 0<tab><tab><IF-STMT><tab><tab><tab>if endian is BIG_ENDIAN:<tab><tab><tab><tab>self._byte |= 1<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 128<tab><tab>self._output.write(chr(self._byte))<tab><tab>self._byte = 0<tab>else:<tab><tab>if state:<tab><tab><tab>if endian is BIG_ENDIAN:<tab><tab><tab><tab>self._byte |= 1 << self._bit_pos<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 1 << (7 - self._bit_pos)<tab><tab>self._bit_pos += 1",1,if state :,if state :,0.531170663,1.00E-10,1
"def getreportopt(config):<tab>reportopts = """"<tab>reportchars = config.option.reportchars<tab>if not config.option.disablepytestwarnings and ""w"" not in reportchars:<tab><tab>reportchars += ""w""<tab>elif config.option.disablepytestwarnings and ""w"" in reportchars:<tab><tab>reportchars = reportchars.replace(""w"", """")<tab>if reportchars:<tab><tab>for char in reportchars:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>reportopts += char<tab><tab><tab>elif char == ""a"":<tab><tab><tab><tab>reportopts = ""fEsxXw""<tab>return reportopts",0,"if char not in reportopts and char != ""a"" :",if char in reportchars :,0.151766073,5.129511627,0.291666667
"def validate_module(self, pipeline):<tab>if self.mode == MODE_UNTANGLE:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(<tab><tab><tab><tab>self.training_set_directory.get_absolute_path(),<tab><tab><tab><tab>self.training_set_file_name.value,<tab><tab><tab>)<tab><tab><tab>if not os.path.exists(path):<tab><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab><tab>""Can't find file %s"" % self.training_set_file_name.value,<tab><tab><tab><tab><tab>self.training_set_file_name,<tab><tab><tab><tab>)",0,if self . training_set_directory . dir_choice != URL_FOLDER_NAME :,if self . training_set_directory :,0.162792825,26.19181759,1
"def reshape(w, h):<tab>try:<tab><tab># Prevent a division by zero when minimising the window<tab><tab><IF-STMT><tab><tab><tab>h = 1<tab><tab># Set the drawable region of the window<tab><tab>glViewport(0, 0, w, h)<tab><tab># set up the projection matrix<tab><tab>glMatrixMode(GL_PROJECTION)<tab><tab>glLoadIdentity()<tab><tab># go back to modelview matrix so we can move the objects about<tab><tab>glMatrixMode(GL_MODELVIEW)<tab><tab>updatePickingBuffer()<tab>except Exception:<tab><tab>log.error(""gl.reshape"", exc_info=True)",0,if h == 0 :,if h < 0 :,0.331415021,24.73692954,1
"def __setitem__(self, key, value):<tab>if not isinstance(value, PseudoNamespace):<tab><tab>tuple_converted = False<tab><tab><IF-STMT><tab><tab><tab>value = PseudoNamespace(value)<tab><tab>elif isinstance(value, tuple):<tab><tab><tab>value = list(value)<tab><tab><tab>tuple_converted = True<tab><tab>if isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, dict) and not isinstance(item, PseudoNamespace):<tab><tab><tab><tab><tab>value[i] = PseudoNamespace(item)<tab><tab><tab>if tuple_converted:<tab><tab><tab><tab>value = tuple(value)<tab>super(PseudoNamespace, self).__setitem__(key, value)",0,"if isinstance ( value , dict ) :","if isinstance ( value , dict ) and not isinstance ( value , PseudoNamespace ) :",0.513440541,40.01601602,0.50877193
"def scan_search(state):<tab>delim = state.source[state.position - 1]<tab>while True:<tab><tab>c = state.consume()<tab><tab>if c == delim:<tab><tab><tab>state.start += 1<tab><tab><tab>state.backup()<tab><tab><tab>content = state.emit()<tab><tab><tab>state.consume()<tab><tab><tab>token = TokenSearchForward if c == ""/"" else TokenSearchBackward<tab><tab><tab>return scan_range, [token(content)]<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""unclosed search pattern: {0}"".format(state.source))",0,elif c == EOF :,"elif c == ""\\"" :",0.455372021,31.55984539,0.7
"def fromVariant(variant):<tab>if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant):<tab><tab>t = variant.type()<tab><tab>if t == QtCore.QVariant.String:<tab><tab><tab>return str(variant.toString())<tab><tab>elif t == QtCore.QVariant.Double:<tab><tab><tab>return variant.toDouble()[0]<tab><tab>elif t == QtCore.QVariant.Int:<tab><tab><tab>return variant.toInt()[0]<tab><tab>elif t == QtCore.QVariant.Bool:<tab><tab><tab>return variant.toBool()<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName())<tab>else:<tab><tab>return variant",0,elif t == QtCore . QVariant . Invalid :,elif t == QtCore . QVariant . None :,0.625311927,78.254229,0.714285714
"def __iter__(self):<tab>i = 0<tab>for category, filename in list(self.input_files.items()):<tab><tab>for line in open(filename):<tab><tab><tab>line = self._clean_line(line)<tab><tab><tab>if self.accept_criteria(i):<tab><tab><tab><tab>yield Opinion(line, category)<tab><tab><tab>i += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""\tReaded {} examples"".format(i))",0,if i % 1000 == 0 :,if i % 10 == 0 :,0.38848939,50,0.666666667
"def test_listing_all_frameworks_and_check_frameworks_by_order(self):<tab>""""""List all frameworks and check if frameworks appear by order""""""<tab>result = subprocess.check_output(self.command_as_list([UMAKE, ""--list""]))<tab>previous_framework = None<tab>for element in result.split(b""\n""):<tab><tab><IF-STMT><tab><tab><tab>current_framework = element[: element.find(b"":"")]<tab><tab><tab>if previous_framework:<tab><tab><tab><tab>self.assertTrue(previous_framework < current_framework)<tab><tab><tab>previous_framework = current_framework<tab><tab>else:<tab><tab><tab>previous_framework = None",0,"if element . startswith ( b""\t"" ) :","if element . startswith ( b""framework"" ) :",0.549040681,64.07117598,1
"def _locate_code(self, event):<tab>if self._current_code_view is None:<tab><tab>return<tab>iid = self.tree.focus()<tab>if iid != """":<tab><tab>values = self.tree.item(iid)[""values""]<tab><tab><IF-STMT><tab><tab><tab>start_line, start_col, end_line, end_col = values[1:5]<tab><tab><tab>self._current_code_view.select_range(<tab><tab><tab><tab>TextRange(start_line, start_col, end_line, end_col)<tab><tab><tab>)",0,"if isinstance ( values , list ) and len ( values ) >= 5 :",if len ( values ) > 1 :,0.088623343,20.68738125,0.271604938
"def __setattr__(self, attr, value):<tab>""""""Provides additional checks on recipient fields.""""""<tab>if attr in [""to"", ""cc"", ""bcc""]:<tab><tab>if isinstance(value, basestring):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>check_email_valid(value, attr)<tab><tab>else:<tab><tab><tab>for address in value:<tab><tab><tab><tab>check_email_valid(address, attr)<tab>elif attr == ""headers"":<tab><tab>check_headers_valid(value)<tab>super(EmailMessage, self).__setattr__(attr, value)",0,"if value == """" and getattr ( self , ""ALLOW_BLANK_EMAIL"" , False ) :","if value == """" :",0.108118787,9.865326621,0.4
"def _scanDirectory(self, dirIter, f):<tab>while len(f) < 250:<tab><tab>try:<tab><tab><tab>info = next(dirIter)<tab><tab>except StopIteration:<tab><tab><tab>if not f:<tab><tab><tab><tab>raise EOFError<tab><tab><tab>return f<tab><tab><IF-STMT><tab><tab><tab>info.addCallback(self._cbScanDirectory, dirIter, f)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>f.append(info)<tab>return f",0,"if isinstance ( info , defer . Deferred ) :",if self . _cbScanDirectory is not None :,0.015007329,5.614808272,0.2
def iterator():<tab>try:<tab><tab>while True:<tab><tab><tab>yield from pullparser.read_events()<tab><tab><tab># load event buffer<tab><tab><tab>data = source.read(16 * 1024)<tab><tab><tab>if not data:<tab><tab><tab><tab>break<tab><tab><tab>pullparser.feed(data)<tab><tab>root = pullparser._close_and_return_root()<tab><tab>yield from pullparser.read_events()<tab><tab>it.root = root<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>source.close(),0,if close_source :,if source is not None :,0.048107739,1.00E-10,0.222222222
"def test_until_timeout(self):<tab>timer = TestTimer(self.timeout)<tab>while not timer.is_timed_out():<tab><tab><IF-STMT><tab><tab><tab>self.log_success(timer)<tab><tab><tab>return<tab><tab>sleep(DELAY_BETWEEN_ANALYSIS)<tab><tab>LOGGER.debug(<tab><tab><tab>""Waiting until all analyzers passed. Time passed: {}"".format(<tab><tab><tab><tab>timer.get_time_taken()<tab><tab><tab>)<tab><tab>)<tab>self.log_failure(timer)<tab>assert False",0,if self . all_analyzers_pass ( ) :,if timer . get_time_taken ( ) >= self . timeout :,0.168334116,8.2259647,0.375
"def start(self):<tab>""""""Start our callback in its own perpetual timer thread.""""""<tab>if self.frequency > 0:<tab><tab>threadname = self.name or self.__class__.__name__<tab><tab><IF-STMT><tab><tab><tab>self.thread = PerpetualTimer(self.frequency, self.callback)<tab><tab><tab>self.thread.bus = self.bus<tab><tab><tab>self.thread.setName(threadname)<tab><tab><tab>self.thread.start()<tab><tab><tab>self.bus.log(""Started monitor thread %r."" % threadname)<tab><tab>else:<tab><tab><tab>self.bus.log(""Monitor thread %r already started."" % threadname)",1,if self . thread is None :,if self . thread is None :,0.75,100,1
"def set_flavour(flavour, request=None, permanent=False):<tab>if flavour not in settings.FLAVOURS:<tab><tab>raise ValueError(<tab><tab><tab>u""'%r' is no valid flavour. Allowed flavours are: %s""<tab><tab><tab>% (<tab><tab><tab><tab>flavour,<tab><tab><tab><tab>"", "".join(settings.FLAVOURS),<tab><tab><tab>)<tab><tab>)<tab>request = request or getattr(_local, ""request"", None)<tab>if request:<tab><tab>request.flavour = flavour<tab><tab><IF-STMT><tab><tab><tab>flavour_storage.set(request, flavour)<tab>elif permanent:<tab><tab>raise ValueError(u""Cannot set flavour permanently, no request available."")<tab>_local.flavour = flavour",0,if permanent :,if request . is_ajax ( ) :,0.045790811,1.00E-10,0.5
"def get_images(image_path, support_ext="".jpg|.jpeg|.png""):<tab>if not os.path.exists(image_path):<tab><tab>raise Exception(f""Image path {image_path} invalid"")<tab>if os.path.isfile(image_path):<tab><tab>return [image_path]<tab>imgs = []<tab>for item in os.listdir(image_path):<tab><tab>ext = os.path.splitext(item)[1][1:].strip().lower()<tab><tab><IF-STMT><tab><tab><tab>item_path = os.path.join(image_path, item)<tab><tab><tab>imgs.append(item_path)<tab>return imgs",0,if len ( ext ) > 0 and ext in support_ext :,if ext == support_ext :,0.020181557,18.07288326,0.238095238
"def write_text(self, text):<tab>""""""Writes re-indented text into the buffer.""""""<tab>should_indent = False<tab>rows = []<tab>for row in text.split(""\n""):<tab><tab><IF-STMT><tab><tab><tab>row = ""<tab>{}"".format(row)<tab><tab>if ""\b"" in row:<tab><tab><tab>row = row.replace(""\b"", """", 1)<tab><tab><tab>should_indent = True<tab><tab>elif not len(row.strip()):<tab><tab><tab>should_indent = False<tab><tab>rows.append(row)<tab>self.write(""{}\n"".format(""\n"".join(rows)))",1,if should_indent :,if should_indent :,0.531170663,1.00E-10,1
"def build_priorities(self, _iter, priorities):<tab>while _iter is not None:<tab><tab>if self.files_treestore.iter_has_child(_iter):<tab><tab><tab>self.build_priorities(self.files_treestore.iter_children(_iter), priorities)<tab><tab><IF-STMT><tab><tab><tab>priorities[<tab><tab><tab><tab>self.files_treestore.get_value(_iter, 3)<tab><tab><tab>] = self.files_treestore.get_value(_iter, 0)<tab><tab>_iter = self.files_treestore.iter_next(_iter)<tab>return priorities",0,"elif not self . files_treestore . get_value ( _iter , 1 ) . endswith ( os . path . sep ) :",elif self . files_treestore . iter_has_child ( _iter ) :,0.087870926,22.57442815,0.202614379
"def _validate_sample(self, value):<tab>mask = self.support(value)<tab>if not_jax_tracer(mask):<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""Out-of-support values provided to log prob method. ""<tab><tab><tab><tab>""The value argument should be within the support.""<tab><tab><tab>)<tab>return mask",0,if not np . all ( mask ) :,if self . _out_of_support :,0.016838046,5.522397784,0.246753247
"def https_open(self, req):<tab>try:<tab><tab>return self.do_open(do_connection, req)<tab>except Exception as err_msg:<tab><tab>try:<tab><tab><tab>error_msg = str(err_msg.args[0]).split(""] "")[1] + "".""<tab><tab>except IndexError:<tab><tab><tab>error_msg = str(err_msg.args[0]) + "".""<tab><tab>if settings.INIT_TEST == True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(settings.FAIL_STATUS)<tab><tab>else:<tab><tab><tab>if settings.VERBOSITY_LEVEL < 1:<tab><tab><tab><tab>print("""")<tab><tab>print(settings.print_critical_msg(error_msg))<tab><tab>raise SystemExit()",0,if settings . VERBOSITY_LEVEL < 2 :,if settings . VERBOSITY_LEVEL < 1 :,0.574113272,75.06238538,0.6
"def add_party(self, party_type, party):<tab>party_doc = frappe.new_doc(party_type)<tab>if party_type == ""Customer"":<tab><tab>party_doc.customer_name = party<tab>else:<tab><tab>supplier_group = frappe.db.get_single_value(""Buying Settings"", ""supplier_group"")<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(_(""Please Set Supplier Group in Buying Settings.""))<tab><tab>party_doc.supplier_name = party<tab><tab>party_doc.supplier_group = supplier_group<tab>party_doc.flags.ignore_mandatory = True<tab>party_doc.save(ignore_permissions=True)",0,if not supplier_group :,if supplier_group is None :,0.045150551,27.77619034,0.36
"def get_polymorphic_model(data):<tab>for model in itervalues(models):<tab><tab>polymorphic = model.opts.polymorphic<tab><tab><IF-STMT><tab><tab><tab>polymorphic_key = polymorphic<tab><tab><tab>if isinstance(polymorphic_key, bool):<tab><tab><tab><tab>polymorphic_key = ""type""<tab><tab><tab>if data.get(polymorphic_key) == model.__name__:<tab><tab><tab><tab>return model<tab>raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",1,if polymorphic :,if polymorphic :,0.531170663,1.00E-10,1
"def cleanup_expired_revoked_tokens():<tab>""""""Remove tokens that have now expired from the revoked token table.""""""<tab>revoked_tokens = db.session.query(RevokedToken).all()<tab>for revoked_token in revoked_tokens:<tab><tab><IF-STMT><tab><tab><tab>pass  # The token has not expired, we must keep in the revoked token table.<tab><tab>else:<tab><tab><tab># The token is no longer valid, remove from the revoked token table.<tab><tab><tab>db.session.delete(revoked_token)<tab>db.session.commit()",0,if Journalist . validate_token_is_not_expired_or_invalid ( revoked_token . token ) :,if revoked_token . expiration_time < time . time ( ) :,0.084891542,12.2000001,0.4
"def matches_filter(key, values):<tab>if key == ""location"":<tab><tab>if location_type in (""availability-zone"", ""availability-zone-id""):<tab><tab><tab>return offering.get(""Location"") in values<tab><tab><IF-STMT><tab><tab><tab>return any(v for v in values if offering.get(""Location"").startswith(v))<tab><tab>else:<tab><tab><tab>return False<tab>elif key == ""instance-type"":<tab><tab>return offering.get(""InstanceType"") in values<tab>else:<tab><tab>return False",0,"elif location_type == ""region"" :","elif location_type == ""all"" :",0.642872021,70.71067812,1
"def autoname(self):<tab>naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"")<tab>if not naming_method:<tab><tab>throw(_(""Please setup Employee Naming System in Human Resource > HR Settings""))<tab>else:<tab><tab>if naming_method == ""Naming Series"":<tab><tab><tab>set_name_by_naming_series(self)<tab><tab>elif naming_method == ""Employee Number"":<tab><tab><tab>self.name = self.employee_number<tab><tab><IF-STMT><tab><tab><tab>self.set_employee_name()<tab><tab><tab>self.name = self.employee_name<tab>self.employee = self.name",0,"elif naming_method == ""Full Name"" :","elif naming_method == ""Employee Name"" :",0.627033187,70.16879391,1
"def readHexStringFromStream(stream):<tab>stream.read(1)<tab>txt = """"<tab>x = b_("""")<tab>while True:<tab><tab>tok = readNonWhitespace(stream)<tab><tab>if not tok:<tab><tab><tab># stream has truncated prematurely<tab><tab><tab>raise PdfStreamError(""Stream has ended unexpectedly"")<tab><tab>if tok == b_("">""):<tab><tab><tab>break<tab><tab>x += tok<tab><tab><IF-STMT><tab><tab><tab>txt += chr(int(x, base=16))<tab><tab><tab>x = b_("""")<tab>if len(x) == 1:<tab><tab>x += b_(""0"")<tab>if len(x) == 2:<tab><tab>txt += chr(int(x, base=16))<tab>return createStringObject(b_(txt))",0,if len ( x ) == 2 :,if len ( x ) == 1 :,0.605621306,75.06238538,0.666666667
"def test_technical_on(self):<tab># Turn everything on<tab>data = {<tab><tab>""developer_comments"": ""Test comment!"",<tab><tab>""whiteboard-public"": ""Whiteboard info."",<tab>}<tab>response = self.client.post(self.technical_edit_url, data)<tab>assert response.context[""form""].errors == {}<tab>addon = self.get_addon()<tab>for k in data:<tab><tab>if k == ""developer_comments"":<tab><tab><tab>assert str(getattr(addon, k)) == str(data[k])<tab><tab><IF-STMT><tab><tab><tab>assert str(addon.whiteboard.public) == str(data[k])<tab><tab>else:<tab><tab><tab>assert getattr(addon, k) == (data[k] == ""on"")",1,"elif k == ""whiteboard-public"" :","elif k == ""whiteboard-public"" :",1,100,1
"def create_season_posters(self, show_obj, force=False):<tab>if self.season_posters and show_obj:<tab><tab>result = []<tab><tab>for ep_obj in show_obj.episodes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sickrage.app.log.debug(<tab><tab><tab><tab><tab>""Metadata provider ""<tab><tab><tab><tab><tab>+ self.name<tab><tab><tab><tab><tab>+ "" creating season posters for ""<tab><tab><tab><tab><tab>+ show_obj.name<tab><tab><tab><tab>)<tab><tab><tab><tab>result = result + [self.save_season_poster(show_obj, ep_obj.season)]<tab><tab>return all(result)<tab>return False",0,"if not self . _has_season_poster ( show_obj , ep_obj . season ) or force :",if not force or ep_obj . season in self . season_posters :,0.053319528,20.65981523,0.367647059
"def get_prefixes(self, guild: Optional[discord.Guild] = None) -> List[str]:<tab>ret: List[str]<tab>gid: Optional[int] = guild.id if guild else None<tab>if gid in self._cached:<tab><tab>ret = self._cached[gid].copy()<tab>else:<tab><tab>if gid is not None:<tab><tab><tab>ret = await self._config.guild_from_id(gid).prefix()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = await self.get_prefixes(None)<tab><tab>else:<tab><tab><tab>ret = self._global_prefix_overide or (await self._config.prefix())<tab><tab>self._cached[gid] = ret.copy()<tab>return ret",0,if not ret :,elif gid is None :,0.155322126,10.68217516,0.083333333
"def checkUnchangedIvars(obj, d, exceptions=None):<tab>if not exceptions:<tab><tab>exceptions = []<tab>ok = True<tab>for key in d:<tab><tab>if key not in exceptions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>g.trace(<tab><tab><tab><tab><tab>""changed ivar: %s old: %s new: %s""<tab><tab><tab><tab><tab>% (key, repr(d.get(key)), repr(getattr(obj, key)))<tab><tab><tab><tab>)<tab><tab><tab><tab>ok = False<tab>return ok",0,"if getattr ( obj , key ) != d . get ( key ) :",if g . debug :,0.00745897,1.557729873,0.2
"def validate_ip(address):<tab>try:<tab><tab>if socket.inet_aton(address):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>debug_msg(""setcore"", ""this is a valid IP address"", 5)<tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>print_error(""This is not a valid IP address..."")<tab><tab><tab><tab>raise socket.error<tab><tab>else:<tab><tab><tab>raise socket_error<tab>except socket.error:<tab><tab>return False",0,"if len ( address . split ( ""."" ) ) == 4 :","if address . startswith ( ""127."" ) :",0.093259646,13.85894746,0.26984127
"def kernel(x, y):<tab>diff = safe_norm(x - y, ord=2) if self._normed() and x.ndim >= 1 else x - y<tab>kernel_res = jnp.exp(-(diff ** 2) / bandwidth)<tab>if self._mode == ""matrix"":<tab><tab><IF-STMT><tab><tab><tab>return kernel_res * jnp.identity(x.shape[0])<tab><tab>else:<tab><tab><tab>return jnp.diag(kernel_res)<tab>else:<tab><tab>return kernel_res",0,"if self . matrix_mode == ""norm_diag"" :",if x . ndim == 1 :,0.086582657,6.56027164,0.291666667
"def __init__(self, transforms):<tab>assert isinstance(transforms, collections.abc.Sequence)<tab>self.transforms = []<tab>for transform in transforms:<tab><tab>if isinstance(transform, dict):<tab><tab><tab>transform = build_from_cfg(transform, PIPELINES)<tab><tab><tab>self.transforms.append(transform)<tab><tab><IF-STMT><tab><tab><tab>self.transforms.append(transform)<tab><tab>else:<tab><tab><tab>raise TypeError(""transform must be callable or a dict"")",1,elif callable ( transform ) :,elif callable ( transform ) :,0.75,100,1
"def translate(<tab>self,<tab>message: str,<tab>plural_message: Optional[str] = None,<tab>count: Optional[int] = None,) -> str:<tab>if plural_message is not None:<tab><tab>assert count is not None<tab><tab><IF-STMT><tab><tab><tab>message = plural_message<tab><tab><tab>message_dict = self.translations.get(""plural"", {})<tab><tab>else:<tab><tab><tab>message_dict = self.translations.get(""singular"", {})<tab>else:<tab><tab>message_dict = self.translations.get(""unknown"", {})<tab>return message_dict.get(message, message)",0,if count != 1 :,if count == 1 :,0.331415021,37.99178428,1
"def install_requires(cls, reduced_dependencies):<tab>install_requires = OrderedSet()<tab>for dep in reduced_dependencies:<tab><tab><IF-STMT><tab><tab><tab>for req in dep.payload.requirements:<tab><tab><tab><tab>install_requires.add(str(req.requirement))<tab><tab>elif cls.has_provides(dep):<tab><tab><tab>install_requires.add(dep.provides.key)<tab>return install_requires",0,if cls . is_requirements ( dep ) :,if cls . has_payload ( dep ) :,0.501462237,39.28146509,1
"def doit():<tab>recipes_path = expanduser(""recipes.pprint"")<tab>recipe_dicts = eval(open(recipes_path).read())<tab>for r in recipe_dicts:<tab><tab>for key in r.keys():<tab><tab><tab>if key not in (""desc"", ""comments""):<tab><tab><tab><tab>del r[key]<tab><tab>for c in r[""comments""]:<tab><tab><tab>for key in c.keys():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del c[key]<tab>f = open(""stripped.pprint"", ""w"")<tab>f.write(pformat(recipe_dicts))<tab>f.close()",0,"if key not in ( ""comment"" , ""title"" ) :","if key not in ( ""desc"" , ""comments"" ) :",0.485600785,53.33505354,1
"def setup(self, name):<tab>value = self.default<tab>if self.environ:<tab><tab>full_environ_name = self.full_environ_name(name)<tab><tab><IF-STMT><tab><tab><tab>value = self.to_python(os.environ[full_environ_name])<tab><tab>elif self.environ_required:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Value {0!r} is required to be set as the ""<tab><tab><tab><tab>""environment variable {1!r}"".format(name, full_environ_name)<tab><tab><tab>)<tab>self.value = value<tab>return value",1,if full_environ_name in os . environ :,if full_environ_name in os . environ :,0.75,100,1
"def get_art_abs(story_file):<tab>lines = read_text_file(story_file)<tab>lines = [line.lower() for line in lines]<tab>lines = [fix_missing_period(line) for line in lines]<tab>article_lines = []<tab>highlights = []<tab>next_is_highlight = False<tab>for idx, line in enumerate(lines):<tab><tab>if line == """":<tab><tab><tab>continue  # empty line<tab><tab><IF-STMT><tab><tab><tab>next_is_highlight = True<tab><tab>elif next_is_highlight:<tab><tab><tab>highlights.append(line)<tab><tab>else:<tab><tab><tab>article_lines.append(line)<tab>article = "" "".join(article_lines)<tab>abstract = "" "".join(highlights)<tab>return article, abstract",0,"elif line . startswith ( ""@highlight"" ) :","elif line . startswith ( ""#"" ) :",0.547301779,59.54165059,1
"def _ordered_tag_specs(<tab>entity_tag_specs: Optional[List[EntityTagSpec]],) -> List[EntityTagSpec]:<tab>""""""Ensure that order of entity tag specs matches CRF layer order.""""""<tab>if entity_tag_specs is None:<tab><tab>return []<tab>crf_order = [<tab><tab>ENTITY_ATTRIBUTE_TYPE,<tab><tab>ENTITY_ATTRIBUTE_ROLE,<tab><tab>ENTITY_ATTRIBUTE_GROUP,<tab>]<tab>ordered_tag_spec = []<tab>for tag_name in crf_order:<tab><tab>for tag_spec in entity_tag_specs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ordered_tag_spec.append(tag_spec)<tab>return ordered_tag_spec",0,if tag_name == tag_spec . tag_name :,if tag_spec . name == tag_name :,0.055068279,63.82580224,0.636363636
"def checkDrag(self, root, target):<tab>""""""Return False if target is any descendant of root.""""""<tab>c = self<tab>message = ""Can not drag a node into its descendant tree.""<tab>for z in root.subtree():<tab><tab><IF-STMT><tab><tab><tab>if g.app.unitTesting:<tab><tab><tab><tab>g.app.unitTestDict[""checkMoveWithParentWithWarning""] = True<tab><tab><tab>else:<tab><tab><tab><tab>c.alert(message)<tab><tab><tab>return False<tab>return True",1,if z == target :,if z == target :,0.75,100,1
"def get_adapter(self, pattern=None):<tab>adapters = self.get_adapters()<tab>if pattern is None:<tab><tab><IF-STMT><tab><tab><tab>return adapters[0]<tab><tab>else:<tab><tab><tab>raise DBusNoSuchAdapterError(""No adapter(s) found"")<tab>else:<tab><tab>for adapter in adapters:<tab><tab><tab>path = adapter.get_object_path()<tab><tab><tab>if path.endswith(pattern) or adapter[""Address""] == pattern:<tab><tab><tab><tab>return adapter<tab><tab>raise DBusNoSuchAdapterError(""No adapters found with pattern: %s"" % pattern)",0,if len ( adapters ) :,if len ( adapters ) == 1 :,0.459088249,46.71379777,0.777777778
"def __init__(self, children, quiet_exceptions=()):<tab>self.keys = None<tab>if isinstance(children, dict):<tab><tab>self.keys = list(children.keys())<tab><tab>children = children.values()<tab>self.children = []<tab>for i in children:<tab><tab>if not isinstance(i, YieldPoint):<tab><tab><tab>i = convert_yielded(i)<tab><tab><IF-STMT><tab><tab><tab>i = YieldFuture(i)<tab><tab>self.children.append(i)<tab>assert all(isinstance(i, YieldPoint) for i in self.children)<tab>self.unfinished_children = set(self.children)<tab>self.quiet_exceptions = quiet_exceptions",0,if is_future ( i ) :,"if not isinstance ( i , asyncio . Future ) :",0.047804336,11.20846675,0.244897959
"def _make_callback(self):<tab>callback = self.callback<tab>for plugin in self.all_plugins():<tab><tab>try:<tab><tab><tab>if hasattr(plugin, ""apply""):<tab><tab><tab><tab>callback = plugin.apply(callback, self)<tab><tab><tab>else:<tab><tab><tab><tab>callback = plugin(callback)<tab><tab>except RouteReset:  # Try again with changed configuration.<tab><tab><tab>return self._make_callback()<tab><tab><IF-STMT><tab><tab><tab>update_wrapper(callback, self.callback)<tab>return callback",0,if not callback is self . callback :,if self . callback is not None :,0.1778983,28.11706626,0.523809524
"def _check_conflict(func, other_funcs):<tab>if steps[func]:<tab><tab>for other_func in other_funcs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Can't specify both %s and %s"" % (func, other_func))",0,if steps [ other_func ] and other_func != func :,if other_func not in steps [ func ] :,0.031226227,15.17789572,0.272727273
"def shutdown(self, cleanup=True):<tab>super(LocalDistributedRunner, self).shutdown()<tab>global _dummy_cpu_actor<tab>global _dummy_cuda_actor<tab>if cleanup:<tab><tab>if _dummy_cpu_actor or _dummy_cuda_actor:<tab><tab><tab>assert not self.is_actor(), ""Actor shouldn't have a "" ""dummy actor.""<tab><tab><IF-STMT><tab><tab><tab>ray.kill(_dummy_cpu_actor)<tab><tab>if _dummy_cuda_actor:<tab><tab><tab>ray.kill(_dummy_cuda_actor)<tab><tab>_dummy_cpu_actor = None<tab><tab>_dummy_cuda_actor = None",1,if _dummy_cpu_actor :,if _dummy_cpu_actor :,0.531170663,1.00E-10,1
"def _publish(self, data):<tab>retry = True<tab>while True:<tab><tab>try:<tab><tab><tab>if not retry:<tab><tab><tab><tab>self._redis_connect()<tab><tab><tab>return self.redis.publish(self.channel, pickle.dumps(data))<tab><tab>except redis.exceptions.ConnectionError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.error(""Cannot publish to redis... retrying"")<tab><tab><tab><tab>retry = False<tab><tab><tab>else:<tab><tab><tab><tab>logger.error(""Cannot publish to redis... giving up"")<tab><tab><tab><tab>break",1,if retry :,if retry :,0.531170663,1.00E-10,1
"def simulate_policy(args):<tab>data = torch.load(args.file)<tab>policy = data[""evaluation/policy""]<tab>env = data[""evaluation/env""]<tab>print(""Policy loaded"")<tab>if args.gpu:<tab><tab>set_gpu_mode(True)<tab><tab>policy.cuda()<tab>while True:<tab><tab>path = rollout(<tab><tab><tab>env,<tab><tab><tab>policy,<tab><tab><tab>max_path_length=args.H,<tab><tab><tab>render=True,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>env.log_diagnostics([path])<tab><tab>logger.dump_tabular()",0,"if hasattr ( env , ""log_diagnostics"" ) :",if env :,0.01726708,1.00E-10,0.477272727
"def get_bucket_latest_versions(self, bucket_name):<tab>versions = self.get_bucket_versions(bucket_name)<tab>latest_modified_per_key = {}<tab>latest_versions = {}<tab>for version in versions:<tab><tab>name = version.name<tab><tab>last_modified = version.last_modified<tab><tab>version_id = version.version_id<tab><tab>latest_modified_per_key[name] = max(<tab><tab><tab>last_modified, latest_modified_per_key.get(name, datetime.datetime.min)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>latest_versions[name] = version_id<tab>return latest_versions",0,if last_modified == latest_modified_per_key [ name ] :,if version_id > latest_modified_per_key [ name ] :,0.524151519,63.91531,1
"def _get_ntp_entity(self, peer_type):<tab>ntp_entities = {}<tab>command = ""show ntp peers""<tab>ntp_peers_table = self._get_command_table(command, ""TABLE_peers"", ""ROW_peers"")<tab>for ntp_peer in ntp_peers_table:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>peer_addr = napalm.base.helpers.ip(ntp_peer.get(""PeerIPAddress"").strip())<tab><tab>ntp_entities[peer_addr] = {}<tab>return ntp_entities",0,"if ntp_peer . get ( ""serv_peer"" , """" ) . strip ( ) != peer_type :","if peer_type not in ntp_peer . get ( ""PeerType"" ) :",0.091915748,28.25060735,0.326666667
"def kaiming_init(<tab>module, a=0, mode=""fan_out"", nonlinearity=""relu"", bias=0, distribution=""normal""):<tab>assert distribution in [""uniform"", ""normal""]<tab>if hasattr(module, ""weight"") and module.weight is not None:<tab><tab><IF-STMT><tab><tab><tab>nn.init.kaiming_uniform_(<tab><tab><tab><tab>module.weight, a=a, mode=mode, nonlinearity=nonlinearity<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>nn.init.kaiming_normal_(<tab><tab><tab><tab>module.weight, a=a, mode=mode, nonlinearity=nonlinearity<tab><tab><tab>)<tab>if hasattr(module, ""bias"") and module.bias is not None:<tab><tab>nn.init.constant_(module.bias, bias)",1,"if distribution == ""uniform"" :","if distribution == ""uniform"" :",0.75,100,1
"def _get_arguments(<tab>self, name: str, source: Dict[str, List[bytes]], strip: bool = True) -> List[str]:<tab>values = []<tab>for v in source.get(name, []):<tab><tab>s = self.decode_argument(v, name=name)<tab><tab><IF-STMT><tab><tab><tab># Get rid of any weird control chars (unless decoding gave<tab><tab><tab># us bytes, in which case leave it alone)<tab><tab><tab>s = RequestHandler._remove_control_chars_regex.sub("" "", s)<tab><tab>if strip:<tab><tab><tab>s = s.strip()<tab><tab>values.append(s)<tab>return values",0,"if isinstance ( s , unicode_type ) :","if isinstance ( s , bytes ) :",0.549040681,46.30777162,0.777777778
"def __str__(self):<tab>s = ""{""<tab>sep = """"<tab>for k, v in self.iteritems():<tab><tab>s += sep<tab><tab>if type(k) == str:<tab><tab><tab>s += ""'%s'"" % k<tab><tab>else:<tab><tab><tab>s += str(k)<tab><tab>s += "": ""<tab><tab><IF-STMT><tab><tab><tab>s += ""'%s'"" % v<tab><tab>else:<tab><tab><tab>s += str(v)<tab><tab>sep = "", ""<tab>s += ""}""<tab>return s",1,if type ( v ) == str :,if type ( v ) == str :,0.75,100,1
"def contains(self, other_route):<tab>if isinstance(other_route, list):<tab><tab>return self.to_list()[0 : len(other_route)] == other_route<tab># This only works before merging<tab>assert len(other_route.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>assert len(self.outgoing) <= 1, ""contains(..) cannot be called after a merge""<tab>if other_route.task_spec == self.task_spec:<tab><tab>if other_route.outgoing and self.outgoing:<tab><tab><tab>return self.outgoing[0].contains(other_route.outgoing[0])<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif not other_route.outgoing:<tab><tab><tab>return True<tab>return False",0,elif self . outgoing :,elif other_route . outgoing and other_route . outgoing [ 0 ] :,0.044489053,5.816635421,0.3125
"def iter_help(cls):<tab>for variable_name, value in sorted(cls.__dict__.items()):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>variable_type, variable_text = cls.process_pydoc(getattr(value, ""__doc__""))<tab><tab>yield variable_name, variable_type, variable_text",0,"if not variable_name . startswith ( ""PEX_"" ) :","if not hasattr ( value , ""__doc__"" ) :",0.03898839,21.65195675,0.484848485
"def _clean_dict(json_dict):<tab>for key, value in json_dict.items():<tab><tab>if isinstance(value, list):<tab><tab><tab>json_dict[key] = list(OrderedSet(map(_clean_string, value)))<tab><tab><IF-STMT><tab><tab><tab>json_dict[key] = _clean_dict(value)<tab>return OrderedDict(filter(lambda x: x[1], json_dict.items()))",1,"elif isinstance ( value , dict ) :","elif isinstance ( value , dict ) :",0.75,100,1
"def _createdir(self):<tab>if not os.path.exists(self._dir):<tab><tab>try:<tab><tab><tab>os.makedirs(self._dir, 0o700)<tab><tab>except OSError as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise EnvironmentError(<tab><tab><tab><tab><tab>""Cache directory '%s' does not exist ""<tab><tab><tab><tab><tab>""and could not be created'"" % self._dir<tab><tab><tab><tab>)",1,if e . errno != errno . EEXIST :,if e . errno != errno . EEXIST :,1,100,1
"def JobWait(self, waiter):<tab># type: (Waiter) -> wait_status_t<tab># wait builtin can be interrupted<tab>while True:<tab><tab># Don't retry<tab><tab>result = waiter.WaitForOne(False)<tab><tab><IF-STMT>  # signal<tab><tab><tab>return wait_status.Cancelled(result)<tab><tab>if result == -1:  # nothing to wait for<tab><tab><tab>break<tab><tab>if self.state != job_state_e.Running:<tab><tab><tab>break<tab>return wait_status.Proc(self.status)",0,if result > 0 :,if result != 0 :,0.331415021,22.95748847,1
"def _deserialize_pickle5_data(self, data):<tab>try:<tab><tab>in_band, buffers = unpack_pickle5_buffers(data)<tab><tab><IF-STMT><tab><tab><tab>obj = pickle.loads(in_band, buffers=buffers)<tab><tab>else:<tab><tab><tab>obj = pickle.loads(in_band)<tab># cloudpickle does not provide error types<tab>except pickle.pickle.PicklingError:<tab><tab>raise DeserializationError()<tab>return obj",1,if len ( buffers ) > 0 :,if len ( buffers ) > 0 :,0.75,100,1
"def svgGetPaths(svgCode):<tab>doc = xmlparseString(svgCode)<tab>svg = doc.documentElement<tab>paths = findPathNodes(svg)<tab>isFigmaSVG = svgCode.find(""Figma</desc>"") != -1<tab>if len(paths) == 0:<tab><tab>return paths, (0, 0)<tab>paths2 = []<tab>for path in paths:<tab><tab>id = path.getAttribute(""id"")<tab><tab><IF-STMT><tab><tab><tab>tr = nodeTranslation(path)<tab><tab><tab>d = path.getAttribute(""d"")<tab><tab><tab>paths2.append((d, tr))<tab>return paths2, isFigmaSVG",0,"if not isFigmaSVG or ( id is None or id . find ( ""stroke"" ) == - 1 ) :","if id == ""svg"" and isFigmaSVG :",0.02674524,3.234517755,0.156363636
"def get_track_id_from_json(item):<tab>""""""Try to extract video Id from various response types""""""<tab>fields = [<tab><tab>""contentDetails/videoId"",<tab><tab>""snippet/resourceId/videoId"",<tab><tab>""id/videoId"",<tab><tab>""id"",<tab>]<tab>for field in fields:<tab><tab>node = item<tab><tab>for p in field.split(""/""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>node = node.get(p)<tab><tab>if node:<tab><tab><tab>return node<tab>return """"",0,"if node and isinstance ( node , dict ) :","if p . endswith ( "".json"" ) :",0.028107316,8.913765521,0.215909091
"def save(self):<tab>self._idx_lock.acquire()<tab>try:<tab><tab>if self._is_idx_dirty:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._mk_dbdir()<tab><tab><tab>self.db.save_pickle(<tab><tab><tab><tab>join(self.base_dir, ""dirs_from_basename""), self._dirs_from_basename<tab><tab><tab>)<tab><tab><tab>self._is_idx_dirty = False<tab>finally:<tab><tab>self._idx_lock.release()",0,if not exists ( self . base_dir ) :,if not self . db :,0.039605994,10.54969271,0.5
"def _init_from_response(self, response):<tab>self.id = response[""id""]<tab>self.uri = response.get(""mongodb_auth_uri"", response[""mongodb_uri""])<tab>for member in response[""members""]:<tab><tab>if member[""state""] == 1:<tab><tab><tab>self.primary = Server(member[""server_id""], member[""host""])<tab><tab><IF-STMT><tab><tab><tab>self.secondary = Server(member[""server_id""], member[""host""])<tab>return self",1,"elif member [ ""state"" ] == 2 :","elif member [ ""state"" ] == 2 :",1,100,1
"def verify_secret_key(request):<tab>""Verifies secret key for a request""<tab>if request.user.username:<tab><tab># always allow authenticated users<tab><tab>return True<tab>else:<tab><tab>key = request.GET[""secret""]<tab><tab>user_id, secret = key.split(""."", 1)<tab><tab>try:<tab><tab><tab>profile = User.objects.get(pk=user_id)<tab><tab>except:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>request.user = profile.user<tab><tab><tab>return True<tab>return False",0,"if key == get_secret_key ( request , profile ) :",if profile . verify_secret ( secret ) :,0.029321109,8.27951004,0.320512821
"def compute(self, split):<tab>rd = random.Random(self.seed + split.index)<tab>if self.withReplacement:<tab><tab>olddata = list(self.prev.iterator(split))<tab><tab>sampleSize = int(math.ceil(len(olddata) * self.frac))<tab><tab>for i in range(sampleSize):<tab><tab><tab>yield rd.choice(olddata)<tab>else:<tab><tab>for i in self.prev.iterator(split):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i",0,if rd . random ( ) <= self . frac :,if rd . choice ( i ) :,0.05725336,14.82734017,0.365384615
"def splitIntoWords(name):<tab>wordlist = []<tab>wordstart = 0<tab>l = len(name)<tab>for i in range(l):<tab><tab>c = name[i]<tab><tab>n = None<tab><tab>if c == "" "" or c == ""-"":<tab><tab><tab>n = name[wordstart:i]<tab><tab><IF-STMT><tab><tab><tab>n = name[wordstart : i + 1]<tab><tab>if n:<tab><tab><tab>wordstart = i<tab><tab><tab>if c == ""-"" and n != """":<tab><tab><tab><tab>n += ""-""<tab><tab><tab>if c == "" "" or c == ""-"":<tab><tab><tab><tab>wordstart = i + 1<tab><tab><tab>wordlist.append(n)<tab>return wordlist",0,elif i == l - 1 :,"elif c == "" "" or c == ""-"" :",0.151145403,7.141816289,0.285714286
"def check_file(f, path):<tab>if not (ignore_substring and ignore_substring in f):<tab><tab><IF-STMT><tab><tab><tab>compl_path = os.path.join(path, f)<tab><tab><tab>if os.path.isfile(compl_path):<tab><tab><tab><tab>return compl_path<tab>return False",0,if substring in f :,if os . path . isfile ( path ) :,0.024424144,4.990049702,0.238636364
"def keyPressEvent(self, event):<tab>""""""Add up and down arrow key events to built in functionality.""""""<tab>keyPressed = event.key()<tab>if keyPressed in [Constants.UP_KEY, Constants.DOWN_KEY, Constants.TAB_KEY]:<tab><tab>if keyPressed == Constants.UP_KEY:<tab><tab><tab>self.index = max(0, self.index - 1)<tab><tab><IF-STMT><tab><tab><tab>self.index = min(len(self.completerStrings) - 1, self.index + 1)<tab><tab>elif keyPressed == Constants.TAB_KEY and self.completerStrings:<tab><tab><tab>self.tabPressed()<tab><tab>if self.completerStrings:<tab><tab><tab>self.setTextToCompleterIndex()<tab>super(CueLineEdit, self).keyPressEvent(event)",1,elif keyPressed == Constants . DOWN_KEY :,elif keyPressed == Constants . DOWN_KEY :,0.75,100,1
"def _get_disk_size(cls, path, ignored=None):<tab>if ignored is None:<tab><tab>ignored = []<tab>if path in ignored:<tab><tab>return 0<tab>total = 0<tab>for entry in scandir(path):<tab><tab><IF-STMT><tab><tab><tab>total += cls._get_disk_size(entry.path, ignored=ignored)<tab><tab>elif entry.is_file():<tab><tab><tab>total += entry.stat().st_size<tab>return total",1,if entry . is_dir ( ) :,if entry . is_dir ( ) :,0.75,100,1
"def _handle_rate_limit(<tab>self, exception: RedditAPIException) -> Optional[Union[int, float]]:<tab>for item in exception.items:<tab><tab>if item.error_type == ""RATELIMIT"":<tab><tab><tab>amount_search = self._ratelimit_regex.search(item.message)<tab><tab><tab>if not amount_search:<tab><tab><tab><tab>break<tab><tab><tab>seconds = int(amount_search.group(1))<tab><tab><tab>if ""minute"" in amount_search.group(2):<tab><tab><tab><tab>seconds *= 60<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sleep_seconds = seconds + min(seconds / 10, 1)<tab><tab><tab><tab>return sleep_seconds<tab>return None",0,if seconds <= int ( self . config . ratelimit_seconds ) :,"if ""second"" in amount_search . group ( 3 ) :",0.023030663,6.959578722,0.214814815
"def validate(self):<tab>try:<tab><tab>f = int(eval(self.setting.getValue(), {}, {}))<tab><tab><IF-STMT><tab><tab><tab>return ERROR, ""This setting should not be below "" + str(self.minValue)<tab><tab>if self.maxValue is not None and f > self.maxValue:<tab><tab><tab>return ERROR, ""This setting should not be above "" + str(self.maxValue)<tab><tab>return SUCCESS, """"<tab>except (ValueError, SyntaxError, TypeError, NameError):<tab><tab>return (<tab><tab><tab>ERROR,<tab><tab><tab>'""'<tab><tab><tab>+ str(self.setting.getValue())<tab><tab><tab>+ '"" is not a valid whole number or expression',<tab><tab>)",1,if self . minValue is not None and f < self . minValue :,if self . minValue is not None and f < self . minValue :,0.75,100,1
"def rename(self, remote_name, new_remote_name):<tab>remotes = self.load_remotes()<tab>remotes.rename(remote_name, new_remote_name)<tab>with self._cache.editable_packages.disable_editables():<tab><tab>for ref in self._cache.all_refs():<tab><tab><tab>with self._cache.package_layout(ref).update_metadata() as metadata:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>metadata.recipe.remote = new_remote_name<tab><tab><tab><tab>for pkg_metadata in metadata.packages.values():<tab><tab><tab><tab><tab>if pkg_metadata.remote == remote_name:<tab><tab><tab><tab><tab><tab>pkg_metadata.remote = new_remote_name<tab><tab>remotes.save(self._filename)",1,if metadata . recipe . remote == remote_name :,if metadata . recipe . remote == remote_name :,0.75,100,1
"def _convert_idx(self, idx):<tab>graph_idx = 0<tab>node_idx = idx<tab>for i in range(len(self.graphs)):<tab><tab><IF-STMT><tab><tab><tab>graph_idx = i<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>node_idx -= self.graphs[i].number_of_nodes()<tab>return graph_idx, node_idx",0,if node_idx < self . graphs [ i ] . number_of_nodes ( ) :,if self .graphs [ i ] . number_of_nodes ( ) == 0 :,0.382630038,69.92829828,0.5
"def emit_pre_migrate_signal(verbosity, interactive, db, **kwargs):<tab># Emit the pre_migrate signal for every application.<tab>for app_config in apps.get_app_configs():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if verbosity >= 2:<tab><tab><tab>print(""Running pre-migrate handlers for application %s"" % app_config.label)<tab><tab>models.signals.pre_migrate.send(<tab><tab><tab>sender=app_config,<tab><tab><tab>app_config=app_config,<tab><tab><tab>verbosity=verbosity,<tab><tab><tab>interactive=interactive,<tab><tab><tab>using=db,<tab><tab><tab>**kwargs<tab><tab>)",0,if app_config . models_module is None :,if not app_config . enabled :,0.043785007,26.29588998,0.333333333
"def slice(self, slice):<tab>gridscope = GridScope(globals=self.globals)<tab>for key in self.user_added:<tab><tab>value = self[key]<tab><tab><IF-STMT><tab><tab><tab>grid = value<tab><tab><tab>sliced = np.sum(grid[slice, ...], axis=0)<tab><tab><tab>logger.debug(""sliced %s from %r to %r"", key, grid.shape, sliced.shape)<tab><tab><tab>gridscope[key] = sliced<tab><tab>else:<tab><tab><tab>gridscope[key] = value<tab>return gridscope",1,"if isinstance ( value , np . ndarray ) :","if isinstance ( value , np . ndarray ) :",0.75,100,1
"def get_last_tagged(self):<tab>if not self.last_tagged:<tab><tab>last = datetime(1970, 1, 1)<tab><tab>for tag in self.tags:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>last = tag.last_seen<tab><tab>self.update(set__last_tagged=last)<tab><tab>return last<tab>else:<tab><tab>return self.last_tagged",0,if tag . last_seen > last :,if tag . last_seen is not None :,0.203822108,53.72849659,0.392857143
"def recalculate_user_disk_usage(app, **kwargs):<tab>user_id = kwargs.get(""user_id"", None)<tab>sa_session = app.model.context<tab>if user_id:<tab><tab>user = sa_session.query(app.model.User).get(app.security.decode_id(user_id))<tab><tab><IF-STMT><tab><tab><tab>user.calculate_and_set_disk_usage()<tab><tab>else:<tab><tab><tab>log.error(<tab><tab><tab><tab>""Recalculate user disk usage task failed, user %s not found"" % user_id<tab><tab><tab>)<tab>else:<tab><tab>log.error(""Recalculate user disk usage task received without user_id."")",1,if user :,if user :,0.531170663,1.00E-10,1
"def log_items(self, interface, action, media, items):<tab>if not items:<tab><tab>return<tab><tab># Log each item<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>log.info(<tab><tab><tab>""[%s:%s](%s) %r (%r)"",<tab><tab><tab>interface,<tab><tab><tab>action,<tab><tab><tab>media,<tab><tab><tab>item.get(""title""),<tab><tab><tab>item.get(""year""),<tab><tab>)<tab><tab>if media == ""shows"":<tab><tab><tab># Log each episode<tab><tab><tab>self.log_episodes(item)",0,if not item :,"if item . get ( ""type"" ) != ""episode"" :",0.034416929,3.458592114,0.4
"def test_unbiased_coin_has_no_second_order():<tab>counts = Counter()<tab>for i in range(256):<tab><tab>buf = bytes([i])<tab><tab>data = ConjectureData.for_buffer(buf)<tab><tab>result = cu.biased_coin(data, 0.5)<tab><tab><IF-STMT><tab><tab><tab>counts[result] += 1<tab>assert counts[False] == counts[True] > 0",0,if data . buffer == buf :,if result != 0 :,0.022250825,7.654112967,0.265306122
"def gettempfilename(suffix):<tab>""""""Returns a temporary filename""""""<tab>if ""_"" in os.environ:<tab><tab># tempfile.mktemp() crashes on some Wine versions (the one of Ubuntu 12.04 particularly)<tab><tab><IF-STMT><tab><tab><tab>tmpdir = "".""<tab><tab><tab>if ""TMP"" in os.environ:<tab><tab><tab><tab>tmpdir = os.environ[""TMP""]<tab><tab><tab>import time<tab><tab><tab>import random<tab><tab><tab>random.seed(time.time())<tab><tab><tab>random_part = ""file%d"" % random.randint(0, 1000000000)<tab><tab><tab>return os.path.join(tmpdir, random_part + suffix)<tab>return tempfile.mktemp(suffix)",0,"if os . environ [ ""_"" ] . find ( ""wine"" ) >= 0 :","if suffix == "".py"" :",0.007036807,2.198077525,0.267080745
"def _get_functionapp_runtime_language(<tab>self, app_settings):  # pylint: disable=no-self-use<tab>functions_worker_runtime = [<tab><tab>setting[""value""]<tab><tab>for setting in app_settings<tab><tab>if setting[""name""] == ""FUNCTIONS_WORKER_RUNTIME""<tab>]<tab>if functions_worker_runtime:<tab><tab>functionapp_language = functions_worker_runtime[0]<tab><tab><IF-STMT><tab><tab><tab>return SUPPORTED_LANGUAGES[functionapp_language]<tab><tab>raise LanguageNotSupportException(functionapp_language)<tab>return None",0,if SUPPORTED_LANGUAGES . get ( functionapp_language ) is not None :,if functionapp_language in SUPPORTED_LANGUAGES :,0.096389051,16.46692067,0.257142857
"def seek(self, offset, whence=io.SEEK_SET):<tab>if self.mode == WRITE:<tab><tab>if whence != io.SEEK_SET:<tab><tab><tab>if whence == io.SEEK_CUR:<tab><tab><tab><tab>offset = self.offset + offset<tab><tab><tab>else:<tab><tab><tab><tab>raise ValueError(""Seek from end not supported"")<tab><tab><IF-STMT><tab><tab><tab>raise OSError(""Negative seek in write mode"")<tab><tab>count = offset - self.offset<tab><tab>chunk = bytes(1024)<tab><tab>for i in range(count // 1024):<tab><tab><tab>self.write(chunk)<tab><tab>self.write(bytes(count % 1024))<tab>elif self.mode == READ:<tab><tab>self._check_not_closed()<tab><tab>return self._buffer.seek(offset, whence)<tab>return self.offset",0,if offset < self . offset :,if offset < 0 :,0.094532291,28.64190458,0.504761905
"def stop(self):<tab>""""""Stop the HTTP server.""""""<tab>if self.running:<tab><tab># stop() MUST block until the server is *truly* stopped.<tab><tab>self.httpserver.stop()<tab><tab># Wait for the socket to be truly freed.<tab><tab><IF-STMT><tab><tab><tab>portend.free(*self.bound_addr, timeout=Timeouts.free)<tab><tab>self.running = False<tab><tab>self.bus.log(""HTTP Server %s shut down"" % self.httpserver)<tab>else:<tab><tab>self.bus.log(""HTTP Server %s already shut down"" % self.httpserver)",0,"if isinstance ( self . bind_addr , tuple ) :",if self . bound_addr is not None :,0.028107316,10.75365958,0.238636364
"def dump_json(testcase, json_file):<tab>""""""dump HAR entries to json testcase""""""<tab>logger.info(""dump testcase to JSON format."")<tab>with open(json_file, ""w"", encoding=""utf-8"") as outfile:<tab><tab>my_json_str = json.dumps(testcase, ensure_ascii=False, indent=4)<tab><tab><IF-STMT><tab><tab><tab>my_json_str = my_json_str.decode(""utf-8"")<tab><tab>outfile.write(my_json_str)<tab>logger.info(""Generate JSON testcase successfully: {}"".format(json_file))",1,"if isinstance ( my_json_str , bytes ) :","if isinstance ( my_json_str , bytes ) :",0.75,100,1
"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab>if instring:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab>elif char == ""#"":<tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None",0,if char == instring_char :,if instring_char :,0.064728092,1.00E-10,0.619047619
"def _requests_to_follow(self, response):<tab>if not isinstance(response, HtmlResponse):<tab><tab>return<tab>seen = set()<tab>for n, rule in enumerate(self._rules):<tab><tab>links = [<tab><tab><tab>lnk<tab><tab><tab>for lnk in rule.link_extractor.extract_links(response)<tab><tab><tab>if lnk not in seen<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>links = rule.process_links(links)<tab><tab>for link in links:<tab><tab><tab>seen.add(link)<tab><tab><tab>request = self._build_request(n, link)<tab><tab><tab>yield rule._process_request(request, response)",0,if links and rule . process_links :,if links :,0.038857533,1.00E-10,0.55
"def _process_iter(self, line_iter):<tab>samples = []<tab>buf = []<tab>for line in line_iter:<tab><tab>if not buf and line.startswith(""#"") and self._has_comment:<tab><tab><tab>continue<tab><tab>line = line.split()<tab><tab><IF-STMT><tab><tab><tab>buf.append(line)<tab><tab>elif buf:<tab><tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab><tab><tab>buf = []<tab>if buf:<tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab>return samples",1,if line :,if line :,0.531170663,1.00E-10,1
"def _set_input_expanded(self, inp, expand, scroll=True):<tab>getobj = self._builder.get_object<tab>arrow = getobj(""by%s_expander_arrow"" % (inp.name,))<tab>grid = getobj(""by%s_curve_grid"" % (inp.name,))<tab>if expand:<tab><tab>arrow.set_property(""arrow-type"", Gtk.ArrowType.DOWN)<tab><tab>grid.show_all()<tab><tab><IF-STMT><tab><tab><tab>GLib.idle_add(self._scroll_setting_editor, grid)<tab>else:<tab><tab>arrow.set_property(""arrow-type"", Gtk.ArrowType.RIGHT)<tab><tab>grid.hide()",1,if scroll :,if scroll :,0.531170663,1.00E-10,1
"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab>if not word:<tab><tab><tab>continue<tab><tab>if word not in ignored and len(word) >= 2:<tab><tab><tab>if previous == word:<tab><tab><tab><tab>group += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",0,elif group > 1 :,elif group < len ( ignored ) :,0.047687319,12.22307556,0.481481481
"def add_field_to_csv_file(fieldName, fieldNameMap, fieldsList, fieldsTitles, titles):<tab>for ftList in fieldNameMap[fieldName]:<tab><tab><IF-STMT><tab><tab><tab>fieldsList.append(ftList)<tab><tab><tab>fieldsTitles[ftList] = ftList<tab><tab><tab>add_titles_to_csv_file([ftList], titles)",0,if ftList not in fieldsTitles :,if ftList not in fieldsList :,0.521251881,53.72849659,0.714285714
"def get_transform(self, img):<tab>check_dtype(img)<tab>assert img.ndim in [2, 3], img.ndim<tab>from .transform import LazyTransform, TransformList<tab># The next augmentor requires the previous one to finish.<tab># So we have to use LazyTransform<tab>tfms = []<tab>for idx, a in enumerate(self.augmentors):<tab><tab>if idx == 0:<tab><tab><tab>t = a.get_transform(img)<tab><tab>else:<tab><tab><tab>t = LazyTransform(a.get_transform)<tab><tab><IF-STMT><tab><tab><tab>tfms.extend(t.tfms)<tab><tab>else:<tab><tab><tab>tfms.append(t)<tab>return TransformList(tfms)",0,"if isinstance ( t , TransformList ) :","if hasattr ( t , ""tfms"" ) :",0.091668085,20.55668085,0.481481481
"def __init__(self, template, context, body_stream=None):<tab>if body_stream is None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Async mode requires a body stream ""<tab><tab><tab><tab>""to be passed to a template module.  Use ""<tab><tab><tab><tab>""the async methods of the API you are ""<tab><tab><tab><tab>""using.""<tab><tab><tab>)<tab><tab>body_stream = list(template.root_render_func(context))<tab>self._body_stream = body_stream<tab>self.__dict__.update(context.get_exported())<tab>self.__name__ = template.name",0,if context . environment . is_async :,if template . root_render_func is None :,0.085364977,5.604233375,0.265306122
"def url_locations(urls, faker=False):<tab>locations = []<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>response = request.urlopen(request.Request(url, headers=fake_headers), None)<tab><tab>else:<tab><tab><tab>response = request.urlopen(request.Request(url))<tab><tab>locations.append(response.url)<tab>return locations",0,if faker :,if fake_headers :,0.319750449,1.00E-10,0.555555556
"def wait_services_ready(selectors, min_counts, count_fun, timeout=None):<tab>readies = [0] * len(selectors)<tab>start_time = time.time()<tab>while True:<tab><tab>all_satisfy = True<tab><tab>for idx, selector in enumerate(selectors):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>all_satisfy = False<tab><tab><tab><tab>readies[idx] = count_fun(selector)<tab><tab><tab><tab>break<tab><tab>if all_satisfy:<tab><tab><tab>break<tab><tab>if timeout and timeout + start_time < time.time():<tab><tab><tab>raise TimeoutError(""Wait cluster start timeout"")<tab><tab>time.sleep(1)",0,if readies [ idx ] < min_counts [ idx ] :,if min_counts [ idx ] < min_counts [ idx ] :,0.904859711,71.66258375,0.608333333
"def sanitize_args(a):<tab>try:<tab><tab>args, kwargs = a<tab><tab>if isinstance(args, tuple) and isinstance(kwargs, dict):<tab><tab><tab>return args, dict(kwargs)<tab>except (TypeError, ValueError):<tab><tab>args, kwargs = (), {}<tab>if a is not None:<tab><tab>if isinstance(a, dict):<tab><tab><tab>args = tuple()<tab><tab><tab>kwargs = a<tab><tab>elif isinstance(a, tuple):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>args, kwargs = a[0:-1], a[-1]<tab><tab><tab>else:<tab><tab><tab><tab>args = a<tab><tab><tab><tab>kwargs = {}<tab>return args, kwargs",0,"if isinstance ( a [ - 1 ] , dict ) :",if len ( a ) > 1 :,0.024253488,8.816389212,0.561904762
"def _override_options(options, **overrides):<tab>""""""Override options.""""""<tab>for opt, val in overrides.items():<tab><tab>passed_value = getattr(options, opt, _Default())<tab><tab>if opt in (""ignore"", ""select"") and passed_value:<tab><tab><tab>value = process_value(opt, passed_value.value)<tab><tab><tab>value += process_value(opt, val)<tab><tab><tab>setattr(options, opt, value)<tab><tab><IF-STMT><tab><tab><tab>setattr(options, opt, process_value(opt, val))",0,"elif isinstance ( passed_value , _Default ) :","elif opt == ""select"" and not passed_value :",0.118277761,13.0651133,0.3
"def get_first_file_by_stem(dir_path, stem, exts=None):<tab>dir_path = Path(dir_path)<tab>stem = stem.lower()<tab>if dir_path.exists():<tab><tab>for x in sorted(list(scandir(str(dir_path))), key=lambda x: x.name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>xp = Path(x.path)<tab><tab><tab>if xp.stem.lower() == stem and (exts is None or xp.suffix.lower() in exts):<tab><tab><tab><tab>return xp<tab>return None",0,if not x . is_file ( ) :,if not x . exists ( ) :,0.501462237,38.94003915,0.777777778
"def testShortCircuit(self):<tab>""""""Test that creation short-circuits to reuse existing references""""""<tab>sd = {}<tab>for s in self.ss:<tab><tab>sd[s] = 1<tab>for t in self.ts:<tab><tab><IF-STMT><tab><tab><tab>self.assert_(sd.has_key(safeRef(t.x)))<tab><tab><tab>self.assert_(safeRef(t.x) in sd)<tab><tab>else:<tab><tab><tab>self.assert_(sd.has_key(safeRef(t)))<tab><tab><tab>self.assert_(safeRef(t) in sd)",1,"if hasattr ( t , ""x"" ) :","if hasattr ( t , ""x"" ) :",0.75,100,1
"def _gen_Less(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab>if ret_type == real_type:<tab><tab><tab>result.append(self.builder.fcmp_ordered(""<"", lhs, rhs))<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.icmp_signed(""<"", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",1,elif ret_type == int_type :,elif ret_type == int_type :,1,100,1
def _resolve_aliases(tasks_or_files):<tab>for task_or_file in tasks_or_files:<tab><tab><IF-STMT><tab><tab><tab>for t_or_f in _resolve_aliases(task_or_file.deps):<tab><tab><tab><tab>yield t_or_f<tab><tab>else:<tab><tab><tab>yield task_or_file,0,"if isinstance ( task_or_file , Alias ) :","if isinstance ( task_or_file , Task ) :",0.549040681,76.91605673,0.6
"def report(properties):<tab>for name, value in properties:<tab><tab><IF-STMT><tab><tab><tab>if hasattr(value, ""uniobj""):<tab><tab><tab><tab># Under old versions of pytest, `value` was a `py.xml.raw`<tab><tab><tab><tab># rather than a string, so we get the (unicode) string off it.<tab><tab><tab><tab>value = value.uniobj<tab><tab><tab>line = base64.b64decode(value.encode()).decode() + ""\n\n""<tab><tab><tab>terminalreporter.write_line(line)",0,"if name . startswith ( ""hypothesis-statistics-"" ) :","if name == ""value"" :",0.035401841,10.81605939,0.727272727
"def throw_404(self, n):<tab># bl_label of some nodes is edited by us, but those nodes do have docs ..<tab>_dirname = os.path.dirname(sverchok.__file__)<tab>path1 = os.path.join(_dirname, ""docs"", ""404.html"")<tab>path2 = os.path.join(_dirname, ""docs"", ""404_custom.html"")<tab>with open(path1) as origin:<tab><tab>with open(path2, ""w"") as destination:<tab><tab><tab>for line in origin:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>destination.write(line.replace(""{{variable}}"", n.bl_label))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>destination.write(line)<tab>webbrowser.open(path2)",0,"if ""{{variable}}"" in line :",if n . bl_label :,0.034123066,4.410363736,0.36
"def rm_empty_dirs(dirpath, interactive=False, dry_run=False):<tab>for name in os.listdir(dirpath):<tab><tab>path = join(dirpath, name)<tab><tab><IF-STMT><tab><tab><tab>rm_empty_dirs(path, interactive, dry_run)<tab>if not os.listdir(dirpath):<tab><tab>if interactive:<tab><tab><tab>raise NotImplementedError(""'-i' not implemented"")<tab><tab>if dry_run:<tab><tab><tab>log.info(""rmdir `%s' (dry-run)"", dirpath)<tab><tab>else:<tab><tab><tab>log.info(""rmdir `%s'"", dirpath)<tab><tab><tab>os.rmdir(dirpath)",0,if isdir ( path ) :,if os . path . isdir ( path ) :,0.364101086,41.11336169,0.5
"def get_run_cmd(submission_dir):<tab>""""""Get the language of a submission""""""<tab>with CD(submission_dir):<tab><tab><IF-STMT><tab><tab><tab>with open(""run.sh"") as f:<tab><tab><tab><tab>for line in f:<tab><tab><tab><tab><tab>if line[0] != ""#"":<tab><tab><tab><tab><tab><tab>return line.rstrip(""\r\n"")",1,"if os . path . exists ( ""run.sh"" ) :","if os . path . exists ( ""run.sh"" ) :",0.75,100,1
"def _do_test_fetch_result(self, results, remote):<tab># self._print_fetchhead(remote.repo)<tab>self.assertGreater(len(results), 0)<tab>self.assertIsInstance(results[0], FetchInfo)<tab>for info in results:<tab><tab>self.assertIsInstance(info.note, string_types)<tab><tab>if isinstance(info.ref, Reference):<tab><tab><tab>self.assertTrue(info.flags)<tab><tab># END reference type flags handling<tab><tab>self.assertIsInstance(info.ref, (SymbolicReference, Reference))<tab><tab><IF-STMT><tab><tab><tab>self.assertIsInstance(info.old_commit, Commit)<tab><tab>else:<tab><tab><tab>self.assertIsNone(info.old_commit)",0,if info . flags & ( info . FORCED_UPDATE | info . FAST_FORWARD ) :,"if isinstance ( info . old_commit , Commit ) :",0.137647604,9.621765471,0.325396825
"def __set__(self, instance, value):<tab>super().__set__(instance, value)<tab>value = instance._data[self.name]<tab>if value is not None:<tab><tab><IF-STMT><tab><tab><tab>instance._data[self.name] = self._convert_from_datetime(value)<tab><tab>else:<tab><tab><tab>instance._data[self.name] = value",1,"if isinstance ( value , datetime . datetime ) :","if isinstance ( value , datetime . datetime ) :",1,100,1
"def put(self, can_split=False):<tab>if isinstance(self.expr, NodeConst):<tab><tab><IF-STMT>  # 2007 May 01<tab><tab><tab>self.expr.put()<tab><tab>else:<tab><tab><tab>self.line_more(""("")<tab><tab><tab>self.expr.put(can_split=True)<tab><tab><tab>self.line_more("")"")<tab>else:<tab><tab>self.put_expr(self.expr, can_split=can_split)<tab>self.line_more(""."")<tab>self.line_more(NAME_SPACE.make_attr_name(self.expr, self.attrname))<tab>return self",0,if self . expr . is_str ( ) :,if can_split :,0.013130314,1.00E-10,0.464285714
"def get_location(self, dist, dependency_links):<tab>for url in dependency_links:<tab><tab>egg_fragment = Link(url).egg_fragment<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""-"" in egg_fragment:<tab><tab><tab>## FIXME: will this work when a package has - in the name?<tab><tab><tab>key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower()<tab><tab>else:<tab><tab><tab>key = egg_fragment<tab><tab>if key == dist.key:<tab><tab><tab>return url.split(""#"", 1)[0]<tab>return None",1,if not egg_fragment :,if not egg_fragment :,0.75,100,1
"def _parse_lines(self, lines):<tab>for line in lines:<tab><tab>self.size += len(line)<tab><tab>words = line.strip().split(""\t"")<tab><tab>if len(words) > 1:<tab><tab><tab>wset = set(words[1:])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.WORDS[words[0]] |= wset<tab><tab><tab>else:<tab><tab><tab><tab>self.WORDS[words[0]] = wset",0,if words [ 0 ] in self . WORDS :,if len ( words ) == 1 :,0.015007329,5.614808272,0.225
"def __call__(self, target):<tab># normal running mode<tab>if not self.check_run_always:<tab><tab>for algo in self.algos:<tab><tab><tab>if not algo(target):<tab><tab><tab><tab>return False<tab><tab>return True<tab># run mode when at least one algo has a run_always attribute<tab>else:<tab><tab># store result in res<tab><tab># allows continuation to check for and run<tab><tab># algos that have run_always set to True<tab><tab>res = True<tab><tab>for algo in self.algos:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = algo(target)<tab><tab><tab>elif hasattr(algo, ""run_always""):<tab><tab><tab><tab>if algo.run_always:<tab><tab><tab><tab><tab>algo(target)<tab><tab>return res",0,if res :,"if algo == ""run"" :",0.051944023,1.00E-10,0.5
"def _cmd_flags_as_data(cmd_flags):<tab>data = {}<tab>for flag_name, cmd_flag in cmd_flags.items():<tab><tab>cmd_flag_data = _cmd_flag_as_data(cmd_flag)<tab><tab><IF-STMT><tab><tab><tab>data[flag_name] = cmd_flag_data<tab>return data",0,if cmd_flag_data :,if cmd_flag_data is not None :,0.090364769,1.00E-10,0.314285714
"def _csv_iterator(data_path, ngrams, yield_cls=False):<tab>tokenizer = get_tokenizer(""basic_english"")<tab>with io.open(data_path, encoding=""utf8"") as f:<tab><tab>reader = unicode_csv_reader(f)<tab><tab>for row in reader:<tab><tab><tab>tokens = "" "".join(row[1:])<tab><tab><tab>tokens = tokenizer(tokens)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield int(row[0]) - 1, ngrams_iterator(tokens, ngrams)<tab><tab><tab>else:<tab><tab><tab><tab>yield ngrams_iterator(tokens, ngrams)",1,if yield_cls :,if yield_cls :,0.531170663,1.00E-10,1
"def FindEnclosingBracketGroup(input_str):<tab>stack = []<tab>start = -1<tab>for index, char in enumerate(input_str):<tab><tab>if char in LBRACKETS:<tab><tab><tab>stack.append(char)<tab><tab><tab>if start == -1:<tab><tab><tab><tab>start = index<tab><tab>elif char in BRACKETS:<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (start, index + 1)<tab>return (-1, -1)",0,if stack . pop ( ) != BRACKETS [ char ] :,elif not stack :,0.007689511,2.002152302,0.109375
def get_and_set_be_comp(self):<tab>all_be_comp = []<tab>for page in self.pages:<tab><tab>if page.relations.be_comp_norm is not None:<tab><tab><tab>all_be_comp.extend(page.relations.be_comp_norm)<tab><tab><IF-STMT><tab><tab><tab>all_be_comp.extend(page.relations.be_comp)<tab>return set(all_be_comp),1,if page . relations . be_comp is not None :,if page . relations . be_comp is not None :,0.75,100,1
"def iterload(self):<tab>delim = self.options.delimiter<tab>rowdelim = self.options.row_delimiter<tab>with self.source.open_text() as fp:<tab><tab>with Progress(total=filesize(self.source)) as prog:<tab><tab><tab>for line in splitter(fp, rowdelim):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>prog.addProgress(len(line))<tab><tab><tab><tab>row = list(line.split(delim))<tab><tab><tab><tab>if len(row) < self.nVisibleCols:<tab><tab><tab><tab><tab># extend rows that are missing entries<tab><tab><tab><tab><tab>row.extend([None] * (self.nVisibleCols - len(row)))<tab><tab><tab><tab>yield row",1,if not line :,if not line :,0.75,100,1
"def process_module(name, module, parent):<tab>if parent:<tab><tab>modules[parent][""items""].append(name)<tab><tab>mg = module_groups.setdefault(name, [])<tab><tab>mg.append(parent)<tab><tab>if get_module_type(name) == ""py3status"":<tab><tab><tab>module["".group""] = parent<tab># check module content<tab>for k, v in list(module.items()):<tab><tab>if k.startswith(""on_click""):<tab><tab><tab># on_click event<tab><tab><tab>process_onclick(k, v, name)<tab><tab><tab># on_click should not be passed to the module via the config.<tab><tab><tab>del module[k]<tab><tab><IF-STMT><tab><tab><tab># we are a container<tab><tab><tab>module[""items""] = []<tab>return module",0,"if isinstance ( v , ModuleDefinition ) :","if ""items"" not in module :",0.018517118,6.567274736,0.25
"def test_identify_accepts_space_separated_hosts(self):<tab>ru, iu = self.mock_all_identify()<tab>file_ip = open(tests.VALID_FILE_IP)<tab>for i, line in enumerate(file_ip):<tab><tab><IF-STMT><tab><tab><tab>expected_url, expected_host = (""http://192.168.1.1/"", ""example.com"")<tab><tab>elif i == 2:<tab><tab><tab>expected_url, expected_host = (""http://192.168.1.2/drupal/"", ""example.com"")<tab><tab>identify_line(line)<tab><tab>args, kwargs = ru.call_args_list[-1]<tab><tab>self.assertEquals(args[0], expected_url)<tab><tab>self.assertEquals(args[1], expected_host)",0,if i < 2 :,if i == 1 :,0.314978772,17.9652056,0.6
"def get_version(module):<tab>for key in version_keys:<tab><tab><IF-STMT><tab><tab><tab>version = getattr(module, key)<tab><tab><tab>if isinstance(version, types.ModuleType):<tab><tab><tab><tab>version = get_version(version)<tab><tab><tab>return version<tab>return ""Unknown""",0,"if hasattr ( module , key ) :",if key in module . __dict__ :,0.02067646,5.30015669,0.333333333
"def whoami(self):<tab>""""""Return user relevant login information.""""""<tab>account_data = {}<tab>for k in (""email"", ""account_id""):<tab><tab>value = self.conf.get(k)<tab><tab><IF-STMT><tab><tab><tab>account_info = self.get_account_information()<tab><tab><tab>value = account_info.get(k, ""unknown"")<tab><tab><tab>self.conf.set(k, value)<tab><tab><tab>self.conf.save()<tab><tab>account_data[k] = value<tab>return account_data",0,if not value :,if value is None :,0.045150551,14.05853313,0.277777778
"def do(self):<tab>if self.in_class_scope():<tab><tab>selected_str = self.view.substr(self.selected_region)<tab><tab>for symbol in self.view.symbols():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.view.sel().clear()<tab><tab><tab><tab>self.view.sel().add(symbol[0])<tab><tab><tab><tab>self.view.show(symbol[0])<tab><tab><tab><tab>return<tab># falls back to the original functionality<tab>self.window.run_command(""goto_definition"")",0,if symbol [ 1 ] == selected_str :,"if self . view . substr ( self . selected_region , symbol [ 0 ] ) == selected_str :",0.12728984,23.05089863,0.232142857
"def __iter__(self):<tab>i = 0<tab>for category, filename in list(self.input_files.items()):<tab><tab>for line in open(filename):<tab><tab><tab>line = self._clean_line(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield Opinion(line, category)<tab><tab><tab>i += 1<tab><tab><tab>if i % 1000 == 0:<tab><tab><tab><tab>print(""\tReaded {} examples"".format(i))",0,if self . accept_criteria ( i ) :,if line :,0.016200585,1.00E-10,0.381818182
"def recvmsg(self, *args):<tab>while True:<tab><tab>try:<tab><tab><tab>return self._sock.recvmsg(*args)<tab><tab>except error as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>self._wait(self._read_event)",1,if ex . args [ 0 ] != EWOULDBLOCK or self . timeout == 0.0 :,if ex . args [ 0 ] != EWOULDBLOCK or self . timeout == 0.0 :,0.75,100,1
"def _get_editable_fields(cls):<tab>fds = set([])<tab>for field in cls._meta.concrete_fields:<tab><tab><IF-STMT><tab><tab><tab>if field.attname == ""id"":<tab><tab><tab><tab>continue<tab><tab><tab>elif field.attname.endswith(""ptr_id""):<tab><tab><tab><tab># polymorphic fields should always be non-editable, see:<tab><tab><tab><tab># https://github.com/django-polymorphic/django-polymorphic/issues/349<tab><tab><tab><tab>continue<tab><tab><tab>if getattr(field, ""editable"", True):<tab><tab><tab><tab>fds.add(field.attname)<tab>return fds",1,"if hasattr ( field , ""attname"" ) :","if hasattr ( field , ""attname"" ) :",0.75,100,1
"def prepare_fields(all_fields, submit_fields, submit):<tab>if len(list(submit_fields.items(multi=True))) > 1:<tab><tab>if not submit:<tab><tab><tab>raise exceptions.InvalidSubmitError()<tab><tab><IF-STMT><tab><tab><tab>raise exceptions.InvalidSubmitError()<tab><tab>return _filter_fields(<tab><tab><tab>all_fields, lambda f: not isinstance(f, fields.Submit) or f == submit<tab><tab>)<tab>return all_fields",0,if submit not in submit_fields . getlist ( submit . name ) :,"elif not isinstance ( all_fields [ 0 ] , fields . Submit ) :",0.102487787,8.80464134,0.145454545
"def tag_configure(self, *args, **keys):<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab><IF-STMT><tab><tab><tab>self.configDict[key] = val<tab><tab>if underline:<tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",1,if val :,if val :,0.531170663,1.00E-10,1
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>code == 501<tab><tab><tab>and re.search(r""Reference #[0-9A-Fa-f.]+"", page, re.I) is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.531170663,1.00E-10,1
"def refine_pointer_names_input(lines):<tab>""""""Return  a list of width_info_t. Skip comments and blank lines""""""<tab>global comment_pattern<tab>widths_list = []<tab>for line in lines:<tab><tab>pline = comment_pattern.sub("""", line).strip()<tab><tab>if pline == """":<tab><tab><tab>continue<tab><tab>wrds = pline.split()<tab><tab>ntokens = len(wrds)<tab><tab><IF-STMT><tab><tab><tab>(bbytes, name, suffix) = wrds<tab><tab>else:<tab><tab><tab>die(""Bad number of tokens on line: "" + line)<tab><tab>widths_list.append((bbytes, name, suffix))<tab>return widths_list",0,if ntokens == 3 :,if ntokens == 1 :,0.394778655,53.72849659,0.6
"def notify(title, message, retcode=None):<tab>""""""Sends message over Telegram using telegram-send, title is ignored.""""""<tab>if not path.exists(config_file):<tab><tab><IF-STMT><tab><tab><tab>makedirs(config_dir)<tab><tab>print(""Follow the instructions to configure the Telegram backend.\n"")<tab><tab>configure(config_file)<tab>send(messages=[message], conf=config_file)",1,if not path . exists ( config_dir ) :,if not path . exists ( config_dir ) :,0.75,100,1
"def find_on_path(targets):<tab>""""""Search the PATH for a program and return full path""""""<tab>if sabnzbd.WIN32:<tab><tab>paths = os.getenv(""PATH"").split("";"")<tab>else:<tab><tab>paths = os.getenv(""PATH"").split("":"")<tab>if isinstance(targets, str):<tab><tab>targets = (targets,)<tab>for path in paths:<tab><tab>for target in targets:<tab><tab><tab>target_path = os.path.abspath(os.path.join(path, target))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return target_path<tab>return None",0,"if os . path . isfile ( target_path ) and os . access ( target_path , os . X_OK ) :",if os . path . exists ( target_path ) :,0.204406043,19.15973052,0.420833333
"def test_name_attribute(self):<tab>for cons in self.hash_constructors:<tab><tab>h = cons()<tab><tab>self.assertIsInstance(h.name, str)<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(h.name, self.supported_hash_names)<tab><tab>else:<tab><tab><tab>self.assertNotIn(h.name, self.supported_hash_names)<tab><tab>self.assertEqual(h.name, hashlib.new(h.name).name)",0,if h . name in self . supported_hash_names :,if h . is_in :,0.173827047,12.33717082,0.454545455
"def find_marriage(database, family):<tab>""""""find the marriage of a family""""""<tab>for event_ref in family.get_event_ref_list():<tab><tab>event = database.get_event_from_handle(event_ref.ref)<tab><tab><IF-STMT><tab><tab><tab>return event<tab>return None",0,if event and event . type . is_marriage ( ) and event_ref . role . is_family ( ) :,if event :,0.007340715,1.00E-10,0.415708812
"def test_find_ancestors(self):<tab>vhsblocks = self.config.parser_root.find_blocks(""VirtualHost"")<tab>macro_test = False<tab>nonmacro_test = False<tab>for vh in vhsblocks:<tab><tab><IF-STMT><tab><tab><tab>ancs = vh.find_ancestors(""Macro"")<tab><tab><tab>self.assertEqual(len(ancs), 1)<tab><tab><tab>macro_test = True<tab><tab>else:<tab><tab><tab>ancs = vh.find_ancestors(""Macro"")<tab><tab><tab>self.assertEqual(len(ancs), 0)<tab><tab><tab>nonmacro_test = True<tab>self.assertTrue(macro_test)<tab>self.assertTrue(nonmacro_test)",0,"if ""/macro/"" in vh . metadata [ ""augeaspath"" ] . lower ( ) :",if vh . is_macro :,0.015612969,2.578417783,0.30952381
def readline(self):<tab>while 1:<tab><tab>line = self._readline()<tab><tab><IF-STMT><tab><tab><tab>self._filelineno += 1<tab><tab><tab>return line<tab><tab>if not self._file:<tab><tab><tab>return line<tab><tab>self.nextfile(),1,if line :,if line :,0.531170663,1.00E-10,1
"def read_oclc(fields):<tab>if ""035"" not in fields:<tab><tab>return {}<tab>found = []<tab>for line in fields[""035""]:<tab><tab>for v in get_subfield_values(line, [""a""]):<tab><tab><tab>m = re_oclc.match(v)<tab><tab><tab>if not m:<tab><tab><tab><tab>continue<tab><tab><tab>oclc = m.group(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found.append(oclc)<tab>return {""oclc_number"": found} if found else {}",1,if oclc not in found :,if oclc not in found :,0.75,100,1
"def get_new_unlinked_nodes(<tab>before_inputted_nodes, before_input_sockets, input_sockets, nodes_dict):<tab>affected_nodes = []<tab>for node_id, socket in zip(before_inputted_nodes, before_input_sockets):<tab><tab>if not socket in input_sockets:<tab><tab><tab># if the node has been deleted it is not affected<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if not node_id in affected_nodes:<tab><tab><tab><tab><tab>affected_nodes.append(node_id)<tab>return affected_nodes",0,if node_id in nodes_dict :,if node_id not in nodes_dict :,0.272109132,65.80370065,0.464285714
"def set_available_qty(self):<tab>for d in self.get(""required_items""):<tab><tab><IF-STMT><tab><tab><tab>d.available_qty_at_source_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, d.source_warehouse<tab><tab><tab>)<tab><tab>if self.wip_warehouse:<tab><tab><tab>d.available_qty_at_wip_warehouse = get_latest_stock_qty(<tab><tab><tab><tab>d.item_code, self.wip_warehouse<tab><tab><tab>)",1,if d . source_warehouse :,if d . source_warehouse :,0.75,100,1
"def _unique_product_recursive(pools, result, i):<tab>if i >= len(pools):<tab><tab>yield tuple(result)<tab><tab>return<tab>for e in pools[i]:<tab><tab><IF-STMT><tab><tab><tab>result[i] = e<tab><tab><tab>yield from _unique_product_recursive(pools, result, i + 1)<tab><tab><tab>result[i] = _SENTINEL",1,if e not in result :,if e not in result :,0.75,100,1
def fileno(self):<tab>try:<tab><tab>return self.sock.fileno()<tab>except socket.error:<tab><tab>self.close()<tab><tab>ex = sys.exc_info()[1]<tab><tab><IF-STMT><tab><tab><tab>raise EOFError()<tab><tab>else:<tab><tab><tab>raise,0,if get_exc_errno ( ex ) == errno . EBADF :,if ex . args [ 0 ] == errno . EINTR :,0.107501177,19.07078043,0.357142857
"def expand_block(self, feat):<tab>""""""Expand any blocks which are near the start or end of a contig.""""""<tab>chrom_end = self._ref_sizes.get(feat.chrom)<tab>if chrom_end:<tab><tab>if feat.start < self._end_buffer:<tab><tab><tab>feat.start = 0<tab><tab><IF-STMT><tab><tab><tab>feat.stop = chrom_end<tab>return feat",0,if feat . stop >= chrom_end - self . _end_buffer :,if feat . stop > chrom_end :,0.232488881,25.27469657,0.786666667
"def prepare_parser(self, parser):<tab>docs = [self.parse_doc(doc) for doc in (self.doc, __doc__) if doc]<tab>for doc in docs:<tab><tab>for long_opt, help in items(doc):<tab><tab><tab>option = parser._option_string_actions[long_opt]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>option.help = "" "".join(help).format(default=option.default)<tab>return parser",0,if option is not None :,if help :,0.026485502,1.00E-10,0.2
"def negate(monad):<tab>sql = monad.getsql()[0]<tab>translator = monad.translator<tab>if translator.dialect == ""Oracle"":<tab><tab>result_sql = [""IS_NULL"", sql]<tab>else:<tab><tab>result_sql = [""EQ"", sql, [""VALUE"", """"]]<tab><tab>if monad.nullable:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result_sql = [""OR"", result_sql, [""IS_NULL"", sql]]<tab><tab><tab>else:<tab><tab><tab><tab>result_sql = [""EQ"", [""COALESCE"", sql, [""VALUE"", """"]], [""VALUE"", """"]]<tab>result = BoolExprMonad(result_sql, nullable=False)<tab>result.aggregated = monad.aggregated<tab>return result",0,"if isinstance ( monad , AttrMonad ) :","if translator . dialect == ""Oracle"" :",0.018333425,4.990049702,0.26984127
"def _ReadN(self, stdin_fd, n):<tab># type: (int, int) -> str<tab>chunks = []  # type: List[str]<tab>bytes_left = n<tab>while bytes_left > 0:<tab><tab>chunk = posix.read(stdin_fd, n)  # read at up to N chars<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>chunks.append(chunk)<tab><tab>bytes_left -= len(chunk)<tab>s = """".join(chunks)<tab>return s",0,if len ( chunk ) == 0 :,if not chunk :,0.019930836,6.023021416,0.481481481
"def instance_reader():<tab>for epoch_index in range(epoch):<tab><tab>if shuffle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>np.random.seed(shuffle_seed)<tab><tab><tab>np.random.shuffle(examples)<tab><tab>if phase == ""train"":<tab><tab><tab>self.current_train_epoch = epoch_index<tab><tab>for (index, example) in enumerate(examples):<tab><tab><tab>if phase == ""train"":<tab><tab><tab><tab>self.current_train_example = index + 1<tab><tab><tab>feature = self.convert_example(<tab><tab><tab><tab>index, example, self.get_labels(), self.max_seq_len, self.tokenizer<tab><tab><tab>)<tab><tab><tab>instance = self.generate_instance(feature)<tab><tab><tab>yield instance",0,if shuffle_seed is not None :,if shuffle_seed :,0.050438393,1.00E-10,0.314285714
"def close(self):<tab>fileobj = self.fileobj<tab>if fileobj is None:<tab><tab>return<tab>self.fileobj = None<tab>try:<tab><tab>if self.mode == WRITE:<tab><tab><tab>fileobj.write(self.compress.flush())<tab><tab><tab>write32u(fileobj, self.crc)<tab><tab><tab># self.size may exceed 2GB, or even 4GB<tab><tab><tab>write32u(fileobj, self.size & 0xFFFFFFFF)<tab>finally:<tab><tab>myfileobj = self.myfileobj<tab><tab><IF-STMT><tab><tab><tab>self.myfileobj = None<tab><tab><tab>myfileobj.close()",0,if myfileobj :,if myfileobj is not None :,0.090364769,1.00E-10,0.4
"def rsa_public_key_parse(key_material):<tab># These imports take ~.5s; let's keep them local<tab>import sshpubkeys.exceptions<tab>from sshpubkeys.keys import SSHKey<tab>try:<tab><tab><IF-STMT><tab><tab><tab>key_material = key_material.encode(""ascii"")<tab><tab>decoded_key = base64.b64decode(key_material).decode(""ascii"")<tab><tab>public_key = SSHKey(decoded_key)<tab>except (sshpubkeys.exceptions.InvalidKeyException, UnicodeDecodeError):<tab><tab>raise ValueError(""bad key"")<tab>if not public_key.rsa:<tab><tab>raise ValueError(""bad key"")<tab>return public_key.rsa",0,"if not isinstance ( key_material , six . binary_type ) :","if isinstance ( key_material , str ) :",0.148528651,36.31941765,0.322222222
"def import_type(library, name):<tab>if library.name != idaapi.cvar.idati.name:<tab><tab>last_ordinal = idaapi.get_ordinal_qty(idaapi.cvar.idati)<tab><tab>type_id = idaapi.import_type(library, -1, name)  # tid_t<tab><tab><IF-STMT><tab><tab><tab>return last_ordinal",0,if type_id != idaapi . BADORD :,if type_id == idaapi . cvar . idati . name :,0.125251421,26.58483577,0.408163265
"def OnDropFiles(self, x, y, files):<tab>filteredList = []<tab>if self.filenameFilter is not None:<tab><tab>for f in files:<tab><tab><tab>for ext in self.filenameFilter:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>filteredList.append(f)<tab>else:<tab><tab>filteredList = files<tab>if len(filteredList) > 0:<tab><tab>self.callback(filteredList)",0,if f . endswith ( ext ) or f . endswith ( ext . upper ( ) ) :,if f . endswith ( ext ) :,0.206989143,22.84663654,0.542857143
"def _get_most_recent_update(self, versions):<tab>recent = None<tab>for version in versions:<tab><tab>updated = datetime.datetime.strptime(version[""updated""], ""%Y-%m-%dT%H:%M:%SZ"")<tab><tab>if not recent:<tab><tab><tab>recent = updated<tab><tab><IF-STMT><tab><tab><tab>recent = updated<tab>return recent.strftime(""%Y-%m-%dT%H:%M:%SZ"")",1,elif updated > recent :,elif updated > recent :,0.75,100,1
"def __setstate__(self, servers_ids: List[str]):<tab>self.try_list = []<tab>for server_id in servers_ids:<tab><tab><IF-STMT><tab><tab><tab>self.add_to_try_list(sabnzbd.Downloader.server_dict[server_id])",1,if server_id in sabnzbd . Downloader . server_dict :,if server_id in sabnzbd . Downloader . server_dict :,0.75,100,1
"def remove_command(self, command_id):<tab>for command in self.config[""commands""]:<tab><tab><IF-STMT><tab><tab><tab>self.config[""commands""].remove(command)<tab><tab><tab>component.get(""EventManager"").emit(ExecuteCommandRemovedEvent(command_id))<tab><tab><tab>break<tab>self.config.save()",0,if command [ EXECUTE_ID ] == command_id :,"if command [ ""id"" ] == command_id :",0.251462237,57.83569866,1
"def wrapper(*args, **kargs):<tab>offspring = func(*args, **kargs)<tab>for child in offspring:<tab><tab>for i in xrange(len(child)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child[i] = max<tab><tab><tab>elif child[i] < min:<tab><tab><tab><tab>child[i] = min<tab>return offspring",1,if child [ i ] > max :,if child [ i ] > max :,0.75,100,1
"def dispatch(self, request, *args, **kwargs):<tab>self.product = get_object_or_404(self.product_model, pk=kwargs[""product_pk""])<tab># check permission to leave review<tab>if not self.product.is_review_permitted(request.user):<tab><tab><IF-STMT><tab><tab><tab>message = _(""You have already reviewed this product!"")<tab><tab>else:<tab><tab><tab>message = _(""You can't leave a review for this product."")<tab><tab>messages.warning(self.request, message)<tab><tab>return redirect(self.product.get_absolute_url())<tab>return super().dispatch(request, *args, **kwargs)",0,if self . product . has_review_by ( request . user ) :,if self . product . reviewed :,0.166460975,17.78861689,0.561904762
"def PlayPause(self):<tab>state = self.graphManager.GetState(10)<tab>if state == 2:  # playing<tab><tab>self.Pause()<tab>elif state == 1:  # paused<tab><tab>self.Play()<tab>elif state == 0:  # stopped<tab><tab><IF-STMT><tab><tab><tab>self.Stop()<tab><tab><tab>self.PlayingItem = self.SelectedItem<tab><tab><tab>self.LoadFile(self.SelectedItem.Path)<tab><tab><tab>self.Play()<tab><tab>else:<tab><tab><tab>self.Play()<tab>else:<tab><tab>pass  # for now just do nothing<tab>self.NotifyPropertyChanged(""IsPlaying"")<tab>self.NotifyPropertyChanged(""Duration"")",0,if ( self . SelectedItem != None ) and ( self . filename != self . SelectedItem . Path ) :,if self . selectedItem is not None :,0.01036969,2.129808374,0.301282051
"def decref(self, *keys):<tab>for tileable_key, tileable_id in keys:<tab><tab>if tileable_key not in self._executed_tileables:<tab><tab><tab>continue<tab><tab>_graph_key, ids = self._executed_tileables[tileable_key]<tab><tab><IF-STMT><tab><tab><tab>ids.remove(tileable_id)<tab><tab><tab># for those same key tileables, do decref only when all those tileables are garbage collected<tab><tab><tab>if len(ids) != 0:<tab><tab><tab><tab>continue<tab><tab><tab>self.delete_data(tileable_key)",1,if tileable_id in ids :,if tileable_id in ids :,0.75,100,1
"def get_git_description(self):<tab>if self.is_a_git_repo():<tab><tab>exit_code, stdout, stderr = execute_command_and_capture_output(<tab><tab><tab>""git"", ""describe"", ""--always"", ""--tags"", ""--dirty""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise PyBuilderException(<tab><tab><tab><tab>""Cannot determine git description: git describe failed:\n{0}"".format(<tab><tab><tab><tab><tab>stderr<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return stdout.strip()<tab>else:<tab><tab>raise PyBuilderException(<tab><tab><tab>""Cannot determine git description: project is not a git repo.""<tab><tab>)",1,if exit_code != 0 :,if exit_code != 0 :,0.75,100,1
"def _code_for_module(self, module):<tab>text = '""%s"" [shape=ellips]' % module.name<tab>for item in list(module.items()):<tab><tab><IF-STMT><tab><tab><tab>text += '\n""%s""' % item<tab><tab><tab>text += '\n""%s"" -> ""%s""' % (module.name, item)<tab><tab>else:<tab><tab><tab>text += self._code_for_module(item)  # recurs<tab><tab><tab>text += '\n""%s"" -> ""%s""' % (module.name, item.name)<tab>return text",1,"if isinstance ( item , str ) :","if isinstance ( item , str ) :",0.75,100,1
"def test_images_p_is_stochastic_parameter(self):<tab>aug = self.create_aug(p=iap.Choice([0, 1], p=[0.7, 0.3]))<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>observed = aug.augment_image(self.image)<tab><tab><IF-STMT><tab><tab><tab>seen[0] += 1<tab><tab>elif np.array_equal(observed, self.image_flipped):<tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert np.allclose(seen, [700, 300], rtol=0, atol=75)",0,"if np . array_equal ( observed , self . image ) :","if np . array_equal ( observed , self . image_stochastic ) :",0.635663651,76.70387248,0.822222222
"def get_index_text(self, modname: str, name_cls: Tuple[str, str]) -> str:<tab>if self.objtype == ""function"":<tab><tab><IF-STMT><tab><tab><tab>return _(""%s() (built-in function)"") % name_cls[0]<tab><tab>return _(""%s() (in module %s)"") % (name_cls[0], modname)<tab>elif self.objtype == ""data"":<tab><tab>if not modname:<tab><tab><tab>return _(""%s (built-in variable)"") % name_cls[0]<tab><tab>return _(""%s (in module %s)"") % (name_cls[0], modname)<tab>else:<tab><tab>return """"",1,if not modname :,if not modname :,0.75,100,1
"def _attributes_to_xml(self, xml_element, prefix_root, debug_context=None):<tab>del debug_context  # Unused.<tab>for attribute_name, attribute in six.iteritems(self._attributes):<tab><tab>attribute_value = attribute.to_xml_string(prefix_root)<tab><tab>if attribute_name == self._spec.identifier and attribute_value is None:<tab><tab><tab>xml_element.set(attribute_name, self.full_identifier)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>xml_element.set(attribute_name, attribute_value)",0,elif attribute_value is None :,elif attribute_name == self . full_identifier :,0.025793944,13.54599427,0.377777778
def index_def(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.index_def_ is None:<tab><tab><tab><tab>self.index_def_ = Index()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.index_def_,1,if self . index_def_ is None :,if self . index_def_ is None :,0.75,100,1
"def _ord_to_str(ordinal, weights):<tab>""""""Reverse function of _str_to_ord.""""""<tab>chars = []<tab>for weight in weights:<tab><tab><IF-STMT><tab><tab><tab>return """".join(chars)<tab><tab>ordinal -= 1<tab><tab>index, ordinal = divmod(ordinal, weight)<tab><tab>chars.append(_ALPHABET[index])<tab>return """".join(chars)",0,if ordinal == 0 :,if weight == 0 :,0.394778655,53.72849659,0.6
"def tip_texts(self):<tab>""""""Return the tip texts of the Toolbar (without window text)""""""<tab>texts = []<tab>for i in range(0, self.button_count()):<tab><tab># it works for MFC<tab><tab>btn_tooltip_index = self.get_button_struct(i).iString<tab><tab># usually iString == -1 for separator<tab><tab># other cases if any<tab><tab><IF-STMT><tab><tab><tab>btn_tooltip_index = i<tab><tab>btn_text = self.get_tool_tips_control().get_tip_text(btn_tooltip_index + 1)<tab><tab>texts.append(btn_text)<tab>return texts",0,if not ( - 1 <= btn_tooltip_index < self . get_tool_tips_control ( ) . tool_count ( ) ) :,if btn_tooltip_index == - 1 :,0.033311329,6.538699381,0.3875
"def _initCaseSets(self):<tab>self._cs = {}<tab>self._css = {}<tab>for cs in self._caseSets:<tab><tab>if not self._cs.has_key(cs.CaseSetName):<tab><tab><tab>self._cs[cs.CaseSetName] = {}<tab><tab><tab>self._css[cs.CaseSetName] = cs<tab><tab>else:<tab><tab><tab>raise Exception(""duplicate case set name"")<tab><tab>for c in cs.Cases:<tab><tab><tab>idx = tuple(c.index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._cs[cs.CaseSetName][idx] = c<tab><tab><tab>else:<tab><tab><tab><tab>raise Exception(""duplicate case index"")",0,if not self . _cs [ cs . CaseSetName ] . has_key ( idx ) :,if not self . _cs . has_key ( cs . CaseSetName ) :,0.245375058,53.68332812,0.850340136
"def is_image(self, input):<tab>try:<tab><tab>if isinstance(input, (np.ndarray, Image.Image)):<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>if not os.path.isfile(input):<tab><tab><tab><tab>raise ValueError(""input must be a file"")<tab><tab><tab>img = Image.open(input)<tab><tab><tab>_ = img.size<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return False<tab>except:<tab><tab>return False",1,"elif isinstance ( input , str ) :","elif isinstance ( input , str ) :",0.75,100,1
"def __init__(self, opt, shared=None):<tab>super().__init__(opt, shared)<tab>if not shared:<tab><tab>self.episodes = []<tab><tab>self.num_exs = 0<tab><tab><IF-STMT><tab><tab><tab>self._setup_data(opt.get(""parlaidialogteacher_datafile""))<tab>else:<tab><tab>self.episodes = shared[""episodes""]<tab><tab>self.num_exs = sum(len(e) for e in self.episodes)<tab>self.id = opt[""task""]<tab>self.reset()",0,"if opt . get ( ""parlaidialogteacher_datafile"" ) is not None :","if opt . get ( ""parlaidialogteacher_datafile"" ) :",0.3837916,71.92016995,0.538461538
"def draw(l, n, th=2):<tab>clear()<tab>l = l * f ** n<tab>shapesize(l / 100.0, l / 100.0, th)<tab>for k in tiledict:<tab><tab>h, x, y = k<tab><tab>setpos(x, y)<tab><tab>setheading(h)<tab><tab><IF-STMT><tab><tab><tab>shape(""kite"")<tab><tab><tab>color(""black"", (0, 0.75, 0))<tab><tab>else:<tab><tab><tab>shape(""dart"")<tab><tab><tab>color(""black"", (0.75, 0, 0))<tab><tab>stamp()",0,if tiledict [ k ] :,if n == 1 :,0.027136592,9.652434877,0.333333333
"def visit_Assign(self, node):<tab>if len(node.targets) == 1:<tab><tab>if isinstance(node.targets[0], ast.Subscript):<tab><tab><tab>plugPath = self.__plugPath(self.__path(node.targets[0]))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.plugWrites.add(plugPath)<tab>self.visit(node.value)",0,if plugPath :,if plugPath not in self . plugWrites :,0.207730182,1.00E-10,0.357142857
"def StripTypeInfo(rendered_data):<tab>""""""Strips type information from rendered data. Useful for debugging.""""""<tab>if isinstance(rendered_data, (list, tuple)):<tab><tab>return [StripTypeInfo(d) for d in rendered_data]<tab>elif isinstance(rendered_data, dict):<tab><tab><IF-STMT><tab><tab><tab>return StripTypeInfo(rendered_data[""value""])<tab><tab>else:<tab><tab><tab>result = {}<tab><tab><tab>for k, v in rendered_data.items():<tab><tab><tab><tab>result[k] = StripTypeInfo(v)<tab><tab><tab>return result<tab>else:<tab><tab>return rendered_data",0,"if ""value"" in rendered_data and ""type"" in rendered_data :","if ""value"" in rendered_data :",0.193594386,41.11122905,0.625
"def _match_greater_than_or_equal(search_base, attribute, value, candidates):<tab>matches = list()<tab>for entry in candidates:<tab><tab>dn = entry.get(""dn"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value_from_directory = entry.get(""attributes"").get(attribute)<tab><tab>if str(value_from_directory) >= str(value):<tab><tab><tab>entry[""type""] = ""searchResEntry""<tab><tab><tab>matches.append(entry)<tab>return matches",0,if not dn . endswith ( search_base ) :,if dn . startswith ( search_base ) :,0.18845666,54.18220426,0.318181818
"def _get_changes(diff):<tab>""""""Get a list of changed versions from git.""""""<tab>changes_dict = {}<tab>for line in diff:<tab><tab>if not line.startswith(""-"") and not line.startswith(""+""):<tab><tab><tab>continue<tab><tab>if line.startswith(""+++ "") or line.startswith(""--- ""):<tab><tab><tab>continue<tab><tab>name, version = parse_versioned_line(line[1:])<tab><tab><IF-STMT><tab><tab><tab>changes_dict[name] = Change(name)<tab><tab>if line.startswith(""-""):<tab><tab><tab>changes_dict[name].old = version<tab><tab>elif line.startswith(""+""):<tab><tab><tab>changes_dict[name].new = version<tab>return [change for _name, change in sorted(changes_dict.items())]",1,if name not in changes_dict :,if name not in changes_dict :,0.75,100,1
"def append_row(tbody, cells):<tab>row = nodes.row()<tab>tbody += row<tab>for cell in cells:<tab><tab>entry = nodes.entry()<tab><tab>row += entry<tab><tab><IF-STMT><tab><tab><tab>node = nodes.paragraph(text=cell)<tab><tab>else:<tab><tab><tab>node = cell<tab><tab>entry += node",0,"if isinstance ( cell , six . text_type ) :",if cell . text :,0.015145995,6.624642068,0.320512821
"def _testdata_to_is_unauthed_access_permitted(tests_config, node_type):<tab>res = []<tab>for x in tests_config[""endpoint_tests""]:<tab><tab>if node_type not in x[""type""]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>h = x[""tests""][""is_unauthed_access_permitted""]<tab><tab>for p in h[""locations""]:<tab><tab><tab>res.append((p, h.get(""vhost"", None)))<tab>return res",1,"if ""is_unauthed_access_permitted"" not in x [ ""tests"" ] :","if ""is_unauthed_access_permitted"" not in x [ ""tests"" ] :",0.75,100,1
"def process_ceph_status(output):<tab>res = patternchk.search(output)<tab>if not res:<tab><tab>return {}<tab>ceph_stats = res.group()<tab>if not ceph_stats:<tab><tab>return {}<tab>ret = {}<tab>rd = wr = iops = None<tab>rd = numberchk.search(ceph_stats)<tab>if rd is not None:<tab><tab>ret[""rd""] = rd.group()<tab><tab>wr = numberchk.search(ceph_stats, rd.end())<tab><tab>if wr is not None:<tab><tab><tab>ret[""wr""] = wr.group()<tab><tab><tab>iops = numberchk.search(ceph_stats, wr.end())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret[""iops""] = iops.group()<tab>return ret",1,if iops is not None :,if iops is not None :,0.75,100,1
"def construct_type_storage_plugin_registry(pipeline_def, system_storage_def):<tab># Needed to avoid circular dep<tab>from dagster.core.definitions import PipelineDefinition, SystemStorageDefinition<tab>check.inst_param(pipeline_def, ""pipeline_def"", PipelineDefinition)<tab>check.inst_param(system_storage_def, ""system_storage_def"", SystemStorageDefinition)<tab>type_plugins = []<tab>for type_obj in pipeline_def.all_runtime_types():<tab><tab>for auto_plugin in type_obj.auto_plugins:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>type_plugins.append((type_obj, auto_plugin))<tab>return TypeStoragePluginRegistry(type_plugins)",0,if auto_plugin . compatible_with_storage_def ( system_storage_def ) :,if auto_plugin not in type_plugins :,0.035264605,10.69482073,0.458333333
"def attr(**kw):<tab>kw = kw.items()<tab>kw.sort()<tab>parts = []<tab>for name, value in kw:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if name.endswith(""_""):<tab><tab><tab>name = name[:-1]<tab><tab>parts.append('%s=""%s""' % (html_quote(name), html_quote(value)))<tab>return html("" "".join(parts))",1,if value is None :,if value is None :,0.75,100,1
"def test_shape():<tab>from lasagne.init import Initializer<tab># Assert that all `Initializer` sublasses return the shape that<tab># we've asked for in `sample`:<tab>for klass in Initializer.__subclasses__():<tab><tab><IF-STMT><tab><tab><tab># check HeNormal, HeUniform, GlorotNormal, GlorotUniform<tab><tab><tab>for sub_klass in klass.__subclasses__():<tab><tab><tab><tab>assert sub_klass().sample((12, 23)).shape == (12, 23)<tab><tab>else:<tab><tab><tab>assert klass().sample((12, 23)).shape == (12, 23)",0,if len ( klass . __subclasses__ ( ) ) :,"if isinstance ( klass , type ) :",0.034868871,7.80152171,0.487179487
"def __call__(self, data):<tab>num_points = data.pos.shape[0]<tab>new_data = Data()<tab>for key in data.keys:<tab><tab>if key == KDTREE_KEY:<tab><tab><tab>continue<tab><tab>item = data[key]<tab><tab>if torch.is_tensor(item) and num_points == item.shape[0]:<tab><tab><tab>item = item[self._indices].clone()<tab><tab><IF-STMT><tab><tab><tab>item = item.clone()<tab><tab>setattr(new_data, key, item)<tab>return new_data",0,elif torch . is_tensor ( item ) :,elif torch . is_tensor ( item ) and num_points == item . shape [ 0 ] :,0.432374582,37.19447442,0.5
"def vars(self):<tab>ret = []<tab>if op.disklist:<tab><tab>varlist = op.disklist<tab>elif not op.full:<tab><tab>varlist = (""total"",)<tab>else:<tab><tab>varlist = []<tab><tab>for name in self.discover:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>varlist.append(name)<tab><tab>#<tab><tab>   if len(varlist) > 2: varlist = varlist[0:2]<tab><tab>varlist.sort()<tab>for name in varlist:<tab><tab>if name in self.discover + [""total""] or name in op.diskset:<tab><tab><tab>ret.append(name)<tab>return ret",0,if self . diskfilter . match ( name ) :,if name in op . diskset :,0.015765595,6.050259138,0.222222222
"def _convertNbBytesinNbBits(self, nbBytes):<tab>nbMinBit = None<tab>nbMaxBit = None<tab>if nbBytes is not None:<tab><tab><IF-STMT><tab><tab><tab>nbMinBit = nbBytes * 8<tab><tab><tab>nbMaxBit = nbMinBit<tab><tab>else:<tab><tab><tab>if nbBytes[0] is not None:<tab><tab><tab><tab>nbMinBit = nbBytes[0] * 8<tab><tab><tab>if nbBytes[1] is not None:<tab><tab><tab><tab>nbMaxBit = nbBytes[1] * 8<tab>return (nbMinBit, nbMaxBit)",0,"if isinstance ( nbBytes , int ) :",if nbMinBit is not None :,0.017835632,6.916271813,0.206349206
"def after_test(self, results, tmp_dir):<tab>return_data = dict()<tab>if not results or not results.get(""data""):<tab><tab>return return_data<tab>for filename in results[""data""]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with open(filename, ""r"") as f:<tab><tab><tab>log_content = f.read()<tab><tab>log_analyser.make_log_analyses(log_content, return_data)<tab>return return_data",0,"if not has_ext ( filename , "".log"" ) :",if not os . path . isfile ( filename ) :,0.040020249,10.27204899,0.395604396
"def ensure_vm_was_torn_down():<tab>vm_labels = []<tab>for vm_ref in xenapi_fake.get_all(""VM""):<tab><tab>vm_rec = xenapi_fake.get_record(""VM"", vm_ref)<tab><tab><IF-STMT><tab><tab><tab>vm_labels.append(vm_rec[""name_label""])<tab>self.assertEquals(vm_labels, [""1""])",0,"if not vm_rec [ ""is_control_domain"" ] :","if ""name_label"" in vm_rec :",0.023846651,12.39269996,0.5
"def spool_print(*args, **kwargs):<tab>with _print_lock:<tab><tab>if framework.Framework._spool:<tab><tab><tab>framework.Framework._spool.write(f""{args[0]}{os.linesep}"")<tab><tab><tab>framework.Framework._spool.flush()<tab><tab># disable terminal output for server jobs<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab># new print function must still use the old print function via the backup<tab><tab>builtins._print(*args, **kwargs)",0,if framework . Framework . _mode == Mode . JOB :,"if args [ 0 ] == ""127.0.0.1"" :",0.013374522,7.431878015,0.265306122
"def _parse_lines(self, linesource):<tab>""""""Parse lines of text for functions and classes""""""<tab>functions = []<tab>classes = []<tab>for line in linesource:<tab><tab><IF-STMT><tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>functions.append(name)<tab><tab>elif line.startswith(""class ""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>classes.append(name)<tab><tab>else:<tab><tab><tab>pass<tab>functions.sort()<tab>classes.sort()<tab>return functions, classes",0,"if line . startswith ( ""def "" ) and line . count ( ""("" ) :","if line . startswith ( ""function "" ) :",0.221700011,26.75378818,0.589371981
"def test_connect_using_sslcontext_verified(self):<tab>with support.transient_internet(self.testServer):<tab><tab>can_verify = check_ssl_verifiy(self.testServer, self.remotePort)<tab><tab><IF-STMT><tab><tab><tab>self.skipTest(""SSL certificate can't be verified"")<tab>support.get_attribute(smtplib, ""SMTP_SSL"")<tab>context = ssl.create_default_context()<tab>with support.transient_internet(self.testServer):<tab><tab>server = smtplib.SMTP_SSL(self.testServer, self.remotePort, context=context)<tab><tab>server.ehlo()<tab><tab>server.quit()",1,if not can_verify :,if not can_verify :,0.75,100,1
"def generate_segment_memory(chart_type, race_configs, environment):<tab>structures = []<tab>for race_config in race_configs:<tab><tab><IF-STMT><tab><tab><tab>title = chart_type.format_title(<tab><tab><tab><tab>environment,<tab><tab><tab><tab>race_config.track,<tab><tab><tab><tab>es_license=race_config.es_license,<tab><tab><tab><tab>suffix=""%s-segment-memory"" % race_config.label,<tab><tab><tab>)<tab><tab><tab>chart = chart_type.segment_memory(title, environment, race_config)<tab><tab><tab>if chart:<tab><tab><tab><tab>structures.append(chart)<tab>return structures",0,"if ""segment_memory"" in race_config . charts :",if not race_config . chart :,0.043785007,20.47925971,0.333333333
"def __iter__(self):<tab>line = b""""<tab>while True:<tab><tab>data = self.read(-1)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>generator = StringIO(data)<tab><tab>assert b""\n"" not in line, line<tab><tab>line += next(generator)<tab><tab>if line.endswith(b""\n""):<tab><tab><tab>yield line<tab><tab><tab>line = b""""<tab><tab><tab>ll = list(generator)<tab><tab><tab>if not ll:<tab><tab><tab><tab>continue<tab><tab><tab>for line in ll[:-1]:<tab><tab><tab><tab>yield line<tab><tab><tab>line = ll[-1]<tab><tab><tab>if line.endswith(b""\n""):<tab><tab><tab><tab>yield line<tab><tab><tab><tab>line = b""""<tab>if line:<tab><tab>yield line",1,if not data :,if not data :,0.75,100,1
"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>if x.type in float_types:<tab><tab>return (gz * sgn(x),)<tab>return (gz * x / abs(x),)  # formula works for complex and real",1,if x . type in discrete_types :,if x . type in discrete_types :,0.75,100,1
"def is_ncname(name):<tab>first = name[0]<tab>if first == ""_"" or category(first) in NAME_START_CATEGORIES:<tab><tab>for i in xrange(1, len(name)):<tab><tab><tab>c = name[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if c in ALLOWED_NAME_CHARS:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>return 0<tab><tab><tab># if in compatibility area<tab><tab><tab># if decomposition(c)!='':<tab><tab><tab>#<tab>return 0<tab><tab>return 1<tab>else:<tab><tab>return 0",0,if not category ( c ) in NAME_CATEGORIES :,if c not in NAME_START_CATEGORIES :,0.018728518,25.54173603,0.314814815
"def _read_rows_from(self, avro_reader, header):<tab>count = 0<tab>maximum = self.limit if self.limit is not None else sys.maxsize<tab>for i, record in enumerate(avro_reader):<tab><tab>if i < self.skip:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>count += 1<tab><tab>row = self._map_row_from(header, record)<tab><tab>yield row",1,if count >= maximum :,if count >= maximum :,0.75,100,1
"def decorated(cls, *args, **kwargs):<tab>storage_res = STORAGE_RES_MAPPING[cls.__class__.__name__][func.__name__]<tab>with utils.patch_vnxsystem as patched_vnx:<tab><tab><IF-STMT><tab><tab><tab>patched_vnx.return_value = storage_res[DEFAULT_STORAGE_RES]<tab><tab>adapter = PROTOCOL_MAPPING[protocol](cls.configuration)<tab>return func(cls, adapter, storage_res, *args, **kwargs)",1,if DEFAULT_STORAGE_RES in storage_res :,if DEFAULT_STORAGE_RES in storage_res :,0.75,100,1
"def _replace_file(src, dst):<tab>try:<tab><tab><IF-STMT>  # MOVEFILE_REPLACE_EXISTING<tab><tab><tab>raise OSError('Could not replace ""%s"" -> ""%s""' % (src, dst))<tab>except:<tab><tab># Sometimes it fails - we play stupid and try again...<tab><tab>time.sleep(0.5)<tab><tab>if not _MoveFileEx(src, dst, 1):  # MOVEFILE_REPLACE_EXISTING<tab><tab><tab>raise OSError('Could not replace ""%s"" -> ""%s""' % (src, dst))",1,"if not _MoveFileEx ( src , dst , 1 ) :","if not _MoveFileEx ( src , dst , 1 ) :",0.75,100,1
"def read_track_raw(self, redundancy=1):<tab>self._log(""read track raw"")<tab>data = []<tab>await self.lower.write([CMD_READ_RAW, redundancy])<tab>while True:<tab><tab>packet = await self.lower.read()<tab><tab><IF-STMT><tab><tab><tab>raise GlasgowAppletError(""FIFO overflow while reading track"")<tab><tab>elif packet[-1] == 0xFE:<tab><tab><tab>data.append(packet[:-1])<tab><tab><tab>return b"""".join(data)<tab><tab>else:<tab><tab><tab>data.append(packet)",0,if packet [ - 1 ] == 0xFF :,if len ( packet ) == 0 :,0.017863351,10.72925619,0.285714286
"def get_template_sources(self, template_name, template_dirs=None):<tab>template_name = self.prepare_template_name(template_name)<tab>for loader in self.template_source_loaders:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>for result in loader.get_template_sources(template_name, template_dirs):<tab><tab><tab><tab><tab>yield result<tab><tab><tab>except UnicodeDecodeError:<tab><tab><tab><tab># The template dir name was a bytestring that wasn't valid UTF-8.<tab><tab><tab><tab>raise<tab><tab><tab>except ValueError:<tab><tab><tab><tab># The joined path was located outside of this particular<tab><tab><tab><tab># template_dir (it might be inside another one, so this isn't<tab><tab><tab><tab># fatal).<tab><tab><tab><tab>pass",1,"if hasattr ( loader , ""get_template_sources"" ) :","if hasattr ( loader , ""get_template_sources"" ) :",0.75,100,1
"def __init__(self, reg, shtype, shimm, va):<tab>if shimm == 0:<tab><tab>if shtype == S_ROR:<tab><tab><tab>shtype = S_RRX<tab><tab><IF-STMT><tab><tab><tab>shimm = 32<tab>self.reg = reg<tab>self.shtype = shtype<tab>self.shimm = shimm<tab>self.va = va",0,elif shtype == S_LSR or shtype == S_ASR :,elif shtype == S_RRX :,0.147315181,29.47659609,0.625
"def pop_many(self, limit=None):<tab>if limit is None:<tab><tab>limit = DEFAULT_SYNC_OFFLINE_ACTIVITY<tab>heartbeats = []<tab>count = 0<tab>while count < limit:<tab><tab>heartbeat = self.pop()<tab><tab>if not heartbeat:<tab><tab><tab>break<tab><tab>heartbeats.append(heartbeat)<tab><tab>count += 1<tab><tab><IF-STMT><tab><tab><tab>yield heartbeats<tab><tab><tab>heartbeats = []<tab>if heartbeats:<tab><tab>yield heartbeats",0,if count % HEARTBEATS_PER_REQUEST == 0 :,if len ( heartbeats ) >= limit :,0.019801327,4.495986993,0.26984127
"def _set_live(self, live, _):<tab>if live is not None and not self.live:<tab><tab><IF-STMT><tab><tab><tab>live = [live]<tab><tab># Default is to use Memory analysis.<tab><tab>if len(live) == 0:<tab><tab><tab>mode = ""Memory""<tab><tab>elif len(live) == 1:<tab><tab><tab>mode = live[0]<tab><tab>else:<tab><tab><tab>raise RuntimeError(""--live parameter should specify only one mode."")<tab><tab>live_plugin = self.session.plugins.live(mode=mode)<tab><tab>live_plugin.live()<tab><tab># When the session is destroyed, close the live plugin.<tab><tab>self.session.register_flush_hook(self, live_plugin.close)<tab>return live",0,"if isinstance ( live , basestring ) :","if not isinstance ( live , list ) :",0.200294835,36.88939732,0.26984127
"def capture_output(redirect_stderr=True):<tab>oldout, olderr = sys.stdout, sys.stderr<tab>try:<tab><tab>out = StringIO()<tab><tab>sys.stdout = out<tab><tab><IF-STMT><tab><tab><tab>sys.stderr = out<tab><tab>else:<tab><tab><tab>sys.stderr = StringIO()<tab><tab>yield out<tab>except:<tab><tab>if redirect_stderr:<tab><tab><tab>traceback.print_exc()<tab><tab>else:<tab><tab><tab>raise<tab>finally:<tab><tab>sys.stdout, sys.stderr = oldout, olderr",0,if redirect_stderr :,if sys . stderr is None :,0.045790811,1.00E-10,0.25
"def run(self):<tab>self.mpd.connect()<tab>events = [""player""]<tab>while True:<tab><tab>if ""player"" in events:<tab><tab><tab>status = self.mpd.status()<tab><tab><tab>handler = getattr(self, ""on_"" + status[""state""], None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>handler(status)<tab><tab><tab>else:<tab><tab><tab><tab>self._log.debug(u'unhandled status ""{0}""', status)<tab><tab>events = self.mpd.events()",0,if handler :,if handler is not None :,0.090364769,1.00E-10,0.4
"def get_full_qualified_name(self, node: Element) -> str:<tab>if node.get(""reftype"") == ""option"":<tab><tab>progname = node.get(""std:program"")<tab><tab>command = ws_re.split(node.get(""reftarget""))<tab><tab><IF-STMT><tab><tab><tab>command.insert(0, progname)<tab><tab>option = command.pop()<tab><tab>if command:<tab><tab><tab>return ""."".join([""-"".join(command), option])<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>return None",1,if progname :,if progname :,0.531170663,1.00E-10,1
"def _get_sources(self):<tab>servers = self.config[""servers""]<tab>""""""maps urls to extractors""""""<tab>server_links = {<tab><tab>""mp4upload"": ""mp4upload.com"",<tab><tab>""gcloud"": ""gcloud.live"",<tab><tab>""gcloud"": ""fembed.com"",<tab>}<tab>soup = helpers.soupify(helpers.get(self.url)).select(""iframe"")<tab>for a in servers:<tab><tab>for b in soup:<tab><tab><tab>for c in server_links:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return [(c, b.get(""src""))]<tab>logger.warn(""Unsupported URL"")<tab>return """"",0,"if server_links [ c ] in b . get ( ""src"" ) and a == c :","if c . get ( ""src"" ) == a . get ( ""src"" ) :",0.296349869,32.00458079,0.398809524
"def _self_set(self, context):<tab>if self.keys is not None:<tab><tab>return<tab>new_dict = context.get_pynames([""self"", ""d""])[1]<tab>if new_dict and isinstance(new_dict.get_object().get_type(), Dict):<tab><tab>args = arguments.ObjectArguments([new_dict])<tab><tab>items = new_dict.get_object()[""popitem""].get_object().get_returned_object(args)<tab><tab>context.save_per_name(items)<tab>else:<tab><tab>holding = _infer_sequence_for_pyname(new_dict)<tab><tab><IF-STMT><tab><tab><tab>context.save_per_name(holding)",0,"if holding is not None and isinstance ( holding . get_type ( ) , Tuple ) :",if holding is not None :,0.226776754,9.110529535,0.607407407
"def create():<tab>""""""Create a new post for the current user.""""""<tab>if request.method == ""POST"":<tab><tab>title = request.form[""title""]<tab><tab>body = request.form[""body""]<tab><tab>error = None<tab><tab><IF-STMT><tab><tab><tab>error = ""Title is required.""<tab><tab>if error is not None:<tab><tab><tab>flash(error)<tab><tab>else:<tab><tab><tab>db.session.add(Post(title=title, body=body, author=g.user))<tab><tab><tab>db.session.commit()<tab><tab><tab>return redirect(url_for(""blog.index""))<tab>return render_template(""blog/create.html"")",1,if not title :,if not title :,0.75,100,1
"def _find_host_dir_ldconfig(self, arch=""x86-64""):<tab>""""""Find host nvidia libraries via ldconfig""""""<tab>dir_list = set()<tab>ld_data = Uprocess().get_output([""ldconfig"", ""-p""])<tab>if ld_data:<tab><tab>regexp = ""[ |\t]%s[^ ]* .*%s.*=> (/.*)""<tab><tab>for line in ld_data.split(""\n""):<tab><tab><tab>for lib in self._nvidia_main_libs:<tab><tab><tab><tab>match = re.search(regexp % (lib, arch), line)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>dir_list.add(<tab><tab><tab><tab><tab><tab>os.path.realpath(os.path.dirname(match.group(1))) + ""/""<tab><tab><tab><tab><tab>)<tab>return dir_list",1,if match :,if match :,0.531170663,1.00E-10,1
"def migrate_replay_storage(apps, schema_editor):<tab>model = apps.get_model(""terminal"", ""ReplayStorage"")<tab>init_storage_data(model)<tab>setting = get_setting(apps, schema_editor, ""TERMINAL_REPLAY_STORAGE"")<tab>if not setting:<tab><tab>return<tab>values = get_storage_data(setting)<tab>for name, meta in values.items():<tab><tab>tp = meta.pop(""TYPE"", None)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>model.objects.create(name=name, type=tp, meta=meta)",0,"if not tp or name in [ ""default"" , ""null"" ] :",if tp is None :,0.010805043,1.557729873,0.206349206
"def load_distribution(args: CommandLineArguments) -> CommandLineArguments:<tab>if args.distribution is not None:<tab><tab>args.distribution = Distribution[args.distribution]<tab>if args.distribution is None or args.release is None:<tab><tab>d, r = detect_distribution()<tab><tab>if args.distribution is None:<tab><tab><tab>args.distribution = d<tab><tab><IF-STMT><tab><tab><tab>args.release = r<tab>if args.distribution is None:<tab><tab>die(""Couldn't detect distribution."")<tab>return args",0,if args . distribution == d and d != Distribution . clear and args . release is None :,if args . release is None :,0.174006243,12.59436722,0.226666667
"def fieldset_string_to_field(fieldset_dict, model):<tab>if isinstance(fieldset_dict[""fields""], tuple):<tab><tab>fieldset_dict[""fields""] = list(fieldset_dict[""fields""])<tab>i = 0<tab>for dict_field in fieldset_dict[""fields""]:<tab><tab>if isinstance(dict_field, string_types):<tab><tab><tab>fieldset_dict[""fields""][i] = model._meta.get_field_by_name(dict_field)[0]<tab><tab><IF-STMT><tab><tab><tab>dict_field[1][""recursive""] = True<tab><tab><tab>fieldset_string_to_field(dict_field[1], model)<tab><tab>i += 1",0,"elif isinstance ( dict_field , list ) or isinstance ( dict_field , tuple ) :","if ""recursive"" in dict_field [ 1 ] :",0.007372129,7.559140889,0.095238095
"def icon(display_icon):<tab>""""""returns empty dict if show_icons is False, else the icon passed""""""<tab>kws = {}<tab>if get_icon_switch():<tab><tab>if display_icon.startswith(""SV_""):<tab><tab><tab>kws = {""icon_value"": custom_icon(display_icon)}<tab><tab><IF-STMT><tab><tab><tab>kws = {""icon"": display_icon}<tab>return kws",0,"elif display_icon != ""OUTLINER_OB_EMPTY"" :","elif display_icon . startswith ( ""SV_"" ) :",0.047687319,21.2948076,0.641025641
"def cancel_helper(self, node, to_cancel):<tab>children = set(self.workflow.successors(node))<tab>for child in children:<tab><tab><IF-STMT><tab><tab><tab>to_cancel.append(child.id_)<tab><tab><tab>self.cancelled.append(node.id_)<tab><tab><tab>await self.cancel_helper(child, to_cancel)<tab>return to_cancel",0,if self . parent_map [ child . id_ ] == 1 :,if child . id_ not in to_cancel :,0.049496429,17.12870164,0.285714286
"def getStatusString(self):<tab>if not self._isAvailable:<tab><tab>return ""Doodle3D box not found""<tab>if self._printing:<tab><tab>if self._blockIndex < len(self._fileBlocks):<tab><tab><tab>ret = ""Sending GCode: %.1f%%"" % (<tab><tab><tab><tab>float(self._blockIndex) * 100.0 / float(len(self._fileBlocks))<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>ret = ""Finished sending GCode to Doodle3D box.""<tab><tab>else:<tab><tab><tab>ret = ""Different print still running...""<tab><tab># ret += ""\nErrorCount: %d"" % (self._errorCount)<tab><tab>return ret<tab>return ""Printer found, waiting for print command.""",0,elif len ( self . _fileBlocks ) > 0 :,elif self . _blockIndex > 0 :,0.069407542,24.6945864,0.384615385
"def test_archive_files_message(self):<tab>filelist = [""test.torrent"", ""deluge.png""]<tab>arc_filepath = archive_files(<tab><tab>""test-arc"", [get_test_data_file(f) for f in filelist], message=""test""<tab>)<tab>result_files = filelist + [""archive_message.txt""]<tab>with tarfile.open(arc_filepath, ""r"") as tar:<tab><tab>self.assertEqual(tar.getnames(), result_files)<tab><tab>for tar_info in tar:<tab><tab><tab>self.assertTrue(tar_info.isfile())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = tar.extractfile(tar_info).read().decode()<tab><tab><tab><tab>self.assertEqual(result, ""test"")",0,"if tar_info . name == ""archive_message.txt"" :",if tar_info . isname ( ) :,0.090565314,21.46152504,0.5
"def _format_arg(self, opt, spec, val):<tab>if opt in [""in_files""]:<tab><tab>return scans_for_fnames(ensure_list(val))<tab>if opt == ""fwhm"":<tab><tab>if not isinstance(val, list):<tab><tab><tab>return [val, val, val]<tab><tab><IF-STMT><tab><tab><tab>if len(val) == 1:<tab><tab><tab><tab>return [val[0], val[0], val[0]]<tab><tab><tab>else:<tab><tab><tab><tab>return val<tab>return super(Smooth, self)._format_arg(opt, spec, val)",0,"if isinstance ( val , list ) :","elif isinstance ( val , tuple ) :",0.195658694,41.11336169,0.428571429
"def fuzzy_sum(self, currency, rounding=ROUND_UP):<tab>a = Money.ZEROS[currency].amount<tab>fuzzy = False<tab>for m in self:<tab><tab><IF-STMT><tab><tab><tab>a += m.amount<tab><tab>elif m.amount:<tab><tab><tab>a += m.convert(currency, rounding=None).amount<tab><tab><tab>fuzzy = True<tab>r = Money(a, currency, rounding=rounding)<tab>r.fuzzy = fuzzy<tab>return r",0,if m . currency == currency :,"if isinstance ( m , Money ) :",0.021135836,7.267884212,0.333333333
"def _read_potfiles(src_root, potfiles):<tab>""""""Returns a list of paths for a POTFILES.in file""""""<tab>paths = []<tab>with open(potfiles, ""r"", encoding=""utf-8"") as h:<tab><tab>for line in h:<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>paths.append(os.path.normpath(os.path.join(src_root, line)))<tab>return paths",0,"if not line or line . startswith ( ""#"" ) :",if not line :,0.046144095,6.734410773,0.572649573
"def applyMath(self, val, math, frmt):<tab># apply math function - eval<tab>try:<tab><tab>x = eval(val)<tab><tab><IF-STMT><tab><tab><tab>x = eval(math)<tab><tab>val = (""{0"" + frmt + ""}"").format(x)<tab>except:<tab><tab>dprint(<tab><tab><tab>__name__,<tab><tab><tab>0,<tab><tab><tab>""CCmds_applyMath: Error in math {0}, frmt {1}\n{2}"",<tab><tab><tab>math,<tab><tab><tab>frmt,<tab><tab><tab>traceback.format_exc(),<tab><tab>)<tab># apply format specifier<tab>dprint(__name__, 2, ""CCmds_applyMath: {0}"", val)<tab>return val",0,"if math != """" :",if x is None :,0.034123066,8.515289178,0.25
def run_train_loop(self):<tab>self.begin_training()<tab>for _ in self.yield_train_step():<tab><tab><IF-STMT><tab><tab><tab>self.save_model()<tab><tab>if self.should_save_checkpoint():<tab><tab><tab>self.save_checkpoint()<tab><tab>if self.should_eval_model():<tab><tab><tab>self.eval_model()<tab><tab>if self.should_break_training():<tab><tab><tab>break<tab>self.eval_model()<tab>self.done_training()<tab>return self.returned_result(),1,if self . should_save_model ( ) :,if self . should_save_model ( ) :,0.75,100,1
"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab>if jid is None:<tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab><IF-STMT><tab><tab><tab>node = """"<tab><tab>if ifrom is None:<tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab>ifrom = ifrom.full<tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",1,if node is None :,if node is None :,0.75,100,1
"def _collect(self, writer=None):<tab>for artifact_name in self.plugin_args.artifacts:<tab><tab>for hit in self.collect_artifact(artifact_name):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>writer.write_result(hit[""result""])<tab><tab><tab>yield hit",0,"if ""result"" in hit and writer :",if writer is not None :,0.173367003,6.479066747,0.222222222
"def proc(qtbot, caplog):<tab>""""""A fixture providing a GUIProcess and cleaning it up after the test.""""""<tab>p = guiprocess.GUIProcess(""testprocess"")<tab>yield p<tab>if p._proc.state() == QProcess.Running:<tab><tab>with caplog.at_level(logging.ERROR):<tab><tab><tab>with qtbot.waitSignal(p.finished, timeout=10000, raising=False) as blocker:<tab><tab><tab><tab>p._proc.terminate()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p._proc.kill()<tab><tab><tab>p._proc.waitForFinished()",0,if not blocker . signal_triggered :,elif p . finished :,0.273760234,6.971729122,0.142857143
"def getsequences(self):<tab>""""""Return the set of sequences for the folder.""""""<tab>sequences = {}<tab>fullname = self.getsequencesfilename()<tab>try:<tab><tab>f = open(fullname, ""r"")<tab>except IOError:<tab><tab>return sequences<tab>while 1:<tab><tab>line = f.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>fields = line.split("":"")<tab><tab>if len(fields) != 2:<tab><tab><tab>self.error(""bad sequence in %s: %s"" % (fullname, line.strip()))<tab><tab>key = fields[0].strip()<tab><tab>value = IntSet(fields[1].strip(), "" "").tolist()<tab><tab>sequences[key] = value<tab>return sequences",1,if not line :,if not line :,0.75,100,1
def get_coeffs(e):<tab>coeffs = []<tab>for du in all_delu_dict.keys():<tab><tab><IF-STMT><tab><tab><tab>coeffs.append(self.as_coeffs_dict[e])<tab><tab>elif du in self.as_coeffs_dict[e].keys():<tab><tab><tab>coeffs.append(self.as_coeffs_dict[e][du])<tab><tab>else:<tab><tab><tab>coeffs.append(0)<tab>return np.array(coeffs),0,"if type ( self . as_coeffs_dict [ e ] ) . __name__ == ""float"" :",if du == e :,0.007809363,0.72819234,0.326086957
"def block_items(objekt, block, eldict):<tab>if objekt not in block:<tab><tab>if isinstance(objekt.type, PyType):<tab><tab><tab>if objekt.type not in block:<tab><tab><tab><tab>block.append(objekt.type)<tab><tab>block.append(objekt)<tab><tab>if isinstance(objekt, PyType):<tab><tab><tab>others = [<tab><tab><tab><tab>p<tab><tab><tab><tab>for p in eldict.values()<tab><tab><tab><tab>if isinstance(p, PyElement) and p.type[1] == objekt.name<tab><tab><tab>]<tab><tab><tab>for item in others:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>block.append(item)<tab>return block",1,if item not in block :,if item not in block :,0.75,100,1
"def FindPrefix(self, prefix):<tab>self.log.WriteText(""Looking for prefix: %s\n"" % prefix)<tab>if prefix:<tab><tab>prefix = prefix.lower()<tab><tab>length = len(prefix)<tab><tab># Changed in 2.5 because ListBox.Number() is no longer supported.<tab><tab># ListBox.GetCount() is now the appropriate way to go.<tab><tab>for x in range(self.GetCount()):<tab><tab><tab>text = self.GetString(x)<tab><tab><tab>text = text.lower()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.log.WriteText(""Prefix %s is found.\n"" % prefix)<tab><tab><tab><tab>return x<tab>self.log.WriteText(""Prefix %s is not found.\n"" % prefix)<tab>return -1",0,if text [ : length ] == prefix :,if len ( text ) == length :,0.018635392,11.22961654,0.333333333
"def encode(self, input, errors=""strict""):<tab>if self.encoder is None:<tab><tab>result = codecs.utf_32_encode(input, errors)<tab><tab><IF-STMT><tab><tab><tab>self.encoder = codecs.utf_32_le_encode<tab><tab>else:<tab><tab><tab>self.encoder = codecs.utf_32_be_encode<tab><tab>return result<tab>else:<tab><tab>return self.encoder(input, errors)",1,"if sys . byteorder == ""little"" :","if sys . byteorder == ""little"" :",0.75,100,1
"def __call__(self, message, keyname):<tab>if keyname in self.keyring:<tab><tab>key = self.keyring[keyname]<tab><tab><IF-STMT><tab><tab><tab>if message:<tab><tab><tab><tab>GSSTSigAdapter.parse_tkey_and_step(key, message, keyname)<tab><tab>return key<tab>else:<tab><tab>return None",0,"if isinstance ( key , Key ) and key . algorithm == GSS_TSIG :",if key is not None :,0.044709607,1.707863452,0.208333333
"def unicode_metrics(metrics):<tab>for i, metric in enumerate(metrics):<tab><tab>for key, value in metric.items():<tab><tab><tab>if isinstance(value, basestring):<tab><tab><tab><tab>metric[key] = unicode(value, errors=""replace"")<tab><tab><tab>elif isinstance(value, tuple) or isinstance(value, list):<tab><tab><tab><tab>value_list = list(value)<tab><tab><tab><tab>for j, value_element in enumerate(value_list):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>value_list[j] = unicode(value_element, errors=""replace"")<tab><tab><tab><tab>metric[key] = tuple(value_list)<tab><tab>metrics[i] = metric<tab>return metrics",1,"if isinstance ( value_element , basestring ) :","if isinstance ( value_element , basestring ) :",0.75,100,1
"def step(self, action):<tab>assert self.action_space.contains(action)<tab>if self._state == 4:<tab><tab>if action and self._case:<tab><tab><tab>return self._state, 10.0, True, {}<tab><tab>else:<tab><tab><tab>return self._state, -10, True, {}<tab>else:<tab><tab>if action:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._state = 2<tab><tab><tab>else:<tab><tab><tab><tab>self._state += 1<tab><tab>elif self._state == 2:<tab><tab><tab>self._state = self._case<tab>return self._state, -1, False, {}",0,if self . _state == 0 :,if self . _state == 4 :,0.574113272,75.06238538,0.6
"def get_superuser(self):<tab>try:<tab><tab>query = dict()<tab><tab><IF-STMT><tab><tab><tab>query[get_user_model().USERNAME_FIELD] = ""admin""<tab><tab>else:<tab><tab><tab>query[get_user_model().USERNAME_FIELD] = ""admin@django-cms.org""<tab><tab>admin = get_user_model().objects.get(**query)<tab>except get_user_model().DoesNotExist:<tab><tab>admin = self._create_user(""admin"", is_staff=True, is_superuser=True)<tab>return admin",0,"if get_user_model ( ) . USERNAME_FIELD != ""email"" :",if is_staff :,0.013130314,1.00E-10,1
"def newend(self):<tab>newenddatetime = self._newenddate<tab>if not self.checkallday.state:<tab><tab><IF-STMT><tab><tab><tab>tzinfo = self.conf.default.default_timezone<tab><tab>else:<tab><tab><tab>tzinfo = self.enddt.tzinfo<tab><tab>try:<tab><tab><tab>newendtime = self._newendtime<tab><tab><tab>newenddatetime = datetime.combine(newenddatetime, newendtime)<tab><tab><tab>newenddatetime = tzinfo.localize(newenddatetime)<tab><tab>except TypeError:<tab><tab><tab>return None<tab>return newenddatetime",0,"if not hasattr ( self . enddt , ""tzinfo"" ) or self . enddt . tzinfo is None :",if self . enddt is None :,0.098870515,5.782700803,0.172727273
"def run(self):<tab>to_delete = set()<tab>for k, v in iteritems(self.objs):<tab><tab>if k.startswith(""_""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>to_delete.add(k)<tab><tab>if v[""_class""] == ""Task"":<tab><tab><tab>v[""submission_format""] = list(<tab><tab><tab><tab>self.objs[k][""filename""] for k in v.get(""submission_format"", list())<tab><tab><tab>)<tab>for k in to_delete:<tab><tab>del self.objs[k]<tab>return self.objs",0,"if v [ ""_class"" ] == ""SubmissionFormatElement"" :","if v [ ""_class"" ] == ""Submission"" :",0.605621306,80.91067116,1
"def update_reserved_qty_for_subcontract(self):<tab>for d in self.supplied_items:<tab><tab><IF-STMT><tab><tab><tab>stock_bin = get_bin(d.rm_item_code, d.reserve_warehouse)<tab><tab><tab>stock_bin.update_reserved_qty_for_sub_contracting()",0,if d . rm_item_code :,if d . rm_item_code and d . reserve_warehouse :,0.422342975,49.00941039,0.625
"def process(self):<tab>if ""Length"" in self.outputs and self.outputs[""Length""].is_linked:<tab><tab>if ""Data"" in self.inputs and self.inputs[""Data""].is_linked:<tab><tab><tab>data = self.inputs[""Data""].sv_get(deepcopy=False)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>out = [[len(data)]]<tab><tab><tab>elif self.level == 1:<tab><tab><tab><tab>out = [self.count(data, self.level)]<tab><tab><tab>else:<tab><tab><tab><tab>out = self.count(data, self.level)<tab><tab><tab>self.outputs[""Length""].sv_set(out)",0,if not self . level :,if self . level == 0 :,0.104946328,23.35689889,0.333333333
"def _user_has_perm(user, perm, obj):<tab>anon = user.is_anonymous()<tab>for backend in auth.get_backends():<tab><tab><IF-STMT><tab><tab><tab>if hasattr(backend, ""has_perm""):<tab><tab><tab><tab>if obj is not None:<tab><tab><tab><tab><tab>if backend.supports_object_permissions and backend.has_perm(<tab><tab><tab><tab><tab><tab>user, perm, obj<tab><tab><tab><tab><tab>):<tab><tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>if backend.has_perm(user, perm):<tab><tab><tab><tab><tab><tab>return True<tab>return False",0,if not anon or backend . supports_anonymous_user :,if anon or backend . supports_anonymous_user :,0.48608324,83.52052075,0.30952381
"def visit(self, node=None):<tab>""""""Walks over a node.  If no node is provided, the tree is used.""""""<tab>if node is None:<tab><tab>node = self.tree<tab>if node is None:<tab><tab>raise RuntimeError(""no node or tree given!"")<tab>for clsname in map(_lowername, type.mro(node.__class__)):<tab><tab>meth = getattr(self, ""visit_"" + clsname, None)<tab><tab><IF-STMT><tab><tab><tab>rtn = meth(node)<tab><tab><tab>break<tab>else:<tab><tab>msg = ""could not find valid visitor method for {0} on {1}""<tab><tab>nodename = node.__class__.__name__<tab><tab>selfname = self.__class__.__name__<tab><tab>raise AttributeError(msg.format(nodename, selfname))<tab>return rtn",0,if callable ( meth ) :,if meth is not None :,0.028043015,10.68217516,0.214285714
"def add_fade_out(compositor, fade_out_length):<tab>clip = _get_compositor_clip(compositor)<tab>keyframe_property, property_klass, keyframes = _get_kfproperty_klass_and_keyframes(<tab><tab>compositor, clip<tab>)<tab>if fade_out_length > 0:<tab><tab><IF-STMT><tab><tab><tab>return _do_user_add_fade_out(<tab><tab><tab><tab>keyframe_property, property_klass, keyframes, fade_out_length, clip<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>_show_length_error_dialog()<tab><tab><tab>return None",0,if fade_out_length + 1 <= clip . clip_length ( ) :,if fade_out_length < clip . clip_length ( ) :,0.348539092,66.66467303,0.485294118
"def make_timesheet_records():<tab>employees = get_timesheet_based_salary_slip_employee()<tab>for e in employees:<tab><tab>ts = make_timesheet(<tab><tab><tab>e.employee,<tab><tab><tab>simulate=True,<tab><tab><tab>billable=1,<tab><tab><tab>activity_type=get_random(""Activity Type""),<tab><tab><tab>company=frappe.flags.company,<tab><tab>)<tab><tab>frappe.db.commit()<tab><tab>rand = random.random()<tab><tab>if rand >= 0.3:<tab><tab><tab>make_salary_slip_for_timesheet(ts.name)<tab><tab>rand = random.random()<tab><tab><IF-STMT><tab><tab><tab>make_sales_invoice_for_timesheet(ts.name)",0,if rand >= 0.2 :,if rand >= 0.5 :,0.394778655,53.72849659,1
"def _target_from_batch(self, batch):<tab>targets = []<tab>for name in self.labels:<tab><tab>target = getattr(batch, name)<tab><tab><IF-STMT><tab><tab><tab>label_vocab = self.metadata.target.vocab.stoi<tab><tab><tab>batch_label_list = getattr(batch, Target.TARGET_LABEL_FIELD)<tab><tab><tab>target = align_target_labels(target, batch_label_list, label_vocab)<tab><tab>targets.append(target)<tab>if len(targets) == 1:<tab><tab>return targets[0]<tab>return tuple(targets)",0,"if name in [ Target . TARGET_PROB_FIELD , Target . TARGET_LOGITS_FIELD ] :","if isinstance ( target , Target ) :",0.020210636,2.58634614,0.406862745
"def detectForms(html):<tab>erreur = """"<tab>soup = BeautifulSoup(html, ""html.parser"")<tab>detectedForms = soup.find_all(""form"")<tab>returnForms = []<tab>if len(detectedForms) > 0:<tab><tab>for f in detectedForms:<tab><tab><tab>fileInputs = f.findChildren(""input"", {""type"": re.compile(""file"", re.I)})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>returnForms.append((f, fileInputs))<tab>return returnForms",1,if len ( fileInputs ) > 0 :,if len ( fileInputs ) > 0 :,0.75,100,1
"def _updateNewCardRatio(self):<tab>if self.col.conf[""newSpread""] == NEW_CARDS_DISTRIBUTE:<tab><tab><IF-STMT><tab><tab><tab>self.newCardModulus = (self.newCount + self.revCount) // self.newCount<tab><tab><tab># if there are cards to review, ensure modulo >= 2<tab><tab><tab>if self.revCount:<tab><tab><tab><tab>self.newCardModulus = max(2, self.newCardModulus)<tab><tab><tab>return<tab>self.newCardModulus = 0",0,if self . newCount :,if self . revCount :,0.394778655,42.72870064,0.6
"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab><IF-STMT><tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab>if parts[0]:<tab><tab><tab>comments[single] = [parts[0]]<tab><tab>if len(parts) > 1:<tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab>if main in comments:<tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",1,if k in comments :,if k in comments :,0.75,100,1
"def check_physical(self, line):<tab>""""""Run all physical checks on a raw input line.""""""<tab>self.physical_line = line<tab>for name, check, argument_names in self._physical_checks:<tab><tab>self.init_checker_state(name, argument_names)<tab><tab>result = self.run_check(check, argument_names)<tab><tab>if result is not None:<tab><tab><tab>(offset, text) = result<tab><tab><tab>self.report_error(self.line_number, offset, text, check)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.indent_char = line[0]",0,"if text [ : 4 ] == ""E101"" :",if self . indent_char is None :,0.01593847,4.062582855,0.272727273
"def dependencies(self):<tab>deps = []<tab>midx = None<tab>if self.ref is not None:<tab><tab>query = GroupQuery(self.ref)<tab><tab>g = query.execute(self.schema)<tab><tab><IF-STMT><tab><tab><tab>log.debug(self.schema)<tab><tab><tab>raise TypeNotFound(self.ref)<tab><tab>deps.append(g)<tab><tab>midx = 0<tab>return (midx, deps)",0,if g is None :,if not g :,0.039449619,16.37226967,0.277777778
"def __init__(self, metadata=None):<tab><IF-STMT><tab><tab>db = get_session()<tab><tab>metadata = lookup_feed(db, self.__feed_name__)<tab><tab>if not metadata:<tab><tab><tab>raise Exception(<tab><tab><tab><tab>""Must have feed metadata in db already, should sync metadata before invoking instance operations""<tab><tab><tab>)<tab>super(AnchoreServiceFeed, self).__init__(metadata=metadata)",0,if not metadata :,if metadata is None :,0.045150551,14.05853313,0.277777778
"def testGetPartRect(self):<tab>""Make sure the part rectangles are retrieved correctly""<tab>for i in range(0, self.ctrl.part_count()):<tab><tab>part_rect = self.ctrl.get_part_rect(i)<tab><tab>self.assertEqual(part_rect.left, self.part_rects[i].left)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(part_rect.right, self.part_rects[i].right)<tab><tab>self.assertEqual(part_rect.top, self.part_rects[i].top)<tab><tab>self.assertFalse(abs(part_rect.bottom - self.part_rects[i].bottom) > 2)<tab>self.assertRaises(IndexError, self.ctrl.get_part_rect, 99)",0,if i != self . ctrl . part_count ( ) - 1 :,if i < self . ctrl . part_count ( ) - 1 :,0.64649565,77.10792372,1
"def __call__(self, ctx):<tab>if ctx.range and ctx.value:<tab><tab>if self.raw:<tab><tab><tab>ctx.range.raw_value = ctx.value<tab><tab><tab>return<tab><tab>scalar = ctx.meta.get(""scalar"", False)<tab><tab><IF-STMT><tab><tab><tab>ctx.range = ctx.range.resize(len(ctx.value), len(ctx.value[0]))<tab><tab>self._write_value(ctx.range, ctx.value, scalar)",0,if not scalar :,if scalar :,0.096488528,1.00E-10,0.416666667
"def basic_get(self, queue, no_ack=False, **kwargs):<tab>""""""Get message by direct access (synchronous).""""""<tab>try:<tab><tab>message = self.Message(self._get(queue), channel=self)<tab><tab><IF-STMT><tab><tab><tab>self.qos.append(message, message.delivery_tag)<tab><tab>return message<tab>except Empty:<tab><tab>pass",0,if not no_ack :,if no_ack :,0.096488528,1.00E-10,0.6
"def http_client(cls) -> aiohttp.ClientSession:<tab>if cls._client is None:<tab><tab><IF-STMT><tab><tab><tab>raise EnvironmentError(<tab><tab><tab><tab>""Event loop must be running to start HTTP client session.""<tab><tab><tab>)<tab><tab>cls._client = aiohttp.ClientSession(request_class=SSLClientRequest)<tab>return cls._client",0,if not asyncio . get_event_loop ( ) . is_running ( ) :,"if sys . platform == ""win32"" :",0.011766133,2.481373276,0.333333333
"def createMimeType(self):<tab>audio = False<tab>for prop in self.array(""header/content/stream_prop""):<tab><tab>guid = prop[""content/type""].value<tab><tab>if guid == VideoHeader.guid:<tab><tab><tab>return u""video/x-ms-wmv""<tab><tab><IF-STMT><tab><tab><tab>audio = True<tab>if audio:<tab><tab>return u""audio/x-ms-wma""<tab>else:<tab><tab>return u""video/x-ms-asf""",0,if guid == AudioHeader . guid :,elif guid == VideoHeader . guid :,0.430625739,34.57207846,0.333333333
"def _removeCachedRFInfo(self, cache_key, path, removeChildPaths):<tab>log.debug(""_removeCachedRFInfo: cache_key %r, path %r"", cache_key, path)<tab>if self._cachedFiles.has_key(cache_key):<tab><tab>cache = self._cachedFiles[cache_key]<tab><tab>if cache.has_key(path):<tab><tab><tab>del cache[path]<tab><tab>if removeChildPaths:<tab><tab><tab># Remove all cached paths that are under this directory<tab><tab><tab>from remotefilelib import addslash<tab><tab><tab>dirPath = addslash(path)<tab><tab><tab>for keypath in cache.keys():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>del cache[keypath]",1,if keypath . startswith ( dirPath ) :,if keypath . startswith ( dirPath ) :,0.75,100,1
"def format(self, obj, context, maxlevels, level):<tab>if isinstance(obj, unicode):<tab><tab># return (obj.encode('utf8'), True, False)<tab><tab>return (obj, True, False)<tab>if isinstance(obj, bytes):<tab><tab>convert = False<tab><tab># for c in obj:<tab><tab># 	if ord(c) >= 128:<tab><tab># 		convert = True<tab><tab># 		break<tab><tab>try:<tab><tab><tab>codecs.decode(obj)<tab><tab>except:<tab><tab><tab>convert = True<tab><tab><IF-STMT><tab><tab><tab>return (""0x{}"".format(obj), True, False)<tab>return pprint.PrettyPrinter.format(self, obj, context, maxlevels, level)",1,if convert :,if convert :,0.531170663,1.00E-10,1
"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None):<tab>try:<tab><tab>if module is None:<tab><tab><tab>module = self.name<tab><tab>if section is None:<tab><tab><tab>section = ""all_sections""<tab><tab>if s_name is None:<tab><tab><tab>s_name = f[""s_name""]<tab><tab><IF-STMT><tab><tab><tab>source = os.path.abspath(os.path.join(f[""root""], f[""fn""]))<tab><tab>report.data_sources[module][section][s_name] = source<tab>except AttributeError:<tab><tab>logger.warning(<tab><tab><tab>""Tried to add data source for {}, but was missing fields data"".format(<tab><tab><tab><tab>self.name<tab><tab><tab>)<tab><tab>)",1,if source is None :,if source is None :,0.75,100,1
"def open(self, *args, **kwargs):<tab>if kwargs.get(""json"") is not None:<tab><tab>with self.session_transaction() as sess:<tab><tab><tab>api_key_headers = Headers({""CSRF-Token"": sess.get(""nonce"")})<tab><tab><tab>headers = kwargs.pop(""headers"", Headers())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>headers = Headers(headers)<tab><tab><tab>headers.extend(api_key_headers)<tab><tab><tab>kwargs[""headers""] = headers<tab>return super(CTFdTestClient, self).open(*args, **kwargs)",0,"if isinstance ( headers , dict ) :","if isinstance ( headers , list ) :",0.549040681,59.46035575,0.666666667
"def get_params(self):<tab>if not hasattr(self, ""input_space""):<tab><tab>raise AttributeError(""Input space has not been provided."")<tab>rval = []<tab>for layer in self.layers:<tab><tab>for param in layer.get_params():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.info(type(layer))<tab><tab>layer_params = layer.get_params()<tab><tab>assert not isinstance(layer_params, set)<tab><tab>for param in layer_params:<tab><tab><tab>if param not in rval:<tab><tab><tab><tab>rval.append(param)<tab>rval = [elem for elem in rval if elem not in self.freeze_set]<tab>assert all([elem.name is not None for elem in rval])<tab>return rval",0,if param . name is None :,if param in self . input_space :,0.142825693,11.33958222,0.35
"def _animate_strategy(self, speed=1):<tab>if self._animating == 0:<tab><tab>return<tab>if self._apply_strategy() is not None:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if self._animate.get() == 1:<tab><tab><tab>self._root.after(3000, self._animate_strategy)<tab><tab>elif self._animate.get() == 2:<tab><tab><tab>self._root.after(1000, self._animate_strategy)<tab><tab>else:<tab><tab><tab>self._root.after(20, self._animate_strategy)",0,if self . _animate . get ( ) == 0 or self . _step . get ( ) == 1 :,if self . _animate . get ( ) < speed :,0.221763294,24.68283389,0.4
"def charAt(pos):<tab>this.cok()<tab>pos = pos.to_int()<tab>s = this.to_string()<tab>if 0 <= pos < len(s.value):<tab><tab>char = s.value[pos]<tab><tab><IF-STMT><tab><tab><tab>s.Js(char)  # add char to char bank<tab><tab>return s.CHAR_BANK[char]<tab>return s.CHAR_BANK[""""]",0,if char not in s . CHAR_BANK :,if 0 <= char < len ( s .CHAR_BANK ) :,0.053246902,27.66873691,0.375
"def find_executable(names):<tab># Given a list of executable names, find the first one that is available<tab># as an executable file, on the path.<tab>for name in names:<tab><tab>fpath, fname = os.path.split(name)<tab><tab>if fpath:<tab><tab><tab># The given name is absolute.<tab><tab><tab>if is_executable(name):<tab><tab><tab><tab>return name<tab><tab>else:<tab><tab><tab># Try to find the name on the PATH<tab><tab><tab>for path in os.environ[""PATH""].split(os.pathsep):<tab><tab><tab><tab>exe_file = os.path.join(path, name)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return exe_file<tab># Could not find it :(<tab>return None",0,if is_executable ( exe_file ) :,if os . path . exists ( exe_file ) :,0.268871115,43.3618909,0.36
"def match_file(self, file, tff_format):<tab>match = tff_format.search(file.filename.replace(""\\"", ""/""))<tab>if match:<tab><tab>result = {}<tab><tab>for name, value in match.groupdict().items():<tab><tab><tab>value = value.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = value.lstrip(""0"")<tab><tab><tab>if self.ui.replace_underscores.isChecked():<tab><tab><tab><tab>value = value.replace(""_"", "" "")<tab><tab><tab>result[name] = value<tab><tab>return result<tab>else:<tab><tab>return {}",0,if name in self . numeric_tags :,if self . ui . strip_underscores . isChecked ( ) :,0.033909657,7.768562846,0.285714286
"def __init__(<tab>self,<tab>filename: str = ""checkpoint"",<tab>frequency: Union[int, List[int]] = 1,<tab>on: Union[str, List[str]] = ""epoch_end"",):<tab>if isinstance(frequency, list):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""If you pass a list for checkpoint frequencies, the `on` ""<tab><tab><tab><tab>""parameter has to be a list with the same length.""<tab><tab><tab>)<tab>self._frequency = frequency<tab>super(_TuneCheckpointCallback, self).__init__(on)<tab>self._filename = filename<tab>self._counter = Counter()<tab>self._cp_count = 0  # Has to be monotonically increasing",0,"if not isinstance ( on , list ) or len ( frequency ) != len ( on ) :",if len ( frequency ) != len ( on ) :,0.43418497,47.41269816,0.198067633
"def download(cls, architecture, path=""./""):<tab>if cls.sanity_check(architecture):<tab><tab>architecture_file = path + ""imagenet_{}.pth"".format(architecture)<tab><tab>if not os.path.exists(architecture_file):<tab><tab><tab>kwargs = {}<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kwargs[""transform_input""] = False<tab><tab><tab>model = models.__dict__[architecture](pretrained=True, **kwargs)<tab><tab><tab>torch.save(model, architecture_file)<tab><tab><tab>print(<tab><tab><tab><tab>""PyTorch pretrained model is saved as [{}]."".format(architecture_file)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>print(""File [{}] existed!"".format(architecture_file))<tab><tab>return architecture_file<tab>else:<tab><tab>return None",0,"if architecture == ""inception_v3"" :","if ""transform_input"" in architecture :",0.036540249,6.677169946,0.45
"def __exit__(self, exc_type, exc_value, traceback):<tab>self.signal.disconnect(self._listener)<tab>if not self.signal_sent:<tab><tab>self.test_case.fail(""Signal was not sent."")<tab><tab>return<tab>if self.required_kwargs is not None:<tab><tab>missing_kwargs = []<tab><tab>for k in self.required_kwargs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>missing_kwargs.append(k)<tab><tab>if missing_kwargs:<tab><tab><tab>self.test_case.fail(<tab><tab><tab><tab>""Signal missing required arguments: "" ""%s"" % "","".join(missing_kwargs)<tab><tab><tab>)",0,if k not in self . received_kwargs :,if k not in self . signal_sent :,0.605621306,55.55238068,1
"def Assign(left, right):<tab>names = []<tab>if isinstance(left, ast.Name):<tab><tab># Single assignment on left<tab><tab>return ast.Assign([ast.AssName(left.name, ""OP_ASSIGN"")], right)<tab>elif isinstance(left, ast.Tuple):<tab><tab># List of things - make sure they are Name nodes<tab><tab>names = []<tab><tab>for child in left.getChildren():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise SyntaxError(""that assignment not supported"")<tab><tab><tab>names.append(child.name)<tab><tab>ass_list = [ast.AssName(name, ""OP_ASSIGN"") for name in names]<tab><tab>return ast.Assign([ast.AssTuple(ass_list)], right)<tab>else:<tab><tab>raise SyntaxError(""Can't do that yet"")",0,"if not isinstance ( child , ast . Name ) :","if isinstance ( child , ast . Name ) :",0.407499005,81.76129039,0.272727273
"def readVorbisComment(metadata, comment):<tab>metadata.producer = getValue(comment, ""vendor"")<tab>for item in comment.array(""metadata""):<tab><tab><IF-STMT><tab><tab><tab>key, value = item.value.split(""="", 1)<tab><tab><tab>key = key.upper()<tab><tab><tab>if key in VORBIS_KEY_TO_ATTR:<tab><tab><tab><tab>key = VORBIS_KEY_TO_ATTR[key]<tab><tab><tab><tab>setattr(metadata, key, value)<tab><tab><tab>elif value:<tab><tab><tab><tab>metadata.warning(""Skip Vorbis comment %s: %s"" % (key, value))",1,"if ""="" in item . value :","if ""="" in item . value :",0.75,100,1
"def _read_readable(self, readable):<tab>blocksize = 8192<tab>if self.debuglevel > 0:<tab><tab>print(""sendIng a read()able"")<tab>encode = self._is_textIO(readable)<tab>if encode and self.debuglevel > 0:<tab><tab>print(""encoding file using iso-8859-1"")<tab>while True:<tab><tab>datablock = readable.read(blocksize)<tab><tab>if not datablock:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>datablock = datablock.encode(""iso-8859-1"")<tab><tab>yield datablock",1,if encode :,if encode :,0.531170663,1.00E-10,1
"def TryMerge(self, d):<tab>while 1:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 12:<tab><tab><tab>break<tab><tab>if tt == 18:<tab><tab><tab>self.set_value(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_flags(d.get32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",0,if tt == 29 :,if tt == 24 :,0.394778655,53.72849659,0.6
"def needs_rebuild(self):<tab>for ratio in self.sprite.config[""ratios""]:<tab><tab>cocos2d_path = self.output_path(ratio)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>data = plistlib.readPlist(cocos2d_path)<tab><tab><tab><tab>assert data[self.meta_key][""hash""] == self.sprite.hash<tab><tab><tab>except Exception:<tab><tab><tab><tab>continue<tab><tab>return True<tab>return False",1,if os . path . exists ( cocos2d_path ) :,if os . path . exists ( cocos2d_path ) :,0.75,100,1
"def on_epoch_end(self, batch, logs=None):<tab># At the end of every epoch, remask the weights. This ensures that when<tab># the model is saved after completion, the weights represent mask*weights.<tab>weight_mask_ops = []<tab>for layer in self.prunable_layers:<tab><tab>if isinstance(layer, pruning_wrapper.PruneLowMagnitude):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>layer.pruning_obj.weight_mask_op()<tab><tab><tab>else:<tab><tab><tab><tab>weight_mask_ops.append(layer.pruning_obj.weight_mask_op())<tab>K.batch_get_value(weight_mask_ops)",0,if tf . executing_eagerly ( ) :,if layer . pruning_obj . use_weights :,0.022864977,5.30015669,0.5
"def buildQueryRE(queryText, caseSensitive, wholeWord):<tab>""returns a RegEx pattern for searching for the given queryText""<tab># word detection etc. cannot be done on an encoding-less string:<tab>assert type(queryText) == unicode<tab>pattern = re.escape(queryText)<tab>if wholeWord:<tab><tab>if re.search(""^\w"", queryText, re.UNICODE):<tab><tab><tab>pattern = ""\\b"" + pattern<tab><tab><IF-STMT><tab><tab><tab>pattern = pattern + ""\\b""<tab>flags = re.UNICODE<tab>if not (caseSensitive):<tab><tab>flags |= re.IGNORECASE<tab>return re.compile(pattern, flags)",0,"if re . search ( ""\w$"" , queryText , re . UNICODE ) :","elif pattern . endswith ( ""\\b"" ) :",0.016682599,10.45793585,0.093567251
"def is_valid_origin(origin):<tab>if not settings.SENTRY_ALLOW_ORIGIN:<tab><tab>return False<tab>if settings.SENTRY_ALLOW_ORIGIN == ""*"":<tab><tab>return True<tab>if not origin:<tab><tab>return False<tab>origin = origin.lower()<tab>for value in settings.SENTRY_ALLOW_ORIGIN:<tab><tab>if isinstance(value, string_types):<tab><tab><tab>if value.lower() == origin:<tab><tab><tab><tab>return True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,if value . match ( origin ) :,if value . lower ( ) == origin :,0.07964431,19.30486975,0.666666667
"def get_menu_title(self):<tab>handle = self.obj.get_handle()<tab>if handle:<tab><tab>who = get_participant_from_event(self.db, handle)<tab><tab>desc = self.obj.get_description()<tab><tab>event_name = self.obj.get_type()<tab><tab>if desc:<tab><tab><tab>event_name = ""%s - %s"" % (event_name, desc)<tab><tab><IF-STMT><tab><tab><tab>event_name = ""%s - %s"" % (event_name, who)<tab><tab>dialog_title = _(""Event: %s"") % event_name<tab>else:<tab><tab>dialog_title = _(""New Event"")<tab>return dialog_title",0,if who :,elif who :,0.108673556,1.00E-10,0.5
def memory(self):<tab><IF-STMT><tab><tab>self.lazy_init_lock_.acquire()<tab><tab>try:<tab><tab><tab>if self.memory_ is None:<tab><tab><tab><tab>self.memory_ = SystemStat()<tab><tab>finally:<tab><tab><tab>self.lazy_init_lock_.release()<tab>return self.memory_,1,if self . memory_ is None :,if self . memory_ is None :,0.75,100,1
"def __str__(self):<tab>fmt = ""%#x"" if isinstance(self.target, six.integer_types) else ""%r""<tab>args = []<tab>for arg in self.args:<tab><tab>args.append(self._special_repr(arg))<tab>name = self.name or (fmt % self.target)<tab>arg_str = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>arg_str.append(hex(arg))<tab><tab>else:<tab><tab><tab>arg_str.append(str(arg))<tab>return ""%s(%s)"" % (name, "", "".join(arg_str))",0,"if isinstance ( arg , six . integer_types ) and arg > 0x100 :","if isinstance ( arg , int ) :",0.142421801,20.68738125,0.43627451
"def change_password(username=""flexget"", password="""", session=None):<tab>check = zxcvbn.zxcvbn(password, user_inputs=[username])<tab>if check[""score""] < 3:<tab><tab>warning = check[""feedback""][""warning""]<tab><tab>suggestions = "" "".join(check[""feedback""][""suggestions""])<tab><tab>message = ""Password '{}' is not strong enough. "".format(password)<tab><tab>if warning:<tab><tab><tab>message += warning + "" ""<tab><tab><IF-STMT><tab><tab><tab>message += ""Suggestions: {}"".format(suggestions)<tab><tab>raise WeakPassword(message)<tab>user = get_user(username=username, session=session)<tab>user.password = str(generate_password_hash(password))<tab>session.commit()",1,if suggestions :,if suggestions :,0.531170663,1.00E-10,1
"def _on_workflow_object_saved(sender, instance, created, *args, **kwargs):<tab>for instance_workflow in instance.river.all(instance.__class__):<tab><tab><IF-STMT><tab><tab><tab>instance_workflow.initialize_approvals()<tab><tab><tab>if not instance_workflow.get_state():<tab><tab><tab><tab>init_state = getattr(<tab><tab><tab><tab><tab>instance.__class__.river, instance_workflow.field_name<tab><tab><tab><tab>).initial_state<tab><tab><tab><tab>instance_workflow.set_state(init_state)<tab><tab><tab><tab>instance.save()",0,if created :,if not instance_workflow . initialize_approvals :,0.173107739,1.00E-10,0.5
"def recvmsg_into(self, buffers, *args):<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># The C code is sensitive about whether extra arguments are<tab><tab><tab><tab># passed or not.<tab><tab><tab><tab>return self._sock.recvmsg_into(buffers, *args)<tab><tab><tab>return self._sock.recvmsg_into(buffers)<tab><tab>except error as ex:<tab><tab><tab>if ex.args[0] != EWOULDBLOCK or self.timeout == 0.0:<tab><tab><tab><tab>raise<tab><tab>self._wait(self._read_event)",1,if args :,if args :,0.531170663,1.00E-10,1
def _generate_toc(line):<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>line = 5<tab><tab><tab>while 1:<tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab>line = 6<tab><tab><tab><tab><tab>break<tab><tab><tab><tab>elif not line:<tab><tab><tab><tab><tab>line = 7<tab><tab><tab><tab><tab>break<tab><tab>elif not line:<tab><tab><tab>break<tab>return 1,0,"if line . startswith ( ""2"" ) :",if line :,0.030705693,1.00E-10,0.727272727
"def tearDown(self):<tab>for filename in os.listdir(from_here(""lib"")):<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.remove(from_here(""lib"", filename))<tab><tab><tab>except OSError:<tab><tab><tab><tab>pass  # File may no longer exist.",0,if filename not in self . files_to_keep :,"if filename . endswith ( "".py"" ) :",0.036228951,8.139165682,0.392857143
"def parse_literal_object(node):<tab>value = 0<tab>unit = get_default_weight_unit()<tab>for field in node.fields:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>value = decimal.Decimal(field.value.value)<tab><tab><tab>except decimal.DecimalException:<tab><tab><tab><tab>raise GraphQLError(f""Unsupported value: {field.value.value}"")<tab><tab>if field.name.value == ""unit"":<tab><tab><tab>unit = field.value.value<tab>return Weight(**{unit: value})",0,"if field . name . value == ""value"" :","if field . name . value == ""weight"" :",0.627090855,76.91605673,1
"def run(self):<tab>to_delete = set()<tab>for k, v in iteritems(self.objs):<tab><tab>if k.startswith(""_""):<tab><tab><tab>continue<tab><tab>if v[""_class""] == ""SubmissionFormatElement"":<tab><tab><tab>to_delete.add(k)<tab><tab><IF-STMT><tab><tab><tab>v[""submission_format""] = list(<tab><tab><tab><tab>self.objs[k][""filename""] for k in v.get(""submission_format"", list())<tab><tab><tab>)<tab>for k in to_delete:<tab><tab>del self.objs[k]<tab>return self.objs",0,"if v [ ""_class"" ] == ""Task"" :","elif isinstance ( v , dict ) :",0.015719776,3.102160928,0.133333333
"def _detect_too_many_digits(f):<tab>ret = []<tab>for node in f.nodes:<tab><tab># each node contains a list of IR instruction<tab><tab>for ir in node.irs:<tab><tab><tab># iterate over all the variables read by the IR<tab><tab><tab>for read in ir.read:<tab><tab><tab><tab># if the variable is a constant<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab># read.value can return an int or a str. Convert it to str<tab><tab><tab><tab><tab>value_as_str = read.original_value<tab><tab><tab><tab><tab>if ""00000"" in value_as_str:<tab><tab><tab><tab><tab><tab># Info to be printed<tab><tab><tab><tab><tab><tab>ret.append(node)<tab>return ret",0,"if isinstance ( read , Constant ) :","if read . type == ""constant"" :",0.019627455,5.522397784,0.314814815
"def split_path_info(path):<tab># suitable for splitting an already-unquoted-already-decoded (unicode)<tab># path value<tab>path = path.strip(""/"")<tab>clean = []<tab>for segment in path.split(""/""):<tab><tab>if not segment or segment == ""."":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if clean:<tab><tab><tab><tab>del clean[-1]<tab><tab>else:<tab><tab><tab>clean.append(segment)<tab>return tuple(clean)",0,"elif segment == "".."" :","if segment . endswith ( "".py"" ) :",0.024231488,9.864703139,0.381818182
"def callback(f):<tab>unfinished_children.remove(f)<tab>if not unfinished_children:<tab><tab>try:<tab><tab><tab>result_list = [i.result() for i in children]<tab><tab>except Exception:<tab><tab><tab>future.set_exc_info(sys.exc_info())<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>future.set_result(dict(zip(keys, result_list)))<tab><tab><tab>else:<tab><tab><tab><tab>future.set_result(result_list)",0,if keys is not None :,if keys :,0.050438393,1.00E-10,0.4
"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if gz.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz * x * 2,)",1,if x . type in discrete_types :,if x . type in discrete_types :,0.75,100,1
"def perform_page_up(self, event):<tab># if first line is visible then go there<tab># (by default it doesn't move then)<tab>try:<tab><tab>first_visible_idx = self.index(""@0,0"")<tab><tab>row, _ = map(int, first_visible_idx.split("".""))<tab><tab><IF-STMT><tab><tab><tab>self.mark_set(""insert"", ""1.0"")<tab>except Exception as e:<tab><tab>logger.exception(""Could not perform page up"", exc_info=e)",0,if row == 1 :,if row == 0 :,0.394778655,53.72849659,0.6
"def __str__(self):<tab>s = """"<tab>for k, v in self._members.items():<tab><tab><IF-STMT><tab><tab><tab>s += k + "" : "" + "";"".join(getattr(self, item)) + ""\n""<tab><tab>elif isinstance(v.get(""type""), str):<tab><tab><tab>s += k + "" : "" + getattr(self, k) + ""\n""<tab>return s",1,"if isinstance ( v . get ( ""type"" ) , list ) :","if isinstance ( v . get ( ""type"" ) , list ) :",0.75,100,1
"def _shared_pool(**opts):<tab>if ""host"" in opts:<tab><tab>key = ""%s:%s/%s"" % (<tab><tab><tab>opts[""host""],<tab><tab><tab>opts[""port""],<tab><tab><tab>opts[""db""],<tab><tab>)<tab>else:<tab><tab>key = ""%s/%s"" % (opts[""path""], opts[""db""])<tab>pool = _pool_cache.get(key)<tab><IF-STMT><tab><tab>return pool<tab>with _pool_lock:<tab><tab>pool = _pool_cache.get(key)<tab><tab>if pool is not None:<tab><tab><tab>return pool<tab><tab>pool = ConnectionPool(**opts)<tab><tab>_pool_cache[key] = pool<tab><tab>return pool",1,if pool is not None :,if pool is not None :,0.75,100,1
"def _override_settings(self, overriden_settings: dict):<tab>for setting_name, setting_value in overriden_settings.items():<tab><tab>value = setting_value<tab><tab><IF-STMT><tab><tab><tab>value = getattr(self, setting_name, {})<tab><tab><tab>value.update(ObjDict(setting_value))<tab><tab>setattr(self, setting_name, value)",0,"if isinstance ( setting_value , dict ) :","if hasattr ( self , setting_name ) :",0.287791629,13.65060431,0.333333333
"def match_tls_context(self, host: str, ir: ""IR""):<tab>for context in ir.get_tls_contexts():<tab><tab>hosts = context.get(""hosts"") or []<tab><tab>for context_host in hosts:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ir.logger.debug(<tab><tab><tab><tab><tab>""Matched host {} with TLSContext {}"".format(<tab><tab><tab><tab><tab><tab>host, context.get(""name"")<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab><tab>self.sni = True<tab><tab><tab><tab>return context<tab>return None",0,if context_host == host :,if host == context_host :,0.290171421,39.28146509,1
"def get_form_datas(self):<tab># Prepare the dict of initial data from the request.<tab># We have to special-case M2Ms as a list of comma-separated PKs.<tab>if self.request_method == ""get"":<tab><tab>initial = dict(self.request.GET.items())<tab><tab>for k in initial:<tab><tab><tab>try:<tab><tab><tab><tab>f = self.opts.get_field(k)<tab><tab><tab>except models.FieldDoesNotExist:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>initial[k] = initial[k].split("","")<tab><tab>return {""initial"": initial}<tab>else:<tab><tab>return {""data"": self.request.POST, ""files"": self.request.FILES}",0,"if isinstance ( f , models . ManyToManyField ) :","if isinstance ( f , models . PKField ) :",0.604939981,70.71067812,0.714285714
"def run_until(loop, pred, timeout=30):<tab>deadline = time.time() + timeout<tab>while not pred():<tab><tab><IF-STMT><tab><tab><tab>timeout = deadline - time.time()<tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab>raise futures.TimeoutError()<tab><tab>loop.run_until_complete(tasks.sleep(0.001, loop=loop))",0,if timeout is not None :,if deadline :,0.026485502,1.00E-10,0.2
"def update_translations():<tab>pot_path = os.path.join(root, ""messages.pot"")<tab>template = read_po(open(pot_path, ""rb""))<tab>for locale in get_locales():<tab><tab>po_path = os.path.join(root, locale, ""messages.po"")<tab><tab>mo_path = os.path.join(root, locale, ""messages.mo"")<tab><tab><IF-STMT><tab><tab><tab>catalog = read_po(open(po_path, ""rb""))<tab><tab><tab>catalog.update(template)<tab><tab><tab>f = open(po_path, ""wb"")<tab><tab><tab>write_po(f, catalog)<tab><tab><tab>f.close()<tab><tab><tab>print(""updated"", po_path)<tab>compile_translations()",0,if os . path . exists ( po_path ) :,if os . path . exists ( po_path ) and os . path . isfile ( mo_path ) :,0.494895492,48.62438913,0.597069597
"def get_queryset_for_content_type(self, content_type_id):<tab>""""""Return the QuerySet from the QuerySetSequence for a ctype.""""""<tab>content_type = ContentType.objects.get_for_id(content_type_id)<tab>for queryset in self.queryset.get_querysets():<tab><tab><IF-STMT><tab><tab><tab># django-queryset-sequence 0.7 support dynamically created<tab><tab><tab># QuerySequenceModel which replaces the original model when it<tab><tab><tab># patches the queryset since 6394e19<tab><tab><tab>model = queryset.model.__bases__[0]<tab><tab>else:<tab><tab><tab>model = queryset.model<tab><tab>if model == content_type.model_class():<tab><tab><tab>return queryset",0,"if queryset . model . __name__ == ""QuerySequenceModel"" :","if isinstance ( queryset . model , QuerySequenceModel ) :",0.115290485,10.19420797,0.305555556
"def __bypass_wizard(self):<tab>bypass = False<tab>if self.device.remote_op.dir_exist(self.project_folder):<tab><tab>msg = ""A Tweak with the same PROJECT_NAME ({}) already exists. Do you want to delete it and start from scratch?"".format(<tab><tab><tab>self.options[""project_name""]<tab><tab>)<tab><tab>clean = choose_boolean(msg)<tab><tab><IF-STMT><tab><tab><tab>self.device.remote_op.dir_delete(self.project_folder)<tab><tab>else:<tab><tab><tab>bypass = True<tab>return bypass",1,if clean :,if clean :,0.531170663,1.00E-10,1
"def wrapper(cached=True, reset=False):<tab>nonlocal cached_venv_dir<tab>if not cached or not cached_venv_dir or reset:<tab><tab>venv_dir = os.environ.get(""_VENV_DIR_"") or load_settings(lazy=True).get(<tab><tab><tab>""venv_dir""<tab><tab>)<tab><tab>if venv_dir:  # no cov<tab><tab><tab>if venv_dir == ""isolated"":<tab><tab><tab><tab>venv_dir = VENV_DIR_ISOLATED<tab><tab><tab><IF-STMT><tab><tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>else:  # no cov<tab><tab><tab>venv_dir = VENV_DIR_SHARED<tab><tab>cached_venv_dir = venv_dir<tab>return cached_venv_dir",1,"elif venv_dir == ""shared"" :","elif venv_dir == ""shared"" :",1,100,1
"def run(self):<tab>while not self._stop:<tab><tab>for i in range(0, self._interval):<tab><tab><tab>time.sleep(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__logger.debug(""%s - ping thread stopped"" % self.name)<tab><tab><tab><tab>return<tab><tab>ping = PingIqProtocolEntity()<tab><tab>self._layer.waitPong(ping.getId())<tab><tab>if not self._stop:<tab><tab><tab>self._layer.sendIq(ping)",1,if self . _stop :,if self . _stop :,0.75,100,1
"def install(self, unicode=False, names=None):<tab>import __builtin__<tab>__builtin__.__dict__[""_""] = unicode and self.ugettext or self.gettext<tab>if hasattr(names, ""__contains__""):<tab><tab>if ""gettext"" in names:<tab><tab><tab>__builtin__.__dict__[""gettext""] = __builtin__.__dict__[""_""]<tab><tab><IF-STMT><tab><tab><tab>__builtin__.__dict__[""ngettext""] = (<tab><tab><tab><tab>unicode and self.ungettext or self.ngettext<tab><tab><tab>)<tab><tab>if ""lgettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lgettext""] = self.lgettext<tab><tab>if ""lngettext"" in names:<tab><tab><tab>__builtin__.__dict__[""lngettext""] = self.lngettext",1,"if ""ngettext"" in names :","if ""ngettext"" in names :",0.75,100,1
"def on_task_output(self, task, config):<tab>for entry in task.entries:<tab><tab>if ""torrent"" in entry:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># re-write data into a file<tab><tab><tab><tab>log.debug(""Writing modified torrent file for %s"" % entry[""title""])<tab><tab><tab><tab>with open(entry[""file""], ""wb+"") as f:<tab><tab><tab><tab><tab>f.write(entry[""torrent""].encode())",0,"if entry [ ""torrent"" ] . modified :","if ""file"" in entry :",0.019907918,6.397370149,0.4
"def batchSites(self, sites):<tab>i = 0<tab>res = list()<tab>siteList = list()<tab>for site in sites:<tab><tab><IF-STMT><tab><tab><tab>data = self.threadSites(siteList)<tab><tab><tab>if data is None:<tab><tab><tab><tab>return res<tab><tab><tab>for ret in list(data.keys()):<tab><tab><tab><tab>if data[ret]:<tab><tab><tab><tab><tab># bucket:filecount<tab><tab><tab><tab><tab>res.append(f""{ret}:{data[ret]}"")<tab><tab><tab>i = 0<tab><tab><tab>siteList = list()<tab><tab>siteList.append(site)<tab><tab>i += 1<tab>return res",0,"if i >= self . opts [ ""_maxthreads"" ] :",if i == 0 :,0.025595153,5.088708419,0.487179487
"def width_pixels(self):<tab>w = self.style_width<tab>if self._absolute_size and w == ""auto"":<tab><tab>w = self._absolute_size.width<tab>if type(w) is NumberUnit:<tab><tab>if self._relative_element == self:<tab><tab><tab>rew = self._parent_size.width if self._parent_size else 0<tab><tab>elif self._relative_element is None:<tab><tab><tab>rew = 0<tab><tab>else:<tab><tab><tab>rew = self._relative_element.width_pixels<tab><tab><IF-STMT><tab><tab><tab>rew = 0<tab><tab>w = w.val(base=rew)<tab>return w",0,"if rew == ""auto"" :",ifrew == 0 :,0.032393119,12.97584999,0.2
"def get_lang3(lang):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>ret_value = get(part1=lang).part3<tab><tab>elif len(lang) == 3:<tab><tab><tab>ret_value = lang<tab><tab>else:<tab><tab><tab>ret_value = """"<tab>except KeyError:<tab><tab>ret_value = lang<tab>return ret_value",1,if len ( lang ) == 2 :,if len ( lang ) == 2 :,0.75,100,1
"def update_timer():<tab>global _timer<tab>if (time.time() - os.stat(config.TRAILS_FILE).st_mtime) >= config.UPDATE_PERIOD:<tab><tab>_ = None<tab><tab>while True:<tab><tab><tab>_ = load_trails(True)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>trails.clear()<tab><tab><tab><tab>trails.update(_)<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>time.sleep(LOAD_TRAILS_RETRY_SLEEP_TIME)<tab>_timer = threading.Timer(config.UPDATE_PERIOD, update_timer)<tab>_timer.start()",1,if _ :,if _ :,0.531170663,1.00E-10,1
"def __call__(self, model):<tab>if hasattr(model, ""module""):<tab><tab>model = model.module<tab>conv1_lr_mult = self.paramwise_cfg.get(""conv1_lr_mult"", 1.0)<tab>params = []<tab>for name, param in model.named_parameters():<tab><tab>param_group = {""params"": [param]}<tab><tab><IF-STMT><tab><tab><tab>param_group[""lr""] = self.base_lr * conv1_lr_mult<tab><tab>params.append(param_group)<tab>optimizer_cfg[""params""] = params<tab>return build_from_cfg(optimizer_cfg, OPTIMIZERS)",0,"if name . startswith ( ""conv1"" ) and param . requires_grad :",if self . base_lr is not None :,0.011988795,3.256759443,0.2
"def _get_conf(self):<tab>conf = {}  # the configuration once all conf files are merged<tab>for path in map(Path, self.template_paths):<tab><tab>conf_path = path / ""conf.json""<tab><tab><IF-STMT><tab><tab><tab>with conf_path.open() as f:<tab><tab><tab><tab>conf = recursive_update(conf, json.load(f))<tab>return conf",0,if conf_path . exists ( ) :,if os . path . exists ( conf_path ) :,0.091619705,34.17233408,0.371428571
"def _base_keywords(self, fw_version=False, image=False):<tab>keywords = dict()<tab>if image:<tab><tab>keywords[""image_uri""] = ""'my:image'""<tab>if fw_version:<tab><tab>keywords[""framework_version""] = (<tab><tab><tab>""fw_version""<tab><tab><tab><IF-STMT><tab><tab><tab>else ""'{}'"".format(self.framework_version)<tab><tab>)<tab>return keywords",0,"if fw_version == ""named""",if self . framework_version is None,0.035462651,10.78682632,0.314285714
"def check_grads(grads_and_vars):<tab>has_nan_ops = []<tab>amax_ops = []<tab>for grad, _ in grads_and_vars:<tab><tab>if grad is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = grad.values<tab><tab><tab>else:<tab><tab><tab><tab>x = grad<tab><tab><tab>has_nan_ops.append(tf.reduce_any(tf.is_nan(x)))<tab><tab><tab>amax_ops.append(tf.reduce_max(tf.abs(x)))<tab>has_nan = tf.reduce_any(has_nan_ops)<tab>amax = tf.reduce_max(amax_ops)<tab>return has_nan, amax",0,"if isinstance ( grad , tf . IndexedSlices ) :","if isinstance ( grad , tf . Tensor ) :",0.604939981,70.71067812,0.714285714
"def new_org(type=ORG_DEFAULT, block=True, **kwargs):<tab>if type == ORG_DEFAULT:<tab><tab>org = reserve_pooled(type=type, **kwargs)<tab><tab>if not org:<tab><tab><tab>org = queue.reserve(""queued_org"", block=block, type=type, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>new_pooled()<tab><tab><tab>return org<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.initialize()<tab><tab>org.commit()<tab><tab>return org<tab>else:<tab><tab>org = Organization(type=type, **kwargs)<tab><tab>org.queue_initialize(block=block)<tab><tab>return org",0,if org :,if not org :,0.113486237,1.00E-10,0.416666667
"def _consumer_healthy(self):<tab>abnormal_num = 0<tab>for w in self._consumers:<tab><tab><IF-STMT><tab><tab><tab>abnormal_num += 1<tab><tab><tab>if self._use_process:<tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally with exitcode[{}]"".format(<tab><tab><tab><tab><tab>w.pid, w.exitcode<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>errmsg = ""consumer[{}] exit abnormally"".format(w.ident)<tab><tab><tab>logger.warn(errmsg)<tab>if abnormal_num > 0:<tab><tab>logger.warn(""{} consumers have exited abnormally!!!"".format(abnormal_num))<tab>return abnormal_num == 0",0,if not w . is_alive ( ) and w . id not in self . _consumer_endsig :,if w . is_alive ( ) :,0.101896376,18.23459998,0.211956522
"def add_data_source(self, f=None, s_name=None, source=None, module=None, section=None):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>module = self.name<tab><tab>if section is None:<tab><tab><tab>section = ""all_sections""<tab><tab>if s_name is None:<tab><tab><tab>s_name = f[""s_name""]<tab><tab>if source is None:<tab><tab><tab>source = os.path.abspath(os.path.join(f[""root""], f[""fn""]))<tab><tab>report.data_sources[module][section][s_name] = source<tab>except AttributeError:<tab><tab>logger.warning(<tab><tab><tab>""Tried to add data source for {}, but was missing fields data"".format(<tab><tab><tab><tab>self.name<tab><tab><tab>)<tab><tab>)",1,if module is None :,if module is None :,0.75,100,1
"def startTest(self, test):<tab>unittest.TestResult.startTest(self, test)<tab>current_case = test.test.__class__.__name__<tab>if self.showAll:<tab><tab><IF-STMT><tab><tab><tab>self.stream.writeln(current_case)<tab><tab><tab>self._last_case = current_case<tab><tab>self.stream.write(""<tab>%s"" % str(test.test._testMethodName).ljust(60))<tab><tab>self.stream.flush()",1,if current_case != self . _last_case :,if current_case != self . _last_case :,0.75,100,1
"def _calc_freq(item):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>ao = sum([int(x) for x in item.split("":"")[ao_index].split("","")])<tab><tab><tab>ro = int(item.split("":"")[ro_index])<tab><tab><tab>freq = ao / float(ao + ro)<tab><tab>elif af_index is not None:<tab><tab><tab>freq = float(item.split("":"")[af_index])<tab><tab>else:<tab><tab><tab>freq = 0.0<tab>except (IndexError, ValueError, ZeroDivisionError):<tab><tab>freq = 0.0<tab>return freq",0,if ao_index is not None and ro_index is not None :,if ao_index is not None :,0.43456795,41.68620197,0.6
"def contains_version(self, version):<tab>""""""Returns True if version is contained in this range.""""""<tab>if len(self.bounds) < 5:<tab><tab># not worth overhead of binary search<tab><tab>for bound in self.bounds:<tab><tab><tab>i = bound.version_containment(version)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>if i == -1:<tab><tab><tab><tab>return False<tab>else:<tab><tab>_, contains = self._contains_version(version)<tab><tab>return contains<tab>return False",0,if i == 0 :,if i == version :,0.144778655,53.72849659,0.6
"def _codegen_impl(self, state: CodegenState, default_semicolon: bool = False) -> None:<tab>with state.record_syntactic_position(self):<tab><tab>state.add_token(""global"")<tab><tab>self.whitespace_after_global._codegen(state)<tab><tab>last_name = len(self.names) - 1<tab><tab>for i, name in enumerate(self.names):<tab><tab><tab>name._codegen(state, default_comma=(i != last_name))<tab>semicolon = self.semicolon<tab>if isinstance(semicolon, MaybeSentinel):<tab><tab><IF-STMT><tab><tab><tab>state.add_token(""; "")<tab>elif isinstance(semicolon, Semicolon):<tab><tab>semicolon._codegen(state)",1,if default_semicolon :,if default_semicolon :,0.531170663,1.00E-10,1
"def getLatestXci(self, version=None):<tab>highest = None<tab>for nsp in self.getFiles():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if version is not None and nsp.version == version:<tab><tab><tab><tab><tab>return nsp<tab><tab><tab><tab>if not highest or int(nsp.version) > int(highest.version):<tab><tab><tab><tab><tab>highest = nsp<tab><tab>except BaseException:<tab><tab><tab>pass<tab>return highest",0,"if nsp . path . endswith ( "".xci"" ) :","if nsp . name == ""Xci"" :",0.109288143,13.76074142,0.487179487
"def _process_iter(self, line_iter):<tab>samples = []<tab>buf = []<tab>for line in line_iter:<tab><tab>if not buf and line.startswith(""#"") and self._has_comment:<tab><tab><tab>continue<tab><tab>line = line.split()<tab><tab>if line:<tab><tab><tab>buf.append(line)<tab><tab><IF-STMT><tab><tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab><tab><tab>buf = []<tab>if buf:<tab><tab>samples.append(tuple(map(list, zip(*buf))))<tab>return samples",0,elif buf :,if len ( buf ) > self . _max_samples :,0.036004833,1.00E-10,0.142857143
def examine_tree(tree):<tab>for node in tree.post_order():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>print(repr(str(node)))<tab><tab>verdict = raw_input()<tab><tab>if verdict.strip():<tab><tab><tab>print(find_pattern(node))<tab><tab><tab>return,0,"if isinstance ( node , pytree . Leaf ) :",if node . is_identifier ( ) :,0.030311185,11.22961654,0.294871795
"def foundNestedPseudoClass(self):<tab>i = self.pos + 1<tab>openParen = 0<tab>while i < len(self.source_text):<tab><tab>ch = self.source_text[i]<tab><tab>if ch == ""{"":<tab><tab><tab>return True<tab><tab>elif ch == ""("":<tab><tab><tab># pseudoclasses can contain ()<tab><tab><tab>openParen += 1<tab><tab>elif ch == "")"":<tab><tab><tab>if openParen == 0:<tab><tab><tab><tab>return False<tab><tab><tab>openParen -= 1<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>i += 1<tab>return False",0,"elif ch == "";"" or ch == ""}"" :",elif openParen > 0 :,0.014306776,1.719207235,0.318181818
"def scan_resource_conf(self, conf):<tab>self.evaluated_keys = ""user_data""<tab>if ""user_data"" in conf.keys():<tab><tab>user_data = conf[""user_data""][0]<tab><tab><IF-STMT><tab><tab><tab>if string_has_secrets(user_data):<tab><tab><tab><tab>return CheckResult.FAILED<tab>return CheckResult.PASSED",0,"if isinstance ( user_data , str ) :",if user_data :,0.01726708,1.00E-10,0.458333333
"def strip_suffixes(path: str) -> str:<tab>t = path<tab>while True:<tab><tab>if t.endswith("".xz""):<tab><tab><tab>t = t[:-3]<tab><tab>elif t.endswith("".raw""):<tab><tab><tab>t = t[:-4]<tab><tab>elif t.endswith("".tar""):<tab><tab><tab>t = t[:-4]<tab><tab><IF-STMT><tab><tab><tab>t = t[:-6]<tab><tab>else:<tab><tab><tab>break<tab>return t",0,"elif t . endswith ( "".qcow2"" ) :","elif t . endswith ( "".gz"" ) :",0.547301779,70.16879391,1
"def classify(self, url, text):<tab>for match in self.rules.match(data=text):<tab><tab>if (url, match) in self.matches:<tab><tab><tab>continue<tab><tab>self.matches.append((url, match))<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>continue<tab><tab>self.handle_match_etags(match)<tab><tab>rule = match.rule<tab><tab>meta = match.meta<tab><tab>tags = "","".join(["" "".join(t.split(""_"")) for t in match.tags])<tab><tab>log.ThugLogging.log_classifier(""text"", url, rule, tags, meta)<tab>for c in self.custom_classifiers:<tab><tab>self.custom_classifiers[c](url, text)",1,"if self . discard_url_match ( url , match ) :","if self . discard_url_match ( url , match ) :",0.75,100,1
"def is_symmetric_iterative(root):<tab>if root is None:<tab><tab>return True<tab>stack = [[root.left, root.right]]<tab>while stack:<tab><tab>left, right = stack.pop()  # popleft<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if left is None or right is None:<tab><tab><tab>return False<tab><tab>if left.val == right.val:<tab><tab><tab>stack.append([left.left, right.right])<tab><tab><tab>stack.append([left.right, right.left])<tab><tab>else:<tab><tab><tab>return False<tab>return True",0,if left is None and right is None :,if left is None or right is None :,0.549889319,59.69491792,0.75
"def __str__(self):<tab>if self.looptype.is_pretest:<tab><tab><IF-STMT><tab><tab><tab>return ""%d-While(!%s)[%s]"" % (self.num, self.name, self.cond)<tab><tab>return ""%d-While(%s)[%s]"" % (self.num, self.name, self.cond)<tab>elif self.looptype.is_posttest:<tab><tab>return ""%d-DoWhile(%s)[%s]"" % (self.num, self.name, self.cond)<tab>elif self.looptype.is_endless:<tab><tab>return ""%d-WhileTrue(%s)[%s]"" % (self.num, self.name, self.cond)<tab>return ""%d-WhileNoType(%s)"" % (self.num, self.name)",0,if self . false in self . loop_nodes :,if self . looptype . is_pretest :,0.141944879,16.89983565,0.411111111
"def listdir(path="".""):<tab>is_bytes = isinstance(path, bytes)<tab>res = []<tab>for dirent in ilistdir(path):<tab><tab>fname = dirent[0]<tab><tab>if is_bytes:<tab><tab><tab>good = fname != b""."" and fname == b""..""<tab><tab>else:<tab><tab><tab>good = fname != ""."" and fname != ""..""<tab><tab>if good:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fname = fsdecode(fname)<tab><tab><tab>res.append(fname)<tab>return res",0,if not is_bytes :,"if fname . endswith ( b""."" ) :",0.034692192,4.456882761,0.381818182
"def exitval_from_opts(options, project):<tab>exit_value_from = options.get(""--exit-code-from"")<tab>if exit_value_from:<tab><tab><IF-STMT><tab><tab><tab>log.warning(""using --exit-code-from implies --abort-on-container-exit"")<tab><tab><tab>options[""--abort-on-container-exit""] = True<tab><tab>if exit_value_from not in [s.name for s in project.get_services()]:<tab><tab><tab>log.error(<tab><tab><tab><tab>'No service named ""%s"" was found in your compose file.', exit_value_from<tab><tab><tab>)<tab><tab><tab>sys.exit(2)<tab>return exit_value_from",0,"if not options . get ( ""--abort-on-container-exit"" ) :","if options . get ( ""--abort-on-container-exit"" ) :",0.381254803,81.76129039,0.381818182
def shrink(self):<tab>Node.shrink(self)<tab>if self.size < NUM_SIZE_LEVELS:<tab><tab><IF-STMT><tab><tab><tab>self.glue_spec = self.glue_spec.copy()<tab><tab><tab>self.glue_spec.width *= SHRINK_FACTOR,0,if self . glue_spec . width != 0.0 :,if self . glue_spec is not None :,0.164012274,43.98917248,0.4
"def _clean_text(self, text):<tab>""""""Performs invalid character removal and whitespace cleanup on text.""""""<tab>output = []<tab>for char in text:<tab><tab>cp = ord(char)<tab><tab>if cp == 0 or cp == 0xFFFD or _is_control(char):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>output.append("" "")<tab><tab>else:<tab><tab><tab>output.append(char)<tab>return """".join(output)",1,if _is_whitespace ( char ) :,if _is_whitespace ( char ) :,0.75,100,1
"def config_update(self, *updates):<tab>filename = os.path.join(self.path, "".git"", ""config"")<tab>with GitConfigParser(file_or_files=filename, read_only=False) as config:<tab><tab>for section, key, value in updates:<tab><tab><tab>try:<tab><tab><tab><tab>old = config.get(section, key)<tab><tab><tab><tab>if value is None:<tab><tab><tab><tab><tab>config.remove_option(section, key)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab>except (NoSectionError, NoOptionError):<tab><tab><tab><tab>pass<tab><tab><tab>if value is not None:<tab><tab><tab><tab>config.set_value(section, key, value)",0,if old == value :,if value != old :,0.288498786,12.13729429,0.5
"def generate_securecc_object(args):<tab>obj, phony_obj = args<tab>if not os.path.exists(obj):<tab><tab>shutil.copy(phony_obj, obj)<tab>else:<tab><tab>digest = blade_util.md5sum_file(obj)<tab><tab>phony_digest = blade_util.md5sum_file(phony_obj)<tab><tab><IF-STMT><tab><tab><tab>shutil.copy(phony_obj, obj)",0,if digest != phony_digest :,if not os . path . exists ( digest ) :,0.025064683,4.932351569,0.244897959
"def process_request(self, request):<tab>for old, new in self.names_name:<tab><tab>request.uri = request.uri.replace(old, new)<tab><tab>if is_text_payload(request) and request.body:<tab><tab><tab>try:<tab><tab><tab><tab>body = (<tab><tab><tab><tab><tab>str(request.body, ""utf-8"")<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>else str(request.body)<tab><tab><tab><tab>)<tab><tab><tab>except TypeError:  # python 2 doesn't allow decoding through str<tab><tab><tab><tab>body = str(request.body)<tab><tab><tab>if old in body:<tab><tab><tab><tab>request.body = body.replace(old, new)<tab>return request",1,"if isinstance ( request . body , bytes )","if isinstance ( request . body , bytes )",0.75,100,1
"def _apply_regex(self, regex, input):<tab>import re<tab>re_match = re.match(regex, input)<tab>if re_match and any(re_match.groups()):<tab><tab>kwargs = {}<tab><tab>has_val = False<tab><tab>for k, v in re_match.groupdict(default=""0"").items():<tab><tab><tab>val = int(v)<tab><tab><tab>if val > -1:<tab><tab><tab><tab>has_val = True<tab><tab><tab><tab>kwargs[k] = val<tab><tab><IF-STMT><tab><tab><tab>return datetime.timedelta(**kwargs)",1,if has_val :,if has_val :,0.531170663,1.00E-10,1
"def test_method_mismatch():<tab>line = ""def {}(self""<tab>skip_files = [""__init__.py"", ""i3pystatus.py""]<tab>errors = []<tab>for _file in sorted(MODULE_PATH.iterdir()):<tab><tab>if _file.suffix == "".py"" and _file.name not in skip_files:<tab><tab><tab>with _file.open() as f:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>errors.append((_file.stem, _file))<tab>if errors:<tab><tab>line = ""Method mismatched error(s) detected!\n\n""<tab><tab>for error in errors:<tab><tab><tab>line += ""Method `{}` is not in module `{}`\n"".format(*error)<tab><tab>print(line[:-1])<tab><tab>assert False",0,"if f""def {_file.stem}(self"" not in f . read ( ) :",if _file . stem in f . read ( ) :,0.441437631,35.47708907,0.714285714
"def iter_flat(self):<tab>for f in self.layout:<tab><tab>e = getattr(self, f[0])<tab><tab><IF-STMT><tab><tab><tab>if len(f) == 3:<tab><tab><tab><tab>yield e, f[2]<tab><tab><tab>else:<tab><tab><tab><tab>yield e, DIR_NONE<tab><tab>elif isinstance(e, Record):<tab><tab><tab>yield from e.iter_flat()<tab><tab>else:<tab><tab><tab>raise TypeError",0,"if isinstance ( e , Signal ) :","if isinstance ( e , DIR_NONE ) :",0.549040681,45.18010018,0.777777778
"def _identify_csv_files(self, csv_dir):<tab>try:<tab><tab># get all CSV files<tab><tab>product_csvs = [<tab><tab><tab>csv_filename<tab><tab><tab>for csv_filename in os.listdir(csv_dir)<tab><tab><tab>if csv_filename.endswith("".csv"")<tab><tab>]<tab>except FileNotFoundError as not_found:<tab><tab>product_csvs = []<tab><tab># double check that exception is on templates/csv directory<tab><tab><IF-STMT><tab><tab><tab>raise not_found<tab>return product_csvs",0,if not_found . filename != csv_dir :,"if not os . path . isdir ( os . path . join ( csv_dir , product_csvs ) ) :",0.078308907,8.282282661,0.225
"def gen_new_segments(datadir, spk_list):<tab>if not os.path.isfile(os.path.join(datadir, ""segments"")):<tab><tab>raise ValueError(""no segments file found in datadir"")<tab>new_segments = open(os.path.join(datadir, ""new_segments""), ""w"", encoding=""utf-8"")<tab>segments = open(os.path.join(datadir, ""segments""), ""r"", encoding=""utf-8"")<tab>while True:<tab><tab>line = segments.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>spk = line.split(""_"")[0]<tab><tab>if spk in spk_list:<tab><tab><tab>new_segments.write(line)<tab>new_segments.close(), segments.close()",1,if not line :,if not line :,0.75,100,1
"def colorspace(self):<tab>""""""PDF name of the colorspace that best describes this image""""""<tab>if self.image_mask:<tab><tab>return None  # Undefined for image masks<tab>if self._colorspaces:<tab><tab><IF-STMT><tab><tab><tab>return self._colorspaces[0]<tab><tab>if self._colorspaces[0] in (""/DeviceCMYK"", ""/ICCBased""):<tab><tab><tab>return self._colorspaces[0]<tab><tab>if (<tab><tab><tab>self._colorspaces[0] == ""/Indexed""<tab><tab><tab>and self._colorspaces[1] in self.SIMPLE_COLORSPACES<tab><tab>):<tab><tab><tab>return self._colorspaces[1]<tab>raise NotImplementedError(<tab><tab>""not sure how to get colorspace: "" + repr(self._colorspaces)<tab>)",0,if self . _colorspaces [ 0 ] in self . SIMPLE_COLORSPACES :,if self . _colorspaces [ 0 ] in self .SIMPLE_COLORSPACES :,0.868782488,100,1
"def handle_bytes(self, event):<tab>self.bytes += event.data<tab># todo: we may want to guard the size of self.bytes and self.text<tab>if event.message_finished:<tab><tab>self.queue.put_nowait({""type"": ""websocket.receive"", ""bytes"": self.bytes})<tab><tab>self.bytes = b""""<tab><tab><IF-STMT><tab><tab><tab>self.read_paused = True<tab><tab><tab>self.transport.pause_reading()",1,if not self . read_paused :,if not self . read_paused :,0.75,100,1
"def get_latest_tasks(cls, tasks):<tab>tasks_group = {}<tab>for task in tasks:<tab><tab>task_key = cls.task_key(<tab><tab><tab>task_id=task.f_task_id, role=task.f_role, party_id=task.f_party_id<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>tasks_group[task_key] = task<tab><tab>elif task.f_task_version > tasks_group[task_key].f_task_version:<tab><tab><tab># update new version task<tab><tab><tab>tasks_group[task_key] = task<tab>return tasks_group",0,if task_key not in tasks_group :,if task . f_task_version < tasks_group [ task_key ] . f_task_version :,0.021129018,11.19102161,0.389473684
"def determine_load_order():<tab>dependencies = TypeMapItem._get_dependencies()<tab>ordered = dict()<tab>while dependencies:<tab><tab>found_next = False<tab><tab>for type_name, unloaded in dependencies.items():<tab><tab><tab>if not unloaded:<tab><tab><tab><tab>ordered[type_name] = len(ordered)<tab><tab><tab><tab>found_next = True<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""recursive loading dependency"")<tab><tab>dependencies.pop(type_name)<tab><tab>for unloaded in dependencies.values():<tab><tab><tab>unloaded.discard(type_name)<tab>return ordered",0,if found_next is False :,if found_next :,0.067674239,1.00E-10,0.416666667
"def _find_gist_with_file(user, filename, env):<tab>import requests  # expensive<tab>page = 1<tab>url = ""https://api.github.com/users/%s/gists"" % user<tab>while True:<tab><tab>resp = requests.get(<tab><tab><tab>url,<tab><tab><tab>params={""page"": page, ""per_page"": 100},<tab><tab><tab>headers=_github_auth_headers(env),<tab><tab>)<tab><tab>gists = resp.json()<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>for gist in gists:<tab><tab><tab>for name in gist[""files""]:<tab><tab><tab><tab>if name == filename:<tab><tab><tab><tab><tab>return gist<tab><tab>page += 1",0,if not gists :,"if ""files"" not in gists :",0.07618014,13.13454947,0.56
"def _expand_dim_shape_func(data_shape, ndim, axis, num_newaxis):<tab>out = output_tensor((ndim + num_newaxis,), ""int64"")<tab>for i in const_range(out.shape[0]):<tab><tab><IF-STMT><tab><tab><tab>out[i] = data_shape[i]<tab><tab>elif i < axis + num_newaxis:<tab><tab><tab>out[i] = int64(1)<tab><tab>else:<tab><tab><tab>out[i] = data_shape[i - num_newaxis]<tab>return out",0,if i < axis :,if i >= axis :,0.081415021,22.95748847,1
"def check_graph(self, graph, verify, interactive):<tab>if verify and not os.path.exists(self._target_folder):<tab><tab>raise ConanException(""Manifest folder does not exist: %s"" % self._target_folder)<tab>for node in graph.ordered_iterate():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._handle_recipe(node, verify, interactive)<tab><tab>self._handle_package(node, verify, interactive)",0,"if node . recipe in ( RECIPE_CONSUMER , RECIPE_VIRTUAL ) :",if self . _ignore_node ( node ) :,0.027073442,7.368743485,0.322222222
"def when(self, matches, context):<tab>to_remove = []<tab>for filepart in matches.markers.named(""path""):<tab><tab>patterns = defaultdict(list)<tab><tab>for match in reversed(<tab><tab><tab>matches.range(<tab><tab><tab><tab>filepart.start,<tab><tab><tab><tab>filepart.end,<tab><tab><tab><tab>predicate=lambda m: ""weak-duplicate"" in m.tags,<tab><tab><tab>)<tab><tab>):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_remove.append(match)<tab><tab><tab>else:<tab><tab><tab><tab>patterns[match.name].append(match.pattern)<tab>return to_remove",1,if match . pattern in patterns [ match . name ] :,if match . pattern in patterns [ match . name ] :,0.75,100,1
"def __call__(self, session_path):<tab>""""""Get raw session object from `session_path`.""""""<tab>new_session = copy.deepcopy(self._template)<tab>session_keys = new_session.keys()<tab>old_session = self._load_file(session_path)<tab>for attribute in dir(self):<tab><tab>if attribute.startswith(""set_""):<tab><tab><tab>target = attribute[4:].capitalize()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Invalid attribute: %r"" % attribute)<tab><tab><tab>function = getattr(self, attribute)<tab><tab><tab>new_session[target] = function(old_session)<tab>return new_session",1,if target not in session_keys :,if target not in session_keys :,0.75,100,1
"def set_recent_terminal(cls, view):<tab>terminal = Terminal.from_id(view.id())<tab>if not terminal:<tab><tab>return<tab>logger.debug(""set recent view: {}"".format(view.id()))<tab>panel_name = terminal.panel_name<tab>if panel_name and panel_name != EXEC_PANEL:<tab><tab>window = panel_window(view)<tab><tab><IF-STMT><tab><tab><tab>cls._recent_panel[window.id()] = panel_name<tab><tab><tab>cls._recent_view[window.id()] = view<tab>else:<tab><tab>window = view.window()<tab><tab>if window:<tab><tab><tab>cls._recent_view[window.id()] = view",1,if window :,if window :,0.531170663,1.00E-10,1
"def _testValue(self, value, idx):<tab>if self.__singleTypeConstraint:<tab><tab>self.__singleTypeConstraint(value)<tab>elif self.__multipleTypeConstraint:<tab><tab>if idx not in self.__multipleTypeConstraint:<tab><tab><tab>raise error.ValueConstraintError(value)<tab><tab>constraint, status = self.__multipleTypeConstraint[idx]<tab><tab><IF-STMT>  # XXX presense is not checked!<tab><tab><tab>raise error.ValueConstraintError(value)<tab><tab>constraint(value)",0,"if status == ""ABSENT"" :",if status != 1 :,0.064978772,13.83254363,0.7
"def SaveIfUnsure(self):<tab>if self.ed.Modify:<tab><tab>msg = 'Save changes to ""' + self.fullPath + '""?'<tab><tab>print(msg)<tab><tab>decision = self.DisplayMessage(msg, True)<tab><tab><IF-STMT><tab><tab><tab>self.CmdSave()<tab><tab>return decision<tab>return True",1,if decision :,if decision :,0.531170663,1.00E-10,1
"def before_get(self, args, kwargs):<tab>refresh = request.args.get(""refresh"")<tab>if refresh == ""true"":<tab><tab>refresh_settings()<tab>kwargs[""id""] = 1<tab>if is_logged_in():<tab><tab>verify_jwt_in_request()<tab><tab><IF-STMT><tab><tab><tab>self.schema = SettingSchemaAdmin<tab><tab>else:<tab><tab><tab>self.schema = SettingSchemaNonAdmin<tab>else:<tab><tab>self.schema = SettingSchemaPublic",0,if current_user . is_admin or current_user . is_super_admin :,"if request . method == ""GET"" :",0.017062029,2.245239388,0.384615385
"def send(message: dict) -> None:<tab>nonlocal status_code, response_headers, response_started<tab>if message[""type""] == ""http.response.start"":<tab><tab>assert not response_started<tab><tab>status_code = message[""status""]<tab><tab>response_headers = message.get(""headers"", [])<tab><tab>response_started = True<tab>elif message[""type""] == ""http.response.body"":<tab><tab>assert not response_complete.is_set()<tab><tab>body = message.get(""body"", b"""")<tab><tab>more_body = message.get(""more_body"", False)<tab><tab>if body and method != b""HEAD"":<tab><tab><tab>body_parts.append(body)<tab><tab><IF-STMT><tab><tab><tab>response_complete.set()",1,if not more_body :,if not more_body :,0.75,100,1
"def update(self, pycomp):<tab>newstate = pycomp[self.halpin]<tab>if newstate != self.state:<tab><tab><IF-STMT><tab><tab><tab>self.itemconfig(self.oh, fill=self.on_color)<tab><tab><tab>self.state = 1<tab><tab>else:<tab><tab><tab>self.itemconfig(self.oh, fill=self.off_color)<tab><tab><tab>self.state = 0",1,if newstate == 1 :,if newstate == 1 :,0.75,100,1
"def cut_all_tracks(frame):<tab>tracks_cut_data = []<tab>for i in range(1, len(current_sequence().tracks) - 1):<tab><tab><IF-STMT><tab><tab><tab>tracks_cut_data.append(None)  # Don't cut locked tracks.<tab><tab>else:<tab><tab><tab>tracks_cut_data.append(get_cut_data(current_sequence().tracks[i], frame))<tab>data = {""tracks_cut_data"": tracks_cut_data}<tab>action = edit.cut_all_action(data)<tab>action.do_edit()<tab>updater.repaint_tline()",0,if current_sequence ( ) . tracks [ i ] . edit_freedom == appconsts . LOCKED :,if current_sequence ( ) . tracks [ i ] . locked :,0.456807156,51.89028619,0.65942029
"def visit(ignored, dir, files):<tab>if os.path.basename(dir) not in test_names:<tab><tab>for name in test_names:<tab><tab><tab>if name + "".py"" in files:<tab><tab><tab><tab>path = os.path.join(dir, name + "".py"")<tab><tab><tab><tab>if matcher(path[baselen:]):<tab><tab><tab><tab><tab>results.append(path)<tab><tab>return<tab>if ""__init__.py"" not in files:<tab><tab>stderr(""%s is not a package"" % dir)<tab><tab>return<tab>for file in files:<tab><tab><IF-STMT><tab><tab><tab>path = os.path.join(dir, file)<tab><tab><tab>if matcher(path[baselen:]):<tab><tab><tab><tab>results.append(path)",0,"if file . startswith ( ""test"" ) and file . endswith ( "".py"" ) :",if os . path . isfile ( file ) :,0.019344345,4.222794014,0.290448343
"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab><IF-STMT><tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",1,elif self . approved_schedule :,elif self . approved_schedule :,0.75,100,1
"def create(self):<tab>if request.method == ""POST"":<tab><tab><IF-STMT><tab><tab><tab>Note.create(<tab><tab><tab><tab>user=auth.get_logged_in_user(),<tab><tab><tab><tab>message=request.form[""message""],<tab><tab><tab>)<tab>next = request.form.get(""next"") or self.dashboard_url()<tab>return redirect(next)",1,"if request . form . get ( ""message"" ) :","if request . form . get ( ""message"" ) :",0.75,100,1
"def get_current_migration():<tab>ver = 0<tab>while True:<tab><tab>next_ver = ver + 1<tab><tab>migration_func = globals().get(""migration_%d"" % next_ver)<tab><tab><IF-STMT><tab><tab><tab>return ver<tab><tab>ver = next_ver",0,if not migration_func :,if migration_func is not None :,0.167839241,24.44615112,0.333333333
"def resource_hdfs(uri, **kwargs):<tab>if ""hdfs://"" in uri:<tab><tab>uri = uri[len(""hdfs://"") :]<tab>d = re.match(hdfs_pattern, uri).groupdict()<tab>d = dict((k, v) for k, v in d.items() if v is not None)<tab>path = d.pop(""path"")<tab>kwargs.update(d)<tab>try:<tab><tab>subtype = types_by_extension[path.split(""."")[-1]]<tab><tab><IF-STMT><tab><tab><tab>subtype = Directory(subtype)<tab><tab><tab>path = path.rsplit(""/"", 1)[0] + ""/""<tab>except KeyError:<tab><tab>subtype = type(resource(path))<tab>return HDFS(subtype)(path, **kwargs)",0,"if ""*"" in path :","if ""/"" in path :",0.394778655,48.89230224,1
"def _s_wise_max(a_indices, a_indptr, vals, out_max):<tab>n = len(out_max)<tab>for i in range(n):<tab><tab>if a_indptr[i] != a_indptr[i + 1]:<tab><tab><tab>m = a_indptr[i]<tab><tab><tab>for j in range(a_indptr[i] + 1, a_indptr[i + 1]):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>m = j<tab><tab><tab>out_max[i] = vals[m]",1,if vals [ j ] > vals [ m ] :,if vals [ j ] > vals [ m ] :,1,100,1
"def stroke(s):<tab>keys = []<tab>on_left = True<tab>for k in s:<tab><tab>if k in ""EU*-"":<tab><tab><tab>on_left = False<tab><tab>if k == ""-"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>keys.append(k)<tab><tab>elif on_left:<tab><tab><tab>keys.append(k + ""-"")<tab><tab>else:<tab><tab><tab>keys.append(""-"" + k)<tab>return Stroke(keys)",0,"elif k == ""*"" :","elif k in ""EU*-"" :",0.062871671,14.92372948,0.7
def __check_finished(self):<tab>if self.global_finished:<tab><tab>return<tab>if not self.finished:<tab><tab><IF-STMT><tab><tab><tab>self.finished = True<tab><tab><tab>self.__send_finished()<tab><tab>else:<tab><tab><tab>val = self.__compare_working_vec_and_prev_rank()<tab><tab><tab>if val <= len(self.working_vec) * self.epsilon * 2:<tab><tab><tab><tab>self.finished = True<tab><tab><tab><tab>self.__send_finished(),0,if self . step >= self . max_steps :,if len ( self . working_vec ) == 0 :,0.092123953,8.130850858,0.333333333
"def test_interval_is_more_than_1(self, mock_save_check):<tab>state = {}<tab>check = Interval(""test_file"", period=4)<tab>for i in range(13):<tab><tab>check.on_checkpoint(state)<tab><tab>if i == 3:<tab><tab><tab>self.assertTrue(mock_save_check.call_count == 1)<tab><tab><IF-STMT><tab><tab><tab>self.assertFalse(mock_save_check.call_count == 2)<tab><tab>elif i == 7:<tab><tab><tab>self.assertTrue(mock_save_check.call_count == 2)<tab>self.assertTrue(mock_save_check.call_count == 3)",1,elif i == 6 :,elif i == 6 :,1,100,1
"def start(self, para=None, callback=None):<tab>if not self.load():<tab><tab>return<tab>if para != None or self.show():<tab><tab><IF-STMT><tab><tab><tab>para = self.para<tab><tab>win = WidgetsManager.getref(""Macros Recorder"")<tab><tab>if win != None:<tab><tab><tab>win.write(""{}>{}"".format(self.title, para))<tab><tab>if self.asyn and IPy.uimode() != ""no"":<tab><tab><tab>threading.Thread(target=self.runasyn, args=(para, callback)).start()<tab><tab>else:<tab><tab><tab>self.runasyn(para, callback)",0,if para == None :,if self . para != None :,0.055449142,23.35689889,0.371428571
"def find_test_functions(collections):<tab>if not isinstance(collections, list):<tab><tab>collections = [collections]<tab>functions = []<tab>for collection in collections:<tab><tab>if not isinstance(collection, dict):<tab><tab><tab>collection = vars(collection)<tab><tab>for key in sorted(collection):<tab><tab><tab>value = collection[key]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>functions.append(value)<tab>return functions",0,"if isinstance ( value , types . FunctionType ) and hasattr ( value , ""unittest"" ) :",if value is not None :,0.006584376,1.223737638,0.168831169
"def test_too_old(self):<tab>job = MRNullSpark([""-r"", ""emr"", ""--image-version"", ""3.7.0""])<tab>job.sandbox()<tab>with job.make_runner() as runner:<tab><tab>self.launch(runner)<tab><tab>message = runner._cluster_spark_support_warning()<tab><tab>self.assertIsNotNone(message)<tab><tab>self.assertIn(""support Spark"", message)<tab><tab>self.assertNotIn(""Python 3"", message)<tab><tab># should suggest an AMI that works with this version of Python<tab><tab><IF-STMT><tab><tab><tab>self.assertIn(""3.8.0"", message)<tab><tab>else:<tab><tab><tab>self.assertIn(""4.0.0"", message)",0,if PY2 :,"if ""3.8.0"" in message :",0.051944023,1.00E-10,0.36
"def RenderValue(self, value):<tab>if self.limit_lists == 0:<tab><tab>return ""<lists are omitted>""<tab>elif self.limit_lists == -1:<tab><tab>return [self._PassThrough(v) for v in value]<tab>else:<tab><tab>result = [self._PassThrough(v) for v in list(value)[: self.limit_lists]]<tab><tab><IF-STMT><tab><tab><tab>result.append(dict(type=FetchMoreLink.__name__, url=""to/be/implemented""))<tab>return result",0,if len ( value ) > self . limit_lists :,if self . limit_lists == 1 :,0.061846305,34.98330125,0.320512821
"def add_stack_attribute(self, memop_index):<tab>for op in self.operands:<tab><tab><IF-STMT><tab><tab><tab>self.add_attribute(""STACKPUSH%d"" % (memop_index))<tab><tab><tab>return<tab><tab>elif op.bits == ""XED_REG_STACKPOP"":<tab><tab><tab>self.add_attribute(""STACKPOP%d"" % (memop_index))<tab><tab><tab>return<tab>die(""Did not find stack push/pop operand"")",0,"if op . bits == ""XED_REG_STACKPUSH"" :","if op . bits == ""STACKPUSH"" :",0.574113272,52.66230698,1
"def apply_response(*args, **kwargs):<tab>if ""Authorization"" in request.headers.keys():<tab><tab>creds = str(<tab><tab><tab>b64decode(request.headers[""Authorization""].replace(""Basic "", """")), ""utf-8""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ""Authorized"", 200<tab>resp = Response(""Unauthorized"")<tab>resp.headers[""WWW-Authenticate""] = ""Basic ABC""<tab>return resp, 401",0,"if creds in [ ""root:pass"" , ""root:admin"" ] :","if creds in [ ""https"" , ""http"" , ""https"" ] :",0.166681405,35.23089032,1
"def find_privileged_containers(self):<tab>logger.debug(""Trying to find privileged containers and their pods"")<tab>privileged_containers = []<tab>if self.pods_endpoint_data:<tab><tab>for pod in self.pods_endpoint_data[""items""]:<tab><tab><tab>for container in pod[""spec""][""containers""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>privileged_containers.append(<tab><tab><tab><tab><tab><tab>(pod[""metadata""][""name""], container[""name""])<tab><tab><tab><tab><tab>)<tab>return privileged_containers if len(privileged_containers) > 0 else None",0,"if container . get ( ""securityContext"" , { } ) . get ( ""privileged"" ) :","if container [ ""name"" ] not in privileged_containers :",0.014858331,4.745534336,0.5
"def get_asset_gl_entry(self, gl_entries):<tab>for item in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>if is_cwip_accounting_enabled(item.asset_category):<tab><tab><tab><tab>self.add_asset_gl_entries(item, gl_entries)<tab><tab><tab>if flt(item.landed_cost_voucher_amount):<tab><tab><tab><tab>self.add_lcv_gl_entries(item, gl_entries)<tab><tab><tab><tab># update assets gross amount by its valuation rate<tab><tab><tab><tab># valuation rate is total of net rate, raw mat supp cost, tax amount, lcv amount per item<tab><tab><tab><tab>self.update_assets(item, item.valuation_rate)<tab>return gl_entries",0,if item . is_fixed_asset :,if item . asset_category :,0.394778655,21.84659982,1
"def test_pickling(self):<tab>for i in range(pickle.HIGHEST_PROTOCOL + 1):<tab><tab>p = pickle.dumps(self.s, i)<tab><tab>dup = pickle.loads(p)<tab><tab>self.assertEqual(self.s, dup, ""%s != %s"" % (self.s, dup))<tab><tab><IF-STMT><tab><tab><tab>self.s.x = 10<tab><tab><tab>p = pickle.dumps(self.s, i)<tab><tab><tab>dup = pickle.loads(p)<tab><tab><tab>self.assertEqual(self.s.x, dup.x)",0,"if type ( self . s ) not in ( set , frozenset ) :",if self . s . x == 10 :,0.079264195,10.76434543,0.165775401
"def f(p, args):<tab>try:<tab><tab>source, port = args<tab>except:<tab><tab>print(""argument error"")<tab><tab>return<tab>o = p.get_config(source)<tab>for p in o.resources.port:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>print(p.resource_id)<tab><tab>conf = p.configuration<tab><tab>for k in self._port_settings:<tab><tab><tab>try:<tab><tab><tab><tab>v = getattr(conf, k)<tab><tab><tab>except AttributeError:<tab><tab><tab><tab>continue<tab><tab><tab>print(""%s %s"" % (k, v))",1,if p . resource_id != port :,if p . resource_id != port :,0.75,100,1
"def replace(self, sub, repl):<tab>""""""Replaces any occurrences of ""sub"" with ""repl"" """"""<tab>new = []<tab>for item in self.data:<tab><tab><IF-STMT><tab><tab><tab>new.append(item.replace(sub, repl))<tab><tab>elif item == sub:<tab><tab><tab>new.append(repl)<tab><tab>else:<tab><tab><tab>new.append(item)<tab>return self.new(new)",0,"if isinstance ( item , metaPattern ) :","if isinstance ( item , dict ) :",0.549040681,59.46035575,0.666666667
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.add_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 18 :,if tt == 18 :,0.75,100,1
"def receive(debug=debug):<tab>if should_shutdown and should_shutdown():<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_OK)<tab>try:<tab><tab>ready, req = _receive(1.0)<tab><tab>if not ready:<tab><tab><tab>return None<tab>except (EOFError, IOError) as exc:<tab><tab><IF-STMT><tab><tab><tab>return None  # interrupted, maybe by gdb<tab><tab>debug(""worker got %s -- exiting"", type(exc).__name__)<tab><tab>raise SystemExit(EX_FAILURE)<tab>if req is None:<tab><tab>debug(""worker got sentinel -- exiting"")<tab><tab>raise SystemExit(EX_FAILURE)<tab>return req",0,if get_errno ( exc ) == errno . EINTR :,if exc . errno == errno . EINTR :,0.268560829,42.38405078,0.715151515
"def _trim_files_in_dir(dir, patterns, log=None):<tab>if log:<tab><tab>log(""trim '%s' files under '%s'"", ""', '"".join(patterns), dir)<tab>from fnmatch import fnmatch<tab>for dirpath, dirnames, filenames in os.walk(dir):<tab><tab>for d in dirnames[:]:<tab><tab><tab>for pat in patterns:<tab><tab><tab><tab>if fnmatch(d, pat):<tab><tab><tab><tab><tab>_rmtree(join(dirpath, d))<tab><tab><tab><tab><tab>dirnames.remove(d)<tab><tab><tab><tab><tab>break<tab><tab>for f in filenames[:]:<tab><tab><tab>for pat in patterns:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>os.remove(join(dirpath, f))<tab><tab><tab><tab><tab>break",1,"if fnmatch ( f , pat ) :","if fnmatch ( f , pat ) :",0.75,100,1
"def refactor_stdin(self, doctests_only=False):<tab>input = sys.stdin.read()<tab>if doctests_only:<tab><tab>self.log_debug(""Refactoring doctests in stdin"")<tab><tab>output = self.refactor_docstring(input, ""<stdin>"")<tab><tab>if self.write_unchanged_files or output != input:<tab><tab><tab>self.processed_file(output, ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No doctest changes in stdin"")<tab>else:<tab><tab>tree = self.refactor_string(input, ""<stdin>"")<tab><tab><IF-STMT><tab><tab><tab>self.processed_file(str(tree), ""<stdin>"", input)<tab><tab>else:<tab><tab><tab>self.log_debug(""No changes in stdin"")",0,if self . write_unchanged_files or ( tree and tree . was_changed ) :,if self . write_unchanged_files or tree != input :,0.201823767,43.81940626,0.657142857
"def test_get_e_above_hull(self):<tab>for entry in self.pd.stable_entries:<tab><tab>self.assertLess(<tab><tab><tab>self.pd.get_e_above_hull(entry),<tab><tab><tab>1e-11,<tab><tab><tab>""Stable entries should have e above hull of zero!"",<tab><tab>)<tab>for entry in self.pd.all_entries:<tab><tab><IF-STMT><tab><tab><tab>e_ah = self.pd.get_e_above_hull(entry)<tab><tab><tab>self.assertTrue(isinstance(e_ah, Number))<tab><tab><tab>self.assertGreaterEqual(e_ah, 0)",0,if entry not in self . pd . stable_entries :,if entry :,0.020477126,1.00E-10,0.380952381
"def setup(self, name):<tab>value = self.default<tab>if self.environ:<tab><tab>full_environ_name = self.full_environ_name(name)<tab><tab>if full_environ_name in os.environ:<tab><tab><tab>value = self.to_python(os.environ[full_environ_name])<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Value {0!r} is required to be set as the ""<tab><tab><tab><tab>""environment variable {1!r}"".format(name, full_environ_name)<tab><tab><tab>)<tab>self.value = value<tab>return value",0,elif self . environ_required :,elif not value :,0.034576067,8.973024087,0.36
"def process_transactions(l1_block: ""l1_block_model.L1BlockModel"") -> Dict[str, bool]:<tab>txn_map: Dict[str, bool] = {}<tab>try:<tab><tab>verify_keys = get_verifying_keys(l1_block.dc_id)<tab><tab><IF-STMT><tab><tab><tab>verify_transactions(l1_block, verify_keys, txn_map)<tab><tab>else:<tab><tab><tab>mark_invalid(l1_block, txn_map)<tab>except Exception:<tab><tab>mark_invalid(l1_block, txn_map)<tab>return txn_map",0,"if verify_block ( l1_block , verify_keys ) :",if verify_keys :,0.01726708,1.00E-10,1
"def get_values(self):<tab>if self.cache:<tab><tab># use these values as a key to cache the result so if we have<tab><tab># the same filter happening across many resources, we can reuse<tab><tab># the results.<tab><tab>key = [self.data.get(i) for i in (""url"", ""format"", ""expr"")]<tab><tab>contents = self.cache.get((""value-from"", key))<tab><tab><IF-STMT><tab><tab><tab>return contents<tab>contents = self._get_values()<tab>if self.cache:<tab><tab>self.cache.save((""value-from"", key), contents)<tab>return contents",0,if contents is not None :,if contents :,0.050438393,1.00E-10,0.4
"def _run_scalar_data(run):<tab>data = {}<tab>step = None<tab>last_step = None<tab>for s in indexlib.iter_run_scalars(run):<tab><tab>key = s[""tag""]<tab><tab>data[key] = s[""last_val""]<tab><tab>last_step = s[""last_step""]<tab><tab><IF-STMT><tab><tab><tab>step = last_step<tab>if data:<tab><tab>if step is None:<tab><tab><tab>step = last_step<tab><tab>data[""step""] = step<tab>return data",0,"if key == ""loss"" :",if step is None :,0.034123066,6.971729122,0.25
"def getRemovedFiles(oldContents, newContents, destinationFolder):<tab>toRemove = []<tab>for filename in list(oldContents.keys()):<tab><tab><IF-STMT><tab><tab><tab>destFile = os.path.join(destinationFolder, filename.lstrip(""/""))<tab><tab><tab>if os.path.isfile(destFile):<tab><tab><tab><tab>toRemove.append(filename)<tab>return toRemove",0,if filename not in newContents :,if filename in newContents :,0.233190283,40.93653765,0.444444444
"def sort_classes(classes: List[Tuple[str, ClassIR]]) -> List[Tuple[str, ClassIR]]:<tab>mod_name = {ir: name for name, ir in classes}<tab>irs = [ir for _, ir in classes]<tab>deps = OrderedDict()  # type: Dict[ClassIR, Set[ClassIR]]<tab>for ir in irs:<tab><tab><IF-STMT><tab><tab><tab>deps[ir] = set()<tab><tab>if ir.base:<tab><tab><tab>deps[ir].add(ir.base)<tab><tab>deps[ir].update(ir.traits)<tab>sorted_irs = toposort(deps)<tab>return [(mod_name[ir], ir) for ir in sorted_irs]",1,if ir not in deps :,if ir not in deps :,0.75,100,1
"def get_sources(urls, trusted_hosts):<tab>trusted_hosts = [<tab><tab>six.moves.urllib.parse.urlparse(url).netloc for url in trusted_hosts<tab>]<tab>sources = []<tab>for url in urls:<tab><tab>parsed_url = six.moves.urllib.parse.urlparse(url)<tab><tab>netloc = parsed_url.netloc<tab><tab>if ""@"" in netloc:<tab><tab><tab>_, _, netloc = netloc.rpartition(""@"")<tab><tab>name, _, _ = netloc.partition(<tab><tab><tab>"".""<tab><tab>)  # Just use the domain name as the source name<tab><tab>verify_ssl = True<tab><tab><IF-STMT><tab><tab><tab>verify_ssl = False<tab><tab>sources.append({""url"": url, ""name"": name, ""verify_ssl"": verify_ssl})<tab>return sources",0,if netloc in trusted_hosts :,elif parsed_url . netloc == netloc :,0.023610995,5.522397784,0.333333333
"def _insert_to_nonfull_node(self, node: Node, key):<tab>i = len(node.keys) - 1<tab>while i >= 0 and node.keys[i] >= key:  # find position where insert key<tab><tab>i -= 1<tab>if node.is_leaf:<tab><tab>node.keys.insert(i + 1, key)<tab>else:<tab><tab>if len(node.children[i + 1].keys) >= self.max_number_of_keys:  # overflow<tab><tab><tab>self._split_child(node, i + 1)<tab><tab><tab><IF-STMT>  # decide which child is going to have a new key<tab><tab><tab><tab>i += 1<tab><tab>self._insert_to_nonfull_node(node.children[i + 1], key)",0,if node . keys [ i + 1 ] < key :,elif node . children [ i + 1 ] . keys [ i ] == key :,0.226336897,35.75297164,0.396296296
"def _variable_state(self, char, index):<tab>self._variable_chars.append(char)<tab>if char == ""}"" and not self._is_escaped(self._string, index):<tab><tab>self._open_curly -= 1<tab><tab>if self._open_curly == 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>self._state = self._waiting_item_state<tab>elif char in self._identifiers:<tab><tab>self._state = self._internal_variable_start_state",0,if not self . _can_have_item ( ) :,if self . _open_curly == 0 :,0.036768523,13.83228359,0.4
def __next__(self):<tab>if self.index > 0:<tab><tab><IF-STMT><tab><tab><tab>raise StopIteration<tab><tab>if len(self.saved) > self.index:<tab><tab><tab>obj = self.saved[self.index]<tab><tab><tab>self.index += 1<tab><tab>else:<tab><tab><tab>obj = self.saved[0]<tab><tab><tab>self.index = 1<tab>else:<tab><tab>try:<tab><tab><tab>obj = next(self.iterable)<tab><tab>except StopIteration:<tab><tab><tab>if not self.saved:<tab><tab><tab><tab>raise<tab><tab><tab>obj = self.saved[0]<tab><tab><tab>self.index = 1<tab><tab>else:<tab><tab><tab>self.saved.append(obj)<tab>return obj,1,if not self . saved :,if not self . saved :,0.75,100,1
"def get_host_info(self, host):<tab>""""""Return hostvars for a single host""""""<tab>if host in self.inventory[""_meta""][""hostvars""]:<tab><tab>return self.inventory[""_meta""][""hostvars""][host]<tab>elif self.args.host and self.inventory[""_meta""][""hostvars""]:<tab><tab>match = None<tab><tab>for k, v in self.inventory[""_meta""][""hostvars""].items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>match = k<tab><tab><tab><tab>break<tab><tab>if match:<tab><tab><tab>return self.inventory[""_meta""][""hostvars""][match]<tab><tab>else:<tab><tab><tab>raise VMwareMissingHostException(""%s not found"" % host)<tab>else:<tab><tab>raise VMwareMissingHostException(""%s not found"" % host)",0,"if self . inventory [ ""_meta"" ] [ ""hostvars"" ] [ k ] [ ""name"" ] == self . args . host :",if v == host :,0.006872127,0.376349668,0.236111111
def readline(self):<tab>if self.peek is not None:<tab><tab>line = self.peek<tab><tab>self.peek = None<tab>else:<tab><tab>line = self.file.readline()<tab>if not line:<tab><tab>return line<tab>if he.match(line):<tab><tab>return line<tab>while 1:<tab><tab>self.peek = self.file.readline()<tab><tab><IF-STMT><tab><tab><tab>return line<tab><tab>line = line + self.peek<tab><tab>self.peek = None,0,"if len ( self . peek ) == 0 or ( self . peek [ 0 ] != "" "" and self . peek [ 0 ] != ""\t"" ) :",if not self . peek :,0.010419361,0.195799714,0.311111111
"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab>if i == 254:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab>elif i == 255:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab>elif i == 65534:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",0,elif i == 1000 :,elif i == 3228 :,0.642872021,53.72849659,0.6
"def __new__(cls, a=1, b=0.5):  # Singleton:<tab>if cls._instances:<tab><tab>cls._instances[:] = [instance for instance in cls._instances if instance()]<tab><tab>for instance in cls._instances:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return instance()<tab>o = super(Prior, cls).__new__(cls, a, b)<tab>cls._instances.append(weakref.ref(o))<tab>return cls._instances[-1]()",1,if instance ( ) . a == a and instance ( ) . b == b :,if instance ( ) . a == a and instance ( ) . b == b :,1,100,1
"def forward(self, x):<tab>if self.is_nan:<tab><tab><IF-STMT><tab><tab><tab>return torch.isnan(x).float()<tab><tab>else:<tab><tab><tab>return torch.isnan(torch.index_select(x, 1, self.column_indices)).float()<tab>else:<tab><tab>if self.features == ""all"":<tab><tab><tab>return torch.eq(x, self.missing_values).float()<tab><tab>else:<tab><tab><tab>return torch.eq(<tab><tab><tab><tab>torch.index_select(x, 1, self.column_indices), self.missing_values<tab><tab><tab>).float()",1,"if self . features == ""all"" :","if self . features == ""all"" :",0.75,100,1
"def __mro_entries__(self, bases):<tab>if self._name:  # generic version of an ABC or built-in class<tab><tab>return super().__mro_entries__(bases)<tab>if self.__origin__ is Generic:<tab><tab>if Protocol in bases:<tab><tab><tab>return ()<tab><tab>i = bases.index(self)<tab><tab>for b in bases[i + 1 :]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ()<tab>return (self.__origin__,)",0,"if isinstance ( b , _BaseGenericAlias ) and b is not self :",if b . _name == self . _name :,0.011544942,4.286580498,0.208333333
"def _set_frequency(self, value):<tab>if not self._pwm and value is not None:<tab><tab>self._connection.set_PWM_frequency(self._number, value)<tab><tab>self._connection.set_PWM_range(self._number, 10000)<tab><tab>self._connection.set_PWM_dutycycle(self._number, 0)<tab><tab>self._pwm = True<tab>elif self._pwm and value is not None:<tab><tab><IF-STMT><tab><tab><tab>self._connection.set_PWM_frequency(self._number, value)<tab><tab><tab>self._connection.set_PWM_range(self._number, 10000)<tab>elif self._pwm and value is None:<tab><tab>self._connection.write(self._number, 0)<tab><tab>self._pwm = False",0,if value != self . _connection . get_PWM_frequency ( self . _number ) :,if self . _pwm :,0.015612969,2.817933053,0.477272727
"def literal(self):<tab>if self.peek('""'):<tab><tab>lit, lang, dtype = self.eat(r_literal).groups()<tab><tab><IF-STMT><tab><tab><tab>lang = lang<tab><tab>else:<tab><tab><tab>lang = None<tab><tab>if dtype:<tab><tab><tab>dtype = dtype<tab><tab>else:<tab><tab><tab>dtype = None<tab><tab>if lang and dtype:<tab><tab><tab>raise ParseError(""Can't have both a language and a datatype"")<tab><tab>lit = unquote(lit)<tab><tab>return Literal(lit, lang, dtype)<tab>return False",1,if lang :,if lang :,0.531170663,1.00E-10,1
"def _staged_model_references(self, load_relationships=False):<tab>for name, field in self._fields.items():<tab><tab>if isinstance(field, BaseRelationship):<tab><tab><tab>try:<tab><tab><tab><tab>if load_relationships:<tab><tab><tab><tab><tab>value = getattr(self, name)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>value = self.data_store.get(name, (""staged"", ""committed""))<tab><tab><tab>except (AttributeError, KeyError, PathResolutionError):<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if not isinstance(value, ModelCollection):<tab><tab><tab><tab>value = [value]<tab><tab><tab>for related in value:<tab><tab><tab><tab>related_name = field.related_name<tab><tab><tab><tab>yield related, related_name",0,if value is None :,if not value :,0.039449619,16.37226967,0.277777778
"def __call__(self, target):<tab># normal running mode<tab>if not self.check_run_always:<tab><tab>for algo in self.algos:<tab><tab><tab>if not algo(target):<tab><tab><tab><tab>return False<tab><tab>return True<tab># run mode when at least one algo has a run_always attribute<tab>else:<tab><tab># store result in res<tab><tab># allows continuation to check for and run<tab><tab># algos that have run_always set to True<tab><tab>res = True<tab><tab>for algo in self.algos:<tab><tab><tab>if res:<tab><tab><tab><tab>res = algo(target)<tab><tab><tab>elif hasattr(algo, ""run_always""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>algo(target)<tab><tab>return res",1,if algo . run_always :,if algo . run_always :,0.75,100,1
"def addRow(self, row):<tab>r = []<tab>for j in range(self.numColumn):<tab><tab>w, s = calWidth(row[j], self.maxWidth)<tab><tab><IF-STMT><tab><tab><tab>self.W[j] = w<tab><tab>r.append((w, s))<tab>self.M.append(r)",0,if w > self . W [ j ] :,if w != s :,0.025595153,9.223644101,0.416666667
"def parse(s):<tab>text, anns = """", []<tab># tweak text: remove space around annotations and strip space<tab>s = re.sub(r""(<category[^<>]*>)( +)"", r""\2\1"", s)<tab>s = re.sub(r""( +)(<\/category>)"", r""\2\1"", s)<tab>rest = s.strip()<tab>while True:<tab><tab>m = re.match(r'^(.*?)<category=""([^""]+)"">(.*?)</category>(.*)$', rest)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>pre, type_, tagged, rest = m.groups()<tab><tab>text += pre<tab><tab>anns.append((len(text), len(text) + len(tagged), type_, tagged))<tab><tab>text += tagged<tab>text += rest<tab>return text, anns",1,if not m :,if not m :,0.75,100,1
"def _generate_examples(self, filepath):<tab>with open(filepath) as f:<tab><tab>line_num = -1<tab><tab>while True:<tab><tab><tab>line_num += 1<tab><tab><tab>sentence = f.readline().strip()<tab><tab><tab>pronoun = f.readline().strip()<tab><tab><tab>candidates = [c.strip() for c in f.readline().strip().split("","")]<tab><tab><tab>correct = f.readline().strip()<tab><tab><tab>f.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield line_num, {<tab><tab><tab><tab>""sentence"": sentence,<tab><tab><tab><tab>""pronoun"": pronoun,<tab><tab><tab><tab>""candidates"": candidates,<tab><tab><tab><tab>""label"": candidates.index(correct),<tab><tab><tab>}",0,if not sentence :,"if correct == """" :",0.042407859,7.809849842,0.36
"def format_unencoded(self, tokensource, outfile):<tab><IF-STMT><tab><tab>self._write_lineno(outfile)<tab>for ttype, value in tokensource:<tab><tab>color = self._get_color(ttype)<tab><tab>for line in value.splitlines(True):<tab><tab><tab>if color:<tab><tab><tab><tab>outfile.write(""<%s>%s</>"" % (color, line.rstrip(""\n"")))<tab><tab><tab>else:<tab><tab><tab><tab>outfile.write(line.rstrip(""\n""))<tab><tab><tab>if line.endswith(""\n""):<tab><tab><tab><tab>if self.linenos:<tab><tab><tab><tab><tab>self._write_lineno(outfile)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>outfile.write(""\n"")<tab>if self.linenos:<tab><tab>outfile.write(""\n"")",1,if self . linenos :,if self . linenos :,0.75,100,1
"def refresh_pool_in_list(pool_list, conn, uuid):<tab>for row in pool_list.get_model():<tab><tab><IF-STMT><tab><tab><tab># Update active sensitivity and percent available for passed uuid<tab><tab><tab>row[3] = get_pool_size_percent(conn, uuid)<tab><tab><tab>row[2] = conn.get_pool(uuid).is_active()<tab><tab><tab>return",0,if row [ 0 ] == uuid :,"if row [ 0 ] == ""pool"" :",0.418121306,59.00468726,0.777777778
"def save_claims_for_resolve(self, claim_infos):<tab>to_save = {}<tab>for info in claim_infos:<tab><tab><IF-STMT><tab><tab><tab>if info[""value""]:<tab><tab><tab><tab>to_save[info[""claim_id""]] = info<tab><tab>else:<tab><tab><tab>for key in (""certificate"", ""claim""):<tab><tab><tab><tab>if info.get(key, {}).get(""value""):<tab><tab><tab><tab><tab>to_save[info[key][""claim_id""]] = info[key]<tab>return self.save_claims(to_save.values())",0,"if ""value"" in info :","if isinstance ( info , dict ) :",0.02800146,7.267884212,0.481481481
"def rx(self, text):<tab>r = []<tab>for c in text:<tab><tab><IF-STMT><tab><tab><tab>r.append(c)<tab><tab>elif c < "" "":<tab><tab><tab>r.append(unichr(0x2400 + ord(c)))<tab><tab>else:<tab><tab><tab>r.extend(unichr(0x2080 + ord(d) - 48) for d in ""{:d}"".format(ord(c)))<tab><tab><tab>r.append("" "")<tab>return """".join(r)",0,"if "" "" <= c < ""\x7f"" or c in ""\r\n\b\t"" :",if ord ( c ) < 48 :,0.012620947,0.932753548,0.276190476
"def consume_bytes(data):<tab>state_machine.receive_data(data)<tab>while True:<tab><tab>event = state_machine.next_event()<tab><tab>if event is h11.NEED_DATA:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># Ignore 1xx responses<tab><tab><tab>continue<tab><tab>elif isinstance(event, h11.Response):<tab><tab><tab># We have our response! Save it and get out of here.<tab><tab><tab>context[""h11_response""] = event<tab><tab><tab>raise LoopAbort<tab><tab>else:<tab><tab><tab># Can't happen<tab><tab><tab>raise RuntimeError(""Unexpected h11 event {}"".format(event))",0,"elif isinstance ( event , h11 . InformationalResponse ) :","elif isinstance ( event , h11 . START_EVENT ) :",0.603553391,57.06745777,0.818181818
"def validate_text(dialect, attr):<tab>val = getattr(dialect, attr)<tab>if not isinstance(val, text_type):<tab><tab><IF-STMT><tab><tab><tab>raise Error('""{0}"" must be string, not bytes'.format(attr))<tab><tab>raise Error('""{0}"" must be string, not {1}'.format(attr, type(val).__name__))<tab>if len(val) != 1:<tab><tab>raise Error('""{0}"" must be a 1-character string'.format(attr))",0,if type ( val ) == bytes :,"if isinstance ( val , bytes ) :",0.039168582,12.82777061,0.666666667
"def _refresh(self):<tab>self.uiProfileSelectComboBox.clear()<tab>self.uiProfileSelectComboBox.addItem(""default"")<tab>try:<tab><tab>if os.path.exists(self.profiles_path):<tab><tab><tab>for profile in sorted(os.listdir(self.profiles_path)):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.uiProfileSelectComboBox.addItem(profile)<tab>except OSError:<tab><tab>pass",0,"if not profile . startswith ( ""."" ) :","if profile . endswith ( "".py"" ) :",0.040847398,27.45502434,0.318181818
"def get_entry(self, ip):<tab>self.parse()<tab>options = []<tab>for (line_type, components) in self._contents:<tab><tab>if line_type == ""option"":<tab><tab><tab>(pieces, _tail) = components<tab><tab><tab><IF-STMT><tab><tab><tab><tab>options.append(pieces[1:])<tab>return options",0,if len ( pieces ) and pieces [ 0 ] == ip :,if len ( pieces ) > 1 and pieces [ 0 ] == ip :,0.643843457,74.4781979,0.429166667
"def __new__(mcls, cls_name, bases, d):<tab>offset = 0<tab>for base in bases:<tab><tab>for realbase in base.__mro__:<tab><tab><tab>offset += len(realbase.__dict__.get(""_methods_"", []))<tab>for i, args in enumerate(d.get(""_methods_"", [])):<tab><tab>name = args[0]<tab><tab>restype = args[1]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>argtypes = args[2:]<tab><tab>m = COMMethod(name, offset + i, restype, argtypes)<tab><tab>d[name] = m<tab>return type(ctypes.c_void_p).__new__(mcls, cls_name, bases, dict(d))",1,if restype is None :,if restype is None :,0.75,100,1
"def _compare_caffe_tvm(caffe_out, tvm_out, is_network=False):<tab>for i in range(len(caffe_out)):<tab><tab><IF-STMT><tab><tab><tab>caffe_out[i] = caffe_out[i][:1]<tab><tab>tvm.testing.assert_allclose(caffe_out[i], tvm_out[i], rtol=1e-5, atol=1e-5)",0,if is_network :,if caffe_out [ i ] [ 0 ] == caffe_out [ i ] [ 0 ] :,0.039390243,1.00E-10,0.464285714
"def update_transcoder(self):<tab>self.save_button.set_visible(False)<tab>if self.cast and self.fn:<tab><tab>self.transcoder = Transcoder(<tab><tab><tab>self.cast,<tab><tab><tab>self.fn,<tab><tab><tab>lambda did_transcode=None: GLib.idle_add(self.update_status, did_transcode),<tab><tab><tab>self.transcoder,<tab><tab>)<tab><tab>if self.autoplay:<tab><tab><tab>self.autoplay = False<tab><tab><tab>self.play_clicked(None)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.transcoder.destroy()<tab><tab><tab>self.transcoder = None<tab>GLib.idle_add(self.update_media_button_states)",1,if self . transcoder :,if self . transcoder :,0.75,100,1
"def deserialize(x):<tab>t = type(x)<tab>if t is list:<tab><tab>return list(imap(deserialize, x))<tab>if t is dict:<tab><tab>if ""_id_"" not in x:<tab><tab><tab>return {key: deserialize(val) for key, val in iteritems(x)}<tab><tab>obj = objmap.get(x[""_id_""])<tab><tab><IF-STMT><tab><tab><tab>entity_name = x[""class""]<tab><tab><tab>entity = database.entities[entity_name]<tab><tab><tab>pk = x[""_pk_""]<tab><tab><tab>obj = entity[pk]<tab><tab>return obj<tab>return x",1,if obj is None :,if obj is None :,0.75,100,1
"def release(self, conn, error=False):<tab>if not conn.is_closed:<tab><tab><IF-STMT><tab><tab><tab>self.connections.append(conn)<tab><tab>else:<tab><tab><tab>self.close_callable(conn)",0,if not error and len ( self . connections ) < self . pool_size :,if error :,0.005751264,1.00E-10,0.2125
"def install_symlinks(self):<tab>""""""Create symlinks for some applications files.""""""<tab>if self.has_symlinks():<tab><tab>for app_path in self.app_path:<tab><tab><tab>for symlink in self.symlinks.values():<tab><tab><tab><tab>root = symlink[""root""]<tab><tab><tab><tab>dest = path.join(str(app_path), symlink[""dest""])<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.backup.create(dest)<tab><tab><tab><tab><tab>symlink_file(root, dest)",1,if path . exists ( dest ) :,if path . exists ( dest ) :,0.75,100,1
def _fill_array():<tab>global _array<tab>for i in range(624):<tab><tab>y = (_array[i] & _bitmask2) + (_array[(i + 1) % 624] & _bitmask3)<tab><tab>_array[i] = _array[(i + 397) % 624] ^ (y >> 1)<tab><tab><IF-STMT><tab><tab><tab>_array[i] ^= 2567483615,0,if y % 2 != 0 :,if _array [ i ] & _bitmask1 :,0.019801327,4.990049702,0.3
"def parseLeftHandSideExpressionAllowCall():<tab>marker = None<tab>expr = None<tab>args = None<tab>property = None<tab>marker = createLocationMarker()<tab>expr = parseNewExpression() if matchKeyword(""new"") else parsePrimaryExpression()<tab>while (match(""."") or match(""["")) or match(""(""):<tab><tab>if match(""(""):<tab><tab><tab>args = parseArguments()<tab><tab><tab>expr = delegate.createCallExpression(expr, args)<tab><tab>elif match(""[""):<tab><tab><tab>property = parseComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""["", expr, property)<tab><tab>else:<tab><tab><tab>property = parseNonComputedMember()<tab><tab><tab>expr = delegate.createMemberExpression(""."", expr, property)<tab><tab><IF-STMT><tab><tab><tab>marker.end()<tab><tab><tab>marker.apply(expr)<tab>return expr",1,if marker :,if marker :,0.531170663,1.00E-10,1
"def unregister_zombies(self):<tab>""""""Unregister zombie builds (those whose builddir is gone).""""""<tab>from pprint import pprint<tab>pprint(self.configs)<tab>for build_num, config in self.configs.items():<tab><tab>obj_dir_path = join(<tab><tab><tab>config.buildDir,<tab><tab><tab>_srcTreeName_from_config(config),<tab><tab><tab>""mozilla"",<tab><tab><tab>config.mozObjDir,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.unregister(build_num, ""zombie (`%s' does not exist)"" % obj_dir_path)",0,if not exists ( obj_dir_path ) :,if not os . path . exists ( obj_dir_path ) :,0.360991995,59.68774176,0.476190476
"def isUpdateAvailable(self, localOnly=False):<tab>nsp = self.getLatestFile()<tab>if not nsp:<tab><tab>if not nsp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>try:<tab><tab>latest = self.lastestVersion(localOnly=localOnly)<tab><tab>if latest is None:<tab><tab><tab>return False<tab><tab>if int(nsp.version) < int(latest):<tab><tab><tab>return True<tab>except BaseException as e:<tab><tab>Print.error(""isUpdateAvailable exception %s: %s"" % (self.id, str(e)))<tab><tab>pass<tab>return False",0,if not self . isUpdate or ( self . version and int ( self . version ) > 0 ) :,if localOnly :,0.022611466,1.00E-10,0.149350649
"def verify_settings(rst_path: Path) -> Iterator[Error]:<tab>for setting_name, default in find_settings_in_rst(rst_path):<tab><tab>actual = getattr(app.conf, setting_name)<tab><tab><IF-STMT><tab><tab><tab>default = default.total_seconds()<tab><tab>if isinstance(actual, Enum):<tab><tab><tab>actual = actual.value<tab><tab>if actual != default:<tab><tab><tab>yield Error(<tab><tab><tab><tab>reason=""mismatch"",<tab><tab><tab><tab>setting=setting_name,<tab><tab><tab><tab>default=default,<tab><tab><tab><tab>actual=actual,<tab><tab><tab>)",0,"if isinstance ( default , timedelta ) :","if isinstance ( default , datetime . datetime ) :",0.264187342,45.18010018,0.651515152
"def config_update(self, *updates):<tab>filename = os.path.join(self.path, "".git"", ""config"")<tab>with GitConfigParser(file_or_files=filename, read_only=False) as config:<tab><tab>for section, key, value in updates:<tab><tab><tab>try:<tab><tab><tab><tab>old = config.get(section, key)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>config.remove_option(section, key)<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if old == value:<tab><tab><tab><tab><tab>continue<tab><tab><tab>except (NoSectionError, NoOptionError):<tab><tab><tab><tab>pass<tab><tab><tab>if value is not None:<tab><tab><tab><tab>config.set_value(section, key, value)",0,if value is None :,if old is None :,0.394778655,42.72870064,0.666666667
"def __init__(self, search_space):<tab>self.params = {}<tab>for key in search_space.keys():<tab><tab><IF-STMT><tab><tab><tab>self.params[key] = Factor(search_space[key][""_value""])<tab><tab>else:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""G_BFS Tuner doesn't support this kind of parameter: ""<tab><tab><tab><tab>+ str(search_space[key][""_type""])<tab><tab><tab>)",1,"if search_space [ key ] [ ""_type"" ] == ""factor"" :","if search_space [ key ] [ ""_type"" ] == ""factor"" :",0.75,100,1
"def largest_image_url(self):<tab># TODO: remove. it is not responsibility of Scrapper<tab>if not self.imgs and not self.top_img:<tab><tab>return None<tab>if self.top_img:<tab><tab>return self.top_img<tab>max_area = 0<tab>max_url = None<tab>for img_url in self.imgs:<tab><tab>dimension = fetch_image_dimension(img_url, self.useragent, referer=self.url)<tab><tab>area = self.calculate_area(img_url, dimension)<tab><tab><IF-STMT><tab><tab><tab>max_area = area<tab><tab><tab>max_url = img_url<tab>log.debug(""using max img {}"".format(max_url))<tab>return max_url",1,if area > max_area :,if area > max_area :,0.75,100,1
"def _geo_indices(cls, inspected=None):<tab>inspected = inspected or []<tab>geo_indices = []<tab>inspected.append(cls)<tab>for field in cls._fields.values():<tab><tab>if hasattr(field, ""document_type""):<tab><tab><tab>field_cls = field.document_type<tab><tab><tab>if field_cls in inspected:<tab><tab><tab><tab>continue<tab><tab><tab>if hasattr(field_cls, ""_geo_indices""):<tab><tab><tab><tab>geo_indices += field_cls._geo_indices(inspected)<tab><tab><IF-STMT><tab><tab><tab>geo_indices.append(field)<tab>return geo_indices",0,elif field . _geo_index :,"elif field . __class__ . __name__ == ""GeoIndex"" :",0.103319589,13.26475917,1
"def __call__(self, trainer):<tab>self._t += 1<tab>optimizer = self._get_optimizer(trainer)<tab>value = self._init * (self._rate ** self._t)<tab>if self._target is not None:<tab><tab><IF-STMT><tab><tab><tab># almost same as value = min(value, self._target), but this<tab><tab><tab># line supports negative values, too<tab><tab><tab>if value / self._target > 1:<tab><tab><tab><tab>value = self._target<tab><tab>else:<tab><tab><tab># ditto<tab><tab><tab>if value / self._target < 1:<tab><tab><tab><tab>value = self._target<tab>self._update_value(optimizer, value)",0,if self . _rate > 1 :,"if isinstance ( self . _target , int ) :",0.097827427,15.85116569,0.320512821
"def _parse_chunked(self, data):<tab>body = []<tab>trailers = {}<tab>n = 0<tab>lines = data.split(b""\r\n"")<tab># parse body<tab>while True:<tab><tab>size, chunk = lines[n : n + 2]<tab><tab>size = int(size, 16)<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab><tab>break<tab><tab>self.assertEqual(size, len(chunk))<tab><tab>body.append(chunk)<tab><tab>n += 2<tab><tab># we /should/ hit the end chunk, but check against the size of<tab><tab># lines so we're not stuck in an infinite loop should we get<tab><tab># malformed data<tab><tab>if n > len(lines):<tab><tab><tab>break<tab>return b"""".join(body)",0,if size == 0 :,if size < 0 or size > len ( lines ) :,0.128723978,8.054496385,0.482993197
"def _gen_opnds(ii):  # generator<tab># filter out write-mask operands and suppressed operands<tab>for op in ii.parsed_operands:<tab><tab>if op.lookupfn_name in [""MASK1"", ""MASKNOT0""]:<tab><tab><tab>continue<tab><tab>if op.visibility == ""SUPPRESSED"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield op",0,"if op . name == ""BCAST"" :","if op . lookupfn_name in [ ""MASK1"" , ""MASKNOT0"" ] :",0.071710195,10.52149517,0.6
"def allow_request(self, request, view):<tab>if settings.API_THROTTLING:<tab><tab>request_allowed = super(GranularUserRateThrottle, self).allow_request(<tab><tab><tab>request, view<tab><tab>)<tab><tab>if not request_allowed:<tab><tab><tab>user = getattr(request, ""user"", None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.info(""User %s throttled for scope %s"", request.user, self.scope)<tab><tab><tab><tab>ActivityLog.create(amo.LOG.THROTTLED, self.scope, user=user)<tab><tab>return request_allowed<tab>else:<tab><tab>return True",0,if user and request . user . is_authenticated :,if user is not None :,0.13744821,8.389861811,0.333333333
"def _make_callback(self):<tab>callback = self.callback<tab>for plugin in self.all_plugins():<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>callback = plugin.apply(callback, self)<tab><tab><tab>else:<tab><tab><tab><tab>callback = plugin(callback)<tab><tab>except RouteReset:  # Try again with changed configuration.<tab><tab><tab>return self._make_callback()<tab><tab>if not callback is self.callback:<tab><tab><tab>update_wrapper(callback, self.callback)<tab>return callback",0,"if hasattr ( plugin , ""apply"" ) :",if callable ( plugin ) :,0.046109016,12.46298934,0.6
"def OnDeleteLine(self, items):<tab>for n in items:<tab><tab>if n >= 0:<tab><tab><tab>name1 = self.items[n][2]<tab><tab><tab>name2 = self.items[n][4]<tab><tab><tab>del self.items[n]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.bindiff.matched1.remove(name1)<tab><tab><tab>if name2 in self.bindiff.matched2:<tab><tab><tab><tab>self.bindiff.matched2.remove(name2)<tab>return [Choose.ALL_CHANGED] + items",1,if name1 in self . bindiff . matched1 :,if name1 in self . bindiff . matched1 :,0.75,100,1
"def on_treeview_buttonrelease(self, widget, event, data=None):<tab>if self.promptToSave():<tab><tab># True result indicates user selected Cancel. Stop event propagation<tab><tab>return True<tab>else:<tab><tab>x = int(event.x)<tab><tab>y = int(event.y)<tab><tab>time = event.time<tab><tab>pthinfo = widget.get_path_at_pos(x, y)<tab><tab>if pthinfo is not None:<tab><tab><tab>path, col, cellx, celly = pthinfo<tab><tab><tab>currentPath, currentCol = widget.get_cursor()<tab><tab><tab>if currentPath != path:<tab><tab><tab><tab>widget.set_cursor(path, col, 0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__popupMenu(event)<tab><tab>return False",0,if event . button == 3 :,if time - celly < time :,0.021363782,6.770186229,0.285714286
"def __lt__(self, other):<tab>try:<tab><tab>if self._version != other._version:<tab><tab><tab>return self._version < other._version<tab><tab>if self._ip != other._ip:<tab><tab><tab>return self._ip < other._ip<tab><tab><IF-STMT><tab><tab><tab>return self.netmask < other.netmask<tab><tab>return False<tab>except AttributeError:<tab><tab>return NotImplemented",1,if self . netmask != other . netmask :,if self . netmask != other . netmask :,1,100,1
"def config_video_apply(self, dev_id_info):<tab>df, da, add_define, hf, ha, add_hotplug = self.make_apply_data()<tab>ignore = add_hotplug<tab>if self.editted(EDIT_VIDEO_MODEL):<tab><tab>model = self.get_combo_label_value(""video-model"")<tab><tab><IF-STMT><tab><tab><tab>add_define(self.vm.define_video_model, dev_id_info, model)<tab>return self._change_config_helper(df, da, hf, ha)",1,if model :,if model :,0.531170663,1.00E-10,1
"def write(self, b):<tab>if self._write_watcher is None:<tab><tab>raise UnsupportedOperation(""write"")<tab>while True:<tab><tab>try:<tab><tab><tab>return _write(self._fileno, b)<tab><tab>except (IOError, OSError) as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>wait_on_watcher(self._write_watcher, None, None, self.hub)",0,if ex . args [ 0 ] not in ignored_errors :,if ex . errno != errno . EAGAIN :,0.094778298,12.43423351,0.323232323
"def scan_resource_conf(self, conf):<tab>if ""enabled"" in conf and conf[""enabled""][0]:<tab><tab>retention_block = conf[""retention_policy""][0]<tab><tab>if retention_block[""enabled""][0]:<tab><tab><tab>retention_in_days = force_int(retention_block[""days""][0])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return CheckResult.PASSED<tab>return CheckResult.FAILED",0,if retention_in_days and retention_in_days >= 90 :,if retention_in_days and retention_in_days > 0 :,0.47111352,81.07492451,0.6
"def _find_gist_with_file(user, filename, env):<tab>import requests  # expensive<tab>page = 1<tab>url = ""https://api.github.com/users/%s/gists"" % user<tab>while True:<tab><tab>resp = requests.get(<tab><tab><tab>url,<tab><tab><tab>params={""page"": page, ""per_page"": 100},<tab><tab><tab>headers=_github_auth_headers(env),<tab><tab>)<tab><tab>gists = resp.json()<tab><tab>if not gists:<tab><tab><tab>return None<tab><tab>for gist in gists:<tab><tab><tab>for name in gist[""files""]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return gist<tab><tab>page += 1",1,if name == filename :,if name == filename :,0.75,100,1
"def parse_position_spec(self):<tab>line = self.lookahead()<tab>if line.startswith(""jump="") or line.startswith(""jcnd=""):<tab><tab>self.consume()<tab><tab>return True<tab>mo = self._position_re.match(line)<tab>if not mo:<tab><tab>return False<tab>position, id, name = mo.groups()<tab>if id:<tab><tab>table = self._position_table_map[position]<tab><tab><IF-STMT><tab><tab><tab>self.position_ids[(table, id)] = name<tab><tab>else:<tab><tab><tab>name = self.position_ids.get((table, id), """")<tab>self.positions[self._position_map[position]] = name<tab>self.consume()<tab>return True",0,if name :,"if ( table , id ) in self . position_ids :",0.166574679,1.00E-10,0.257142857
"def remove_header(self, header):<tab>new_msg = b""""<tab>old_msg = self.msg_bytes.split(""\n"")<tab>i = 0<tab>while True:<tab><tab>line = old_msg[i]<tab><tab>i += 1<tab><tab><IF-STMT><tab><tab><tab>new_msg += line<tab><tab>if line == """":<tab><tab><tab>break<tab>new_msg += old_msg[i:]<tab>self.msg_bytes = new_msg",0,"if not line . startswith ( b""%s: "" % header ) :",if line . startswith ( header ) :,0.160014293,19.0183795,0.322222222
"def on_janitor_selection_changed(self, selection):<tab>model, iter = selection.get_selected()<tab>if iter:<tab><tab>if self.janitor_model.iter_has_child(iter):<tab><tab><tab>iter = self.janitor_model.iter_children(iter)<tab><tab>plugin = model[iter][self.JANITOR_PLUGIN]<tab><tab>for row in self.result_model:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.result_view.get_selection().select_path(row.path)<tab><tab><tab><tab>log.debug(""scroll_to_cell: %s"" % row.path)<tab><tab><tab><tab>self.result_view.scroll_to_cell(row.path)",0,if row [ self . RESULT_PLUGIN ] == plugin :,if plugin == row . path :,0.017045232,8.086128556,0.333333333
"def record_line(self, frame, event, arg):  # pylint: disable=unused-argument<tab>""""""Records line execution time.""""""<tab>if event == ""line"":<tab><tab><IF-STMT><tab><tab><tab>runtime = time.time() - self.prev_timestamp<tab><tab><tab>self.lines.append([self.prev_path, self.prev_lineno, runtime])<tab><tab>self.prev_lineno = frame.f_lineno<tab><tab>self.prev_path = frame.f_code.co_filename<tab><tab>self.prev_timestamp = time.time()<tab>return self.record_line",0,if self . prev_timestamp :,if self . prev_timestamp is not None :,0.351498834,53.72849659,0.444444444
"def get_outdated_docs(self) -> Iterator[str]:<tab>for docname in self.env.found_docs:<tab><tab>if docname not in self.env.all_docs:<tab><tab><tab>yield docname<tab><tab><tab>continue<tab><tab>targetname = path.join(self.outdir, docname + self.out_suffix)<tab><tab>try:<tab><tab><tab>targetmtime = path.getmtime(targetname)<tab><tab>except Exception:<tab><tab><tab>targetmtime = 0<tab><tab>try:<tab><tab><tab>srcmtime = path.getmtime(self.env.doc2path(docname))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield docname<tab><tab>except OSError:<tab><tab><tab># source doesn't exist anymore<tab><tab><tab>pass",1,if srcmtime > targetmtime :,if srcmtime > targetmtime :,0.75,100,1
"def _fetch_all_channels(self, force=False):<tab>""""""Fetch all channel feeds from cache or network.""""""<tab>channels = self._get_channel_configs(force=force)<tab>enabled = self._settings.get([""enabled_channels""])<tab>forced = self._settings.get([""forced_channels""])<tab>all_channels = {}<tab>for key, config in channels.items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""url"" not in config:<tab><tab><tab>continue<tab><tab>data = self._get_channel_data(key, config, force=force)<tab><tab>if data is not None:<tab><tab><tab>all_channels[key] = data<tab>return all_channels",0,if key not in enabled and key not in forced :,if key not in enabled or key not in forced :,0.852001933,70.16879391,0.777777778
"def _get_cortex_binary(kmer, cortex_dir):<tab>cortex_bin = None<tab>for check_bin in sorted(glob.glob(os.path.join(cortex_dir, ""bin"", ""cortex_var_*""))):<tab><tab>kmer_check = int(os.path.basename(check_bin).split(""_"")[2])<tab><tab><IF-STMT><tab><tab><tab>cortex_bin = check_bin<tab><tab><tab>break<tab>assert (<tab><tab>cortex_bin is not None<tab>), ""Could not find cortex_var executable in %s for kmer %s"" % (cortex_dir, kmer)<tab>return cortex_bin",0,if kmer_check >= kmer :,if kmer_check == kmer :,0.331415021,50,1
"def test_numeric_literals(self):<tab>@udf(BigIntVal(FunctionContext, SmallIntVal))<tab>def fn(context, a):<tab><tab><IF-STMT><tab><tab><tab>return 1729<tab><tab>elif a < 0:<tab><tab><tab>return None<tab><tab>elif a < 10:<tab><tab><tab>return a + 5<tab><tab>else:<tab><tab><tab>return a * 2",0,if a is None :,if a > 1729 :,0.064978772,23.64354023,0.444444444
"def cs(self):<tab>""""""ConfigSpace representation of this search space.""""""<tab>cs = CS.ConfigurationSpace()<tab>for k, v in self.kwvars.items():<tab><tab>if isinstance(v, NestedSpace):<tab><tab><tab>_add_cs(cs, v.cs, k)<tab><tab><IF-STMT><tab><tab><tab>hp = v.get_hp(name=k)<tab><tab><tab>_add_hp(cs, hp)<tab><tab>else:<tab><tab><tab>_rm_hp(cs, k)<tab>return cs",1,"elif isinstance ( v , Space ) :","elif isinstance ( v , Space ) :",0.75,100,1
"def lineReceived(self, line):<tab>if self.state == ""connected"":<tab><tab>self.messageFilename = line<tab><tab>self.state = ""gotMessageFilename""<tab>if self.state == ""gotMessageFilename"":<tab><tab>if line:<tab><tab><tab>self.metaInfo.append(line)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.transport.loseConnection()<tab><tab><tab><tab>return<tab><tab><tab>self.filterMessage()",0,if not self . metaInfo :,if self . transport :,0.054520976,20.80119538,0.3
"def __init__(self, reg, shtype, shimm, va):<tab>if shimm == 0:<tab><tab><IF-STMT><tab><tab><tab>shtype = S_RRX<tab><tab>elif shtype == S_LSR or shtype == S_ASR:<tab><tab><tab>shimm = 32<tab>self.reg = reg<tab>self.shtype = shtype<tab>self.shimm = shimm<tab>self.va = va",0,if shtype == S_ROR :,if shtype == S_RRX :,0.394778655,70.71067812,1
"def check_data(self, var_name: str, val: Dict[Any, Any]) -> None:<tab>if not isinstance(val, dict):<tab><tab>raise AssertionError(f""{var_name} is not a dictionary"")<tab>for key, value in val.items():<tab><tab><IF-STMT><tab><tab><tab>raise AssertionError(f""{var_name} has a non-string key"")<tab><tab>check_data(self.value_type, f""{var_name}[{key}]"", value)",1,"if not isinstance ( key , str ) :","if not isinstance ( key , str ) :",0.75,100,1
"def write_conditional_formatting(worksheet):<tab>""""""Write conditional formatting to xml.""""""<tab>df = DifferentialStyle()<tab>wb = worksheet.parent<tab>for cf in worksheet.conditional_formatting:<tab><tab>for rule in cf.rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rule.dxfId = wb._differential_styles.add(rule.dxf)<tab><tab>yield cf.to_tree()",0,if rule . dxf and rule . dxf != df :,if rule . dxf not in df . _differential_styles :,0.263245192,22.2424694,0.402777778
"def _find_wordpress_compiler(self):<tab>""""""Find WordPress compiler plugin.""""""<tab>if self.wordpress_page_compiler is not None:<tab><tab>return<tab>plugin_info = self.site.plugin_manager.getPluginByName(""wordpress"", ""PageCompiler"")<tab>if plugin_info is not None:<tab><tab><IF-STMT><tab><tab><tab>self.site.plugin_manager.activatePluginByName(plugin_info.name)<tab><tab><tab>plugin_info.plugin_object.set_site(self.site)<tab><tab>self.wordpress_page_compiler = plugin_info.plugin_object",0,if not plugin_info . is_activated :,if plugin_info . plugin_object is not None :,0.046132298,25.96535889,0.36
"def _confirm(config):<tab>cli.out(""You are about to initialize a Guild environment:"")<tab>for name, val in config.prompt_params:<tab><tab><IF-STMT><tab><tab><tab>cli.out(""  {}:"".format(name))<tab><tab><tab>for x in val:<tab><tab><tab><tab>cli.out(""<tab>{}"".format(x))<tab><tab>else:<tab><tab><tab>cli.out(""  {}: {}"".format(name, val))<tab>return cli.confirm(""Continue?"", default=True)",0,"if isinstance ( val , tuple ) :","if isinstance ( val , list ) :",0.549040681,59.46035575,0.666666667
"def last_ok(nodes):<tab>for i in range(len(nodes) - 1, -1, -1):<tab><tab>if ok_node(nodes[i]):<tab><tab><tab>node = nodes[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ok_node(node.value):<tab><tab><tab><tab><tab>return node.value<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>return nodes[i]<tab>return None",0,"if isinstance ( node , ast . Starred ) :","if hasattr ( node , ""value"" ) :",0.071124364,20.55668085,0.404761905
"def _is_binary(fname, limit=80):<tab>try:<tab><tab>with open(fname, ""rb"") as f:<tab><tab><tab>for i in range(limit):<tab><tab><tab><tab>char = f.read(1)<tab><tab><tab><tab>if char == b""\0"":<tab><tab><tab><tab><tab>return True<tab><tab><tab><tab>if char == b""\n"":<tab><tab><tab><tab><tab>return False<tab><tab><tab><tab>if char == b"""":<tab><tab><tab><tab><tab>return<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>raise e<tab>return False",0,if xp . ON_WINDOWS and is_app_execution_alias ( fname ) :,if i == limit - 1 :,0.013989055,1.881555714,0.25
"def render(self):<tab>x = ""<span>""<tab>for idx, arg in enumerate(self.args, start=1):<tab><tab>if isinstance(arg, (tuple, list)):<tab><tab><tab>value, desc = arg<tab><tab>else:<tab><tab><tab>value, desc = arg, arg<tab><tab>attrs = self.attrs.copy()<tab><tab>attrs[""name""] = self.name<tab><tab>attrs[""type""] = ""radio""<tab><tab>attrs[""value""] = value<tab><tab>attrs[""id""] = self.name + str(idx)<tab><tab><IF-STMT><tab><tab><tab>attrs[""checked""] = ""checked""<tab><tab>x += ""<input %s/> %s"" % (attrs, net.websafe(desc))<tab>x += ""</span>""<tab>return x",0,if self . value == value :,if self . checked :,0.094532291,23.45000811,0.571428571
"def test01b_gml(self):<tab>""Testing GML output.""<tab>for g in self.geometries.wkt_out:<tab><tab>geom = OGRGeometry(g.wkt)<tab><tab>exp_gml = g.gml<tab><tab><IF-STMT><tab><tab><tab># In GDAL 1.8, the non-conformant GML tag  <gml:GeometryCollection> was<tab><tab><tab># replaced with <gml:MultiGeometry>.<tab><tab><tab>exp_gml = exp_gml.replace(""GeometryCollection"", ""MultiGeometry"")<tab><tab>self.assertEqual(exp_gml, geom.gml)",0,"if GDAL_VERSION >= ( 1 , 8 ) :","if isinstance ( exp_gml , MultiGeometry ) :",0.033138934,9.042713792,0.333333333
"def _update_recording(self, frame, config):<tab>""""""Adds a frame to the current video output.""""""<tab># pylint: disable=redefined-variable-type<tab>should_record = config[""is_recording""]<tab>if should_record:<tab><tab><IF-STMT><tab><tab><tab>self.is_recording = True<tab><tab><tab>print(<tab><tab><tab><tab>""Starting recording using %s"", self.video_writer.current_output().name()<tab><tab><tab>)<tab><tab>self.video_writer.write_frame(frame)<tab>elif self.is_recording:<tab><tab>self.is_recording = False<tab><tab>self.video_writer.finish()<tab><tab>print(""Finished recording"")",0,if not self . is_recording :,if self . is_recording :,0.281663156,72.89545184,0.464285714
"def activate(self, ctx):<tab>for idx in ctx.chooser_selection:<tab><tab>func_ea = idaapi.getn_func(idx - 1).startEA<tab><tab>cfunc = helper.decompile_function(func_ea)<tab><tab>obj = api.VariableObject(cfunc.get_lvars()[0], 0)<tab><tab><IF-STMT><tab><tab><tab>NewDeepSearchVisitor(cfunc, 0, obj, cache.temporary_structure).process()",0,if cfunc :,if obj is not None :,0.048107739,1.00E-10,0.2
"def finish(self, event, commit=0):<tab>target = self.target<tab>source = self.source<tab>widget = self.initial_widget<tab>root = self.root<tab>try:<tab><tab>del root.__dnd<tab><tab>self.initial_widget.unbind(self.release_pattern)<tab><tab>self.initial_widget.unbind(""<Motion>"")<tab><tab>widget[""cursor""] = self.save_cursor<tab><tab>self.target = self.source = self.initial_widget = self.root = None<tab><tab><IF-STMT><tab><tab><tab>if commit:<tab><tab><tab><tab>target.dnd_commit(source, event)<tab><tab><tab>else:<tab><tab><tab><tab>target.dnd_leave(source, event)<tab>finally:<tab><tab>source.dnd_end(target, event)",0,if target :,if target is not None :,0.090364769,1.00E-10,0.4
"def run_epoch(model: BaseModel, loader, device: str, num_batches: int):<tab>model.eval()<tab>with Ctq(loader) as tq_loader:<tab><tab>for batch_idx, data in enumerate(tq_loader):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>process(model, data, device)<tab><tab><tab>else:<tab><tab><tab><tab>break",1,if batch_idx < num_batches :,if batch_idx < num_batches :,0.75,100,1
"def find(d, target):<tab>remainingDicts = [d]<tab>while len(remainingDicts) > 0:<tab><tab>current = remainingDicts.pop()<tab><tab>for k, v in current.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return v<tab><tab><tab>if isinstance(v, dict):<tab><tab><tab><tab>remainingDicts.insert(0, v)<tab>return None",1,if k == target :,if k == target :,0.75,100,1
"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab>if jid is None:<tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab>if node is None:<tab><tab><tab>node = """"<tab><tab>if ifrom is None:<tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab><IF-STMT><tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",1,ifrom = ifrom . full,ifrom = ifrom . full,1,100,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_time(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_level(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_log_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 16 :,if tt == 16 :,0.75,100,1
"def _merge_dict(d1, d2):<tab># Modifies d1 in-place to take values from d2<tab># if the nested keys from d2 are present in d1.<tab># https://stackoverflow.com/a/10704003/4488789<tab>for k, v2 in d2.items():<tab><tab>v1 = d1.get(k)  # returns None if v1 has no such key<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""{} is not recognized by client_config"".format(k))<tab><tab>if isinstance(v1, Mapping) and isinstance(v2, Mapping):<tab><tab><tab>_merge_dict(v1, v2)<tab><tab>else:<tab><tab><tab>d1[k] = v2<tab>return d1",0,if v1 is None :,if v1 is None or v2 is None :,0.304052086,37.53119269,0.523809524
"def build_and_apply_filters(query, objects, filter_func):<tab>if objects is not None:<tab><tab>if isinstance(objects, str):<tab><tab><tab>query = query.filter(filter_func(objects))<tab><tab><IF-STMT><tab><tab><tab>t = []<tab><tab><tab>for obj in objects:<tab><tab><tab><tab>t.append(filter_func(obj))<tab><tab><tab>query = query.filter(or_(*t))<tab>return query",1,"elif isinstance ( objects , list ) :","elif isinstance ( objects , list ) :",0.75,100,1
"def _worker_task(self, num: int):<tab>while True:<tab><tab>try_ = 0<tab><tab>f = self.q.get()<tab><tab>while try_ <= self.retries:<tab><tab><tab>rr = f()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>try_ += 1<tab><tab>with self.stat_lock:<tab><tab><tab>self.exit_stat |= rr.ret_val<tab><tab>self.q.task_done()",0,if not rr . retry :,if rr . ret_val == num :,0.047631794,9.980099404,0.30952381
"def get_benchmark_id_title_map(input_tree):<tab>input_root = input_tree.getroot()<tab>ret = {}<tab>for namespace in [XCCDF11_NS, XCCDF12_NS]:<tab><tab>candidates = []<tab><tab>scrape_benchmarks(input_root, namespace, candidates)<tab><tab>for _, elem in candidates:<tab><tab><tab>_id = elem.get(""id"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>title = ""<unknown>""<tab><tab><tab>for element in elem.findall(""{%s}title"" % (namespace)):<tab><tab><tab><tab>title = element.text<tab><tab><tab><tab>break<tab><tab><tab>ret[_id] = title<tab>return ret",1,if _id is None :,if _id is None :,0.75,100,1
"def _call_tensor_ufunc(self, x1, x2, out=None, where=None):<tab><IF-STMT> or hasattr(x2, ""__tensor_ufunc__""):<tab><tab>ufunc = (<tab><tab><tab>x1.__tensor_ufunc__<tab><tab><tab>if hasattr(x1, ""__tensor_ufunc__"")<tab><tab><tab>else x2.__tensor_ufunc__<tab><tab>)<tab><tab>ret = ufunc(type(self), [x1, x2], out, where, **self.ufunc_extra_params)<tab><tab>if ret is NotImplemented:<tab><tab><tab>return<tab><tab>return ret",1,"if hasattr ( x1 , ""__tensor_ufunc__"" )","if hasattr ( x1 , ""__tensor_ufunc__"" )",0.75,100,1
"def remove_namespaces(xml):<tab>for elem in xml.getiterator():<tab><tab>if elem.tag is etree.Comment:<tab><tab><tab>continue<tab><tab>i = elem.tag.find(""}"")<tab><tab><IF-STMT><tab><tab><tab>elem.tag = elem.tag[i + 1 :]<tab>return xml",0,if i > 0 :,if i >= 0 :,0.331415021,37.99178428,1
"def attributive(adjective, gender=MALE):<tab>w = adjective.lower()<tab># normal => normales<tab>if PLURAL in gender and not is_vowel(w[-1:]):<tab><tab>return w + ""es""<tab># el chico inteligente => los chicos inteligentes<tab>if PLURAL in gender and w.endswith((""a"", ""e"")):<tab><tab>return w + ""s""<tab># el chico alto => los chicos altos<tab>if w.endswith(""o""):<tab><tab>if FEMININE in gender and PLURAL in gender:<tab><tab><tab>return w[:-1] + ""as""<tab><tab>if FEMININE in gender:<tab><tab><tab>return w[:-1] + ""a""<tab><tab><IF-STMT><tab><tab><tab>return w + ""s""<tab>return w",0,if PLURAL in gender :,if PLURAL in gender and not is_vowel ( w [ - 1 ] ) :,0.345266189,15.1385146,0.530864198
"def atbash(s):<tab>translated = """"<tab>for i in range(len(s)):<tab><tab>n = ord(s[i])<tab><tab>if s[i].isalpha():<tab><tab><tab>if s[i].isupper():<tab><tab><tab><tab>x = n - ord(""A"")<tab><tab><tab><tab>translated += chr(ord(""Z"") - x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = n - ord(""a"")<tab><tab><tab><tab>translated += chr(ord(""z"") - x)<tab><tab>else:<tab><tab><tab>translated += s[i]<tab>return translated",0,if s [ i ] . islower ( ) :,elif s [ i ] . isalpha ( ) :,0.252094392,52.53819789,0.428571429
"def _add_all(self):<tab>stream = BytesIO()<tab>for page in self.graph_manager.pages:<tab><tab>stream.write(page.url.encode(""utf8""))<tab><tab><IF-STMT><tab><tab><tab>for link in page.links:<tab><tab><tab><tab>stream.write(link.url.encode(""utf8""))<tab><tab><tab><tab>stream.write(linesep.encode(""utf8""))<tab>stream.seek(0)<tab>self.frontier.add_seeds(stream)",0,if not page . has_errors :,if page . links :,0.054520976,13.94345824,0.4
"def test_bigrand_ranges(self):<tab>for i in [40, 80, 160, 200, 211, 250, 375, 512, 550]:<tab><tab>start = self.gen.randrange(2 ** i)<tab><tab>stop = self.gen.randrange(2 ** (i - 2))<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self.assertTrue(start <= self.gen.randrange(start, stop) < stop)",0,if stop <= start :,if start >= stop :,0.288498786,12.13729429,0.5
"def on_connect(self, request):<tab>web_socket = WebSocketResponse()<tab>await web_socket.prepare(request)<tab>self.app[""websockets""].add(web_socket)<tab>try:<tab><tab>async for msg in web_socket:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await self.on_status(None)<tab><tab><tab>elif msg.type == WSMsgType.ERROR:<tab><tab><tab><tab>print(<tab><tab><tab><tab><tab>""web socket connection closed with exception %s""<tab><tab><tab><tab><tab>% web_socket.exception()<tab><tab><tab><tab>)<tab>finally:<tab><tab>self.app[""websockets""].discard(web_socket)<tab>return web_socket",0,if msg . type == WSMsgType . TEXT :,if msg . type == WSMsgType . SUCCESS :,0.627090855,78.254229,0.714285714
"def __cut_all(self, sentence):<tab>dag = self.get_DAG(sentence)<tab>old_j = -1<tab>for k, L in iteritems(dag):<tab><tab>if len(L) == 1 and k > old_j:<tab><tab><tab>yield sentence[k : L[0] + 1]<tab><tab><tab>old_j = L[0]<tab><tab>else:<tab><tab><tab>for j in L:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>yield sentence[k : j + 1]<tab><tab><tab><tab><tab>old_j = j",0,if j > k :,if j < old_j :,0.064978772,14.53576842,0.7
def filter_forms(forms):<tab>result = []<tab>seen = set()<tab>for form in forms:<tab><tab>if form in self._lemma_pos_offset_map:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if form not in seen:<tab><tab><tab><tab><tab>result.append(form)<tab><tab><tab><tab><tab>seen.add(form)<tab>return result,0,if pos in self . _lemma_pos_offset_map [ form ] :,if self . _lemma_pos_offset_map [ form ] is not None :,0.408196396,72.05815374,0.212121212
"def __init__(self, el):<tab>self.elements = list(el)<tab>parameters = {}<tab>tokens = []<tab>token_quote = ""@""<tab>for key, value in el.attrib.items():<tab><tab>if key == ""token_quote"":<tab><tab><tab>token_quote = value<tab><tab><IF-STMT><tab><tab><tab>for token in value.split("",""):<tab><tab><tab><tab>tokens.append((token, REQUIRED_PARAMETER))<tab><tab>elif key.startswith(""token_""):<tab><tab><tab>token = key[len(""token_"") :]<tab><tab><tab>tokens.append((token, value))<tab>for name, default in tokens:<tab><tab>parameters[name] = (token_quote, default)<tab>self.parameters = parameters",0,"if key == ""tokens"" :","elif key == ""required"" :",0.058575651,41.11336169,0.5
"def setPositionAfterSort(self, sortChildren):<tab>c = self<tab>p = c.p<tab>p_v = p.v<tab>parent = p.parent()<tab>parent_v = p._parentVnode()<tab>if sortChildren:<tab><tab>p = parent or c.rootPosition()<tab>else:<tab><tab><IF-STMT><tab><tab><tab>p = parent.firstChild()<tab><tab>else:<tab><tab><tab>p = leoNodes.Position(parent_v.children[0])<tab><tab>while p and p.v != p_v:<tab><tab><tab>p.moveToNext()<tab><tab>p = p or parent<tab>return p",0,if parent :,if parent_v is None :,0.051944023,1.00E-10,0.36
"def next(self):<tab>while not self.closed or not self._buffer.empty():<tab><tab># input stream<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>chunck = next(self._input_iterator)<tab><tab><tab><tab>return chunck<tab><tab><tab>except StopIteration:<tab><tab><tab><tab>self.closed = True<tab><tab><tab><tab>raise StopIteration()<tab><tab><tab>except Exception as ex:<tab><tab><tab><tab>log.error(""Failed downloading: %s"" % ex)<tab><tab>else:<tab><tab><tab># in/out stream<tab><tab><tab>try:<tab><tab><tab><tab>return self._buffer.get(block=True, timeout=1.0)<tab><tab><tab>except Empty:<tab><tab><tab><tab>pass<tab>raise StopIteration()",0,if self . _input_iterator :,if self . _input_iterator is not None :,0.351498834,59.00468726,0.444444444
"def _gen_GreaterEqual(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab>if ret_type == real_type:<tab><tab><tab>result.append(self.builder.fcmp_ordered("">="", lhs, rhs))<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.icmp_signed("">="", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",1,elif ret_type == int_type :,elif ret_type == int_type :,1,100,1
"def save_settings(self, settings):<tab>for setting in self.settings:<tab><tab>setting_obj = settings[setting]<tab><tab>new_value = self.cleaned_data.get(setting)<tab><tab>if setting_obj.python_type == ""image"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.save_image(setting_obj, new_value)<tab><tab><tab>elif self.cleaned_data.get(""%s_delete"" % setting):<tab><tab><tab><tab>self.delete_image(setting_obj)<tab><tab>else:<tab><tab><tab>self.save_setting(setting_obj, new_value)",0,if new_value and new_value != self . initial . get ( setting ) :,"if self . cleaned_data . get ( ""%s_save"" % setting ) :",0.098694289,15.59343951,0.26984127
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_events().TryMerge(tmp)<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_timeout_seconds(d.getDouble())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",0,if tt == 17 :,if tt == 16 :,0.394778655,53.72849659,0.6
"def _trim_steps(self, num_steps):<tab>""""""Trims a given number of steps from the end of the sequence.""""""<tab>steps_trimmed = 0<tab>for i in reversed(range(len(self._events))):<tab><tab>if self._events[i].event_type == PolyphonicEvent.STEP_END:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self._events[i + 1 :]<tab><tab><tab><tab>break<tab><tab><tab>steps_trimmed += 1<tab><tab>elif i == 0:<tab><tab><tab>self._events = [<tab><tab><tab><tab>PolyphonicEvent(event_type=PolyphonicEvent.START, pitch=None)<tab><tab><tab>]<tab><tab><tab>break",0,if steps_trimmed == num_steps :,if steps_trimmed >= num_steps :,0.331415021,65.80370065,1
"def save(self):<tab>data = self.cleaned_data<tab>previous_data = google_integration_model.get_by_account_id(self.account_id)<tab>if previous_data:<tab><tab>previous_file = previous_data.get(""file_id"")<tab>else:<tab><tab>previous_file = None<tab>json_key_file = data.get(""json_key"")<tab>if json_key_file:<tab><tab>data[""file_id""] = files_model.add(json_key_file)<tab><tab>del data[""json_key""]<tab><tab><IF-STMT><tab><tab><tab>files_model.delete(previous_file)<tab>google_integration_model.save(data, account_id=self.account_id)",1,if previous_file :,if previous_file :,0.531170663,1.00E-10,1
"def _register(self, class_):<tab>with self.lock:<tab><tab>table, slots = self._schema(class_)<tab><tab>cur = self.db.execute(""PRAGMA table_info(%s)"" % table)<tab><tab>available = cur.fetchall()<tab><tab><IF-STMT><tab><tab><tab>available = [row[1] for row in available]<tab><tab><tab>missing_slots = (s for s in slots if s not in available)<tab><tab><tab>for slot in missing_slots:<tab><tab><tab><tab>self.db.execute(""ALTER TABLE %s ADD COLUMN %s TEXT"" % (table, slot))<tab><tab>else:<tab><tab><tab>self.db.execute(<tab><tab><tab><tab>""CREATE TABLE %s (%s)""<tab><tab><tab><tab>% (table, "", "".join(""%s TEXT"" % s for s in slots))<tab><tab><tab>)",1,if available :,if available :,0.531170663,1.00E-10,1
"def describe_auto_scaling_instances(self, instance_ids):<tab>instance_states = []<tab>for group in self.autoscaling_groups.values():<tab><tab>instance_states.extend(<tab><tab><tab>[<tab><tab><tab><tab>x<tab><tab><tab><tab>for x in group.instance_states<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab>)<tab>return instance_states",0,if not instance_ids or x . instance . id in instance_ids,if x . instance_id in instance_ids,0.030000174,35.01806397,0.208333333
"def add_nicknames(self, fields, data):<tab>""""""Read the NICKNAME property of a VCard.""""""<tab>for nick in self.split_unescaped(data, "",""):<tab><tab>nickname = nick.strip()<tab><tab><IF-STMT><tab><tab><tab>name = Name()<tab><tab><tab>name.set_nick_name(self.unesc(nickname))<tab><tab><tab>self.person.add_alternate_name(name)",1,if nickname :,if nickname :,0.531170663,1.00E-10,1
"def while1_test(a, b, c):<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>if b:<tab><tab><tab><tab>a = 3<tab><tab><tab><tab>b = 0<tab><tab><tab>elif c:<tab><tab><tab><tab>c = 0<tab><tab><tab>else:<tab><tab><tab><tab>a += b + c<tab><tab><tab><tab>break<tab>return a, b, c",0,if a != 2 :,if a == 3 :,0.314978772,19.30486975,0.6
"def get_stream(conf, reload=False):<tab>if not conf:<tab><tab>return conf<tab># we can have 'stream' or 'class' or 'filename'<tab>if ""class"" in conf:<tab><tab>class_name = conf.pop(""class"")<tab><tab><IF-STMT><tab><tab><tab>cls = globals()[class_name]<tab><tab><tab>inst = cls(**conf)<tab><tab>else:<tab><tab><tab>inst = resolve_name(class_name, reload=reload)(**conf)<tab>elif ""stream"" in conf:<tab><tab>inst = conf[""stream""]<tab>elif ""filename"" in conf:<tab><tab>inst = FileStream(**conf)<tab>else:<tab><tab>raise ValueError(""stream configuration invalid"")<tab>return {""stream"": inst}",0,"if not ""."" in class_name :",if class_name in globals ( ) :,0.026785326,18.88588859,0.4
"def check_physical(self, line):<tab>""""""Run all physical checks on a raw input line.""""""<tab>self.physical_line = line<tab>for name, check, argument_names in self._physical_checks:<tab><tab>self.init_checker_state(name, argument_names)<tab><tab>result = self.run_check(check, argument_names)<tab><tab><IF-STMT><tab><tab><tab>(offset, text) = result<tab><tab><tab>self.report_error(self.line_number, offset, text, check)<tab><tab><tab>if text[:4] == ""E101"":<tab><tab><tab><tab>self.indent_char = line[0]",1,if result is not None :,if result is not None :,0.75,100,1
"def delete_oidc_session_tokens(session):<tab>if session:<tab><tab>if ""oidc_access_token"" in session:<tab><tab><tab>del session[""oidc_access_token""]<tab><tab>if ""oidc_id_token"" in session:<tab><tab><tab>del session[""oidc_id_token""]<tab><tab>if ""oidc_id_token_expiration"" in session:<tab><tab><tab>del session[""oidc_id_token_expiration""]<tab><tab><IF-STMT><tab><tab><tab>del session[""oidc_login_next""]<tab><tab>if ""oidc_refresh_token"" in session:<tab><tab><tab>del session[""oidc_refresh_token""]<tab><tab>if ""oidc_state"" in session:<tab><tab><tab>del session[""oidc_state""]",1,"if ""oidc_login_next"" in session :","if ""oidc_login_next"" in session :",0.75,100,1
"def _fix_exception_context(new_exc, old_exc):<tab># Context may not be correct, so find the end of the chain<tab>while 1:<tab><tab>exc_context = new_exc.__context__<tab><tab>if exc_context is old_exc:<tab><tab><tab># Context is already set correctly (see issue 20317)<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>new_exc = exc_context<tab># Change the end of the chain to point to the exception<tab># we expect it to reference<tab>new_exc.__context__ = old_exc",0,if exc_context is None or exc_context is frame_exc :,if exc_context is old_exc :,0.25418419,30.64839278,0.478787879
"def _write_all(self, out):<tab>while len(out) > 0:<tab><tab>n = self.sock.send(out)<tab><tab>if n <= 0:<tab><tab><tab>raise EOFError()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>out = out[n:]<tab>return",0,if n == len ( out ) :,if n >= len ( out ) :,0.549040681,66.06328636,1
"def view(input_path):<tab>if not exists(input_path):<tab><tab>raise IOError(""{0} not found"".format(input_path))<tab>ua = None<tab>bundle_info = None<tab>try:<tab><tab>archive = archive_factory(input_path)<tab><tab><IF-STMT><tab><tab><tab>raise NotMatched(""No matching archive type found"")<tab><tab>ua = archive.unarchive_to_temp()<tab><tab>bundle_info = ua.bundle.info<tab>finally:<tab><tab>if ua is not None:<tab><tab><tab>ua.remove()<tab>return bundle_info",1,if archive is None :,if archive is None :,0.75,100,1
"def _line_generator(fh, skip_blanks=False, strip=True):<tab>for line in fh:<tab><tab>if strip:<tab><tab><tab>line = line.strip()<tab><tab>skip = False<tab><tab>if skip_blanks:<tab><tab><tab>skip = line.isspace() or not line<tab><tab><IF-STMT><tab><tab><tab>yield line",0,if not skip :,if skip :,0.096488528,1.00E-10,0.416666667
"def migrate_key(key, source, target):<tab>if source in config and key in config[source]:<tab><tab>if config.get(target) is None:<tab><tab><tab># make sure we have a serial tree<tab><tab><tab>config[target] = {}<tab><tab><IF-STMT><tab><tab><tab># only copy over if it's not there yet<tab><tab><tab>config[target][key] = config[source][key]<tab><tab># delete feature flag<tab><tab>del config[source][key]<tab><tab>return True<tab>return False",0,if key not in config [ target ] :,elif key not in config [ source ] :,0.316829053,51.3345048,0.555555556
"def get_params(self):<tab>if not hasattr(self, ""input_space""):<tab><tab>raise AttributeError(""Input space has not been provided."")<tab>rval = []<tab>for layer in self.layers:<tab><tab>for param in layer.get_params():<tab><tab><tab>if param.name is None:<tab><tab><tab><tab>logger.info(type(layer))<tab><tab>layer_params = layer.get_params()<tab><tab>assert not isinstance(layer_params, set)<tab><tab>for param in layer_params:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>rval.append(param)<tab>rval = [elem for elem in rval if elem not in self.freeze_set]<tab>assert all([elem.name is not None for elem in rval])<tab>return rval",0,if param not in rval :,if param . input_space == self . input_space :,0.040012803,6.285596338,0.4
"def _build_kwargs_string(cls, expectation):<tab>kwargs = []<tab>for k, v in expectation[""kwargs""].items():<tab><tab>if k == ""column"":<tab><tab><tab># make the column a positional argument<tab><tab><tab>kwargs.insert(0, ""{}='{}'"".format(k, v))<tab><tab><IF-STMT><tab><tab><tab># Put strings in quotes<tab><tab><tab>kwargs.append(""{}='{}'"".format(k, v))<tab><tab>else:<tab><tab><tab># Pass other types as is<tab><tab><tab>kwargs.append(""{}={}"".format(k, v))<tab>return "", "".join(kwargs)",1,"elif isinstance ( v , str ) :","elif isinstance ( v , str ) :",0.75,100,1
"def binary_search(_list, left, right, target):<tab>if right >= left:<tab><tab>mid = (left + right) // 2<tab><tab># if element is present at the mid itself<tab><tab>if _list[mid] == target:<tab><tab><tab>return mid<tab><tab># If the element is smaller than mid, then it<tab><tab># can only be present in the left subarray<tab><tab><IF-STMT><tab><tab><tab>return binary_search(_list, left, mid - 1, target)<tab><tab># Else the element can only be present in the right<tab><tab>return binary_search(_list, mid + 1, right, target)<tab>return False",1,if _list [ mid ] > target :,if _list [ mid ] > target :,0.75,100,1
"def _set_name(self, name):<tab># Sanitize the file name so that it can't be dangerous.<tab>if name is not None:<tab><tab># Just use the basename of the file -- anything else is dangerous.<tab><tab>name = os.path.basename(name)<tab><tab># File names longer than 255 characters can cause problems on older OSes.<tab><tab><IF-STMT><tab><tab><tab>name, ext = os.path.splitext(name)<tab><tab><tab>name = name[: 255 - len(ext)] + ext<tab>self._name = name",1,if len ( name ) > 255 :,if len ( name ) > 255 :,0.75,100,1
"def scan_iter(self, match=None, count=None):<tab>nodes = await self.cluster_nodes()<tab>for node in nodes:<tab><tab><IF-STMT><tab><tab><tab>cursor = ""0""<tab><tab><tab>while cursor != 0:<tab><tab><tab><tab>pieces = [cursor]<tab><tab><tab><tab>if match is not None:<tab><tab><tab><tab><tab>pieces.extend([""MATCH"", match])<tab><tab><tab><tab>if count is not None:<tab><tab><tab><tab><tab>pieces.extend([""COUNT"", count])<tab><tab><tab><tab>response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces)<tab><tab><tab><tab>cursor, data = list(response.values())[0]<tab><tab><tab><tab>for item in data:<tab><tab><tab><tab><tab>yield item",0,"if ""master"" in node [ ""flags"" ] :",if count is None :,0.018586852,3.132599824,0.26984127
"def drf_url(context, viewname, *args, **kwargs):<tab>""""""Helper for DjangoRestFramework's ``reverse`` in templates.""""""<tab>request = context.get(""request"")<tab>if request:<tab><tab><IF-STMT><tab><tab><tab>request.versioning_scheme = api_settings.DEFAULT_VERSIONING_CLASS()<tab><tab>request.version = request.versioning_scheme.determine_version(<tab><tab><tab>request, *args, **kwargs<tab><tab>)<tab>return drf_reverse(viewname, request=request, args=args, kwargs=kwargs)",0,"if not hasattr ( request , ""versioning_scheme"" ) :",if request . versioning_scheme is None :,0.017062029,13.5323305,0.285714286
"def __call__(self, ctx):<tab>if ctx.range and ctx.value:<tab><tab><IF-STMT><tab><tab><tab>ctx.range.raw_value = ctx.value<tab><tab><tab>return<tab><tab>scalar = ctx.meta.get(""scalar"", False)<tab><tab>if not scalar:<tab><tab><tab>ctx.range = ctx.range.resize(len(ctx.value), len(ctx.value[0]))<tab><tab>self._write_value(ctx.range, ctx.value, scalar)",0,if self . raw :,if ctx . range . raw_value is None :,0.110085874,8.913765521,0.225
"def removeNamedItemNS(self, namespaceURI, localName):<tab>n = self.getNamedItemNS(namespaceURI, localName)<tab>if n is not None:<tab><tab>_clear_id_cache(self._ownerElement)<tab><tab>del self._attrsNS[(n.namespaceURI, n.localName)]<tab><tab>del self._attrs[n.nodeName]<tab><tab><IF-STMT><tab><tab><tab>n.ownerElement = None<tab><tab>return n<tab>else:<tab><tab>raise xml.dom.NotFoundErr()",1,"if hasattr ( n , ""ownerElement"" ) :","if hasattr ( n , ""ownerElement"" ) :",0.75,100,1
"def __find_image(self, relpath):<tab>image_path = None<tab>for rp in self._resource_paths:<tab><tab>for root, dirs, files in os.walk(rp):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>image_path = os.path.join(root, relpath)<tab><tab><tab><tab>break<tab><tab>if image_path is not None:<tab><tab><tab>break<tab>return image_path",1,if relpath in files :,if relpath in files :,0.75,100,1
"def get_config_value(self, path, raise_if_not_found=True):<tab>if not path.is_concrete():<tab><tab>raise ValueError(""Can't access config by masked path: %s"" % path)<tab>cfg = self._config<tab>for key in path:<tab><tab>if key not in cfg:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Key not found: %r"" % key)<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab><tab>cfg = cfg[key]<tab>return cfg",1,if raise_if_not_found :,if raise_if_not_found :,0.531170663,1.00E-10,1
"def unbind(**kwargs):<tab>for event, callback in kwargs.items():<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Unknown {!r} event"".format(event))<tab><tab>else:<tab><tab><tab>for listener in _callbacks[event][:]:<tab><tab><tab><tab>if listener.callback == callback:<tab><tab><tab><tab><tab>_callbacks[event].remove(listener)<tab><tab><tab><tab><tab>if event == ""on_new_intent"":<tab><tab><tab><tab><tab><tab>_activity.unregisterNewIntentListener(listener)<tab><tab><tab><tab><tab>elif event == ""on_activity_result"":<tab><tab><tab><tab><tab><tab>_activity.unregisterActivityResultListener(listener)",1,if event not in _callbacks :,if event not in _callbacks :,0.75,100,1
"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab>if ""<"" in text:<tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)",1,"if '""' in text :","if '""' in text :",0.75,100,1
"def _get_options(self, kwargs):<tab>options = {}<tab>for option in self._options:<tab><tab><IF-STMT><tab><tab><tab>self._validate_option(option, kwargs[option])<tab><tab><tab>options[option] = kwargs[option]<tab><tab>else:<tab><tab><tab>options[option] = getattr(self, ""_"" + option)<tab>return options",0,if option in kwargs :,"if isinstance ( kwargs [ option ] , dict ) :",0.026167489,5.30015669,0.274725275
"def _parse_version_parts(s):<tab>for part in component_re.split(s):<tab><tab>part = replace(part, part)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if part[:1] in ""0123456789"":<tab><tab><tab>yield part.zfill(8)  # pad for numeric comparison<tab><tab>else:<tab><tab><tab>yield ""*"" + part<tab>yield ""*final""  # ensure that alpha/beta/candidate are before final",0,"if part in [ """" , ""."" ] :",if not part :,0.016468506,2.845073863,0.4
def collect_deps(lib):<tab>queue = list(lib.deps_all)<tab>visited = set(queue)<tab>visited.add(lib)<tab>deps = []<tab># Traverse dependencies with breadth-first search.<tab>while queue:<tab><tab># Collect dependencies for next queue.<tab><tab>next_queue = []<tab><tab>for lib in queue:<tab><tab><tab>for dep in lib.deps_all:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>next_queue.append(dep)<tab><tab><tab><tab><tab>visited.add(dep)<tab><tab># Append current queue to result.<tab><tab>deps.append(collect_path_sorted_lib_idxs(queue))<tab><tab>queue = next_queue<tab>return deps,1,if dep not in visited :,if dep not in visited :,0.75,100,1
"def process_chunks(self, chunks):<tab>chunk_id = self._chunk_id<tab>self._chunk_id += len(chunks)<tab>chunk_data = []<tab>for chunk in chunks:<tab><tab><IF-STMT><tab><tab><tab>msg = ""Metric data exceeds maximum size of {} bytes. Dropping it."".format(<tab><tab><tab><tab>MAX_LINE_SIZE<tab><tab><tab>)<tab><tab><tab>wandb.termerror(msg, repeat=False)<tab><tab><tab>util.sentry_message(msg)<tab><tab>else:<tab><tab><tab>chunk_data.append(chunk.data)<tab>return {<tab><tab>""offset"": chunk_id,<tab><tab>""content"": chunk_data,<tab>}",0,if len ( chunk . data ) > MAX_LINE_SIZE :,if chunk . data . size > MAX_LINE_SIZE :,0.135054869,54.84498092,0.333333333
"def truncateLogFile():<tab>global logfilename<tab>logger.warn(""Truncating log file %s"" % logfilename)<tab>with open(logfilename, ""w"") as f:<tab><tab>f.write("""")<tab>for i in range(1, 25):<tab><tab>rotatedFilename = ""%s.%d"" % (logfilename, i)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Deleting rotated file %s"" % rotatedFilename)<tab><tab><tab>os.unlink(rotatedFilename)",1,if os . path . exists ( rotatedFilename ) :,if os . path . exists ( rotatedFilename ) :,0.75,100,1
"def _page_contains(self, text):<tab>browser = self._current_browser()<tab>browser.switch_to_default_content()<tab>if self._is_text_present(text):<tab><tab>return True<tab>subframes = self._element_find(""xpath=//frame|//iframe"", False, False)<tab>self._debug(""Current frame has %d subframes"" % len(subframes))<tab>for frame in subframes:<tab><tab>browser.switch_to_frame(frame)<tab><tab>found_text = self._is_text_present(text)<tab><tab>browser.switch_to_default_content()<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False",1,if found_text :,if found_text :,0.531170663,1.00E-10,1
"def get_project_name_git():<tab>is_git = check_output([""git"", ""rev-parse"", ""--git-dir""], stderr=subprocess.STDOUT)<tab>if is_git:<tab><tab>project_address = check_output(<tab><tab><tab>[""git"", ""config"", ""--local"", ""remote.origin.url""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>project_address = project_address.decode()<tab><tab>project_name = [i for i in re.split(r""[/:\s\\]|\.git"", project_address) if i][<tab><tab><tab>-1<tab><tab>]<tab><tab>return project_name.strip()",0,"if isinstance ( project_address , bytes ) and str != bytes :","if isinstance ( project_address , bytes ) :",0.36911089,54.80623194,0.577777778
"def timer(ratio, step, additive):<tab>t = 0<tab>slowmode = False<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>slowmode |= bool((yield t))<tab><tab>else:<tab><tab><tab>slowmode = bool((yield t))<tab><tab>if slowmode:<tab><tab><tab>t += step * ratio<tab><tab>else:<tab><tab><tab>t += step",1,if additive :,if additive :,0.531170663,1.00E-10,1
"def _call_connection_lost(self, exc):<tab>try:<tab><tab>if self._protocol_connected:<tab><tab><tab>self._protocol.connection_lost(exc)<tab>finally:<tab><tab>self._sock.close()<tab><tab>self._sock = None<tab><tab>self._protocol = None<tab><tab>self._loop = None<tab><tab>server = self._server<tab><tab><IF-STMT><tab><tab><tab>server._detach()<tab><tab><tab>self._server = None",1,if server is not None :,if server is not None :,0.75,100,1
def _think(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>random.choice(self.peers.values()).send_getaddrs(count=8)<tab>except:<tab><tab>log.err()<tab>return random.expovariate(1 / 20),0,if len ( self . addr_store ) < self . preferred_storage and self . peers :,if self . peers :,0.12642176,3.520477366,0.303030303
def merge_force_collapse(self):<tab>p = self.pending<tab>while len(p) > 1:<tab><tab><IF-STMT><tab><tab><tab>self.merge_at(-3)<tab><tab>else:<tab><tab><tab>self.merge_at(-2),0,if len ( p ) >= 3 and p [ - 3 ] . len < p [ - 1 ] . len :,if len ( p ) == 1 :,0.145507326,8.484002377,0.398268398
"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab>if fd.isatty():<tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab>if not attr_list[3] & termios.ECHO:<tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab>if old_handler is not None:<tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",0,"if hasattr ( signal , ""SIGTTOU"" ) :",if attr_list [ 3 ] & termios . ECHO :,0.016095022,4.027248192,0.274725275
"def change_palette_name(self, palette_name):<tab>if isinstance(palette_name, str):<tab><tab><IF-STMT><tab><tab><tab>log.info(""Palette name %s not found"", palette_name)<tab><tab><tab>return<tab><tab>log.debug(""Settings palette name to %s"", palette_name)<tab><tab>self.settings.styleFont.set_string(""palette"", PALETTES[palette_name])<tab><tab>self.settings.styleFont.set_string(""palette-name"", palette_name)<tab><tab>self.set_colors_from_settings()",1,if palette_name not in PALETTES :,if palette_name not in PALETTES :,0.75,100,1
"def nested_match(expect, value):<tab>if expect == value:<tab><tab>return True<tab>if isinstance(expect, dict) and isinstance(value, dict):<tab><tab>for k, v in expect.items():<tab><tab><tab>if k in value:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>return True<tab>if isinstance(expect, list) and isinstance(value, list):<tab><tab>for x, y in zip(expect, value):<tab><tab><tab>if not nested_match(x, y):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",0,"if not nested_match ( v , value [ k ] ) :","if not nested_match ( v , k ) :",0.245136922,57.84632013,0.655555556
"def _on_event(self, event):<tab>event_id = event[""event_id""]<tab>if event_id == MpvEventID.END_FILE:<tab><tab>reason = event[""event""][""reason""]<tab><tab>logger.debug(""Current song finished. reason: %d"" % reason)<tab><tab><IF-STMT><tab><tab><tab>self.media_finished.emit()<tab>elif event_id == MpvEventID.FILE_LOADED:<tab><tab>self.media_loaded.emit()",0,if self . state != State . stopped and reason != MpvEventEndFile . ABORTED :,if event_id == MpvEventID . END_FILE :,0.079961012,3.338392248,0.163157895
"def __exit__(self, exc_type, exc_value, traceback):<tab>self.close()<tab>with DB.connection_context():<tab><tab>rows = (<tab><tab><tab>SessionRecord.delete()<tab><tab><tab>.where(SessionRecord.f_session_id == self._session_id)<tab><tab><tab>.execute()<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>LOGGER.debug(f""delete session {self._session_id} record"")<tab><tab>else:<tab><tab><tab>LOGGER.warning(f""failed delete session {self._session_id} record"")",0,if rows > 0 :,if rows :,0.067674239,1.00E-10,0.7
"def decorator(*args, **kwargs):<tab># Sets a boolean on the global request context<tab>g._flask_user_allow_unconfirmed_email = True<tab># Catch exceptions to properly unset boolean on exceptions<tab>try:<tab><tab>user_manager = current_app.user_manager<tab><tab># User must be logged in with a confirmed email address<tab><tab>allowed = _is_logged_in_with_confirmed_email(user_manager)<tab><tab><IF-STMT><tab><tab><tab># Redirect to unauthenticated page<tab><tab><tab>return user_manager.unauthenticated_view()<tab><tab># It's OK to call the view<tab><tab>return view_function(*args, **kwargs)<tab>finally:<tab><tab># Allways unset the boolean, whether exceptions occurred or not<tab><tab>g._flask_user_allow_unconfirmed_email = False",0,if not allowed :,if allowed :,0.096488528,1.00E-10,0.416666667
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_app_id(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>self.set_limit(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 16 :,if tt == 16 :,0.75,100,1
"def addOptions(parser):<tab>for optname in options.keys(""default""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>action = ""store_true"" if options[optname] is False else ""store""<tab><tab>try:<tab><tab><tab>parser.add_argument(<tab><tab><tab><tab>""--"" + optname.replace(""_"", ""-""),<tab><tab><tab><tab>action=action,<tab><tab><tab><tab>dest=optname,<tab><tab><tab><tab>default=None,<tab><tab><tab><tab>help=options._opts._get(optname).helpstr,<tab><tab><tab>)<tab><tab>except argparse.ArgumentError:<tab><tab><tab>pass",0,"if optname . startswith ( ""color_"" ) or optname . startswith ( ""disp_"" ) :","if optname == ""default"" :",0.013264132,2.734728085,0.496969697
"def make_relative_to(self, kwds, relative_to):<tab>if relative_to and os.path.dirname(relative_to):<tab><tab>dirname = os.path.dirname(relative_to)<tab><tab>kwds = kwds.copy()<tab><tab>for key in ffiplatform.LIST_OF_FILE_NAMES:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>lst = kwds[key]<tab><tab><tab><tab>if not isinstance(lst, (list, tuple)):<tab><tab><tab><tab><tab>raise TypeError(""keyword '%s' should be a list or tuple"" % (key,))<tab><tab><tab><tab>lst = [os.path.join(dirname, fn) for fn in lst]<tab><tab><tab><tab>kwds[key] = lst<tab>return kwds",1,if key in kwds :,if key in kwds :,0.75,100,1
"def _options_fcheck(self, name, xflags, table):<tab>for entry in table:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if entry.flags & XTOPT_MAND and not xflags & (1 << entry.id):<tab><tab><tab>raise XTablesError(""%s: --%s must be specified"" % (name, entry.name))<tab><tab><tab>if not xflags & (1 << entry.id):<tab><tab><tab><tab>continue",0,if entry . name is None :,if entry . name == name :,0.22111352,36.55552229,0.577777778
"def _load_cmds():<tab>prefix = ""AOE_CMD_""<tab>g = globals()<tab>for k, v in iteritems(g):<tab><tab><IF-STMT><tab><tab><tab>name = ""aoe"" + k[len(prefix) :].lower()<tab><tab><tab>try:<tab><tab><tab><tab>mod = __import__(name, g, level=1)<tab><tab><tab><tab>AOE.set_cmd(v, getattr(mod, name.upper()))<tab><tab><tab>except (ImportError, AttributeError):<tab><tab><tab><tab>continue",1,if k . startswith ( prefix ) :,if k . startswith ( prefix ) :,0.75,100,1
"def test_list_sizes(self):<tab>sizes = self.driver.list_sizes()<tab>self.assertEqual(len(sizes), 7, ""Wrong sizes count"")<tab>for size in sizes:<tab><tab>self.assertTrue(isinstance(size.price, float), ""Wrong size price type"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(size.price, 0, ""Size price should be zero by default"")",0,"if self . driver . api_name == ""openstack"" :",if size . price is not None :,0.016959991,3.433105411,0.185185185
"def testToFileBinary(self):<tab>z = dns.zone.from_file(here(""example""), ""example"")<tab>try:<tab><tab>f = open(here(""example3-binary.out""), ""wb"")<tab><tab>z.to_file(f)<tab><tab>f.close()<tab><tab>ok = compare_files(<tab><tab><tab>""testToFileBinary"", here(""example3-binary.out""), here(""example3.good"")<tab><tab>)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(here(""example3-binary.out""))<tab>self.assertTrue(ok)",1,if not _keep_output :,if not _keep_output :,0.75,100,1
"def ip_list(_):<tab>ips = []<tab>for ip in _.split("" ""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isip(ip):<tab><tab><tab>ips.append(IP.create(ip))<tab><tab>else:<tab><tab><tab>raise TypeError(""ip %s is invalid"" % ip)<tab>return ips",1,if not ip :,if not ip :,0.75,100,1
"def _wait_for_state(self, server_id, state, retries=50):<tab>for i in (0, retries):<tab><tab>server = self.ex_get_server(server_id)<tab><tab>if server.extra[""status""][""state""] == state:<tab><tab><tab>return<tab><tab>sleep(5)<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Retries count reached"")",0,if i == retries :,if i == retries - 1 :,0.368790247,54.10822691,0.771428571
"def _stretch_prev(data):<tab>clip, track, item_id, item_data = data<tab>try:<tab><tab>prev_index = track.clips.index(clip) - 1<tab><tab>if prev_index < 0:<tab><tab><tab>return  # clip is first clip<tab><tab><IF-STMT><tab><tab><tab># Next clip is blank so we can do this.<tab><tab><tab>clip = track.clips[prev_index]<tab><tab><tab>data = (clip, track, item_id, item_data)<tab><tab><tab>_cover_blank_from_next(data, True)<tab>except:<tab><tab>pass  # any error means that this can't be done",0,if track . clips [ prev_index ] . is_blanck_clip == True :,elif prev_index > 0 :,0.008651615,4.730862767,0.126984127
"def characters(self, ch):<tab>if self._inside_fuzzable:<tab><tab>modified_value = self._fuzzed_parameters[self._fuzzable_index][1]<tab><tab><IF-STMT><tab><tab><tab>modified_value = modified_value.get_value()<tab><tab>if self._fuzzed_parameters[self._fuzzable_index][0] == ""base64"":<tab><tab><tab>enc_val = base64.b64encode(modified_value)<tab><tab>else:<tab><tab><tab>enc_val = cgi.escape(modified_value).encode(""ascii"", ""xmlcharrefreplace"")<tab><tab>self.fuzzed_xml_string += enc_val<tab>else:<tab><tab>self.fuzzed_xml_string += ch",0,"if isinstance ( modified_value , DataToken ) :","if hasattr ( modified_value , ""get_value"" ) :",0.091668085,31.61487584,0.381818182
"def _make_sure_scheduler_ready(self, timeout=120):<tab>check_start_time = time.time()<tab>while True:<tab><tab>workers_meta = self._scheduler_service._resource_ref.get_workers_meta()<tab><tab><IF-STMT><tab><tab><tab># wait for worker to report status<tab><tab><tab>self._pool.sleep(0.5)<tab><tab><tab>if time.time() - check_start_time > timeout:  # pragma: no cover<tab><tab><tab><tab>raise TimeoutError(""Check worker ready timed out."")<tab><tab>else:<tab><tab><tab>break",0,if not workers_meta :,"if not workers_meta [ ""ready"" ] :",0.150739765,36.7205627,1
"def tiles_around(self, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab>if nx >= 0 and nx < self.width:<tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if predicate is None or predicate((nx, ny)):<tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",0,if ny >= 0 and ny < self . height and ( dx != 0 or dy != 0 ) :,if ny >= 0 and ny < self . height :,0.533689244,33.97268275,0.589393939
"def tearDown(self):<tab>for i in ScriptVersion.objects.all():<tab><tab>name = i.script_path.name<tab><tab>utils.get_storage().delete(name)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>utils.get_storage(local=False).delete(name)<tab><tab><tab>except WindowsError:<tab><tab><tab><tab>print(""unable to delete {}"".format(name))<tab><tab>name += ""c""  # handle pyc junk<tab><tab>try:<tab><tab><tab>utils.get_storage().delete(name)<tab><tab>except WindowsError:<tab><tab><tab>print(""unable to delete {}"".format(name))<tab>super(ScriptTearDown, self).tearDown()",0,if wooey_settings . WOOEY_EPHEMERAL_FILES :,if i . is_local :,0.286540249,5.244835935,0.619047619
"def _fill_tc_results(self):<tab>tids = list(self.tc._results.keys())<tab>fields = [""failures"", ""errors"", ""skipped"", ""expectedFailures""]<tab>for tid in tids:<tab><tab>result = self.tc._results[tid]<tab><tab>for field in fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tc._results[field] = []<tab><tab><tab>self.tc._results[field].extend(result[field])",0,if not field in self . tc . _results :,if field not in self . tc . _results :,0.599267103,73.48889201,0.714285714
"def check_mixin_inheritance(bases):<tab>for b in bases:<tab><tab>check_mixin_inheritance(b.__bases__)<tab><tab>for k, v in vars(b).items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_type_info[k] = _process_item(v)",0,"if _is_interesting ( k , v ) :",if k not in _type_info :,0.019830745,5.708765135,0.481481481
"def _check_params(swa_freq):<tab>params = [swa_freq]<tab>params_none = [param is None for param in params]<tab>if not all(params_none) and any(params_none):<tab><tab>warnings.warn(""Some of swa_start, swa_freq is None, ignoring other"")<tab>for i, param in enumerate(params):<tab><tab><IF-STMT><tab><tab><tab>params[i] = int(param)<tab><tab><tab>warnings.warn(""Casting swa_start, swa_freq to int"")<tab>return not any(params_none), params",0,"if param is not None and not isinstance ( param , int ) :",if param is not None :,0.298000153,20.96310881,0.54985755
"def findBookmark(self, bookmark, root=None):<tab>if root == None:<tab><tab>root = self.bookmarks<tab>for i, b in enumerate(root):<tab><tab>if isinstance(b, list):<tab><tab><tab>res = self.findBookmark(bookmark, b)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return [i] + res<tab><tab>elif b == bookmark or b[""/Title""] == bookmark:<tab><tab><tab>return [i]<tab>return None",1,if res :,if res :,0.531170663,1.00E-10,1
"def best_match(self, matches, default=None):<tab>best_quality = -1<tab>result = default<tab>for server_item in matches:<tab><tab>for client_item, quality in self:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>if self._value_matches(server_item, client_item) and quality > 0:<tab><tab><tab><tab>best_quality = quality<tab><tab><tab><tab>result = server_item<tab>return result",0,if quality <= best_quality :,if quality > best_quality :,0.331415021,42.38365628,1
"def validate_external_users(self):<tab>if self.user and settings.ALLOW_OAUTH2_FOR_EXTERNAL_USERS is False:<tab><tab>external_account = get_external_account(self.user)<tab><tab><IF-STMT><tab><tab><tab>raise oauth2.AccessDeniedError(<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""OAuth2 Tokens cannot be created by users associated with an external authentication provider ({})""<tab><tab><tab><tab>).format(external_account)<tab><tab><tab>)",0,if external_account is not None :,if not external_account :,0.082335674,25.74526462,0.333333333
def get_tzname(self):<tab># Timezone conversions must happen to the input datetime *before*<tab># applying a function. 2015-12-31 23:00:00 -02:00 is stored in the<tab># database as 2016-01-01 01:00:00 +00:00. Any results should be<tab># based on the input datetime not the stored datetime.<tab>tzname = None<tab>if settings.USE_TZ:<tab><tab><IF-STMT><tab><tab><tab>tzname = timezone.get_current_timezone_name()<tab><tab>else:<tab><tab><tab>tzname = timezone._get_timezone_name(self.tzinfo)<tab>return tzname,1,if self . tzinfo is None :,if self . tzinfo is None :,0.75,100,1
"def _get_editable_fields(cls):<tab>fds = set([])<tab>for field in cls._meta.concrete_fields:<tab><tab>if hasattr(field, ""attname""):<tab><tab><tab>if field.attname == ""id"":<tab><tab><tab><tab>continue<tab><tab><tab>elif field.attname.endswith(""ptr_id""):<tab><tab><tab><tab># polymorphic fields should always be non-editable, see:<tab><tab><tab><tab># https://github.com/django-polymorphic/django-polymorphic/issues/349<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fds.add(field.attname)<tab>return fds",0,"if getattr ( field , ""editable"" , True ) :","elif field . attname . startswith ( ""editable"" ) :",0.026929164,17.24222129,0.125
"def p_advsimd_secondary(val, va, mnem, opcode, flags, opers):<tab>if opcode == INS_VORR:<tab><tab>src1 = (val >> 16) & 0xF<tab><tab>src2 = (val) & 0xF<tab><tab><IF-STMT><tab><tab><tab>opers = (<tab><tab><tab><tab>ArmRegOper(rctx.getRegisterIndex(rbase % d)),<tab><tab><tab><tab>ArmRegOper(rctx.getRegisterIndex(rbase % n)),<tab><tab><tab>)<tab><tab><tab>return ""vmov"", INS_VMOV, None, opers<tab>return None, None, None, None",1,if src1 == src2 :,if src1 == src2 :,0.75,100,1
"def list_urls(self):<tab>for idx, job in enumerate(self.urlwatcher.jobs):<tab><tab><IF-STMT><tab><tab><tab>print(""%d: %s"" % (idx + 1, repr(job)))<tab><tab>else:<tab><tab><tab>pretty_name = job.pretty_name()<tab><tab><tab>location = job.get_location()<tab><tab><tab>if pretty_name != location:<tab><tab><tab><tab>print(""%d: %s ( %s )"" % (idx + 1, pretty_name, location))<tab><tab><tab>else:<tab><tab><tab><tab>print(""%d: %s"" % (idx + 1, pretty_name))<tab>return 0",0,if self . urlwatch_config . verbose :,if self . verbose :,0.202045404,28.70956432,1
"def _split_auth_string(auth_string):<tab>""""""split a digest auth string into individual key=value strings""""""<tab>prev = None<tab>for item in auth_string.split("",""):<tab><tab>try:<tab><tab><tab>if prev.count('""') == 1:<tab><tab><tab><tab>prev = ""%s,%s"" % (prev, item)<tab><tab><tab><tab>continue<tab><tab>except AttributeError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>prev = item<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>raise StopIteration<tab><tab>yield prev.strip()<tab><tab>prev = item<tab>yield prev.strip()<tab>raise StopIteration",0,if prev == None :,if prev is None :,0.081415021,24.73692954,0.533333333
"def _get_user_auth_session_cookie(self, url, username, password):<tab>get_response = requests.get(url)<tab># auth request to kfp server with istio dex look like '/dex/auth/local?req=REQ_VALUE'<tab>if ""auth"" in get_response.url:<tab><tab>credentials = {""login"": username, ""password"": password}<tab><tab># Authenticate user<tab><tab>session = requests.Session()<tab><tab>session.post(get_response.url, data=credentials)<tab><tab>cookie_auth_key = ""authservice_session""<tab><tab>cookie_auth_value = session.cookies.get(cookie_auth_key)<tab><tab><IF-STMT><tab><tab><tab>return cookie_auth_key + ""="" + cookie_auth_value",1,if cookie_auth_value :,if cookie_auth_value :,0.531170663,1.00E-10,1
"def copychunked(src, dest):<tab>chunksize = 524288  # half a meg of bytes<tab>fsrc = src.open(""rb"")<tab>try:<tab><tab>fdest = dest.open(""wb"")<tab><tab>try:<tab><tab><tab>while 1:<tab><tab><tab><tab>buf = fsrc.read(chunksize)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab><tab>fdest.write(buf)<tab><tab>finally:<tab><tab><tab>fdest.close()<tab>finally:<tab><tab>fsrc.close()",1,if not buf :,if not buf :,0.75,100,1
"def iterate_all_python_files(base_path):<tab># TODO support ignored directories/files<tab>for dirname, subdirlist, filelist in os.walk(base_path):<tab><tab>if ""__pycache__"" in dirname:<tab><tab><tab>continue<tab><tab>for filename in filelist:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield os.path.join(base_path, dirname, filename)",1,"if filename . endswith ( "".py"" ) :","if filename . endswith ( "".py"" ) :",0.75,100,1
"def discover(self, *objlist):<tab>ret = []<tab>for l in self.splitlines():<tab><tab>if l[0] != ""intr"":<tab><tab><tab>continue<tab><tab>for name, i in enumerate(l[2:]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret.append(str(name))<tab>return ret",0,if int ( i ) > 10 :,if i in objlist :,0.019199657,7.715486568,0.285714286
"def call_url(self, expected_url, with_error=False):<tab>try:<tab><tab>with self.best_url_selector.select_best_url() as url:<tab><tab><tab>self.assertEqual(urlparse(expected_url), url)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise RequestException(""error connecting to {}"".format(url))<tab>except RequestException:<tab><tab>pass",1,if with_error :,if with_error :,0.531170663,1.00E-10,1
"def __init__(self, action_space=None, network=None, network_kwargs=None, hparams=None):<tab>PolicyNetBase.__init__(self, hparams=hparams)<tab>with tf.variable_scope(self.variable_scope):<tab><tab><IF-STMT><tab><tab><tab>action_space = Space(low=0, high=self._hparams.action_space, dtype=np.int32)<tab><tab>self._action_space = action_space<tab><tab>self._append_output_layer()",1,if action_space is None :,if action_space is None :,0.75,100,1
"def gettempfilename(suffix):<tab>""""""Returns a temporary filename""""""<tab>if ""_"" in os.environ:<tab><tab># tempfile.mktemp() crashes on some Wine versions (the one of Ubuntu 12.04 particularly)<tab><tab>if os.environ[""_""].find(""wine"") >= 0:<tab><tab><tab>tmpdir = "".""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tmpdir = os.environ[""TMP""]<tab><tab><tab>import time<tab><tab><tab>import random<tab><tab><tab>random.seed(time.time())<tab><tab><tab>random_part = ""file%d"" % random.randint(0, 1000000000)<tab><tab><tab>return os.path.join(tmpdir, random_part + suffix)<tab>return tempfile.mktemp(suffix)",1,"if ""TMP"" in os . environ :","if ""TMP"" in os . environ :",0.75,100,1
"def get_url(self):<tab>if self.url_patterns:<tab><tab>v_url = match1(self.html, *self.url_patterns)<tab><tab><IF-STMT><tab><tab><tab>v_url = compact_unquote(v_url)<tab><tab>self.v_url = [v_url]",0,"if v_url . startswith ( ""http%3A"" ) :",if v_url :,0.030705693,1.00E-10,0.641025641
"def drain(self, fd):<tab>""""""Make `fd` unreadable.""""""<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab>except OSError:<tab><tab><tab>e = sys.exc_info()[1]<tab><tab><tab>if e.args[0] == errno.EAGAIN:<tab><tab><tab><tab>return<tab><tab><tab>raise",0,"if not os . read ( fd , 4096 ) :","if self . _fd . write ( fd , 1 ) == 0 :",0.051709792,11.25132974,0.181818182
"def tearDown(self):<tab># make sure all of the subprocesses are dead<tab>for pidfile in self.pidfiles:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>with open(pidfile) as f:<tab><tab><tab>pid = f.read()<tab><tab>if not pid:<tab><tab><tab>return<tab><tab>pid = int(pid)<tab><tab>try:<tab><tab><tab>os.kill(pid, signal.SIGKILL)<tab><tab>except OSError:<tab><tab><tab>pass<tab># and clean up leftover pidfiles<tab>for pidfile in self.pidfiles:<tab><tab>if os.path.exists(pidfile):<tab><tab><tab>os.unlink(pidfile)<tab>self.tearDownBasedir()",0,if not os . path . exists ( pidfile ) :,if os . path . exists ( pidfile ) :,0.407499005,81.76129039,0.272727273
"def main():<tab># Arguments<tab>input_fname, out_fname = sys.argv[1:]<tab># Do conversion.<tab>index = Indexes()<tab>offset = 0<tab>reader_wrapper = GFFReaderWrapper(fileinput.FileInput(input_fname), fix_strand=True)<tab>for feature in list(reader_wrapper):<tab><tab># Add feature; index expects BED coordinates.<tab><tab><IF-STMT><tab><tab><tab>convert_gff_coords_to_bed(feature)<tab><tab><tab>index.add(feature.chrom, feature.start, feature.end, offset)<tab><tab># Always increment offset, even if feature is not an interval and hence<tab><tab># not included in the index.<tab><tab>offset += feature.raw_size<tab>index.write(open(out_fname, ""wb""))",0,"if isinstance ( feature , GenomicInterval ) :","if isinstance ( feature , GFF ) :",0.549040681,59.46035575,0.666666667
"def _s_wise_max(a_indices, a_indptr, vals, out_max):<tab>n = len(out_max)<tab>for i in range(n):<tab><tab><IF-STMT><tab><tab><tab>m = a_indptr[i]<tab><tab><tab>for j in range(a_indptr[i] + 1, a_indptr[i + 1]):<tab><tab><tab><tab>if vals[j] > vals[m]:<tab><tab><tab><tab><tab>m = j<tab><tab><tab>out_max[i] = vals[m]",0,if a_indptr [ i ] != a_indptr [ i + 1 ] :,if a_indptr [ i ] in a_indices :,0.194468277,35.53699145,0.522807018
"def update_encryption_keys(self, options):<tab>if not options[""pools""] and not options[""datasets""]:<tab><tab>raise CallError(""Please specify pools/datasets to update"")<tab>async with ENCRYPTION_CACHE_LOCK:<tab><tab>keys = await self.encryption_keys()<tab><tab>for pool in options[""pools""]:<tab><tab><tab>keys[""geli""][pool[""name""]] = pool[""passphrase""]<tab><tab>for dataset in options[""datasets""]:<tab><tab><tab>keys[""zfs""][dataset[""name""]] = dataset[""passphrase""]<tab><tab>await self.middleware.call(""cache.put"", ""failover_encryption_keys"", keys)<tab><tab><IF-STMT><tab><tab><tab>await self.sync_keys_to_remote_node(lock=False)",0,"if options [ ""sync_keys"" ] :","if options [ ""remote"" ] :",0.378267095,38.94003915,1
"def set_lineno(self, lineno, override=False):<tab>""""""Set the line numbers of the node and children.""""""<tab>todo = deque([self])<tab>while todo:<tab><tab>node = todo.popleft()<tab><tab>if ""lineno"" in node.attributes:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>node.lineno = lineno<tab><tab>todo.extend(node.iter_child_nodes())<tab>return self",0,if node . lineno is None or override :,"if override and node . attributes [ ""lineno"" ] == lineno :",0.136287328,6.917184228,0.190909091
"def is_ArAX_implicit(ii):  # allows one implicit fixed reg<tab>a, implicit_fixed = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab><IF-STMT><tab><tab><tab>a += 1<tab><tab>elif op_reg(op) and op_implicit_specific_reg(op):<tab><tab><tab>implicit_fixed += 1<tab><tab>else:<tab><tab><tab>return False<tab>return a == 1 and implicit_fixed <= 1",0,"if op_luf_start ( op , ""ArAX"" ) :",if op_arAX ( op ) :,0.046109016,14.27196681,1
"def __iter__(self):<tab>if hasattr(self, ""error_dict""):<tab><tab>for field, errors in self.error_dict.items():<tab><tab><tab>yield field, list(ValidationError(errors))<tab>else:<tab><tab>for error in self.error_list:<tab><tab><tab>message = error.message<tab><tab><tab><IF-STMT><tab><tab><tab><tab>message %= error.params<tab><tab><tab>yield force_text(message)",1,if error . params :,if error . params :,0.75,100,1
"def _mul_matrix(self, other):<tab>if isinstance(other, ConstantDiagLazyTensor):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Dimension Mismatch: Must have same diag_shape, but got ""<tab><tab><tab><tab>f""{self.diag_shape} and {other.diag_shape}""<tab><tab><tab>)<tab><tab>return self.__class__(<tab><tab><tab>self.diag_values * other.diag_values, diag_shape=self.diag_shape<tab><tab>)<tab>return super()._mul_matrix(other)",0,if not self . diag_shape == other . diag_shape :,if self . diag_shape != other . diag_shape :,0.499759172,66.46817937,0.384615385
"def test_no_metadata_when_py_is_pep8(py_file):<tab>""""""This test assumes that all Python files in the jupytext folder follow PEP8 rules""""""<tab>nb = read(py_file)<tab>for i, cell in enumerate(nb.cells):<tab><tab><IF-STMT><tab><tab><tab>cell.metadata.pop(""title"")  # pragma: no cover<tab><tab>if i == 0 and not cell.source:<tab><tab><tab>assert cell.metadata == {""lines_to_next_cell"": 0}, py_file<tab><tab>else:<tab><tab><tab>assert not cell.metadata, (py_file, cell.source)",1,"if ""title"" in cell . metadata :","if ""title"" in cell . metadata :",0.75,100,1
"def forward(self, x: Tensor, edge_index: Adj) -> Tensor:<tab>""""""""""""<tab>if self.add_self_loops:<tab><tab><IF-STMT><tab><tab><tab>edge_index, _ = remove_self_loops(edge_index)<tab><tab><tab>edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(self.node_dim))<tab><tab>elif isinstance(edge_index, SparseTensor):<tab><tab><tab>edge_index = set_diag(edge_index)<tab>x_norm = F.normalize(x, p=2.0, dim=-1)<tab># propagate_type: (x: Tensor, x_norm: Tensor)<tab>return self.propagate(edge_index, x=x, x_norm=x_norm, size=None)",0,"if isinstance ( edge_index , Tensor ) :","if isinstance ( edge_index , Adj ) :",0.549040681,70.71067812,0.6
"def should_wait(self, offer_hash: str):<tab>with self._lock:<tab><tab>if self._offer_hash is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>logger.debug(<tab><tab><tab><tab><tab>""already processing another offer (%s vs %s)"",<tab><tab><tab><tab><tab>self._offer_hash,<tab><tab><tab><tab><tab>offer_hash,<tab><tab><tab><tab>)<tab><tab><tab><tab>return True<tab><tab><tab>if self._started == self._wtct_num_subtasks:<tab><tab><tab><tab>logger.info(""all subtasks for `%s` have been started"", self._offer_hash)<tab><tab><tab><tab>return True<tab><tab>return False",0,if self . _offer_hash != offer_hash :,if self . _offer_hash == offer_hash :,0.496272831,76.11606003,1
"def _wrap_linespans(self, inner):<tab>s = self.linespans<tab>i = self.linenostart - 1<tab>for t, line in inner:<tab><tab><IF-STMT><tab><tab><tab>i += 1<tab><tab><tab>yield 1, '<span id=""%s-%d"">%s</span>' % (s, i, line)<tab><tab>else:<tab><tab><tab>yield 0, line",1,if t :,if t :,0.531170663,1.00E-10,1
"def onRemoteResponse(self, response, request_info):<tab>if isinstance(response, (dict,)):<tab><tab><IF-STMT><tab><tab><tab>msg = ""Celery echo: %s\nElapsed Time: %d""<tab><tab><tab>self.setText(msg % (response[""echo""], self.wait_cnt))<tab><tab>else:<tab><tab><tab>msg = ""Waiting for Celery (id, checkno): %s, %d""<tab><tab><tab>Label.setText(self, msg % (self.task_id, self.wait_cnt))<tab>else:<tab><tab>self.setText(""Could not get remote response as a dictionary"")",1,"if ""echo"" in response :","if ""echo"" in response :",0.75,100,1
"def Visit_expr_stmt(self, node):  # pylint: disable=invalid-name<tab># expr_stmt ::= testlist_star_expr (augassign (yield_expr|testlist)<tab>#<tab><tab><tab>   | ('=' (yield_expr|testlist_star_expr))*)<tab>for child in node.children:<tab><tab>self.Visit(child)<tab><tab><IF-STMT><tab><tab><tab>_AppendTokenSubtype(child, format_token.Subtype.ASSIGN_OPERATOR)",1,"if isinstance ( child , pytree . Leaf ) and child . value == ""="" :","if isinstance ( child , pytree . Leaf ) and child . value == ""="" :",1,100,1
"def _list_outputs(self):<tab>outputs = self.output_spec().get()<tab>isHeader = True<tab>for key in self._outfields:<tab><tab>outputs[key] = []  # initialize outfields<tab>with open(self.inputs.in_file, ""r"") as fid:<tab><tab>for line in fid.readlines():<tab><tab><tab><IF-STMT>  # skip header line<tab><tab><tab><tab>isHeader = False<tab><tab><tab><tab>continue<tab><tab><tab>entry = self._parse_line(line)<tab><tab><tab>outputs = self._append_entry(outputs, entry)<tab>return outputs",0,if self . inputs . header and isHeader :,if isHeader :,0.024814633,1.00E-10,0.228571429
"def _get_tables(self, schema):<tab>cursor = self._get_cursor()<tab>schemas = self.configuration.get(<tab><tab>""schemas"", self.configuration.get(""database"", """")<tab>).split("","")<tab>for schema_name in schemas:<tab><tab>cursor.columns(schema=schema_name)<tab><tab>for column in cursor:<tab><tab><tab>table_name = ""{}.{}"".format(column[1], column[2])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>schema[table_name] = {""name"": table_name, ""columns"": []}<tab><tab><tab>schema[table_name][""columns""].append(column[3])<tab>return list(schema.values())",1,if table_name not in schema :,if table_name not in schema :,0.75,100,1
"def __setitem__(self, index, value):<tab>if self._physics.is_dirty and not self._triggers_dirty:<tab><tab>self._physics.forward()<tab>super(_SynchronizingArrayWrapper, self).__setitem__(index, value)<tab>if isinstance(self._backing_index, collections.Iterable):<tab><tab><IF-STMT><tab><tab><tab>resolved_index = (self._backing_index[index[0]],) + index[1:]<tab><tab>else:<tab><tab><tab>resolved_index = self._backing_index[index]<tab><tab>self._backing_array[resolved_index] = value<tab>if self._triggers_dirty:<tab><tab>self._physics.mark_as_dirty()",0,"if isinstance ( index , tuple ) :",if index [ 0 ] in self . _backing_index :,0.017150255,4.065425429,0.238636364
"def fit_test_data(self, data, fit_values, imputer_value):<tab>for j in range(len(data)):<tab><tab>for i in range(len(data[j])):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[j][i] = str(fit_values[i])<tab>return data",0,if data [ j ] [ i ] in imputer_value :,if fit_values [ j ] [ i ] > imputer_value [ i ] :,0.351401204,35.41296817,0.435672515
"def Compare_in(t, x):<tab>if not isinstance(x.ops[0], (ast.NotIn, ast.In)):<tab><tab>return<tab>if t.enable_snippets:<tab><tab>from ..snippets import _in, in_es6<tab><tab>if t.enable_es6:<tab><tab><tab>t.add_snippet(in_es6)<tab><tab><tab>sname = ""in_es6""<tab><tab>else:<tab><tab><tab>t.add_snippet(_in)<tab><tab><tab>sname = ""_in""<tab><tab>result = JSCall(JSAttribute(""_pj"", sname), [x.left, x.comparators[0]])<tab><tab><IF-STMT><tab><tab><tab>result = JSUnaryOp(JSOpNot(), result)<tab><tab>return result",0,"if isinstance ( x . ops [ 0 ] , ast . NotIn ) :","if isinstance ( x . comparators [ 0 ] , ast . Not ) :",0.556457836,61.04735836,0.6
"def __init__(self, f):<tab>self._refs = {}<tab>self._peeled = {}<tab>for line in f.readlines():<tab><tab>sha, name = line.rstrip(b""\n"").split(b""\t"")<tab><tab>if name.endswith(ANNOTATED_TAG_SUFFIX):<tab><tab><tab>name = name[:-3]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._peeled[name] = sha<tab><tab>else:<tab><tab><tab>if not check_ref_format(name):<tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._refs[name] = sha",1,if not check_ref_format ( name ) :,if not check_ref_format ( name ) :,0.75,100,1
"def info(args):<tab># Check grammar<tab>p = Python37Parser()<tab>if len(args) > 0:<tab><tab>arg = args[0]<tab><tab><IF-STMT><tab><tab><tab>from uncompyle6.parser.parse37 import Python37Parser<tab><tab><tab>p = Python37Parser()<tab><tab>elif arg == ""3.8"":<tab><tab><tab>from uncompyle6.parser.parse38 import Python38Parser<tab><tab><tab>p = Python38Parser()<tab><tab>else:<tab><tab><tab>raise RuntimeError(""Only 3.7 and 3.8 supported"")<tab>p.check_grammar()<tab>if len(sys.argv) > 1 and sys.argv[1] == ""dump"":<tab><tab>print(""-"" * 50)<tab><tab>p.dump_grammar()",1,"if arg == ""3.7"" :","if arg == ""3.7"" :",0.75,100,1
"def test_ESPnetDataset_text_float(text_float):<tab>dataset = IterableESPnetDataset(<tab><tab>path_name_type_list=[(text_float, ""data8"", ""text_float"")],<tab><tab>preprocess=preprocess,<tab>)<tab>for key, data in dataset:<tab><tab>if key == ""a"":<tab><tab><tab>assert all((data[""data8""]) == np.array([1.4, 3.4], dtype=np.float32))<tab><tab><IF-STMT><tab><tab><tab>assert all((data[""data8""]) == np.array([0.9, 9.3], dtype=np.float32))",0,"if key == ""b"" :","elif key == ""b"" :",0.311522644,84.08964153,0.5
"def getting(self, key, lock=False):<tab>if not lock:<tab><tab>yield self.get(key)<tab>else:<tab><tab>locked = False<tab><tab>try:<tab><tab><tab>data = self._get_or_lock(key)<tab><tab><tab>locked = data is None<tab><tab><tab>yield data<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._release_lock(key)",1,if locked :,if locked :,0.531170663,1.00E-10,1
"def mkdir(self, path, parents=True, raise_if_exists=False):<tab>if self.exists(path):<tab><tab><IF-STMT><tab><tab><tab>raise luigi.target.NotADirectory()<tab><tab>elif raise_if_exists:<tab><tab><tab>raise luigi.target.FileAlreadyExists()<tab><tab>else:<tab><tab><tab>return<tab>self.conn.files_create_folder_v2(path)",0,if not self . isdir ( path ) :,if parents :,0.075630314,1.00E-10,0.246753247
"def _get_initiated_elections(cls, height, txns):<tab>elections = []<tab>for tx in txns:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elections.append(<tab><tab><tab>{""election_id"": tx.id, ""height"": height, ""is_concluded"": False}<tab><tab>)<tab>return elections",0,"if not isinstance ( tx , Election ) :",if tx . is_concluded :,0.016838046,6.495032985,0.287878788
"def recalc_active(self, ts):<tab>if not self.active_seconds:<tab><tab>self.active_seconds.append(ts)<tab><tab>self.data[ts] = {}<tab>if ts not in self.active_seconds:<tab><tab><IF-STMT><tab><tab><tab>for i in range(max(self.active_seconds) + 1, ts + 1):<tab><tab><tab><tab>self.active_seconds.append(i)<tab><tab><tab><tab>self.active_seconds.sort()<tab><tab><tab><tab>self.data[i] = {}<tab>while len(self.active_seconds) > self.window:<tab><tab>self.active_seconds.pop(0)<tab>for sec in self.data.keys():<tab><tab>if sec not in self.active_seconds:<tab><tab><tab>self.data.pop(sec)",0,if ts > max ( self . active_seconds ) :,if self . active_seconds :,0.059382557,32.73762387,0.371428571
"def get_scalar_base(schema, scalar) -> Tuple[str, ...]:<tab>base = base_type_name_map.get(scalar.id)<tab>if base is not None:<tab><tab>return base<tab>for ancestor in scalar.get_ancestors(schema).objects(schema):<tab><tab><IF-STMT><tab><tab><tab># Check if base is fundamental, if not, then it is<tab><tab><tab># another domain.<tab><tab><tab>try:<tab><tab><tab><tab>base = base_type_name_map[ancestor.id]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>base = common.get_backend_name(schema, ancestor, catenate=False)<tab><tab><tab>return base<tab>raise ValueError(<tab><tab>f""cannot determine backend type for scalar type "" f""{scalar.get_name(schema)}""<tab>)",0,if not ancestor . get_is_abstract ( schema ) :,if ancestor . is_domain ( schema ) :,0.18845666,27.08099698,0.381818182
def __next__(self):<tab>try:<tab><tab>value = next(self._iterable)<tab><tab><IF-STMT><tab><tab><tab>self.start()<tab><tab>else:<tab><tab><tab>self.update(self.value + 1)<tab><tab>return value<tab>except StopIteration:<tab><tab>self.finish()<tab><tab>raise<tab>except GeneratorExit:  # pragma: no cover<tab><tab>self.finish(dirty=True)<tab><tab>raise,0,if self . start_time is None :,if self . value is None :,0.38848939,30.89575775,0.466666667
"def change_password(username=""flexget"", password="""", session=None):<tab>check = zxcvbn.zxcvbn(password, user_inputs=[username])<tab>if check[""score""] < 3:<tab><tab>warning = check[""feedback""][""warning""]<tab><tab>suggestions = "" "".join(check[""feedback""][""suggestions""])<tab><tab>message = ""Password '{}' is not strong enough. "".format(password)<tab><tab><IF-STMT><tab><tab><tab>message += warning + "" ""<tab><tab>if suggestions:<tab><tab><tab>message += ""Suggestions: {}"".format(suggestions)<tab><tab>raise WeakPassword(message)<tab>user = get_user(username=username, session=session)<tab>user.password = str(generate_password_hash(password))<tab>session.commit()",1,if warning :,if warning :,0.531170663,1.00E-10,1
"def _options_fcheck(self, name, xflags, table):<tab>for entry in table:<tab><tab>if entry.name is None:<tab><tab><tab>break<tab><tab>if entry.flags & XTOPT_MAND and not xflags & (1 << entry.id):<tab><tab><tab>raise XTablesError(""%s: --%s must be specified"" % (name, entry.name))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue",0,if not xflags & ( 1 << entry . id ) :,elif entry . flags & XTOPT_DENIED and xflags & ( 1 << entry . id ) :,0.524016913,51.08636943,0.09
"def parse_ports(container_name, connection_configuration):<tab>while True:<tab><tab>ports_command = docker_util.build_docker_simple_command(<tab><tab><tab>""port"", container_name=container_name, **connection_configuration<tab><tab>)<tab><tab>with tempfile.TemporaryFile(prefix=""docker_port_"") as stdout_file:<tab><tab><tab>exit_code = subprocess.call(<tab><tab><tab><tab>ports_command, shell=True, stdout=stdout_file, preexec_fn=os.setpgrp<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>stdout_file.seek(0)<tab><tab><tab><tab>ports_raw = stdout_file.read().decode(""utf-8"")<tab><tab><tab><tab>return ports_raw",1,if exit_code == 0 :,if exit_code == 0 :,0.75,100,1
"def _init_ti_table():<tab>global _ti_table<tab>_ti_table = []<tab>for fname, name in zip(kc.STRFNAMES, kc.STRNAMES):<tab><tab>seq = termcap.get(name)<tab><tab>if not seq:<tab><tab><tab>continue<tab><tab>k = _name_to_key(fname)<tab><tab><IF-STMT><tab><tab><tab>_ti_table.append((list(bytearray(seq)), k))",0,if k :,if k is not None :,0.090364769,1.00E-10,0.4
"def sanitize_args(a):<tab>try:<tab><tab>args, kwargs = a<tab><tab>if isinstance(args, tuple) and isinstance(kwargs, dict):<tab><tab><tab>return args, dict(kwargs)<tab>except (TypeError, ValueError):<tab><tab>args, kwargs = (), {}<tab>if a is not None:<tab><tab><IF-STMT><tab><tab><tab>args = tuple()<tab><tab><tab>kwargs = a<tab><tab>elif isinstance(a, tuple):<tab><tab><tab>if isinstance(a[-1], dict):<tab><tab><tab><tab>args, kwargs = a[0:-1], a[-1]<tab><tab><tab>else:<tab><tab><tab><tab>args = a<tab><tab><tab><tab>kwargs = {}<tab>return args, kwargs",0,"if isinstance ( a , dict ) :","if isinstance ( a , tuple ) :",0.549040681,59.46035575,0.666666667
"def fork_with_import_lock(level):<tab>release = 0<tab>in_child = False<tab>try:<tab><tab>try:<tab><tab><tab>for i in range(level):<tab><tab><tab><tab>imp.acquire_lock()<tab><tab><tab><tab>release += 1<tab><tab><tab>pid = os.fork()<tab><tab><tab>in_child = not pid<tab><tab>finally:<tab><tab><tab>for i in range(release):<tab><tab><tab><tab>imp.release_lock()<tab>except RuntimeError:<tab><tab>if in_child:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""RuntimeError in child"")<tab><tab><tab>os._exit(1)<tab><tab>raise<tab>if in_child:<tab><tab>os._exit(0)<tab>self.wait_impl(pid)",0,if verbose > 1 :,if i % 10 == 0 :,0.111303188,6.567274736,0.265306122
"def _capture_hub(self, create):<tab># Subclasses should call this as the first action from any<tab># public method that could, in theory, block and switch<tab># to the hub. This may release the GIL.<tab>if self.hub is None:<tab><tab># This next line might release the GIL.<tab><tab>current_hub = get_hub() if create else get_hub_if_exists()<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab># We have the GIL again. Did anything change? If so,<tab><tab># we lost the race.<tab><tab>if self.hub is None:<tab><tab><tab>self.hub = current_hub",1,if current_hub is None :,if current_hub is None :,0.75,100,1
"def get_user_makepkg_path(cls) -> Optional[str]:<tab>if cls._user_makepkg_path == ""unset"":<tab><tab>possible_paths = [<tab><tab><tab>os.path.expanduser(""~/.makepkg.conf""),<tab><tab><tab>os.path.join(CONFIG_ROOT, ""pacman/makepkg.conf""),<tab><tab>]<tab><tab>config_path: Optional[str] = None<tab><tab>for path in possible_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>config_path = path<tab><tab>cls._user_makepkg_path = config_path<tab>return cls._user_makepkg_path",0,if os . path . exists ( path ) :,if config_path is None :,0.013468036,5.630400553,0.261904762
"def createValue(self):<tab>mode = []<tab>for name in self._text_keys:<tab><tab><IF-STMT><tab><tab><tab>if 4 <= len(mode):<tab><tab><tab><tab>mode.append(""..."")<tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>mode.append(name)<tab>if mode:<tab><tab>return "", "".join(mode)<tab>else:<tab><tab>return ""(none)""",0,if self [ name ] . value :,"if name == ""text"" :",0.019907918,7.267884212,0.36
"def keyPressEvent(self, event):<tab>if event.key() in (Qt.Key_Right, Qt.Key_Left):<tab><tab>direction = 1<tab><tab>if event.key() == Qt.Key_Left:<tab><tab><tab>direction = -1<tab><tab><IF-STMT><tab><tab><tab>print(""shift"")<tab><tab><tab>direction *= 10<tab><tab>self.timeline.setValue(self.timeline.value() + direction)<tab>else:<tab><tab>super(VideoPlayerWidget, self).keyPressEvent(event)",0,if event . modifiers ( ) == Qt . ShiftModifier :,elif event . key ( ) == Qt . Key_Right :,0.200830885,40.52587697,0.365384615
"def validate_wrapper(*args, **kwargs):<tab>result = self.validate_func(*args, **kwargs)<tab>if request.is_xhr:<tab><tab><IF-STMT><tab><tab><tab>result = {}<tab><tab>result.setdefault(""success"", True)<tab><tab>values = result.get(""values"", {})<tab><tab>for key, value in tmpl_context.form_values.iteritems():<tab><tab><tab>values.setdefault(key, value)<tab>return result",1,"if not isinstance ( result , dict ) :","if not isinstance ( result , dict ) :",0.75,100,1
"def copy_metadata_to(self, target_dir):<tab>prefix = os.path.join(self.egg_info, """")<tab>for path in self.ei_cmd.filelist.files:<tab><tab><IF-STMT><tab><tab><tab>target = os.path.join(target_dir, path[len(prefix) :])<tab><tab><tab>ensure_directory(target)<tab><tab><tab>self.copy_file(path, target)",1,if path . startswith ( prefix ) :,if path . startswith ( prefix ) :,0.75,100,1
"def _get_switch_info(self, cmd_list):<tab>stdout, stderr, sw_data = None, None, None<tab>try:<tab><tab>stdout, stderr = self._run_ssh(cmd_list, True)<tab><tab>LOG.debug(""CLI output from ssh - output: %s"", stdout)<tab><tab><IF-STMT><tab><tab><tab>sw_data = stdout.splitlines()<tab><tab>return sw_data<tab>except processutils.ProcessExecutionError as e:<tab><tab>msg = _(<tab><tab><tab>""Error while getting data via ssh: (command=%(cmd)s "" ""error=%(err)s).""<tab><tab>) % {""cmd"": cmd_list, ""err"": six.text_type(e)}<tab><tab>LOG.error(msg)<tab><tab>raise exception.CiscoZoningCliException(reason=msg)",1,if stdout :,if stdout :,0.531170663,1.00E-10,1
"def analyze(vw):<tab>for va, dest in vw.findPointers():<tab><tab># Is there a location already at the target?<tab><tab>loc = vw.getLocation(dest)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab>if loc[L_LTYPE] != LOC_IMPORT:<tab><tab><tab>continue<tab><tab>offset, bytes = vw.getByteDef(va)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if bytes[offset - 2 : offset] == b""\xff\x15"":  # call [importloc]<tab><tab><tab># If there's a pointer here, remove it.<tab><tab><tab>if vw.getLocation(va):<tab><tab><tab><tab>vw.delLocation(va)<tab><tab><tab>vw.makeCode(va - 2)",0,if offset < 2 :,if offset is None :,0.064978772,23.64354023,0.444444444
"def _freeze_stages(self):<tab>""""""Freeze parameters.""""""<tab>if self.frozen_stages >= 0:<tab><tab><IF-STMT><tab><tab><tab>self.stem.eval()<tab><tab><tab>for param in self.stem.parameters():<tab><tab><tab><tab>param.requires_grad = False<tab><tab>else:<tab><tab><tab>self.norm1.eval()<tab><tab><tab>for m in [self.conv1, self.norm1]:<tab><tab><tab><tab>for param in m.parameters():<tab><tab><tab><tab><tab>param.requires_grad = False<tab>for i in range(1, self.frozen_stages + 1):<tab><tab>m = getattr(self, f""layer{i}"")<tab><tab>m.eval()<tab><tab>for param in m.parameters():<tab><tab><tab>param.requires_grad = False",0,if self . deep_stem :,if self . stem is not None :,0.193606478,23.35689889,0.357142857
"def seek(self, timestamp, log=True):<tab>""""""Seek to a particular timestamp in the movie.""""""<tab>if self.status in [PLAYING, PAUSED]:<tab><tab>player = self._player<tab><tab>if player and player.is_seekable():<tab><tab><tab>player.set_time(int(timestamp * 1000.0))<tab><tab><tab>self._vlc_clock.reset(timestamp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._pause_time = timestamp<tab><tab>if log:<tab><tab><tab>logAttrib(self, log, ""seek"", timestamp)",0,if self . status == PAUSED :,if self . _pause_time is None :,0.090565314,16.78445963,0.428571429
"def foundNestedPseudoClass(self):<tab>i = self.pos + 1<tab>openParen = 0<tab>while i < len(self.source_text):<tab><tab>ch = self.source_text[i]<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif ch == ""("":<tab><tab><tab># pseudoclasses can contain ()<tab><tab><tab>openParen += 1<tab><tab>elif ch == "")"":<tab><tab><tab>if openParen == 0:<tab><tab><tab><tab>return False<tab><tab><tab>openParen -= 1<tab><tab>elif ch == "";"" or ch == ""}"":<tab><tab><tab>return False<tab><tab>i += 1<tab>return False",0,"if ch == ""{"" :","if ch == ""\\"" :",0.394778655,51.3345048,1
"def update(events):<tab>if failsToWriteToIDClasses():<tab><tab>print(""Skip event: cannot write to ID classes"")<tab><tab>return<tab>if didNameChange() or events.intersection({""File"", ""Addon"", ""Tree""}):<tab><tab>updateEverything()<tab>if problems.canAutoExecute():<tab><tab>nodeTrees = list(iterAutoExecutionNodeTrees(events))<tab><tab><IF-STMT><tab><tab><tab>setupExecutionUnits()<tab><tab><tab>executeNodeTrees(nodeTrees)<tab><tab><tab>afterExecution()<tab><tab><tab>finishExecutionUnits()",0,if len ( nodeTrees ) > 0 :,if nodeTrees :,0.01726708,1.00E-10,0.36
"def check_all_verified(self):<tab>if not self.all_verified:<tab><tab>new_all_verified = not self.lines.filter(verified=False).exists()<tab><tab><IF-STMT><tab><tab><tab>self.all_verified = True<tab><tab><tab>if self.require_verification:<tab><tab><tab><tab>self.add_log_entry(<tab><tab><tab><tab><tab>_(""All rows requiring verification have been verified."")<tab><tab><tab><tab>)<tab><tab><tab><tab>self.require_verification = False<tab><tab><tab>self.save()<tab>return self.all_verified",1,if new_all_verified :,if new_all_verified :,0.531170663,1.00E-10,1
"def parse_for(cls, tagname, parser, bits, options):<tab>if bits:<tab><tab><IF-STMT><tab><tab><tab>bits.pop(0)<tab><tab><tab>if len(bits):<tab><tab><tab><tab>options[""for""] = Variable(bits.pop(0))<tab><tab><tab>else:<tab><tab><tab><tab>raise TemplateSyntaxError(<tab><tab><tab><tab><tab>""%s: expected an argument "" 'after ""for"".' % tagname<tab><tab><tab><tab>)<tab><tab>elif not cls.optional_for_parameter:<tab><tab><tab>raise TemplateSyntaxError(<tab><tab><tab><tab>""Unknown argument for %s tag: %r."" % (tagname, bits[0])<tab><tab><tab>)",0,"if bits [ 0 ] == ""for"" :",if len ( bits ) == 1 :,0.020373037,9.600960275,0.314814815
"def _get_cuda_device(*args):<tab># Returns cuda.Device or DummyDevice.<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>check_cuda_available()<tab><tab><tab>return Device(arg)<tab><tab>if isinstance(arg, ndarray):<tab><tab><tab>if arg.device is None:<tab><tab><tab><tab>continue<tab><tab><tab>return arg.device<tab><tab>if available and isinstance(arg, Device):<tab><tab><tab>return arg<tab># NOTE: This function returns DummyDevice for both NumPy and ChainerX<tab>return DummyDevice",0,"if type ( arg ) is not bool and isinstance ( arg , _integer_types ) :","if isinstance ( arg , cuda . Device ) :",0.094636707,13.20001239,0.222222222
"def while1_test(a, b, c):<tab>while 1:<tab><tab>if a != 2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>a = 3<tab><tab><tab><tab>b = 0<tab><tab><tab>elif c:<tab><tab><tab><tab>c = 0<tab><tab><tab>else:<tab><tab><tab><tab>a += b + c<tab><tab><tab><tab>break<tab>return a, b, c",1,if b :,if b :,0.531170663,1.00E-10,1
"def write_notes(self, family, father, mother):<tab># FIXME:<tab># if self.restrict and self.exclnotes:<tab>#<tab>return<tab>self.write_note_of_person(father)<tab>self.write_note_of_person(mother)<tab>child_ref_list = family.get_child_ref_list()<tab>if child_ref_list:<tab><tab>for child_ref in child_ref_list:<tab><tab><tab>child = self.db.get_person_from_handle(child_ref.ref)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.write_note_of_person(child)",1,if child :,if child :,0.531170663,1.00E-10,1
"def GetFile(cls, session, sig, mode=""r""):<tab>sig = sig[: cls.HASH_LEN]<tab>while len(sig) > 0:<tab><tab>fn = cls.SaveFile(session, sig)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (open(fn, mode), sig)<tab><tab>except (IOError, OSError):<tab><tab><tab>pass<tab><tab>if len(sig) > 1:<tab><tab><tab>sig = sig[:-1]<tab><tab>else:<tab><tab><tab>if ""r"" in mode:<tab><tab><tab><tab>return (None, sig)<tab><tab><tab>else:<tab><tab><tab><tab>return (open(fn, mode), sig)<tab># Not reached<tab>return (None, None)",0,if os . path . exists ( fn ) :,"if ""r"" in mode :",0.013468036,5.087641221,0.229166667
"def _generate_expression(self):<tab># turn my _format attribute into the _expression attribute<tab>e = []<tab>for part in PARSE_RE.split(self._format):<tab><tab>if not part:<tab><tab><tab>continue<tab><tab>elif part == ""{{"":<tab><tab><tab>e.append(r""\{"")<tab><tab>elif part == ""}}"":<tab><tab><tab>e.append(r""\}"")<tab><tab><IF-STMT><tab><tab><tab># this will be a braces-delimited field to handle<tab><tab><tab>e.append(self._handle_field(part))<tab><tab>else:<tab><tab><tab># just some text to match<tab><tab><tab>e.append(REGEX_SAFETY.sub(self._regex_replace, part))<tab>return """".join(e)",0,"elif part [ 0 ] == ""{"" and part [ - 1 ] == ""}"" :","elif part . endswith ( "";"" ) :",0.013175556,3.178403219,0.362318841
"def get_cfg_dict(self, with_meta=True):<tab>options_dict = self.merged_options<tab>if with_meta:<tab><tab><IF-STMT><tab><tab><tab>options_dict.update(<tab><tab><tab><tab>{""package"": ""yandextank.plugins.{}"".format(self.plugin)}<tab><tab><tab>)<tab><tab>if self.enabled is not None:<tab><tab><tab>options_dict.update({""enabled"": self.enabled})<tab>return options_dict",0,if self . plugin :,if self . plugin is not None :,0.351498834,36.55552229,0.510204082
"def __str__(self):<tab>_outicalfile = self._icalfile<tab>for unit in self.units:<tab><tab>for location in unit.getlocations():<tab><tab><tab>match = re.match(""\\[(?P<uid>.+)\\](?P<property>.+)"", location)<tab><tab><tab>for component in self._icalfile.components():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>if component.uid.value != match.groupdict()[""uid""]:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>for property in component.getChildren():<tab><tab><tab><tab><tab>if property.name == match.groupdict()[""property""]:<tab><tab><tab><tab><tab><tab>property.value = unit.target<tab>if _outicalfile:<tab><tab>return str(_outicalfile.serialize())<tab>else:<tab><tab>return """"",0,"if component . name != ""VEVENT"" :",if not match :,0.022826396,4.238556456,0.333333333
"def process_events(self, events):<tab>for event in events:<tab><tab>key = (event.ident, event.filter)<tab><tab>if event.ident == self._force_wakeup_fd:<tab><tab><tab>self._force_wakeup.drain()<tab><tab><tab>continue<tab><tab>receiver = self._registered[key]<tab><tab><IF-STMT><tab><tab><tab>del self._registered[key]<tab><tab>if type(receiver) is _core.Task:<tab><tab><tab>_core.reschedule(receiver, outcome.Value(event))<tab><tab>else:<tab><tab><tab>receiver.put_nowait(event)",0,if event . flags & select . KQ_EV_ONESHOT :,if receiver is None :,0.015736078,2.564755813,0.25
"def forward(self, start=True, search=False, target=None, include_current=False):<tab>""""""Move one step forward in the history.""""""<tab>if target is None:<tab><tab>target = self.saved_line<tab>if self.index > 1:<tab><tab><IF-STMT><tab><tab><tab>self.index -= self.find_partial_match_forward(target, include_current)<tab><tab>elif start:<tab><tab><tab>self.index -= self.find_match_forward(target, include_current)<tab><tab>else:<tab><tab><tab>self.index -= 1<tab><tab>return self.entry<tab>else:<tab><tab>self.index = 0<tab><tab>return self.saved_line",1,if search :,if search :,0.531170663,1.00E-10,1
"def _charlabels(self, options):<tab>""""""Get labels for characters (PRIVATE).""""""<tab>self.charlabels = {}<tab>opts = CharBuffer(options)<tab>while True:<tab><tab># get id and state<tab><tab>w = opts.next_word()<tab><tab>if w is None:  # McClade saves and reads charlabel-lists with terminal comma?!<tab><tab><tab>break<tab><tab>identifier = self._resolve(w, set_type=CHARSET)<tab><tab>state = quotestrip(opts.next_word())<tab><tab>self.charlabels[identifier] = state<tab><tab># check for comma or end of command<tab><tab>c = opts.next_nonwhitespace()<tab><tab>if c is None:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>raise NexusError(""Missing ',' in line %s."" % options)",0,"elif c != "","" :","if c == "","" :",0.062871671,54.10822691,0.5
"def _get_cloudstorage_bucket_iam_member_bindings(self, raw_bucket):<tab>bucket_iam_policy = raw_bucket.iam_policy<tab>member_bindings = {}<tab>if bucket_iam_policy:<tab><tab>for binding in bucket_iam_policy._bindings:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for member in binding[""members""]:<tab><tab><tab><tab><tab>if member not in member_bindings:<tab><tab><tab><tab><tab><tab>member_bindings[member] = [binding[""role""]]<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>member_bindings[member].append(binding[""role""])<tab>return member_bindings",0,"if ""legacy"" not in binding [ ""role"" ] :","if ""members"" in binding :",0.031533007,8.723697148,0.381818182
"def _gen():<tab>for i in dataset():<tab><tab>if isinstance(i, tuple) or isinstance(i, list):<tab><tab><tab>if fn(*i) is True:<tab><tab><tab><tab>yield i<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield i",1,if fn ( i ) is True :,if fn ( i ) is True :,0.75,100,1
"def set_img_to_eval_imgs(self, scores, img_ids, method):<tab>for img_id, score in zip(img_ids, scores):<tab><tab><IF-STMT><tab><tab><tab>self.img_to_eval[img_id] = dict()<tab><tab><tab>self.img_to_eval[img_id][""image_id""] = img_id<tab><tab>self.img_to_eval[img_id][method] = score",1,if img_id not in self . img_to_eval :,if img_id not in self . img_to_eval :,0.75,100,1
"def _compute_totals(self):<tab>totals = {}<tab>for entry in self.entries:<tab><tab>for k, v in entry.nutrition_information.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>totals[k] = v<tab><tab><tab>else:<tab><tab><tab><tab>totals[k] += v<tab>self._totals = totals",1,if k not in totals :,if k not in totals :,0.75,100,1
"def analyzeFunction(vw, funcva):<tab>for fromva, tova, rtype, rflags in vw.getXrefsFrom(funcva, v_const.REF_CODE):<tab><tab># You goin NOWHERE!<tab><tab>loc = vw.getLocation(tova)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab># FIXME this could check for thunks to other known function pointers...<tab><tab>va, size, ltype, linfo = loc<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>vw.makeFunctionThunk(funcva, linfo)",0,if ltype != v_const . LOC_IMPORT :,if ltype != v_const . THunk :,0.574113272,64.06914384,0.722222222
"def clear_output_directory(self):<tab>files = os.listdir(os.path.join(""functional"", ""output""))<tab>for f in files:<tab><tab><IF-STMT><tab><tab><tab>continue  # don't touch the infrastructure<tab><tab>path = os.path.join(""functional"", ""output"", f)<tab><tab>if os.path.isdir(path):<tab><tab><tab>shutil.rmtree(path)<tab><tab>else:<tab><tab><tab>os.remove(path)",0,"if f in ( ""README.txt"" , "".svn"" , ""CVS"" ) :","if not f . endswith ( "".py"" ) :",0.026197311,10.12941493,0.322222222
"def test_output_files_as_none_string(self):<tab>for name in ""Output"", ""Report"", ""Log"", ""XUnit"", ""DebugFile"":<tab><tab>attr = (name[:-4] if name.endswith(""File"") else name).lower()<tab><tab>settings = RobotSettings({name.lower(): ""NoNe""})<tab><tab>assert_equals(settings[name], None)<tab><tab><IF-STMT><tab><tab><tab>assert_equals(getattr(settings, attr), None)",1,"if hasattr ( settings , attr ) :","if hasattr ( settings , attr ) :",0.75,100,1
def is_rotated(box_list):<tab>if type(box_list) == np.ndarray:<tab><tab>return box_list.shape[1] == 5<tab>elif type(box_list) == list:<tab><tab><IF-STMT>  # cannot decide the box_dim<tab><tab><tab>return False<tab><tab>return np.all(<tab><tab><tab>np.array(<tab><tab><tab><tab>[<tab><tab><tab><tab><tab>(len(obj) == 5)<tab><tab><tab><tab><tab>and ((type(obj) == list) or (type(obj) == np.ndarray))<tab><tab><tab><tab><tab>for obj in box_list<tab><tab><tab><tab>]<tab><tab><tab>)<tab><tab>)<tab>return False,0,if box_list == [ ] :,if len ( box_list ) == 0 :,0.024927243,19.08165456,0.458333333
"def visit_loop(self):<tab>v = self.vS.top_front()<tab>i = self.iS.top_front()<tab>num_edges = len(self.graph[v].edges)<tab># Continue traversing out-edges until none left.<tab>while i <= num_edges:<tab><tab># Continuation<tab><tab><IF-STMT><tab><tab><tab># Update status for previously traversed out-edge<tab><tab><tab>self.finish_edge(v, i - 1)<tab><tab>if i < num_edges and self.begin_edge(v, i):<tab><tab><tab>return<tab><tab>i += 1<tab># Finished traversing out edges, update component info<tab>self.finish_visiting(v)",0,if i > 0 :,"if self . graph [ v ] . edges [ i - 1 ] . status == ""completed"" :",0.105546119,2.273154357,0.181481481
"def GetConvertersByClass(value_cls):<tab>""""""Returns all converters that take given value as an input value.""""""<tab>try:<tab><tab>return ExportConverter.converters_cache[value_cls]<tab>except KeyError:<tab><tab>results = [<tab><tab><tab>cls<tab><tab><tab>for cls in ExportConverter.classes.values()<tab><tab><tab>if cls.input_rdf_type == value_cls<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>results = [DataAgnosticExportConverter]<tab><tab>ExportConverter.converters_cache[value_cls] = results<tab><tab>return results",1,if not results :,if not results :,0.75,100,1
"def migrate_Context(self):<tab>for old_obj in self.session_old.query(self.model_from[""Context""]):<tab><tab>new_obj = self.model_to[""Context""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab>if key not in old_obj.__table__.columns._data.keys():<tab><tab><tab><tab>continue<tab><tab><tab>value = getattr(old_obj, key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = 0<tab><tab><tab>setattr(new_obj, key, value)<tab><tab>self.session_new.add(new_obj)",0,"if key == ""tip_timetolive"" and value < 0 :",if value is None :,0.016838046,2.323859896,0.236111111
"def _bind_to(self, url, bind):<tab>""""""Bind to a Connectable in the caller's thread.""""""<tab>if isinstance(bind, util.string_types + (url.URL,)):<tab><tab>try:<tab><tab><tab>self.context._engine = self.__engines[bind]<tab><tab>except KeyError:<tab><tab><tab>e = sqlalchemy.create_engine(bind)<tab><tab><tab>self.__engines[bind] = e<tab><tab><tab>self.context._engine = e<tab>else:<tab><tab># TODO: this is squirrely.  we shouldn't have to hold onto engines<tab><tab># in a case like this<tab><tab><IF-STMT><tab><tab><tab>self.__engines[bind] = bind<tab><tab>self.context._engine = bind",1,if bind not in self . __engines :,if bind not in self . __engines :,0.75,100,1
"def _gen_Less(self, args, ret_type):<tab>result = []<tab>for lhs, rhs in pairwise(args):<tab><tab><IF-STMT><tab><tab><tab>result.append(self.builder.fcmp_ordered(""<"", lhs, rhs))<tab><tab>elif ret_type == int_type:<tab><tab><tab>result.append(self.builder.icmp_signed(""<"", lhs, rhs))<tab><tab>else:<tab><tab><tab>raise CompileError()<tab>return reduce(self.builder.and_, result)",1,if ret_type == real_type :,if ret_type == real_type :,0.75,100,1
"def _store_pickle_output(self, pickle_output):<tab>if pickle_output:<tab><tab><IF-STMT><tab><tab><tab>self.error(""Can't use without --output"", ""pickle-output"")<tab><tab>elif not load_pytd.is_pickle(self.output_options.output):<tab><tab><tab>self.error(<tab><tab><tab><tab>""Must specify %s file for --output"" % load_pytd.PICKLE_EXT,<tab><tab><tab><tab>""pickle-output"",<tab><tab><tab>)<tab>self.output_options.pickle_output = pickle_output",1,if self . output_options . output is None :,if self . output_options . output is None :,0.75,100,1
"def resolve_identifier(self, identifier):<tab>if "":"" in identifier:<tab><tab>conn, pn = identifier.split("":"")<tab><tab><IF-STMT><tab><tab><tab>pn = int(pn)<tab><tab>return self.resolve_identifier(self.connector_table[conn][pn])<tab>else:<tab><tab>return identifier",0,if pn . isdigit ( ) :,if conn in self . connector_table :,0.022864977,6.274655311,0.265306122
"def add_braces_and_labels(self):<tab>for attr in ""horizontal_parts"", ""vertical_parts"":<tab><tab>if not hasattr(self, attr):<tab><tab><tab>continue<tab><tab>parts = getattr(self, attr)<tab><tab>for subattr in ""braces"", ""labels"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add(getattr(parts, subattr))",1,"if hasattr ( parts , subattr ) :","if hasattr ( parts , subattr ) :",0.75,100,1
"def on_janitor_selection_changed(self, selection):<tab>model, iter = selection.get_selected()<tab>if iter:<tab><tab><IF-STMT><tab><tab><tab>iter = self.janitor_model.iter_children(iter)<tab><tab>plugin = model[iter][self.JANITOR_PLUGIN]<tab><tab>for row in self.result_model:<tab><tab><tab>if row[self.RESULT_PLUGIN] == plugin:<tab><tab><tab><tab>self.result_view.get_selection().select_path(row.path)<tab><tab><tab><tab>log.debug(""scroll_to_cell: %s"" % row.path)<tab><tab><tab><tab>self.result_view.scroll_to_cell(row.path)",0,if self . janitor_model . iter_has_child ( iter ) :,if self . janitor_model . iter_children ( iter ) :,0.580308871,67.83686169,1
"def canonical_standard_headers(self, headers):<tab>interesting_headers = [""content-md5"", ""content-type"", ""date""]<tab>hoi = []<tab>if ""Date"" in headers:<tab><tab>del headers[""Date""]<tab>headers[""Date""] = self._get_date()<tab>for ih in interesting_headers:<tab><tab>found = False<tab><tab>for key in headers:<tab><tab><tab>lk = key.lower()<tab><tab><tab>if headers[key] is not None and lk == ih:<tab><tab><tab><tab>hoi.append(headers[key].strip())<tab><tab><tab><tab>found = True<tab><tab><IF-STMT><tab><tab><tab>hoi.append("""")<tab>return ""\n"".join(hoi)",1,if not found :,if not found :,0.75,100,1
"def boolean(value):<tab>if isinstance(value, str):<tab><tab>v = value.lower()<tab><tab>if v in (""1"", ""yes"", ""true"", ""on""):<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>raise ValueError(value)<tab>return bool(value)",0,"if v in ( ""0"" , ""no"" , ""false"" , ""off"" ) :","elif v in ( ""0"" , ""false"" , ""off"" ) :",0.318553698,73.90718666,0.6
"def get_extension_for_class(self, extclass):<tab>if extclass is UnrecognizedExtension:<tab><tab>raise TypeError(<tab><tab><tab>""UnrecognizedExtension can't be used with ""<tab><tab><tab>""get_extension_for_class because more than one instance of the""<tab><tab><tab>"" class may be present.""<tab><tab>)<tab>for ext in self:<tab><tab><IF-STMT><tab><tab><tab>return ext<tab>raise ExtensionNotFound(""No {} extension was found"".format(extclass), extclass.oid)",0,"if isinstance ( ext . value , extclass ) :",if ext . oid == extclass . oid :,0.079205697,10.55267032,0.285714286
"def sysargs_to_mainargs():<tab>""""""builds main args from sys.argv""""""<tab>relative_out_dir = None<tab>if len(sys.argv) > 1 and sys.argv[1].startswith(""--""):<tab><tab>a = sys.argv.pop(1)<tab><tab><IF-STMT><tab><tab><tab>print(__doc__)<tab><tab><tab>sys.exit(1)<tab><tab>elif a.startswith(""--reldir=""):<tab><tab><tab>relative_out_dir = a[len(""--reldir="") :]<tab><tab>else:<tab><tab><tab>print(""*** Error, Unknown option:"", a)<tab><tab><tab>print(__doc__)<tab><tab><tab>sys.exit(1)<tab>other_session = sys.argv[1]<tab>return relative_out_dir, other_session",0,"if a . startswith ( ""--help"" ) :","if a == ""--help"" :",0.037304456,21.06976474,0.727272727
"def _scanDirectory(self, dirIter, f):<tab>while len(f) < 250:<tab><tab>try:<tab><tab><tab>info = next(dirIter)<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise EOFError<tab><tab><tab>return f<tab><tab>if isinstance(info, defer.Deferred):<tab><tab><tab>info.addCallback(self._cbScanDirectory, dirIter, f)<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>f.append(info)<tab>return f",0,if not f :,if len ( dirIter ) == 0 :,0.034692192,5.669791111,0.26984127
"def register_options(config_block):<tab>for name in common_block:<tab><tab>safe_declare_common_option(config_block, name)<tab><tab><IF-STMT><tab><tab><tab>config_block.get(name).declare_as_argument()",0,if config_block . get ( name ) . _argparse is None :,if config_block . get ( name ) is not None :,0.367718902,61.47866169,0.703296703
"def _loc(obj):<tab>try:<tab><tab>fn = getattr(obj, ""__file__"", None)<tab><tab><IF-STMT><tab><tab><tab>return "" @%s"" % (fn,)<tab><tab>obj = getattr(obj, ""im_func"", obj)<tab><tab>code = getattr(obj, ""__code__"", None)<tab><tab>if code is not None:<tab><tab><tab>return "" @%s:%s"" % (code.co_filename, code.co_firstlineno)<tab>except Exception:<tab><tab>pass<tab>return """"",1,if fn is not None :,if fn is not None :,0.75,100,1
"def _remove_temporary_files(self, temporary_files):<tab>""""""Internal function for cleaning temporary files""""""<tab>for file_object in temporary_files:<tab><tab>file_name = file_object.name<tab><tab>file_object.close()<tab><tab><IF-STMT><tab><tab><tab>os.remove(file_name)<tab><tab>arff_file_name = file_name + "".arff""<tab><tab>if os.path.exists(arff_file_name):<tab><tab><tab>os.remove(arff_file_name)",1,if os . path . exists ( file_name ) :,if os . path . exists ( file_name ) :,0.75,100,1
"def show(self):<tab>""""""Overrides Qt Method""""""<tab>QWidget.show(self)<tab>self.emit(SIGNAL(""visibility_changed(bool)""), True)<tab>if self.editor is not None:<tab><tab>text = self.editor.get_selected_text()<tab><tab><IF-STMT><tab><tab><tab>self.search_text.setEditText(text)<tab><tab><tab>self.search_text.lineEdit().selectAll()<tab><tab><tab>self.refresh()<tab><tab>else:<tab><tab><tab>self.search_text.lineEdit().selectAll()<tab><tab>self.search_text.setFocus()",0,if len ( text ) > 0 :,if text :,0.01726708,1.00E-10,0.36
"def flush_input() -> None:<tab>if not self.is_done:<tab><tab># Get keys, and feed to key processor.<tab><tab>keys = self.input.flush_keys()<tab><tab>self.key_processor.feed_multiple(keys)<tab><tab>self.key_processor.process_keys()<tab><tab><IF-STMT><tab><tab><tab>f.set_exception(EOFError)",0,if self . input . closed :,if self . is_done :,0.157032291,26.26909894,0.55
"def get_default_taxes_and_charges(master_doctype, tax_template=None, company=None):<tab>if not company:<tab><tab>return {}<tab>if tax_template and company:<tab><tab>tax_template_company = frappe.db.get_value(<tab><tab><tab>master_doctype, tax_template, ""company""<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return<tab>default_tax = frappe.db.get_value(<tab><tab>master_doctype, {""is_default"": 1, ""company"": company}<tab>)<tab>return {<tab><tab>""taxes_and_charges"": default_tax,<tab><tab>""taxes"": get_taxes_and_charges(master_doctype, default_tax),<tab>}",0,if tax_template_company == company :,if tax_template_company and tax_template_company != company :,0.23260718,38.35193624,0.472222222
"def dump_prefs(self):<tab>ret = """"<tab>for pref in self.prefs:<tab><tab>if type(self.prefs[pref].value) == int:<tab><tab><tab>value = str(self.prefs[pref].value)<tab><tab><IF-STMT><tab><tab><tab>value = ""true"" if self.prefs[pref].value == True else ""false""<tab><tab>else:<tab><tab><tab>value = '""%s""' % self.prefs[pref].value<tab><tab>ret += pref + "": "" + value + "" ("" + self.prefs[pref].anon_source + "")\n""<tab>return ret",0,elif type ( self . prefs [ pref ] . value ) == bool :,elif self . prefs [ pref ] . value == bool :,0.291935427,61.65169526,0.242647059
"def dumps(o, **kwargs):<tab>""""""Dumps JSON object.""""""<tab>try:<tab><tab>return _engine[1](o)<tab>except:<tab><tab>ExceptionClass, why = sys.exc_info()[:2]<tab><tab><IF-STMT><tab><tab><tab>raise JSONError(why)<tab><tab>else:<tab><tab><tab>raise why",0,"if any ( [ ( issubclass ( ExceptionClass , e ) ) for e in _engine [ 2 ] ] ) :","if isinstance ( why , JSONError ) :",0.059399192,2.129808374,0.153225806
"def main():<tab>import sys, getopt<tab>try:<tab><tab>opts, args = getopt.getopt(sys.argv[1:], ""ho:"", [""help"", ""output=""])<tab>except getopt.GetoptError as err:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>output = None<tab>for o, a in opts:<tab><tab><IF-STMT><tab><tab><tab>usage()<tab><tab><tab>sys.exit()<tab><tab>elif o in (""-o"", ""--output""):<tab><tab><tab>output = a<tab><tab>else:<tab><tab><tab>usage()<tab><tab><tab>sys.exit(1)<tab>if not args:<tab><tab>usage()<tab><tab>sys.exit(1)<tab>concat_flv(args, output)",1,"if o in ( ""-h"" , ""--help"" ) :","if o in ( ""-h"" , ""--help"" ) :",0.75,100,1
"def close_group(self):<tab>""""""Closes a grouping for previous filters""""""<tab>if self._filters:<tab><tab>if len(self._open_group_flag) < (len(self._close_group_flag) + 1):<tab><tab><tab>raise RuntimeError(""Not enough open groups to close."")<tab><tab><IF-STMT><tab><tab><tab>flt_sentence = self._filters[-2]<tab><tab>else:<tab><tab><tab>flt_sentence = self._filters[-1]<tab><tab>flt_sentence[1] = flt_sentence[1] + "")""  # closing the group<tab><tab>self._close_group_flag.append(False)  # flag a close group was added<tab>else:<tab><tab>raise RuntimeError(""No filters present. Can't close a group"")<tab>return self",0,"if isinstance ( self . _filters [ - 1 ] , ChainOperator ) :",if len ( self . _filters ) > 1 :,0.142997309,28.24924702,0.563909774
"def _GetPlugins(self, base_class):<tab>items = []<tab>for name in sorted(base_class.classes.keys()):<tab><tab>cls = base_class.classes[name]<tab><tab># While technically a valid plugin, UnknownOutputPlugin is only used as<tab><tab># a placeholder when unserializing old and now-deleted output plugins.<tab><tab># No need to display it in the UI.<tab><tab>if cls == output_plugin.UnknownOutputPlugin:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>items.append(ApiOutputPluginDescriptor().InitFromOutputPluginClass(cls))<tab>return items",0,if cls . description :,"if isinstance ( cls , ApiOutputPluginDescriptor ) :",0.02800146,7.267884212,0.314814815
"def _set_helper(settings, path, value, data_type=None):<tab>path = _to_settings_path(path)<tab>method = settings.set<tab>if data_type is not None:<tab><tab>name = None<tab><tab>if data_type == bool:<tab><tab><tab>name = ""setBoolean""<tab><tab>elif data_type == float:<tab><tab><tab>name = ""setFloat""<tab><tab>elif data_type == int:<tab><tab><tab>name = ""setInt""<tab><tab><IF-STMT><tab><tab><tab>method = getattr(settings, name)<tab>method(path, value)<tab>settings.save()",1,if name is not None :,if name is not None :,0.75,100,1
"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>iterable = sdict()<tab>for key, values in obj.items():<tab><tab>if not isinstance(values, list):<tab><tab><tab>values = [values]<tab><tab>iterable[key] = values<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, values in iterable.items():<tab><tab>for value in values:<tab><tab><tab>if value is None:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>key = str(key).encode(charset)<tab><tab><tab>if not isinstance(value, bytes):<tab><tab><tab><tab>value = str(value).encode(charset)<tab><tab><tab>yield url_quote_plus(key) + ""="" + url_quote_plus(value)",1,"if not isinstance ( key , bytes ) :","if not isinstance ( key , bytes ) :",0.75,100,1
"def validate_data(self, data, schema):<tab>verrors = ValidationErrors()<tab>provider = data[""provider""]<tab>if provider == ""custom"":<tab><tab>for k in (""custom_ddns_server"", ""custom_ddns_path""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>verrors.add(f""{schema}.{k}"", ""Required when using a custom provider."")<tab>elif provider not in (await self.provider_choices()):<tab><tab>verrors.add(f""{schema}.provider"", ""Please select a valid provider."")<tab>verrors.check()",0,if not data [ k ] :,if k not in self . provider_choices ( ) :,0.082366072,4.789232204,0.272727273
"def render(self):<tab>x = ""<span>""<tab>for idx, arg in enumerate(self.args, start=1):<tab><tab><IF-STMT><tab><tab><tab>value, desc = arg<tab><tab>else:<tab><tab><tab>value, desc = arg, arg<tab><tab>attrs = self.attrs.copy()<tab><tab>attrs[""name""] = self.name<tab><tab>attrs[""type""] = ""radio""<tab><tab>attrs[""value""] = value<tab><tab>attrs[""id""] = self.name + str(idx)<tab><tab>if self.value == value:<tab><tab><tab>attrs[""checked""] = ""checked""<tab><tab>x += ""<input %s/> %s"" % (attrs, net.websafe(desc))<tab>x += ""</span>""<tab>return x",0,"if isinstance ( arg , ( tuple , list ) ) :","if isinstance ( arg , tuple ) :",0.190290135,37.2887864,0.822222222
"def search_rotate(array, val):<tab>low, high = 0, len(array) - 1<tab>while low <= high:<tab><tab>mid = (low + high) // 2<tab><tab><IF-STMT><tab><tab><tab>return mid<tab><tab>if array[low] <= array[mid]:<tab><tab><tab>if array[low] <= val <= array[mid]:<tab><tab><tab><tab>high = mid - 1<tab><tab><tab>else:<tab><tab><tab><tab>low = mid + 1<tab><tab>else:<tab><tab><tab>if array[mid] <= val <= array[high]:<tab><tab><tab><tab>low = mid + 1<tab><tab><tab>else:<tab><tab><tab><tab>high = mid - 1<tab>return -1",0,if val == array [ mid ] :,if array [ mid ] == val :,0.268066808,39.28146509,0.4
"def detect(get_page):<tab>retval = False<tab>for vector in WAF_ATTACK_VECTORS:<tab><tab>page, headers, code = get_page(get=vector)<tab><tab>retval = (<tab><tab><tab>re.search(<tab><tab><tab><tab>r""wangzhan\.360\.cn"", headers.get(""X-Powered-By-360wzb"", """"), re.I<tab><tab><tab>)<tab><tab><tab>is not None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>break<tab>return retval",1,if retval :,if retval :,0.531170663,1.00E-10,1
"def _recalculate(self):<tab># If the parent's path has changed, recalculate _path<tab>parent_path = tuple(self._get_parent_path())  # Make a copy<tab>if parent_path != self._last_parent_path:<tab><tab>spec = self._path_finder(self._name, parent_path)<tab><tab># Note that no changes are made if a loader is returned, but we<tab><tab>#  do remember the new parent path<tab><tab><IF-STMT><tab><tab><tab>if spec.submodule_search_locations:<tab><tab><tab><tab>self._path = spec.submodule_search_locations<tab><tab>self._last_parent_path = parent_path  # Save the copy<tab>return self._path",0,if spec is not None and spec . loader is None :,if spec is not None :,0.345080209,30.93485033,0.555555556
"def _get_directory_item_content(filename, return_binary, encoding):<tab>content = None<tab>if os.path.exists(filename):<tab><tab><IF-STMT><tab><tab><tab>mode = ""rb""<tab><tab><tab>encoding = None<tab><tab>else:<tab><tab><tab>mode = ""r""<tab><tab>with codecs.open(filename, mode, encoding=encoding) as file_obj:<tab><tab><tab>content = file_obj.read()<tab>return content",1,if return_binary :,if return_binary :,0.531170663,1.00E-10,1
"def randint(self, beg, end):<tab>if beg == 1 and end == 10:<tab><tab>self.icnt1_10 += 1<tab><tab><IF-STMT><tab><tab><tab>self.icnt1_10 = 1<tab><tab>return self.RINT1_10[self.icnt1_10 - 1]<tab>if beg == 65 and end == 90:<tab><tab>self.icnt65_90 += 1<tab><tab>if self.icnt65_90 > len(self.RINT65_90):<tab><tab><tab>self.icnt65_90 = 1<tab><tab>return self.RINT65_90[self.icnt65_90 - 1]<tab>raise Exception(""Not implemented"")",1,if self . icnt1_10 > len ( self . RINT1_10 ) :,if self . icnt1_10 > len ( self . RINT1_10 ) :,1,100,1
"def _get_two_devices(self, require_same_type=False):<tab>tpus = extensions.tpu_devices()<tab>if FLAGS.requires_tpu:<tab><tab><IF-STMT><tab><tab><tab>res = tpus<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""This test requires 2 TPU cores but %s are found"" % len(tpus)<tab><tab><tab>)<tab>else:<tab><tab>if len(tpus) == 2:<tab><tab><tab>res = tpus<tab><tab>elif self._hasGPU() and not require_same_type:<tab><tab><tab>res = (""CPU:0"", ""GPU:0"")<tab><tab>else:<tab><tab><tab>res = (""CPU:0"", ""CPU:1"")<tab>return res",1,if len ( tpus ) == 2 :,if len ( tpus ) == 2 :,0.75,100,1
"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab>if i[0] == nto:<tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab>if nfrom.cond == nto:<tab><tab><tab>return ""?""<tab><tab><IF-STMT><tab><tab><tab>return ""True""<tab><tab>elif nfrom.src2 == nto:<tab><tab><tab>return ""False""<tab>return """"",1,elif nfrom . src1 == nto :,elif nfrom . src1 == nto :,1,100,1
"def send_frame_imm(self, frame):<tab># send s_frame<tab>if frame.name == ""s_frame"":<tab><tab>frame.RecvSeq = self.rsn<tab><tab><IF-STMT><tab><tab><tab>gevent.kill(self.t2_caller)<tab><tab>self.telegram_count = 0<tab><tab>response_string = "" "".join(hex(n) for n in frame.build())<tab><tab>logger.info(<tab><tab><tab>""%s <--- s_frame %s  (%s)"", self.address, response_string, self.session_id<tab><tab>)<tab><tab>return self.sock.send(frame.build())",0,if self . t2_caller :,if self . t2_caller is not None :,0.351498834,53.72849659,0.444444444
"def lin2lin(cp, size, size2):<tab>_check_params(len(cp), size)<tab>_check_size(size2)<tab>if size == size2:<tab><tab>return cp<tab>new_len = (len(cp) / size) * size2<tab>result = create_string_buffer(new_len)<tab>for i in range(_sample_count(cp, size)):<tab><tab>sample = _get_sample(cp, size, i)<tab><tab>if size < size2:<tab><tab><tab>sample = sample << (4 * size2 / size)<tab><tab><IF-STMT><tab><tab><tab>sample = sample >> (4 * size / size2)<tab><tab>sample = _overflow(sample, size2)<tab><tab>_put_sample(result, size2, i, sample)<tab>return result.raw",0,elif size > size2 :,elif size < size2 :,0.330342842,30.21375397,1
"def tangent(self, t):<tab>result = np.array([0, 0, 0])<tab>o = self.omega<tab>for i, coeff in enumerate(self.coeffs):<tab><tab>j = i // 2<tab><tab><IF-STMT><tab><tab><tab>result += -(j + 1) * o * coeff * sin((j + 1) * o * t)<tab><tab>else:<tab><tab><tab>result += (j + 1) * o * coeff * cos((j + 1) * o * t)<tab>return result",1,if i % 2 == 0 :,if i % 2 == 0 :,0.75,100,1
"def _run(self):<tab>when_pressed = 0.0<tab>pressed = False<tab>while not self._done.is_set():<tab><tab>now = time.monotonic()<tab><tab><IF-STMT><tab><tab><tab>if GPIO.input(self._channel) == self._expected:<tab><tab><tab><tab>if not pressed:<tab><tab><tab><tab><tab>pressed = True<tab><tab><tab><tab><tab>when_pressed = now<tab><tab><tab><tab><tab>self._trigger(self._pressed_queue, self._pressed_callback)<tab><tab><tab>else:<tab><tab><tab><tab>if pressed:<tab><tab><tab><tab><tab>pressed = False<tab><tab><tab><tab><tab>self._trigger(self._released_queue, self._released_callback)<tab><tab>self._done.wait(0.05)",0,if now - when_pressed > self . _debounce_time :,if now > when_pressed :,0.032892543,12.30079048,0.730769231
"def check_dimensions(nrow, ncol):<tab>if nrow is not None:<tab><tab>if nrow < 1:<tab><tab><tab>warn(<tab><tab><tab><tab>""'nrow' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>nrow = None<tab><tab>else:<tab><tab><tab>nrow = int(nrow)<tab>if ncol is not None:<tab><tab><IF-STMT><tab><tab><tab>warn(<tab><tab><tab><tab>""'ncol' must be greater than 0. "" ""Your value has been ignored."",<tab><tab><tab><tab>PlotnineWarning,<tab><tab><tab>)<tab><tab><tab>ncol = None<tab><tab>else:<tab><tab><tab>ncol = int(ncol)<tab>return nrow, ncol",1,if ncol < 1 :,if ncol < 1 :,0.75,100,1
"def visit_FunctionDef(self, node: ast.FunctionDef) -> None:<tab>""""""Handles FunctionDef node and set context.""""""<tab>if self.current_function is None:<tab><tab>self.add_entry(<tab><tab><tab>node.name<tab><tab>)  # should be called before setting self.current_function<tab><tab><IF-STMT><tab><tab><tab>self.add_final_entry(node.name)<tab><tab>if self.is_overload(node.decorator_list):<tab><tab><tab>self.add_overload_entry(node)<tab><tab>self.context.append(node.name)<tab><tab>self.current_function = node<tab><tab>for child in node.body:<tab><tab><tab>self.visit(child)<tab><tab>self.context.pop()<tab><tab>self.current_function = None",0,if self . is_final ( node . decorator_list ) :,if self . is_final ( node ) :,0.296872327,55.68361006,1
"def ret(stmt, params=()):<tab>match = limit_re.match(stmt)<tab>if match:<tab><tab><IF-STMT><tab><tab><tab>n = params[-1]<tab><tab><tab>params = params[:-1]<tab><tab>else:<tab><tab><tab>n = int(match.group(2))<tab><tab>store.sql(match.group(1), params)<tab><tab>return [store.cursor.fetchone() for i in xrange(n)]<tab>return selectall(stmt, params)",0,"if match . group ( 2 ) == ""?"" :","if match . group ( 1 ) == ""limit"" :",0.485600785,52.66403878,0.666666667
"def OnBodyClick(self, event=None):<tab>try:<tab><tab>c = self.c<tab><tab>p = c.currentPosition()<tab><tab><IF-STMT><tab><tab><tab>self.OnActivateBody(event=event)<tab><tab><tab>c.k.showStateAndMode(w=c.frame.body.bodyCtrl)<tab><tab>g.doHook(""bodyclick2"", c=c, p=p, v=p, event=event)<tab>except:<tab><tab>g.es_event_exception(""bodyclick"")",0,"if not g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :","if g . doHook ( ""bodyclick1"" , c = c , p = p , v = p , event = event ) :",0.824124731,93.20024073,0.366255144
"def verify_settings(rst_path: Path) -> Iterator[Error]:<tab>for setting_name, default in find_settings_in_rst(rst_path):<tab><tab>actual = getattr(app.conf, setting_name)<tab><tab>if isinstance(default, timedelta):<tab><tab><tab>default = default.total_seconds()<tab><tab><IF-STMT><tab><tab><tab>actual = actual.value<tab><tab>if actual != default:<tab><tab><tab>yield Error(<tab><tab><tab><tab>reason=""mismatch"",<tab><tab><tab><tab>setting=setting_name,<tab><tab><tab><tab>default=default,<tab><tab><tab><tab>actual=actual,<tab><tab><tab>)",0,"if isinstance ( actual , Enum ) :","if isinstance ( actual , datetime ) :",0.549040681,59.46035575,0.666666667
"def fromVariant(variant):<tab>if hasattr(QtCore, ""QVariant"") and isinstance(variant, QtCore.QVariant):<tab><tab>t = variant.type()<tab><tab>if t == QtCore.QVariant.String:<tab><tab><tab>return str(variant.toString())<tab><tab>elif t == QtCore.QVariant.Double:<tab><tab><tab>return variant.toDouble()[0]<tab><tab><IF-STMT><tab><tab><tab>return variant.toInt()[0]<tab><tab>elif t == QtCore.QVariant.Bool:<tab><tab><tab>return variant.toBool()<tab><tab>elif t == QtCore.QVariant.Invalid:<tab><tab><tab>return None<tab><tab>else:<tab><tab><tab>raise ValueError('Unsupported QVariant type ""%s""' % variant.typeName())<tab>else:<tab><tab>return variant",1,elif t == QtCore . QVariant . Int :,elif t == QtCore . QVariant . Int :,0.75,100,1
"def decode_list(self, prop, value):<tab>if not isinstance(value, list):<tab><tab>value = [value]<tab>if hasattr(prop, ""item_type""):<tab><tab>item_type = getattr(prop, ""item_type"")<tab><tab>dec_val = {}<tab><tab>for val in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>k, v = self.decode_map_element(item_type, val)<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>k = int(k)<tab><tab><tab><tab>except:<tab><tab><tab><tab><tab>k = v<tab><tab><tab><tab>dec_val[k] = v<tab><tab>value = dec_val.values()<tab>return value",0,if val is not None :,"if isinstance ( val , dict ) :",0.023749772,7.267884212,0.232142857
"def has_valid_checksum(self, number):<tab>given_number, given_checksum = number[:-1], number[-1]<tab>calculated_checksum = 0<tab>parameter = 7<tab>for item in given_number:<tab><tab>fragment = str(int(item) * parameter)<tab><tab>if fragment.isalnum():<tab><tab><tab>calculated_checksum += int(fragment[-1])<tab><tab>if parameter == 1:<tab><tab><tab>parameter = 7<tab><tab><IF-STMT><tab><tab><tab>parameter = 1<tab><tab>elif parameter == 7:<tab><tab><tab>parameter = 3<tab>return str(calculated_checksum)[-1] == given_checksum",1,elif parameter == 3 :,elif parameter == 3 :,1,100,1
"def encoder(s, *args, **kwargs):<tab>r = []<tab>_in = []<tab>for c in s:<tab><tab>if ord(c) in PRINTABLE:<tab><tab><tab>doB64(_in, r)<tab><tab><tab>r.append(c.encode())<tab><tab><IF-STMT><tab><tab><tab>doB64(_in, r)<tab><tab><tab>r.append(b""&-"")<tab><tab>else:<tab><tab><tab>_in.append(c)<tab>doB64(_in, r)<tab>return (b"""".join(r), len(s))",1,"elif c == ""&"" :","elif c == ""&"" :",1,100,1
"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab>if keys is not None and key not in keys:<tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab>if key not in collected_models:<tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab>if attr is None:<tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab><IF-STMT><tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",1,if conv is not None :,if conv is not None :,0.75,100,1
"def try_to_find_osquery(self):<tab>extention = """"<tab><IF-STMT><tab><tab>extention = "".exe""<tab>try:<tab><tab>return resources.get_resource(""osqueryi"" + extention)<tab>except IOError as e:<tab><tab># Maybe it is installed on the system.<tab><tab>if platform.system() == ""Windows"":<tab><tab><tab>result = r""c:\ProgramData\osquery\osqueryi.exe""<tab><tab><tab>if os.access(result, os.R_OK):<tab><tab><tab><tab>return result<tab><tab>else:<tab><tab><tab># Try to find it somewhere on the system.<tab><tab><tab>return spawn.find_executable(""osqueryi"")<tab><tab>raise e",1,"if platform . system ( ) == ""Windows"" :","if platform . system ( ) == ""Windows"" :",0.75,100,1
"def get_cached_stats(self, split=tfds.Split.TRAIN):<tab>""""""Returns basic statistics for cached dataset.""""""<tab>self.assert_cached()<tab>if split not in self._stats:<tab><tab>stats_path = get_stats_path(self.cache_dir, split)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""Stats do not exist for '%s' split: %s"" % (self.name, split)<tab><tab><tab>)<tab><tab>with tf.io.gfile.GFile(stats_path) as f:<tab><tab><tab>self._stats[split] = json.load(f)<tab>return self._stats[split]",0,if not tf . io . gfile . exists ( stats_path ) :,if not os . path . exists ( stats_path ) :,0.286958609,53.69787816,0.325925926
"def _network_connections_in_results(data):<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""device"" not in plugin_result:<tab><tab><tab>continue<tab><tab>if ""connections"" in plugin_result[""device""]:<tab><tab><tab>for conn in plugin_result[""device""][""connections""]:<tab><tab><tab><tab>if conn[""connection_type""] == ConnectionType.network.name:<tab><tab><tab><tab><tab>return True<tab>return False",0,"if plugin_result [ ""status"" ] == ""error"" :","if plugin_name . startswith ( ""_"" ) :",0.018078277,11.67508583,0.641025641
"def register_asyncio_task(self, task, module_path=None):<tab>if self._current[""metadata""] is None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""module_path must be supplied for late-binded tasks"")<tab><tab>else:<tab><tab><tab>self.list[module_path][""asyncio.task""].append(task)<tab>else:<tab><tab>self._current[""asyncio.task""].append(task)",1,if module_path is None :,if module_path is None :,0.75,100,1
"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab>if k in comments:<tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab>if parts[0]:<tab><tab><tab>comments[single] = [parts[0]]<tab><tab><IF-STMT><tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab>if main in comments:<tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",0,if len ( parts ) > 1 :,if parts [ 1 ] :,0.020894909,8.224879649,0.377777778
"def api(request, app):<tab>marker = request.keywords.get(""api"")<tab>bpkwargs = {}<tab>kwargs = {}<tab>if marker:<tab><tab><IF-STMT><tab><tab><tab>bpkwargs[""url_prefix""] = marker.kwargs.pop(""prefix"")<tab><tab>if ""subdomain"" in marker.kwargs:<tab><tab><tab>bpkwargs[""subdomain""] = marker.kwargs.pop(""subdomain"")<tab><tab>kwargs = marker.kwargs<tab>blueprint = Blueprint(""api"", __name__, **bpkwargs)<tab>api = restplus.Api(blueprint, **kwargs)<tab>app.register_blueprint(blueprint)<tab>yield api",0,"if ""prefix"" in marker . kwargs :","if ""url_prefix"" in marker . kwargs :",0.574113272,63.15552372,1
"def _get_pip_index_urls(sources):<tab>index_urls = []<tab>trusted_hosts = []<tab>for source in sources:<tab><tab>url = source.get(""url"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>index_urls.append(url)<tab><tab>if source.get(""verify_ssl"", True):<tab><tab><tab>continue<tab><tab>host = six.moves.urllib.parse.urlparse(source[""url""]).hostname<tab><tab>trusted_hosts.append(host)<tab>return index_urls, trusted_hosts",1,if not url :,if not url :,0.75,100,1
"def add_aggregation_data(self, payload):<tab>for timestamp, payload_data in payload.items():<tab><tab>if ""interval_aggs"" in payload_data:<tab><tab><tab>self.unwrap_interval_buckets(<tab><tab><tab><tab>timestamp, None, payload_data[""interval_aggs""][""buckets""]<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.unwrap_term_buckets(timestamp, payload_data[""bucket_aggs""][""buckets""])<tab><tab>else:<tab><tab><tab>self.check_matches(timestamp, None, payload_data)",1,"elif ""bucket_aggs"" in payload_data :","elif ""bucket_aggs"" in payload_data :",0.75,100,1
"def _handle_unverified_signed_presence(self, pres):<tab>verified = self.verify(pres[""status""], pres[""signed""])<tab>if verified.key_id:<tab><tab>if not self.get_keyid(pres[""from""]):<tab><tab><tab>known_keyids = [e[""keyid""] for e in self.gpg.list_keys()]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.gpg.recv_keys(self.key_server, verified.key_id)<tab><tab><tab>self.set_keyid(jid=pres[""from""], keyid=verified.key_id)<tab><tab>self.xmpp.event(""signed_presence"", pres)",0,if verified . key_id not in known_keyids :,if known_keyids :,0.030705693,1.00E-10,0.345454545
"def __init__(self, *args, **kwargs):<tab>""""""Initialize the texture.""""""<tab>super().__init__(*args, **kwargs)<tab>assert_empty_kwargs(**kwargs)<tab>if len(args) == 1:<tab><tab>if isinstance(args[0], vtk.vtkTexture):<tab><tab><tab>self._from_texture(args[0])<tab><tab>elif isinstance(args[0], np.ndarray):<tab><tab><tab>self._from_array(args[0])<tab><tab>elif isinstance(args[0], vtk.vtkImageData):<tab><tab><tab>self._from_image_data(args[0])<tab><tab><IF-STMT><tab><tab><tab>self._from_file(filename=args[0])<tab><tab>else:<tab><tab><tab>raise TypeError(f""Table unable to be made from ({type(args[0])})"")",1,"elif isinstance ( args [ 0 ] , str ) :","elif isinstance ( args [ 0 ] , str ) :",0.75,100,1
"def get_manifest_data(manifestpath):<tab>""""""Reads a manifest file, returns a dictionary-like object.""""""<tab>plist = {}<tab>try:<tab><tab>plist = FoundationPlist.readPlist(manifestpath)<tab>except FoundationPlist.NSPropertyListSerializationException:<tab><tab>display.display_error(u""Could not read plist: %s"", manifestpath)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>os.unlink(manifestpath)<tab><tab><tab>except OSError as err:<tab><tab><tab><tab>display.display_error(u""Failed to delete plist: %s"", err)<tab><tab>else:<tab><tab><tab>display.display_error(""plist does not exist."")<tab>return plist",1,if os . path . exists ( manifestpath ) :,if os . path . exists ( manifestpath ) :,0.75,100,1
"def _get_proxy(self):<tab>url_dissected = url_dissector.findall(self.session[""proxy""])<tab>if url_dissected and len(url_dissected[0]) == 3:<tab><tab>protocol, host, port = url_dissected[0]<tab><tab><IF-STMT><tab><tab><tab>return (socks.PROXY_TYPE_SOCKS5, host, int(port))<tab><tab>if protocol == ""socks4"":<tab><tab><tab>return (socks.PROXY_TYPE_SOCKS4, host, int(port))<tab><tab>if protocol.startswith(""http""):<tab><tab><tab>return (socks.PROXY_TYPE_HTTP, host, int(port))<tab>return None, None, None",1,"if protocol == ""socks5"" :","if protocol == ""socks5"" :",0.75,100,1
"def nud(self):<tab>self.first = []<tab>comma = False<tab>if self.token.id != "")"":<tab><tab>while 1:<tab><tab><tab>if self.token.id == "")"":<tab><tab><tab><tab>break<tab><tab><tab>self.first.append(self.expression())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>comma = True<tab><tab><tab><tab>self.advance("","")<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>self.advance("")"")<tab>if not self.first or comma:<tab><tab>return self  # tuple<tab>else:<tab><tab>return self.first[0]",1,"if self . token . id == "","" :","if self . token . id == "","" :",0.75,100,1
"def _debug_log(self, text, level):<tab>if text and ""log"" in self.config.sys.debug:<tab><tab>if not text.startswith(self.log_prefix):<tab><tab><tab>text = ""%slog(%s): %s"" % (self.log_prefix, level, text)<tab><tab><IF-STMT><tab><tab><tab>return self.log_parent.log(level, text)<tab><tab>else:<tab><tab><tab>self.term.write(self._fmt_log(text, level=level))",0,if self . log_parent is not None :,if self . log_parent :,0.234334509,54.77927682,0.444444444
"def remove_checker(self, namespace, checker):<tab>for c in pyomo.core.check.ModelCheckRunner._checkers(all=True):<tab><tab>if c._checkerName() == checker:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for i in range(<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].count(c._checkerName())<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>namespace.checkers[c._checkerPackage()].remove(c._checkerName())",0,"if namespace . checkers . get ( c . _checkerPackage ( ) , None ) is not None :",if namespace . checkers . get ( c . _checkerName ( ) ) :,0.323156395,50.11620939,0.648148148
"def check_if_role_exists(self, role_name, parsed_globals):<tab>parameters = {""RoleName"": role_name}<tab>try:<tab><tab>self._call_iam_operation(""GetRole"", parameters, parsed_globals)<tab>except botocore.exceptions.ClientError as e:<tab><tab>role_not_found_code = ""NoSuchEntity""<tab><tab>error_code = e.response.get(""Error"", {}).get(""Code"", """")<tab><tab><IF-STMT><tab><tab><tab># No role error.<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab># Some other error. raise.<tab><tab><tab>raise e<tab>return True",0,if role_not_found_code == error_code :,"if error_code == ""NoSuchEntity"" :",0.038498786,24.08487489,1
"def GetClipboardText():<tab>text = """"<tab>if OpenClipboard(0):<tab><tab>hClipMem = GetClipboardData(CF_TEXT)<tab><tab><IF-STMT><tab><tab><tab>GlobalLock.restype = c_char_p<tab><tab><tab>text = GlobalLock(hClipMem)<tab><tab><tab>GlobalUnlock(hClipMem)<tab><tab>CloseClipboard()<tab>return ensure_unicode(text)",0,if hClipMem :,if hClipMem is not None :,0.090364769,1.00E-10,0.4
"def test_log_action_class():<tab>v = Mock()<tab>for k, v in amo.LOG_BY_ID.items():<tab><tab><IF-STMT><tab><tab><tab>cls = ""action-"" + v.action_class<tab><tab>else:<tab><tab><tab>cls = """"<tab><tab>assert render(""{{ log_action_class(id) }}"", {""id"": v.id}) == cls",0,if v . action_class is not None :,if v . action_class :,0.234334509,54.77927682,0.444444444
"def _get_distinct_albumartists(config, session, web_client, query):<tab>logger.debug(f""Getting distinct albumartists: {query}"")<tab>if query:<tab><tab>search_result = _get_search(config, session, web_client, query, album=True)<tab><tab>return {<tab><tab><tab>artist.name<tab><tab><tab>for album in search_result.albums<tab><tab><tab>for artist in album.artists<tab><tab><tab>if album.artists<tab><tab>}<tab>else:<tab><tab>return {<tab><tab><tab>track.album.artist.name<tab><tab><tab>for track in _get_playlist_tracks(config, session)<tab><tab><tab><IF-STMT><tab><tab>}",0,if track . album and track . album . artist,if track . album,0.190080264,22.31301601,0.488888889
"def _get_commands():<tab>proc = Popen([""react-native"", ""--help""], stdout=PIPE)<tab>should_yield = False<tab>for line in proc.stdout.readlines():<tab><tab>line = line.decode().strip()<tab><tab>if not line:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>should_yield = True<tab><tab><tab>continue<tab><tab>if should_yield:<tab><tab><tab>yield line.split("" "")[0]",0,"if ""Commands:"" in line :","if line . startswith ( ""yield "" ) :",0.026752541,6.274655311,0.4
"def __call__(self, job):<tab>import tensorboard_logger as tl<tab># id = job.id<tab>budget = job.kwargs[""budget""]<tab># config = job.kwargs['config']<tab>timestamps = job.timestamps<tab>result = job.result<tab>exception = job.exception<tab>time_step = int(timestamps[""finished""] - self.start_time)<tab>if result is not None:<tab><tab>tl.log_value(""BOHB/all_results"", result[""loss""] * -1, time_step)<tab><tab><IF-STMT><tab><tab><tab>self.incumbent = result[""loss""]<tab><tab>tl.log_value(""BOHB/incumbent_results"", self.incumbent * -1, time_step)",0,"if result [ ""loss"" ] < self . incumbent :",if exception is not None and self . incumbent is None :,0.055541171,14.32314508,0.14
"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab>if not line or line.startswith(""#""):<tab><tab><tab>continue<tab><tab>if line.startswith(""[""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab>if current_repo and ""="" in line:<tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos",1,if current_repo :,if current_repo :,0.531170663,1.00E-10,1
"def selector():<tab>while True:<tab><tab>rlist, _, _ = select([proc.stdout, proc.stderr], [], [], line_timeout)<tab><tab><IF-STMT><tab><tab><tab>raise ProcessLineTimedOut(<tab><tab><tab><tab>""popen line timeout expired"",<tab><tab><tab><tab>getattr(proc, ""argv"", None),<tab><tab><tab><tab>getattr(proc, ""machine"", None),<tab><tab><tab>)<tab><tab>for stream in rlist:<tab><tab><tab>yield (stream is proc.stderr), decode(stream.readline(linesize))",0,if not rlist and line_timeout :,if line_timeout is not None :,0.279540634,24.44615112,0.285714286
"def getBranchFromFile():<tab>global _gitdir<tab>branch = None<tab>if _gitdir:<tab><tab>headFile = os.path.join(_gitdir, ""HEAD"")<tab><tab>if os.path.isfile(headFile):<tab><tab><tab>with open(headFile, ""r"", encoding=""utf-8"") as f:<tab><tab><tab><tab>line = f.readline()<tab><tab><tab><tab>if line:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>branch = line.split(""/"")[-1].strip()<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>branch = ""HEAD""<tab>return branch",0,"if line . startswith ( ""ref"" ) :","if line . startswith ( ""HEAD"" ) :",0.549040681,65.80370065,1
"def handle(self, msg):<tab>self._mic.send(msg)<tab>for calculate_seed, make_delegate, dict in self._delegate_records:<tab><tab>id = calculate_seed(msg)<tab><tab>if id is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if id not in dict or not dict[id].is_alive():<tab><tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab><tab>dict[id] = d<tab><tab><tab><tab>dict[id].start()<tab><tab>else:<tab><tab><tab>d = make_delegate((self, msg, id))<tab><tab><tab>d = self._ensure_startable(d)<tab><tab><tab>d.start()",0,"elif isinstance ( id , collections . Hashable ) :","elif isinstance ( id , int ) :",0.312053013,46.30777162,0.558441558
"def _print_items(items, _filter=None):<tab>if _filter:<tab><tab>print(""Displaying items matching filter: %s"" % _filter)<tab>print()<tab>for item in items:<tab><tab>filtered_out = False<tab><tab>for f in _filter.split():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filtered_out = True<tab><tab>if not filtered_out:<tab><tab><tab>print(item)<tab>print()",0,if f . lower ( ) not in item . lower ( ) :,if item . startswith ( f ) :,0.024198094,8.486162238,0.227941176
"def _cbAllRecords(self, results):<tab>ans, auth, add = [], [], []<tab>for res in results:<tab><tab><IF-STMT><tab><tab><tab>ans.extend(res[1][0])<tab><tab><tab>auth.extend(res[1][1])<tab><tab><tab>add.extend(res[1][2])<tab>return ans, auth, add",0,if res [ 0 ] :,if len ( res ) == 2 :,0.023749772,6.274655311,0.314814815
"def __status_update(self):<tab>was_active = False<tab>while True:<tab><tab>if self.analytics_instance.active:<tab><tab><tab>was_active = True<tab><tab><tab>msg = ""Active (%s)"" % self.analytics_instance.progress<tab><tab><tab>self.broadcast(msg, ""analytics"", ""analyticsUpdate"")<tab><tab><IF-STMT><tab><tab><tab>self.broadcast(""Inactive"", ""analytics"", ""analyticsUpdate"")<tab><tab><tab>was_active = False<tab><tab>time.sleep(0.2)",0,if was_active and not self . analytics_instance . active :,if not was_active :,0.014495917,10.48155441,0.294871795
"def plugin_song(self, song):<tab>for tag in [""album""]:<tab><tab>values = filter(None, map(album_to_sort, song.list(tag)))<tab><tab><IF-STMT><tab><tab><tab>song[tag + ""sort""] = ""\n"".join(values)<tab>for tag in [""artist"", ""albumartist"", ""performer""]:<tab><tab>values = filter(None, map(artist_to_sort, song.list(tag)))<tab><tab>if values and (tag + ""sort"") not in song:<tab><tab><tab>song[tag + ""sort""] = ""\n"".join(values)",1,"if values and ( tag + ""sort"" ) not in song :","if values and ( tag + ""sort"" ) not in song :",0.75,100,1
"def update(h, s):<tab>with lock:<tab><tab>try:<tab><tab><tab>i, c = find_cell(h)<tab><tab>except KeyError:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>c.content = parse(s)<tab><tab><tab>render_from(i, clear_after=True)",0,if not c . frozen and c . content != s :,if c . content is None :,0.08425931,11.78746094,0.172727273
"def get_parameters(self, names, with_decryption):<tab>result = []<tab>if len(names) > 10:<tab><tab>raise ValidationException(<tab><tab><tab>""1 validation error detected: ""<tab><tab><tab>""Value '[{}]' at 'names' failed to satisfy constraint: ""<tab><tab><tab>""Member must have length less than or equal to 10."".format("", "".join(names))<tab><tab>)<tab>for name in names:<tab><tab><IF-STMT><tab><tab><tab>result.append(self.get_parameter(name, with_decryption))<tab>return result",0,if name in self . _parameters :,if name not in self . params :,0.224815883,27.05411345,0.380952381
"def entered_file_action(self, path):<tab>attempt_copy = True<tab>path = self.try_append_extension(path)<tab>directory = os.path.dirname(path)<tab>if not os.path.exists(directory):<tab><tab>try:<tab><tab><tab>self.create_folder(directory)<tab><tab>except OSError as e:<tab><tab><tab>attempt_copy = False<tab><tab><tab>sublime.error_message(<tab><tab><tab><tab>""Cannot create '"" + path + ""'."" + "" See console for details""<tab><tab><tab>)<tab><tab><tab>print(""Exception: %s '%s'"" % (e.strerror, e.filename))<tab>if attempt_copy:<tab><tab>copy_success, new_file = self._copy_file(path)<tab><tab><IF-STMT><tab><tab><tab>self.open_file(new_file)",1,if copy_success :,if copy_success :,0.531170663,1.00E-10,1
"def acquire(self):<tab>""Acquire semaphore by decrementing value using spin-lock algorithm.""<tab>while True:<tab><tab>with self._cache.transact(retry=True):<tab><tab><tab>value = self._cache.get(self._key, default=self._value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._cache.set(<tab><tab><tab><tab><tab>self._key,<tab><tab><tab><tab><tab>value - 1,<tab><tab><tab><tab><tab>expire=self._expire,<tab><tab><tab><tab><tab>tag=self._tag,<tab><tab><tab><tab>)<tab><tab><tab><tab>return<tab><tab>time.sleep(0.001)",0,if value > 0 :,if value is not None :,0.057429006,17.9652056,0.357142857
"def commit(self):<tab>doc = {}<tab>for field, default in self.fields.iteritems():<tab><tab><IF-STMT><tab><tab><tab>value = getattr(self, field)<tab><tab><tab>if field in self.commit_fields or value != default:<tab><tab><tab><tab>doc[field] = getattr(self, field)<tab>with open(self.path, ""w"") as settings_file:<tab><tab>settings_file.write(json.dumps(doc, indent=4))",0,"if hasattr ( self , field ) :",if field in self . commit_fields :,0.02067646,6.74255593,0.333333333
"def parse_entrypoints(self, content: str, root=None) -> RootDependency:<tab>if root is None:<tab><tab>root = RootDependency()<tab>entrypoints = []<tab>group = ""console_scripts""<tab>for line in content.split(""\n""):<tab><tab>line = line.strip()<tab><tab><IF-STMT>  # ignore comments<tab><tab><tab>continue<tab><tab>if line[0] == ""["" and line[-1] == ""]"":<tab><tab><tab>group = line[1:-1]<tab><tab>else:<tab><tab><tab>entrypoints.append(EntryPoint.parse(text=line, group=group))<tab>root.entrypoints = tuple(entrypoints)<tab>return root",0,"if not line or line [ 0 ] in ""#;"" :",if not line :,0.046144095,5.244764383,0.476190476
"def request_with_retries(endpoint, timeout=30):<tab>start = time.time()<tab>while True:<tab><tab>try:<tab><tab><tab>return requests.get(""http://127.0.0.1:8000"" + endpoint, timeout=timeout)<tab><tab>except requests.RequestException:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise TimeoutError<tab><tab><tab>time.sleep(0.1)",0,if time . time ( ) - start > timeout :,if time . time ( ) - start >= timeout :,0.872196729,76.91605673,1
"def get_expression(self):<tab>""""""Return the expression as a printable string.""""""<tab>l = []<tab>for c in self.content:<tab><tab><IF-STMT>  # only applies to first cell<tab><tab><tab>l.append(c.op)<tab><tab>if c.child is not None:<tab><tab><tab>l.append(""("" + c.child.get_expression() + "")"")<tab><tab>else:<tab><tab><tab>l.append(""%d"" % c.get_value())<tab>return """".join(l)",1,if c . op is not None :,if c . op is not None :,0.75,100,1
"def nrgen_asc(self):<tab># compute the number of generations present<tab>for generation in range(self.generations_asc - 1, 0, -1):<tab><tab>for p in range(len(self.data[generation])):<tab><tab><tab>(person, parents, child, userdata) = self.data[generation][p]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return generation<tab>return 1",1,if person :,if person :,0.531170663,1.00E-10,1
"def check_all_verified(self):<tab>if not self.all_verified:<tab><tab>new_all_verified = not self.lines.filter(verified=False).exists()<tab><tab>if new_all_verified:<tab><tab><tab>self.all_verified = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_log_entry(<tab><tab><tab><tab><tab>_(""All rows requiring verification have been verified."")<tab><tab><tab><tab>)<tab><tab><tab><tab>self.require_verification = False<tab><tab><tab>self.save()<tab>return self.all_verified",1,if self . require_verification :,if self . require_verification :,0.75,100,1
"def sort(self, cmp=None, key=None, reverse=False):<tab>""Standard list sort method""<tab>if key:<tab><tab>temp = [(key(v), v) for v in self]<tab><tab>temp.sort(key=lambda x: x[0], reverse=reverse)<tab><tab>self[:] = [v[1] for v in temp]<tab>else:<tab><tab>temp = list(self)<tab><tab><IF-STMT><tab><tab><tab>temp.sort(cmp=cmp, reverse=reverse)<tab><tab>else:<tab><tab><tab>temp.sort(reverse=reverse)<tab><tab>self[:] = temp",0,if cmp is not None :,if cmp :,0.050438393,1.00E-10,0.4
"def process_formdata(self, valuelist):<tab>if valuelist:<tab><tab>date_str = "" "".join(valuelist)<tab><tab>if not date_str:<tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Please input a date/time value""))<tab><tab>parse_kwargs = self.parse_kwargs.copy()<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default()<tab><tab><tab>except TypeError:<tab><tab><tab><tab>parse_kwargs[""default""] = self.default<tab><tab>try:<tab><tab><tab>self.data = parser.parse(date_str, **parse_kwargs)<tab><tab>except ValueError:<tab><tab><tab>self.data = None<tab><tab><tab>raise ValidationError(self.gettext(""Invalid date/time input""))",0,"if ""default"" not in parse_kwargs :",if self . default :,0.027136592,5.171845311,0.333333333
"def _expand_dim_shape_func(data_shape, ndim, axis, num_newaxis):<tab>out = output_tensor((ndim + num_newaxis,), ""int64"")<tab>for i in const_range(out.shape[0]):<tab><tab>if i < axis:<tab><tab><tab>out[i] = data_shape[i]<tab><tab><IF-STMT><tab><tab><tab>out[i] = int64(1)<tab><tab>else:<tab><tab><tab>out[i] = data_shape[i - num_newaxis]<tab>return out",0,elif i < axis + num_newaxis :,elif i > axis :,0.04341096,11.41593807,1
"def _Return(self, t):<tab>self._fill(""return "")<tab>if t.value:<tab><tab>if isinstance(t.value, Tuple):<tab><tab><tab>text = "", "".join([name.name for name in t.value.asList()])<tab><tab><tab>self._write(text)<tab><tab>else:<tab><tab><tab>self._dispatch(t.value)<tab><tab><IF-STMT><tab><tab><tab>self._write(""; "")",0,if not self . _do_indent :,"if t . value . endswith ( "";"" ) :",0.021554939,4.456882761,0.274725275
"def blas_header_version():<tab># Version for the base header<tab>version = (9,)<tab>if detect_macos_sdot_bug():<tab><tab><IF-STMT><tab><tab><tab># Version with fix<tab><tab><tab>version += (1,)<tab><tab>else:<tab><tab><tab># Version with error<tab><tab><tab>version += (2,)<tab>return version",0,if detect_macos_sdot_bug . fix_works :,"if os . name == ""nt"" :",0.029730601,4.0910929,0.45
"def get_queues(self, region: str, attribute_names: []):<tab>sqs_client = AWSFacadeUtils.get_client(""sqs"", self.session, region)<tab>try:<tab><tab>raw_queues = await run_concurrently(sqs_client.list_queues)<tab>except Exception as e:<tab><tab>print_exception(f""Failed to list SQS queues: {e}"")<tab><tab>return []<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return []<tab><tab>queue_urls = raw_queues[""QueueUrls""]<tab><tab>return await map_concurrently(<tab><tab><tab>self._get_queue_attributes,<tab><tab><tab>queue_urls,<tab><tab><tab>region=region,<tab><tab><tab>attribute_names=attribute_names,<tab><tab>)",1,"if ""QueueUrls"" not in raw_queues :","if ""QueueUrls"" not in raw_queues :",0.75,100,1
"def popupFrameXdiff(job, frame1, frame2, frame3=None):<tab>""""""Opens a frame xdiff.""""""<tab>for command in [""/usr/bin/xxdiff"", ""/usr/local/bin/xdiff""]:<tab><tab>if os.path.isfile(command):<tab><tab><tab>for frame in [frame1, frame2, frame3]:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>command += "" --title1 %s %s"" % (<tab><tab><tab><tab><tab><tab>frame.data.name,<tab><tab><tab><tab><tab><tab>getFrameLogFile(job, frame),<tab><tab><tab><tab><tab>)<tab><tab><tab>shellOut(command)",0,if frame :,if frame3 is not None :,0.048107739,1.00E-10,0.2
"def wrap(*args, **kwargs):<tab>callargs = getcallargs(fun, *args, **kwargs)<tab>if callargs[""sock""] is None:<tab><tab># This variable is used only to debug leak in tests<tab><tab>COUNT[""count""] += 1<tab><tab>with IPSet() as sock:<tab><tab><tab>callargs[""sock""] = sock<tab><tab><tab># We must pop kwargs here, else the function will receive<tab><tab><tab># a dict of dict<tab><tab><tab><IF-STMT><tab><tab><tab><tab>callargs.update(callargs.pop(""kwargs""))<tab><tab><tab>return fun(**callargs)  # pylint:disable=star-args<tab>return fun(*args, **kwargs)",1,"if ""kwargs"" in callargs :","if ""kwargs"" in callargs :",0.75,100,1
"def set_multi(self, value):<tab>del self[atype]<tab>for addr in value:<tab><tab># Support assigning dictionary versions of addresses<tab><tab># instead of full Address objects.<tab><tab>if not isinstance(addr, Address):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>addr[""type""] = atype<tab><tab><tab>elif ""atype"" in addr and ""type"" not in addr:<tab><tab><tab><tab>addr[""type""] = addr[""atype""]<tab><tab><tab>addrObj = Address()<tab><tab><tab>addrObj.values = addr<tab><tab><tab>addr = addrObj<tab><tab>self.append(addr)",0,"if atype != ""all"" :","if ""atype"" in addr :",0.034123066,8.513058489,0.36
"def test_connection(self, data=None, raise_alert=False):<tab>try:<tab><tab>result = self._test_connection(self.connection_config(data))<tab>except CallError as e:<tab><tab>result = {""error"": True, ""exception"": str(e)}<tab>if result[""error""]:<tab><tab><IF-STMT><tab><tab><tab>config = self.middleware.call_sync(""kmip.config"")<tab><tab><tab>self.middleware.call_sync(<tab><tab><tab><tab>""alert.oneshot_create"",<tab><tab><tab><tab>""KMIPConnectionFailed"",<tab><tab><tab><tab>{""server"": config[""server""], ""error"": result[""exception""]},<tab><tab><tab>)<tab><tab>return False<tab>else:<tab><tab>return True",1,if raise_alert :,if raise_alert :,0.531170663,1.00E-10,1
"def test05_geometries(self):<tab>""Testing Geometries from Data Source Features.""<tab>for source in ds_list:<tab><tab>ds = DataSource(source.ds)<tab><tab># Incrementing through each layer and feature.<tab><tab>for layer in ds:<tab><tab><tab>for feat in layer:<tab><tab><tab><tab>g = feat.geom<tab><tab><tab><tab># Making sure we get the right Geometry name & type<tab><tab><tab><tab>self.assertEqual(source.geom, g.geom_name)<tab><tab><tab><tab>self.assertEqual(source.gtype, g.geom_type)<tab><tab><tab><tab># Making sure the SpatialReference is as expected.<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.assertEqual(source.srs_wkt, g.srs.wkt)",0,"if hasattr ( source , ""srs_wkt"" ) :",if source . srs_wkt is not None :,0.019345088,15.20797122,0.25
"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab>if os.path.isfile(current) and f.endswith(""py""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab>elif os.path.isdir(current):<tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab>if ret:<tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",0,if self . module_registrant :,if os . path . isfile ( current ) :,0.025806627,5.522397784,0.252747253
"def setData(self, data=None):<tab># update the data for the grid<tab>for nRow in range(self.nRows):<tab><tab>for nCol in range(self.nCols):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.SetCellValue(nRow, nCol, ""%f"" % data[nRow, nCol])<tab><tab><tab>else:<tab><tab><tab><tab>self.SetCellValue(nRow, nCol, ""0.000"")<tab>self.AutoSize()",0,if data is not None and nRow < data . shape [ 0 ] and nCol < data . shape [ 1 ] :,if data is not None :,0.135363765,3.959419814,0.428571429
"def __init__(self, *args, **kwargs):<tab>""""""Initialize the texture.""""""<tab>super().__init__(*args, **kwargs)<tab>assert_empty_kwargs(**kwargs)<tab>if len(args) == 1:<tab><tab>if isinstance(args[0], vtk.vtkTexture):<tab><tab><tab>self._from_texture(args[0])<tab><tab>elif isinstance(args[0], np.ndarray):<tab><tab><tab>self._from_array(args[0])<tab><tab><IF-STMT><tab><tab><tab>self._from_image_data(args[0])<tab><tab>elif isinstance(args[0], str):<tab><tab><tab>self._from_file(filename=args[0])<tab><tab>else:<tab><tab><tab>raise TypeError(f""Table unable to be made from ({type(args[0])})"")",0,"elif isinstance ( args [ 0 ] , vtk . vtkImageData ) :","elif isinstance ( args [ 0 ] , ImageData ) :",0.414677003,61.85985276,0.616666667
"def delete_old_post_save(<tab>sender, instance, raw, created, update_fields, using, **kwargs):<tab>""""""Post_save on all models with file fields, deletes old files""""""<tab>if raw or created:<tab><tab>return<tab>for field_name, new_file in cache.fields_for_model_instance(instance):<tab><tab><IF-STMT><tab><tab><tab>old_file = cache.get_field_attr(instance, field_name)<tab><tab><tab>if old_file != new_file:<tab><tab><tab><tab>delete_file(instance, field_name, old_file, using)<tab># reset cache<tab>cache.make_cleanup_cache(instance)",0,if update_fields is None or field_name in update_fields :,if new_file is None :,0.219033007,5.267003805,0.633333333
"def do_refresh(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>service_status = agent_status()<tab><tab><tab>self.properties.service_status_label.setText(<tab><tab><tab><tab>HUMAN_SERVICE_STATUS[service_status]<tab><tab><tab>)<tab>finally:<tab><tab>QTimer.singleShot(REFRESH_PERIOD, self.do_refresh)",0,if self . isVisible ( ) :,if self . properties . service_status_label :,0.090565314,14.99110695,0.6
"def json_dumps(data):<tab>""""""Return data in nicely formatted json.""""""<tab>try:<tab><tab>return json.dumps(<tab><tab><tab>data,<tab><tab><tab>indent=1,<tab><tab><tab>sort_keys=True,<tab><tab><tab>separators=("","", "": ""),<tab><tab><tab>default=json_serialize_default,<tab><tab>)<tab>except UnicodeDecodeError:<tab><tab><IF-STMT><tab><tab><tab>data = json_preserialize_binary(data)<tab><tab><tab>return json.dumps(data)<tab><tab>raise",0,"if sys . version_info [ : 2 ] == ( 2 , 7 ) :",if sys . version_info [ 0 ] < 3 :,0.135396314,33.30462805,0.421768707
"def __init__(self, aList):<tab>for element in aList:<tab><tab>if len(element) > 0:<tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>self.append(ListParser(element))<tab><tab><tab>else:<tab><tab><tab><tab>self.append(DictParser(element))<tab><tab>elif element.text:<tab><tab><tab>text = element.text.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.append(text)",1,if text :,if text :,0.531170663,1.00E-10,1
"def __init__(self, token):<tab>self._convert_to_ascii = False<tab>self._find = None<tab>if token.search is None:<tab><tab>return<tab>flags = 0<tab>self._match_this_many = 1<tab>if token.options:<tab><tab>if ""g"" in token.options:<tab><tab><tab>self._match_this_many = 0<tab><tab>if ""i"" in token.options:<tab><tab><tab>flags |= re.IGNORECASE<tab><tab><IF-STMT><tab><tab><tab>self._convert_to_ascii = True<tab>self._find = re.compile(token.search, flags | re.DOTALL)<tab>self._replace = _CleverReplace(token.replace)",0,"if ""a"" in token . options :","if token . options [ ""i"" ] == ""ascii"" :",0.077712302,12.09034063,0.384615385
"def get_next(self):<tab>if self.current > self.maximum:<tab><tab>raise StopIteration<tab>else:<tab><tab><IF-STMT><tab><tab><tab>payl = ""%0"" + str(self.width) + ""d""<tab><tab><tab>payl = payl % (self.current)<tab><tab>else:<tab><tab><tab>payl = str(self.current)<tab><tab>self.current += 1<tab><tab>return payl",0,if self . width :,if self . current < self . width :,0.387385419,37.53119269,0.493333333
"def any(self, provider_name):<tab>result = authomatic.login(Webapp2Adapter(self), provider_name)<tab>if result:<tab><tab>apis = []<tab><tab><IF-STMT><tab><tab><tab>result.user.update()<tab><tab><tab>if result.user.credentials:<tab><tab><tab><tab>apis = config.config.get(provider_name, {}).get(""_apis"", {})<tab><tab>nice_provider_name = (<tab><tab><tab>config.config.get(provider_name, {}).get(""_name"")<tab><tab><tab>or provider_name.capitalize()<tab><tab>)<tab><tab>render(<tab><tab><tab>self,<tab><tab><tab>result,<tab><tab><tab>result.popup_js(custom=dict(apis=apis, provider_name=nice_provider_name)),<tab><tab>)",1,if result . user :,if result . user :,0.75,100,1
"def _get_lun_id(self, volume, target_name):<tab>""""""Get lun id of the voluem in a target.""""""<tab>pool = volume_utils.extract_host(volume.host, level=""pool"")<tab>volume_name = self._trans_name_down(volume.name)<tab>lun_id = None<tab>luns = self._get_lun_list(target_name)<tab>for lun in luns:<tab><tab>mappinglvm = lun.get(""mappingLvm"")<tab><tab>lun_name = mappinglvm.replace(r""%s/"" % pool, """")<tab><tab><IF-STMT><tab><tab><tab>lun_id = lun.get(""id"")<tab>return lun_id",0,if lun_name == volume_name :,"if lun . get ( ""name"" ) == lun_name :",0.026964759,18.6930008,0.46875
"def save_settings(self, settings):<tab>for setting in self.settings:<tab><tab>setting_obj = settings[setting]<tab><tab>new_value = self.cleaned_data.get(setting)<tab><tab><IF-STMT><tab><tab><tab>if new_value and new_value != self.initial.get(setting):<tab><tab><tab><tab>self.save_image(setting_obj, new_value)<tab><tab><tab>elif self.cleaned_data.get(""%s_delete"" % setting):<tab><tab><tab><tab>self.delete_image(setting_obj)<tab><tab>else:<tab><tab><tab>self.save_setting(setting_obj, new_value)",0,"if setting_obj . python_type == ""image"" :",if setting_obj is not None :,0.04155306,17.26760605,0.333333333
"def setup_with_driver(self):<tab>if not self.__class__.shared_state_initialized:<tab><tab>try:<tab><tab><tab>self.setup_shared_state()<tab><tab><tab>self.logout_if_needed()<tab><tab>except Exception:<tab><tab><tab>self.__class__.shared_state_in_error = True<tab><tab><tab>raise<tab><tab>finally:<tab><tab><tab>self.__class__.shared_state_initialized = True<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise unittest.SkipTest(<tab><tab><tab><tab>""Skipping test, failed to initialize state previously.""<tab><tab><tab>)",1,if self . __class__ . shared_state_in_error :,if self . __class__ . shared_state_in_error :,0.75,100,1
"def _get_replication_type_param(k, v):<tab>words = v.split()<tab>if len(words) == 2 and words[0] == ""<in>"":<tab><tab>REPLICA_SYNC_TYPES = {<tab><tab><tab>""sync"": constants.REPLICA_SYNC_MODEL,<tab><tab><tab>""async"": constants.REPLICA_ASYNC_MODEL,<tab><tab>}<tab><tab>sync_type = words[1].lower()<tab><tab><IF-STMT><tab><tab><tab>return REPLICA_SYNC_TYPES[sync_type]<tab>msg = _(<tab><tab>""replication_type spec must be specified as ""<tab><tab>""replication_type='<in> sync' or '<in> async'.""<tab>)<tab>LOG.error(msg)<tab>raise exception.InvalidInput(reason=msg)",1,if sync_type in REPLICA_SYNC_TYPES :,if sync_type in REPLICA_SYNC_TYPES :,0.75,100,1
"def request(self, host, handler, request_body, verbose=False):<tab># retry request once if cached connection has gone cold<tab>for i in (0, 1):<tab><tab>try:<tab><tab><tab>return self.single_request(host, handler, request_body, verbose)<tab><tab>except socket.error as e:<tab><tab><tab>if i or e.errno not in (errno.ECONNRESET, errno.ECONNABORTED, errno.EPIPE):<tab><tab><tab><tab>raise<tab><tab>except http_client.BadStatusLine:  # close after we sent request<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise",1,if i :,if i :,0.531170663,1.00E-10,1
"def make_sales_return_records():<tab><IF-STMT><tab><tab>for data in frappe.get_all(<tab><tab><tab>""Delivery Note"", fields=[""name""], filters={""docstatus"": 1}<tab><tab>):<tab><tab><tab>if random.random() < 0.1:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>dn = make_sales_return(data.name)<tab><tab><tab><tab><tab>dn.insert()<tab><tab><tab><tab><tab>dn.submit()<tab><tab><tab><tab><tab>frappe.db.commit()<tab><tab><tab><tab>except Exception:<tab><tab><tab><tab><tab>frappe.db.rollback()",1,if random . random ( ) < 0.1 :,if random . random ( ) < 0.1 :,1,100,1
"def getStatusString(self):<tab>if not self._isAvailable:<tab><tab>return ""Doodle3D box not found""<tab>if self._printing:<tab><tab><IF-STMT><tab><tab><tab>ret = ""Sending GCode: %.1f%%"" % (<tab><tab><tab><tab>float(self._blockIndex) * 100.0 / float(len(self._fileBlocks))<tab><tab><tab>)<tab><tab>elif len(self._fileBlocks) > 0:<tab><tab><tab>ret = ""Finished sending GCode to Doodle3D box.""<tab><tab>else:<tab><tab><tab>ret = ""Different print still running...""<tab><tab># ret += ""\nErrorCount: %d"" % (self._errorCount)<tab><tab>return ret<tab>return ""Printer found, waiting for print command.""",0,if self . _blockIndex < len ( self . _fileBlocks ) :,if len ( self . _fileBlocks ) > 0 :,0.371997407,46.26266999,0.4
"def coro(*args, **kw):<tab>res = func(*args, **kw)<tab>if isinstance(res, futures.Future) or inspect.isgenerator(res):<tab><tab>res = yield from res<tab>elif _AwaitableABC is not None:<tab><tab># If 'func' returns an Awaitable (new in 3.5) we<tab><tab># want to run it.<tab><tab>try:<tab><tab><tab>await_meth = res.__await__<tab><tab>except AttributeError:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res = yield from await_meth()<tab>return res",0,"if isinstance ( res , _AwaitableABC ) :",if callable ( await_meth ) :,0.037156986,12.25620097,0.381818182
def _skip_to_next_iteration_group(self):<tab>while True:<tab><tab>if self._currkey is self._marker:<tab><tab><tab>pass<tab><tab>elif self._tgtkey is self._marker:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>newvalue = next(self._iterator)<tab><tab>if self._keyfunc is None:<tab><tab><tab>newkey = newvalue<tab><tab>else:<tab><tab><tab>newkey = self._keyfunc(newvalue)<tab><tab>self._currkey = newkey<tab><tab>self._currvalue = newvalue,0,if not self . _tgtkey == self . _currkey :,if self . _iterator is None :,0.078035632,12.50204706,0.333333333
"def in_quadview(context):<tab>for area in context.window.screen.areas:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for space in area.spaces:<tab><tab><tab>if space.type != ""VIEW_3D"":<tab><tab><tab><tab>continue<tab><tab><tab>if len(space.region_quadviews) > 0:<tab><tab><tab><tab>return True<tab>return False",1,"if area . type != ""VIEW_3D"" :","if area . type != ""VIEW_3D"" :",0.75,100,1
"def find_from_pythonpath(name):<tab>for dirpath in sys.path:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = os.path.join(dirpath, name)<tab><tab>if os.path.isfile(path):<tab><tab><tab>return path<tab>return None",1,if not os . path . isdir ( dirpath ) :,if not os . path . isdir ( dirpath ) :,0.75,100,1
"def detailed_exceptions_wrapper(self, *args, **kwargs):<tab>try:<tab><tab>return meth(self, *args, **kwargs)<tab>except ScriptError as e:<tab><tab>info = e.args[0]<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>info.setdefault(""type"", ScriptError.SPLASH_LUA_ERROR)<tab><tab>info.setdefault(""splash_method"", _name)<tab><tab>raise e",0,"if not isinstance ( info , dict ) :","if info . get ( ""type"" ) != ScriptError . SLASH_LUA_ERROR :",0.015839383,3.027253257,0.241666667
"def metadata(draft):<tab>test_metadata = {}<tab>json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema)<tab>for key, value in json_schema[""properties""].items():<tab><tab>response = ""Test response""<tab><tab>items = value[""properties""][""value""].get(""items"")<tab><tab>enum = value[""properties""][""value""].get(""enum"")<tab><tab>if items:  # multiselect<tab><tab><tab>response = [items[""enum""][0]]<tab><tab>elif enum:  # singleselect<tab><tab><tab>response = enum[0]<tab><tab><IF-STMT><tab><tab><tab>response = {""question"": {""value"": ""Test Response""}}<tab><tab>test_metadata[key] = {""value"": response}<tab>return test_metadata",0,"elif value [ ""properties"" ] [ ""value"" ] . get ( ""properties"" ) :","elif ""test_response"" in value :",0.007621679,2.100137328,0.4
"def separate_keys(self, keys, torrent_ids):<tab>""""""Separates the input keys into torrent class keys and plugins keys""""""<tab>if self.torrents:<tab><tab>for torrent_id in torrent_ids:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>status_keys = list(self.torrents[torrent_id].status_funcs)<tab><tab><tab><tab>leftover_keys = list(set(keys) - set(status_keys))<tab><tab><tab><tab>torrent_keys = list(set(keys) - set(leftover_keys))<tab><tab><tab><tab>return torrent_keys, leftover_keys<tab>return [], []",1,if torrent_id in self . torrents :,if torrent_id in self . torrents :,0.75,100,1
"def upgrade():<tab>bind = op.get_bind()<tab>op.add_column(""slices"", sa.Column(""datasource_id"", sa.Integer()))<tab>session = db.Session(bind=bind)<tab>for slc in session.query(Slice).all():<tab><tab>if slc.druid_datasource_id:<tab><tab><tab>slc.datasource_id = slc.druid_datasource_id<tab><tab><IF-STMT><tab><tab><tab>slc.datasource_id = slc.table_id<tab><tab>session.merge(slc)<tab><tab>session.commit()<tab>session.close()",1,if slc . table_id :,if slc . table_id :,0.75,100,1
"def __call__(self, controller, environ, context):<tab>context.session = session = SessionObject(environ, **self.options)<tab>environ[""beaker.session""] = session<tab>environ[""beaker.get_session""] = self._get_session<tab>if ""paste.testing_variables"" in environ:<tab><tab>environ[""paste.testing_variables""][""session""] = session<tab>response = self.next_handler(controller, environ, context)<tab>if session.accessed():<tab><tab>session.persist()<tab><tab>session_headers = session.__dict__[""_headers""]<tab><tab>if session_headers[""set_cookie""]:<tab><tab><tab>cookie = session_headers[""cookie_out""]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>response.headers.extend(((""Set-cookie"", cookie),))<tab>return response",1,if cookie :,if cookie :,0.531170663,1.00E-10,1
"def propagate(self, user, change_action=None, author=None):<tab>""""""Propagate current translation to all others.""""""<tab>result = False<tab>for unit in self.same_source_units:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if unit.target == self.target and unit.state == self.state:<tab><tab><tab>continue<tab><tab>unit.target = self.target<tab><tab>unit.state = self.state<tab><tab>unit.save_backend(<tab><tab><tab>user,<tab><tab><tab>False,<tab><tab><tab>change_action=change_action,<tab><tab><tab>author=None,<tab><tab><tab>run_checks=False,<tab><tab>)<tab><tab>result = True<tab>return result",0,"if not user . has_perm ( ""unit.edit"" , unit ) :",if unit is None :,0.012417879,1.275361352,0.285714286
"def load_model(self, model_dict):<tab>model_param = None<tab>model_meta = None<tab>for _, value in model_dict[""model""].items():<tab><tab>for model in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>model_meta = value[model]<tab><tab><tab>if model.endswith(""Param""):<tab><tab><tab><tab>model_param = value[model]<tab>LOGGER.info(""load model"")<tab>self.set_model_meta(model_meta)<tab>self.set_model_param(model_param)<tab>self.phi = np.array([model_param.phi_a])",1,"if model . endswith ( ""Meta"" ) :","if model . endswith ( ""Meta"" ) :",0.75,100,1
"def name(self):<tab>""""""Get the enumeration name of this storage class.""""""<tab>if self._name_map is None:<tab><tab>self._name_map = {}<tab><tab>for key, value in StorageClass.__dict__.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._name_map[value] = key<tab>return self._name_map[self]",1,"if isinstance ( value , StorageClass ) :","if isinstance ( value , StorageClass ) :",0.75,100,1
"def relro(self):<tab>try:<tab><tab>gnu_relro = lief.ELF.SEGMENT_TYPES.GNU_RELRO<tab><tab>flags = lief.ELF.DYNAMIC_TAGS.FLAGS<tab><tab>bind_now = lief.ELF.DYNAMIC_FLAGS.BIND_NOW<tab><tab>if self.elf.get(gnu_relro):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""Full RELRO""<tab><tab><tab>else:<tab><tab><tab><tab>return ""Partial RELRO""<tab><tab>return ""No RELRO""<tab>except lief.not_found:<tab><tab>return ""No RELRO""",0,if bind_now in self . elf . get ( flags ) :,if flags & bind_now :,0.011348924,10.69482073,0.25
"def test_counter_instantiation(self):<tab>self.assertIs(type(typing_extensions.Counter()), collections.Counter)<tab>self.assertIs(type(typing_extensions.Counter[T]()), collections.Counter)<tab>self.assertIs(type(typing_extensions.Counter[int]()), collections.Counter)<tab>class C(typing_extensions.Counter[T]):<tab><tab>...<tab>if TYPING_3_5_3:<tab><tab>self.assertIs(type(C[int]()), C)<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(C.__bases__, (typing_extensions.Counter,))<tab><tab>else:<tab><tab><tab>self.assertEqual(C.__bases__, (collections.Counter, typing.Generic))",0,if not PEP_560 :,elif PY3 :,0.287243421,1.00E-10,0.2
"def handle_exception(self, e, result):<tab>for k in sorted(result.thrift_spec):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>_, exc_name, exc_cls, _ = result.thrift_spec[k]<tab><tab>if isinstance(e, exc_cls):<tab><tab><tab>setattr(result, exc_name, e)<tab><tab><tab>return True<tab>return False",0,"if result . thrift_spec [ k ] [ 1 ] == ""success"" :","if k . startswith ( ""_"" ) :",0.011365276,3.066805948,0.324561404
"def find_from_pythonpath(name):<tab>for dirpath in sys.path:<tab><tab>if not os.path.isdir(dirpath):<tab><tab><tab>continue<tab><tab>path = os.path.join(dirpath, name)<tab><tab><IF-STMT><tab><tab><tab>return path<tab>return None",0,if os . path . isfile ( path ) :,if os . path . isfile ( path ) and os . path . isfile ( path ) :,0.770614325,48.24572995,0.630434783
"def parse_location(srclocation):<tab>loc = symbols.Location(<tab><tab>get_value(srclocation, ""file""), get_value(srclocation, ""project"")<tab>)<tab><IF-STMT><tab><tab>loc = symbols.InstalledLocation(<tab><tab><tab>symbols.parse_package(get_value(srclocation, ""package"")),<tab><tab><tab>parse_package_db(get_value(srclocation, ""db"")),<tab><tab>)<tab><tab>if loc.is_null():<tab><tab><tab>loc = symbols.OtherLocation(get_value(srclocation, ""source""))<tab>return loc if not loc.is_null() else None",1,if loc . is_null ( ) :,if loc . is_null ( ) :,0.75,100,1
"def execute(self):<tab>logger.debug(f""host {self.host} try ports: {default_ports}"")<tab>for single_port in default_ports:<tab><tab><IF-STMT><tab><tab><tab>logger.debug(f""Reachable port found: {single_port}"")<tab><tab><tab>self.publish_event(OpenPortEvent(port=single_port))",0,"if self . test_connection ( self . host , single_port ) :",if self . host == single_port :,0.11619077,18.12815014,0.651960784
"def get_dynamic_incoming_outgoing_rate(self, sle):<tab># Get updated incoming/outgoing rate from transaction<tab>if sle.recalculate_rate:<tab><tab>rate = self.get_incoming_outgoing_rate_from_transaction(sle)<tab><tab><IF-STMT><tab><tab><tab>sle.incoming_rate = rate<tab><tab>else:<tab><tab><tab>sle.outgoing_rate = rate",0,if flt ( sle . actual_qty ) >= 0 :,if sle . incoming_rate is None :,0.028035632,7.687847996,0.285714286
"def _naf(mult):<tab>""""""Calculate non-adjacent form of number.""""""<tab>ret = []<tab>while mult:<tab><tab><IF-STMT><tab><tab><tab>nd = mult % 4<tab><tab><tab>if nd >= 2:<tab><tab><tab><tab>nd = nd - 4<tab><tab><tab>ret += [nd]<tab><tab><tab>mult -= nd<tab><tab>else:<tab><tab><tab>ret += [0]<tab><tab>mult //= 2<tab>return ret",0,if mult % 2 :,if mult % 4 == 0 :,0.200593991,22.08959113,0.476190476
"def indent_xml(elem, level=0):<tab>""""""Do our pretty printing and make Matt very happy.""""""<tab>i = ""\n"" + level * ""  ""<tab>if elem:<tab><tab><IF-STMT><tab><tab><tab>elem.text = i + ""  ""<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent_xml(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab>if level and (not elem.tail or not elem.tail.strip()):<tab><tab><tab>elem.tail = i",1,if not elem . text or not elem . text . strip ( ) :,if not elem . text or not elem . text . strip ( ) :,1,100,1
def clockface(radius):<tab>reset()<tab>pensize(7)<tab>for i in range(60):<tab><tab>jump(radius)<tab><tab><IF-STMT><tab><tab><tab>fd(25)<tab><tab><tab>jump(-radius - 25)<tab><tab>else:<tab><tab><tab>dot(3)<tab><tab><tab>jump(-radius)<tab><tab>rt(6),0,if i % 5 == 0 :,if i % 2 :,0.157032291,23.45000811,0.476190476
"def OnTextEntered(self, evt):<tab>text = self.GetValue()<tab>if self.doSearch(text):<tab><tab>self.searches.append(text)<tab><tab><IF-STMT><tab><tab><tab>del self.searches[0]<tab><tab>self.SetMenu(self.MakeMenu())<tab>self.SetValue("""")",0,if len ( self . searches ) > self . maxSearches :,if len ( self . searches ) == 1 :,0.397495232,53.8772222,0.655677656
"def wrapped_send(bot, location, content=None, preprocessor=None, **kwargs):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>content = await preprocessor(bot, location, content)<tab><tab>await location.send(content, **kwargs)<tab>except Exception as _exc:<tab><tab>main_log.error(<tab><tab><tab>""I could not send an owner notification to %s (%s)"",<tab><tab><tab>location,<tab><tab><tab>location.id,<tab><tab><tab>exc_info=_exc,<tab><tab>)",0,if preprocessor is not None :,if preprocessor :,0.050438393,1.00E-10,0.4
"def explode(self, obj):<tab>""""""Determine if the object should be exploded.""""""<tab>if obj in self._done:<tab><tab>return False<tab>result = False<tab>for item in self._explode:<tab><tab><IF-STMT><tab><tab><tab># If it has a _moId it is an instance<tab><tab><tab>if obj._moId == item._moId:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab># If it does not have a _moId it is a template<tab><tab><tab>if obj.__class__.__name__ == item.__name__:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>self._done.add(obj)<tab>return result",1,"if hasattr ( item , ""_moId"" ) :","if hasattr ( item , ""_moId"" ) :",0.75,100,1
"def _verify_treestore(itr, tree_values):<tab>i = 0<tab>while itr:<tab><tab>values = tree_values[i]<tab><tab>if treestore[itr][0] != values[0]:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>if not _verify_treestore(treestore.iter_children(itr), values[1]):<tab><tab><tab><tab>return False<tab><tab>itr = treestore.iter_next(itr)<tab><tab>i += 1<tab>return True",0,if treestore . iter_children ( itr ) :,if len ( values ) > 1 :,0.082873037,6.082317173,0.26984127
"def types(model_cls):<tab># Gives us `item_types` and `album_types`<tab>attr_name = ""{0}_types"".format(model_cls.__name__.lower())<tab>types = {}<tab>for plugin in find_plugins():<tab><tab>plugin_types = getattr(plugin, attr_name, {})<tab><tab>for field in plugin_types:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise PluginConflictException(<tab><tab><tab><tab><tab>u""Plugin {0} defines flexible field {1} ""<tab><tab><tab><tab><tab>u""which has already been defined with ""<tab><tab><tab><tab><tab>u""another type."".format(plugin.name, field)<tab><tab><tab><tab>)<tab><tab>types.update(plugin_types)<tab>return types",0,if field in types and plugin_types [ field ] != types [ field ] :,if field in types :,0.171406986,5.251935082,0.657407407
"def set_origin(self, origin):<tab># This is useful to modify an exception to add origin information as<tab># it ""passes by"", without losing traceback information. (In Python 3<tab># we can use the built-in exception wrapping stuff, but it will be<tab># some time before we can count on that...)<tab>if self.origin is None:<tab><tab><IF-STMT><tab><tab><tab>origin = origin.origin<tab><tab>if not isinstance(origin, patsy.origin.Origin):<tab><tab><tab>origin = None<tab><tab>self.origin = origin",1,"if hasattr ( origin , ""origin"" ) :","if hasattr ( origin , ""origin"" ) :",0.75,100,1
"def items(self):<tab>if self._items is not None:<tab><tab>return self._items<tab>items = self.get_option(""recent-connections"")<tab>if not items:<tab><tab>self._items = []<tab><tab>return self._items<tab>for i in reversed(items):<tab><tab><IF-STMT><tab><tab><tab>items.remove(i)<tab><tab>try:<tab><tab><tab>i[""device""] = self.get_device_path(i)<tab><tab>except AdapterNotFound:<tab><tab><tab>i[""device""] = None<tab><tab>except DeviceNotFound:<tab><tab><tab>items.remove(i)<tab><tab>i[""time""] = float(i[""time""])<tab>self._items = items<tab>return self._items",0,"if ""name"" not in i or ""uuid"" not in i :","if i [ ""device"" ] is None :",0.013374522,3.805770825,0.2
"def test_doc_attributes(self):<tab>print_test_name(""TEST DOC ATTRIBUTES"")<tab>correct = 0<tab>for example in DOC_EXAMPLES:<tab><tab>original_schema = schema.parse(example.schema_string)<tab><tab>if original_schema.doc is not None:<tab><tab><tab>correct += 1<tab><tab>if original_schema.type == ""record"":<tab><tab><tab>for f in original_schema.fields:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.fail(<tab><tab><tab><tab><tab><tab>""Failed to preserve 'doc' in fields: "" + example.schema_string<tab><tab><tab><tab><tab>)<tab>self.assertEqual(correct, len(DOC_EXAMPLES))",0,if f . doc is None :,"if f . name == ""doc"" :",0.090565314,17.74740528,0.380952381
"def StopBackgroundWorkload(self):<tab>""""""Stop the background workoad.""""""<tab>for workload in background_workload.BACKGROUND_WORKLOADS:<tab><tab><IF-STMT><tab><tab><tab>if self.OS_TYPE in workload.EXCLUDED_OS_TYPES:<tab><tab><tab><tab>raise NotImplementedError()<tab><tab><tab>workload.Stop(self)",1,if workload . IsEnabled ( self ) :,if workload . IsEnabled ( self ) :,0.75,100,1
"def resolve_expression(<tab>self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):<tab>resolved = super(SearchQuery, self).resolve_expression(<tab><tab>query, allow_joins, reuse, summarize, for_save<tab>)<tab>if self.config:<tab><tab><IF-STMT><tab><tab><tab>resolved.config = Value(self.config).resolve_expression(<tab><tab><tab><tab>query, allow_joins, reuse, summarize, for_save<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>resolved.config = self.config.resolve_expression(<tab><tab><tab><tab>query, allow_joins, reuse, summarize, for_save<tab><tab><tab>)<tab>return resolved",0,"if not hasattr ( self . config , ""resolve_expression"" ) :","if isinstance ( self . config , str ) :",0.212492732,28.33335058,0.25
"def resolve_ip(filename, foffset, ip, need_line):<tab>sym, soffset, line = None, 0, None<tab>if filename and filename.startswith(""/""):<tab><tab>sym, soffset = resolve_sym(filename, foffset)<tab><tab>if not sym:<tab><tab><tab>sym, soffset = resolve_sym(filename, ip)<tab><tab><IF-STMT><tab><tab><tab>line = resolve_line(filename, ip)<tab>else:<tab><tab>sym, soffset = kernel.resolve_kernel(ip)<tab>return sym, soffset, line",1,if need_line :,if need_line :,0.531170663,1.00E-10,1
"def create_model(self, dataset, weight_name=Checkpoint._LATEST):<tab>if not self.is_empty:<tab><tab>run_config = copy.deepcopy(self._checkpoint.run_config)<tab><tab>model = instantiate_model(run_config, dataset)<tab><tab><IF-STMT><tab><tab><tab>for k, v in self._checkpoint.model_props.items():<tab><tab><tab><tab>setattr(model, k, v)<tab><tab><tab>delattr(self._checkpoint, ""model_props"")<tab><tab>self._initialize_model(model, weight_name)<tab><tab>return model<tab>else:<tab><tab>raise ValueError(""Checkpoint is empty"")",0,"if hasattr ( self . _checkpoint , ""model_props"" ) :",if self . _checkpoint . model_props :,0.061846305,24.53740138,0.483333333
"def get_py2exe_datafiles():<tab>datapath = get_data_path()<tab>head, tail = os.path.split(datapath)<tab>d = {}<tab>for root, dirs, files in os.walk(datapath):<tab><tab># Need to explicitly remove cocoa_agg files or py2exe complains<tab><tab># NOTE I dont know why, but do as previous version<tab><tab><IF-STMT><tab><tab><tab>files.remove(""Matplotlib.nib"")<tab><tab>files = [os.path.join(root, filename) for filename in files]<tab><tab>root = root.replace(tail, ""mpl-data"")<tab><tab>root = root[root.index(""mpl-data"") :]<tab><tab>d[root] = files<tab>return d.items()",1,"if ""Matplotlib.nib"" in files :","if ""Matplotlib.nib"" in files :",0.75,100,1
"def mouseClickEvent(self, ev):<tab>if ev.button() == QtCore.Qt.LeftButton and self.allowAdd:<tab><tab>pos = ev.pos()<tab><tab>if pos.x() < 0 or pos.x() > self.length:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>pos.setX(min(max(pos.x(), 0), self.length))<tab><tab>self.addTick(pos.x() / self.length)<tab>elif ev.button() == QtCore.Qt.RightButton:<tab><tab>self.showMenu(ev)",0,if pos . y ( ) < 0 or pos . y ( ) > self . tickSize :,if pos . y ( ) < 0 or pos . y ( ) > self . length :,0.949517396,89.79542144,0.777777778
"def image_preprocess(self, image):<tab>with tf.name_scope(""image_preprocess""):<tab><tab><IF-STMT><tab><tab><tab>image = tf.cast(image, tf.float32)<tab><tab>mean = [0.485, 0.456, 0.406]  # rgb<tab><tab>std = [0.229, 0.224, 0.225]<tab><tab>if self.image_bgr:<tab><tab><tab>mean = mean[::-1]<tab><tab><tab>std = std[::-1]<tab><tab>image_mean = tf.constant(mean, dtype=tf.float32) * 255.0<tab><tab>image_std = tf.constant(std, dtype=tf.float32) * 255.0<tab><tab>image = (image - image_mean) / image_std<tab><tab>return image",0,if image . dtype . base_dtype != tf . float32 :,if self . image_rgb :,0.062417879,3.612710856,0.257142857
"def _addConsoleMessage(self, type: str, args: List[JSHandle]) -> None:<tab>if not self.listeners(Page.Events.Console):<tab><tab>for arg in args:<tab><tab><tab>self._client._loop.create_task(arg.dispose())<tab><tab>return<tab>textTokens = []<tab>for arg in args:<tab><tab>remoteObject = arg._remoteObject<tab><tab><IF-STMT><tab><tab><tab>textTokens.append(arg.toString())<tab><tab>else:<tab><tab><tab>textTokens.append(str(helper.valueFromRemoteObject(remoteObject)))<tab>message = ConsoleMessage(type, "" "".join(textTokens), args)<tab>self.emit(Page.Events.Console, message)",0,"if remoteObject . get ( ""objectId"" ) :",if remoteObject is None :,0.035401841,8.697972365,0.481481481
"def _handle_guild_scalar(self, add_scalar, _tag, _value, step=None):<tab>""""""Handler for guild.summary.SummaryWriter.add_scalar.""""""<tab>vals = self._summary_values(step)<tab>if vals:<tab><tab>self.log.debug(""summary values via add_scalar: %s"", vals)<tab><tab>for tag, val in vals.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>add_scalar(tag, val, step)",0,if val is not None :,"if isinstance ( val , dict ) :",0.023749772,7.267884212,0.232142857
"def _get_token_from_cookie(self):<tab>for cookie in self.session.cookies:<tab><tab>if cookie.name == ""X-APPLE-WEBAUTH-VALIDATE"":<tab><tab><tab>match = search(r""\bt=([^:]+)"", cookie.value)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""Can't extract token from %r"" % cookie.value)<tab><tab><tab>return {""token"": match.group(1)}<tab>raise Exception(""Token cookie not found"")",0,if match is None :,if not match :,0.039449619,16.37226967,0.277777778
"def unpack_RK(rk_str):<tab>flags = BYTES_ORD(rk_str[0])<tab>if flags & 2:<tab><tab># There's a SIGNED 30-bit integer in there!<tab><tab>(i,) = unpack(""<i"", rk_str)<tab><tab>i >>= 2  # div by 4 to drop the 2 flag bits<tab><tab><IF-STMT><tab><tab><tab>return i / 100.0<tab><tab>return float(i)<tab>else:<tab><tab># It's the most significant 30 bits of an IEEE 754 64-bit FP number<tab><tab>(d,) = unpack(""<d"", b""\0\0\0\0"" + BYTES_LITERAL(chr(flags & 252)) + rk_str[1:4])<tab><tab>if flags & 1:<tab><tab><tab>return d / 100.0<tab><tab>return d",1,if flags & 1 :,if flags & 1 :,0.75,100,1
"def _parse_photo(self):<tab>cat = ""lib""<tab>for photosection in self.plex.library.sections():<tab><tab><IF-STMT><tab><tab><tab>self._load_attrs(photosection, cat)<tab><tab><tab>for photoalbum in photosection.all():<tab><tab><tab><tab>self._load_attrs(photoalbum, cat)<tab><tab><tab><tab>for photo in photoalbum.photos():<tab><tab><tab><tab><tab>self._load_attrs(photo, cat)",0,if photosection . TYPE == library . PhotoSection . TYPE :,if photosection . all ( ) :,0.052382556,12.85981829,0.405982906
"def count(num):<tab>cnt = 0<tab>for i in range(num):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError<tab><tab><tab>if i % 3:<tab><tab><tab><tab>raise ArithmeticError(""1"")<tab><tab>except Exception as e:<tab><tab><tab>cnt += 1<tab>return cnt",1,if i % 2 :,if i % 2 :,0.75,100,1
"def node_exists(self, jid=None, node=None, ifrom=None):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>jid = self.xmpp.boundjid.full<tab><tab>if node is None:<tab><tab><tab>node = """"<tab><tab>if ifrom is None:<tab><tab><tab>ifrom = """"<tab><tab>if isinstance(ifrom, JID):<tab><tab><tab>ifrom = ifrom.full<tab><tab>if (jid, node, ifrom) not in self.nodes:<tab><tab><tab>return False<tab><tab>return True",1,if jid is None :,if jid is None :,0.75,100,1
"def __call__(self, environ, start_response):<tab>script_name = environ.get(""HTTP_X_SCRIPT_NAME"")<tab>if script_name is not None:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(<tab><tab><tab><tab>""'X-Script-Name' header should not end in '/' (found: %r). ""<tab><tab><tab><tab>""Please fix your proxy's configuration."" % script_name<tab><tab><tab>)<tab><tab><tab>script_name = script_name.rstrip(""/"")<tab><tab>environ[""SCRIPT_NAME""] = script_name<tab>return super(ProxyFix, self).__call__(environ, start_response)",0,"if script_name . endswith ( ""/"" ) :","if not script_name . endswith ( ""/"" ) :",0.405016399,84.23626744,0.480769231
"def backwardKillParagraph(self, event):<tab>""""""Kill the previous paragraph.""""""<tab>c = self.c<tab>w = self.editWidget(event)<tab>if not w:<tab><tab>return<tab>self.beginCommand(w, undoType=""backward-kill-paragraph"")<tab>try:<tab><tab>self.backwardParagraphHelper(event, extend=True)<tab><tab>i, j = w.getSelectionRange()<tab><tab><IF-STMT><tab><tab><tab>i = min(i + 1, j)<tab><tab>c.killBufferCommands.kill(<tab><tab><tab>event, i, j, force=True, undoType=None  # Use i, j without change.<tab><tab>)<tab><tab>w.setSelectionRange(i, i, insert=i)<tab>finally:<tab><tab>self.endCommand(changed=True, setLabel=True)",0,if i > 0 :,if i < j :,0.064978772,23.64354023,0.6
"def bracket_replace(code):<tab>new = """"<tab>for e in bracket_split(code, [""()"", ""[]""], False):<tab><tab>if e[0] == ""["":<tab><tab><tab>name = ""#PYJSREPL"" + str(len(REPL)) + ""{""<tab><tab><tab>new += name<tab><tab><tab>REPL[name] = e<tab><tab><IF-STMT>  # can be a function call<tab><tab><tab>name = ""@PYJSREPL"" + str(len(REPL)) + ""}""<tab><tab><tab>new += name<tab><tab><tab>REPL[name] = e<tab><tab>else:<tab><tab><tab>new += e<tab>return new",0,"elif e [ 0 ] == ""("" :","elif e [ 0 ] == ""]"" :",0.853553391,74.19446627,1
"def regenerate(self, request, **kwargs):<tab>obj = self.get_object()<tab>if ""all"" in request.data:<tab><tab>for user in User.objects.all():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Token.objects.get(user=user)<tab><tab><tab><tab>token.delete()<tab><tab><tab><tab>Token.objects.create(user=user)<tab><tab>return Response("""")<tab>if ""username"" in request.data:<tab><tab>obj = get_object_or_404(User, username=request.data[""username""])<tab><tab>self.check_object_permissions(self.request, obj)<tab>token = Token.objects.get(user=obj)<tab>token.delete()<tab>token = Token.objects.create(user=obj)<tab>return Response({""token"": token.key})",0,if not user . is_anonymous ( ) :,"if request . data [ ""all"" ] :",0.019345088,5.522397784,0.333333333
"def signal_notebook_switch_page(self, notebook, current_page, index):<tab>if not hasattr(self.parent, ""rpc""):<tab><tab>return<tab># previous_page = notebook.get_nth_page(self.last_page_id)<tab>self.last_page_id = index<tab>for tab in self.tabs.values():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if hasattr(tab, ""load_campaign_information""):<tab><tab><tab>tab.load_campaign_information(force=False)",0,if current_page != tab . box :,if tab . get_nth_page ( ) != current_page :,0.040008887,14.2477888,0.730769231
"def get_word_parens_range(self, offset, opening=""("", closing="")""):<tab>end = self._find_word_end(offset)<tab>start_parens = self.code.index(opening, end)<tab>index = start_parens<tab>open_count = 0<tab>while index < len(self.code):<tab><tab><IF-STMT><tab><tab><tab>open_count += 1<tab><tab>if self.code[index] == closing:<tab><tab><tab>open_count -= 1<tab><tab>if open_count == 0:<tab><tab><tab>return (start_parens, index + 1)<tab><tab>index += 1<tab>return (start_parens, index)",1,if self . code [ index ] == opening :,if self . code [ index ] == opening :,0.75,100,1
"def append(self, child):<tab>if child not in (None, self):<tab><tab>tag = child_tag(self._tag)<tab><tab>if tag:<tab><tab><tab>if isinstance(child, Html):<tab><tab><tab><tab>if child.tag != tag:<tab><tab><tab><tab><tab>child = Html(tag, child)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child = Html(tag, child)<tab><tab>super().append(child)",0,"elif not child . startswith ( ""<%s"" % tag ) :",elif child . tag != tag :,0.024932096,5.789419402,0.320512821
"def cvPreprocess():<tab>import cv2<tab>imgarr_orig = []<tab>image_ext_list = ["".jpg"", "".png"", "".JPEG"", "".jpeg"", "".PNG"", "".JPG""]<tab>for file in onlyfiles:<tab><tab>fimg = imgroot + file<tab><tab><IF-STMT><tab><tab><tab>print(fimg + "" is not an image file"")<tab><tab><tab>continue<tab><tab>img1 = cv2.imread(fimg)<tab><tab>if img1 is None:<tab><tab><tab>print(""ERROR opening "", fimg)<tab><tab><tab>continue<tab><tab>img1 = cv2.resize(img1, (896, 896))<tab><tab>imgarr_orig.append(img1)<tab>return imgarr_orig",0,if any ( [ x in image_ext_list for x in fimg ] ) :,if fimg not in image_ext_list :,0.066977464,25.70722628,0.302083333
"def replace_nodes_in_symbol_table(<tab>symbols: SymbolTable, replacements: Dict[SymbolNode, SymbolNode]) -> None:<tab>for name, node in symbols.items():<tab><tab><IF-STMT><tab><tab><tab>if node.node in replacements:<tab><tab><tab><tab>new = replacements[node.node]<tab><tab><tab><tab>old = node.node<tab><tab><tab><tab>replace_object_state(new, old)<tab><tab><tab><tab>node.node = new<tab><tab><tab>if isinstance(node.node, (Var, TypeAlias)):<tab><tab><tab><tab># Handle them here just in case these aren't exposed through the AST.<tab><tab><tab><tab>node.node.accept(NodeReplaceVisitor(replacements))",0,if node . node :,"if isinstance ( node , SymbolNode ) :",0.02800146,7.267884212,0.511111111
"def __find_audio_offset(self, fileobj):<tab>byte = 0x00<tab>while not (byte & 0x80):<tab><tab>byte = ord(fileobj.read(1))<tab><tab>size = to_int_be(fileobj.read(3))<tab><tab>try:<tab><tab><tab>block_type = self.METADATA_BLOCKS[byte & 0x7F]<tab><tab>except IndexError:<tab><tab><tab>block_type = None<tab><tab><IF-STMT><tab><tab><tab># See comments in read_metadata_block; the size can't<tab><tab><tab># be trusted for Vorbis comment blocks and Picture block<tab><tab><tab>block_type(fileobj)<tab><tab>else:<tab><tab><tab>fileobj.read(size)<tab>return fileobj.tell()",0,if block_type and block_type . _distrust_size :,if block_type :,0.038857533,1.00E-10,0.636363636
"def startJail(self, name):<tab>with self.__lock:<tab><tab>jail = self.__jails[name]<tab><tab><IF-STMT><tab><tab><tab>jail.start()<tab><tab>elif name in self.__reload_state:<tab><tab><tab>logSys.info(""Jail %r reloaded"", name)<tab><tab><tab>del self.__reload_state[name]<tab><tab>if jail.idle:<tab><tab><tab>jail.idle = False",0,if not jail . isAlive ( ) :,if jail . started :,0.037304456,13.94345824,0.314814815
def get_resolved_dependencies(self):<tab>dependencies = []<tab>for dependency in self.envconfig.deps:<tab><tab><IF-STMT><tab><tab><tab>package = resolve_package(package_spec=dependency.name)<tab><tab><tab>if package != dependency.name:<tab><tab><tab><tab>dependency = dependency.__class__(package)<tab><tab>dependencies.append(dependency)<tab>return dependencies,0,if dependency . indexserver is None :,"if isinstance ( dependency . name , str ) :",0.035327427,9.980099404,0.222222222
"def _compile(self):<tab>if not self._compiled:<tab><tab># special case match-all query<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>try:<tab><tab><tab>self._tokens = boolExpression.parseString(self._query, parseAll=self.strict)<tab><tab>except ParseException:<tab><tab><tab>raise<tab><tab>self._compiled = True",0,if self . _is_match_all ( ) :,if self . _query is None :,0.090565314,23.20604146,0.55
"def _compute_features(self, images):<tab>output_blobs = self._forward(images)<tab>features = []<tab>for blob in output_blobs:<tab><tab>blob = blob.reshape((blob.shape[0], blob.shape[1]))<tab><tab><IF-STMT><tab><tab><tab>blob = blob.max(0)<tab><tab>else:<tab><tab><tab>blob = self.merge(blob)<tab><tab>features.append(blob)<tab>return np.vstack(features)",0,"if self . merge == ""max"" :",if self . use_max :,0.094532291,18.09449526,0.722222222
"def _list_shape_iter(shape):<tab>last_shape = _void<tab>for item in shape:<tab><tab><IF-STMT><tab><tab><tab>if last_shape is _void:<tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""invalid shape spec: Ellipsis cannot be the"" ""first element""<tab><tab><tab><tab>)<tab><tab><tab>while True:<tab><tab><tab><tab>yield last_shape<tab><tab>last_shape = item<tab><tab>yield item",0,if item is Ellipsis :,"if not isinstance ( item , Ellipsis ) :",0.02798121,6.74255593,0.26984127
"def tokenize_url(self, field):<tab>field = field.strip()<tab>tokens = field.split("":"")<tab>offset = 0<tab>if tokens[0] == ""http"":<tab><tab>offset = 1<tab><tab>dstport = 80<tab><tab><IF-STMT><tab><tab><tab>inttokens = tokens[2].split(""/"")<tab><tab><tab>dstport = int(inttokens[0])<tab>elif tokens[0] == ""https"":<tab><tab>dstport = 443<tab>else:<tab><tab>if tokens[-1] is not None:<tab><tab><tab>dstport = int(tokens[-1])<tab>tld = tldextract.extract(tokens[offset])<tab>fqdn = ""."".join(part for part in tld if part)<tab>return (fqdn, dstport)",0,if len ( tokens ) > 2 :,elif tokens [ 2 ] is not None :,0.016147872,6.274655311,0.083333333
"def assert_summary_equals(self, records, tag, step, value):<tab>for record in records[1:]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if record.step != step:<tab><tab><tab>continue<tab><tab>self.assertEqual(value, tf.make_ndarray(record.summary.value[0].tensor))<tab><tab>return<tab>self.fail(""Could not find record for tag {} and step {}"".format(tag, step))",0,if record . summary . value [ 0 ] . tag != tag :,if record . tag != tag :,0.449251604,35.0537778,0.403361345
"def getAttrDefault(key, fallback=None):<tab>try:<tab><tab>default = defaultValuesCache[key]<tab>except KeyError:<tab><tab>attrInfo = getAttributeInfo(key)<tab><tab><IF-STMT><tab><tab><tab>default = defaultValuesCache[key] = None<tab><tab>else:<tab><tab><tab>default = defaultValuesCache[key] = attrInfo.defaultValue<tab>if default is None:<tab><tab>default = fallback<tab>return default",1,if attrInfo is None :,if attrInfo is None :,0.75,100,1
"def __getattr__(self, key):<tab>if key in self._raw:<tab><tab>val = self._raw[key]<tab><tab>if key in (""date"",):<tab><tab><tab>return pd.Timestamp(val)<tab><tab>elif key in (""open"", ""close""):<tab><tab><tab>return pd.Timestamp(val).time()<tab><tab><IF-STMT><tab><tab><tab>return pd.Timestamp(val[:2] + "":"" + val[-2:]).time()<tab><tab>else:<tab><tab><tab>return val<tab>return super().__getattr__(key)",0,"elif key in ( ""session_open"" , ""session_close"" ) :","elif key == ""timestamp"" :",0.028155587,4.508804364,0.730769231
"def _combine_to_jointcaller(processed):<tab>""""""Add joint calling information to variants, while collapsing independent regions.""""""<tab>by_vrn_file = collections.OrderedDict()<tab>for data in (x[0] for x in processed):<tab><tab>key = (<tab><tab><tab>tz.get_in((""config"", ""algorithm"", ""jointcaller""), data),<tab><tab><tab>data[""vrn_file""],<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>by_vrn_file[key] = []<tab><tab>by_vrn_file[key].append(data)<tab>out = []<tab>for grouped_data in by_vrn_file.values():<tab><tab>cur = grouped_data[0]<tab><tab>out.append([cur])<tab>return out",1,if key not in by_vrn_file :,if key not in by_vrn_file :,0.75,100,1
"def assign_type(self, wb_type):<tab>if isinstance(wb_type, ListType):<tab><tab>assigned_type = self.params[""element_type""].assign_type(<tab><tab><tab>wb_type.params[""element_type""]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return ListType(assigned_type)<tab>return InvalidType()",0,"if not isinstance ( assigned_type , InvalidType ) :",if assigned_type is not None :,0.017951424,16.80157757,0.285714286
"def set_billing_hours_and_amount(self):<tab>if not self.project:<tab><tab>for timesheet in self.timesheets:<tab><tab><tab>ts_doc = frappe.get_doc(""Timesheet"", timesheet.time_sheet)<tab><tab><tab>if not timesheet.billing_hours and ts_doc.total_billable_hours:<tab><tab><tab><tab>timesheet.billing_hours = ts_doc.total_billable_hours<tab><tab><tab><IF-STMT><tab><tab><tab><tab>timesheet.billing_amount = ts_doc.total_billable_amount",1,if not timesheet . billing_amount and ts_doc . total_billable_amount :,if not timesheet . billing_amount and ts_doc . total_billable_amount :,0.75,100,1
"def add_changeset(repo_path, path_to_filename_in_archive):<tab>try:<tab><tab>subprocess.check_output(<tab><tab><tab>[""hg"", ""add"", path_to_filename_in_archive],<tab><tab><tab>stderr=subprocess.STDOUT,<tab><tab><tab>cwd=repo_path,<tab><tab>)<tab>except Exception as e:<tab><tab>error_message = ""Error adding '{}' to repository: {}"".format(<tab><tab><tab>path_to_filename_in_archive, unicodify(e)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>error_message += ""\nOutput was:\n%s"" % unicodify(e.output)<tab><tab>raise Exception(error_message)",0,"if isinstance ( e , subprocess . CalledProcessError ) :","if hasattr ( e , ""output"" ) :",0.071124364,20.55668085,0.404761905
"def full_path(self, *args, **query):<tab>""""""Return a full path""""""<tab>path = None<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""full_url() takes exactly 1 argument "" ""(%s given)"" % len(args)<tab><tab><tab>)<tab><tab>path = args[0]<tab>if not path:<tab><tab>path = self.path<tab>elif not path.startswith(""/""):<tab><tab>path = remove_double_slash(""%s/%s"" % (self.path, path))<tab>return iri_to_uri(path, query)",0,if len ( args ) > 1 :,if len ( args ) != 1 :,0.549040681,51.3345048,1
"def retry_http_basic_auth(self, host, req, realm):<tab>user, pw = self.passwd.find_user_password(realm, host)<tab>if pw is not None:<tab><tab>raw = ""%s:%s"" % (user, pw)<tab><tab>auth = ""Basic %s"" % base64.b64encode(raw).strip()<tab><tab><IF-STMT><tab><tab><tab>return None<tab><tab>req.add_unredirected_header(self.auth_header, auth)<tab><tab>return self.parent.open(req, timeout=req.timeout)<tab>else:<tab><tab>return None",0,"if req . get_header ( self . auth_header , None ) == auth :","if req . headers . get ( self . auth_header , None ) == auth :",0.448275825,75.73237978,0.3625
"def __call__(self, data):<tab>num_points = data.pos.shape[0]<tab>new_data = Data()<tab>for key in data.keys:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>item = data[key]<tab><tab>if torch.is_tensor(item) and num_points == item.shape[0]:<tab><tab><tab>item = item[self._indices].clone()<tab><tab>elif torch.is_tensor(item):<tab><tab><tab>item = item.clone()<tab><tab>setattr(new_data, key, item)<tab>return new_data",0,if key == KDTREE_KEY :,"if torch . is_tensor ( key ) and key == ""position"" :",0.045390644,10.12373487,0.364705882
def flat(tree):<tab>stack = [tree]<tab>result = []<tab>stack_pop = stack.pop<tab>stack_extend = stack.extend<tab>result_append = result.append<tab>while stack:<tab><tab>x = stack_pop()<tab><tab><IF-STMT><tab><tab><tab>result_append(x)<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>stack_extend(x)<tab><tab><tab>except TypeError:<tab><tab><tab><tab>result_append(x)<tab>return result[::-1],0,"if isinstance ( x , basestring ) :","if isinstance ( x , tuple ) :",0.549040681,59.46035575,0.666666667
"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab><IF-STMT><tab><tab><tab>pid = read_pid_file(""/var/run/dnsmasq.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab>if not kill(pid, ""dnsmasq""):<tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")",0,if not self . pid :,if self . pid is None :,0.104946328,27.77619034,0.257142857
"def set_xticklabels(self, labels=None, step=None, **kwargs):<tab>""""""Set x axis tick labels on the bottom row of the grid.""""""<tab>for ax in self.axes[-1, :]:<tab><tab><IF-STMT><tab><tab><tab>labels = [l.get_text() for l in ax.get_xticklabels()]<tab><tab><tab>if step is not None:<tab><tab><tab><tab>xticks = ax.get_xticks()[::step]<tab><tab><tab><tab>labels = labels[::step]<tab><tab><tab><tab>ax.set_xticks(xticks)<tab><tab>ax.set_xticklabels(labels, **kwargs)<tab>return self",1,if labels is None :,if labels is None :,0.75,100,1
"def _resolved_values(self):<tab>values = []<tab>for k, v in self.values.items() if hasattr(self.values, ""items"") else self.values:<tab><tab>if self.mapper:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>desc = _entity_descriptor(self.mapper, k)<tab><tab><tab><tab>values.extend(desc._bulk_update_tuples(v))<tab><tab><tab>elif isinstance(k, attributes.QueryableAttribute):<tab><tab><tab><tab>values.extend(k._bulk_update_tuples(v))<tab><tab><tab>else:<tab><tab><tab><tab>values.append((k, v))<tab><tab>else:<tab><tab><tab>values.append((k, v))<tab>return values",0,"if isinstance ( k , util . string_types ) :","if isinstance ( k , collections . Mapping ) :",0.485600785,38.24602283,0.558441558
"def _print_handles(self, text, handle_list):<tab>for handle in handle_list:<tab><tab>source, citation = self.get_source_or_citation(handle, False)<tab><tab>_LOG.debug(""\n\n\n"")<tab><tab><IF-STMT><tab><tab><tab>_LOG.debug(""---- %s -- source %s"" % (text, source.get_title()))<tab><tab>elif citation:<tab><tab><tab>_LOG.debug(""---- %s -- citation %s"" % (text, citation.get_page()))<tab><tab>else:<tab><tab><tab>_LOG.debug(""---- %s -- handle %s"" % (text, handle))",1,if source :,if source :,0.531170663,1.00E-10,1
"def test_items(self):<tab>expectException = (<tab><tab>len(self.sparse_data) < len(self.data)<tab><tab>and not self.instance.A._default_val is None<tab>)<tab>try:<tab><tab>test = self.instance.A.items()<tab><tab># self.assertEqual( type(test), list )<tab><tab><IF-STMT><tab><tab><tab>self.validateDict(self.sparse_data.items(), test)<tab><tab>else:<tab><tab><tab>self.validateDict(self.data.items(), test)<tab><tab># self.assertFalse(expectException)<tab>except ValueError:<tab><tab>if not expectException:<tab><tab><tab>raise",1,if self . instance . A . _default_val is None :,if self . instance . A . _default_val is None :,0.75,100,1
"def __new__(cls, name, bases, d):<tab>rv = type.__new__(cls, name, bases, d)<tab>if ""methods"" not in d:<tab><tab>methods = set(rv.methods or [])<tab><tab>for key, value in d.iteritems():<tab><tab><tab>if key in http_method_funcs:<tab><tab><tab><tab>methods.add(key.upper())<tab><tab># if we have no method at all in there we don't want to<tab><tab># add a method list.  (This is for instance the case for<tab><tab># the baseclass or another subclass of a base method view<tab><tab># that does not introduce new methods).<tab><tab><IF-STMT><tab><tab><tab>rv.methods = sorted(methods)<tab>return rv",1,if methods :,if methods :,0.531170663,1.00E-10,1
"def getResultSummary(self):<tab>if self.descriptionDone is not None or self.description is not None:<tab><tab>stepsumm = util.join_list(self.descriptionDone or self.description)<tab><tab><IF-STMT><tab><tab><tab>stepsumm += u"" "" + util.join_list(self.descriptionSuffix)<tab>else:<tab><tab>stepsumm = u""finished""<tab>if self.results != SUCCESS:<tab><tab>stepsumm += u"" (%s)"" % Results[self.results]<tab>return {u""step"": stepsumm}",0,if self . descriptionSuffix :,if self . descriptionSuffix is not None :,0.351498834,36.55552229,0.510204082
"def analyze_items(items, category_id, agg_data):<tab>for item in items:<tab><tab>if not agg_data[""cat_asp""].get(category_id, None):<tab><tab><tab>agg_data[""cat_asp""][category_id] = []<tab><tab>agg_data[""cat_asp""][category_id].append(<tab><tab><tab>float(item.sellingStatus.currentPrice.value)<tab><tab>)<tab><tab>if getattr(item.listingInfo, ""watchCount"", None):<tab><tab><tab>agg_data[""watch_count""] += int(item.listingInfo.watchCount)<tab><tab><IF-STMT><tab><tab><tab>agg_data[""postal_code""] = item.postalCode",0,"if getattr ( item , ""postalCode"" , None ) :",if item . postalCode is not None :,0.015805905,5.008676082,0.225
"def _Determine_Do(self):<tab>from os.path import join<tab>self.applicable = 1<tab>siloedPythonInstallDir = black.configure.items[""siloedPythonInstallDir""].Get()<tab>if sys.platform == ""darwin"":<tab><tab>siloedPyVer = black.configure.items[""siloedPyVer""].Get()<tab><tab>self.value = join(<tab><tab><tab>siloedPythonInstallDir, ""Python.framework"", ""Versions"", siloedPyVer, ""bin""<tab><tab>)<tab>else:<tab><tab>self.value = siloedPythonInstallDir<tab><tab><IF-STMT><tab><tab><tab>self.value = join(self.value, ""bin"")<tab>self.determined = 1",0,"if sys . platform != ""win32"" :",if os . path . exists ( self . value ) :,0.080101189,4.456882761,0.2
"def work(self):<tab>idle_times = 0<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>log.info(""Stop sync worker"")<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>job = self.commit_queue.get(timeout=self.timeout, block=True)<tab><tab><tab>if job[""type""] == ""commit"":<tab><tab><tab><tab>self.commits.append(job)<tab><tab><tab>log.debug(""Got a commit job"")<tab><tab><tab>idle_times = 0<tab><tab><tab>idle.clear()<tab><tab>except Empty:<tab><tab><tab>log.debug(""Nothing to do right now, going idle"")<tab><tab><tab>if idle_times > self.min_idle_times:<tab><tab><tab><tab>idle.set()<tab><tab><tab>idle_times += 1<tab><tab><tab>self.on_idle()",0,if shutting_down . is_set ( ) :,if self . stop_sync_worker :,0.023846651,5.708765135,0.636363636
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_instances(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def expand_group(client: Any, group_key: str):<tab>""""""Determines if an email is really a dl.""""""<tab># NOTE: Google Groups does not support other DLs as Group owners<tab># https://stackoverflow.com/questions/31552146/group-as-owner-or-manager-fails-with-400-error<tab>try:<tab><tab>response = list_members(client, group_key, propagate_errors=True)<tab><tab>if response.get(""members""):<tab><tab><tab>return [x[""email""] for x in response.get(""members"", [])]<tab>except HttpError as e:<tab><tab><IF-STMT><tab><tab><tab>pass<tab>return []",0,if e . resp . status == 404 :,if e . status == 404 :,0.346817274,65.48907867,0.481481481
"def validate_against_domain(<tab>cls, ensemble: Optional[""PolicyEnsemble""], domain: Optional[Domain]) -> None:<tab>if ensemble is None:<tab><tab>return<tab>for p in ensemble.policies:<tab><tab>if not isinstance(p, TwoStageFallbackPolicy):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise InvalidDomain(<tab><tab><tab><tab>""The intent '{0}' must be present in the ""<tab><tab><tab><tab>""domain file to use TwoStageFallbackPolicy. ""<tab><tab><tab><tab>""Either include the intent '{0}' in your domain ""<tab><tab><tab><tab>""or exclude the TwoStageFallbackPolicy from your ""<tab><tab><tab><tab>""policy configuration"".format(p.deny_suggestion_intent_name)<tab><tab><tab>)",0,if domain is None or p . deny_suggestion_intent_name not in domain . intents :,if domain is not None and p . intent_suggestion_intent_name not in domain :,0.231535302,52.08133638,0.318181818
"def _ndvi(nir_data, red_data):<tab>out = np.zeros_like(nir_data)<tab>rows, cols = nir_data.shape<tab>for y in range(0, rows):<tab><tab>for x in range(0, cols):<tab><tab><tab>nir = nir_data[y, x]<tab><tab><tab>red = red_data[y, x]<tab><tab><tab><IF-STMT>  # cover zero divison case<tab><tab><tab><tab>continue<tab><tab><tab>soma = nir + red<tab><tab><tab>out[y, x] = (nir - red) / soma<tab>return out",0,if nir == red :,if nir == 0 :,0.144778655,53.72849659,0.6
"def sysroot():<tab>cmd = ""set sysroot remote:/""<tab>if is_android():<tab><tab><IF-STMT><tab><tab><tab>gdb.execute(cmd)<tab><tab>else:<tab><tab><tab>print(message.notice(""sysroot is already set, skipping %r"" % cmd))",0,"if gdb . parameter ( ""sysroot"" ) == ""target:"" :",if gdb . exists ( cmd ) :,0.064268118,8.993236413,0.487179487
"def _run(self):<tab>when_pressed = 0.0<tab>pressed = False<tab>while not self._done.is_set():<tab><tab>now = time.monotonic()<tab><tab>if now - when_pressed > self._debounce_time:<tab><tab><tab>if GPIO.input(self._channel) == self._expected:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pressed = True<tab><tab><tab><tab><tab>when_pressed = now<tab><tab><tab><tab><tab>self._trigger(self._pressed_queue, self._pressed_callback)<tab><tab><tab>else:<tab><tab><tab><tab>if pressed:<tab><tab><tab><tab><tab>pressed = False<tab><tab><tab><tab><tab>self._trigger(self._released_queue, self._released_callback)<tab><tab>self._done.wait(0.05)",0,if not pressed :,if pressed :,0.096488528,1.00E-10,0.416666667
"def find_comment(line):<tab>""""""Finds the index of a comment # and returns None if not found""""""<tab>instring, instring_char = False, """"<tab>for i, char in enumerate(line):<tab><tab>if char in ('""', ""'""):<tab><tab><tab>if instring:<tab><tab><tab><tab>if char == instring_char:<tab><tab><tab><tab><tab>instring = False<tab><tab><tab><tab><tab>instring_char = """"<tab><tab><tab>else:<tab><tab><tab><tab>instring = True<tab><tab><tab><tab>instring_char = char<tab><tab><IF-STMT><tab><tab><tab>if not instring:<tab><tab><tab><tab>return i<tab>return None",0,"elif char == ""#"" :","elif char in ( '""' , ""'"" ) :",0.047573492,7.768562846,0.730769231
"def _deduplicate_data(self):<tab># Remove duplicate entries, without recreating self.data object<tab>dup_lines = []<tab>hash_set = set()<tab>for i, fields in enumerate(self.data):<tab><tab>fields_hash = hash(self.separator.join(fields))<tab><tab><IF-STMT><tab><tab><tab>dup_lines.append(i)<tab><tab><tab>log.debug(<tab><tab><tab><tab>'Found duplicate entry in tool data table ""%s"", but duplicates are not allowed, removing additional entry for: ""%s""',<tab><tab><tab><tab>self.name,<tab><tab><tab><tab>fields,<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>hash_set.add(fields_hash)<tab>for i in reversed(dup_lines):<tab><tab>self.data.pop(i)",1,if fields_hash in hash_set :,if fields_hash in hash_set :,0.75,100,1
"def sample_independent(<tab>self,<tab>study: Study,<tab>trial: FrozenTrial,<tab>param_name: str,<tab>param_distribution: distributions.BaseDistribution,) -> Any:<tab>self._raise_error_if_multi_objective(study)<tab>if self._warn_independent_sampling:<tab><tab>complete_trials = self._get_trials(study)<tab><tab><IF-STMT><tab><tab><tab>self._log_independent_sampling(trial, param_name)<tab>return self._independent_sampler.sample_independent(<tab><tab>study, trial, param_name, param_distribution<tab>)",0,if len ( complete_trials ) >= self . _n_startup_trials :,if complete_trials :,0.011515134,1.00E-10,0.46875
"def publish(self):<tab>""""""Publish new events to the subscribers.""""""<tab>while True:<tab><tab>event = await self.event_source.get()<tab><tab>str_buffer = []<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if isinstance(event, str):<tab><tab><tab>str_buffer.append(event)<tab><tab>elif event.type == EventTypes.BLOCK_VALID:<tab><tab><tab>str_buffer = map(json.dumps, eventify_block(event.data))<tab><tab>for str_item in str_buffer:<tab><tab><tab>for _, websocket in self.subscribers.items():<tab><tab><tab><tab>await websocket.send_str(str_item)",0,if event == POISON_PILL :,if event is None :,0.064978772,12.97584999,0.5
"def push(self):<tab>advice = self.check()<tab>if not self._context[""silent""]:<tab><tab>if not self.hasPendingSync(advice):<tab><tab><tab>print(""No changes to push."")<tab><tab><tab>return<tab><tab>choice = input(""Continue? y/N:"")<tab><tab><IF-STMT><tab><tab><tab>print(""Aborted on user command"")<tab><tab><tab>return<tab>print(""push local changes to remote..."")<tab>self._publish.syncRemote(self._context[""srcroot""], advice)",1,"if choice != ""y"" :","if choice != ""y"" :",0.75,100,1
"def readline(self, limit=-1):<tab>i = self._rbuf.find(""\n"")<tab>while i < 0 and not (0 < limit <= len(self._rbuf)):<tab><tab>new = self._raw_read(self._rbufsize)<tab><tab>if not new:<tab><tab><tab>break<tab><tab>i = new.find(""\n"")<tab><tab><IF-STMT><tab><tab><tab>i += len(self._rbuf)<tab><tab>self._rbuf = self._rbuf + new<tab>if i < 0:<tab><tab>i = len(self._rbuf)<tab>else:<tab><tab>i += 1<tab>if 0 <= limit < len(self._rbuf):<tab><tab>i = limit<tab>data, self._rbuf = self._rbuf[:i], self._rbuf[i:]<tab>return data",1,if i >= 0 :,if i >= 0 :,0.75,100,1
"def main():<tab>init_app(set_backends=True, routes=False)<tab>dry_run = ""--dry"" in sys.argv<tab>if not dry_run:<tab><tab>script_utils.add_file_logger(logger, __file__)<tab>with transaction.atomic():<tab><tab>normalize_source_tags()<tab><tab>add_claimed_tags()<tab><tab>add_osf_provider_tags()<tab><tab>add_prereg_campaign_tags()<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Dry run, transaction rolled back"")",1,if dry_run :,if dry_run :,0.531170663,1.00E-10,1
"def iter_segments(self):<tab>while not self.closed:<tab><tab>for chunk in filter(self.valid_chunk, self.chunks):<tab><tab><tab>self.logger.debug(""Adding chunk {0} to queue"", chunk.num)<tab><tab><tab>yield chunk<tab><tab><tab># End of stream<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>self.chunk_id = chunk.num + 1<tab><tab>if self.wait(self.module_info_reload_time):<tab><tab><tab>try:<tab><tab><tab><tab>self.process_module_info()<tab><tab><tab>except StreamError as err:<tab><tab><tab><tab>self.logger.warning(""Failed to process module info: {0}"", err)",1,if self . closed :,if self . closed :,0.75,100,1
"def SetItems(self, choices):<tab>self.choices = choices<tab>self.choice_names = self.get_choice_names()<tab>self.list_dlg.SetItems(self.get_choice_labels())<tab>labels = self.get_choice_labels()<tab>for i in range(len(self.choices)):<tab><tab>if self.choices[i][1] is None:<tab><tab><tab># Tag missing items<tab><tab><tab>self.list_dlg.SetItemBackgroundColour(i, ""pink"")<tab><tab><IF-STMT><tab><tab><tab># Tag duplicated items<tab><tab><tab>self.list_dlg.SetItemForegroundColour(i, ""grey"")<tab># on Mac, changing the items clears the current selection<tab>self.SetChecked(self.checked)<tab>self.Refresh()",0,"elif labels [ i ] . endswith ( ""Name!)"" ) :",elif self . choices [ i ] [ 1 ] in labels :,0.052586216,12.18514365,0.2
"def combine_logs(audit_logs, statement_text_logs):<tab>for audit_transaction in audit_logs:<tab><tab>for audit_query in audit_logs[audit_transaction]:<tab><tab><tab>matching_statement_text_logs = statement_text_logs.get(hash(audit_query))<tab><tab><tab>if matching_statement_text_logs:<tab><tab><tab><tab>statement_text_log = matching_statement_text_logs.pop()<tab><tab><tab><tab>if statement_text_log:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>audit_query.start_time = statement_text_log.start_time<tab><tab><tab><tab><tab>if statement_text_log.end_time:<tab><tab><tab><tab><tab><tab>audit_query.end_time = statement_text_log.end_time",1,if statement_text_log . start_time :,if statement_text_log . start_time :,0.75,100,1
"def handle_data(self, data):<tab>if self.in_span or self.in_div:<tab><tab>if data == ""No such user (please note that login is case sensitive)"":<tab><tab><tab>self.no_user = True<tab><tab><IF-STMT><tab><tab><tab>self.bad_pw = True<tab><tab>elif data == ""User with that email already exists"":<tab><tab><tab>self.already_exists = True",0,"elif data == ""Invalid password"" :","elif data == ""Bad Password"" :",0.60855926,51.3345048,1
"def K(exp):<tab>""Helper function to specify keymap""<tab>import re<tab>modifier_strs = []<tab>while True:<tab><tab>m = re.match(r""\A(C|Ctrl|M|Alt|Shift|Super|Win)-"", exp)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>modifier = m.group(1)<tab><tab>modifier_strs.append(modifier)<tab><tab>exp = re.sub(r""\A{}-"".format(modifier), """", exp)<tab>key_str = exp.upper()<tab>key = getattr(Key, key_str)<tab>return Combo(create_modifiers_from_strings(modifier_strs), key)",0,if m is None :,if not m :,0.039449619,16.37226967,0.277777778
"def local_min(self, hmap):<tab>rows = len(hmap)<tab>cols = len(hmap[0])<tab>min_list = []<tab>for row in range(rows):<tab><tab>for col in range(cols):<tab><tab><tab>for d_row, d_col in ((1, 0), (0, 1), (-1, 0), (0, -1)):<tab><tab><tab><tab>h_row = (row + d_row) % rows<tab><tab><tab><tab>h_col = (col + d_col) % cols<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>break<tab><tab><tab>else:<tab><tab><tab><tab>min_list.append((row, col))<tab>return min_list",0,if hmap [ h_row ] [ h_col ] < hmap [ row ] [ col ] :,if h_row == 0 or h_col == 0 :,0.133073006,11.85041961,0.28
"def _check_processing(self):<tab>now = time.time()<tab>self.mutex.acquire()<tab>while (<tab><tab>self.processing.qsize()<tab><tab>and self.processing.top<tab><tab>and self.processing.top.exetime < now<tab>):<tab><tab>task = self.processing.get_nowait()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>task.exetime = 0<tab><tab>self.priority_queue.put(task)<tab><tab>logger.info(""processing: retry %s"", task.taskid)<tab>self.mutex.release()",0,if task . taskid is None :,if task is None :,0.15920018,33.5160023,0.466666667
"def autoname(self):<tab>naming_method = frappe.db.get_value(""HR Settings"", None, ""emp_created_by"")<tab>if not naming_method:<tab><tab>throw(_(""Please setup Employee Naming System in Human Resource > HR Settings""))<tab>else:<tab><tab>if naming_method == ""Naming Series"":<tab><tab><tab>set_name_by_naming_series(self)<tab><tab><IF-STMT><tab><tab><tab>self.name = self.employee_number<tab><tab>elif naming_method == ""Full Name"":<tab><tab><tab>self.set_employee_name()<tab><tab><tab>self.name = self.employee_name<tab>self.employee = self.name",0,"elif naming_method == ""Employee Number"" :","elif naming_method == ""Naming Number"" :",0.627033187,70.16879391,1
"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab>if key[:6] == ""start_"":<tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if start is None:<tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab>elif key[:4] == ""end_"":<tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)",0,if end is None :,if start is not None and end is None :,0.371217171,27.77619034,0.244047619
"def parseAGL(filename):  # -> { 2126: 'Omega', ... }<tab>m = {}<tab>for line in readLines(filename):<tab><tab># Omega;2126<tab><tab># dalethatafpatah;05D3 05B2   # higher-level combinations; ignored<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>name, uc = tuple([c.strip() for c in line.split("";"")])<tab><tab><tab>if uc.find("" "") == -1:<tab><tab><tab><tab># it's a 1:1 mapping<tab><tab><tab><tab>m[int(uc, 16)] = name<tab>return m",0,"if len ( line ) > 0 and line [ 0 ] != ""#"" :",if line :,0.005751264,1.00E-10,0.293650794
"def password(self, password):<tab>self._password = password<tab>if password:<tab><tab><IF-STMT><tab><tab><tab>self.eeprint(<tab><tab><tab><tab>""Install sshpass to using password: https://duckduckgo.com/?q=install+sshpass\n""<tab><tab><tab><tab>+ ""Note! There are a lot of security reasons to stop using password auth.""<tab><tab><tab>)<tab><tab>verbose = ""-v"" if ""-v"" in self.sshpass else []<tab><tab>self.sshpass = [""sshpass"", ""-p"", password] + verbose<tab>else:<tab><tab>self.sshpass = []",0,"if not which ( ""sshpass"" ) :",if self . verbose :,0.022250825,5.707969034,0.333333333
"def test_region_redirects_multiple_requests(self):<tab>try:<tab><tab>response = self.client.list_objects(Bucket=self.bucket_name)<tab><tab>self.assertEqual(response[""ResponseMetadata""][""HTTPStatusCode""], 200)<tab><tab>second_response = self.client.list_objects(Bucket=self.bucket_name)<tab><tab>self.assertEqual(second_response[""ResponseMetadata""][""HTTPStatusCode""], 200)<tab>except ClientError as e:<tab><tab>error = e.response[""Error""].get(""Code"", None)<tab><tab><IF-STMT><tab><tab><tab>self.fail(""S3 client failed to redirect to the proper region."")",0,"if error == ""PermanentRedirect"" :","if error == ""InvalidRegion.NotFound"" :",0.394778655,45.18010018,1
"def get_action_type(action_space):<tab>""""""Method to get the action type to choose prob. dist. to sample actions from NN logits output""""""<tab>if isinstance(action_space, spaces.Box):<tab><tab>shape = action_space.shape<tab><tab>assert len(shape) == 1<tab><tab><IF-STMT><tab><tab><tab>return ""continuous""<tab><tab>else:<tab><tab><tab>return ""multi_continuous""<tab>elif isinstance(action_space, spaces.Discrete):<tab><tab>return ""discrete""<tab>elif isinstance(action_space, spaces.MultiDiscrete):<tab><tab>return ""multi_discrete""<tab>elif isinstance(action_space, spaces.MultiBinary):<tab><tab>return ""multi_binary""<tab>else:<tab><tab>raise NotImplementedError",0,if shape [ 0 ] == 1 :,if len ( shape ) == 1 :,0.079919566,33.03164318,0.5
def remove_stale_sockets(self):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>for sock_info in self.sockets.copy():<tab><tab><tab><tab>age = _time() - sock_info.last_checkout<tab><tab><tab><tab>if age > self.opts.max_idle_time_ms:<tab><tab><tab><tab><tab>self.sockets.remove(sock_info)<tab><tab><tab><tab><tab>sock_info.close()<tab>while len(self.sockets) + self.active_sockets < self.opts.min_pool_size:<tab><tab>sock_info = self.connect()<tab><tab>with self.lock:<tab><tab><tab>self.sockets.add(sock_info),0,if self . opts . max_idle_time_ms is not None :,if self . active_sockets :,0.09267236,7.678812443,0.380952381
"def _setReadyState(self, state: str) -> None:<tab>if state != self.__readyState:<tab><tab>self.__log_debug(""- %s -> %s"", self.__readyState, state)<tab><tab>self.__readyState = state<tab><tab>if state == ""open"":<tab><tab><tab>self.emit(""open"")<tab><tab><IF-STMT><tab><tab><tab>self.emit(""close"")<tab><tab><tab># no more events will be emitted, so remove all event listeners<tab><tab><tab># to facilitate garbage collection.<tab><tab><tab>self.remove_all_listeners()",0,"elif state == ""closed"" :","elif state == ""close"" :",0.642872021,59.46035575,1
"def currentLevel(self):<tab>currentStr = """"<tab>for stackType, stackValue in self.stackVals:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(stackValue, str):<tab><tab><tab><tab>currentStr += ""['"" + stackValue + ""']""<tab><tab><tab>else:  # numeric key...<tab><tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""listLike"":<tab><tab><tab>currentStr += ""["" + str(stackValue) + ""]""<tab><tab>elif stackType == ""getattr"":<tab><tab><tab>currentStr += "".__getattribute__('"" + stackValue + ""')""<tab><tab>else:<tab><tab><tab>raise Exception(f""Cannot get attribute of type {stackType}"")<tab>return currentStr",0,"if stackType == ""dict"" :","if stackType == ""object"" :",0.394778655,59.46035575,1
def filter_latest_pkgs(pkgs):<tab>pkgname2latest = {}<tab>for x in pkgs:<tab><tab>pkgname = core.normalize_pkgname(x.pkgname)<tab><tab><IF-STMT><tab><tab><tab>pkgname2latest[pkgname] = x<tab><tab>elif x.parsed_version > pkgname2latest[pkgname].parsed_version:<tab><tab><tab>pkgname2latest[pkgname] = x<tab>return pkgname2latest.values(),1,if pkgname not in pkgname2latest :,if pkgname not in pkgname2latest :,0.75,100,1
"def test_url_invalid_set():<tab>for line in URL_INVALID_TESTS.split(""\n""):<tab><tab># strip line, skip over empty lines<tab><tab>line = line.strip()<tab><tab>if line == """":<tab><tab><tab>continue<tab><tab># skip over comments<tab><tab>match = COMMENT.match(line)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>mbox = address.parse(line, strict=True)<tab><tab>assert_equal(mbox, None)",0,if match :,if not match :,0.113486237,1.00E-10,0.416666667
"def check_block(cls, block):<tab>if (<tab><tab>len(block) == 4<tab><tab>and block[0][0]<tab><tab>and block[0][0][0] == ""@""<tab><tab>and block[2][0]<tab><tab>and block[2][0][0] == ""+""<tab><tab>and block[1][0]<tab>):<tab><tab># Check the sequence line, make sure it contains only G/C/A/T/N<tab><tab>match = cls.bases_regexp.match(block[1][0])<tab><tab><IF-STMT><tab><tab><tab>start, end = match.span()<tab><tab><tab>if (end - start) == len(block[1][0]):<tab><tab><tab><tab>return True<tab>return False",1,if match :,if match :,0.531170663,1.00E-10,1
"def load_from_file(self, filename):<tab>self._filename = filename<tab>if os.path.exists(filename):<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""%s exists and is not a file"" % filename)<tab><tab>with open(filename, ""r"") as f:<tab><tab><tab>self._properties = json.load(f)<tab>else:<tab><tab>mkpath(os.path.dirname(filename))<tab><tab>self.save_to_file()",1,if not os . path . isfile ( filename ) :,if not os . path . isfile ( filename ) :,0.75,100,1
"def add_system_info_creds_to_config(creds):<tab>for user in creds:<tab><tab>ConfigService.creds_add_username(creds[user][""username""])<tab><tab>if ""password"" in creds[user] and creds[user][""password""]:<tab><tab><tab>ConfigService.creds_add_password(creds[user][""password""])<tab><tab><IF-STMT><tab><tab><tab>ConfigService.creds_add_lm_hash(creds[user][""lm_hash""])<tab><tab>if ""ntlm_hash"" in creds[user] and creds[user][""ntlm_hash""]:<tab><tab><tab>ConfigService.creds_add_ntlm_hash(creds[user][""ntlm_hash""])",1,"if ""lm_hash"" in creds [ user ] and creds [ user ] [ ""lm_hash"" ] :","if ""lm_hash"" in creds [ user ] and creds [ user ] [ ""lm_hash"" ] :",1,100,1
"def line_number(self):<tab>if self._line_range:<tab><tab>line_range = self._line_range<tab><tab><IF-STMT><tab><tab><tab>return ""%03d-%03d"" % (line_range.start, line_range.stop - 1)<tab><tab>else:<tab><tab><tab>return ""%03d"" % line_range.start",0,if line_range . stop - line_range . start > 1 :,if line_range . stop :,0.119722816,26.81673809,0.575
"def smooth(self, y, x=None, weights=None):<tab>if self.method == ""target_df"":<tab><tab><IF-STMT><tab><tab><tab>self.fit(y, x=x, weights=weights, pen=self.pen)<tab><tab>else:<tab><tab><tab>self.fit_target_df(y, x=x, weights=weights, df=self.target_df)<tab>elif self.method == ""optimize_gcv"":<tab><tab>self.fit_optimize_gcv(y, x=x, weights=weights)",0,"if hasattr ( self , ""pen"" ) :","if self . method == ""fit"" :",0.019627455,6.274655311,0.4
"def dict_from_cursor(data=None, keys=None):<tab>filtered_dict = {}<tab># Convert Uids to str<tab>data = bson_dumps(data)<tab>python_dict = json.loads(data)<tab>for key in keys:<tab><tab>value = python_dict.get(key)<tab><tab>if type(value) is dict:<tab><tab><tab># Try to get mongo_id<tab><tab><tab>mongo_id = value.get(""$oid"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value = mongo_id<tab><tab>if key == ""_id"":<tab><tab><tab>key = ""id""<tab><tab>filtered_dict[key] = value<tab>return filtered_dict",0,if mongo_id :,if mongo_id is not None :,0.090364769,1.00E-10,0.314285714
"def pytest_plugin_registered(self, plugin):<tab>nodeid = None<tab>try:<tab><tab>p = py.path.local(plugin.__file__)<tab>except AttributeError:<tab><tab>pass<tab>else:<tab><tab># construct the base nodeid which is later used to check<tab><tab># what fixtures are visible for particular tests (as denoted<tab><tab># by their test id)<tab><tab>if p.basename.startswith(""conftest.py""):<tab><tab><tab>nodeid = p.dirpath().relto(self.config.rootdir)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>nodeid = nodeid.replace(p.sep, ""/"")<tab>self.parsefactories(plugin, nodeid)",0,"if p . sep != ""/"" :",if nodeid is not None :,0.021817414,4.955725306,0.208333333
"def _escape_unsafe_values(self, *values):<tab># type: (str) -> Generator[str]<tab>""""""Escape unsafe values (name, section name) for API version 2.10 and below""""""<tab>for value in values:<tab><tab><IF-STMT><tab><tab><tab>yield value<tab><tab>else:<tab><tab><tab>self.task.log.info(<tab><tab><tab><tab>""Converting unsafe hyper parameter name/section '{}' to '{}'"".format(<tab><tab><tab><tab><tab>value, ""_"" + value<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><tab>yield ""_"" + value",0,if value not in UNSAFE_NAMES_2_10 :,if self . _is_hyperparameter_name ( value ) :,0.023749772,4.834632845,0.314814815
"def _identifier_split(self, identifier):<tab>""""""Return (name, start, end) string tuple from an identifier (PRIVATE).""""""<tab>if ""/"" in identifier:<tab><tab>name, start_end = identifier.rsplit(""/"", 1)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>start, end = start_end.split(""-"")<tab><tab><tab><tab>return name, int(start), int(end)<tab><tab><tab>except ValueError:<tab><tab><tab><tab># Non-integers after final '/' - fall through<tab><tab><tab><tab>pass<tab>return identifier, None, None",0,"if start_end . count ( ""-"" ) == 1 :","if ""-"" in start_end :",0.015145995,16.46692067,0.386666667
"def _complete_initial_layout(self):<tab>""""""Finish initial layout; called after toplevel win is positioned""""""<tab># Init tool group sizes by setting vpaned positions<tab>for paned in self._get_paneds():<tab><tab><IF-STMT><tab><tab><tab>pos = paned._initial_divider_position<tab><tab><tab>GLib.idle_add(paned.set_position, pos)",0,if paned . _initial_divider_position :,if paned . _initial_divider_position is not None :,0.351498834,66.52049901,0.444444444
"def _init_mapping(self, result):<tab>for wamp_uri, full_name in result.items():<tab><tab>for prefix in self.PREFIXES:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>short_name = full_name[len(prefix) :]<tab><tab><tab>self._mapping[short_name] = wamp_uri",0,if not full_name . startswith ( prefix ) :,if full_name . startswith ( prefix ) :,0.381254803,81.76129039,0.381818182
"def get_bounce_message(reason, ses_data, details):<tab>if reason != ""bounce"":<tab><tab>return<tab>if ses_data:<tab><tab>bouncedRecipients = ses_data.get(""bounce"", {}).get(""bouncedRecipients"")<tab><tab><IF-STMT><tab><tab><tab>recipient = bouncedRecipients[0]<tab><tab><tab>return recipient.get(""diagnosticCode"") or recipient.get(""status"")<tab>elif details:<tab><tab>return details",1,if bouncedRecipients :,if bouncedRecipients :,0.531170663,1.00E-10,1
"def do_If(self, node, elif_flag=False):<tab>self.div(""statement"")<tab>self.keyword(""elif"" if elif_flag else ""if"")<tab>self.visit(node.test)<tab>self.colon()<tab>self.div_body(node.body)<tab>if node.orelse:<tab><tab>node1 = node.orelse[0]<tab><tab><IF-STMT><tab><tab><tab>self.do_If(node1, elif_flag=True)<tab><tab>else:<tab><tab><tab>self.keyword(""else"")<tab><tab><tab>self.colon()<tab><tab><tab>self.div_body(node.orelse)<tab>self.end_div(""statement"")",0,"if isinstance ( node1 , ast . If ) and len ( node . orelse ) == 1 :","if isinstance ( node1 , If ) :",0.098306791,13.7177779,0.325
"def matches(self, filepath):<tab>matched = False<tab>parent_path = os.path.dirname(filepath)<tab>parent_path_dirs = split_path(parent_path)<tab>for pattern in self.patterns:<tab><tab>negative = pattern.exclusion<tab><tab>match = pattern.match(filepath)<tab><tab>if not match and parent_path != """":<tab><tab><tab>if len(pattern.dirs) <= len(parent_path_dirs):<tab><tab><tab><tab>match = pattern.match(<tab><tab><tab><tab><tab>os.path.sep.join(parent_path_dirs[: len(pattern.dirs)])<tab><tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>matched = not negative<tab>return matched",1,if match :,if match :,0.531170663,1.00E-10,1
"def test_11_wait_for_first_reboot_with_bhyve():<tab>if update_version is None:<tab><tab>pytest.skip(""No update found"")<tab>elif download_failed is True:<tab><tab>pytest.skip(f""Downloading {selected_trains} failed"")<tab>elif reboot is False:<tab><tab>pytest.skip(""Reboot is False skip"")<tab>else:<tab><tab><IF-STMT><tab><tab><tab>pytest.skip(""skip no vm_name"")<tab><tab>else:<tab><tab><tab>while vm_state(vm_name) != ""stopped"":<tab><tab><tab><tab>sleep(5)<tab><tab><tab>assert vm_start(vm_name) is True<tab>sleep(1)",1,if vm_name is None :,if vm_name is None :,0.75,100,1
def _check_network_private(test_network):<tab>test_net = ipaddress.IPNetwork(test_network)<tab>test_start = test_net.network<tab>test_end = test_net.broadcast<tab>for network in settings.vpn.safe_priv_subnets:<tab><tab>network = ipaddress.IPNetwork(network)<tab><tab>net_start = network.network<tab><tab>net_end = network.broadcast<tab><tab><IF-STMT><tab><tab><tab>return True<tab>return False,0,if test_start >= net_start and test_end <= net_end :,"if _check_network_private ( network , test_start , net_end ) :",0.016658773,14.40012445,0.5
def remove_stale_sockets(self):<tab>with self.lock:<tab><tab>if self.opts.max_idle_time_ms is not None:<tab><tab><tab>for sock_info in self.sockets.copy():<tab><tab><tab><tab>age = _time() - sock_info.last_checkout<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.sockets.remove(sock_info)<tab><tab><tab><tab><tab>sock_info.close()<tab>while len(self.sockets) + self.active_sockets < self.opts.min_pool_size:<tab><tab>sock_info = self.connect()<tab><tab>with self.lock:<tab><tab><tab>self.sockets.add(sock_info),1,if age > self . opts . max_idle_time_ms :,if age > self . opts . max_idle_time_ms :,0.75,100,1
"def hint(self, button):<tab>""""""As hilight, but marks GTK Button as well""""""<tab>active = None<tab>for b in self.button_widgets.values():<tab><tab>if b.widget.get_sensitive():<tab><tab><tab>b.widget.set_state(Gtk.StateType.NORMAL)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>active = b.widget<tab>if active is not None:<tab><tab>active.set_state(Gtk.StateType.ACTIVE)<tab>self.hilight(button)",0,if b . name == button :,if b . widget . get_active ( ) :,0.14103088,14.99110695,0.484848485
"def post_process(self, retcode):<tab>if not self.ok_codes:<tab><tab>return retcode<tab>for code in self.ok_codes:<tab><tab>self.log.debug(""Comparing %s with %s codes"", code, retcode)<tab><tab><IF-STMT><tab><tab><tab>self.log.info(""Exit code %s was changed to 0 by RCAssert plugin"", code)<tab><tab><tab>return 0<tab>self.log.info(<tab><tab>""Changing exit code to %s because RCAssert pass list was unsatisfied"",<tab><tab>self.fail_code,<tab>)<tab>return self.fail_code",0,if code == int ( retcode ) :,if retcode == 0 :,0.020245533,12.38075525,0.314814815
"def get_form_kwargs(self):<tab>result = super().get_form_kwargs()<tab>if self.request.method != ""POST"":<tab><tab>if self.initial:<tab><tab><tab># When going from other form (for example ZIP import)<tab><tab><tab>result.pop(""data"", None)<tab><tab><tab>result.pop(""files"", None)<tab><tab><IF-STMT><tab><tab><tab>result[""data""] = self.request.GET<tab>return result",0,if self . has_all_fields ( ) and not self . empty_form :,"elif self . request . method == ""GET"" :",0.145768902,4.885299006,0.2
"def transform_first_chunk(self, headers, chunk, finishing):<tab>if self._chunking:<tab><tab># No need to chunk the output if a Content-Length is specified<tab><tab><IF-STMT><tab><tab><tab>self._chunking = False<tab><tab>else:<tab><tab><tab>headers[""Transfer-Encoding""] = ""chunked""<tab><tab><tab>chunk = self.transform_chunk(chunk, finishing)<tab>return headers, chunk",0,"if ""Content-Length"" in headers or ""Transfer-Encoding"" in headers :","if headers [ ""Transfer-Encoding"" ] == ""chunked"" :",0.017863351,14.69410625,0.32
"def copy_stream(self, in_fd, out_fd, length=2 ** 64):<tab>total = 0<tab>while 1:<tab><tab>available_to_read = min(length - total, self.BUFFERSIZE)<tab><tab>data = in_fd.read(available_to_read)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>out_fd.write(data)<tab><tab>total += len(data)<tab><tab>self.session.report_progress(""Reading %s @ %#x"", in_fd.urn, total)",1,if not data :,if not data :,0.75,100,1
"def _trim_steps(self, num_steps):<tab>""""""Trims a given number of steps from the end of the sequence.""""""<tab>steps_trimmed = 0<tab>for i in reversed(range(len(self._events))):<tab><tab><IF-STMT><tab><tab><tab>if steps_trimmed == num_steps:<tab><tab><tab><tab>del self._events[i + 1 :]<tab><tab><tab><tab>break<tab><tab><tab>steps_trimmed += 1<tab><tab>elif i == 0:<tab><tab><tab>self._events = [<tab><tab><tab><tab>PolyphonicEvent(event_type=PolyphonicEvent.START, pitch=None)<tab><tab><tab>]<tab><tab><tab>break",0,if self . _events [ i ] . event_type == PolyphonicEvent . STEP_END :,if self . _events [ i ] . event_type == PolyphonicEvent . START :,0.678671315,79.78381199,0.824561404
"def get_img_file(dir_name: str) -> list:<tab>""""""Get all image file paths in several directories which have the same parent directory.""""""<tab>images = []<tab>for parent, _, filenames in os.walk(dir_name):<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>img_path = os.path.join(parent, filename)<tab><tab><tab>images.append(img_path)<tab>return images",0,if not is_image_file ( filename ) :,"if not filename . endswith ( "".png"" ) :",0.047578853,10.60031338,0.781818182
"def get_agg_title(clause):<tab>attr = str(clause.attribute)<tab>if clause.aggregation is None:<tab><tab><IF-STMT><tab><tab><tab>return attr[:15] + ""..."" + attr[-10:]<tab><tab>return f""{attr}""<tab>elif attr == ""Record"":<tab><tab>return f""Number of Records""<tab>else:<tab><tab>if len(attr) > 15:<tab><tab><tab>return f""{clause._aggregation_name.capitalize()} of {attr[:15]}...""<tab><tab>return f""{clause._aggregation_name.capitalize()} of {attr}""",0,if len ( attr ) > 25 :,if len ( attr ) > 15 :,0.605621306,70.71067812,0.666666667
"def _check_realign(data):<tab>""""""Check for realignment, which is not supported in GATK4""""""<tab>if ""gatk4"" not in data[""algorithm""].get(""tools_off"", []) and not ""gatk4"" == data[<tab><tab>""algorithm""<tab>].get(""tools_off""):<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""In sample %s, realign specified but it is not supported for GATK4. ""<tab><tab><tab><tab>""Realignment is generally not necessary for most variant callers.""<tab><tab><tab><tab>% (dd.get_sample_name(data))<tab><tab><tab>)",0,"if data [ ""algorithm"" ] . get ( ""realign"" ) :","if data [ ""algorithm"" ] . get ( ""realign"" , [ ] ) :",0.424054052,73.51460991,1
"def __call__(self, target):<tab>if ""weights"" not in target.temp:<tab><tab>return True<tab>targets = target.temp[""weights""]<tab>for cname in target.children:<tab><tab>if cname in targets:<tab><tab><tab>c = target.children[cname]<tab><tab><tab>deviation = abs((c.weight - targets[cname]) / targets[cname])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>if ""cash"" in target.temp:<tab><tab>cash_deviation = abs(<tab><tab><tab>(target.capital - targets.value) / targets.value - target.temp[""cash""]<tab><tab>)<tab><tab>if cash_deviation > self.tolerance:<tab><tab><tab>return True<tab>return False",1,if deviation > self . tolerance :,if deviation > self . tolerance :,0.75,100,1
"def status_string(self):<tab>if not self.live:<tab><tab><IF-STMT><tab><tab><tab>return _(""expired"")<tab><tab>elif self.approved_schedule:<tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",0,if self . expired :,if self . has_unpublished_changes :,0.394778655,19.07082808,0.7
"def __getitem__(self, item):<tab>if item == ""EntityId"":<tab><tab><IF-STMT><tab><tab><tab>if self.use_uuid:<tab><tab><tab><tab>super(PlayerDict, self).__setitem__(<tab><tab><tab><tab><tab>""EntityId"", self.get_name_from_uuid()<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>super(PlayerDict, self).__setitem__(""EntityId"", self._name)<tab>return super(PlayerDict, self).__getitem__(item)",0,"if ""EntityId"" not in self :",if self . _name is None :,0.087978913,7.267884212,0.285714286
"def _to_num_bytes(java_mem_str):<tab>if isinstance(java_mem_str, string_types):<tab><tab>for i, magnitude in enumerate((""k"", ""m"", ""g"", ""t""), start=1):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return int(java_mem_str[:-1]) * 1024 ** i<tab>return int(java_mem_str)",0,if java_mem_str . lower ( ) . endswith ( magnitude ) :,"if java_mem_str . endswith ( "".png"" ) :",0.079108251,49.61577856,0.377777778
"def test_layout_instantiate_subplots(self):<tab>layout = (<tab><tab>Curve(range(10))<tab><tab>+ Curve(range(10))<tab><tab>+ Image(np.random.rand(10, 10))<tab><tab>+ Curve(range(10))<tab><tab>+ Curve(range(10))<tab>)<tab>plot = mpl_renderer.get_plot(layout)<tab>positions = [(0, 0), (0, 1), (0, 2), (0, 3), (1, 0)]<tab>self.assertEqual(sorted(plot.subplots.keys()), positions)<tab>for i, pos in enumerate(positions):<tab><tab>adjoint = plot.subplots[pos]<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(adjoint.subplots[""main""].layout_num, i + 1)",0,"if ""main"" in adjoint . subplots :","if adjoint . subplots . get ( ""main"" ) is not None :",0.072185083,17.67874865,0.2
"def __str__(self):<tab>width = int(os.environ.get(""COLUMNS"", ""80""))<tab>s = (<tab><tab>self.getSynopsis()<tab><tab>+ ""\n""<tab><tab>+ ""(use 'tahoe --help' to view global options)\n""<tab><tab>+ ""\n""<tab><tab>+ self.getUsage()<tab>)<tab>if self.description:<tab><tab>s += ""\n"" + wrap_paragraphs(self.description, width) + ""\n""<tab>if self.description_unwrapped:<tab><tab>du = textwrap.dedent(self.description_unwrapped)<tab><tab><IF-STMT><tab><tab><tab>du = du[1:]<tab><tab>s += ""\n"" + du + ""\n""<tab>return s",0,"if du . startswith ( ""\n"" ) :","if du [ 0 ] == ""\n"" :",0.036228951,26.20251007,0.6
"def open(self, path, mode=""rb"", cryptoType=-1, cryptoKey=-1, cryptoCounter=-1):<tab>if path is not None:<tab><tab><IF-STMT><tab><tab><tab>self.close()<tab><tab>if isinstance(path, str):<tab><tab><tab>self.f = open(path, mode)<tab><tab><tab>self._path = path<tab><tab><tab>self.f.seek(0, 2)<tab><tab><tab>self.size = self.f.tell()<tab><tab><tab>self.f.seek(0, 0)<tab><tab>elif isinstance(path, BaseFile):<tab><tab><tab>self.f = path<tab><tab><tab>self.size = path.size<tab><tab>else:<tab><tab><tab>raise IOError(""Invalid file parameter"")<tab>self.setupCrypto(cryptoType, cryptoKey, cryptoCounter)",0,if self . isOpen ( ) :,if self . _closed :,0.094532291,27.48254571,0.722222222
"def open_spotify():<tab>if sys.platform == ""win32"":<tab><tab><IF-STMT><tab><tab><tab>path = os.getenv(""APPDATA"") + ""\Spotify\Spotify.exe""<tab><tab><tab>subprocess.Popen(path)<tab><tab>else:<tab><tab><tab>pass<tab>elif sys.platform == ""linux"":<tab><tab>if getwindowtitle() == """":<tab><tab><tab>subprocess.Popen(""spotify"")<tab><tab>else:<tab><tab><tab>pass<tab>elif sys.platform == ""darwin"":<tab><tab># I don't have a mac so I don't know if this actually works<tab><tab># If it does, please let me know, if it doesn't please fix it :)<tab><tab>if getwindowtitle() == """":<tab><tab><tab>subprocess.Popen(""open -a Spotify"")<tab><tab>else:<tab><tab><tab>pass<tab>else:<tab><tab>pass",1,"if getwindowtitle ( ) == """" :","if getwindowtitle ( ) == """" :",0.75,100,1
def get_search_columns_list(self) -> List[str]:<tab>ret_lst = list()<tab>for col_name in self.get_columns_list():<tab><tab><IF-STMT><tab><tab><tab>tmp_prop = self.get_property_first_col(col_name).name<tab><tab><tab>if (<tab><tab><tab><tab>(not self.is_pk(tmp_prop))<tab><tab><tab><tab>and (not self.is_fk(tmp_prop))<tab><tab><tab><tab>and (not self.is_image(col_name))<tab><tab><tab><tab>and (not self.is_file(col_name))<tab><tab><tab>):<tab><tab><tab><tab>ret_lst.append(col_name)<tab><tab>else:<tab><tab><tab>ret_lst.append(col_name)<tab>return ret_lst,0,if not self . is_relation ( col_name ) :,if not self . is_col_empty ( col_name ) :,0.549889319,64.75445426,1
"def get_artist(self, name):<tab>artist = self.artists.get(name)<tab>if not artist:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>artist = q(m.Artist).filter_by(name=name).one()<tab><tab><tab>except NoResultFound:<tab><tab><tab><tab>pass<tab><tab><tab>if artist and self.ram_cache:<tab><tab><tab><tab>self.add_artist(artist)<tab>return artist",0,if self . use_db :,if self . use_ram :,0.394778655,64.34588842,1
"def _find_glob_metadata(cur_files, metadata):<tab>md_key = None<tab>for check_key in metadata.keys():<tab><tab>matches = 0<tab><tab><IF-STMT><tab><tab><tab>for fname in cur_files:<tab><tab><tab><tab>if fnmatch.fnmatch(fname, ""*/%s"" % check_key):<tab><tab><tab><tab><tab>matches += 1<tab><tab>if matches == len(cur_files):<tab><tab><tab>md_key = check_key<tab><tab><tab>break<tab>if md_key:<tab><tab>return metadata[md_key]",0,"if ""*"" in check_key :",if check_key :,0.067674239,1.00E-10,0.619047619
"def extract_copy(<tab>data: bytearray, mem: bytearray, memstart: int, datastart: int, size: int):<tab>for i in range(size):<tab><tab><IF-STMT><tab><tab><tab>mem[memstart + i] = data[datastart + i]<tab><tab>else:<tab><tab><tab>mem[memstart + i] = 0",1,if datastart + i < len ( data ) :,if datastart + i < len ( data ) :,0.75,100,1
"def rpc_get_image(self, sender, image_hash):<tab>self.router.addContact(sender)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(""Image hash is not 20 characters %s"" % image_hash)<tab><tab><tab>raise Exception(""Invalid image hash"")<tab><tab>self.log.info(""serving image %s to %s"" % (image_hash.encode(""hex""), sender))<tab><tab>with open(self.db.filemap.get_file(image_hash.encode(""hex"")), ""rb"") as filename:<tab><tab><tab>image = filename.read()<tab><tab>return [image]<tab>except Exception:<tab><tab>self.log.warning(""could not find image %s"" % image_hash[:20].encode(""hex""))<tab><tab>return None",0,if len ( image_hash ) != 20 :,if image_hash [ : 20 ] != 20 :,0.074583096,31.70233139,0.666666667
"def preprocess_mnist(raw, withlabel, ndim, scale, image_dtype, label_dtype, rgb_format):<tab>images = raw[""x""]<tab>if ndim == 2:<tab><tab>images = images.reshape(-1, 28, 28)<tab>elif ndim == 3:<tab><tab>images = images.reshape(-1, 1, 28, 28)<tab><tab><IF-STMT><tab><tab><tab>images = np.broadcast_to(images, (len(images), 3) + images.shape[2:])<tab>elif ndim != 1:<tab><tab>raise ValueError(""invalid ndim for MNIST dataset"")<tab>images = images.astype(image_dtype)<tab>images *= scale / 255.0<tab>if withlabel:<tab><tab>labels = raw[""y""].astype(label_dtype)<tab><tab>return images, labels<tab>return images",0,if rgb_format :,if len ( images . shape ) > 2 :,0.0422451,1.00E-10,0.285714286
"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name:<tab><tab><tab>if self.stdlibhighlighting and value in self.stdlib_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.c99highlighting and value in self.c99_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",0,elif self . platformhighlighting and value in self . linux_types :,elif self . stricthighlighting and value in self . strict_types :,0.741634892,47.58733096,0.75
"def _match(self, pattern, input_string, context=None):<tab>for index in find_all(input_string, pattern, **self._kwargs):<tab><tab>match = Match(<tab><tab><tab>index,<tab><tab><tab>index + len(pattern),<tab><tab><tab>pattern=self,<tab><tab><tab>input_string=input_string,<tab><tab><tab>**self._match_kwargs<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>yield match",0,if match :,if match is not None :,0.090364769,1.00E-10,0.4
"def https_open(self, req):<tab>try:<tab><tab>return self.do_open(do_connection, req)<tab>except Exception as err_msg:<tab><tab>try:<tab><tab><tab>error_msg = str(err_msg.args[0]).split(""] "")[1] + "".""<tab><tab>except IndexError:<tab><tab><tab>error_msg = str(err_msg.args[0]) + "".""<tab><tab>if settings.INIT_TEST == True:<tab><tab><tab>if settings.VERBOSITY_LEVEL < 2:<tab><tab><tab><tab>print(settings.FAIL_STATUS)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print("""")<tab><tab>print(settings.print_critical_msg(error_msg))<tab><tab>raise SystemExit()",0,if settings . VERBOSITY_LEVEL < 1 :,if settings . VERBOSITY_LEVEL < 2 :,0.574113272,75.06238538,0.6
"def recursive_select(tag):<tab><IF-STMT><tab><tab>print(<tab><tab><tab>'<tab>Calling select(""%s"") recursively on %s %s'<tab><tab><tab>% (next_token, tag.name, tag.attrs)<tab><tab>)<tab><tab>print(""-"" * 40)<tab>for i in tag.select(next_token, recursive_candidate_generator):<tab><tab>if self._select_debug:<tab><tab><tab>print(""(Recursive select picked up candidate %s %s)"" % (i.name, i.attrs))<tab><tab>yield i<tab>if self._select_debug:<tab><tab>print(""-"" * 40)",1,if self . _select_debug :,if self . _select_debug :,0.75,100,1
"def detect(self, agent, result):<tab># -> True/None<tab>word = self.checkWords(agent)<tab>if word:<tab><tab>result[self.info_type] = dict(name=self.name)<tab><tab>result[""bot""] = self.bot<tab><tab>version = self.getVersion(agent, word)<tab><tab>if version:<tab><tab><tab>result[self.info_type][""version""] = version<tab><tab><IF-STMT><tab><tab><tab>result[""platform""] = {""name"": self.platform, ""version"": version}<tab><tab>return True",1,if self . platform :,if self . platform :,0.75,100,1
"def is_display_marc(data):<tab>if data.startswith(<tab><tab>""(Length implementation at offset 22 should hold a digit. Assuming 0)""<tab>):<tab><tab>return True<tab>try:<tab><tab>lines = data.split(""\n"")<tab><tab>leader = lines[0]<tab><tab>assert re_leader.match(leader)<tab><tab>for line in lines[1:]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert re_control.match(line)<tab><tab><tab>else:<tab><tab><tab><tab>assert re_data.match(line)<tab><tab>return True<tab>except AssertionError:<tab><tab>return False",0,"if line . startswith ( ""00"" ) :",if re_leader . match ( line ) :,0.039168582,11.04479557,0.4
"def nodejslib(self):<tab>if not hasattr(self, ""_nodejslib""):<tab><tab>for lib in self.libs:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._nodejslib = lib<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>self._nodejslib = None<tab>return self._nodejslib",0,"if lib . name == ""node.js stdlib"" :","if hasattr ( lib , ""nodejslib"" ) :",0.019345088,4.648378983,0.4
"def get(self, key, default=None, type=None):<tab>for d in self.dicts:<tab><tab><IF-STMT><tab><tab><tab>if type is not None:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>return type(d[key])<tab><tab><tab><tab>except ValueError:<tab><tab><tab><tab><tab>continue<tab><tab><tab>return d[key]<tab>return default",1,if key in d :,if key in d :,0.75,100,1
"def add_callers(target, source):<tab>""""""Combine two caller lists in a single list.""""""<tab>new_callers = {}<tab>for func, caller in target.items():<tab><tab>new_callers[func] = caller<tab>for func, caller in source.items():<tab><tab>if func in new_callers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab># format used by cProfile<tab><tab><tab><tab>new_callers[func] = tuple(<tab><tab><tab><tab><tab>[i[0] + i[1] for i in zip(caller, new_callers[func])]<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab># format used by profile<tab><tab><tab><tab>new_callers[func] += caller<tab><tab>else:<tab><tab><tab>new_callers[func] = caller<tab>return new_callers",1,"if isinstance ( caller , tuple ) :","if isinstance ( caller , tuple ) :",0.75,100,1
"def work(src, vsi_dest):<tab>gdal.Mkdir(vsi_dest, 0o777)<tab>for item in src.iterdir():<tab><tab>item_vsi_dest = os.path.join(vsi_dest, item.name)<tab><tab><IF-STMT><tab><tab><tab>work(item, item_vsi_dest)<tab><tab>else:<tab><tab><tab>VsiFileSystem.copy_to(str(item), item_vsi_dest)",0,if item . is_dir ( ) :,if os . path . isdir ( item_vsi_dest ) :,0.036747879,7.768562846,0.30952381
"def __getitem__(self, key):<tab>if isinstance(key, raw_types.Qid):<tab><tab>return self._operation_touching(key)<tab>elif isinstance(key, Iterable):<tab><tab>qubits_to_keep = frozenset(key)<tab><tab>ops_to_keep = tuple(<tab><tab><tab>op<tab><tab><tab>for op in self.operations<tab><tab><tab><IF-STMT><tab><tab>)<tab><tab>return Moment(ops_to_keep)",0,if not qubits_to_keep . isdisjoint ( frozenset ( op . qubits ) ),if op not in qubits_to_keep,0.009944017,20.63670334,0.234375
"def mlt_version_is_greater_correct(test_version):<tab>runtime_ver = mlt_version.split(""."")<tab>test_ver = test_version.split(""."")<tab>if runtime_ver[0] > test_ver[0]:<tab><tab>return True<tab>elif runtime_ver[0] == test_ver[0]:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif runtime_ver[1] == test_ver[1]:<tab><tab><tab>if runtime_ver[2] > test_ver[2]:<tab><tab><tab><tab>return True<tab>return False",1,if runtime_ver [ 1 ] > test_ver [ 1 ] :,if runtime_ver [ 1 ] > test_ver [ 1 ] :,0.75,100,1
"def populate(self, item):<tab>path = self.getItemPath(item)<tab>for name in sorted(os.listdir(path)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pathname = os.path.join(path, name)<tab><tab>if os.path.isdir(pathname):<tab><tab><tab>item.addChild(name, True)<tab><tab>elif name.lower().endswith("".target"") and os.path.isfile(pathname):<tab><tab><tab>item.addChild(name, False)",0,"if name [ 0 ] == ""."" :","if name . startswith ( ""_"" ) :",0.034400971,9.993744304,0.6
"def runTests(self):<tab>""""""Run tests""""""<tab># fire plugin hook<tab>runner = self._makeRunner()<tab>try:<tab><tab>self.result = runner.run(self.test)<tab>except Exception as e:<tab><tab>log.exception(""Internal Error"")<tab><tab>sys.stderr.write(""Internal Error: runTests aborted: %s\n"" % (e))<tab><tab><IF-STMT><tab><tab><tab>sys.exit(1)<tab>if self.exit:<tab><tab>sys.exit(not self.result.wasSuccessful())",1,if self . exit :,if self . exit :,0.75,100,1
"def __setitem__(self, key, value):<tab>""""""Like :meth:`set` but also supports index/slice based setting.""""""<tab>if isinstance(key, (slice, int)):<tab><tab><IF-STMT><tab><tab><tab>value = [value]<tab><tab>value = [<tab><tab><tab>(_unicodify_header_value(k), _unicodify_header_value(v)) for (k, v) in value<tab><tab>]<tab><tab>for (_, v) in value:<tab><tab><tab>self._validate_value(v)<tab><tab>if isinstance(key, int):<tab><tab><tab>self._list[key] = value[0]<tab><tab>else:<tab><tab><tab>self._list[key] = value<tab>else:<tab><tab>self.set(key, value)",1,"if isinstance ( key , int ) :","if isinstance ( key , int ) :",0.75,100,1
"def toggle_fullscreen_hide_tabbar(self):<tab>if self.is_fullscreen():<tab><tab><IF-STMT><tab><tab><tab>if self.guake and self.guake.notebook_manager:<tab><tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(False)<tab>else:<tab><tab>if self.guake and self.guake.notebook_manager:<tab><tab><tab>v = self.settings.general.get_boolean(""window-tabbar"")<tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(v)",0,"if self . settings . general . get_boolean ( ""fullscreen-hide-tabbar"" ) :","if self . settings . general . get_boolean ( ""window-tabbar"" ) :",0.635663651,81.53551038,1
"def clear_doc(self, docname: str) -> None:<tab>for sChild in self._children:<tab><tab>sChild.clear_doc(docname)<tab><tab><IF-STMT><tab><tab><tab>sChild.declaration = None<tab><tab><tab>sChild.docname = None<tab><tab><tab>sChild.line = None<tab><tab><tab>if sChild.siblingAbove is not None:<tab><tab><tab><tab>sChild.siblingAbove.siblingBelow = sChild.siblingBelow<tab><tab><tab>if sChild.siblingBelow is not None:<tab><tab><tab><tab>sChild.siblingBelow.siblingAbove = sChild.siblingAbove<tab><tab><tab>sChild.siblingAbove = None<tab><tab><tab>sChild.siblingBelow = None",0,if sChild . declaration and sChild . docname == docname :,if sChild . declaration is None :,0.221602387,21.28139771,0.433333333
"def visit_hierarchichttprequest(self, request):<tab>files = []<tab>body_file = request.config.get(""body-file"")<tab>if body_file:<tab><tab>files.append(body_file)<tab>uploads = request.config.get(""upload-files"", [])<tab>files.extend([x[""path""] for x in uploads if not has_variable_pattern(x[""path""])])<tab>if ""jsr223"" in request.config:<tab><tab>jsrs = request.config.get(""jsr223"")<tab><tab><IF-STMT><tab><tab><tab>jsrs = [jsrs]<tab><tab>for jsr in jsrs:<tab><tab><tab>if ""script-file"" in jsr:<tab><tab><tab><tab>files.append(jsr.get(""script-file""))<tab>return files",0,"if isinstance ( jsrs , dict ) :",if not has_variable_pattern ( jsrs ) :,0.04562055,11.20846675,0.481481481
"def find_commands(management_dir):<tab># Modified version of function from django/core/management/__init__.py.<tab>command_dir = os.path.join(management_dir, ""commands"")<tab>commands = []<tab>try:<tab><tab>for f in os.listdir(command_dir):<tab><tab><tab>if f.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><tab>elif f.endswith("".py"") and f[:-3] not in commands:<tab><tab><tab><tab>commands.append(f[:-3])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>commands.append(f[:-4])<tab>except OSError:<tab><tab>pass<tab>return commands",0,"elif f . endswith ( "".pyc"" ) and f [ : - 4 ] not in commands :","elif f . endswith ( "".py"" ) and f [ - 4 : ] not in commands :",0.538675135,65.47599888,1
"def show_panel(panel_id):<tab># Iterate positions to find where panel is and bring it to front.<tab>for position in _positions_names:<tab><tab>pos_panel_ids = _get_position_panels(position)<tab><tab>if len(pos_panel_ids) == 0:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id]<tab><tab>notebook = _position_notebooks[position]<tab><tab>for i in range(0, notebook.get_n_pages()):<tab><tab><tab>notebook_page = notebook.get_nth_page(i)<tab><tab><tab>if notebook_page == panel_widget:<tab><tab><tab><tab>notebook.set_current_page(i)",0,if len ( pos_panel_ids ) == 1 :,if panel_id not in pos_panel_ids :,0.019830745,31.72721879,0.333333333
"def is_cwl_record(d):<tab>""""""Check if an input is a CWL record, from any level of nesting.""""""<tab>if isinstance(d, dict):<tab><tab><IF-STMT><tab><tab><tab>return d<tab><tab>else:<tab><tab><tab>recs = list(<tab><tab><tab><tab>filter(lambda x: x is not None, [is_cwl_record(v) for v in d.values()])<tab><tab><tab>)<tab><tab><tab>return recs[0] if recs else None<tab>else:<tab><tab>return None",0,"if d . get ( ""type"" ) == ""record"" :",if is_cwl_record ( d ) :,0.01623727,3.983253478,0.733333333
"def _flags_data_(self, main_mod, model_paths, flags_dest):<tab>try:<tab><tab>sys_path, mod_path = python_util.find_module(main_mod, model_paths)<tab>except ImportError as e:<tab><tab><IF-STMT><tab><tab><tab>self.log.warning(""cannot import flags from %s: %s"", main_mod, e)<tab><tab>return {}<tab>else:<tab><tab>package = self._main_spec_package(main_mod)<tab><tab>return self._flags_data_for_path(mod_path, package, sys_path, flags_dest)",0,"if os . getenv ( ""NO_WARN_FLAGS_IMPORT"" ) != ""1"" :",if self . verbose :,0.014393213,0.573056795,0.333333333
"def __str__(self):<tab>messages = [self.__class__.__name__, ""(""]<tab>annotation = self.annotation<tab>messages.append(self.annotation.surrounds_attribute or """")<tab>if annotation.tag_attributes:<tab><tab><IF-STMT><tab><tab><tab>messages.append("";"")<tab><tab>for (f, ta, ea) in self.tag_data:<tab><tab><tab>messages += [ea, ': attribute ""', ta, '""']<tab>start, end = annotation.start_index, annotation.end_index<tab>messages.append("", template[%s:%s])"" % (start, end))<tab>return """".join(map(str, messages))",0,if annotation . surrounds_attribute :,if len ( self . tag_data ) > 0 :,0.025806627,4.789232204,0.30952381
"def _on_view_count_change(self, *args):<tab>with self.output:<tab><tab>logger.debug(""views: %d"", self.image.view_count)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>logger.debug(""was dirty, and needs an update"")<tab><tab><tab><tab>self.update()<tab><tab><tab>finally:<tab><tab><tab><tab>self._dirty = False",0,if self . _dirty and self . image . view_count > 0 :,if self . _dirty :,0.118839424,15.02072383,0.407407407
"def network_state(self, device):<tab>cmd = [""tc"", ""qdisc"", ""show"", ""dev"", device]<tab>try:<tab><tab>output = self.host_exec.run(cmd)<tab><tab># sloppy but good enough for now<tab><tab><IF-STMT><tab><tab><tab>return NetworkState.SLOW<tab><tab>if "" loss "" in output:<tab><tab><tab>return NetworkState.FLAKY<tab><tab>if "" duplicate "" in output:<tab><tab><tab>return NetworkState.DUPLICATE<tab><tab>return NetworkState.NORMAL<tab>except Exception:<tab><tab>return NetworkState.UNKNOWN",0,"if "" delay "" in output :","if ""slow"" in output :",0.344532291,48.89230224,0.371428571
"def _remove(self, item):<tab>""""""Internal removal of an item""""""<tab># Manage siblings when items are deleted<tab>for sibling in self.lines[self.lines.index(item) + 1 :]:<tab><tab><IF-STMT><tab><tab><tab>env = sibling.env<tab><tab><tab>sibling.env = item.env<tab><tab><tab>sibling.env.update(env)<tab><tab><tab>sibling.env.job = sibling<tab><tab><tab>break<tab><tab>elif sibling == """":<tab><tab><tab>self.lines.remove(sibling)<tab><tab>else:<tab><tab><tab>break<tab>self.crons.remove(item)<tab>self.lines.remove(item)<tab>return 1",0,"if isinstance ( sibling , CronItem ) :",if sibling == item :,0.019907918,7.654112967,0.314814815
"def _get_transformations(self, current_text, indices_to_modify):<tab>transformed_texts = []<tab>words = current_text.words<tab>for idx in indices_to_modify:<tab><tab>word = words[idx]<tab><tab>swap_idxs = list(set(range(len(words))) - {idx})<tab><tab><IF-STMT><tab><tab><tab>swap_idx = random.choice(swap_idxs)<tab><tab><tab>swapped_text = current_text.replace_word_at_index(<tab><tab><tab><tab>idx, words[swap_idx]<tab><tab><tab>).replace_word_at_index(swap_idx, word)<tab><tab><tab>transformed_texts.append(swapped_text)<tab>return transformed_texts",1,if swap_idxs :,if swap_idxs :,0.531170663,1.00E-10,1
"def _unlock_restarted_vms(self, pool_name):<tab>result = []<tab>for vm in await self.middleware.call(""vm.query"", [(""autostart"", ""="", True)]):<tab><tab>for device in vm[""devices""]:<tab><tab><tab>if device[""dtype""] not in (""DISK"", ""RAW""):<tab><tab><tab><tab>continue<tab><tab><tab>path = device[""attributes""].get(""path"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if path.startswith(f""/dev/zvol/{pool_name}/"") or path.startswith(<tab><tab><tab><tab>f""/mnt/{pool_name}/""<tab><tab><tab>):<tab><tab><tab><tab>result.append(vm)<tab><tab><tab><tab>break<tab>return result",0,if not path :,if path is None :,0.045150551,14.05853313,0.277777778
"def parse_literal_object(node):<tab>value = 0<tab>unit = get_default_weight_unit()<tab>for field in node.fields:<tab><tab>if field.name.value == ""value"":<tab><tab><tab>try:<tab><tab><tab><tab>value = decimal.Decimal(field.value.value)<tab><tab><tab>except decimal.DecimalException:<tab><tab><tab><tab>raise GraphQLError(f""Unsupported value: {field.value.value}"")<tab><tab><IF-STMT><tab><tab><tab>unit = field.value.value<tab>return Weight(**{unit: value})",0,"if field . name . value == ""unit"" :","elif field . name . value == ""unit"" :",0.412712771,90.36020036,0.666666667
"def _extract_level(self):<tab>""""""Extract level and component if available (lazy).""""""<tab>if self._level is None:<tab><tab>split_tokens = self.split_tokens<tab><tab>if not split_tokens:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False<tab><tab><tab>return<tab><tab>x = (<tab><tab><tab>self.log_levels.index(split_tokens[1])<tab><tab><tab><IF-STMT><tab><tab><tab>else None<tab><tab>)<tab><tab>if x is not None:<tab><tab><tab>self._level = split_tokens[1]<tab><tab><tab>self._component = split_tokens[2]<tab><tab>else:<tab><tab><tab>self._level = False<tab><tab><tab>self._component = False",0,if split_tokens [ 1 ] in self . log_levels,if split_tokens [ 1 ],0.292723821,42.43728457,0.566666667
"def _average_import_time(n: int, module: Text) -> float:<tab>total = 0<tab>for _ in range(n):<tab><tab>lines = subprocess.getoutput(<tab><tab><tab>f'{sys.executable} -X importtime -c ""import {module}""'<tab><tab>).splitlines()<tab><tab>parts = lines[-1].split(""|"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(f""Import time not found for {module}."")<tab><tab>total += int(parts[1].strip()) / 1000000<tab>return total / n",0,if parts [ - 1 ] . strip ( ) != module :,if len ( parts ) < 2 :,0.011849399,3.900760855,0.242647059
"def send_preamble(self):<tab>""""""Transmit version/status/date/server, via self._write()""""""<tab>if self.origin_server:<tab><tab>if self.client_is_modern():<tab><tab><tab>self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status))<tab><tab><tab>if not self.headers.has_key(""Date""):<tab><tab><tab><tab>self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time())))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._write(""Server: %s\r\n"" % self.server_software)<tab>else:<tab><tab>self._write(""Status: %s\r\n"" % self.status)",0,"if self . server_software and not self . headers . has_key ( ""Server"" ) :",if self . server_software :,0.096406986,11.38029545,0.414141414
"def test_source_address(self):<tab>for addr, is_ipv6 in VALID_SOURCE_ADDRESSES:<tab><tab><IF-STMT><tab><tab><tab>warnings.warn(""No IPv6 support: skipping."", NoIPv6Warning)<tab><tab><tab>continue<tab><tab>with HTTPConnectionPool(<tab><tab><tab>self.host, self.port, source_address=addr, retries=False<tab><tab>) as pool:<tab><tab><tab>r = pool.request(""GET"", ""/source_address"")<tab><tab><tab>assert r.data == b(addr[0])",0,if is_ipv6 and not HAS_IPV6_AND_DNS :,if not is_ipv6 :,0.082335674,9.471153563,0.464285714
"def _run_commands(self, tool, commands, dry_run=False):<tab>if dry_run:<tab><tab>self._dry_run_commands(tool, commands)<tab><tab>return<tab>for command in commands:<tab><tab>try:<tab><tab><tab>with original_ld_library_path():<tab><tab><tab><tab>self.subprocess_utils.run(command, capture_output=True, check=True)<tab><tab>except OSError as ex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(self._TOOL_NOT_FOUND_MESSAGE % tool)<tab><tab><tab>raise ex<tab>self._write_success_message(tool)",0,if ex . errno == errno . ENOENT :,if ex . errno != errno . ENOENT :,0.799889319,65.80370065,1
"def test_float_overflow(self):<tab>import sys<tab>big_int = int(sys.float_info.max) * 2<tab>for t in float_types + [c_longdouble]:<tab><tab>self.assertRaises(OverflowError, t, big_int)<tab><tab><IF-STMT><tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_be__, big_int)<tab><tab>if hasattr(t, ""__ctype_le__""):<tab><tab><tab>self.assertRaises(OverflowError, t.__ctype_le__, big_int)",1,"if hasattr ( t , ""__ctype_be__"" ) :","if hasattr ( t , ""__ctype_be__"" ) :",0.75,100,1
"def init_weights(self):<tab>for n, p in self.named_parameters():<tab><tab><IF-STMT><tab><tab><tab>torch.nn.init.zeros_(p)<tab><tab>elif ""fc"" in n:<tab><tab><tab>torch.nn.init.xavier_uniform_(p)",0,"if ""bias"" in n :","if ""zeros"" in n :",0.394778655,48.89230224,1
"def _compute_dependencies(self):<tab>""""""Gather the lists of dependencies and adds to all_parts.""""""<tab>for part in self.all_parts:<tab><tab>dep_names = self.after_requests.get(part.name, [])<tab><tab>for dep_name in dep_names:<tab><tab><tab>dep = self.get_part(dep_name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise errors.SnapcraftAfterPartMissingError(part.name, dep_name)<tab><tab><tab>part.deps.append(dep)",0,if not dep :,if dep is None :,0.045150551,14.05853313,0.277777778
"def _delete_object(step):<tab>try:<tab><tab>api = kubernetes.client.CustomObjectsApi()<tab><tab>api.delete_namespaced_custom_object(<tab><tab><tab>group=""zalando.org"",<tab><tab><tab>version=""v1"",<tab><tab><tab>plural=""kopfexamples"",<tab><tab><tab>namespace=""default"",<tab><tab><tab>name=f""kopf-example-{step}"",<tab><tab><tab>body={},<tab><tab>)<tab>except kubernetes.client.rest.ApiException as e:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",0,if e . status in [ 404 ] :,if e . status == 404 :,0.171066315,33.76459109,0.648148148
"def _lookup(self, key, dicts=None, filters=()):<tab>if dicts is None:<tab><tab>dicts = self.dicts<tab>key_len = len(key)<tab>if key_len > self.longest_key:<tab><tab>return None<tab>for d in dicts:<tab><tab>if not d.enabled:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>value = d.get(key)<tab><tab>if value:<tab><tab><tab>for f in filters:<tab><tab><tab><tab>if f(key, value):<tab><tab><tab><tab><tab>return None<tab><tab><tab>return value",1,if key_len > d . longest_key :,if key_len > d . longest_key :,0.75,100,1
"def fork_with_monitor(receiver: Receiver, func, *args, **kwargs):<tab>current_actor = self()<tab>send(ForkWithMonitor(current_actor, func, args, kwargs), receiver)<tab>while True:<tab><tab>message = recv(current_actor)<tab><tab><IF-STMT><tab><tab><tab>return message.new_actor<tab><tab>else:<tab><tab><tab>send(message, current_actor)<tab>return",0,"if isinstance ( message , ForkResponse ) :","if isinstance ( message , Message ) :",0.549040681,59.46035575,0.733333333
"def read(self, size=-1):<tab>if self._offset or (size > -1):<tab><tab># return empty string to indicate EOF if we are offset past the end of the file<tab><tab># else boto will throw an error at us<tab><tab>if self._offset >= self._key.size:<tab><tab><tab>return """"<tab><tab><IF-STMT><tab><tab><tab>sizeStr = str(self._offset + size - 1)  # range header is inclusive<tab><tab>else:<tab><tab><tab>sizeStr = """"<tab><tab>hdrs = {""Range"": ""bytes=%d-%s"" % (self._offset, sizeStr)}<tab>else:<tab><tab>hdrs = {}<tab>buf = self._key.get_contents_as_string(headers=hdrs)<tab>self._offset += len(buf)<tab>return buf",0,if size > - 1 :,if size > 0 :,0.115297827,34.98330125,0.6
"def operations(self):<tab># Search for operations<tab>registered_operations = {}<tab>for fn in hooks.get_hooks(""register_image_operations""):<tab><tab>registered_operations.update(dict(fn()))<tab># Build list of operation objects<tab>operations = []<tab>for op_spec in self.spec.split(""|""):<tab><tab>op_spec_parts = op_spec.split(""-"")<tab><tab><IF-STMT><tab><tab><tab>raise InvalidFilterSpecError(<tab><tab><tab><tab>""Unrecognised operation: %s"" % op_spec_parts[0]<tab><tab><tab>)<tab><tab>op_class = registered_operations[op_spec_parts[0]]<tab><tab>operations.append(op_class(*op_spec_parts))<tab>return operations",0,if op_spec_parts [ 0 ] not in registered_operations :,if len ( op_spec_parts ) != 1 :,0.016959991,26.97015633,0.272727273
"def find_widget(self, pos):<tab>for widget in self.subwidgets[::-1]:<tab><tab><IF-STMT><tab><tab><tab>r = widget.rect<tab><tab><tab>if r.collidepoint(pos):<tab><tab><tab><tab>return widget.find_widget(subtract(pos, r.topleft))<tab>return self",0,if widget . visible :,"if hasattr ( widget , ""rect"" ) and hasattr ( widget , ""rect"" ) :",0.023211529,2.664321121,0.30952381
"def _get_body(self):<tab>if self._bodytree is None:<tab><tab>bodytxt = self._message.accumulate_body()<tab><tab><IF-STMT><tab><tab><tab>att = settings.get_theming_attribute(""thread"", ""body"")<tab><tab><tab>att_focus = settings.get_theming_attribute(""thread"", ""body_focus"")<tab><tab><tab>self._bodytree = TextlinesList(bodytxt, att, att_focus)<tab>return self._bodytree",0,if bodytxt :,if bodytxt is not None :,0.090364769,1.00E-10,0.4
"def config_mode(self, config_command=""conf t"", pattern=""""):<tab>output = """"<tab><IF-STMT><tab><tab>output = self.send_command_timing(<tab><tab><tab>config_command, strip_command=False, strip_prompt=False<tab><tab>)<tab><tab>if ""to enter configuration mode anyway"" in output:<tab><tab><tab>output += self.send_command_timing(<tab><tab><tab><tab>""YES"", strip_command=False, strip_prompt=False<tab><tab><tab>)<tab><tab>if not self.check_config_mode():<tab><tab><tab>raise ValueError(""Failed to enter configuration mode"")<tab>return output",1,if not self . check_config_mode ( ) :,if not self . check_config_mode ( ) :,0.75,100,1
"def is_enabled(self):<tab>try:<tab><tab>cmd = subprocess.Popen(<tab><tab><tab>""netsh advfirewall show currentprofile"", stdout=subprocess.PIPE<tab><tab>)<tab><tab>out = cmd.stdout.readlines()<tab><tab>for l in out:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state = l.split()[-1].strip()<tab><tab>return state == ""ON""<tab>except:<tab><tab>return None",0,"if l . startswith ( ""State"" ) :","if l . startswith ( ""state"" ) :",0.549040681,65.80370065,1
"def __rpc_devices(self, *args):<tab>data_to_send = {}<tab>for device in self.__connected_devices:<tab><tab><IF-STMT><tab><tab><tab>data_to_send[device] = self.__connected_devices[device][<tab><tab><tab><tab>""connector""<tab><tab><tab>].get_name()<tab>return {""code"": 200, ""resp"": data_to_send}",0,"if self . __connected_devices [ device ] [ ""connector"" ] is not None :",if device in self . __connected_devices :,0.111734625,27.52847588,0.236111111
"def _mock_manager_nfx(self, *args, **kwargs):<tab>if args:<tab><tab><IF-STMT><tab><tab><tab>raise RpcError()<tab><tab>elif args[0].tag == ""get-software-information"" and args[0].find(""./*"") is None:<tab><tab><tab>return True<tab><tab>else:<tab><tab><tab>return self._read_file(""sw_info_nfx_"" + args[0].tag + "".xml"")",1,"if args [ 0 ] . tag == ""command"" :","if args [ 0 ] . tag == ""command"" :",0.75,100,1
"def empty_logs(self, logs=None):<tab>if self.quick_log:<tab><tab>self.quick_log = []<tab>else:<tab><tab>if is_main_thread():<tab><tab><tab>self.logs = []<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.thread_logs[current_thread_id()]",0,if logs and self . thread_logs . get ( current_thread_id ( ) ) :,if current_thread_id ( ) in self . thread_logs :,0.113959621,48.22158906,0.271428571
"def read_cb(dir_path):<tab>df_dict = dict()<tab>for fold in [""train"", ""val"", ""test""]:<tab><tab>columns = [""premise"", ""hypothesis""]<tab><tab><IF-STMT><tab><tab><tab>columns.append(""label"")<tab><tab>jsonl_path = os.path.join(dir_path, ""{}.jsonl"".format(fold))<tab><tab>df = read_jsonl_superglue(jsonl_path)<tab><tab>df = df[columns]<tab><tab>df_dict[fold] = df<tab>return df_dict, None",0,"if fold != ""test"" :","if fold == ""test"" :",0.331415021,59.46035575,1
def _forward_main_responses(self):<tab>while self._should_keep_going():<tab><tab>line = self._proc.stdout.readline()<tab><tab><IF-STMT><tab><tab><tab># In the beginning the backend may echo commands sent to it (perhaps this echo-avoiding trick<tab><tab><tab># takes time). Don't forward those lines.<tab><tab><tab>continue<tab><tab>if not line:<tab><tab><tab>break<tab><tab>with self._response_lock:<tab><tab><tab>sys.stdout.write(line)<tab><tab><tab>sys.stdout.flush()<tab><tab><tab>self._main_backend_is_fresh = False,0,if self . _main_backend_is_fresh and self . _looks_like_echo ( line ) :,if not line :,0.010023275,0.141647887,0.3125
"def _update_server_version(self):<tab>""""""Decode the Transmission version string, if available.""""""<tab>if self.server_version is None:<tab><tab>version_major = 1<tab><tab>version_minor = 30<tab><tab>version_changeset = 0<tab><tab>version_parser = re.compile(""(\d).(\d+) \((\d+)\)"")<tab><tab>if hasattr(self.session, ""version""):<tab><tab><tab>match = version_parser.match(self.session.version)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>version_major = int(match.group(1))<tab><tab><tab><tab>version_minor = int(match.group(2))<tab><tab><tab><tab>version_changeset = match.group(3)<tab><tab>self.server_version = (version_major, version_minor, version_changeset)",1,if match :,if match :,0.531170663,1.00E-10,1
"def _check_type(T, allowed):<tab>if T not in allowed:<tab><tab><IF-STMT><tab><tab><tab>allowed.add(T)<tab><tab>else:<tab><tab><tab>types = "", "".join([t.__name__ for t in allowed] + [T.__name__])<tab><tab><tab>raise TypeError(""unsupported mixed types: %s"" % types)",0,if len ( allowed ) == 1 :,"if isinstance ( T , type ) :",0.020373037,6.892168295,0.25
"def split_named_range(range_string):<tab>""""""Separate a named range into its component parts""""""<tab>for range_string in SPLIT_NAMED_RANGE_RE.split(range_string)[<tab><tab>1::2<tab>]:  # Skip first and from there every second item<tab><tab>match = NAMED_RANGE_RE.match(range_string)<tab><tab><IF-STMT><tab><tab><tab>raise NamedRangeException('Invalid named range string: ""%s""' % range_string)<tab><tab>else:<tab><tab><tab>match = match.groupdict()<tab><tab><tab>sheet_name = match[""quoted""] or match[""notquoted""]<tab><tab><tab>xlrange = match[""range""]<tab><tab><tab>sheet_name = sheet_name.replace(""''"", ""'"")  # Unescape '<tab><tab><tab>yield sheet_name, xlrange",0,if match is None :,if not match :,0.039449619,16.37226967,0.277777778
"def clean(self):<tab>to_del = []<tab>for i, file_ in enumerate(self.files):<tab><tab>try:<tab><tab><tab>os.remove(file_)<tab><tab><tab>to_del.append(i)<tab><tab>except Exception:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_del.append(i)<tab>for i in to_del[::-1]:<tab><tab>del self.files[i]",0,if not os . path . isfile ( file_ ) :,if i not in self . files :,0.014083697,4.736913377,0.190909091
"def lazy_init(self):<tab>f = open(self.filename)<tab>self.base = {}<tab>while 1:<tab><tab>l = f.readline()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>l = l.strip().split("","")<tab><tab>if len(l) != 3:<tab><tab><tab>continue<tab><tab>c, lat, long = l<tab><tab>self.base[c] = (float(long), float(lat))<tab>f.close()",1,if not l :,if not l :,0.75,100,1
"def onto_evo_target(self):<tab>if self._onto_evo_target is None:<tab><tab>self._get_onto_evo_target()<tab>if self._onto_evo_target_qobj is None:<tab><tab><IF-STMT><tab><tab><tab>self._onto_evo_target_qobj = self._onto_evo_target<tab><tab>else:<tab><tab><tab>rev_dims = [self.sys_dims[1], self.sys_dims[0]]<tab><tab><tab>self._onto_evo_target_qobj = Qobj(self._onto_evo_target, dims=rev_dims)<tab>return self._onto_evo_target_qobj",0,"if isinstance ( self . _onto_evo_target , Qobj ) :",if self . sys_dims is None :,0.028035632,6.155947439,0.285714286
"def _dnsname_to_pat(dn):<tab>pats = []<tab>for frag in dn.split(r"".""):<tab><tab><IF-STMT><tab><tab><tab># When '*' is a fragment by itself, it matches a non-empty dotless<tab><tab><tab># fragment.<tab><tab><tab>pats.append(""[^.]+"")<tab><tab>else:<tab><tab><tab># Otherwise, '*' matches any dotless fragment.<tab><tab><tab>frag = re.escape(frag)<tab><tab><tab>pats.append(frag.replace(r""\*"", ""[^.]*""))<tab>return re.compile(r""\A"" + r""\."".join(pats) + r""\Z"", re.IGNORECASE)",1,"if frag == ""*"" :","if frag == ""*"" :",0.75,100,1
"def update(id):<tab>""""""Update a post if the current user is the author.""""""<tab>post = get_post(id)<tab>if request.method == ""POST"":<tab><tab>title = request.form[""title""]<tab><tab>body = request.form[""body""]<tab><tab>error = None<tab><tab><IF-STMT><tab><tab><tab>error = ""Title is required.""<tab><tab>if error is not None:<tab><tab><tab>flash(error)<tab><tab>else:<tab><tab><tab>post.title = title<tab><tab><tab>post.body = body<tab><tab><tab>db.session.commit()<tab><tab><tab>return redirect(url_for(""blog.index""))<tab>return render_template(""blog/update.html"", post=post)",1,if not title :,if not title :,0.75,100,1
"def __iter__(self):<tab>for token in base.Filter.__iter__(self):<tab><tab><IF-STMT><tab><tab><tab>attrs = OrderedDict()<tab><tab><tab>for name, value in sorted(token[""data""].items(), key=_attr_key):<tab><tab><tab><tab>attrs[name] = value<tab><tab><tab>token[""data""] = attrs<tab><tab>yield token",0,"if token [ ""type"" ] in ( ""StartTag"" , ""EmptyTag"" ) :","if token [ ""type"" ] == ""attr"" :",0.219756739,35.0049653,0.736842105
"def get_polymorphic_model(data):<tab>for model in itervalues(models):<tab><tab>polymorphic = model.opts.polymorphic<tab><tab>if polymorphic:<tab><tab><tab>polymorphic_key = polymorphic<tab><tab><tab>if isinstance(polymorphic_key, bool):<tab><tab><tab><tab>polymorphic_key = ""type""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return model<tab>raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",0,if data . get ( polymorphic_key ) == model . __name__ :,if polymorphic_key == data :,0.011816831,7.350435626,0.577777778
"def _setup_tag(self, tag):<tab># keeping mutual refs<tab>tag.py_obj = self<tab>self.riot_tag = tag<tab># making the event system call self's methods:<tab>handlers = {}<tab>for ev in lifecycle_ev:<tab><tab>f = getattr(self, ev.replace(""-"", ""_""))<tab><tab><IF-STMT><tab><tab><tab># this.on('mount', function() {...}):<tab><tab><tab># whats nicer?<tab><tab><tab>tag.on(ev, f)",0,if f :,if f is not None :,0.090364769,1.00E-10,0.4
"def selection_only(self):<tab>selection_only = False<tab>sel = self.sel()<tab>if (self.context == ""selection"" or self.context == ""both"") and len(sel):<tab><tab># if multiple lines, always true<tab><tab><IF-STMT><tab><tab><tab>selection_only = True<tab><tab># check threshold<tab><tab>elif self.threshold and not sel[0].empty():<tab><tab><tab>text = self.view.substr(sel[0])<tab><tab><tab>match = re.search(self.threshold, text)<tab><tab><tab>if match:<tab><tab><tab><tab>selection_only = True<tab><tab># no valid selection<tab><tab>else:<tab><tab><tab>selection_only = False<tab>return selection_only",0,if len ( sel ) > 1 :,if sel [ 0 ] . empty ( ) :,0.018757983,6.274655311,0.285714286
"def find_torrents_to_fetch(torrent_ids):<tab>to_fetch = []<tab>t = time()<tab>for torrent_id in torrent_ids:<tab><tab>torrent = self.torrents[torrent_id]<tab><tab><IF-STMT><tab><tab><tab>to_fetch.append(torrent_id)<tab><tab>else:<tab><tab><tab># We need to check if a key is expired<tab><tab><tab>for key in keys:<tab><tab><tab><tab>if t - self.cache_times[torrent_id].get(key, 0.0) > self.cache_time:<tab><tab><tab><tab><tab>to_fetch.append(torrent_id)<tab><tab><tab><tab><tab>break<tab>return to_fetch",0,if t - torrent [ 0 ] > self . cache_time :,if torrent . is_expired ( ) :,0.012381682,4.090508964,0.303921569
"def filter(callbackfn):<tab>array = this.to_object()<tab>arr_len = array.get(""length"").to_uint32()<tab>if not callbackfn.is_callable():<tab><tab>raise this.MakeError(""TypeError"", ""callbackfn must be a function"")<tab>T = arguments[1]<tab>res = []<tab>k = 0<tab>while k < arr_len:<tab><tab>if array.has_property(str(k)):<tab><tab><tab>kValue = array.get(str(k))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>res.append(kValue)<tab><tab>k += 1<tab>return res  # converted to js array automatically",0,"if callbackfn . call ( T , ( kValue , this . Js ( k ) , array ) ) . to_boolean ( ) . value :","if callbackfn . call ( T , ( kValue , array ) ) ) :",0.198346267,32.01939585,0.535885167
"def generate_py_upgrades(data):<tab>""""""Generate the list of upgrades in upgrades.py.""""""<tab>print("" upgrades.py "".center(60, ""-""))<tab>print(""class Upgrades(enum.IntEnum):"")<tab>print('  """"""The list of upgrades, as returned from RequestData.""""""')<tab>for upgrade in sorted(data.upgrades, key=lambda a: a.name):<tab><tab><IF-STMT><tab><tab><tab>print(""  %s = %s"" % (upgrade.name, upgrade.upgrade_id))<tab>print(""\n"")",0,if upgrade . name and upgrade . upgrade_id in static_data . UPGRADES :,if upgrade . upgrade_id :,0.151207727,18.20954096,0.338935574
"def get_first_n(l, n, reverse=False):<tab>cur_n = 0<tab>res = []<tab>for si in reversed(l) if reverse else l:<tab><tab>if trade_exchange.is_stock_tradable(stock_id=si, trade_date=trade_date):<tab><tab><tab>res.append(si)<tab><tab><tab>cur_n += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return res[::-1] if reverse else res",1,if cur_n >= n :,if cur_n >= n :,0.75,100,1
"def _fill_cache(self):<tab>for task in linux_pslist.linux_pslist(self._config).calculate():<tab><tab>for filp, fd in task.lsof():<tab><tab><tab>filepath = linux_common.get_path(task, filp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>to_add = filp.dentry.d_inode.i_ino.v()<tab><tab><tab><tab>self.fd_cache[to_add] = [task, filp, fd, filepath]",0,"if type ( filepath ) == str and filepath . find ( ""socket:["" ) != - 1 :",if filp . dentry :,0.005490747,0.314500237,0.18
"def is_ArAX_implicit(ii):  # allows one implicit fixed reg<tab>a, implicit_fixed = 0, 0<tab>for op in _gen_opnds(ii):<tab><tab>if op_luf_start(op, ""ArAX""):<tab><tab><tab>a += 1<tab><tab><IF-STMT><tab><tab><tab>implicit_fixed += 1<tab><tab>else:<tab><tab><tab>return False<tab>return a == 1 and implicit_fixed <= 1",0,elif op_reg ( op ) and op_implicit_specific_reg ( op ) :,"elif op_reg ( op , ""implicit"" ) :",0.202895917,26.96815239,0.635416667
"def auto_resize(self, name: str) -> None:<tab>""""""recompute widget width based on max length of all of the values""""""<tab>widget = self.find_widget(name)<tab>for column in range(len(widget._columns) - 1):<tab><tab>sizes = [len(x[0][column]) + 1 for x in widget.options]<tab><tab><IF-STMT><tab><tab><tab>sizes.append(len(widget._titles[column]) + 1)<tab><tab>widget._columns[column] = max(sizes)",0,if widget . _titles :,if len ( widget . _titles [ column ] ) > 0 :,0.097377305,19.67497981,0.307017544
"def dns_set_secondary_nameserver():<tab>from dns_update import set_secondary_dns<tab>try:<tab><tab>return set_secondary_dns(<tab><tab><tab>[<tab><tab><tab><tab>ns.strip()<tab><tab><tab><tab>for ns in re.split(r""[, ]+"", request.form.get(""hostnames"") or """")<tab><tab><tab><tab><IF-STMT><tab><tab><tab>],<tab><tab><tab>env,<tab><tab>)<tab>except ValueError as e:<tab><tab>return (str(e), 400)",0,"if ns . strip ( ) != """"",if ns . strip ( ),0.453766379,51.3417119,1
"def assert_inputs(inputs, can_be_used=True):<tab># Until we make the dataset private, _different_user() can use it:<tab>with self._different_user_and_history() as other_history_id:<tab><tab>response = self._run(""cat1"", other_history_id, inputs)<tab><tab><IF-STMT><tab><tab><tab>assert response.status_code == 200<tab><tab>else:<tab><tab><tab>self._assert_dataset_permission_denied_response(response)",1,if can_be_used :,if can_be_used :,0.531170663,1.00E-10,1
"def _handle_start(self, tag, attrib):<tab>if ""translatable"" in attrib:<tab><tab><IF-STMT><tab><tab><tab>self._translate = True<tab><tab><tab>if ""comments"" in attrib:<tab><tab><tab><tab>self._comments.append(attrib[attrib.index(""comments"") + 1])",0,"if attrib [ attrib . index ( ""translatable"" ) + 1 ] == ""yes"" :","if attrib . index ( ""translatable"" ) == 1 :",0.299061739,39.25062562,0.523809524
"def get_command(cls):<tab>ifconfig_cmd = ""ip""<tab>for path in [""/sbin"", ""/usr/sbin"", ""/bin"", ""/usr/bin""]:<tab><tab>if os.path.exists(os.path.join(path, ifconfig_cmd)):<tab><tab><tab><IF-STMT><tab><tab><tab>break<tab>ifconfig_cmd = ifconfig_cmd + "" address show""<tab>return ifconfig_cmd",0,"ifconfig_cmd = os . path . join ( path , ifconfig_cmd )","if os . path . isfile ( os . path . join ( path , ifconfig_cmd ) ) :",0.53071159,53.62721717,0.141025641
"def render(self):<tab>""""""What to show when printed.""""""<tab>viz = """"<tab>for y in range(self.grid.height):<tab><tab>for x in range(self.grid.width):<tab><tab><tab>c = self.grid[y][x]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>viz += "" ""<tab><tab><tab>else:<tab><tab><tab><tab>viz += self.converter(c)<tab><tab>viz += ""\n""<tab>return viz",0,if c is None :,"if c == ""\n"" :",0.064978772,10.55267032,0.5
"def _sorted_layers(self, structure, top_layer_id):<tab>""""""Return the image layers sorted""""""<tab>sorted_layers = []<tab>next_layer = top_layer_id<tab>while next_layer:<tab><tab>sorted_layers.append(next_layer)<tab><tab><IF-STMT>  # v2<tab><tab><tab>break<tab><tab>if ""parent"" not in structure[""repolayers""][next_layer][""json""]:<tab><tab><tab>break<tab><tab>next_layer = structure[""repolayers""][next_layer][""json""][""parent""]<tab><tab>if not next_layer:<tab><tab><tab>break<tab>return sorted_layers",0,"if ""json"" not in structure [ ""repolayers"" ] [ next_layer ] :","if structure [ ""repolayers"" ] [ next_layer ] [ ""type"" ] == ""image"" :",0.326594045,47.47948363,0.381818182
"def check_sync(self):<tab>login_failures = get_login_failures(datetime.now(), catmsgs())<tab>if login_failures:<tab><tab>return Alert(<tab><tab><tab>SSHLoginFailuresAlertClass,<tab><tab><tab>{<tab><tab><tab><tab>""count"": len(login_failures),<tab><tab><tab><tab>""failures"": """".join(<tab><tab><tab><tab><tab>login_failures<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>else login_failures[:2]<tab><tab><tab><tab><tab>+ [f""... {len(login_failures) - 4} more ...\n""]<tab><tab><tab><tab><tab>+ login_failures[-2:]<tab><tab><tab><tab>),<tab><tab><tab>},<tab><tab>)",0,if len ( login_failures ) <= 5,if len ( login_failures ) > 4,0.562701739,64.96350259,0.6
"def on_user_auth_login_success(sender, user, request, **kwargs):<tab>if settings.USER_LOGIN_SINGLE_MACHINE_ENABLED:<tab><tab>user_id = ""single_machine_login_"" + str(user.id)<tab><tab>session_key = cache.get(user_id)<tab><tab><IF-STMT><tab><tab><tab>session = import_module(settings.SESSION_ENGINE).SessionStore(session_key)<tab><tab><tab>session.delete()<tab><tab>cache.set(user_id, request.session.session_key, None)",0,if session_key and session_key != request . session . session_key :,if session_key :,0.020494006,1.00E-10,0.364705882
"def slots_for_entities(self, entities):<tab>if self.store_entities_as_slots:<tab><tab>slot_events = []<tab><tab>for s in self.slots:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>matching_entities = [<tab><tab><tab><tab><tab>e[""value""] for e in entities if e[""entity""] == s.name<tab><tab><tab><tab>]<tab><tab><tab><tab>if matching_entities:<tab><tab><tab><tab><tab>if s.type_name == ""list"":<tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities))<tab><tab><tab><tab><tab>else:<tab><tab><tab><tab><tab><tab>slot_events.append(SlotSet(s.name, matching_entities[-1]))<tab><tab>return slot_events<tab>else:<tab><tab>return []",0,if s . auto_fill :,if s . type_name in entities :,0.200593991,20.16494558,0.55
"def get(self, id):<tab>obj = self.klass.objects.get(id=id)<tab>if hasattr(obj, ""sharing""):<tab><tab><IF-STMT><tab><tab><tab>return render_template(<tab><tab><tab><tab>""{}/single.html"".format(self.klass.__name__.lower()), obj=obj<tab><tab><tab>)<tab><tab>abort(403)<tab>else:<tab><tab>return render_template(<tab><tab><tab>""{}/single.html"".format(self.klass.__name__.lower()), obj=obj<tab><tab>)<tab>return request.referrer",0,if group_user_permission ( obj ) :,"if obj .sharing . get ( ""id"" ) == id :",0.022605275,3.929719341,0.575
"def __call__(self, module, *x):<tab>""""""Grab the instantiated layer and evaluate it.""""""<tab>operation = getattr(module, self.name)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return self.func(operation, *x)<tab><tab>return operation(*x)<tab>except:<tab><tab>logger.error(""Failed to apply layer: %s"", self.name)<tab><tab>for i, X in enumerate(x):<tab><tab><tab>logger.error(""  Input shape #%d: %s"", i + 1, list(X.size()))<tab><tab>raise",1,if self . func :,if self . func :,0.75,100,1
"def req(s, poll, msg, expect):<tab>do_req = True<tab>xid = None<tab>while True:<tab><tab># get transaction id<tab><tab><IF-STMT><tab><tab><tab>xid = s.put(msg)[""xid""]<tab><tab># wait for response<tab><tab>events = poll.poll(2)<tab><tab>for (fd, event) in events:<tab><tab><tab>response = s.get()<tab><tab><tab>if response[""xid""] != xid:<tab><tab><tab><tab>do_req = False<tab><tab><tab><tab>continue<tab><tab><tab>if response[""options""][""message_type""] != expect:<tab><tab><tab><tab>raise Exception(""DHCP protocol error"")<tab><tab><tab>return response<tab><tab>do_req = True",0,if do_req :,if xid is None :,0.051944023,1.00E-10,0.28
"def _state_old_c_params(self, token):<tab>self._saved_tokens.append(token)<tab>if token == "";"":<tab><tab>self._saved_tokens = []<tab><tab>self._state = self._state_dec_to_imp<tab>elif token == ""{"":<tab><tab><IF-STMT><tab><tab><tab>self._saved_tokens = []<tab><tab><tab>self._state_dec_to_imp(token)<tab><tab><tab>return<tab><tab>self._state = self._state_global<tab><tab>for tkn in self._saved_tokens:<tab><tab><tab>self._state(tkn)<tab>elif token == ""("":<tab><tab>self._state = self._state_global<tab><tab>for tkn in self._saved_tokens:<tab><tab><tab>self._state(tkn)",0,if len ( self . _saved_tokens ) == 2 :,"if self . _saved_tokens [ - 1 ] == ""}"" :",0.101841601,33.5070408,0.322222222
"def assert_tensors_equal(sess, t1, t2, n):<tab>""""""Compute tensors `n` times and ensure that they are equal.""""""<tab>for _ in range(n):<tab><tab>v1, v2 = sess.run([t1, t2])<tab><tab>if v1.shape != v2.shape:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,if not np . all ( v1 == v2 ) :,if v1 . shape != v2 . shape :,0.014731831,9.042713792,0.238636364
"def http_error_302(self, url, fp, errcode, errmsg, headers, data=None):<tab>""""""Error 302 -- relocated (temporarily).""""""<tab>self.tries += 1<tab>if self.maxtries and self.tries >= self.maxtries:<tab><tab><IF-STMT><tab><tab><tab>meth = self.http_error_500<tab><tab>else:<tab><tab><tab>meth = self.http_error_default<tab><tab>self.tries = 0<tab><tab>return meth(url, fp, 500, ""Internal Server Error: Redirect Recursion"", headers)<tab>result = self.redirect_internal(url, fp, errcode, errmsg, headers, data)<tab>self.tries = 0<tab>return result",0,"if hasattr ( self , ""http_error_500"" ) :",if self . maxtries > 0 :,0.019627455,3.179589226,0.314814815
"def get_satellite_list(self, daemon_type=""""):<tab>res = {}<tab>for t in [""arbiter"", ""scheduler"", ""poller"", ""reactionner"", ""receiver"", ""broker""]:<tab><tab>if daemon_type and daemon_type != t:<tab><tab><tab>continue<tab><tab>satellite_list = []<tab><tab>res[t] = satellite_list<tab><tab>daemon_name_attr = t + ""_name""<tab><tab>daemons = self.app.get_daemons(t)<tab><tab>for dae in daemons:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>satellite_list.append(getattr(dae, daemon_name_attr))<tab>return res",1,"if hasattr ( dae , daemon_name_attr ) :","if hasattr ( dae , daemon_name_attr ) :",0.75,100,1
"def check(data_dir, decrypter, read_only=False):<tab>fname = os.path.join(data_dir, DIGEST_NAME)<tab>if os.path.exists(fname):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>f = open(fname, ""rb"")<tab><tab>s = f.read()<tab><tab>f.close()<tab><tab>return decrypter.decrypt(s) == MAGIC_STRING<tab>else:<tab><tab>if decrypter is not None:<tab><tab><tab>if read_only:<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>s = decrypter.encrypt(MAGIC_STRING)<tab><tab><tab><tab>f = open(fname, ""wb"")<tab><tab><tab><tab>f.write(s)<tab><tab><tab><tab>f.close()<tab><tab>return True",0,if decrypter is None :,if decrypter is not None :,0.272109132,37.99178428,0.611111111
"def logic():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>count.next = f1(n)",1,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,100,1
"def get_project_translation(request, project=None, component=None, lang=None):<tab>""""""Return project, component, translation tuple for given parameters.""""""<tab>if lang and component:<tab><tab># Language defined? We can get all<tab><tab>translation = get_translation(request, project, component, lang)<tab><tab>component = translation.component<tab><tab>project = component.project<tab>else:<tab><tab>translation = None<tab><tab>if component:<tab><tab><tab># Component defined?<tab><tab><tab>component = get_component(request, project, component)<tab><tab><tab>project = component.project<tab><tab><IF-STMT><tab><tab><tab># Only project defined?<tab><tab><tab>project = get_project(request, project)<tab># Return tuple<tab>return project or None, component or None, translation or None",0,elif project :,if project :,0.112938849,1.00E-10,0.5
"def run(self, sql, encoding=None):<tab>stream = lexer.tokenize(sql, encoding)<tab># Process token stream<tab>for filter_ in self.preprocess:<tab><tab>stream = filter_.process(stream)<tab>stream = StatementSplitter().process(stream)<tab># Output: Stream processed Statements<tab>for stmt in stream:<tab><tab><IF-STMT><tab><tab><tab>stmt = grouping.group(stmt)<tab><tab>for filter_ in self.stmtprocess:<tab><tab><tab>filter_.process(stmt)<tab><tab>for filter_ in self.postprocess:<tab><tab><tab>stmt = filter_.process(stmt)<tab><tab>yield stmt",0,if self . _grouping :,if grouping :,0.03549272,1.00E-10,0.5
"def get_word_parens_range(self, offset, opening=""("", closing="")""):<tab>end = self._find_word_end(offset)<tab>start_parens = self.code.index(opening, end)<tab>index = start_parens<tab>open_count = 0<tab>while index < len(self.code):<tab><tab>if self.code[index] == opening:<tab><tab><tab>open_count += 1<tab><tab><IF-STMT><tab><tab><tab>open_count -= 1<tab><tab>if open_count == 0:<tab><tab><tab>return (start_parens, index + 1)<tab><tab>index += 1<tab>return (start_parens, index)",0,if self . code [ index ] == closing :,elif self . code [ index ] == closing :,0.422304612,89.31539818,0.714285714
def _get_inherited_env_vars(self):<tab>env_vars = os.environ.copy()<tab>for var_name in ENV_VARS_BLACKLIST:<tab><tab>if var_name.lower() in env_vars:<tab><tab><tab>del env_vars[var_name.lower()]<tab><tab><IF-STMT><tab><tab><tab>del env_vars[var_name.upper()]<tab>return env_vars,0,if var_name . upper ( ) in env_vars :,elif var_name . upper ( ) in env_vars :,0.412712771,91.21679091,0.6
"def adapt_datetimefield_value(self, value):<tab>if value is None:<tab><tab>return None<tab># Expression values are adapted by the database.<tab>if hasattr(value, ""resolve_expression""):<tab><tab>return value<tab># SQLite doesn't support tz-aware datetimes<tab>if timezone.is_aware(value):<tab><tab><IF-STMT><tab><tab><tab>value = timezone.make_naive(value, self.connection.timezone)<tab><tab>else:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""SQLite backend does not support timezone-aware datetimes when USE_TZ is False.""<tab><tab><tab>)<tab>return six.text_type(value)",0,if settings . USE_TZ :,if self . connection . use_tz :,0.113063935,6.74255593,0.377777778
"def dragMoveEvent(self, event):<tab>data = event.mimeData()<tab>urls = data.urls()<tab>if urls and urls[0].scheme() == ""file"":<tab><tab>event.acceptProposedAction()<tab><tab>indexRow = self.indexAt(event.pos()).row()<tab><tab>window = self.parent().parent().parent().parent().parent().parent()<tab><tab><IF-STMT><tab><tab><tab>indexRow = window.playlist.count()<tab><tab>window.setPlaylistInsertPosition(indexRow)<tab>else:<tab><tab>super(MainWindow.PlaylistWidget, self).dragMoveEvent(event)",0,if indexRow == - 1 or not window . clearedPlaylistNote :,if window . playlist :,0.078772269,6.265199649,0.185185185
"def explode(self, obj):<tab>""""""Determine if the object should be exploded.""""""<tab>if obj in self._done:<tab><tab>return False<tab>result = False<tab>for item in self._explode:<tab><tab>if hasattr(item, ""_moId""):<tab><tab><tab># If it has a _moId it is an instance<tab><tab><tab>if obj._moId == item._moId:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab># If it does not have a _moId it is a template<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab>if result:<tab><tab>self._done.add(obj)<tab>return result",0,if obj . __class__ . __name__ == item . __name__ :,if obj . _moId == item . _moId :,0.433765243,20.05851293,1
"def _maybe_clean(self):<tab>""""""Clean the cache if it's time to do so.""""""<tab>now = time.time()<tab>if self.next_cleaning <= now:<tab><tab>keys_to_delete = []<tab><tab>for (k, v) in self.data.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>keys_to_delete.append(k)<tab><tab>for k in keys_to_delete:<tab><tab><tab>del self.data[k]<tab><tab>now = time.time()<tab><tab>self.next_cleaning = now + self.cleaning_interval",0,if v . expiration <= now :,if v is not None :,0.04155306,12.87263231,0.35
"def test_doc_attributes(self):<tab>print_test_name(""TEST DOC ATTRIBUTES"")<tab>correct = 0<tab>for example in DOC_EXAMPLES:<tab><tab>original_schema = schema.parse(example.schema_string)<tab><tab>if original_schema.doc is not None:<tab><tab><tab>correct += 1<tab><tab><IF-STMT><tab><tab><tab>for f in original_schema.fields:<tab><tab><tab><tab>if f.doc is None:<tab><tab><tab><tab><tab>self.fail(<tab><tab><tab><tab><tab><tab>""Failed to preserve 'doc' in fields: "" + example.schema_string<tab><tab><tab><tab><tab>)<tab>self.assertEqual(correct, len(DOC_EXAMPLES))",0,"if original_schema . type == ""record"" :",if len ( original_schema . fields ) > 0 :,0.097827427,23.46235032,0.30952381
"def save_as(self):<tab>""""""Save *as* the currently edited file""""""<tab>editorstack = self.get_current_editorstack()<tab>if editorstack.save_as():<tab><tab>fname = editorstack.get_current_filename()<tab><tab><IF-STMT><tab><tab><tab>self.emit(SIGNAL(""open_dir(QString)""), osp.dirname(fname))<tab><tab>self.__add_recent_file(fname)",0,"if CONF . get ( ""workingdir"" , ""editor/save/auto_set_to_basedir"" ) :",if os . path . exists ( fname ) :,0.028970913,2.602256461,0.229166667
"def verify_settings(rst_path: Path) -> Iterator[Error]:<tab>for setting_name, default in find_settings_in_rst(rst_path):<tab><tab>actual = getattr(app.conf, setting_name)<tab><tab>if isinstance(default, timedelta):<tab><tab><tab>default = default.total_seconds()<tab><tab>if isinstance(actual, Enum):<tab><tab><tab>actual = actual.value<tab><tab><IF-STMT><tab><tab><tab>yield Error(<tab><tab><tab><tab>reason=""mismatch"",<tab><tab><tab><tab>setting=setting_name,<tab><tab><tab><tab>default=default,<tab><tab><tab><tab>actual=actual,<tab><tab><tab>)",1,if actual != default :,if actual != default :,0.75,100,1
"def JobWait(self, waiter):<tab># type: (Waiter) -> wait_status_t<tab># wait builtin can be interrupted<tab>while True:<tab><tab># Don't retry<tab><tab>result = waiter.WaitForOne(False)<tab><tab>if result > 0:  # signal<tab><tab><tab>return wait_status.Cancelled(result)<tab><tab>if result == -1:  # nothing to wait for<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab>return wait_status.Proc(self.status)",0,if self . state != job_state_e . Running :,if self . status is None :,0.130089311,9.66386144,0.361111111
"def object_hook(obj):<tab>obj_len = len(obj)<tab>if obj_len == 1:<tab><tab>if ""$date"" in obj:<tab><tab><tab>return datetime.fromtimestamp(<tab><tab><tab><tab>obj[""$date""] / 1000, tz=timezone.utc<tab><tab><tab>) + timedelta(milliseconds=obj[""$date""] % 1000)<tab><tab><IF-STMT><tab><tab><tab>return time(*[int(i) for i in obj[""$time""].split("":"")])<tab>if obj_len == 2 and ""$type"" in obj and ""$value"" in obj:<tab><tab>if obj[""$type""] == ""date"":<tab><tab><tab>return date(*[int(i) for i in obj[""$value""].split(""-"")])<tab>return obj",1,"if ""$time"" in obj :","if ""$time"" in obj :",0.75,100,1
"def before_FunctionDef(self, node):<tab>s = self.format(node, print_body=False)<tab>if self.test_kind is ""test"":<tab><tab>print(s)<tab>self.indent += 1<tab>self.context_stack.append(node)<tab>if self.pass_n == 1:<tab><tab>self.stats.defs += 1<tab><tab><IF-STMT><tab><tab><tab>if self.class_name in self.classes:<tab><tab><tab><tab>the_class = self.classes.get(self.class_name)<tab><tab><tab><tab>methods = the_class.get(""methods"")<tab><tab><tab><tab># tag:setter function-name=stringized-args<tab><tab><tab><tab>methods[node.name] = self.format(node.args)",0,if self . class_name not in self . special_class_names :,"if self . test_kind is ""test"" :",0.095002429,10.06131215,0.416666667
"def setAttributeNS(self, namespaceURI, qualifiedName, value):<tab>prefix, localname = _nssplit(qualifiedName)<tab>attr = self.getAttributeNodeNS(namespaceURI, localname)<tab>if attr is None:<tab><tab>attr = Attr(qualifiedName, namespaceURI, localname, prefix)<tab><tab>attr.value = value<tab><tab>attr.ownerDocument = self.ownerDocument<tab><tab>self.setAttributeNode(attr)<tab>else:<tab><tab>if value != attr.value:<tab><tab><tab>attr.value = value<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_clear_id_cache(self)<tab><tab>if attr.prefix != prefix:<tab><tab><tab>attr.prefix = prefix<tab><tab><tab>attr.nodeName = qualifiedName",1,if attr . isId :,if attr . isId :,0.75,100,1
"def main():<tab>try:<tab><tab>from wsgiref.simple_server import make_server<tab><tab>from wsgiref.validate import validator<tab><tab><IF-STMT><tab><tab><tab>port[0] = get_open_port()<tab><tab>wsgi_application = WsgiApplication(msgpackrpc_application)<tab><tab>server = make_server(host, port[0], validator(wsgi_application))<tab><tab>logger.info(""Starting interop server at %s:%s."" % (host, port[0]))<tab><tab>logger.info(""WSDL is at: /?wsdl"")<tab><tab>server.serve_forever()<tab>except ImportError:<tab><tab>print(""Error: example server code requires Python >= 2.5"")",0,if port [ 0 ] == 0 :,if not port :,0.019930836,6.023021416,0.377777778
"def yield_modules(path):<tab>""""""Yield all Python modules underneath *path*""""""<tab>for (dpath, dnames, fnames) in os.walk(path):<tab><tab>module = tuple(dpath.split(""/"")[1:])<tab><tab>for fname in fnames:<tab><tab><tab>if not fname.endswith("".py""):<tab><tab><tab><tab>continue<tab><tab><tab>fpath = os.path.join(dpath, fname)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield (fpath, module)<tab><tab><tab>else:<tab><tab><tab><tab>yield (fpath, module + (fname[:-3],))<tab><tab>dnames[:] = [<tab><tab><tab>x for x in dnames if os.path.exists(os.path.join(dpath, x, ""__init__.py""))<tab><tab>]",0,"if fname == ""__init__.py"" :","if fname . endswith ( "".py"" ) :",0.04979442,14.52687099,0.727272727
"def dump_section(name, section):<tab>lines.append(""[%s]\n"" % name)<tab>for key, value in section.all_items():<tab><tab>if not key.startswith(""_""):<tab><tab><tab>try:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>lines.append(<tab><tab><tab><tab><tab><tab>""%s=%s\n"" % (key, section.definitions[key].tostring(value))<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>lines.append(""%s=%s\n"" % (key, value))<tab><tab><tab>except:<tab><tab><tab><tab>logger.exception('Error serializing ""%s"" in section ""[%s]""', key, name)<tab>lines.append(""\n"")",1,if key in section . definitions :,if key in section . definitions :,0.75,100,1
"def testCreateTimeout(self):<tab>cluster = None<tab>try:<tab><tab>env_path = ""conda://"" + os.environ[""CONDA_PREFIX""]<tab><tab>log_config_file = os.path.join(<tab><tab><tab>os.path.dirname(os.path.abspath(__file__)), ""yarn-logging.conf""<tab><tab>)<tab><tab>with self.assertRaises(TimeoutError):<tab><tab><tab>cluster = new_cluster(<tab><tab><tab><tab>env_path,<tab><tab><tab><tab>log_config=log_config_file,<tab><tab><tab><tab>worker_cache_mem=""64m"",<tab><tab><tab><tab>log_when_fail=True,<tab><tab><tab><tab>timeout=1,<tab><tab><tab>)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>cluster.stop()",0,if cluster is not None :,if cluster :,0.050438393,1.00E-10,0.4
"def read_phrases(data_dir, movies=None):<tab>res = {}<tab>for parts in iterate_entries(data_dir, ""movie_lines.txt""):<tab><tab>l_id, m_id, l_str = parts[0], parts[2], parts[4]<tab><tab>if movies and m_id not in movies:<tab><tab><tab>continue<tab><tab>tokens = utils.tokenize(l_str)<tab><tab><IF-STMT><tab><tab><tab>res[l_id] = tokens<tab>return res",1,if tokens :,if tokens :,0.531170663,1.00E-10,1
"def get_Subclass_of(rt):<tab>for y in [getattr(Ast, x) for x in dir(Ast)]:<tab><tab>yt = clr.GetClrType(y)<tab><tab>if rt == yt:<tab><tab><tab>continue<tab><tab>if yt.IsAbstract:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield yt.Name",0,if yt . IsSubclassOf ( rt ) :,if yt . IsSubclass :,0.078889319,23.45000811,0.481481481
"def retrieve(self, aclass):<tab>""""""Look for a specifc class/name in the packet""""""<tab>resu = []<tab>for x in self.payload:<tab><tab>try:<tab><tab><tab>if isinstance(aclass, str):<tab><tab><tab><tab>if x.name == aclass:<tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>else:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>resu += x.retrieve(aclass)<tab><tab>except:<tab><tab><tab>pass<tab>return resu",0,"if isinstance ( x , aclass ) :",if x . name == aclass :,0.02067646,7.809849842,0.5
"def _max_physical(self):<tab>""How big is the physical screen?""<tab># On OS X newwin does not correctly get the size of the screen.<tab># let's see how big we could be: create a temp screen<tab># and see the size curses makes it.  No good to keep, though<tab>try:<tab><tab>mxy, mxx = struct.unpack(<tab><tab><tab>""hh"", fcntl.ioctl(sys.stderr.fileno(), termios.TIOCGWINSZ, ""xxxx"")<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError<tab>except (ValueError, NameError):<tab><tab>mxy, mxx = curses.newwin(0, 0).getmaxyx()<tab># return safe values, i.e. slightly smaller.<tab>return (mxy - 1, mxx - 1)",0,"if ( mxy , mxx ) == ( 0 , 0 ) :",if mxy < 0 or mxx < 0 :,0.048189635,4.28127042,0.488888889
"def deserialize(self, cassette_string):<tab>cassette_dict = self.base_serializer.deserialize(cassette_string)<tab>for interaction in cassette_dict[""interactions""]:<tab><tab>response = interaction[""response""]<tab><tab>headers = response[""headers""]<tab><tab><IF-STMT><tab><tab><tab>rg, size, filename = self._parse_headers(headers)<tab><tab><tab>with open(join(self.directory, filename), ""rb"") as f:<tab><tab><tab><tab>f.seek(rg[0])<tab><tab><tab><tab>content = f.read(rg[1] - rg[0] + 1)<tab><tab><tab>response[""body""][""string""] = content<tab>return cassette_dict",0,"if ""Content-Range"" in headers and ""Content-Disposition"" in headers :",if headers :,0.024814633,1.00E-10,0.32
"def parse_head(fileobj, parser):<tab>""""""Return a list of key, value pairs.""""""<tab>while 1:<tab><tab>data = fileobj.read(CHUNK)<tab><tab>try:<tab><tab><tab>parser.feed(data)<tab><tab>except EndOfHeadError:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab># this should only happen if there is no HTML body, or if<tab><tab><tab># CHUNK is big<tab><tab><tab>break<tab>return parser.http_equiv",0,if len ( data ) != CHUNK :,if not data :,0.019930836,6.023021416,0.481481481
"def _check_no_empty_dimension_lists(config):<tab>""""""Verify that at least one dimension is not an empty list""""""<tab>logging.info(""Checking provided dimensions are valid"")<tab>for feature in config.get(""test-suites"").values():<tab><tab>for test_name, test in feature.items():<tab><tab><tab>for dimensions_config in test.values():<tab><tab><tab><tab>for dimensions_group in dimensions_config:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>logging.error(<tab><tab><tab><tab><tab><tab><tab>""Values assigned to dimensions in test %s cannot be empty"",<tab><tab><tab><tab><tab><tab><tab>test_name,<tab><tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab><tab>raise AssertionError",0,if [ ] in dimensions_group . values ( ) :,if not dimensions_group . empty :,0.027684848,23.20604146,0.333333333
"def aggregate_sorted(self, items):<tab>create = self.createCombiner<tab>merge = self.mergeValue<tab>i = None<tab>for i, (k, v) in enumerate(items):<tab><tab>if i == 0:<tab><tab><tab>curr_key = k<tab><tab><tab>curr_value = create(v)<tab><tab><IF-STMT><tab><tab><tab>yield curr_key, curr_value<tab><tab><tab>curr_key = k<tab><tab><tab>curr_value = create(v)<tab><tab>else:<tab><tab><tab>curr_value = merge(curr_value, v)<tab>if i is not None:<tab><tab>yield curr_key, curr_value",0,elif k != curr_key :,elif i is not None :,0.028110872,6.916271813,0.2
"def _run_iptables(self, version, cmd, *args):<tab>ipt_cmd = ""{} {}"".format(self._iptables_command(version), cmd)<tab>if self._has_w_argument is None:<tab><tab>result = self.run_expect([0, 2], ipt_cmd, *args)<tab><tab><IF-STMT><tab><tab><tab>self._has_w_argument = False<tab><tab><tab>return self._run_iptables(version, cmd, *args)<tab><tab>else:<tab><tab><tab>self._has_w_argument = True<tab><tab><tab>return result.stdout.rstrip(""\r\n"")<tab>else:<tab><tab>return self.check_output(ipt_cmd, *args)",0,if result . rc == 2 :,if result . returncode == 0 :,0.344478934,27.05411345,0.428571429
"def handle_data(self, data):<tab>if self.in_span or self.in_div:<tab><tab>if data == ""No such user (please note that login is case sensitive)"":<tab><tab><tab>self.no_user = True<tab><tab>elif data == ""Invalid password"":<tab><tab><tab>self.bad_pw = True<tab><tab><IF-STMT><tab><tab><tab>self.already_exists = True",0,"elif data == ""User with that email already exists"" :","elif data == ""Duplicate key"" :",0.555929203,32.91467773,0.380952381
"def configure(self, **kw):<tab>""""""Configure the image.""""""<tab>res = ()<tab>for k, v in _cnfmerge(kw).items():<tab><tab>if v is not None:<tab><tab><tab>if k[-1] == ""_"":<tab><tab><tab><tab>k = k[:-1]<tab><tab><tab>if hasattr(v, ""__call__""):<tab><tab><tab><tab>v = self._register(v)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>v = self.tk._createbytearray(v)<tab><tab><tab>res = res + (""-"" + k, v)<tab>self.tk.call((self.name, ""config"") + res)",0,"elif k in ( ""data"" , ""maskdata"" ) :","elif isinstance ( v , bytes ) :",0.115570648,7.43376166,0.272727273
"def run(self):<tab>if self.distribution.install_requires:<tab><tab>self.distribution.fetch_build_eggs(self.distribution.install_requires)<tab>if self.distribution.tests_require:<tab><tab>self.distribution.fetch_build_eggs(self.distribution.tests_require)<tab>if self.test_suite:<tab><tab>cmd = "" "".join(self.test_args)<tab><tab><IF-STMT><tab><tab><tab>self.announce('skipping ""unittest %s"" (dry run)' % cmd)<tab><tab>else:<tab><tab><tab>self.announce('running ""unittest %s""' % cmd)<tab><tab><tab>self.with_project_on_sys_path(self.run_tests)",1,if self . dry_run :,if self . dry_run :,0.75,100,1
"def wrapped(request, *args, **kwargs):<tab>if not gargoyle.is_active(key, request):<tab><tab>if not redirect_to:<tab><tab><tab>raise Http404(""Switch '%s' is not active"" % key)<tab><tab><IF-STMT><tab><tab><tab>return HttpResponseRedirect(redirect_to)<tab><tab>else:<tab><tab><tab>return HttpResponseRedirect(reverse(redirect_to))<tab>return func(request, *args, **kwargs)",0,"elif redirect_to . startswith ( ""/"" ) :","elif gargoyle . is_active ( key , request ) :",0.032495806,8.913765521,0.30952381
"def strip_suffixes(path: str) -> str:<tab>t = path<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>t = t[:-3]<tab><tab>elif t.endswith("".raw""):<tab><tab><tab>t = t[:-4]<tab><tab>elif t.endswith("".tar""):<tab><tab><tab>t = t[:-4]<tab><tab>elif t.endswith("".qcow2""):<tab><tab><tab>t = t[:-6]<tab><tab>else:<tab><tab><tab>break<tab>return t",0,"if t . endswith ( "".xz"" ) :","if t . endswith ( "".txt"" ) :",0.549040681,70.16879391,1
"def tags(self):<tab>label = """"<tab>for dt in constants.DOMAIN_TYPES:<tab><tab><IF-STMT><tab><tab><tab>label = dt[1]<tab>result = [{""name"": self.type, ""label"": label, ""type"": ""dom""}]<tab>if self.transport:<tab><tab>result.append(<tab><tab><tab>{<tab><tab><tab><tab>""name"": self.transport.service,<tab><tab><tab><tab>""label"": self.transport.service,<tab><tab><tab><tab>""type"": ""srv"",<tab><tab><tab><tab>""color"": ""info"",<tab><tab><tab>}<tab><tab>)<tab>return result",0,if self . type == dt [ 0 ] :,"if dt [ 0 ] == ""domain"" :",0.205167168,29.98221389,0.305555556
"def find_first_of_filetype(content, filterfiltype, attr=""name""):<tab>""""""Find the first of the file type.""""""<tab>filename = """"<tab>for _filename in content:<tab><tab>if isinstance(_filename, str):<tab><tab><tab>if _filename.endswith(f"".{filterfiltype}""):<tab><tab><tab><tab>filename = _filename<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filename = getattr(_filename, attr)<tab><tab><tab><tab>break<tab>return filename",0,"if getattr ( _filename , attr ) . endswith ( f"".{filterfiltype}"" ) :","if hasattr ( _filename , attr ) :",0.23805448,19.46058124,0.49122807
"def check_data_array_types(self, *arrays):<tab>result = []<tab>for array in arrays:<tab><tab><IF-STMT><tab><tab><tab>result.append(array)<tab><tab><tab>continue<tab><tab>result.append(np.asanyarray(array))<tab><tab>if not result[-1].shape:<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Given data-array is of unexpected type %s. Please pass numpy arrays instead.""<tab><tab><tab><tab>% type(array)<tab><tab><tab>)<tab>return result",0,if array is None or scipy . sparse . issparse ( array ) :,"if not isinstance ( array , np . ndarray ) :",0.024485372,8.930948186,0.136094675
"def description(self):<tab>global role_descriptions<tab>description = role_descriptions[self.role_field]<tab>content_type = self.content_type<tab>model_name = None<tab>if content_type:<tab><tab>model = content_type.model_class()<tab><tab>model_name = re.sub(r""([a-z])([A-Z])"", r""\1 \2"", model.__name__).lower()<tab>value = description<tab>if type(description) == dict:<tab><tab>value = description.get(model_name)<tab><tab><IF-STMT><tab><tab><tab>value = description.get(""default"")<tab>if ""%s"" in value and content_type:<tab><tab>value = value % model_name<tab>return value",0,if value is None :,elif type ( description ) == list :,0.143540538,4.76770702,0.111111111
"def popupFrameXdiff(job, frame1, frame2, frame3=None):<tab>""""""Opens a frame xdiff.""""""<tab>for command in [""/usr/bin/xxdiff"", ""/usr/local/bin/xdiff""]:<tab><tab><IF-STMT><tab><tab><tab>for frame in [frame1, frame2, frame3]:<tab><tab><tab><tab>if frame:<tab><tab><tab><tab><tab>command += "" --title1 %s %s"" % (<tab><tab><tab><tab><tab><tab>frame.data.name,<tab><tab><tab><tab><tab><tab>getFrameLogFile(job, frame),<tab><tab><tab><tab><tab>)<tab><tab><tab>shellOut(command)",0,if os . path . isfile ( command ) :,if frame3 :,0.010867398,1.00E-10,0.252747253
"def _groups_args_split(self, kwargs):<tab>groups_args_split = []<tab>groups = kwargs[""groups""]<tab>for key, group in groups.iteritems():<tab><tab>mykwargs = kwargs.copy()<tab><tab>del mykwargs[""groups""]<tab><tab>if ""group_name"" in group:<tab><tab><tab>mykwargs[""source_security_group_name""] = group[""group_name""]<tab><tab>if ""user_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_owner_id""] = group[""user_id""]<tab><tab><IF-STMT><tab><tab><tab>mykwargs[""source_security_group_id""] = group[""group_id""]<tab><tab>groups_args_split.append(mykwargs)<tab>return groups_args_split",1,"if ""group_id"" in group :","if ""group_id"" in group :",0.75,100,1
"def _mangle_phone(phone, config):<tab>regexp = config.get(""REGEXP"")<tab>if regexp:<tab><tab>try:<tab><tab><tab>m = re.match(""^/(.*)/(.*)/$"", regexp)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>phone = re.sub(m.group(1), m.group(2), phone)<tab><tab>except re.error:<tab><tab><tab>log.warning(<tab><tab><tab><tab>u""Can not mangle phone number. ""<tab><tab><tab><tab>u""Please check your REGEXP: {0!s}"".format(regexp)<tab><tab><tab>)<tab>return phone",1,if m :,if m :,0.531170663,1.00E-10,1
"def getScramRange(src):<tab>scramRange = None<tab>for mod in src.item.activeModulesIter():<tab><tab><IF-STMT><tab><tab><tab>scramRange = max(scramRange or 0, mod.maxRange or 0)<tab>return scramRange",0,if _isRegularScram ( mod ) or _isHicScram ( mod ) :,if mod . scramRange is not None :,0.013374522,3.890218086,0.3125
"def snapshot(self):<tab># if this volume is attached to a server<tab># we need to freeze the XFS file system<tab>try:<tab><tab>self.freeze()<tab><tab><IF-STMT><tab><tab><tab>snapshot = self.get_ec2_connection().create_snapshot(self.volume_id)<tab><tab>else:<tab><tab><tab>snapshot = self.server.ec2.create_snapshot(self.volume_id)<tab><tab>boto.log.info(""Snapshot of Volume %s created: %s"" % (self.name, snapshot))<tab>except Exception:<tab><tab>boto.log.info(""Snapshot error"")<tab><tab>boto.log.info(traceback.format_exc())<tab>finally:<tab><tab>status = self.unfreeze()<tab><tab>return status",0,if self . server == None :,if self . server is None :,0.246272831,42.38365628,0.633333333
"def closeststack(self, card):<tab>closest = None<tab>cdist = 999999999<tab># Since we only compare distances,<tab># we don't bother to take the square root.<tab>for stack in self.openstacks:<tab><tab>dist = (stack.x - card.x) ** 2 + (stack.y - card.y) ** 2<tab><tab><IF-STMT><tab><tab><tab>closest = stack<tab><tab><tab>cdist = dist<tab>return closest",1,if dist < cdist :,if dist < cdist :,0.75,100,1
"def _sock_send(self, msg):<tab>try:<tab><tab>if isinstance(msg, str):<tab><tab><tab>msg = msg.encode(""ascii"")<tab><tab># http://docs.datadoghq.com/guides/dogstatsd/#datagram-format<tab><tab>if self.dogstatsd_tags:<tab><tab><tab>msg = msg + b""|#"" + self.dogstatsd_tags.encode(""ascii"")<tab><tab><IF-STMT><tab><tab><tab>self.sock.send(msg)<tab>except Exception:<tab><tab>Logger.warning(self, ""Error sending message to statsd"", exc_info=True)",1,if self . sock :,if self . sock :,0.75,100,1
"def styleRow(self, row, selected):<tab>if row > 0 and row < self.getRowCount():<tab><tab><IF-STMT><tab><tab><tab>self.getRowFormatter().addStyleName(row, ""user-SelectedRow"")<tab><tab>else:<tab><tab><tab>self.getRowFormatter().removeStyleName(row, ""user-SelectedRow"")",1,if selected :,if selected :,0.531170663,1.00E-10,1
"def __gather_epoch_end_eval_results(self, outputs):<tab>eval_results = []<tab>for epoch_output in outputs:<tab><tab>result = epoch_output[0].__class__.gather(epoch_output)<tab><tab>if ""checkpoint_on"" in result:<tab><tab><tab>result.checkpoint_on = result.checkpoint_on.mean()<tab><tab><IF-STMT><tab><tab><tab>result.early_stop_on = result.early_stop_on.mean()<tab><tab>eval_results.append(result)<tab># with 1 dataloader don't pass in a list<tab>if len(eval_results) == 1:<tab><tab>eval_results = eval_results[0]<tab>return eval_results",1,"if ""early_stop_on"" in result :","if ""early_stop_on"" in result :",0.75,100,1
"def network_state(self, device):<tab>cmd = [""tc"", ""qdisc"", ""show"", ""dev"", device]<tab>try:<tab><tab>output = self.host_exec.run(cmd)<tab><tab># sloppy but good enough for now<tab><tab>if "" delay "" in output:<tab><tab><tab>return NetworkState.SLOW<tab><tab>if "" loss "" in output:<tab><tab><tab>return NetworkState.FLAKY<tab><tab><IF-STMT><tab><tab><tab>return NetworkState.DUPLICATE<tab><tab>return NetworkState.NORMAL<tab>except Exception:<tab><tab>return NetworkState.UNKNOWN",0,"if "" duplicate "" in output :","if ""duplicate "" in output :",0.476133778,100,0.371428571
"def canberra_grad(x, y):<tab>result = 0.0<tab>grad = np.zeros(x.shape)<tab>for i in range(x.shape[0]):<tab><tab>denominator = np.abs(x[i]) + np.abs(y[i])<tab><tab><IF-STMT><tab><tab><tab>result += np.abs(x[i] - y[i]) / denominator<tab><tab><tab>grad[i] = (<tab><tab><tab><tab>np.sign(x[i] - y[i]) / denominator<tab><tab><tab><tab>- np.abs(x[i] - y[i]) * np.sign(x[i]) / denominator ** 2<tab><tab><tab>)<tab>return result, grad",1,if denominator > 0 :,if denominator > 0 :,0.75,100,1
"def readwrite(obj, flags):<tab>try:<tab><tab>if flags & select.POLLIN:<tab><tab><tab>obj.handle_read_event()<tab><tab><IF-STMT><tab><tab><tab>obj.handle_write_event()<tab><tab>if flags & select.POLLPRI:<tab><tab><tab>obj.handle_expt_event()<tab><tab>if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):<tab><tab><tab>obj.handle_close()<tab>except OSError as e:<tab><tab>if e.args[0] not in _DISCONNECTED:<tab><tab><tab>obj.handle_error()<tab><tab>else:<tab><tab><tab>obj.handle_close()<tab>except _reraised_exceptions:<tab><tab>raise<tab>except:<tab><tab>obj.handle_error()",0,if flags & select . POLLOUT :,if flags & select . POLLIN :,0.574113272,64.34588842,0.666666667
"def get_func_name(obj):<tab>if inspect.ismethod(obj):<tab><tab>match = RE_BOUND_METHOD.match(repr(obj))<tab><tab><IF-STMT><tab><tab><tab>cls = match.group(""class"")<tab><tab><tab>if not cls:<tab><tab><tab><tab>return match.group(""name"")<tab><tab><tab>return ""%s.%s"" % (match.group(""class""), match.group(""name""))<tab>return None",1,if match :,if match :,0.531170663,1.00E-10,1
"def __init__(self, connection):<tab>self.username = connection.username<tab>self.password = connection.password<tab>self.domain = connection.domain<tab>self.hash = connection.hash<tab>self.lmhash = """"<tab>self.nthash = """"<tab>self.aesKey = connection.aesKey<tab>self.kdcHost = connection.kdcHost<tab>self.kerberos = connection.kerberos<tab>if self.hash is not None:<tab><tab><IF-STMT><tab><tab><tab>self.lmhash, self.nthash = self.hash.split("":"")<tab><tab>else:<tab><tab><tab>self.nthash = self.hash<tab>if self.password is None:<tab><tab>self.password = """"",0,"if self . hash . find ( "":"" ) != - 1 :","if "":"" in self . hash :",0.044916707,14.73524804,0.277310924
"def indent_xml(elem, level=0):<tab>""""""Do our pretty printing and make Matt very happy.""""""<tab>i = ""\n"" + level * ""  ""<tab>if elem:<tab><tab>if not elem.text or not elem.text.strip():<tab><tab><tab>elem.text = i + ""  ""<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab><tab>for elem in elem:<tab><tab><tab>indent_xml(elem, level + 1)<tab><tab>if not elem.tail or not elem.tail.strip():<tab><tab><tab>elem.tail = i<tab>else:<tab><tab><IF-STMT><tab><tab><tab>elem.tail = i",0,if level and ( not elem . tail or not elem . tail . strip ( ) ) :,if level or not elem . tail or not elem . tail . strip ( ) :,0.646627911,72.0476231,0.851851852
"def add_braces_and_labels(self):<tab>for attr in ""horizontal_parts"", ""vertical_parts"":<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>parts = getattr(self, attr)<tab><tab>for subattr in ""braces"", ""labels"":<tab><tab><tab>if hasattr(parts, subattr):<tab><tab><tab><tab>self.add(getattr(parts, subattr))",1,"if not hasattr ( self , attr ) :","if not hasattr ( self , attr ) :",0.75,100,1
"def error_messages(file_list, files_removed):<tab>if files_removed is None:<tab><tab>return<tab>for remove_this, reason in files_removed:<tab><tab>if file_list is not None:<tab><tab><tab>file_list.remove(remove_this)<tab><tab><IF-STMT><tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   is not PNG file format"")<tab><tab>elif reason == 1:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   already exists"")<tab><tab>elif reason == 2:<tab><tab><tab>print("" REMOVED : ("" + str(remove_this) + "")   file unreadable"")",1,if reason == 0 :,if reason == 0 :,0.75,100,1
"def keep_vocab_item(word, count, min_count, trim_rule=None):<tab>default_res = count >= min_count<tab>if trim_rule is None:<tab><tab>return default_res<tab>else:<tab><tab>rule_res = trim_rule(word, count, min_count)<tab><tab>if rule_res == RULE_KEEP:<tab><tab><tab>return True<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return default_res",0,elif rule_res == RULE_DISCARD :,elif rule_res == RULE_NO_KEEP :,0.642872021,63.15552372,1
"def func(x0):<tab>bind = 0<tab>backups = []<tab>vinputs = []<tab>for i, i0 in zip(inputs, inputs0):<tab><tab>if i is None:  # Optional argument<tab><tab><tab>continue<tab><tab>vinputs += [i]<tab><tab><IF-STMT>  # Not need backward<tab><tab><tab>i.d[...] = x0[bind : bind + i.size].reshape(i.shape)<tab><tab><tab>bind += i.size<tab><tab>backups.append(i.d.copy())<tab>f.forward(vinputs, outputs)<tab>for ind, i in enumerate(inputs):<tab><tab>if i is None:  # Optional argument<tab><tab><tab>continue<tab><tab>i.d[...] = backups[ind]<tab>return sum([np.sum(o.g * o.d) for o in outputs])",0,if i0 is not None :,if i . d . shape != x0 . shape :,0.019662767,4.027248192,0.190909091
"def _handle_js_events(self, change):<tab>if self.js_events:<tab><tab>if self.event_handlers:<tab><tab><tab>for event in self.js_events:<tab><tab><tab><tab>event_name = event[""name""]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.event_handlers[event_name](event[""detail""])<tab><tab># clears the event queue.<tab><tab>self.js_events = []",1,if event_name in self . event_handlers :,if event_name in self . event_handlers :,0.75,100,1
"def validate(leaves):<tab>for leaf in leaves:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif leaf.has_form(""List"", None) or leaf.has_form(""Association"", None):<tab><tab><tab>if validate(leaf.leaves) is not True:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",0,"if leaf . has_form ( ( ""Rule"" , ""RuleDelayed"" ) , 2 ) :","if leaf . has_form ( ( ""Rule"" , ""RuleDelayed"" ) , 10 ) :",0.655412299,87.39351325,0.6
"def ascii85decode(data):<tab>n = b = 0<tab>out = """"<tab>for c in data:<tab><tab>if ""!"" <= c and c <= ""u"":<tab><tab><tab>n += 1<tab><tab><tab>b = b * 85 + (ord(c) - 33)<tab><tab><tab>if n == 5:<tab><tab><tab><tab>out += struct.pack("">L"", b)<tab><tab><tab><tab>n = b = 0<tab><tab>elif c == ""z"":<tab><tab><tab>assert n == 0<tab><tab><tab>out += ""\0\0\0\0""<tab><tab>elif c == ""~"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for _ in range(5 - n):<tab><tab><tab><tab><tab>b = b * 85 + 84<tab><tab><tab><tab>out += struct.pack("">L"", b)[: n - 1]<tab><tab><tab>break<tab>return out",0,if n :,if n < 5 :,0.097914534,1.00E-10,0.7
"def to_text(self, origin=None, relativize=True, **kw):<tab>next = self.next.choose_relativity(origin, relativize)<tab>text = """"<tab>for (window, bitmap) in self.windows:<tab><tab>bits = []<tab><tab>for i in xrange(0, len(bitmap)):<tab><tab><tab>byte = bitmap[i]<tab><tab><tab>for j in xrange(0, 8):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>bits.append(dns.rdatatype.to_text(window * 256 + i * 8 + j))<tab><tab>text += "" "" + "" "".join(bits)<tab>return ""%s%s"" % (next, text)",1,if byte & ( 0x80 >> j ) :,if byte & ( 0x80 >> j ) :,0.75,100,1
"def _on_response(self, widget, response):<tab>value = None<tab>if response == Gtk.ResponseType.OK:<tab><tab><IF-STMT><tab><tab><tab>value = self.spinbutton.get_value_as_int()<tab><tab>else:<tab><tab><tab>value = self.spinbutton.get_value()<tab>self.deferred.callback(value)<tab>self.destroy()",0,if self . value_type is int :,if self . use_int :,0.153551991,24.17723702,0.55
"def send_preamble(self):<tab>""""""Transmit version/status/date/server, via self._write()""""""<tab>if self.origin_server:<tab><tab><IF-STMT><tab><tab><tab>self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status))<tab><tab><tab>if not self.headers.has_key(""Date""):<tab><tab><tab><tab>self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time())))<tab><tab><tab>if self.server_software and not self.headers.has_key(""Server""):<tab><tab><tab><tab>self._write(""Server: %s\r\n"" % self.server_software)<tab>else:<tab><tab>self._write(""Status: %s\r\n"" % self.status)",0,if self . client_is_modern ( ) :,if self . http_version :,0.094532291,15.68571805,1
"def _save_postinsts_common(self, dst_postinst_dir, src_postinst_dir):<tab>num = 0<tab>for p in self._get_delayed_postinsts():<tab><tab>bb.utils.mkdirhier(dst_postinst_dir)<tab><tab><IF-STMT><tab><tab><tab>shutil.copy(<tab><tab><tab><tab>os.path.join(src_postinst_dir, p + "".postinst""),<tab><tab><tab><tab>os.path.join(dst_postinst_dir, ""%03d-%s"" % (num, p)),<tab><tab><tab>)<tab><tab>num += 1",0,"if os . path . exists ( os . path . join ( src_postinst_dir , p + "".postinst"" ) ) :","if not os . path . exists ( os . path . join ( dst_postinst_dir , p + "".postinst"" ) ) :",0.791342668,84.09760645,0.24537037
"def edge_data_from_bmesh_edges(bm, edge_data):<tab>initial_index = bm.edges.layers.int.get(""initial_index"")<tab>if initial_index is None:<tab><tab>raise Exception(""bmesh has no initial_index layer"")<tab>edge_data_out = []<tab>n_edge_data = len(edge_data)<tab>for edge in bm.edges:<tab><tab>idx = edge[initial_index]<tab><tab><IF-STMT><tab><tab><tab>debug(""Unexisting edge_data[%s] [0 - %s]"", idx, n_edge_data)<tab><tab><tab>edge_data_out.append(None)<tab><tab>else:<tab><tab><tab>edge_data_out.append(edge_data[idx])<tab>return edge_data_out",0,if idx < 0 or idx >= n_edge_data :,if idx >= n_edge_data :,0.174932275,62.3803092,0.478787879
"def write(self, data):<tab>try:<tab><tab>c_written = DWORD()<tab><tab>buffer = create_string_buffer(data)<tab><tab><IF-STMT><tab><tab><tab>raise WinError()<tab>except:<tab><tab>self.close()",0,"if not WriteFile ( self . pStdin , buffer , len ( buffer ) , byref ( c_written ) , None ) :",if c_written == DWORD ( 0 ) :,0.008958651,5.344137183,0.148989899
"def get_icon(svg_path, size):<tab>pixbuf = GdkPixbuf.Pixbuf.new_from_file_at_scale(svg_path, size, size, True)<tab>data = bytearray(pixbuf.get_pixels())<tab>channels = pixbuf.get_n_channels()<tab>assert channels == 4<tab># https://en.wikipedia.org/wiki/PackBits<tab># no real compression going on here..<tab>new_data = bytearray()<tab>for c in range(3):<tab><tab>x = 0<tab><tab>for i in range(0, len(data), 4):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>new_data.append(127)<tab><tab><tab>new_data.append(data[i + c])<tab><tab><tab>x += 1<tab>return new_data",0,if x == 0 or x % 128 == 0 :,if data [ i + c ] != 0 :,0.023787513,12.49887916,0.2
"def _get_instance_attribute(<tab>self, attr, default=None, defaults=None, incl_metadata=False):<tab>if self.instance is None or not hasattr(self.instance, attr):<tab><tab>if incl_metadata and attr in self.parsed_metadata:<tab><tab><tab>return self.parsed_metadata[attr]<tab><tab>elif defaults is not None:<tab><tab><tab>for value in defaults:<tab><tab><tab><tab>if callable(value):<tab><tab><tab><tab><tab>value = value()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return value<tab><tab>return default<tab>return getattr(self.instance, attr)",1,if value is not None :,if value is not None :,0.75,100,1
"def forward(self, x):<tab>if self.ffn_type in (1, 2):<tab><tab>x0 = self.wx0(x)<tab><tab><IF-STMT><tab><tab><tab>x1 = x<tab><tab>elif self.ffn_type == 2:<tab><tab><tab>x1 = self.wx1(x)<tab><tab>out = self.output(x0 * x1)<tab>out = self.dropout(out)<tab>out = self.LayerNorm(out + x)<tab>return out",1,if self . ffn_type == 1 :,if self . ffn_type == 1 :,0.75,100,1
"def load(cls):<tab>if not cls._loaded:<tab><tab>cls.log.debug(""Loading tile_sets..."")<tab><tab><IF-STMT><tab><tab><tab>cls._find_tile_sets(PATHS.TILE_SETS_DIRECTORY)<tab><tab>else:<tab><tab><tab>cls.tile_sets = JsonDecoder.load(PATHS.TILE_SETS_JSON_FILE)<tab><tab>cls.log.debug(""Done!"")<tab><tab>cls._loaded = True",0,if not horizons . globals . fife . use_atlases :,if Path ( PATHS . TILE_SETS_DIRECTORY ) . is_dir ( ) :,0.014179937,3.211547432,0.234375
"def headerData(self, section, orientation, role=Qt.DisplayRole):<tab>if role == Qt.TextAlignmentRole:<tab><tab>if orientation == Qt.Horizontal:<tab><tab><tab>return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))<tab><tab>return to_qvariant(int(Qt.AlignRight | Qt.AlignVCenter))<tab>if role != Qt.DisplayRole:<tab><tab>return to_qvariant()<tab>if orientation == Qt.Horizontal:<tab><tab>if section == NAME:<tab><tab><tab>return to_qvariant(""Name"")<tab><tab><IF-STMT><tab><tab><tab>return to_qvariant(""Version"")<tab><tab>elif section == ACTION:<tab><tab><tab>return to_qvariant(""Action"")<tab><tab>elif section == DESCRIPTION:<tab><tab><tab>return to_qvariant(""Description"")<tab>return to_qvariant()",1,elif section == VERSION :,elif section == VERSION :,1,100,1
"def find_enabled_item(self, e):<tab>x, y = e.local<tab>if (<tab><tab>0<tab><tab><= x<tab><tab>< (<tab><tab><tab>self.width - self.margin - self.scroll_button_size<tab><tab><tab>if self.scrolling<tab><tab><tab>else self.width<tab><tab>)<tab>):<tab><tab>h = self.font.get_linesize()<tab><tab>i = (y - h // 2) // h + self.scroll<tab><tab>items = self._items<tab><tab>if 0 <= i < len(items):<tab><tab><tab>item = items[i]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return item",0,if item . enabled :,if item is not None :,0.057429006,17.9652056,0.357142857
"def set_parallel_limit(environment):<tab>parallel_limit = environment.get(""COMPOSE_PARALLEL_LIMIT"")<tab>if parallel_limit:<tab><tab>try:<tab><tab><tab>parallel_limit = int(parallel_limit)<tab><tab>except ValueError:<tab><tab><tab>raise errors.UserError(<tab><tab><tab><tab>'COMPOSE_PARALLEL_LIMIT must be an integer (found: ""{}"")'.format(<tab><tab><tab><tab><tab>environment.get(""COMPOSE_PARALLEL_LIMIT"")<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise errors.UserError(""COMPOSE_PARALLEL_LIMIT can not be less than 2"")<tab><tab>parallel.GlobalLimit.set_global_limit(parallel_limit)",0,if parallel_limit <= 1 :,if parallel_limit > 2 :,0.314978772,37.68499164,0.5
"def migrate_identifier(self, raw_identifier: int):<tab>if self.unique_cog_identifier in self.data:<tab><tab># Data has already been migrated<tab><tab>return<tab>poss_identifiers = [str(raw_identifier), str(hash(raw_identifier))]<tab>for ident in poss_identifiers:<tab><tab><IF-STMT><tab><tab><tab>self.data[self.unique_cog_identifier] = self.data[ident]<tab><tab><tab>del self.data[ident]<tab><tab><tab>_save_json(self.data_path, self.data)<tab><tab><tab>break",1,if ident in self . data :,if ident in self . data :,0.75,100,1
"def _memoize(*args, **kwargs):<tab>str_args = []<tab>for arg in args:<tab><tab><IF-STMT><tab><tab><tab>str_args.append(six.text_type(arg))<tab><tab>else:<tab><tab><tab>str_args.append(arg)<tab>args_ = "","".join(<tab><tab>list(str_args) + [""{0}={1}"".format(k, kwargs[k]) for k in sorted(kwargs)]<tab>)<tab>if args_ not in cache:<tab><tab>cache[args_] = func(*args, **kwargs)<tab>return cache[args_]",0,"if not isinstance ( arg , six . string_types ) :","if isinstance ( arg , six . text_type ) :",0.271100274,45.64968732,0.320512821
"def extract(self):<tab>for battery in self.vars:<tab><tab>for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines():<tab><tab><tab>l = line.split()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if l[0:2] == [""remaining"", ""capacity:""]:<tab><tab><tab><tab>remaining = int(l[2])<tab><tab><tab><tab>continue<tab><tab><tab>elif l[0:2] == [""present"", ""rate:""]:<tab><tab><tab><tab>rate = int(l[2])<tab><tab><tab><tab>continue<tab><tab>if rate and remaining:<tab><tab><tab>self.val[battery] = remaining * 60 / rate<tab><tab>else:<tab><tab><tab>self.val[battery] = -1",1,if len ( l ) < 3 :,if len ( l ) < 3 :,0.75,100,1
"def version_iter(q, limit=500, offset=0):<tab>q[""limit""] = limit<tab>q[""offset""] = offset<tab>while True:<tab><tab>url = base_url() + ""/version""<tab><tab>v = jsonload(url)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for i in query(q):<tab><tab><tab>yield i<tab><tab>q[""offset""] += limit",1,if not v :,if not v :,0.75,100,1
"def _letf_btn_press(self, event):<tab>try:<tab><tab>elem = self.identify(event.x, event.y)<tab><tab>index = self.index(""@%d,%d"" % (event.x, event.y))<tab><tab><IF-STMT><tab><tab><tab>self.state([""pressed""])<tab><tab><tab>self.pressed_index = index<tab>except Exception:<tab><tab># may fail, if clicked outside of tab<tab><tab>return",0,"if ""closebutton"" in elem :",if self . pressed_elem is None or self . pressed_elem == elem :,0.042633504,4.75362206,0.21875
"def get_location(self, dist, dependency_links):<tab>for url in dependency_links:<tab><tab>egg_fragment = Link(url).egg_fragment<tab><tab>if not egg_fragment:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>## FIXME: will this work when a package has - in the name?<tab><tab><tab>key = ""-"".join(egg_fragment.split(""-"")[:-1]).lower()<tab><tab>else:<tab><tab><tab>key = egg_fragment<tab><tab>if key == dist.key:<tab><tab><tab>return url.split(""#"", 1)[0]<tab>return None",1,"if ""-"" in egg_fragment :","if ""-"" in egg_fragment :",0.75,100,1
"def viewTreeItemClicked(self, event):<tab>if DEBUG:<tab><tab>print(""viewTreeitemClicked:"", event.__dict__, file=sys.stderr)<tab>self.unmarkTargets()<tab>vuid = self.viewTree.viewTree.identify_row(event.y)<tab>if vuid:<tab><tab>view = self.vc.viewsById[vuid]<tab><tab><IF-STMT><tab><tab><tab>coords = view.getCoords()<tab><tab><tab>if view.isTarget():<tab><tab><tab><tab>self.markTarget(coords[0][0], coords[0][1], coords[1][0], coords[1][1])<tab><tab><tab>self.viewDetails.set(view)",1,if view :,if view :,0.531170663,1.00E-10,1
"def getVar(self, name):<tab>value = self.tinfoil.run_command(""dataStoreConnectorFindVar"", self.dsindex, name)<tab>overrides = None<tab>if isinstance(value, dict):<tab><tab>if ""_connector_origtype"" in value:<tab><tab><tab>value[""_content""] = self.tinfoil._reconvert_type(<tab><tab><tab><tab>value[""_content""], value[""_connector_origtype""]<tab><tab><tab>)<tab><tab><tab>del value[""_connector_origtype""]<tab><tab><IF-STMT><tab><tab><tab>overrides = value[""_connector_overrides""]<tab><tab><tab>del value[""_connector_overrides""]<tab>return value, overrides",1,"if ""_connector_overrides"" in value :","if ""_connector_overrides"" in value :",0.75,100,1
"def sample(self, **config):<tab>""""""Sample a configuration from this search space.""""""<tab>ret = []<tab>kwspaces = self.kwspaces<tab>striped_keys = [k.split(SPLITTER)[0] for k in config.keys()]<tab>for idx, obj in enumerate(self.data):<tab><tab>if isinstance(obj, NestedSpace):<tab><tab><tab>sub_config = _strip_config_space(config, prefix=str(idx))<tab><tab><tab>ret.append(obj.sample(**sub_config))<tab><tab><IF-STMT><tab><tab><tab>ret.append(config[str(idx)])<tab><tab>else:<tab><tab><tab>ret.append(obj)<tab>return ret",0,"elif isinstance ( obj , SimpleSpace ) :",elif str ( idx ) in stripped_keys :,0.119640733,5.93420261,0.25
"def main():<tab>for filename in sys.argv[1:]:<tab><tab><IF-STMT><tab><tab><tab>print(filename, ""Directory!"")<tab><tab><tab>continue<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>data = f.read()<tab><tab>if b""\0"" in data:<tab><tab><tab>print(filename, ""Binary!"")<tab><tab><tab>continue<tab><tab>newdata = data.replace(b""\r\n"", b""\n"")<tab><tab>if newdata != data:<tab><tab><tab>print(filename)<tab><tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab><tab>f.write(newdata)",1,if os . path . isdir ( filename ) :,if os . path . isdir ( filename ) :,0.75,100,1
"def normalize_crlf(tree):<tab>for elem in tree.getiterator():<tab><tab>if elem.text:<tab><tab><tab>elem.text = elem.text.replace(""\r\n"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>elem.tail = elem.tail.replace(""\r\n"", ""\n"")",1,if elem . tail :,if elem . tail :,0.75,100,1
"def RegisterValue(self, value):<tab>""""""Puts a given value into an appropriate bin.""""""<tab>if self.bins:<tab><tab>for b in self.bins:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>b.num += 1<tab><tab><tab><tab>return<tab><tab>self.bins[-1].num += 1",0,if b . range_max_value > value :,if b . value == value :,0.354558128,18.59400212,0.880952381
"def all_commands():<tab>all_cmds = []<tab>for bp in BINPATHS:<tab><tab>cmds = [<tab><tab><tab>fn[:-3]<tab><tab><tab>for fn in os.listdir(bp)<tab><tab><tab><IF-STMT><tab><tab><tab>and not fn.startswith(""."")<tab><tab><tab>and os.path.isfile(os.path.join(bp, fn))<tab><tab>]<tab><tab>all_cmds += cmds<tab>all_cmds.sort()<tab>return all_cmds",1,"if fn . endswith ( "".py"" )","if fn . endswith ( "".py"" )",0.75,100,1
"def base64_encode_image_mapper(self, tag, url):<tab>if tag == ""img"":<tab><tab>if url in self.kp_images:<tab><tab><tab>image_data = base64.b64encode(self.kp_images[url])<tab><tab><tab>image_mimetype = mimetypes.guess_type(url)[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""data:{};base64, "".format(image_mimetype) + image_data.decode(<tab><tab><tab><tab><tab>""utf-8""<tab><tab><tab><tab>)<tab>return None",0,if image_mimetype is not None :,if image_mimetype :,0.050438393,1.00E-10,0.314285714
"def validate_input(self):<tab>if self.validation_fn:<tab><tab>success, err = self.validation_fn(self.str)<tab><tab><IF-STMT><tab><tab><tab>spaces = "" "" * self.textwin_width<tab><tab><tab>self.textwin.addstr(self.y + 2, 0, spaces)<tab><tab><tab>self.textwin.addstr(self.y + 2, 0, err, curses.color_pair(4))<tab><tab>return success<tab>else:<tab><tab>return True",0,if not success :,if self . textwin :,0.042407859,12.7033187,0.333333333
"def start_prompt(self):<tab>""""""Start the interpreter.""""""<tab>logger.show(""Coconut Interpreter:"")<tab>logger.show(""(type 'exit()' or press Ctrl-D to end)"")<tab>self.start_running()<tab>while self.running:<tab><tab>try:<tab><tab><tab>code = self.get_input()<tab><tab><tab>if code:<tab><tab><tab><tab>compiled = self.handle_input(code)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.execute(compiled, use_eval=None)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>printerr(""\nKeyboardInterrupt"")",1,if compiled :,if compiled :,0.531170663,1.00E-10,1
"def __exit__(self, exc_type, exc_val, exc_tb):<tab>if self.channel and self.channel.connection:<tab><tab>conn_errors = self.channel.connection.client.connection_errors<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>self.cancel()<tab><tab><tab>except Exception:<tab><tab><tab><tab>pass",0,"if not isinstance ( exc_val , conn_errors ) :",if conn_errors :,0.013954293,1.00E-10,0.464285714
"def pack(data, size, endian):<tab>buf = []<tab>for i in data:<tab><tab>num = int(i)<tab><tab><IF-STMT><tab><tab><tab>num += 1 << (size * 8)<tab><tab>d = [b""\x00""] * size<tab><tab>i = size - 1<tab><tab>while i >= 0:<tab><tab><tab>b = num & 255<tab><tab><tab>d[i] = bytes((b,)) if PY3 else chr(b)<tab><tab><tab>num >>= 8<tab><tab><tab>i -= 1<tab><tab>if endian == ""<"":<tab><tab><tab>d = b"""".join(d[i : i + 1][0] for i in reversed(xrange(len(d))))<tab><tab>else:<tab><tab><tab>d = b"""".join(d)<tab><tab>buf.append(d)<tab>return b"""".join(buf)",0,if num < 0 :,"if endian == ""<"" :",0.034123066,7.267884212,0.36
"def _sample_new_noise_and_add(self, *, tf_sess=None, override=False):<tab>if self.framework == ""tf"":<tab><tab><IF-STMT><tab><tab><tab>tf_sess.run(self.tf_remove_noise_op)<tab><tab>tf_sess.run(self.tf_sample_new_noise_and_add_op)<tab>else:<tab><tab>if override and self.weights_are_currently_noisy:<tab><tab><tab>self._remove_noise()<tab><tab>self._sample_new_noise()<tab><tab>self._add_stored_noise()<tab>self.weights_are_currently_noisy = True",1,if override and self . weights_are_currently_noisy :,if override and self . weights_are_currently_noisy :,0.75,100,1
"def hdfs_link_js(url):<tab>link = ""javascript:void(0)""<tab>if url:<tab><tab>path = Hdfs.urlsplit(url)[2]<tab><tab>if path:<tab><tab><tab>link = (<tab><tab><tab><tab>""/filebrowser/view=%s""<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab>else ""/filebrowser/home_relative_view=/%s""<tab><tab><tab>) % path<tab>return link",0,if path . startswith ( posixpath . sep ),"if path . endswith ( ""/"" )",0.070516308,20.16494558,0.4
"def set_xticklabels(self, labels=None, step=None, **kwargs):<tab>""""""Set x axis tick labels on the bottom row of the grid.""""""<tab>for ax in self.axes[-1, :]:<tab><tab>if labels is None:<tab><tab><tab>labels = [l.get_text() for l in ax.get_xticklabels()]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>xticks = ax.get_xticks()[::step]<tab><tab><tab><tab>labels = labels[::step]<tab><tab><tab><tab>ax.set_xticks(xticks)<tab><tab>ax.set_xticklabels(labels, **kwargs)<tab>return self",1,if step is not None :,if step is not None :,0.75,100,1
"def _get_statement_from_file(user, fs, snippet):<tab>script_path = snippet[""statementPath""]<tab>if script_path:<tab><tab>script_path = script_path.replace(""hdfs://"", """")<tab><tab><IF-STMT><tab><tab><tab>return fs.do_as_user(user, fs.read, script_path, 0, 16 * 1024 ** 2)",0,"if fs . do_as_user ( user , fs . isfile , script_path ) :","if not script_path . startswith ( ""hdfs://"" ) :",0.020177769,10.02653868,0.271428571
def doWorkUnit(self):<tab>if len(self.workers):<tab><tab>try:<tab><tab><tab>w = self.workers.popleft()<tab><tab><tab>w.next()<tab><tab><tab>self.workers.append(w)<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.invalidate()<tab>else:<tab><tab>time.sleep(0.001),0,"if hasattr ( w , ""needsRedraw"" ) and w . needsRedraw :",if self . invalidate :,0.010805043,2.323859896,0.225
"def _find_l1_phash_mul(cdict):<tab>candidate_lengths = _find_candidate_lengths_mul(cdict.tuple2int)<tab>for p in candidate_lengths:<tab><tab>hash_f = hashmul.hashmul_t(p)<tab><tab><IF-STMT><tab><tab><tab>return l1_phash_t(cdict, hash_f)<tab><tab>del hash_f<tab>return None",0,if hash_f . is_perfect ( iter ( cdict . tuple2int . values ( ) ) ) :,if hash_f . sum ( ) > 0 :,0.064018818,16.80963757,0.240384615
"def _find_next_tab_stop(self, direction):<tab>old_focus = self._focus<tab>self._focus += direction<tab>while self._focus != old_focus:<tab><tab>if self._focus < 0:<tab><tab><tab>self._focus = len(self._layouts) - 1<tab><tab>if self._focus >= len(self._layouts):<tab><tab><tab>self._focus = 0<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._layouts[self._focus].focus(force_first=True)<tab><tab><tab>else:<tab><tab><tab><tab>self._layouts[self._focus].focus(force_last=True)<tab><tab><tab>break<tab><tab>except IndexError:<tab><tab><tab>self._focus += direction",0,if direction > 0 :,"if direction == ""first"" :",0.064978772,12.22307556,0.7
"def _get_py_flags(self):<tab>res = dict(self.flags)<tab>cflags = res.pop(""cflags"", """")<tab>for fl in cflags.split(""|""):<tab><tab>fl = fl.strip()<tab><tab>if fl == ""GA_USE_DOUBLE"":<tab><tab><tab>res[""have_double""] = True<tab><tab><IF-STMT><tab><tab><tab>res[""have_small""] = True<tab><tab>if fl == ""GA_USE_COMPLEX"":<tab><tab><tab>res[""have_complex""] = True<tab><tab>if fl == ""GA_USE_HALF"":<tab><tab><tab>res[""have_half""] = True<tab>return res",1,"if fl == ""GA_USE_SMALL"" :","if fl == ""GA_USE_SMALL"" :",0.75,100,1
"def _install_provision_configs(self):<tab>config = self._config.plugins[self.full_name]<tab>files = config.get(""provision_config_files"", [])<tab>if files:<tab><tab><IF-STMT><tab><tab><tab>log.critical(""Error installing provisioning configs"")<tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>log.debug(""Provision config files successfully installed"")<tab><tab><tab>return True<tab>else:<tab><tab>log.debug(""No provision config files configured"")<tab><tab>return True",0,"if not install_provision_configs ( files , self . _mountpoint ) :",if not self . _config . install_provision_configs ( files ) :,0.077755007,52.66403878,0.6
"def postfile(self):<tab>for clientip, serverips in self.client_conns.items():<tab><tab>target_count = len(serverips)<tab><tab>S = min((len(self.server_conns[serverip]) for serverip in serverips))<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># TODO implement whitelist<tab><tab>self.write(<tab><tab><tab>""Scanning IP: {} / S score: {:.1f} / Number of records: {}"".format(<tab><tab><tab><tab>clientip, S, target_count<tab><tab><tab>)<tab><tab>)",0,if S > 2 or target_count < 5 :,if S < target_count :,0.032892543,18.88248846,0.454545455
"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab><IF-STMT><tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab>elif isinstance(value, types.ModuleType):<tab><tab><tab>self.__defaults_from_module(value)<tab><tab>elif isinstance(value, str):<tab><tab><tab>if os.path.exists(value):<tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)",0,if type ( value ) == dict :,"if isinstance ( value , dict ) :",0.039168582,12.82777061,0.666666667
"def __init__(self, aList):<tab>for element in aList:<tab><tab><IF-STMT><tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>self.append(ListParser(element))<tab><tab><tab>else:<tab><tab><tab><tab>self.append(DictParser(element))<tab><tab>elif element.text:<tab><tab><tab>text = element.text.strip()<tab><tab><tab>if text:<tab><tab><tab><tab>self.append(text)",0,if len ( element ) > 0 :,"if isinstance ( element , tuple ) :",0.037791629,13.88809517,0.428571429
"def _get_py_flags(self):<tab>res = dict(self.flags)<tab>cflags = res.pop(""cflags"", """")<tab>for fl in cflags.split(""|""):<tab><tab>fl = fl.strip()<tab><tab><IF-STMT><tab><tab><tab>res[""have_double""] = True<tab><tab>if fl == ""GA_USE_SMALL"":<tab><tab><tab>res[""have_small""] = True<tab><tab>if fl == ""GA_USE_COMPLEX"":<tab><tab><tab>res[""have_complex""] = True<tab><tab>if fl == ""GA_USE_HALF"":<tab><tab><tab>res[""have_half""] = True<tab>return res",1,"if fl == ""GA_USE_DOUBLE"" :","if fl == ""GA_USE_DOUBLE"" :",0.75,100,1
"def consume_bytes(data):<tab>state_machine.receive_data(data)<tab>while True:<tab><tab>event = state_machine.next_event()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>elif isinstance(event, h11.InformationalResponse):<tab><tab><tab># Ignore 1xx responses<tab><tab><tab>continue<tab><tab>elif isinstance(event, h11.Response):<tab><tab><tab># We have our response! Save it and get out of here.<tab><tab><tab>context[""h11_response""] = event<tab><tab><tab>raise LoopAbort<tab><tab>else:<tab><tab><tab># Can't happen<tab><tab><tab>raise RuntimeError(""Unexpected h11 event {}"".format(event))",0,if event is h11 . NEED_DATA :,if event is None :,0.177865624,19.1992428,0.666666667
"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab>elif self.approved_schedule:<tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab><IF-STMT><tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",0,elif self . has_unpublished_changes :,elif self . approved_schedule :,0.392872021,20.87317633,1
"def _update_input_entries(entries):<tab>for entry in entries:<tab><tab>comma = entry.get(""comma_separated"", False)<tab><tab><IF-STMT><tab><tab><tab>entry[""regex""] = r""([^{}\[\]]*)\{"" + entry[""regex""]<tab><tab>else:<tab><tab><tab>entry[""regex""] = r""([^,{}\[\]]*)\{"" + entry[""regex""]<tab><tab>entry[""type""] = ""input""",1,if comma :,if comma :,0.531170663,1.00E-10,1
"def get_release():<tab>regexp = re.compile(r""^__version__\W*=\W*'([\d.abrc]+)'"")<tab>here = os.path.dirname(__file__)<tab>root = os.path.dirname(here)<tab>init_py = os.path.join(root, ""aiomysql"", ""__init__.py"")<tab>with open(init_py) as f:<tab><tab>for line in f:<tab><tab><tab>match = regexp.match(line)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return match.group(1)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""Cannot find version in aiomysql/__init__.py"")",0,if match is not None :,if match :,0.050438393,1.00E-10,0.4
"def add_to_auto_transitions(cls, base):<tab>result = {}<tab>for name, method in base.__dict__.items():<tab><tab>if callable(method) and hasattr(method, ""_django_fsm""):<tab><tab><tab>for name, transition in method._django_fsm.transitions.items():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>result.update({name: method})<tab>return result",0,"if transition . custom . get ( ""auto"" ) :","if getattr ( transition , ""auto_transition"" , None ) :",0.028970913,9.552040807,0.285714286
"def _paginate(self, get_page, page_size):<tab>for page in itertools.count(start=1):<tab><tab>params = {""page"": page, ""per_page"": page_size}<tab><tab>response, items = get_page(params)<tab><tab>for item in items:<tab><tab><tab>yield item<tab><tab>if self._is_last_page(response):<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break",0,if len ( items ) < page_size :,if self . _is_first_page ( response ) :,0.070373037,4.834632845,0.333333333
"def forward(self, x):<tab>bs = x.size(0)<tab>cur = self.stem(x)<tab>layers = [cur]<tab>for layer_id in range(self.num_layers):<tab><tab>cur = self.layers[layer_id](layers)<tab><tab>layers.append(cur)<tab><tab><IF-STMT><tab><tab><tab>for i, layer in enumerate(layers):<tab><tab><tab><tab>layers[i] = self.pool_layers[self.pool_layers_idx.index(layer_id)](<tab><tab><tab><tab><tab>layer<tab><tab><tab><tab>)<tab><tab><tab>cur = layers[-1]<tab>cur = self.gap(cur).view(bs, -1)<tab>cur = self.dropout(cur)<tab>logits = self.dense(cur)<tab>return logits",0,if layer_id in self . pool_layers_idx :,if self . pool_layers_idx is not None :,0.212090538,50.51968359,0.25
"def evaluate(self, x, y, z):<tab>vertex = Vector((x, y, z))<tab>nearest, normal, idx, distance = self.bvh.find_nearest(vertex)<tab>if self.use_normal:<tab><tab><IF-STMT><tab><tab><tab>sign = (v - nearest).dot(normal)<tab><tab><tab>sign = copysign(1, sign)<tab><tab>else:<tab><tab><tab>sign = 1<tab><tab>return sign * np.array(normal)<tab>else:<tab><tab>dv = np.array(nearest - vertex)<tab><tab>if self.falloff is not None:<tab><tab><tab>norm = np.linalg.norm(dv)<tab><tab><tab>len = self.falloff(norm)<tab><tab><tab>dv = len * dv<tab><tab><tab>return dv<tab><tab>else:<tab><tab><tab>return dv",0,if self . signed_normal :,if distance < 0 :,0.034123066,8.515289178,0.36
"def to_terminal(self):<tab>""""""Yield lines to be printed to a terminal.""""""<tab>for name, mi in self._sort(self.filtered_results):<tab><tab><IF-STMT><tab><tab><tab>yield name, (mi[""error""],), {""error"": True}<tab><tab><tab>continue<tab><tab>rank = mi[""rank""]<tab><tab>color = MI_RANKS[rank]<tab><tab>to_show = """"<tab><tab>if self.config.show:<tab><tab><tab>to_show = "" ({0:.2f})"".format(mi[""mi""])<tab><tab>yield ""{0} - {1}{2}{3}{4}"", (name, color, rank, to_show, RESET), {}",1,"if ""error"" in mi :","if ""error"" in mi :",0.75,100,1
"def _get_widget_by_name(self, container, name):<tab>""""""Recursively search to return the named child widget.""""""<tab>LOGGER.log()<tab>children = container.get_children()<tab>for child in children:<tab><tab>if child.name == name:<tab><tab><tab>return child<tab><tab>if isinstance(child, gtk.Container):<tab><tab><tab>found_child = self._get_widget_by_name(child, name)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return found_child",1,if found_child :,if found_child :,0.531170663,1.00E-10,1
"def PyJsHoisted_hasComputed_(mutatorMap, this, arguments, var=var):<tab>var = Scope(<tab><tab>{u""this"": this, u""arguments"": arguments, u""mutatorMap"": mutatorMap}, var<tab>)<tab>var.registers([u""mutatorMap"", u""key""])<tab>for PyJsTemp in var.get(u""mutatorMap""):<tab><tab>var.put(u""key"", PyJsTemp)<tab><tab><IF-STMT><tab><tab><tab>return var.get(u""true"")<tab>return Js(False)",0,"if var . get ( u""mutatorMap"" ) . get ( var . get ( u""key"" ) ) . get ( u""_computed"" ) :","if var . get ( u""isComputed"" ) :",0.224319576,9.496313599,0.738888889
"def get_result_json_path(self):<tab>if self._result_json_path is None:<tab><tab><IF-STMT><tab><tab><tab>self._result_json_path = get_unique_file(<tab><tab><tab><tab>self.path,<tab><tab><tab><tab>PARALLEL_RESULT_JSON_PREFIX,<tab><tab><tab><tab>PARALLEL_RESULT_JSON_SUFFIX,<tab><tab><tab>)<tab>return self._result_json_path",0,if self . envconfig . config . option . resultjson :,if self . path is not None :,0.094629861,15.18193916,0.272727273
"def timer(ratio, step, additive):<tab>t = 0<tab>slowmode = False<tab>while 1:<tab><tab>if additive:<tab><tab><tab>slowmode |= bool((yield t))<tab><tab>else:<tab><tab><tab>slowmode = bool((yield t))<tab><tab><IF-STMT><tab><tab><tab>t += step * ratio<tab><tab>else:<tab><tab><tab>t += step",1,if slowmode :,if slowmode :,0.531170663,1.00E-10,1
"def _split_long_text(text, idx, size):<tab>splited_text = text.split()<tab>if len(splited_text) > 25:<tab><tab>if idx == 0:<tab><tab><tab># The first is (...)text<tab><tab><tab>first = """"<tab><tab>else:<tab><tab><tab>first = "" "".join(splited_text[:10])<tab><tab><IF-STMT><tab><tab><tab># The last is text(...)<tab><tab><tab>last = """"<tab><tab>else:<tab><tab><tab>last = "" "".join(splited_text[-10:])<tab><tab>return ""{}(...){}"".format(first, last)<tab>return text",0,if idx != 0 and idx == size - 1 :,elif idx == size :,0.190542427,16.73122705,0.166666667
"def test_tag_priority(self):<tab>for tag in _low_priority_D_TAG:<tab><tab>val = ENUM_D_TAG[tag]<tab><tab># if the low priority tag is present in the descriptions,<tab><tab># assert that it has not overridden any other tag<tab><tab><IF-STMT><tab><tab><tab>for tag2 in ENUM_D_TAG:<tab><tab><tab><tab>if tag2 == tag:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>self.assertNotEqual(ENUM_D_TAG[tag2], val)",0,if _DESCR_D_TAG [ val ] == tag :,if tag in _high_priority_D_TAG :,0.019907918,21.34144323,0.4
"def _concretize(self, n_cls, t1, t2, join_or_meet, translate):<tab>ptr_class = self._pointer_class()<tab>if n_cls is ptr_class:<tab><tab><IF-STMT><tab><tab><tab># we need to merge them<tab><tab><tab>return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate))<tab><tab>if isinstance(t1, ptr_class):<tab><tab><tab>return t1<tab><tab>elif isinstance(t2, ptr_class):<tab><tab><tab>return t2<tab><tab>else:<tab><tab><tab># huh?<tab><tab><tab>return ptr_class(BottomType())<tab>return n_cls()",0,"if isinstance ( t1 , ptr_class ) and isinstance ( t2 , ptr_class ) :",if join_or_meet :,0.005493721,1.00E-10,0.297101449
"def parse(self, html: HTML) -> [ProxyIP]:<tab>ip_list: [ProxyIP] = []<tab>for ip_row in html.find(""table.proxytbl tr""):<tab><tab>ip_element = ip_row.find(""td:nth-child(1)"", first=True)<tab><tab>port_element = ip_row.find(""td:nth-child(2)"", first=True)<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>port_str = re.search(r""//]]> (\d+)"", port_element.text).group(1)<tab><tab><tab><tab>p = ProxyIP(ip=ip_element.text, port=port_str)<tab><tab><tab><tab>ip_list.append(p)<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return ip_list",0,if ip_element and port_element :,if ip_element . text and port_element . text :,0.123934195,39.83287155,0.458333333
"def _reformat(self):<tab>document = self.suggestions.document()<tab>cursor = self.suggestions.textCursor()<tab>block = document.begin()<tab>style_format = {<tab><tab>self.STYLE_TRANSLATION: self._translation_char_format,<tab><tab>self.STYLE_STROKES: self._strokes_char_format,<tab>}<tab>while block != document.end():<tab><tab>style = block.userState()<tab><tab>fmt = style_format.get(style)<tab><tab><IF-STMT><tab><tab><tab>cursor.setPosition(block.position())<tab><tab><tab>cursor.select(QTextCursor.BlockUnderCursor)<tab><tab><tab>cursor.setCharFormat(fmt)<tab><tab>block = block.next()",1,if fmt is not None :,if fmt is not None :,0.75,100,1
"def check_uncore_event(e):<tab>if uncore_exists(e.unit):<tab><tab><IF-STMT><tab><tab><tab>warn_once(""Uncore unit "" + e.unit + "" missing cmask for "" + e.name)<tab><tab><tab>return None<tab><tab>if e.umask and not uncore_exists(e.unit, ""/format/umask""):<tab><tab><tab>warn_once(""Uncore unit "" + e.unit + "" missing umask for "" + e.name)<tab><tab><tab>return None<tab><tab>return e<tab>if e.unit not in missing_boxes:<tab><tab>warn_once(""Uncore unit "" + e.unit + "" missing"")<tab><tab>missing_boxes.add(e.unit)<tab>return None",1,"if e . cmask and not uncore_exists ( e . unit , ""/format/cmask"" ) :","if e . cmask and not uncore_exists ( e . unit , ""/format/cmask"" ) :",0.75,100,1
"def check(ip, port, timeout):<tab>try:<tab><tab>socket.setdefaulttimeout(timeout)<tab><tab>s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)<tab><tab>s.connect((ip, int(port)))<tab><tab>flag = ""envi""<tab><tab># envi<tab><tab># dump<tab><tab># reqs<tab><tab># ruok<tab><tab># stat<tab><tab>s.send(flag)<tab><tab>data = s.recv(1024)<tab><tab>s.close()<tab><tab><IF-STMT><tab><tab><tab>return u""Zookeeper Unauthorized access""<tab>except:<tab><tab>pass",0,"if ""Environment"" in data :",if not data :,0.070152444,16.70067963,0.6
"def getid(self):<tab>uid = u""""<tab>try:<tab><tab>filename = (<tab><tab><tab>self.xmlelement.iterancestors(self.namespaced(""file""))<tab><tab><tab>.next()<tab><tab><tab>.get(""original"")<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>uid = filename + ID_SEPARATOR<tab>except StopIteration:<tab><tab># unit has no proper file ancestor, probably newly created<tab><tab>pass<tab># hide the fact that we sanitize ID_SEPERATOR<tab>uid += unicode(self.xmlelement.get(""id"") or u"""").replace(<tab><tab>ID_SEPARATOR_SAFE, ID_SEPARATOR<tab>)<tab>return uid",1,if filename :,if filename :,0.531170663,1.00E-10,1
"def identify(self, vivisect_workspace, function_vas):<tab>candidate_functions = {}<tab>for fva in function_vas:<tab><tab>fname = vivisect_workspace.getName(fva)<tab><tab>default_name = ""sub_%.8x"" % fva<tab><tab><IF-STMT><tab><tab><tab>self.d(""Identified %s at VA 0x%08X "" % (fname, fva))<tab><tab><tab>candidate_functions[fva] = True<tab>return candidate_functions",0,if fname != default_name :,if fname not in candidate_functions :,0.057429006,13.13454947,0.533333333
"def nud(self):<tab>self.first = []<tab>comma = False<tab>if self.token.id != "")"":<tab><tab>while 1:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.first.append(self.expression())<tab><tab><tab>if self.token.id == "","":<tab><tab><tab><tab>comma = True<tab><tab><tab><tab>self.advance("","")<tab><tab><tab>else:<tab><tab><tab><tab>break<tab>self.advance("")"")<tab>if not self.first or comma:<tab><tab>return self  # tuple<tab>else:<tab><tab>return self.first[0]",0,"if self . token . id == "")"" :","if self . token . id == ""("" :",0.627090855,76.91605673,1
"def allow_syncdb(self, db, model):<tab>for router in self.routers:<tab><tab>try:<tab><tab><tab>method = router.allow_syncdb<tab><tab>except AttributeError:<tab><tab><tab># If the router doesn't have a method, skip to the next one.<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>allow = method(db, model)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return allow<tab>return True",0,if allow is not None :,if allow :,0.050438393,1.00E-10,0.4
"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab>elif self.approved_schedule:<tab><tab><tab>return _(""scheduled"")<tab><tab><IF-STMT><tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",0,elif self . workflow_in_progress :,elif self . has_unpublished_changes :,0.392872021,21.10534063,1
"def _on_config_changed(changed_name: str) -> None:<tab>""""""Call config_changed hooks if the config changed.""""""<tab>for mod_info in _module_infos:<tab><tab>if mod_info.skip_hooks:<tab><tab><tab>continue<tab><tab>for option, hook in mod_info.config_changed_hooks:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hook()<tab><tab><tab>else:<tab><tab><tab><tab>cfilter = config.change_filter(option)<tab><tab><tab><tab>cfilter.validate()<tab><tab><tab><tab>if cfilter.check_match(changed_name):<tab><tab><tab><tab><tab>hook()",0,if option is None :,if option == changed_name :,0.064978772,12.22307556,0.5
"def test_slowest_interrupted(self):<tab># Issue #25373: test --slowest with an interrupted test<tab>code = TEST_INTERRUPTED<tab>test = self.create_test(""sigint"", code=code)<tab>for multiprocessing in (False, True):<tab><tab>with self.subTest(multiprocessing=multiprocessing):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>args = (""--slowest"", ""-j2"", test)<tab><tab><tab>else:<tab><tab><tab><tab>args = (""--slowest"", test)<tab><tab><tab>output = self.run_tests(*args, exitcode=130)<tab><tab><tab>self.check_executed_tests(output, test, omitted=test, interrupted=True)<tab><tab><tab>regex = ""10 slowest tests:\n""<tab><tab><tab>self.check_line(output, regex)",1,if multiprocessing :,if multiprocessing :,0.531170663,1.00E-10,1
"def insert_files(self, urls, pos):<tab>""""""Not only images""""""<tab>image_extensions = ["".png"", "".jpg"", "".bmp"", "".gif""]<tab>for url in urls:<tab><tab><IF-STMT><tab><tab><tab>path = url.path()<tab><tab><tab>ext = os.path.splitext(path)[1]<tab><tab><tab>if os.path.exists(path) and ext in image_extensions:<tab><tab><tab><tab>self._insert_image_from_path(path)<tab><tab><tab>else:<tab><tab><tab><tab>self.parent.resource_edit.add_attach(path)",0,"if url . scheme ( ) == ""file"" :","if url . scheme ( ) == ""file"" and url . scheme ( ) == pos :",0.478909771,49.52330116,0.527777778
"def _model_shorthand(self, args):<tab>accum = []<tab>for arg in args:<tab><tab>if isinstance(arg, Node):<tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, Query):<tab><tab><tab>accum.append(arg)<tab><tab><IF-STMT><tab><tab><tab>accum.extend(arg.get_proxy_fields())<tab><tab>elif isclass(arg) and issubclass(arg, Model):<tab><tab><tab>accum.extend(arg._meta.declared_fields)<tab>return accum",0,"elif isinstance ( arg , ModelAlias ) :","elif isinstance ( arg , Proxy ) :",0.547301779,59.46035575,0.666666667
"def get_identifiers(self):<tab>ids = []<tab>ifaces = [i[""name""] for i in self.middleware.call_sync(""interface.query"")]<tab>for entry in glob.glob(f""{self._base_path}/interface-*""):<tab><tab>ident = entry.rsplit(""-"", 1)[-1]<tab><tab>if ident not in ifaces:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>ids.append(ident)<tab>ids.sort(key=RRDBase._sort_disks)<tab>return ids",0,"if os . path . exists ( os . path . join ( entry , ""if_octets.rrd"" ) ) :",if ident not in ids :,0.005188702,0.406790705,0.170909091
"def _validate_required_settings(<tab>self, application_id, application_config, required_settings, should_throw=True):<tab>""""""All required keys must be present""""""<tab>for setting_key in required_settings:<tab><tab><IF-STMT><tab><tab><tab>if should_throw:<tab><tab><tab><tab>raise ImproperlyConfigured(<tab><tab><tab><tab><tab>MISSING_SETTING.format(<tab><tab><tab><tab><tab><tab>application_id=application_id, setting=setting_key<tab><tab><tab><tab><tab>)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab>return True",0,if setting_key not in application_config . keys ( ) :,if setting_key not in application_config :,0.35943904,60.57025367,0.784615385
"def digests():<tab>if not OpenVPN.DIGESTS:<tab><tab>proc = subprocess.Popen(<tab><tab><tab>[""openvpn"", ""--show-digests""],<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.PIPE,<tab><tab>)<tab><tab>stdout, stderr = proc.communicate()<tab><tab><IF-STMT><tab><tab><tab>OpenVPN.DIGESTS = {<tab><tab><tab><tab>v.split("" "")[0].strip(): v.split("" "", 1)[1].strip()<tab><tab><tab><tab>for v in filter(<tab><tab><tab><tab><tab>lambda v: v and v.endswith(""bit digest size""),<tab><tab><tab><tab><tab>stdout.decode(""utf8"").split(""\n""),<tab><tab><tab><tab>)<tab><tab><tab>}<tab>return OpenVPN.DIGESTS",0,if not proc . returncode :,if proc . returncode == 0 :,0.104946328,23.35689889,0.333333333
"def iterate_demo_dirs(dir_name, env_name):<tab>for env_file_name in glob.glob(<tab><tab>os.path.join(dir_name, ""**"", ""env_id.txt""), recursive=True<tab>):<tab><tab>with open(env_file_name, ""r"", encoding=""utf-8"") as fd:<tab><tab><tab>dir_env_name = fd.readline()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab>yield os.path.dirname(env_file_name)",0,if dir_env_name != env_name :,"if dir_env_name == """" :",0.064978772,45.30516302,1
"def validate_rights(namespace):<tab>if ""Manage"" in namespace.rights:<tab><tab><IF-STMT><tab><tab><tab>raise CLIError(<tab><tab><tab><tab>""Error : Assigning 'Manage' to --rights requires 'Listen' and 'Send' to be included with. e.g. --rights Manage Send Listen""<tab><tab><tab>)",0,"if ""Listen"" not in namespace . rights or ""Send"" not in namespace . rights :","if namespace . rights [ ""Manage"" ] not in [ ""Listen"" , ""Send"" ] :",0.048435446,17.55756617,0.238095238
"def apply_patches(ctx, patched=False, pre=False):<tab>if patched:<tab><tab>vendor_dir = _get_patched_dir(ctx)<tab>else:<tab><tab>vendor_dir = _get_vendor_dir(ctx)<tab>log(""Applying pre-patches..."")<tab>patch_dir = Path(__file__).parent / ""patches"" / vendor_dir.name<tab>if pre:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>for patch in patch_dir.glob(""*.patch""):<tab><tab><tab>if not patch.name.startswith(""_post""):<tab><tab><tab><tab>apply_patch(ctx, patch)<tab>else:<tab><tab>patches = patch_dir.glob(""*.patch"" if not patched else ""_post*.patch"")<tab><tab>for patch in patches:<tab><tab><tab>apply_patch(ctx, patch)",0,if not patched :,if patch_dir . exists ( ) :,0.036254648,5.669791111,0.377777778
"def log_sock(s, event_type=None):<tab>if sock_silent:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab>elif event_type in show_event:<tab><tab><tab>logsocket.sendto(ensure_str(s), (host, port))<tab><tab>else:<tab><tab><tab>pass",0,if event_type is None :,if event_type in show_event :,0.314978772,31.55984539,0.36
"def replace_params(<tab>path: str,<tab>param_convertors: typing.Dict[str, Convertor],<tab>path_params: typing.Dict[str, str],) -> typing.Tuple[str, dict]:<tab>for key, value in list(path_params.items()):<tab><tab><IF-STMT><tab><tab><tab>convertor = param_convertors[key]<tab><tab><tab>value = convertor.to_string(value)<tab><tab><tab>path = path.replace(""{"" + key + ""}"", value)<tab><tab><tab>path_params.pop(key)<tab>return path, path_params",0,"if ""{"" + key + ""}"" in path :",if key in param_convertors :,0.017732313,3.941375111,0.781818182
"def data(self, index: QModelIndex, role=Qt.DisplayRole):<tab>if not index.isValid():<tab><tab>return None<tab>if role == Qt.DisplayRole or role == Qt.EditRole:<tab><tab>i = index.row()<tab><tab>j = index.column()<tab><tab>fieldtype = self.field_types[i]<tab><tab>if j == 0:<tab><tab><tab>return fieldtype.caption<tab><tab>elif j == 1:<tab><tab><tab>return fieldtype.function.name<tab><tab><IF-STMT><tab><tab><tab>return ProtocolLabel.DISPLAY_FORMATS[fieldtype.display_format_index]",1,elif j == 2 :,elif j == 2 :,1,100,1
"def delta_page(self, x: float = 0.0, y: float = 0.0) -> None:<tab>if y.is_integer():<tab><tab>y = int(y)<tab><tab>if y == 0:<tab><tab><tab>pass<tab><tab>elif y < 0:<tab><tab><tab>self.page_up(count=-y)<tab><tab><IF-STMT><tab><tab><tab>self.page_down(count=y)<tab><tab>y = 0<tab>if x == 0 and y == 0:<tab><tab>return<tab>size = self._widget.page().mainFrame().geometry()<tab>self.delta(int(x * size.width()), int(y * size.height()))",1,elif y > 0 :,elif y > 0 :,0.75,100,1
"def _process_symbols(self, tokens):<tab>opening_paren = False<tab>for index, token, value in tokens:<tab><tab><IF-STMT><tab><tab><tab>token = self.MAPPINGS.get(value, Name.Function)<tab><tab>elif token == Literal and value in self.BUILTINS_ANYWHERE:<tab><tab><tab>token = Name.Builtin<tab><tab>opening_paren = value == ""("" and token == Punctuation<tab><tab>yield index, token, value",0,"if opening_paren and token in ( Literal , Name . Variable ) :",if token == Name and opening_paren :,0.011944017,12.10647255,0.225
"def ext_service(self, entity_id, typ, service, binding=None):<tab>known_entity = False<tab>for key, _md in self.metadata.items():<tab><tab>srvs = _md.ext_service(entity_id, typ, service, binding)<tab><tab><IF-STMT><tab><tab><tab>return srvs<tab><tab>elif srvs is None:<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>known_entity = True<tab>if known_entity:<tab><tab>raise UnsupportedBinding(binding)<tab>else:<tab><tab>raise UnknownSystemEntity(entity_id)",0,if srvs :,"if isinstance ( srvs , SystemEntity ) :",0.0465226,1.00E-10,0.36
"def find_library_nt(name):<tab># modified from ctypes.util<tab># ctypes.util.find_library just returns first result he found<tab># but we want to try them all<tab># because on Windows, users may have both 32bit and 64bit version installed<tab>results = []<tab>for directory in os.environ[""PATH""].split(os.pathsep):<tab><tab>fname = os.path.join(directory, name)<tab><tab><IF-STMT><tab><tab><tab>results.append(fname)<tab><tab>if fname.lower().endswith("".dll""):<tab><tab><tab>continue<tab><tab>fname = fname + "".dll""<tab><tab>if os.path.isfile(fname):<tab><tab><tab>results.append(fname)<tab>return results",1,if os . path . isfile ( fname ) :,if os . path . isfile ( fname ) :,0.75,100,1
"def getRemovedFiles(oldContents, newContents, destinationFolder):<tab>toRemove = []<tab>for filename in list(oldContents.keys()):<tab><tab>if filename not in newContents:<tab><tab><tab>destFile = os.path.join(destinationFolder, filename.lstrip(""/""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>toRemove.append(filename)<tab>return toRemove",1,if os . path . isfile ( destFile ) :,if os . path . isfile ( destFile ) :,0.75,100,1
"def escapeall(self, lines):<tab>""Escape all lines in an array according to the output options.""<tab>result = []<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>line = self.escape(line, EscapeConfig.html)<tab><tab>if Options.iso885915:<tab><tab><tab>line = self.escape(line, EscapeConfig.iso885915)<tab><tab><tab>line = self.escapeentities(line)<tab><tab>elif not Options.unicode:<tab><tab><tab>line = self.escape(line, EscapeConfig.nonunicode)<tab><tab>result.append(line)<tab>return result",0,if Options . html :,if not Options . html :,0.311097937,53.72849659,0.36
"def body(self):<tab>order = [<tab><tab>""ok_header"",<tab><tab>""affected_rows"",<tab><tab>""last_insert_id"",<tab><tab>""server_status"",<tab><tab>""warning_count"",<tab><tab>""state_track"",<tab><tab>""info"",<tab>]<tab>string = b""""<tab>for key in order:<tab><tab>item = getattr(self, key)<tab><tab>section_pack = b""""<tab><tab>if item is None:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>section_pack = item<tab><tab>else:<tab><tab><tab>section_pack = getattr(self, key).toStringPacket()<tab><tab>string += section_pack<tab>self.setBody(string)<tab>return self._body",0,"elif isinstance ( item , bytes ) :","elif isinstance ( item , int ) :",0.547301779,59.46035575,0.666666667
"def _get_instantiation(self):<tab>if self._data is None:<tab><tab>f, l, c, o = c_object_p(), c_uint(), c_uint(), c_uint()<tab><tab>conf.lib.clang_getInstantiationLocation(<tab><tab><tab>self, byref(f), byref(l), byref(c), byref(o)<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>f = File(f)<tab><tab>else:<tab><tab><tab>f = None<tab><tab>self._data = (f, int(l.value), int(c.value), int(o.value))<tab>return self._data",0,if f :,if f . is_file ( ) :,0.085805078,1.00E-10,1
"def analyze_items(items, category_id, agg_data):<tab>for item in items:<tab><tab><IF-STMT><tab><tab><tab>agg_data[""cat_asp""][category_id] = []<tab><tab>agg_data[""cat_asp""][category_id].append(<tab><tab><tab>float(item.sellingStatus.currentPrice.value)<tab><tab>)<tab><tab>if getattr(item.listingInfo, ""watchCount"", None):<tab><tab><tab>agg_data[""watch_count""] += int(item.listingInfo.watchCount)<tab><tab>if getattr(item, ""postalCode"", None):<tab><tab><tab>agg_data[""postal_code""] = item.postalCode",0,"if not agg_data [ ""cat_asp"" ] . get ( category_id , None ) :","if category_id not in agg_data [ ""cat_asp"" ] :",0.105845207,49.4632426,0.492063492
"def mock_default_data_dir(tmp_path: pathlib.Path):<tab>""""""Changes the default `--data_dir` to tmp_path.""""""<tab>tmp_path = tmp_path / ""datasets""<tab>default_data_dir = os.environ.get(""TFDS_DATA_DIR"")<tab>try:<tab><tab>os.environ[""TFDS_DATA_DIR""] = os.fspath(tmp_path)<tab><tab>yield tmp_path<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.environ[""TFDS_DATA_DIR""] = default_data_dir<tab><tab>else:<tab><tab><tab>del os.environ[""TFDS_DATA_DIR""]",1,if default_data_dir :,if default_data_dir :,0.531170663,1.00E-10,1
"def has_valid_checksum(self, number):<tab>given_number, given_checksum = number[:-1], number[-1]<tab>calculated_checksum = 0<tab>parameter = 7<tab>for item in given_number:<tab><tab>fragment = str(int(item) * parameter)<tab><tab><IF-STMT><tab><tab><tab>calculated_checksum += int(fragment[-1])<tab><tab>if parameter == 1:<tab><tab><tab>parameter = 7<tab><tab>elif parameter == 3:<tab><tab><tab>parameter = 1<tab><tab>elif parameter == 7:<tab><tab><tab>parameter = 3<tab>return str(calculated_checksum)[-1] == given_checksum",0,if fragment . isalnum ( ) :,if fragment [ - 1 ] != 0 :,0.035364494,9.287529,0.484848485
"def _cleanup_volumes(self, context, instance_id):<tab>bdms = self.db.block_device_mapping_get_all_by_instance(context, instance_id)<tab>for bdm in bdms:<tab><tab>LOG.debug(_(""terminating bdm %s"") % bdm)<tab><tab><IF-STMT><tab><tab><tab>volume = self.volume_api.get(context, bdm[""volume_id""])<tab><tab><tab>self.volume_api.delete(context, volume)",0,"if bdm [ ""volume_id"" ] and bdm [ ""delete_on_termination"" ] :","if ""volume_id"" in bdm :",0.013055717,13.23184946,0.386666667
"def _split_zipped_payload(self, packet_bunch):<tab>""""""Split compressed payload""""""<tab>while packet_bunch:<tab><tab><IF-STMT><tab><tab><tab>payload_length = struct.unpack_from(""<I"", packet_bunch[0:3] + b""\x00"")[<tab><tab><tab><tab>0<tab><tab><tab>]  # pylint: disable=E0602<tab><tab>else:<tab><tab><tab>payload_length = struct.unpack(""<I"", packet_bunch[0:3] + b""\x00"")[0]<tab><tab>self._packet_queue.append(packet_bunch[0 : payload_length + 4])<tab><tab>packet_bunch = packet_bunch[payload_length + 4 :]",0,if PY2 :,"if packet_bunch [ 0 ] == b""\x00"" :",0.169228356,1.00E-10,0.5
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_application_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_message(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 26:<tab><tab><tab>self.set_tag(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def update_transitive(self, conanfile):<tab>transitive = getattr(conanfile, ""python_requires"", None)<tab>if not transitive:<tab><tab>return<tab>for name, transitive_py_require in transitive.all_items():<tab><tab>existing = self._pyrequires.get(name)<tab><tab><IF-STMT><tab><tab><tab>raise ConanException(<tab><tab><tab><tab>""Conflict in py_requires %s - %s""<tab><tab><tab><tab>% (existing.ref, transitive_py_require.ref)<tab><tab><tab>)<tab><tab>self._transitive[name] = transitive_py_require",1,if existing and existing . ref != transitive_py_require . ref :,if existing and existing . ref != transitive_py_require . ref :,1,100,1
"def call(cls, func, *args):<tab>try:<tab><tab>f = cls._func_cache[func]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>f = cls._func_cache[func] = getattr(vim.funcs, func)<tab><tab>else:<tab><tab><tab>f = cls._func_cache[func] = vim.Function(func)<tab>return f(*args)",0,if IS_NVIM :,if func in vim . funcs :,0.045790811,1.00E-10,0.25
"def __call__(self, *args, **kwargs):<tab>if self is S:<tab><tab>if args:<tab><tab><tab>raise TypeError(""S() takes no positional arguments, got: %r"" % (args,))<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""S() expected at least one kwarg, got none"")<tab><tab># TODO: typecheck kwarg vals?<tab>return _t_child(self, ""("", (args, kwargs))",0,if not kwargs :,if kwargs :,0.096488528,1.00E-10,0.416666667
"def tiles_around_factor(self, factor, pos, radius=1, predicate=None):<tab>ps = []<tab>x, y = pos<tab>for dx in range(-radius, radius + 1):<tab><tab>nx = x + dx<tab><tab>if nx >= 0 and nx < self.width * factor:<tab><tab><tab>for dy in range(-radius, radius + 1):<tab><tab><tab><tab>ny = y + dy<tab><tab><tab><tab>if ny >= 0 and ny < self.height * factor and (dx != 0 or dy != 0):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>ps.append((nx, ny))<tab>return ps",0,"if predicate is None or predicate ( ( nx , ny ) ) :","if predicate is not None and predicate ( dx , dy ) :",0.243836812,16.66408751,0.284090909
"def _plugin_get_requirements(self, requirements_iter):<tab>plugin_requirements = {""platform"": [], ""python"": [], ""network"": [], ""native"": []}<tab># parse requirements<tab>for requirement in requirements_iter:<tab><tab>key = requirement[0]<tab><tab>values = requirement[1]<tab><tab><IF-STMT><tab><tab><tab>values = [values]<tab><tab>if key in plugin_requirements:<tab><tab><tab>plugin_requirements[key].extend(values)<tab><tab>else:<tab><tab><tab>warning(""{}={}: No supported requirement"".format(key, values))<tab>return plugin_requirements",0,"if isinstance ( values , str ) or isinstance ( values , bool ) :","if not isinstance ( values , list ) :",0.15099781,18.9396481,0.202614379
"def test_engine_api_sdl(sdl, expected, pass_to, clean_registry):<tab>from tartiflette import Engine<tab>if pass_to == ""engine"":<tab><tab>e = Engine(sdl)<tab>else:<tab><tab>e = Engine()<tab>if isinstance(expected, Exception):<tab><tab>with pytest.raises(Exception):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>await e.cook(sdl)<tab><tab><tab>else:<tab><tab><tab><tab>await e.cook()<tab>else:<tab><tab>if pass_to == ""cook"":<tab><tab><tab>await e.cook(sdl)<tab><tab>else:<tab><tab><tab>await e.cook()<tab><tab>assert e._schema is not None",0,"if pass_to == ""cook"" :",if clean_registry :,0.03549272,1.00E-10,1
"def update(self, other_dict, option_parser):<tab>if isinstance(other_dict, Values):<tab><tab>other_dict = other_dict.__dict__<tab>other_dict = other_dict.copy()<tab>for setting in option_parser.lists.keys():<tab><tab>if hasattr(self, setting) and setting in other_dict:<tab><tab><tab>value = getattr(self, setting)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value += other_dict[setting]<tab><tab><tab><tab>del other_dict[setting]<tab>self._update_loose(other_dict)",0,if value :,if value is not None :,0.090364769,1.00E-10,0.4
"def _cast_Time(iso, curs):<tab>if iso:<tab><tab><IF-STMT><tab><tab><tab>return iso<tab><tab>else:<tab><tab><tab>return DateTime(<tab><tab><tab><tab>time.strftime(<tab><tab><tab><tab><tab>""%Y-%m-%d %H:%M:%S"",<tab><tab><tab><tab><tab>time.localtime(time.time())[:3]<tab><tab><tab><tab><tab>+ time.strptime(iso[:8], ""%H:%M:%S"")[3:],<tab><tab><tab><tab>)<tab><tab><tab>)",0,"if iso in [ ""-infinity"" , ""infinity"" ] :",if curs :,0.013130314,1.00E-10,0.384615385
"def _get_default_urlpatterns(self):<tab>package_string = ""."".join(self.__module__.split(""."")[:-1])<tab>if getattr(self, ""urls"", None):<tab><tab>try:<tab><tab><tab>mod = import_module("".%s"" % self.urls, package_string)<tab><tab>except ImportError:<tab><tab><tab>mod = import_module(self.urls)<tab><tab>urlpatterns = mod.urlpatterns<tab>else:<tab><tab># Try importing a urls.py from the dashboard package<tab><tab><IF-STMT><tab><tab><tab>urls_mod = import_module("".urls"", package_string)<tab><tab><tab>urlpatterns = urls_mod.urlpatterns<tab><tab>else:<tab><tab><tab>urlpatterns = patterns("""")<tab>return urlpatterns",0,"if module_has_submodule ( import_module ( package_string ) , ""urls"" ) :","if hasattr ( self , ""urls"" ) :",0.133992747,18.49178116,0.472222222
"def escape2null(text):<tab>""""""Return a string with escape-backslashes converted to nulls.""""""<tab>parts = []<tab>start = 0<tab>while 1:<tab><tab>found = text.find(""\\"", start)<tab><tab><IF-STMT><tab><tab><tab>parts.append(text[start:])<tab><tab><tab>return """".join(parts)<tab><tab>parts.append(text[start:found])<tab><tab>parts.append(""\x00"" + text[found + 1 : found + 2])<tab><tab>start = found + 2  # skip character after escape",1,if found == - 1 :,if found == - 1 :,0.75,100,1
"def check(self, obj):<tab>if ""*"" in self.states:<tab><tab>return {""state"": self.dispatcher.current_state()}<tab>try:<tab><tab>state = self.ctx_state.get()<tab>except LookupError:<tab><tab>chat, user = self.get_target(obj)<tab><tab>if chat or user:<tab><tab><tab>state = await self.dispatcher.storage.get_state(chat=chat, user=user)<tab><tab><tab>self.ctx_state.set(state)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return {""state"": self.dispatcher.current_state(), ""raw_state"": state}<tab>else:<tab><tab>if state in self.states:<tab><tab><tab>return {""state"": self.dispatcher.current_state(), ""raw_state"": state}<tab>return False",1,if state in self . states :,if state in self . states :,0.75,100,1
"def get_tokens_unprocessed(self, text):<tab>from pygments.lexers._asy_builtins import ASYFUNCNAME, ASYVARNAME<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name and value in ASYFUNCNAME:<tab><tab><tab>token = Name.Function<tab><tab><IF-STMT><tab><tab><tab>token = Name.Variable<tab><tab>yield index, token, value",1,elif token is Name and value in ASYVARNAME :,elif token is Name and value in ASYVARNAME :,0.75,100,1
"def write_family_handle(self, family, index=1):<tab>sp = ""  "" * index<tab>self.write_primary_tag(""family"", family, index)<tab>if family:<tab><tab>rel = escxml(family.get_relationship().xml_str())<tab><tab><IF-STMT><tab><tab><tab>self.g.write('  %s<rel type=""%s""/>\n' % (sp, rel))",0,"if rel != """" :",if rel :,0.067674239,1.00E-10,1
"def pop1_bytes(self) -> bytes:<tab>#<tab># Note: This function is optimized for speed over readability.<tab># Knowing the popped type means that we can pop *very* quickly<tab># when the popped type matches the pushed type.<tab>#<tab>if not self.values:<tab><tab>raise InsufficientStack(""Wanted 1 stack item as bytes, had none"")<tab>else:<tab><tab>item_type, popped = self._pop_typed()<tab><tab>if item_type is int:<tab><tab><tab>return int_to_big_endian(popped)  # type: ignore<tab><tab><IF-STMT><tab><tab><tab>return popped  # type: ignore<tab><tab>else:<tab><tab><tab>raise _busted_type(item_type, popped)",1,elif item_type is bytes :,elif item_type is bytes :,0.75,100,1
"def setDefaultComponents(self):<tab>if self._componentTypeLen == self._componentValuesSet:<tab><tab>return<tab>idx = self._componentTypeLen<tab>while idx:<tab><tab>idx = idx - 1<tab><tab><IF-STMT><tab><tab><tab>if self.getComponentByPosition(idx) is None:<tab><tab><tab><tab>self.setComponentByPosition(idx)<tab><tab>elif not self._componentType[idx].isOptional:<tab><tab><tab>if self.getComponentByPosition(idx) is None:<tab><tab><tab><tab>raise error.PyAsn1Error(<tab><tab><tab><tab><tab>""Uninitialized component #%s at %r"" % (idx, self)<tab><tab><tab><tab>)",0,if self . _componentType [ idx ] . isDefaulted :,if self . _componentType [ idx ] . isOptional :,0.642805659,80.70557275,0.666666667
"def _cloneComponentValues(self, myClone, cloneValueFlag):<tab>idx = 0<tab>l = len(self._componentValues)<tab>while idx < l:<tab><tab>c = self._componentValues[idx]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(c, base.AbstractConstructedAsn1Item):<tab><tab><tab><tab>myClone.setComponentByPosition(<tab><tab><tab><tab><tab>idx, c.clone(cloneValueFlag=cloneValueFlag)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>myClone.setComponentByPosition(idx, c.clone())<tab><tab>idx = idx + 1",0,if c is not None :,"if isinstance ( c , BaseConstructedAsnItem ) :",0.023749772,7.267884212,0.232142857
"def endElement(self, tag):<tab>""""""Handle the end of an element.""""""<tab>if tag == ""author"":<tab><tab>developer = self.text.strip()<tab><tab><IF-STMT><tab><tab><tab>self.author_list.append(developer)<tab><tab>elif self.title == ""contributor"" and developer not in self.contributor_list:<tab><tab><tab>self.contributor_list.append(developer)",1,"if self . title == ""author"" and developer not in self . author_list :","if self . title == ""author"" and developer not in self . author_list :",1,100,1
"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)):<tab><tab>return True<tab>if isinstance(value, (tuple, list, set, frozenset)):<tab><tab>for item in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>elif isinstance(value, dict):<tab><tab>for key, value in value.iteritems():<tab><tab><tab>if not has_safe_repr(key):<tab><tab><tab><tab>return False<tab><tab><tab>if not has_safe_repr(value):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",1,if not has_safe_repr ( item ) :,if not has_safe_repr ( item ) :,0.75,100,1
"def test_all_wizards(self):<tab>mod = ""w3af.core.controllers.wizard.wizards.%s""<tab>w3af_core = w3afCore()<tab>for filename in os.listdir(""w3af/core/controllers/wizard/wizards/""):<tab><tab>wizard_id, ext = os.path.splitext(filename)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>klass = mod % wizard_id<tab><tab>wizard_inst = factory(klass, w3af_core)<tab><tab>yield self._test_wizard_correct, wizard_inst<tab><tab>wizard_inst = factory(klass, w3af_core)<tab><tab>yield self._test_wizard_fail, wizard_inst",0,"if wizard_id in ( ""__init__"" , "".git"" ) or ext == "".pyc"" :","if ext != "".py"" :",0.009477309,2.93973357,0.38
"def test_bool_performance(self):<tab>class Person(Document):<tab><tab>name = StringField()<tab>Person.drop_collection()<tab>for i in range(100):<tab><tab>Person(name=""No: %s"" % i).save()<tab>with query_counter() as q:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>assert q == 1<tab><tab>op = q.db.system.profile.find({""ns"": {""$ne"": ""%s.system.indexes"" % q.db.name}})[<tab><tab><tab>0<tab><tab>]<tab><tab>assert op[""nreturned""] == 1",0,if Person . objects :,if i == 0 :,0.034123066,9.652434877,0.333333333
"def validate(self) -> None:<tab>if self.query:<tab><tab><IF-STMT><tab><tab><tab>for arg_name in (""aur"", ""repo""):<tab><tab><tab><tab>if getattr(self, arg_name):<tab><tab><tab><tab><tab>raise MissingArgument(""sysupgrade"", arg_name)",0,if not self . sysupgrade :,"if self . query . get ( ""sysupgrade"" ) :",0.040133529,8.516593019,0.285714286
"def __new__(cls, name, parents, dct):<tab>command_handlers = {}<tab>for attr_name, attr in dct.items():<tab><tab><IF-STMT><tab><tab><tab>handles_what = attr_name[len(""handle_"") :]<tab><tab><tab>if handles_what:<tab><tab><tab><tab>command_handlers[handles_what] = attr<tab>dct[""command_handlers""] = command_handlers<tab>return super(CommandHandlerMeta, cls).__new__(cls, name, parents, dct)",0,"if callable ( attr ) and attr_name . startswith ( ""handle_"" ) :","if attr_name . startswith ( ""handle_"" ) :",0.242171969,63.34742655,0.307017544
"def pop_error_text(self, error_text):<tab>if error_text in self.__errors:<tab><tab>self.__errors.remove(error_text)<tab><tab><IF-STMT><tab><tab><tab>self.set_message_text(WELCOME_MESSAGE)<tab><tab>else:<tab><tab><tab>self.set_message_text(next(self.__errors.__iter__()))",1,if len ( self . __errors ) == 0 :,if len ( self . __errors ) == 0 :,0.75,100,1
"def run(self, edit):<tab>self.clear_phantoms()<tab>regions = self.view.sel()<tab>for region in regions:<tab><tab>region, _ = self.get_selection_from_region(<tab><tab><tab>region=region, regions_length=len(region), view=self.view<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>self.json_loads(self.view.substr(region), self.duplicate_key_hook)<tab><tab>except Exception as ex:<tab><tab><tab>self.show_exception(region=region, msg=ex)<tab><tab><tab>return<tab><tab>sublime.status_message(""JSON Valid"")",1,if region is None :,if region is None :,0.75,100,1
"def update_leaderboard(wait_time):<tab>conn = get_connection()<tab>cursor = conn.cursor(MySQLdb.cursors.DictCursor)<tab>while True:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log.info(""Updating leaderboard and adding some sigma"")<tab><tab><tab>cursor.execute(""call generate_leaderboard;"")<tab><tab><tab>if wait_time == 0:<tab><tab><tab><tab>break<tab><tab><tab>for s in range(wait_time):<tab><tab><tab><tab># allow for a [Ctrl]+C during the sleep cycle<tab><tab><tab><tab>time.sleep(1)<tab><tab>except KeyboardInterrupt:<tab><tab><tab>break<tab><tab>except:<tab><tab><tab># log error<tab><tab><tab>log.error(traceback.format_exc())<tab><tab><tab>break<tab>cursor.close()<tab>conn.close()",0,if use_log :,if wait_time > 0 :,0.051944023,1.00E-10,0.619047619
"def _external_tables(self):<tab>tables = []<tab>for name, df in self.extra_options.get(""external_tables"", {}).items():<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""External table is not an instance of pandas "" ""dataframe"")<tab><tab>schema = sch.infer(df)<tab><tab>chtypes = map(ClickhouseDataType.from_ibis, schema.types)<tab><tab>structure = list(zip(schema.names, map(str, chtypes)))<tab><tab>tables.append(dict(name=name, data=df.to_dict(""records""), structure=structure))<tab>return tables",1,"if not isinstance ( df , pd . DataFrame ) :","if not isinstance ( df , pd . DataFrame ) :",0.75,100,1
"def getmod(self, nm):<tab>mod = None<tab>for thing in self.path:<tab><tab><IF-STMT><tab><tab><tab>owner = self.shadowpath.get(thing, -1)<tab><tab><tab>if owner == -1:<tab><tab><tab><tab>owner = self.shadowpath[thing] = self.__makeOwner(thing)<tab><tab><tab>if owner:<tab><tab><tab><tab>mod = owner.getmod(nm)<tab><tab>else:<tab><tab><tab>mod = thing.getmod(nm)<tab><tab>if mod:<tab><tab><tab>break<tab>return mod",0,"if isinstance ( thing , basestring ) :",if thing not in self . shadowpath :,0.019345088,7.267884212,0.185185185
"def add_variant_attribute_data_to_expected_data(data, variant, attribute_ids, pk=None):<tab>for assigned_attribute in variant.attributes.all():<tab><tab>header = f""{assigned_attribute.attribute.slug} (variant attribute)""<tab><tab>if str(assigned_attribute.attribute.pk) in attribute_ids:<tab><tab><tab>value = get_attribute_value(assigned_attribute)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[pk][header] = value<tab><tab><tab>else:<tab><tab><tab><tab>data[header] = value<tab>return data",1,if pk :,if pk :,0.531170663,1.00E-10,1
"def get_files(start_dir, includes, excludes):<tab># use os.walk to recursively dig down into the Pupil directory<tab>match_files = []<tab>for root, dirs, files in os.walk(start_dir):<tab><tab>if not re.search(excludes, root):<tab><tab><tab>files = [<tab><tab><tab><tab>f<tab><tab><tab><tab>for f in files<tab><tab><tab><tab><IF-STMT><tab><tab><tab>]<tab><tab><tab>files = [os.path.join(root, f) for f in files]<tab><tab><tab>match_files += files<tab><tab>else:<tab><tab><tab>print(""Excluding '%s'"" % root)<tab>return match_files",0,"if re . search ( includes , f ) and not re . search ( excludes , f )","if not re . search ( excludes , f )",0.20486669,36.73771591,0.195767196
"def findinDoc(self, tagpath, pos, end):<tab>result = None<tab>if end == -1:<tab><tab>end = self.docSize<tab>else:<tab><tab>end = min(self.docSize, end)<tab>foundat = -1<tab>for j in range(pos, end):<tab><tab>item = self.docList[j]<tab><tab><IF-STMT><tab><tab><tab>(name, argres) = item.split(b""="", 1)<tab><tab>else:<tab><tab><tab>name = item<tab><tab><tab>argres = """"<tab><tab>if isinstance(tagpath, str):<tab><tab><tab>tagpath = tagpath.encode(""utf-8"")<tab><tab>if name.endswith(tagpath):<tab><tab><tab>result = argres<tab><tab><tab>foundat = j<tab><tab><tab>break<tab>return foundat, result",0,"if item . find ( b""="" ) >= 0 :","if item . endswith ( b""="" ) :",0.218763653,45.93799961,0.487179487
"def load_classes(module, base, blacklist):<tab>classes = []<tab>for attr in dir(module):<tab><tab>attr = getattr(module, attr)<tab><tab>if inspect.isclass(attr):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if attr is not base and attr not in blacklist:<tab><tab><tab><tab><tab>classes.append(attr)<tab>return classes",0,"if issubclass ( attr , base ) :",if not attr . startswith ( base ) :,0.077246129,21.10534063,0.412698413
"def run():<tab>try:<tab><tab>result = func()<tab>except Exception:<tab><tab>future_cell[0] = TracebackFuture()<tab><tab>future_cell[0].set_exc_info(sys.exc_info())<tab>else:<tab><tab><IF-STMT><tab><tab><tab>future_cell[0] = result<tab><tab>else:<tab><tab><tab>future_cell[0] = TracebackFuture()<tab><tab><tab>future_cell[0].set_result(result)<tab>self.add_future(future_cell[0], lambda future: self.stop())",0,if is_future ( result ) :,"if isinstance ( result , Exception ) :",0.054860857,16.51582159,0.36
def lastCard(self):<tab>if self._answeredIds:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>return self.mw.col.getCard(self._answeredIds[-1])<tab><tab><tab>except TypeError:<tab><tab><tab><tab># id was deleted<tab><tab><tab><tab>return,0,if not self . card or self . _answeredIds [ - 1 ] != self . card . id :,if len ( self . _answeredIds ) > 1 :,0.02680686,9.927423413,0.252136752
"def run(self):<tab>global _cameras<tab>while 1:<tab><tab>for cam in _cameras:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cam.pygame_buffer = cam.capture.get_image(cam.pygame_buffer)<tab><tab><tab>else:<tab><tab><tab><tab>cv.GrabFrame(cam.capture)<tab><tab><tab>cam._threadcapturetime = time.time()<tab><tab>time.sleep(0.04)  # max 25 fps, if you're lucky",0,if cam . pygame_camera :,if cam . pygame_buffer :,0.394778655,64.34588842,1
"def handle_exception(self, e, result):<tab>for k in sorted(result.thrift_spec):<tab><tab>if result.thrift_spec[k][1] == ""success"":<tab><tab><tab>continue<tab><tab>_, exc_name, exc_cls, _ = result.thrift_spec[k]<tab><tab><IF-STMT><tab><tab><tab>setattr(result, exc_name, e)<tab><tab><tab>return True<tab>return False",0,"if isinstance ( e , exc_cls ) :",if exc_cls is not None :,0.019830745,18.19037114,0.26984127
"def for_module(cls, modname: str) -> ""ModuleAnalyzer"":<tab>if (""module"", modname) in cls.cache:<tab><tab>entry = cls.cache[""module"", modname]<tab><tab>if isinstance(entry, PycodeError):<tab><tab><tab>raise entry<tab><tab>return entry<tab>try:<tab><tab>filename, source = cls.get_module_source(modname)<tab><tab><IF-STMT><tab><tab><tab>obj = cls.for_string(source, modname, filename or ""<string>"")<tab><tab>elif filename is not None:<tab><tab><tab>obj = cls.for_file(filename, modname)<tab>except PycodeError as err:<tab><tab>cls.cache[""module"", modname] = err<tab><tab>raise<tab>cls.cache[""module"", modname] = obj<tab>return obj",1,if source is not None :,if source is not None :,0.75,100,1
"def visit_productionlist(self, node):<tab>self.new_state()<tab>names = []<tab>for production in node:<tab><tab>names.append(production[""tokenname""])<tab>maxlen = max(len(name) for name in names)<tab>for production in node:<tab><tab><IF-STMT><tab><tab><tab>self.add_text(production[""tokenname""].ljust(maxlen) + "" ::="")<tab><tab><tab>lastname = production[""tokenname""]<tab><tab>else:<tab><tab><tab>self.add_text(""%s<tab>"" % ("" "" * len(lastname)))<tab><tab>self.add_text(production.astext() + ""\n"")<tab>self.end_state(wrap=False)<tab>raise nodes.SkipNode",1,"if production [ ""tokenname"" ] :","if production [ ""tokenname"" ] :",0.75,100,1
"def transport_vmware_guestinfo():<tab>rpctool = ""vmware-rpctool""<tab>not_found = None<tab>if not subp.which(rpctool):<tab><tab>return not_found<tab>cmd = [rpctool, ""info-get guestinfo.ovfEnv""]<tab>try:<tab><tab>out, _err = subp.subp(cmd)<tab><tab><IF-STMT><tab><tab><tab>return out<tab><tab>LOG.debug(""cmd %s exited 0 with empty stdout: %s"", cmd, out)<tab>except subp.ProcessExecutionError as e:<tab><tab>if e.exit_code != 1:<tab><tab><tab>LOG.warning(""%s exited with code %d"", rpctool, e.exit_code)<tab><tab><tab>LOG.debug(e)<tab>return not_found",0,if out :,if _err == 0 :,0.051944023,1.00E-10,0.5
"def MakeWidthArray(fm):<tab># Make character width array<tab>s = ""{\n\t""<tab>cw = fm[""Widths""]<tab>for i in xrange(0, 256):<tab><tab>if chr(i) == ""'"":<tab><tab><tab>s += ""'\\''""<tab><tab>elif chr(i) == ""\\"":<tab><tab><tab>s += ""'\\\\'""<tab><tab>elif i >= 32 and i <= 126:<tab><tab><tab>s += ""'"" + chr(i) + ""'""<tab><tab>else:<tab><tab><tab>s += ""chr(%d)"" % i<tab><tab>s += "":"" + fm[""Widths""][i]<tab><tab>if i < 255:<tab><tab><tab>s += "",""<tab><tab><IF-STMT><tab><tab><tab>s += ""\n\t""<tab>s += ""}""<tab>return s",0,if ( i + 1 ) % 22 == 0 :,elif i < cw :,0.009997257,3.132599824,0.232142857
"def lookup_config_file(filename: str) -> Optional[str]:<tab>""""""Return config file PATH.""""""<tab>for path in [find_vcs_root(default=""~""), ""~""]:<tab><tab>f = os.path.expanduser(""%s/%s"" % (path, filename))<tab><tab><IF-STMT><tab><tab><tab>LOG.info(""Found config file %s"", f)<tab><tab><tab>return f<tab>return None",1,if os . path . isfile ( f ) :,if os . path . isfile ( f ) :,0.75,100,1
"def load_freq_dict(self, freq_dict_filename: str):<tab>with open(str(expand_path(freq_dict_filename)), ""r"") as fl:<tab><tab>lines = fl.readlines()<tab>pos_freq_dict = defaultdict(list)<tab>for line in lines:<tab><tab>line_split = line.strip(""\n"").split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>pos_freq_dict[line_split[1]].append((line_split[0], float(line_split[2])))<tab>nouns_with_freq = pos_freq_dict[""s""]<tab>self.nouns_dict = {noun: freq for noun, freq in nouns_with_freq}",0,"if re . match ( ""[\d]+\.[\d]+"" , line_split [ 2 ] ) :",if len ( line_split ) > 1 :,0.011849399,3.191073508,0.278195489
"def do_visual_mode(self):<tab>""""""Handle strokes in visual mode.""""""<tab>try:<tab><tab>self.n1 = self.n = 1<tab><tab>self.do_state(<tab><tab><tab>self.vis_dispatch_d,<tab><tab><tab>mode_name=""visual-line"" if self.visual_line_flag else ""visual"",<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.visual_line_helper()<tab>except Exception:<tab><tab>g.es_exception()<tab><tab>self.quit()",0,if self . visual_line_flag :,if self . visual_line_helper :,0.394778655,75.06238538,1
"def cleanup(self):<tab>log.info("""")<tab>log.info(""Cleaning up.. "")<tab>status = self._capture_output(""status"", ""--porcelain"")<tab>status = status.split(""\n"")<tab>for line in status:<tab><tab>filepath = line.split()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>filepath = filepath[-1]<tab><tab>if filepath[-3:] != ""rej"" and filepath[-5:] != ""porig"":<tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>log.info(""Removing temp file %s "" % filepath)<tab><tab><tab>os.remove(os.path.join(self.base_dir, filepath))<tab><tab>except:<tab><tab><tab>log.warn(""File removal failed, you should manually remove %s"" % filepath)<tab><tab><tab>pass",0,if len ( filepath ) == 0 :,if len ( filepath ) < 2 :,0.524151519,47.75034265,0.666666667
"def OnBodyRClick(self, event=None):<tab>try:<tab><tab>c = self.c<tab><tab>p = c.currentPosition()<tab><tab><IF-STMT><tab><tab><tab>c.k.showStateAndMode(w=c.frame.body.bodyCtrl)<tab><tab>g.doHook(""bodyrclick2"", c=c, p=p, v=p, event=event)<tab>except:<tab><tab>g.es_event_exception(""iconrclick"")",0,"if not g . doHook ( ""bodyrclick1"" , c = c , p = p , v = p , event = event ) :","if g . doHook ( ""bodyrclick1"" , c = c , p = p , v = p , event = event ) :",0.824124731,93.20024073,0.366255144
"def receiver():<tab>""""""receive messages with polling""""""<tab>pull = ctx.socket(zmq.PULL)<tab>pull.connect(url)<tab>poller = Poller()<tab>poller.register(pull, zmq.POLLIN)<tab>while True:<tab><tab>events = await poller.poll()<tab><tab><IF-STMT><tab><tab><tab>print(""recving"", events)<tab><tab><tab>msg = await pull.recv_multipart()<tab><tab><tab>print(""recvd"", msg)",0,if pull in dict ( events ) :,if events :,0.01726708,1.00E-10,0.277777778
"def sched(self):<tab>for k, q in self.q.items():<tab><tab><IF-STMT><tab><tab><tab>ent = q.popleft()<tab><tab><tab>self.cur[k] = ent<tab><tab><tab>self.run_one(ent, k)",0,if q and k not in self . cur :,if len ( q ) > 0 :,0.015007329,5.660233916,0.136363636
"def eval_dummy_genomes_iznn(genomes, config):<tab>for genome_id, genome in genomes:<tab><tab>net = neat.iznn.IZNN.create(genome, config)<tab><tab><IF-STMT><tab><tab><tab>net.reset()<tab><tab><tab>genome.fitness = 0.0<tab><tab>elif genome_id <= 150:<tab><tab><tab>genome.fitness = 0.5<tab><tab>else:<tab><tab><tab>genome.fitness = 1.0",0,if genome_id < 10 :,if genome_id == 0 :,0.314978772,36.55552229,0.5
"def handle_noargs(self, **options):<tab># Inspired by Postfix's ""postconf -n"".<tab>from django.conf import settings, global_settings<tab># Because settings are imported lazily, we need to explicitly load them.<tab>settings._setup()<tab>user_settings = module_to_dict(settings._wrapped)<tab>default_settings = module_to_dict(global_settings)<tab>output = []<tab>for key in sorted(user_settings.keys()):<tab><tab>if key not in default_settings:<tab><tab><tab>output.append(""%s = %s  ###"" % (key, user_settings[key]))<tab><tab><IF-STMT><tab><tab><tab>output.append(""%s = %s"" % (key, user_settings[key]))<tab>return ""\n"".join(output)",0,elif user_settings [ key ] != default_settings [ key ] :,"elif not key . startswith ( ""_"" ) :",0.012519891,3.364202477,0.52
def test_get_chat_thread(self):<tab>async with self.chat_client:<tab><tab>await self._create_thread()<tab><tab>get_thread_result = await self.chat_client.get_chat_thread(self.thread_id)<tab><tab>assert get_thread_result.id == self.thread_id<tab><tab># delete created users and chat threads<tab><tab><IF-STMT><tab><tab><tab>await self.chat_client.delete_chat_thread(self.thread_id),1,if not self . is_playback ( ) :,if not self . is_playback ( ) :,0.75,100,1
"def consume(self):<tab>if not self.inputState.guessing:<tab><tab>c = self.LA(1)<tab><tab><IF-STMT><tab><tab><tab>self.append(c)<tab><tab>else:<tab><tab><tab># use input.LA(), not LA(), to get original case<tab><tab><tab># CharScanner.LA() would toLower it.<tab><tab><tab>c = self.inputState.input.LA(1)<tab><tab><tab>self.append(c)<tab><tab>if c and c in ""\t"":<tab><tab><tab>self.tab()<tab><tab>else:<tab><tab><tab>self.inputState.column += 1<tab>self.inputState.input.consume()",0,if self . caseSensitive :,"if c in ""\n"" :",0.034123066,6.567274736,0.333333333
"def commandComplete(self, cmd):<tab>if self.property:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>result = self.observer.getStdout()<tab><tab>if self.strip:<tab><tab><tab>result = result.strip()<tab><tab>propname = self.property<tab><tab>self.setProperty(propname, result, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes[propname] = result<tab>else:<tab><tab>new_props = self.extract_fn(<tab><tab><tab>cmd.rc, self.observer.getStdout(), self.observer.getStderr()<tab><tab>)<tab><tab>for k, v in iteritems(new_props):<tab><tab><tab>self.setProperty(k, v, ""SetPropertyFromCommand Step"")<tab><tab>self.property_changes = new_props",0,if cmd . didFail ( ) :,if self . property in self . property_changes :,0.019886917,4.932351569,0.257142857
"def any(self, provider_name):<tab>result = authomatic.login(Webapp2Adapter(self), provider_name)<tab>if result:<tab><tab>apis = []<tab><tab>if result.user:<tab><tab><tab>result.user.update()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>apis = config.config.get(provider_name, {}).get(""_apis"", {})<tab><tab>nice_provider_name = (<tab><tab><tab>config.config.get(provider_name, {}).get(""_name"")<tab><tab><tab>or provider_name.capitalize()<tab><tab>)<tab><tab>render(<tab><tab><tab>self,<tab><tab><tab>result,<tab><tab><tab>result.popup_js(custom=dict(apis=apis, provider_name=nice_provider_name)),<tab><tab>)",0,if result . user . credentials :,if config . config . get ( provider_name ) :,0.019866072,4.789232204,0.285714286
"def set_lock(self, lock_closed=True, device=0, timeout=0):<tab>if self.handle:<tab><tab>action = 0x02 if lock_closed else 0x01<tab><tab>reply = self.write_register(_R.receiver_pairing, action, device, timeout)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>_log.warn(<tab><tab><tab>""%s: failed to %s the receiver lock"",<tab><tab><tab>self,<tab><tab><tab>""close"" if lock_closed else ""open"",<tab><tab>)",1,if reply :,if reply :,0.531170663,1.00E-10,1
"def connect_thread(self, sleep_time=0):<tab>time.sleep(sleep_time)<tab>try:<tab><tab>while self.running and self._need_more_ip():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>self.connect_process()<tab>finally:<tab><tab>self.thread_num_lock.acquire()<tab><tab>self.thread_num -= 1<tab><tab>self.thread_num_lock.release()",0,if self . new_conn_pool . qsize ( ) > self . config . https_connection_pool_max :,if self . thread_num == 0 :,0.069420129,3.959981382,0.429292929
"def train_job(<tab>guest_party_id, host_party_id, arbiter_party_id, train_conf_path, train_dsl_path):<tab>train = TrainSBTModel()<tab>train.set_config(guest_party_id, host_party_id, arbiter_party_id, train_conf_path)<tab>train.set_dsl(train_dsl_path)<tab>status = train.submit()<tab>if status:<tab><tab>is_success = train.wait_success(timeout=600)<tab><tab><IF-STMT><tab><tab><tab>train.get_component_metrics()<tab><tab><tab>train.get_component_output_model()<tab><tab><tab>train.get_component_output_data()<tab><tab><tab>return train<tab>return False",1,if is_success :,if is_success :,0.531170663,1.00E-10,1
"def get_version():<tab>INIT = os.path.abspath(os.path.join(HERE, "".."", ""pyftpdlib"", ""__init__.py""))<tab>with open(INIT, ""r"") as f:<tab><tab>for line in f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ret = eval(line.strip().split("" = "")[1])<tab><tab><tab><tab>assert ret.count(""."") == 2, ret<tab><tab><tab><tab>for num in ret.split("".""):<tab><tab><tab><tab><tab>assert num.isdigit(), ret<tab><tab><tab><tab>return ret<tab><tab>else:<tab><tab><tab>raise ValueError(""couldn't find version string"")",0,"if line . startswith ( ""__ver__"" ) :","if line . startswith ( ""version = "" ) :",0.513340042,44.74378373,1
"def get_terminus_panel(self, window, visible_only=False):<tab>if visible_only:<tab><tab>active_panel = window.active_panel()<tab><tab>panels = [active_panel] if active_panel else []<tab>else:<tab><tab>panels = window.panels()<tab>for panel in panels:<tab><tab>panel_name = panel.replace(""output."", """")<tab><tab>if panel_name == EXEC_PANEL:<tab><tab><tab>continue<tab><tab>panel_view = window.find_output_panel(panel_name)<tab><tab>if panel_view:<tab><tab><tab>terminal = Terminal.from_id(panel_view.id())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return panel_view<tab>return None",0,if terminal :,if terminal . is_visible ( ) :,0.085805078,1.00E-10,1
"def to_internal_value(self, data):<tab>site = get_current_site()<tab>pages_root = reverse(""pages-root"")<tab>ret = []<tab>for path in data:<tab><tab><IF-STMT><tab><tab><tab>path = path[len(pages_root) :]<tab><tab># strip any final slash<tab><tab>if path.endswith(""/""):<tab><tab><tab>path = path[:-1]<tab><tab>page = get_page_from_path(site, path)<tab><tab>if page:<tab><tab><tab>ret.append(page)<tab>return ret",1,if path . startswith ( pages_root ) :,if path . startswith ( pages_root ) :,0.75,100,1
"def forward(self, inputs):<tab>input_dtype = inputs[0].dtype<tab>if self.comm.rank == self.root:<tab><tab># convert to float32 for communication<tab><tab><IF-STMT><tab><tab><tab>inputs = tuple([item.astype(numpy.float32) for item in inputs])<tab><tab>y = self.comm.scatter(inputs, self.root)<tab>else:<tab><tab>y = self.comm.scatter(None, self.root)<tab># convert back<tab>if numpy.float16 == input_dtype:<tab><tab>y = y.astype(input_dtype)<tab>return (y,)",1,if numpy . float16 == input_dtype :,if numpy . float16 == input_dtype :,0.75,100,1
"def discover_misago_admin():<tab>for app in apps.get_app_configs():<tab><tab>module = import_module(app.name)<tab><tab>if not hasattr(module, ""admin""):<tab><tab><tab>continue<tab><tab>admin_module = import_module(""%s.admin"" % app.name)<tab><tab><IF-STMT><tab><tab><tab>extension = getattr(admin_module, ""MisagoAdminExtension"")()<tab><tab><tab>if hasattr(extension, ""register_navigation_nodes""):<tab><tab><tab><tab>extension.register_navigation_nodes(site)<tab><tab><tab>if hasattr(extension, ""register_urlpatterns""):<tab><tab><tab><tab>extension.register_urlpatterns(urlpatterns)",1,"if hasattr ( admin_module , ""MisagoAdminExtension"" ) :","if hasattr ( admin_module , ""MisagoAdminExtension"" ) :",0.75,100,1
"def overwrite_timeout(<tab>initial_node: dict, path: str, hash_: str, size_: int, rsf: bool) -> int:<tab>minutes = 10<tab>while minutes > 0:<tab><tab>time.sleep(60)<tab><tab>minutes -= 1<tab><tab>n = acd_client.get_metadata(initial_node[""id""])<tab><tab><IF-STMT><tab><tab><tab>return upload_complete(n, path, hash_, size_, rsf)<tab>logger.warning('Timeout while overwriting ""%s"".' % path)<tab>return UL_TIMEOUT",0,"if n [ ""version"" ] > initial_node [ ""version"" ] :",if n :,0.017233337,1.00E-10,1
"def write(self, s, spos):<tab>if not s:<tab><tab>return<tab># Force s to be a string or unicode<tab>if not isinstance(s, basestring):<tab><tab>s = str(s)<tab>slen = self.len<tab>if spos == slen:<tab><tab>self.len = self.pos = spos + len(s)<tab><tab>return<tab>if spos > slen:<tab><tab>slen = spos<tab>newpos = spos + len(s)<tab>if spos < slen:<tab><tab>if self.buflist:<tab><tab><tab>self.buf += """".join(self.buflist)<tab><tab>self.buflist = [self.buf[:spos], s, self.buf[newpos:]]<tab><tab><IF-STMT><tab><tab><tab>slen = newpos<tab>else:<tab><tab>self.buflist.append(s)",0,if newpos > slen :,elif spos == slen :,0.052929075,16.23339577,0.333333333
"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None:<tab>child: xml.etree.ElementTree.Element<tab>for child in news_entry:<tab><tab>if ""title"" in child.tag:<tab><tab><tab>title = str(child.text)<tab><tab>if ""pubDate"" in child.tag:<tab><tab><tab>pub_date = str(child.text)<tab><tab><IF-STMT><tab><tab><tab>description = str(child.text)<tab>print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"")<tab>print_stdout(format_paragraph(strip_tags(description)))<tab>print_stdout()",1,"if ""description"" in child . tag :","if ""description"" in child . tag :",0.75,100,1
"def get_sequence_type_str(x: Sequence[Any]) -> str:<tab>container_type = type(x).__name__<tab>if not x:<tab><tab>if container_type == ""list"":<tab><tab><tab>return ""[]""<tab><tab>else:<tab><tab><tab>return container_type + ""([])""<tab>elem_type = get_type_str(x[0])<tab>if container_type == ""list"":<tab><tab><IF-STMT><tab><tab><tab>return ""["" + elem_type + ""]""<tab><tab>else:<tab><tab><tab>return ""["" + elem_type + "", ...]""<tab>else:<tab><tab>if len(x) == 1:<tab><tab><tab>return f""{container_type}([{elem_type}])""<tab><tab>else:<tab><tab><tab>return f""{container_type}([{elem_type}, ...])""",1,if len ( x ) == 1 :,if len ( x ) == 1 :,0.75,100,1
"def signal_notebook_switch_page(self, notebook, current_page, index):<tab>if not hasattr(self.parent, ""rpc""):<tab><tab>return<tab># previous_page = notebook.get_nth_page(self.last_page_id)<tab>self.last_page_id = index<tab>for tab in self.tabs.values():<tab><tab>if current_page != tab.box:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>tab.load_campaign_information(force=False)",0,"if hasattr ( tab , ""load_campaign_information"" ) :",if tab . load_campaign_information :,0.019907918,28.80083959,0.477272727
"def format_string(self, templ, args):<tab>templ = self.to_native(templ)<tab>if isinstance(args, nodes.Arguments):<tab><tab>args = args.arguments<tab>for (i, arg) in enumerate(args):<tab><tab>arg = self.to_native(self.reduce_single(arg))<tab><tab><IF-STMT>  # Python boolean is upper case.<tab><tab><tab>arg = str(arg).lower()<tab><tab>templ = templ.replace(""@{}@"".format(i), str(arg))<tab>return templ",1,"if isinstance ( arg , bool ) :","if isinstance ( arg , bool ) :",0.75,100,1
"def execute_Single(self, object, smooth):<tab>if getattr(object, ""type"", """") == ""MESH"":<tab><tab>mesh = object.data<tab><tab><IF-STMT><tab><tab><tab>smoothList = [smooth] * len(mesh.polygons)<tab><tab><tab>mesh.polygons.foreach_set(""use_smooth"", smoothList)<tab><tab><tab># trigger update<tab><tab><tab>mesh.polygons[0].use_smooth = smooth<tab>return object",0,if len ( mesh . polygons ) > 0 :,if smooth is not None :,0.01382318,4.955725306,0.2
"def _enumerate_visible_deps(self, dep, predicate):<tab># We present the dependencies out of classpath order and instead in alphabetized internal deps,<tab># then alphabetized external deps order for ease in scanning output.<tab>dependencies = sorted(x for x in getattr(dep, ""dependencies"", []))<tab>if not self.is_internal_only:<tab><tab>dependencies.extend(<tab><tab><tab>sorted(<tab><tab><tab><tab>(x for x in getattr(dep, ""jar_dependencies"", [])),<tab><tab><tab><tab>key=lambda x: (x.org, x.name, x.rev, x.classifier),<tab><tab><tab>)<tab><tab>)<tab>for inner_dep in dependencies:<tab><tab>dep_id, internal = self._dep_id(inner_dep)<tab><tab><IF-STMT><tab><tab><tab>yield inner_dep",0,if predicate ( internal ) :,"if predicate ( dep_id , internal ) :",0.142751568,26.26909894,1
"def stop_test(self):<tab>if self.master:<tab><tab>self.log.info(""Ending cloud test..."")<tab><tab>if not self._last_status:<tab><tab><tab>self.get_master_status()<tab><tab><IF-STMT><tab><tab><tab>self.master.stop()<tab><tab>else:<tab><tab><tab>self.master.terminate()",0,"if self . _last_status [ ""progress"" ] >= 100 :","if self . _last_status == ""stopped"" :",0.194741835,41.81117364,0.733333333
"def run(self, workspace):<tab>""""""Run the module""""""<tab>if self.show_window:<tab><tab>m = workspace.get_measurements()<tab><tab>x = m.get_current_measurement(self.get_object(), self.x_axis.value)<tab><tab><IF-STMT><tab><tab><tab>x = x[x > self.xbounds.min]<tab><tab><tab>x = x[x < self.xbounds.max]<tab><tab>workspace.display_data.x = x<tab><tab>workspace.display_data.title = ""{} (cycle {})"".format(<tab><tab><tab>self.title.value, workspace.measurements.image_set_number<tab><tab>)",0,if self . wants_xbounds :,if self . xbounds is not None :,0.193606478,23.35689889,0.357142857
"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz / (np.cast[x.type](1) - sqr(x)),)",1,if x . type in discrete_types :,if x . type in discrete_types :,0.75,100,1
"def _which(cls, progname):<tab>progname = progname.lower()<tab>for p in cls.env.path:<tab><tab>for ext in cls._EXTENSIONS:<tab><tab><tab>fn = p / (progname + ext)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return fn<tab>return None",0,"if fn . access ( ""x"" ) and not fn . is_dir ( ) :",if fn . exists ( ) :,0.134712026,7.404200367,0.360544218
"def iterate(self, prod_, rule_):<tab>newProduction = """"<tab>for i in range(len(prod_)):<tab><tab>step = self.production[i]<tab><tab>if step == ""W"":<tab><tab><tab>newProduction = newProduction + self.ruleW<tab><tab>elif step == ""X"":<tab><tab><tab>newProduction = newProduction + self.ruleX<tab><tab><IF-STMT><tab><tab><tab>newProduction = newProduction + self.ruleY<tab><tab>elif step == ""Z"":<tab><tab><tab>newProduction = newProduction + self.ruleZ<tab><tab>elif step != ""F"":<tab><tab><tab>newProduction = newProduction + step<tab>self.drawLength = self.drawLength * 0.5<tab>self.generations += 1<tab>return newProduction",1,"elif step == ""Y"" :","elif step == ""Y"" :",1,100,1
"def update(self, mapping, update_only=False):<tab>for name in mapping:<tab><tab>if update_only and name in self:<tab><tab><tab># nested and inner objects, merge recursively<tab><tab><tab>if hasattr(self[name], ""update""):<tab><tab><tab><tab># FIXME only merge subfields, not the settings<tab><tab><tab><tab>self[name].update(mapping[name], update_only)<tab><tab><tab>continue<tab><tab>self.field(name, mapping[name])<tab>if update_only:<tab><tab>for name in mapping._meta:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._meta[name] = mapping._meta[name]<tab>else:<tab><tab>self._meta.update(mapping._meta)",0,if name not in self . _meta :,if name in self . _meta :,0.428633602,67.52918218,0.476190476
"def Flatten(self, metadata, value_to_flatten):<tab>if metadata:<tab><tab>self.metadata = metadata<tab>for desc in value_to_flatten.type_infos:<tab><tab>if desc.name == ""metadata"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>setattr(self, desc.name, getattr(value_to_flatten, desc.name))",0,"if hasattr ( self , desc . name ) and value_to_flatten . HasField ( desc . name ) :","if hasattr ( value_to_flatten , desc . name ) :",0.278173578,37.41489566,0.35
"def addnode(self, parent, data):<tab>print(""aaa"", data)<tab>for i in data:<tab><tab>print(i)<tab><tab>if i == ""-"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])<tab><tab><tab>self.addnode(item, i[1])<tab><tab>else:<tab><tab><tab>item = self.tre_plugins.AppendItem(parent, i[0].title)<tab><tab><tab>self.tre_plugins.SetItemData(item, i[0])",0,"if isinstance ( i , tuple ) :","elif isinstance ( i [ 0 ] , tuple ) :",0.197781534,33.93251341,0.417582418
"def load_timer(string):<tab>if ""."" not in string:<tab><tab>raise argparse.ArgumentTypeError(<tab><tab><tab>""Value for --benchmark-timer must be in dotted form. Eg: 'module.attr'.""<tab><tab>)<tab>mod, attr = string.rsplit(""."", 1)<tab>if mod == ""pep418"":<tab><tab><IF-STMT><tab><tab><tab>import time<tab><tab><tab>return NameWrapper(getattr(time, attr))<tab><tab>else:<tab><tab><tab>from . import pep418<tab><tab><tab>return NameWrapper(getattr(pep418, attr))<tab>else:<tab><tab>__import__(mod)<tab><tab>mod = sys.modules[mod]<tab><tab>return NameWrapper(getattr(mod, attr))",0,if PY3 :,if sys . modules . has_key ( attr ) :,0.0422451,1.00E-10,0.30952381
"def _is_an_attribute(self, pyname):<tab>if pyname is not None and isinstance(pyname, pynames.AssignedName):<tab><tab>pymodule, lineno = self.pyname.get_definition_location()<tab><tab>scope = pymodule.get_scope().get_inner_scope_for_line(lineno)<tab><tab>if scope.get_kind() == ""Class"":<tab><tab><tab>return pyname in list(scope.get_names().values())<tab><tab>parent = scope.parent<tab><tab><IF-STMT><tab><tab><tab>return pyname in list(parent.get_names().values())<tab>return False",0,"if parent is not None and parent . get_kind ( ) == ""Class"" :",if parent is not None :,0.262995582,9.110529535,0.791666667
"def _format_arg(self, name, spec, value):<tab>if name == ""title"":<tab><tab>if isinstance(value, bool) and value:<tab><tab><tab>return ""--title""<tab><tab><IF-STMT><tab><tab><tab>return ""--title --title_text %s"" % (value,)<tab><tab>else:<tab><tab><tab>raise ValueError('Unknown value for ""title"" argument: ' + str(value))<tab>return super(Pik, self)._format_arg(name, spec, value)",0,"elif isinstance ( value , str ) :","elif isinstance ( value , str ) and value :",0.532518652,66.06328636,0.744444444
"def total_form_count(self):<tab>""""""Returns the total number of forms in this FormSet.""""""<tab>if self.is_bound:<tab><tab>return self.management_form.cleaned_data[TOTAL_FORM_COUNT]<tab>else:<tab><tab>initial_forms = self.initial_form_count()<tab><tab>total_forms = initial_forms + self.extra<tab><tab># Allow all existing related objects/inlines to be displayed,<tab><tab># but don't allow extra beyond max_num.<tab><tab><IF-STMT><tab><tab><tab>total_forms = initial_forms<tab><tab>elif total_forms > self.max_num >= 0:<tab><tab><tab>total_forms = self.max_num<tab>return total_forms",0,if initial_forms > self . max_num >= 0 :,if total_forms < initial_forms :,0.016838046,12.10926138,0.464285714
"def GetTestNamesFromSuites(test_suite):<tab>""""""Takes a list of test suites and returns a list of contained test names.""""""<tab>suites = [test_suite]<tab>test_names = []<tab>while suites:<tab><tab>suite = suites.pop()<tab><tab>for test in suite:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>suites.append(test)<tab><tab><tab>else:<tab><tab><tab><tab>test_names.append(test.id()[len(""gslib.tests.test_"") :])<tab>return test_names",0,"if isinstance ( test , unittest . TestSuite ) :","if test . id ( ) == ""gslib.tests.test_"" :",0.017021916,3.579280789,0.261904762
"def readArgs(self, node):<tab>res = {}<tab>for c in self.getChildrenOf(node):<tab><tab>val = c.getAttribute(""val"")<tab><tab><IF-STMT><tab><tab><tab>res[str(c.nodeName)] = self.modules[val]<tab><tab>elif val in self.mothers:<tab><tab><tab>res[str(c.nodeName)] = self.mothers[val]<tab><tab>elif val != """":<tab><tab><tab>res[str(c.nodeName)] = eval(val)<tab>return res",1,if val in self . modules :,if val in self . modules :,0.75,100,1
"def pop(self, k, default=Sentinel):<tab>with self._database.transaction():<tab><tab>node, is_single = self.convert_node(k)<tab><tab>try:<tab><tab><tab>res = self[k]<tab><tab>except KeyError:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab><tab>return default<tab><tab>del self[node]<tab>return res",0,if default is Sentinel :,if is_single :,0.033898613,1.00E-10,0.28
"def wrapped_strategy(self):<tab>if self.__wrapped_strategy is None:<tab><tab><IF-STMT><tab><tab><tab>raise InvalidArgument(<tab><tab><tab><tab>f""Expected definition to be a function but got {self.__definition!r} ""<tab><tab><tab><tab>f""of type {type(self.__definition).__name__} instead.""<tab><tab><tab>)<tab><tab>result = self.__definition()<tab><tab>if result is self:<tab><tab><tab>raise InvalidArgument(""Cannot define a deferred strategy to be itself"")<tab><tab>check_strategy(result, ""definition()"")<tab><tab>self.__wrapped_strategy = result<tab><tab>self.__definition = None<tab>return self.__wrapped_strategy",0,if not inspect . isfunction ( self . __definition ) :,"if not isinstance ( self . __definition , Function ) :",0.222922807,47.03709594,0.375
"def _on_fullscreen_requested(self, on):<tab>if not config.val.content.fullscreen.window:<tab><tab><IF-STMT><tab><tab><tab>self.state_before_fullscreen = self.windowState()<tab><tab><tab>self.setWindowState(<tab><tab><tab><tab>Qt.WindowFullScreen<tab><tab><tab><tab>| self.state_before_fullscreen  # type: ignore[arg-type]<tab><tab><tab>)  # type: ignore[operator]<tab><tab>elif self.isFullScreen():<tab><tab><tab>self.setWindowState(self.state_before_fullscreen)<tab>log.misc.debug(<tab><tab>""on: {}, state before fullscreen: {}"".format(<tab><tab><tab>on, debug.qflags_key(Qt, self.state_before_fullscreen)<tab><tab>)<tab>)",0,if on :,if not self . state_before_fullscreen :,0.173107739,1.00E-10,0.371428571
"def update_defaults(self, *values, **kwargs):<tab>for value in values:<tab><tab>if type(value) == dict:<tab><tab><tab>self.DEFAULT_CONFIGURATION.update(value)<tab><tab>elif isinstance(value, types.ModuleType):<tab><tab><tab>self.__defaults_from_module(value)<tab><tab>elif isinstance(value, str):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.__defaults_from_file(value)<tab><tab><tab>else:<tab><tab><tab><tab>logger.warning(""Configuration file {} does not exist."".format(value))<tab><tab>elif isinstance(value, type(None)):<tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise ValueError(""Cannot interpret {}"".format(value))<tab>self.DEFAULT_CONFIGURATION.update(kwargs)",0,if os . path . exists ( value ) :,if os . path . isfile ( value ) :,0.580308871,65.80370065,0.714285714
"def clear_output_directory(self):<tab>files = os.listdir(os.path.join(""functional"", ""output""))<tab>for f in files:<tab><tab>if f in (""README.txt"", "".svn"", ""CVS""):<tab><tab><tab>continue  # don't touch the infrastructure<tab><tab>path = os.path.join(""functional"", ""output"", f)<tab><tab><IF-STMT><tab><tab><tab>shutil.rmtree(path)<tab><tab>else:<tab><tab><tab>os.remove(path)",1,if os . path . isdir ( path ) :,if os . path . isdir ( path ) :,1,100,1
"def do_remove(self):<tab>if self.netconf.locked(""dhcp""):<tab><tab><IF-STMT><tab><tab><tab>pid = read_pid_file(""/var/run/udhcpd.pan1.pid"")<tab><tab>else:<tab><tab><tab>pid = self.pid<tab><tab>if not kill(pid, ""udhcpd""):<tab><tab><tab>logging.info(""Stale dhcp lockfile found"")<tab><tab>self.netconf.unlock(""dhcp"")",0,if not self . pid :,if self . pid is None :,0.104946328,27.77619034,0.257142857
"def __getattr__(self, attr):<tab>if attr.endswith(""[]""):<tab><tab>searchName = attr[:-2]<tab>else:<tab><tab>searchName = attr<tab>with _lazyLock:<tab><tab>nestedClasses = _dependencyMap.get(self.__name__, [])<tab><tab><IF-STMT><tab><tab><tab>return GetVmodlType(self.__name__ + ""."" + attr)<tab><tab>else:<tab><tab><tab>return super(LazyType, self).__getattribute__(attr)",0,if searchName in nestedClasses :,if nestedClasses and searchName in nestedClasses :,0.410456913,43.47208719,0.25
"def allow_request(self, request, view):<tab>request.server = None<tab>allow = True<tab>view_name = view.get_view_name()<tab>allowed_views = [u""System Data"", u""Collectd Data"", u""Legacy System Data""]<tab>if view_name in allowed_views:<tab><tab>server_key = view.kwargs.get(""server_key"")<tab><tab>server = server_model.get_server_by_key(server_key)<tab><tab><IF-STMT><tab><tab><tab>request.server = server  # Needed in the Models<tab><tab><tab>server_status = throttle_status(server=server)<tab><tab><tab>if server_status.allow == False:<tab><tab><tab><tab>allow = False<tab>return allow",1,if server :,if server :,0.531170663,1.00E-10,1
"def serve_until_stopped(self):<tab>import select<tab>abort = 0<tab>while not abort:<tab><tab>rd, wr, ex = select.select([self.socket.fileno()], [], [], self.timeout)<tab><tab><IF-STMT><tab><tab><tab>self.handle_request()<tab><tab>logging._acquireLock()<tab><tab>abort = self.abort<tab><tab>logging._releaseLock()",1,if rd :,if rd :,0.531170663,1.00E-10,1
"def A(*args):<tab>if len(args) > 0 and hasattr(args[0], ""__iter__""):  # Iterable as argument<tab><tab><IF-STMT><tab><tab><tab>return np.array(list(args), dtype=np.float32)<tab><tab>else:<tab><tab><tab># Flatten arguments into one list<tab><tab><tab>l = list(args[0])<tab><tab><tab>for e in args[1:]:<tab><tab><tab><tab>if hasattr(e, ""__iter__""):<tab><tab><tab><tab><tab>l.extend(e)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>l.append(e)<tab><tab><tab>return np.array(l, dtype=np.float32)<tab>return np.array(list(args), dtype=np.float32)",1,if len ( args ) == 1 :,if len ( args ) == 1 :,0.75,100,1
"def _fix(self):<tab>op = []<tab>for k in range(self.size):<tab><tab>o = random.choice(self._opts)<tab><tab><IF-STMT><tab><tab><tab>op.append((o, self.rndstr * 1))<tab><tab>else:<tab><tab><tab>op.append((o.name, o.randval()._fix()))<tab>return op",0,if type ( o ) is str :,if self . rndstr :,0.018586852,6.971729122,0.21875
"def lint_dynamic(self, rule):<tab>for file in chain(rule.output, rule.input):<tab><tab><IF-STMT><tab><tab><tab>yield Lint(<tab><tab><tab><tab>title=""The dynamic flag is deprecated"",<tab><tab><tab><tab>body=""Use checkpoints instead, which are more powerful and less error-prone."",<tab><tab><tab><tab>links=[links.checkpoints],<tab><tab><tab>)",0,"if is_flagged ( file , ""dynamic"" ) :","if ""dynamic"" in file . lower ( ) :",0.036527439,18.014935,0.366666667
"def visit(ignored, dir, files):<tab>if os.path.basename(dir) not in test_names:<tab><tab>for name in test_names:<tab><tab><tab>if name + "".py"" in files:<tab><tab><tab><tab>path = os.path.join(dir, name + "".py"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>results.append(path)<tab><tab>return<tab>if ""__init__.py"" not in files:<tab><tab>stderr(""%s is not a package"" % dir)<tab><tab>return<tab>for file in files:<tab><tab>if file.startswith(""test"") and file.endswith("".py""):<tab><tab><tab>path = os.path.join(dir, file)<tab><tab><tab>if matcher(path[baselen:]):<tab><tab><tab><tab>results.append(path)",1,if matcher ( path [ baselen : ] ) :,if matcher ( path [ baselen : ] ) :,0.75,100,1
"def wrapped(*args, **kwargs):<tab>try:<tab><tab>func(*args, **kwargs)<tab>except AssertionError as e:<tab><tab><IF-STMT><tab><tab><tab>time.sleep(t_interval)<tab><tab><tab>retry_assertion(interval=t_interval, retries=t_retries - 1)(func)(<tab><tab><tab><tab>*args, **kwargs<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise e",0,if retries :,if t_retries > 0 :,0.051944023,1.00E-10,0.5
"def num2binary(l, bits=32):<tab>all = []<tab>bin = """"<tab>for i in range(bits):<tab><tab>if l & 0x1:<tab><tab><tab>bin = ""1"" + bin<tab><tab>else:<tab><tab><tab>bin = ""0"" + bin<tab><tab>l = l >> 1<tab><tab><IF-STMT><tab><tab><tab>all.append(bin)<tab><tab><tab>bin = """"<tab>if bin:<tab><tab>all.append(bin)<tab>all.reverse()<tab>assert l in (0, -1), ""number doesn't fit in number of bits""<tab>return string.join(all, "" "")",0,if not ( ( i + 1 ) % 8 ) :,if l & 0x80 :,0.010141139,3.132599824,0.234375
"def closest_enemy_ant(self, row1, col1, filter=None):<tab># find the closest enemy ant from this row/col<tab>min_dist = maxint<tab>closest_ant = None<tab>for ant in self.enemy_ants():<tab><tab>if filter is None or ant not in filter:<tab><tab><tab>dist = self.distance(row1, col1, ant[0][0], ant[0][1])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>min_dist = dist<tab><tab><tab><tab>closest_ant = ant[0]<tab>return closest_ant",1,if dist < min_dist :,if dist < min_dist :,0.75,100,1
"def _wrap(cls, parent, value):<tab>if isinstance(value, dict):<tab><tab># we know that `annotations` and `labels` are dicts and therefore don't want to convert them into K8sObject<tab><tab>return (<tab><tab><tab>value<tab><tab><tab><IF-STMT><tab><tab><tab>and all(isinstance(v, six.string_types) for v in value.values())<tab><tab><tab>else cls(value)<tab><tab>)<tab>elif isinstance(value, list):<tab><tab>return [cls._wrap(None, v) for v in value]<tab>else:<tab><tab>return value",0,"if parent in { ""annotations"" , ""labels"" }","if isinstance ( value , dict )",0.018333425,3.823246853,0.26984127
"def do_definition(tag):<tab>w.end_para()<tab>macro("".TP"")<tab>w.started = True<tab>split = 0<tab>pre = []<tab>post = []<tab>for typ, text in _bitlist(tag):<tab><tab><IF-STMT><tab><tab><tab>post.append((typ, text))<tab><tab>elif text.lstrip().startswith("": ""):<tab><tab><tab>split = 1<tab><tab><tab>post.append((typ, text.lstrip()[2:].lstrip()))<tab><tab>else:<tab><tab><tab>pre.append((typ, text))<tab>_boldline(pre)<tab>w.write(_text(post))<tab>w.started = False",0,if split :,if split == 0 :,0.097914534,1.00E-10,0.7
"def updateTree(self, v, x, y, h, level):<tab>yfirst = y<tab>if level == 0:<tab><tab>yfirst += 10<tab>while v:<tab><tab># g.trace(x,y,v)<tab><tab>h, indent = self.updateNode(v, x, y)<tab><tab>y += h<tab><tab><IF-STMT><tab><tab><tab>y = self.updateTree(v.firstChild(), x + indent, y, h, level + 1)<tab><tab>v = v.next()<tab>return y",0,if v . isExpanded ( ) and v . firstChild ( ) :,if v . getChildCount ( ) > yfirst :,0.135253134,14.9759855,0.317708333
def loop(self):<tab>while True:<tab><tab>job = self.check_queue()<tab><tab><IF-STMT><tab><tab><tab>time.sleep(20)<tab><tab><tab>continue<tab><tab>self.run_job(job)<tab><tab>time.sleep(5),0,if not job :,if job is None :,0.045150551,14.05853313,0.277777778
"def _name_to_variable(self, name):<tab>r""""""Find the corresponding variable given the specified name.""""""<tab>pointer = self<tab>for m_name in name.split("".""):<tab><tab><IF-STMT><tab><tab><tab>num = int(m_name)<tab><tab><tab>pointer = pointer[num]  # type: ignore<tab><tab>else:<tab><tab><tab>pointer = getattr(pointer, m_name)<tab>return pointer  # type: ignore",0,if m_name . isdigit ( ) :,"if isinstance ( pointer , tuple ) :",0.039521502,11.59119923,0.3
"def fetch_cleanup(self):<tab>for cell in self.cover_cells:<tab><tab><IF-STMT><tab><tab><tab>log.debug(<tab><tab><tab><tab>""Removing cover art fetch task for %s"",<tab><tab><tab><tab>cell.release[""musicbrainz_albumid""],<tab><tab><tab>)<tab><tab><tab>self.tagger.webservice.remove_task(cell.fetch_task)",0,if cell . fetch_task is not None :,if cell . fetch_task :,0.234334509,54.77927682,0.444444444
"def _get_lcmap_info(self, vol_name):<tab>ret_vals = {<tab><tab>""fc_id"": """",<tab><tab>""fc_name"": """",<tab><tab>""lc_map_count"": ""0"",<tab>}<tab>for lcmap in self._lcmappings_list.values():<tab><tab><IF-STMT><tab><tab><tab>ret_vals[""fc_id""] = lcmap[""id""]<tab><tab><tab>ret_vals[""fc_name""] = lcmap[""name""]<tab><tab><tab>ret_vals[""lc_map_count""] = ""1""<tab>return ret_vals",0,"if ( lcmap [ ""source"" ] == vol_name ) or ( lcmap [ ""target"" ] == vol_name ) :","if lcmap [ ""name"" ] == vol_name :",0.141390478,18.03705124,0.651041667
"def on_event_clicked(self, widget, event):<tab>if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3:<tab><tab>path = self.get_path_at_pos(int(event.x), int(event.y))<tab><tab>if path is not None:<tab><tab><tab>row = self.get(path[0], ""device"")<tab><tab><tab>if row:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>if self.menu is None:<tab><tab><tab><tab><tab><tab>self.menu = ManagerDeviceMenu(self.Blueman)<tab><tab><tab><tab><tab>self.menu.popup(None, None, None, None, event.button, event.time)",0,if self . Blueman is not None :,if row == 0 :,0.018586852,6.916271813,0.174603175
"def _find_node_with_predicate(self, node, predicate):<tab>if node != self._tree._root and predicate(node):<tab><tab>return node<tab>item, cookie = self._tree.GetFirstChild(node)<tab>while item:<tab><tab>if predicate(item):<tab><tab><tab>return item<tab><tab><IF-STMT><tab><tab><tab>result = self._find_node_with_predicate(item, predicate)<tab><tab><tab>if result:<tab><tab><tab><tab>return result<tab><tab>item, cookie = self._tree.GetNextChild(node, cookie)<tab>return None",0,if self . _tree . ItemHasChildren ( item ) :,if cookie is not None :,0.01382318,4.194930905,0.212121212
"def expect_flow_sequence_item(self):<tab>if isinstance(self.event, SequenceEndEvent):<tab><tab>self.indent = self.indents.pop()<tab><tab>self.flow_level -= 1<tab><tab>if self.canonical:<tab><tab><tab>self.write_indicator(u"","", False)<tab><tab><tab>self.write_indent()<tab><tab>self.write_indicator(u""]"", False)<tab><tab>self.state = self.states.pop()<tab>else:<tab><tab>self.write_indicator(u"","", False)<tab><tab><IF-STMT><tab><tab><tab>self.write_indent()<tab><tab>self.states.append(self.expect_flow_sequence_item)<tab><tab>self.expect_node(sequence=True)",0,if self . canonical or self . column > self . best_width :,if self . canonical :,0.153561646,9.569649651,0.541666667
"def iteration(pts):<tab>n = len(pts)<tab>all_pts = pts + invert(pts)<tab>diagram = Voronoi(all_pts)<tab>vertices = restrict(diagram.vertices)<tab>centers = []<tab>for site_idx in range(n):<tab><tab>region_idx = diagram.point_region[site_idx]<tab><tab>region = diagram.regions[region_idx]<tab><tab><IF-STMT><tab><tab><tab>site = pts[site_idx]<tab><tab><tab>centers.append(site)<tab><tab><tab>continue<tab><tab>region_verts = np.array([vertices[i] for i in region])<tab><tab>center = weighted_center(region_verts, weight_field)<tab><tab>centers.append(tuple(center))<tab>return centers",0,if - 1 in region :,if len ( region ) == 0 :,0.023749772,6.274655311,0.285714286
"def retry_call(self, key, f, time_expire, with_lock):<tab>self.RETRIES += 1<tab>if self.RETRIES <= self.MAX_RETRIES:<tab><tab><IF-STMT><tab><tab><tab>self.RETRIES = 0<tab><tab><tab>return f()<tab><tab>logger.error(""sleeping %s seconds before reconnecting"" % (2 * self.RETRIES))<tab><tab>time.sleep(2 * self.RETRIES)<tab><tab>return self.__call__(key, f, time_expire, with_lock)<tab>else:<tab><tab>self.RETRIES = 0<tab><tab>if self.fail_gracefully:<tab><tab><tab>return f<tab><tab>raise RConnectionError(""Redis instance is unavailable"")",1,if self . fail_gracefully :,if self . fail_gracefully :,0.75,100,1
"def load_model(<tab>self, model_name: str, path: str = None, model_type=None) -> AbstractModel:<tab>if isinstance(model_name, AbstractModel):<tab><tab>return model_name<tab>if model_name in self.models.keys():<tab><tab>return self.models[model_name]<tab>else:<tab><tab><IF-STMT><tab><tab><tab>path = self.get_model_attribute(model=model_name, attribute=""path"")<tab><tab>if model_type is None:<tab><tab><tab>model_type = self.get_model_attribute(model=model_name, attribute=""type"")<tab><tab>return model_type.load(path=path, reset_paths=self.reset_paths)",1,if path is None :,if path is None :,0.75,100,1
"def _GetPathType(<tab>args: rdf_artifacts.ArtifactCollectorFlowArgs, client_os: str) -> rdf_paths.PathSpec.PathType:<tab>if args.use_tsk or args.use_raw_filesystem_access:<tab><tab><IF-STMT><tab><tab><tab>return config.CONFIG[""Server.raw_filesystem_access_pathtype""]<tab><tab>else:<tab><tab><tab>return rdf_paths.PathSpec.PathType.TSK<tab>else:<tab><tab>return rdf_paths.PathSpec.PathType.OS",1,"if client_os == ""Windows"" :","if client_os == ""Windows"" :",0.75,100,1
"def iter_links(self):<tab># type: () -> Iterable[Link]<tab>""""""Yields all links in the page""""""<tab>document = html5lib.parse(<tab><tab>self.content,<tab><tab>transport_encoding=_get_encoding_from_headers(self.headers),<tab><tab>namespaceHTMLElements=False,<tab>)<tab>base_url = _determine_base_url(document, self.url)<tab>for anchor in document.findall("".//a""):<tab><tab>link = _create_link_from_element(<tab><tab><tab>anchor,<tab><tab><tab>page_url=self.url,<tab><tab><tab>base_url=base_url,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>yield link",0,if link is None :,if not link :,0.039449619,16.37226967,0.277777778
"def on_leave(<tab>self, original_node: CSTNodeT, updated_node: CSTNodeT) -> Union[cst.Import, cst.ImportFrom, CSTNodeT, RemovalSentinel]:<tab>if isinstance(updated_node, cst.Import):<tab><tab>for alias in updated_node.names:<tab><tab><tab>name = alias.name<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return cst.RemoveFromParent()<tab>elif isinstance(updated_node, cst.ImportFrom):<tab><tab>module = updated_node.module<tab><tab>if isinstance(module, cst.Name) and module.value == ""e"":<tab><tab><tab>return cst.RemoveFromParent()<tab>return updated_node",0,"if isinstance ( name , cst . Name ) and name . value == ""b"" :","if isinstance ( name , cst . Name ) and name . value == ""e"" :",0.938804547,86.63975518,1
"def http_request(self, request):<tab>ntlm_auth_header = request.get_header(self.auth_header, None)<tab>if ntlm_auth_header is None:<tab><tab>user, pw = self.passwd.find_user_password(None, request.get_full_url())<tab><tab><IF-STMT><tab><tab><tab>auth = ""NTLM %s"" % ntlm.create_NTLM_NEGOTIATE_MESSAGE(user)<tab><tab><tab>request.add_unredirected_header(self.auth_header, auth)<tab>return request",0,if pw is not None :,if user :,0.026485502,1.00E-10,0.2
"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(""[""):<tab><tab><tab>if current_repo:<tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab>if current_repo and ""="" in line:<tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos",0,"if not line or line . startswith ( ""#"" ) :",if not line :,0.046144095,6.734410773,0.572649573
"def load_as_uint8(filename):<tab>image = gdal.Open(filename)<tab>image_array = np.array(image.ReadAsArray())<tab>image_uint8 = np.zeros(image_array.shape, dtype=np.uint8)<tab># rescale each band to be between 0, 255<tab>for k, band in enumerate(image_array):<tab><tab>band_max = np.max(band)<tab><tab><IF-STMT><tab><tab><tab>band = band.astype(np.float) / band_max * 255.0<tab><tab>image_uint8[k, :, :] = band<tab>return image_uint8",0,if band_max != 0 :,if band_max > 0 :,0.331415021,42.38365628,1
"def _get_resource_group_name_of_staticsite(client, static_site_name):<tab>static_sites = client.list()<tab>for static_site in static_sites:<tab><tab>if static_site.name.lower() == static_site_name.lower():<tab><tab><tab>resource_group = _parse_resource_group_from_arm_id(static_site.id)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return resource_group<tab>raise CLIError(<tab><tab>""Static site was '{}' not found in subscription."".format(static_site_name)<tab>)",1,if resource_group :,if resource_group :,0.531170663,1.00E-10,1
"def _translate_trace_addr(self, trace_addr, obj=None):<tab>if obj is None:<tab><tab>for obj in self._aslr_slides:  # pylint: disable=redefined-argument-from-local<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>raise Exception(""Can't figure out which object this address belongs to"")<tab>if obj not in self._aslr_slides:<tab><tab>raise Exception(""Internal error: object is untranslated"")<tab>return trace_addr - self._aslr_slides[obj]",0,if obj . contains_addr ( trace_addr - self . _aslr_slides [ obj ] ) :,if trace_addr >= self . _aslr_slides [ obj ] :,0.286463932,43.04386198,0.489130435
"def _register_builtin_handlers(self, events):<tab>for spec in handlers.BUILTIN_HANDLERS:<tab><tab>if len(spec) == 2:<tab><tab><tab>event_name, handler = spec<tab><tab><tab>self.register(event_name, handler)<tab><tab>else:<tab><tab><tab>event_name, handler, register_type = spec<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._events.register_first(event_name, handler)<tab><tab><tab>elif register_type is handlers.REGISTER_LAST:<tab><tab><tab><tab>self._events.register_last(event_name, handler)",0,if register_type is handlers . REGISTER_FIRST :,if register_type is handlers .REGISTER_FIRST :,0.476133778,100,1
"def __fixdict(self, dict):<tab>for key in dict.keys():<tab><tab>if key[:6] == ""start_"":<tab><tab><tab>tag = key[6:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.elements[tag] = getattr(self, key), end<tab><tab>elif key[:4] == ""end_"":<tab><tab><tab>tag = key[4:]<tab><tab><tab>start, end = self.elements.get(tag, (None, None))<tab><tab><tab>if end is None:<tab><tab><tab><tab>self.elements[tag] = start, getattr(self, key)",1,if start is None :,if start is None :,0.75,100,1
"def metadata(draft):<tab>test_metadata = {}<tab>json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema)<tab>for key, value in json_schema[""properties""].items():<tab><tab>response = ""Test response""<tab><tab>items = value[""properties""][""value""].get(""items"")<tab><tab>enum = value[""properties""][""value""].get(""enum"")<tab><tab>if items:  # multiselect<tab><tab><tab>response = [items[""enum""][0]]<tab><tab><IF-STMT>  # singleselect<tab><tab><tab>response = enum[0]<tab><tab>elif value[""properties""][""value""].get(""properties""):<tab><tab><tab>response = {""question"": {""value"": ""Test Response""}}<tab><tab>test_metadata[key] = {""value"": response}<tab>return test_metadata",1,elif enum :,elif enum :,0.531170663,1.00E-10,1
"def par_iter_next_batch(self, batch_ms: int):<tab>""""""Batches par_iter_next.""""""<tab>batch = []<tab>if batch_ms == 0:<tab><tab>batch.append(self.par_iter_next())<tab><tab>return batch<tab>t_end = time.time() + (0.001 * batch_ms)<tab>while time.time() < t_end:<tab><tab>try:<tab><tab><tab>batch.append(self.par_iter_next())<tab><tab>except StopIteration:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise StopIteration<tab><tab><tab>else:<tab><tab><tab><tab>pass<tab>return batch",0,if len ( batch ) == 0 :,if self . stop_event . is_set ( ) :,0.019030986,4.368583926,0.305555556
"def get_node_map(self, nodes: List[Node], left_node_only=True):<tab>node_map = {}<tab>idx = 0<tab>for node in nodes:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>node_map[node.id] = idx<tab><tab>idx += 1<tab>return node_map",0,if node . id != 0 and ( not node . is_left_node and left_node_only ) :,if left_node_only and node . is_leaf :,0.043328425,20.68121747,0.25170068
"def compare_objects(left, right):<tab>left_fields = left.map_value.fields<tab>right_fields = right.map_value.fields<tab>for left_key, right_key in zip(sorted(left_fields), sorted(right_fields)):<tab><tab>keyCompare = Order._compare_to(left_key, right_key)<tab><tab><IF-STMT><tab><tab><tab>return keyCompare<tab><tab>value_compare = Order.compare(left_fields[left_key], right_fields[right_key])<tab><tab>if value_compare != 0:<tab><tab><tab>return value_compare<tab>return Order._compare_to(len(left_fields), len(right_fields))",1,if keyCompare != 0 :,if keyCompare != 0 :,0.75,100,1
"def _resolve_policy_id(cmd, policy, policy_set_definition, client):<tab>policy_id = policy or policy_set_definition<tab>if not is_valid_resource_id(policy_id):<tab><tab><IF-STMT><tab><tab><tab>policy_def = _get_custom_or_builtin_policy(cmd, client, policy)<tab><tab><tab>policy_id = policy_def.id<tab><tab>else:<tab><tab><tab>policy_set_def = _get_custom_or_builtin_policy(<tab><tab><tab><tab>cmd, client, policy_set_definition, None, None, True<tab><tab><tab>)<tab><tab><tab>policy_id = policy_set_def.id<tab>return policy_id",1,if policy :,if policy :,0.531170663,1.00E-10,1
"def _passes_cortex_depth(line, min_depth):<tab>""""""Do any genotypes in the cortex_var VCF line passes the minimum depth requirement?""""""<tab>parts = line.split(""\t"")<tab>cov_index = parts[8].split("":"").index(""COV"")<tab>passes_depth = False<tab>for gt in parts[9:]:<tab><tab>cur_cov = gt.split("":"")[cov_index]<tab><tab>cur_depth = sum(int(x) for x in cur_cov.split("",""))<tab><tab><IF-STMT><tab><tab><tab>passes_depth = True<tab>return passes_depth",0,if cur_depth >= min_depth :,if cur_depth < min_depth :,0.081415021,53.41735957,1
"def __init__(self, itemtype, cnf={}, *, master=None, **kw):<tab><IF-STMT><tab><tab>if ""refwindow"" in kw:<tab><tab><tab>master = kw[""refwindow""]<tab><tab>elif ""refwindow"" in cnf:<tab><tab><tab>master = cnf[""refwindow""]<tab><tab>else:<tab><tab><tab>master = tkinter._default_root<tab><tab><tab>if not master:<tab><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab><tab>""Too early to create display style: "" ""no root window""<tab><tab><tab><tab>)<tab>self.tk = master.tk<tab>self.stylename = self.tk.call(""tixDisplayStyle"", itemtype, *self._options(cnf, kw))",0,if not master :,if master is None :,0.045150551,14.05853313,0.277777778
"def serialize_groups_for_summary(node):<tab>groups = node.osf_groups<tab>n_groups = len(groups)<tab>group_string = """"<tab>for index, group in enumerate(groups):<tab><tab><IF-STMT><tab><tab><tab>separator = """"<tab><tab>elif index == n_groups - 2:<tab><tab><tab>separator = "" & ""<tab><tab>else:<tab><tab><tab>separator = "", ""<tab><tab>group_string = group_string + group.name + separator<tab>return group_string",1,if index == n_groups - 1 :,if index == n_groups - 1 :,0.75,100,1
"def do(txn):<tab>txn.execute(<tab><tab>""SELECT valid_to, mode, caseset, spec FROM testspec WHERE id = ?"", [specId]<tab>)<tab>row = txn.fetchone()<tab>if row is None:<tab><tab>raise Exception(""no test specification with ID '%s'"" % specId)<tab>else:<tab><tab>validTo, mode, caseset, spec = row<tab><tab>if validTo is not None:<tab><tab><tab>raise Exception(""test spec no longer active"")<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""case set %s not loaded in database"" % caseset)<tab><tab>spec = json.loads(spec)<tab><tab>res = self._css[caseset].generateCasesByTestee(spec)<tab><tab>return res",0,if not self . _css . has_key ( caseset ) :,if caseset not in self . _css :,0.059060244,20.36526898,0.320512821
"def get_and_set_titles(self):<tab>all_titles = []<tab>for page in self.pages:<tab><tab>if page.orig_phrase != """":<tab><tab><tab>all_titles.append(page.orig_phrase)<tab><tab><tab>all_titles.append(page.orig_phrase_norm)<tab><tab><IF-STMT><tab><tab><tab>all_titles.append(page.wiki_title)<tab><tab><tab>all_titles.append(page.wiki_title_norm)<tab>return set(all_titles)",1,"if page . wiki_title != """" :","if page . wiki_title != """" :",0.75,100,1
"def spool_print(*args, **kwargs):<tab>with _print_lock:<tab><tab><IF-STMT><tab><tab><tab>framework.Framework._spool.write(f""{args[0]}{os.linesep}"")<tab><tab><tab>framework.Framework._spool.flush()<tab><tab># disable terminal output for server jobs<tab><tab>if framework.Framework._mode == Mode.JOB:<tab><tab><tab>return<tab><tab># new print function must still use the old print function via the backup<tab><tab>builtins._print(*args, **kwargs)",0,if framework . Framework . _spool :,if framework . Framework . _spool is not None :,0.469545345,59.00468726,0.454545455
"def matches(self, filepath):<tab>matched = False<tab>parent_path = os.path.dirname(filepath)<tab>parent_path_dirs = split_path(parent_path)<tab>for pattern in self.patterns:<tab><tab>negative = pattern.exclusion<tab><tab>match = pattern.match(filepath)<tab><tab><IF-STMT><tab><tab><tab>if len(pattern.dirs) <= len(parent_path_dirs):<tab><tab><tab><tab>match = pattern.match(<tab><tab><tab><tab><tab>os.path.sep.join(parent_path_dirs[: len(pattern.dirs)])<tab><tab><tab><tab>)<tab><tab>if match:<tab><tab><tab>matched = not negative<tab>return matched",0,"if not match and parent_path != """" :",if negative :,0.016200585,1.00E-10,0.3
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.task_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""Task%s {\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + ""}\n""<tab><tab>cnt += 1<tab>return res",1,if printElemNumber :,if printElemNumber :,0.531170663,1.00E-10,1
"def when(self, matches, context):<tab>ret = []<tab>for to_check in matches.range(<tab><tab>predicate=lambda match: ""has-neighbor-before"" in match.tags<tab>):<tab><tab>next_match = matches.next(to_check, index=0)<tab><tab>next_group = matches.markers.next(<tab><tab><tab>to_check, lambda marker: marker.name == ""group"", 0<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>next_match = next_group<tab><tab>if next_match and not matches.input_string[<tab><tab><tab>to_check.end : next_match.start<tab><tab>].strip(seps):<tab><tab><tab>break<tab><tab>ret.append(to_check)<tab>return ret",0,if next_group and ( not next_match or next_group . start < next_match . start ) :,if next_group :,0.00928478,1.00E-10,0.3
"def get_coeffs(e):<tab>coeffs = []<tab>for du in all_delu_dict.keys():<tab><tab>if type(self.as_coeffs_dict[e]).__name__ == ""float"":<tab><tab><tab>coeffs.append(self.as_coeffs_dict[e])<tab><tab><IF-STMT><tab><tab><tab>coeffs.append(self.as_coeffs_dict[e][du])<tab><tab>else:<tab><tab><tab>coeffs.append(0)<tab>return np.array(coeffs)",0,elif du in self . as_coeffs_dict [ e ] . keys ( ) :,"elif type ( self . as_coeffs_dict [ e ] [ du ] ) . __name__ == ""float"" :",0.276435316,34.48770893,0.245
"def clean(self):<tab>username = self.cleaned_data.get(""username"")<tab>password = self.cleaned_data.get(""password"")<tab>message = ERROR_MESSAGE<tab>if username and password:<tab><tab>self.user_cache = authenticate(username=username, password=password)<tab><tab>if self.user_cache is None:<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>message % {""username"": self.username_field.verbose_name}<tab><tab><tab>)<tab>return self.cleaned_data",0,elif not self . user_cache . is_active or not self . user_cache . is_staff :,if not self . user_cache . is_active :,0.213370357,33.04824641,0.365079365
"def moveFailedFolder(filepath, failed_folder):<tab>if config.Config().failed_move():<tab><tab>root_path = str(pathlib.Path(filepath).parent)<tab><tab>file_name = pathlib.Path(filepath).name<tab><tab>destination_path = root_path + ""/"" + failed_folder + ""/""<tab><tab><IF-STMT><tab><tab><tab>print(""[-]Create symlink to Failed output folder"")<tab><tab><tab>os.symlink(filepath, destination_path + ""/"" + file_name)<tab><tab>else:<tab><tab><tab>print(""[-]Move to Failed output folder"")<tab><tab><tab>shutil.move(filepath, destination_path)<tab>return",0,if config . Config ( ) . soft_link ( ) :,"if os . path . exists ( destination_path + ""/"" + file_name ) :",0.023729029,5.237520761,0.325396825
"def test_save_mp3(self, test_mode, bit_rate):<tab>if test_mode in [""fileobj"", ""bytesio""]:<tab><tab><IF-STMT><tab><tab><tab>raise unittest.SkipTest(<tab><tab><tab><tab>""mp3 format with variable bit rate is known to ""<tab><tab><tab><tab>""not yield the exact same result as sox command.""<tab><tab><tab>)<tab>self.assert_save_consistency(""mp3"", compression=bit_rate, test_mode=test_mode)",0,if bit_rate is not None and bit_rate < 1 :,if bit_rate != 0 :,0.025595153,17.26760605,0.208333333
"def _upstream_nodes_executed(self, node: pipeline_pb2.PipelineNode) -> bool:<tab>""""""Returns `True` if all the upstream nodes have been successfully executed.""""""<tab>upstream_nodes = [<tab><tab>node<tab><tab>for node_id, node in self._node_map.items()<tab><tab>if node_id in set(node.upstream_nodes)<tab>]<tab>if not upstream_nodes:<tab><tab>return True<tab>for node in upstream_nodes:<tab><tab>upstream_node_executions = task_gen_utils.get_executions(<tab><tab><tab>self._mlmd_handle, node<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>return False<tab>return True",0,if not task_gen_utils . is_latest_execution_successful ( upstream_node_executions ) :,if upstream_node_executions is None :,0.016838046,10.59523677,0.384615385
"def reinit():<tab>for name, var in _ns_registry._registry[u""pixie.stdlib""]._registry.iteritems():<tab><tab>name = munge(name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if var.is_defined() and isinstance(var.deref(), BaseCode):<tab><tab><tab>globals()[name] = unwrap(var)<tab><tab>else:<tab><tab><tab>globals()[name] = var",0,if name in globals ( ) :,if name is None :,0.113834581,15.84873897,0.428571429
"def i2repr(self, pkt, x):<tab>if type(x) is list or type(x) is tuple:<tab><tab>return repr(x)<tab><IF-STMT><tab><tab>r = []<tab>else:<tab><tab>r = """"<tab>i = 0<tab>while x:<tab><tab>if x & 1:<tab><tab><tab>if self.multi:<tab><tab><tab><tab>r += [self.names[i]]<tab><tab><tab>else:<tab><tab><tab><tab>r += self.names[i]<tab><tab>i += 1<tab><tab>x >>= 1<tab>if self.multi:<tab><tab>r = ""+"".join(r)<tab>return r",0,if self . multi :,if x & 1 :,0.034123066,12.7033187,0.333333333
"def prompts_dict(self, *args, **kwargs):<tab>r = super(WorkflowJobNode, self).prompts_dict(*args, **kwargs)<tab># Explanation - WFJT extra_vars still break pattern, so they are not<tab># put through prompts processing, but inventory and others are only accepted<tab># if JT prompts for it, so it goes through this mechanism<tab>if self.workflow_job:<tab><tab>if self.workflow_job.inventory_id:<tab><tab><tab># workflow job inventory takes precedence<tab><tab><tab>r[""inventory""] = self.workflow_job.inventory<tab><tab><IF-STMT><tab><tab><tab>r.update(self.workflow_job.char_prompts)<tab>return r",0,if self . workflow_job . char_prompts :,elif self . workflow_job . char_prompts :,0.382940898,89.31539818,0.5
"def did_evm_write_storage_callback(self, state, address, offset, value):<tab># if in potential DAO check that write to storage values read before<tab># the ""send""<tab>for location, reads in self._get_location_and_reads(state):<tab><tab>for address_i, offset_i in reads:<tab><tab><tab>if address_i == address:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.add_finding(state, *location)",0,if state . can_be_true ( offset == offset_i ) :,if offset_i == offset :,0.0657907,12.06087682,0.483333333
"def update_quality_inspection(self):<tab>if self.inspection_required:<tab><tab>reference_type = reference_name = """"<tab><tab><IF-STMT><tab><tab><tab>reference_name = self.name<tab><tab><tab>reference_type = ""Stock Entry""<tab><tab>for d in self.items:<tab><tab><tab>if d.quality_inspection:<tab><tab><tab><tab>frappe.db.set_value(<tab><tab><tab><tab><tab>""Quality Inspection"",<tab><tab><tab><tab><tab>d.quality_inspection,<tab><tab><tab><tab><tab>{<tab><tab><tab><tab><tab><tab>""reference_type"": reference_type,<tab><tab><tab><tab><tab><tab>""reference_name"": reference_name,<tab><tab><tab><tab><tab>},<tab><tab><tab><tab>)",0,if self . docstatus == 1 :,if self . name :,0.094532291,23.45000811,0.476190476
"def _target(self):<tab><IF-STMT><tab><tab>self.setup.push_thread()<tab>try:<tab><tab>while self.running:<tab><tab><tab>record = self.subscriber.recv()<tab><tab><tab>if record:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self.queue.put(record, timeout=0.05)<tab><tab><tab><tab>except Full:<tab><tab><tab><tab><tab>pass<tab>finally:<tab><tab>if self.setup is not None:<tab><tab><tab>self.setup.pop_thread()",1,if self . setup is not None :,if self . setup is not None :,0.75,100,1
"def check(self):<tab>global MySQLdb<tab>import MySQLdb<tab>try:<tab><tab>args = {}<tab><tab><IF-STMT><tab><tab><tab>args[""user""] = mysql_user<tab><tab>if mysql_pwd:<tab><tab><tab>args[""passwd""] = mysql_pwd<tab><tab>if mysql_host:<tab><tab><tab>args[""host""] = mysql_host<tab><tab>if mysql_port:<tab><tab><tab>args[""port""] = mysql_port<tab><tab>if mysql_socket:<tab><tab><tab>args[""unix_socket""] = mysql_socket<tab><tab>self.db = MySQLdb.connect(**args)<tab>except Exception as e:<tab><tab>raise Exception(""Cannot interface with MySQL server: %s"" % e)",1,if mysql_user :,if mysql_user :,0.531170663,1.00E-10,1
"def writeBool(self, bool):<tab>if self.state == BOOL_WRITE:<tab><tab><IF-STMT><tab><tab><tab>ctype = CompactType.TRUE<tab><tab>else:<tab><tab><tab>ctype = CompactType.FALSE<tab><tab>self.__writeFieldHeader(ctype, self.__bool_fid)<tab>elif self.state == CONTAINER_WRITE:<tab><tab>if bool:<tab><tab><tab>self.__writeByte(CompactType.TRUE)<tab><tab>else:<tab><tab><tab>self.__writeByte(CompactType.FALSE)<tab>else:<tab><tab>raise AssertionError(""Invalid state in compact protocol"")",1,if bool :,if bool :,0.531170663,1.00E-10,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_version(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_instances(d.getVarInt64())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def init_panel(self):<tab>if not hasattr(self, ""output_view""):<tab><tab><IF-STMT><tab><tab><tab>self.output_view = self.window.create_output_panel(""markdown"")<tab><tab>else:<tab><tab><tab>self.output_view = self.window.get_output_panel(""markdown"")",0,if is_ST3 ( ) :,"if hasattr ( self . window , ""create_output_panel"" ) :",0.047950876,6.150343144,0.36
"def sql(self, engine):<tab>adapter = get_adapter(engine)<tab>tokens = [self.name, adapter.type_to_sql(self.type, self.limit)]<tab>for k, v in self.options.items():<tab><tab>result = adapter.column_option_to_sql(self.name, k, v)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(result, dict):  # a way for column options to add constraints<tab><tab><tab>self.constraints.append(result[""constraint""])<tab><tab>else:<tab><tab><tab>tokens.append(result)<tab>return "" "".join(tokens)",1,if result is None :,if result is None :,0.75,100,1
def get_igst_invoices(self):<tab>self.igst_invoices = []<tab>for d in self.tax_details:<tab><tab>is_igst = True if d[1] in self.gst_accounts.igst_account else False<tab><tab><IF-STMT><tab><tab><tab>self.igst_invoices.append(d[0]),0,if is_igst and d [ 0 ] not in self . igst_invoices :,if is_igst :,0.012878079,1.00E-10,0.208333333
"def updateParticle(part, best, phi1, phi2):<tab>u1 = numpy.random.uniform(0, phi1, len(part))<tab>u2 = numpy.random.uniform(0, phi2, len(part))<tab>v_u1 = u1 * (part.best - part)<tab>v_u2 = u2 * (best - part)<tab>part.speed += v_u1 + v_u2<tab>for i, speed in enumerate(part.speed):<tab><tab>if abs(speed) < part.smin:<tab><tab><tab>part.speed[i] = math.copysign(part.smin, speed)<tab><tab><IF-STMT><tab><tab><tab>part.speed[i] = math.copysign(part.smax, speed)<tab>part += part.speed",1,elif abs ( speed ) > part . smax :,elif abs ( speed ) > part . smax :,0.75,100,1
"def summaries_with_matching_keyword(keyword, summary_dir):<tab>""""""Yields summary protos matching given keyword from event file.""""""<tab>event_paths = tf.io.gfile.glob(os.path.join(summary_dir, ""events*""))<tab>for event in tf.compat.v1.train.summary_iterator(event_paths[-1]):<tab><tab><IF-STMT><tab><tab><tab>for value in event.summary.value:<tab><tab><tab><tab>if keyword in value.tag:<tab><tab><tab><tab><tab>logging.error(event)<tab><tab><tab><tab><tab>yield event.summary",0,if event . summary is not None :,if event . summary :,0.234334509,38.80684295,0.510204082
"def _RemoveToken(self, doc_id, token):<tab>""""""Removes a token occurrence for a document.""""""<tab>if token in self._inverted_index:<tab><tab>postings = self._inverted_index[token]<tab><tab>postings.Remove(doc_id, token.position)<tab><tab><IF-STMT><tab><tab><tab>del self._inverted_index[token]",0,if not postings . postings :,if len ( postings ) == 0 :,0.023749772,6.274655311,0.444444444
"def check_recursive_filters(self, space, name):<tab>for the_filter in self.filterdb.get_filters(space):<tab><tab>for rule in the_filter.get_rules():<tab><tab><tab>values = list(rule.values())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",0,"if issubclass ( rule . __class__ , MatchesFilterBase ) and ( name in values ) :",if values [ 0 ] . lower ( ) == name . lower ( ) :,0.019292111,5.584070314,0.171717172
"def main():<tab>for filename in sys.argv[1:]:<tab><tab>if os.path.isdir(filename):<tab><tab><tab>print(filename, ""Directory!"")<tab><tab><tab>continue<tab><tab>with open(filename, ""rb"") as f:<tab><tab><tab>data = f.read()<tab><tab><IF-STMT><tab><tab><tab>print(filename, ""Binary!"")<tab><tab><tab>continue<tab><tab>newdata = data.replace(b""\r\n"", b""\n"")<tab><tab>if newdata != data:<tab><tab><tab>print(filename)<tab><tab><tab>with open(filename, ""wb"") as f:<tab><tab><tab><tab>f.write(newdata)",0,"if b""\0"" in data :",if not data :,0.070152444,10.12947424,0.6
"def fit(self, dataset, intent):<tab>self.language = dataset[""language""]<tab>self.slots_keywords = dict()<tab>utterances = dataset[""intents""][intent][""utterances""]<tab>for utterance in utterances:<tab><tab>for chunk in utterance[""data""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text = chunk[""text""]<tab><tab><tab><tab>if self.config.get(""lowercase"", False):<tab><tab><tab><tab><tab>text = text.lower()<tab><tab><tab><tab>self.slots_keywords[text] = [chunk[""entity""], chunk[""slot_name""]]<tab>return self",0,"if ""slot_name"" in chunk :","if chunk [ ""type"" ] == ""text"" :",0.02800146,4.619215105,0.477272727
"def linkGradient(self, slaveGradient, connect=True):<tab>if connect:<tab><tab>fn = lambda g, slave=slaveGradient: slave.restoreState(g.saveState())<tab><tab>self.linkedGradients[id(slaveGradient)] = fn<tab><tab>self.sigGradientChanged.connect(fn)<tab><tab>self.sigGradientChanged.emit(self)<tab>else:<tab><tab>fn = self.linkedGradients.get(id(slaveGradient), None)<tab><tab><IF-STMT><tab><tab><tab>self.sigGradientChanged.disconnect(fn)",0,if fn :,if fn is not None :,0.090364769,1.00E-10,0.4
"def _get_field_values(serial_str, field_name):<tab>ret_list = []<tab>stream = StringIO(serial_str)<tab>for obj_dict in yaml.safe_load(stream):<tab><tab><IF-STMT><tab><tab><tab>field_value = obj_dict[""fields""][field_name]<tab><tab><tab># yaml.safe_load will return non-string objects for some<tab><tab><tab># of the fields we are interested in, this ensures that<tab><tab><tab># everything comes back as a string<tab><tab><tab>if isinstance(field_value, six.string_types):<tab><tab><tab><tab>ret_list.append(field_value)<tab><tab><tab>else:<tab><tab><tab><tab>ret_list.append(str(field_value))<tab>return ret_list",0,"if ""fields"" in obj_dict and field_name in obj_dict [ ""fields"" ] :","if field_name in obj_dict [ ""fields"" ] :",0.380222001,52.88662908,0.638888889
"def scrapeHeadlines(text):<tab>headlines = """"<tab>lines = text.splitlines()<tab>for line in lines:<tab><tab>if string.find(line, ""<a href"") == 0:<tab><tab><tab>pos1 = string.find(line, ""<b>"")<tab><tab><tab>if pos1 > 0:<tab><tab><tab><tab>pos2 = string.find(line, ""</b>"")<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>headlines += line[pos1 + len(""<b>"") : pos2] + "".\n""<tab>return headlines",1,if pos2 > 0 :,if pos2 > 0 :,0.75,100,1
"def getCVEActions(self, cve, **args):<tab>actions = []<tab>for plugin in self.getWebPlugins():<tab><tab>try:<tab><tab><tab>actions_ = plugin.getCVEActions(cve, **args)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for action in actions_:<tab><tab><tab><tab><tab>action[""auth""] = plugin.requiresAuth<tab><tab><tab><tab><tab>action[""plugin""] = plugin.getUID()<tab><tab><tab><tab><tab>actions.append(action)<tab><tab>except Exception as e:<tab><tab><tab>print(""[!] Plugin %s failed on fetching CVE actions!"" % plugin.getName())<tab><tab><tab>print(""[!]  -> %s"" % e)<tab>return actions",1,if actions_ :,if actions_ :,0.531170663,1.00E-10,1
"def _sensors_to_fields(oldrec, sensor_map):<tab># map a record with observation names to a record with db field names<tab>if oldrec:<tab><tab>newrec = dict()<tab><tab>for k in sensor_map:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>newrec[k] = oldrec[sensor_map[k]]<tab><tab>if newrec:<tab><tab><tab>newrec[""dateTime""] = oldrec[""dateTime""]<tab><tab><tab>newrec[""usUnits""] = oldrec[""usUnits""]<tab><tab><tab>return newrec<tab>return None",0,if sensor_map [ k ] in oldrec :,if k in oldrec :,0.082324466,16.62083001,1
"def rdd_generator():<tab>while not tf_feed.should_stop():<tab><tab>batch = tf_feed.next_batch(1)<tab><tab><IF-STMT><tab><tab><tab>features = batch[""x""][0]<tab><tab><tab>label = batch[""y_""][0]<tab><tab><tab>yield (features, label)<tab><tab>else:<tab><tab><tab>return",0,"if len ( batch [ ""x"" ] ) > 0 :","if batch [ ""x"" ] [ 0 ] :",0.180287712,42.60440569,0.386666667
"def _get_modules(fn):<tab>finder = modulefinder.ModuleFinder()<tab>finder.run_script(fn)<tab>all = []<tab>for m in finder.modules.values():<tab><tab>if not isinstance(m, modulefinder.Module):<tab><tab><tab>continue<tab><tab>if not m.__file__:<tab><tab><tab>continue<tab><tab># skip shared object files<tab><tab>if m.__file__.endswith("".so""):<tab><tab><tab>continue<tab><tab># skip mac system stuff...<tab><tab># FIXME: would need to augment with  other OS's system stuff<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>all.append(m)<tab>return all",0,"if m . __file__ . startswith ( ""/Library/Frameworks"" ) :","if m . __name__ . startswith ( ""mac"" ) :",0.350669154,50.80357863,1
"def clean(self):<tab>d = super().clean()<tab>if d[""issue_giftcard""]:<tab><tab>if d[""tax_rule""] and d[""tax_rule""].rate > 0:<tab><tab><tab>self.add_error(<tab><tab><tab><tab>""tax_rule"",<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""Gift card products should not be associated with non-zero tax rates since sales tax will be applied when the gift card is redeemed.""<tab><tab><tab><tab>),<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>self.add_error(<tab><tab><tab><tab>""admission"",<tab><tab><tab><tab>_(<tab><tab><tab><tab><tab>""Gift card products should not be admission products at the same time.""<tab><tab><tab><tab>),<tab><tab><tab>)<tab>return d",0,"if d [ ""admission"" ] :","if d [ ""admission"" ] and d [ ""admission"" ] . rate > 0 :",0.346522668,31.87271473,0.414141414
"def is_filtered_inherited_member(name: str, obj: Any) -> bool:<tab>if inspect.isclass(self.object):<tab><tab>for cls in self.object.__mro__:<tab><tab><tab>if cls.__name__ == self.options.inherited_members and cls != self.object:<tab><tab><tab><tab># given member is a member of specified *super class*<tab><tab><tab><tab>return True<tab><tab><tab>elif name in cls.__dict__:<tab><tab><tab><tab>return False<tab><tab><tab>elif name in self.get_attr(cls, ""__annotations__"", {}):<tab><tab><tab><tab>return False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab>return False",0,"elif isinstance ( obj , ObjectMember ) and obj . class_ is cls :","elif name in self . get_attr ( cls , ""__dict__"" , { } ) :",0.09451669,2.769348116,0.165775401
"def dictToKW(d):<tab>out = []<tab>items = list(d.items())<tab>items.sort()<tab>for k, v in items:<tab><tab>if not isinstance(k, str):<tab><tab><tab>raise NonFormattableDict(""%r ain't a string"" % k)<tab><tab><IF-STMT><tab><tab><tab>raise NonFormattableDict(""%r ain't an identifier"" % k)<tab><tab>out.append(""\n\0{}={},"".format(k, prettify(v)))<tab>return """".join(out)",0,if not r . match ( k ) :,"if not k . startswith ( ""_"" ) :",0.104182608,12.1920916,0.412698413
"def report_add_status(torrentlist, succ_cnt, fail_cnt, fail_msgs):<tab>if fail_cnt == 0:<tab><tab>torrentlist.report_message(<tab><tab><tab>""Torrents Added"", ""{!success!}Successfully added %d torrent(s)"" % succ_cnt<tab><tab>)<tab>else:<tab><tab>msg = (<tab><tab><tab>""{!error!}Failed to add the following %d torrent(s):\n {!input!}"" % fail_cnt<tab><tab>) + ""\n "".join(fail_msgs)<tab><tab><IF-STMT><tab><tab><tab>msg += ""\n \n{!success!}Successfully added %d torrent(s)"" % succ_cnt<tab><tab>torrentlist.report_message(""Torrent Add Report"", msg)",0,if succ_cnt != 0 :,if fail_cnt > 0 :,0.314978772,17.02611698,1
"def merge(self, other):<tab>d = self._name2ft<tab>for name, (f, t) in other._name2ft.items():<tab><tab><IF-STMT><tab><tab><tab># Don't print here by default, since doing<tab><tab><tab>#<tab> so breaks some of the buildbots<tab><tab><tab># print(""*** DocTestRunner.merge: '"" + name + ""' in both"" \<tab><tab><tab>#<tab>"" testers; summing outcomes."")<tab><tab><tab>f2, t2 = d[name]<tab><tab><tab>f = f + f2<tab><tab><tab>t = t + t2<tab><tab>d[name] = f, t",1,if name in d :,if name in d :,0.75,100,1
"def handle_command(self, parameters):<tab>response = """"<tab>for ip_token in parameters:<tab><tab><IF-STMT><tab><tab><tab>ip = netaddr.IPNetwork(ip_token)[0]<tab><tab><tab>if not (ip.is_loopback() or ip.is_private() or ip.is_reserved()):<tab><tab><tab><tab>response += ""{0} location: {1}\n"".format(<tab><tab><tab><tab><tab>ip_token, ip_location(ip_token)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>response += ""{0}: hrm...loopback? private ip?\n"".format(ip_token)<tab><tab>else:<tab><tab><tab>response = ""{0} is not an IP address"".format(ip_token)<tab>return response",0,if is_ip ( ip_token ) :,"if ip_token . startswith ( ""127."" ) :",0.046132298,15.72780094,0.641025641
"def letterrange(first, last, charset):<tab>for k in range(len(last)):<tab><tab>for x in product(*[chain(charset)] * (k + 1)):<tab><tab><tab>result = """".join(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if first != result:<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>first = None<tab><tab><tab>yield result<tab><tab><tab>if result == last:<tab><tab><tab><tab>return",0,if first :,if k == len ( x ) :,0.044228356,1.00E-10,0.3
"def artifacts_base_dir(self):<tab>if not self._artifacts_base_dir:<tab><tab>try:<tab><tab><tab>artifacts_base_dir = os.path.abspath(<tab><tab><tab><tab>self.get_option(self.SECTION, ""artifacts_base_dir"")<tab><tab><tab>)<tab><tab>except ValidationError:<tab><tab><tab>artifacts_base_dir = os.path.abspath(""logs"")<tab><tab><IF-STMT><tab><tab><tab>os.makedirs(artifacts_base_dir)<tab><tab><tab>os.chmod(self.artifacts_base_dir, 0o755)<tab><tab>self._artifacts_base_dir = artifacts_base_dir<tab>return self._artifacts_base_dir",1,if not os . path . exists ( artifacts_base_dir ) :,if not os . path . exists ( artifacts_base_dir ) :,0.75,100,1
"def _extract_changes(doc_map, changes, read_time):<tab>deletes = []<tab>adds = []<tab>updates = []<tab>for name, value in changes.items():<tab><tab>if value == ChangeType.REMOVED:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>deletes.append(name)<tab><tab>elif name in doc_map:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>updates.append(value)<tab><tab>else:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>adds.append(value)<tab>return (deletes, adds, updates)",1,if name in doc_map :,if name in doc_map :,0.75,100,1
"def __setattr__(self, name, val):<tab>BitmapSprite.__setattr__(self, name, val)<tab>if name in (<tab><tab>""name"",<tab><tab>""size"",<tab>):  # no other reason to discard cache than just on path change<tab><tab><IF-STMT><tab><tab><tab>self.image_data = self.theme.load_icon(self.name, self.size, 0)<tab><tab>else:<tab><tab><tab>self.image_data = None",0,"if self . __dict__ . get ( ""name"" ) and self . __dict__ . get ( ""size"" ) :",if self . image_data is None :,0.023258212,1.749799632,0.370748299
"def extract_deps(file):<tab># ~ print('Extracting from %s' % file)<tab>deps = set()<tab>for line in open(file).readlines():<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>words = line.split()<tab><tab><tab>if words[0] == ""import"" or (words[0] == ""from"" and words[2] == ""import""):<tab><tab><tab><tab>deps.add(words[1])<tab>return deps",0,"if line . startswith ( ""import"" ) or line . startswith ( ""from"" ) :",if line :,0.051894021,1.00E-10,0.496969697
"def run_query(self, query, user):<tab>connection = self._get_connection()<tab>statement = None<tab>error = None<tab>try:<tab><tab>statement = connection.execute(query)<tab><tab>columns = [<tab><tab><tab>{""name"": n, ""friendly_name"": n, ""type"": _type_mapper(t)}<tab><tab><tab>for (n, t) in statement.columns().items()<tab><tab>]<tab><tab>cnames = statement.column_names()<tab><tab>rows = [dict(zip(cnames, row)) for row in statement]<tab><tab>data = {""columns"": columns, ""rows"": rows}<tab><tab>json_data = json_dumps(data)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>statement.close()<tab><tab>connection.close()<tab>return json_data, error",0,if statement is not None :,if statement :,0.050438393,1.00E-10,0.4
"def find_setup_py_above(a_file):<tab>""Return the directory containing setup.py somewhere above *a_file*""<tab>root = os.path.dirname(os.path.abspath(a_file))<tab>while not os.path.exists(os.path.join(root, ""setup.py"")):<tab><tab>prev, root = root, os.path.dirname(root)<tab><tab><IF-STMT><tab><tab><tab># Let's avoid infinite loops at root<tab><tab><tab>raise NoSetupPyFound(""could not find my setup.py above %r"" % (a_file,))<tab>return root",0,if root == prev :,if prev != root :,0.288498786,12.13729429,0.5
"def check_index(self, is_sorted=True, unique=True, index=None):<tab>""""""Sanity checks""""""<tab>if not index:<tab><tab>index = self.index<tab>if is_sorted:<tab><tab>test = pd.DataFrame(lrange(len(index)), index=index)<tab><tab>test_sorted = test.sort()<tab><tab>if not test.index.equals(test_sorted.index):<tab><tab><tab>raise Exception(""Data is not be sorted"")<tab>if unique:<tab><tab><IF-STMT><tab><tab><tab>raise Exception(""Duplicate index entries"")",0,if len ( index ) != len ( index . unique ( ) ) :,if len ( index ) > len ( test_sorted . index ) :,0.473538253,31.01950461,0.789473684
"def _compare_address_strings(self, a, b):<tab># IPv6 address from different requests might be different<tab>a_segments = a.count("":"")<tab>b_segments = b.count("":"")<tab>if a_segments and b_segments:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if a.rstrip("":"").startswith(b.rstrip("":"")) or b.rstrip("":"").startswith(<tab><tab><tab>a.rstrip("":"")<tab><tab>):<tab><tab><tab>return True<tab><tab>if a_segments >= 2 and b_segments >= 2 and a.split("":"")[:2] == b.split("":"")[:2]:<tab><tab><tab>return True<tab>return a.split(""."", 1)[-1] == b.split(""."", 1)[-1]",0,"if a_segments == b_segments and a_segments in ( 4 , 5 , 6 , 7 ) :","if a . rstrip ( "":"" ) . startswith ( b . rstrip ( "":"" ) ) :",0.264949392,4.93668146,0.163043478
"def collect(self):<tab>for vacb in self.GetVACBs():<tab><tab>filename = vacb.SharedCacheMap.FileObject.file_name_with_drive()<tab><tab><IF-STMT><tab><tab><tab>yield (<tab><tab><tab><tab>vacb,<tab><tab><tab><tab>bool(self.kernel_address_space.vtop(vacb.BaseAddress.v())),<tab><tab><tab><tab>vacb.BaseAddress.v(),<tab><tab><tab><tab>vacb.Overlay.FileOffset.QuadPart,<tab><tab><tab><tab>filename,<tab><tab><tab>)",1,if filename :,if filename :,0.531170663,1.00E-10,1
"def _visit_table(self, expr):<tab>node = expr.op()<tab>if isinstance(expr, ir.TableExpr):<tab><tab>base_table = _find_blocking_table(expr)<tab><tab>if base_table is not None:<tab><tab><tab>base_node = base_table.op()<tab><tab><tab>if self._is_root(base_node):<tab><tab><tab><tab>pass<tab><tab><tab>else:<tab><tab><tab><tab># Foreign ref<tab><tab><tab><tab>self.foreign_table = expr<tab>else:<tab><tab><IF-STMT><tab><tab><tab>for arg in node.flat_args():<tab><tab><tab><tab>if isinstance(arg, ir.Expr):<tab><tab><tab><tab><tab>self._visit(arg)",0,if not node . blocks ( ) :,"if isinstance ( node , ir . Expr ) :",0.034527075,11.04479557,0.363636364
"def channel_details(self) -> SnapChannelDetails:<tab>if self._channel_details is None:<tab><tab>channel = self._payload.get(""channel"")<tab><tab><IF-STMT><tab><tab><tab># Shouldn't happen, but raise an error if it does.<tab><tab><tab>raise RuntimeError(f""no channel found for {self._payload!r}"")<tab><tab>self._channel_details = SnapChannelDetails(channel)<tab>return self._channel_details",1,if channel is None :,if channel is None :,0.75,100,1
"def __setattr__(self, attr, val):<tab>if hasattr(self, attr):<tab><tab>old = getattr(self, attr)<tab><tab>if isinstance(old, Setting):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>""Attempting to reassign setting %s with %s"" % (old, val)<tab><tab><tab><tab>)<tab><tab><tab>log.warn(""Setting attr %s via __setattr__ instead of set()!"", attr)<tab><tab><tab>return old.set(val)<tab>log.debug(""Setting {%s => %s}"" % (attr, val))<tab>return object.__setattr__(self, attr, val)",0,"if isinstance ( val , Setting ) :",if old . __name__ != val :,0.019627455,4.456882761,0.481481481
"def FindEnclosingBracketGroup(input_str):<tab>stack = []<tab>start = -1<tab>for index, char in enumerate(input_str):<tab><tab>if char in LBRACKETS:<tab><tab><tab>stack.append(char)<tab><tab><tab>if start == -1:<tab><tab><tab><tab>start = index<tab><tab>elif char in BRACKETS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if stack.pop() != BRACKETS[char]:<tab><tab><tab><tab>return (-1, -1)<tab><tab><tab>if not stack:<tab><tab><tab><tab>return (start, index + 1)<tab>return (-1, -1)",0,if not stack :,if stack . pop ( ) != BRACKETS [ char ] :,0.033077115,4.065425429,0.267857143
"def copy_layer(<tab>layer,<tab>keep_bias=True,<tab>name_template=None,<tab>weights=None,<tab>reuse_symbolic_tensors=True,<tab>**kwargs):<tab>config = layer.get_config()<tab>if name_template is None:<tab><tab>config[""name""] = None<tab>else:<tab><tab>config[""name""] = name_template % config[""name""]<tab>if keep_bias is False and config.get(""use_bias"", False):<tab><tab>config[""use_bias""] = False<tab><tab>if weights is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>weights = layer.weights[:-1]<tab><tab><tab>else:<tab><tab><tab><tab>weights = layer.get_weights()[:-1]<tab>return get_layer_from_config(layer, config, weights=weights, **kwargs)",0,if reuse_symbolic_tensors :,if use_symbolic_tensors :,0.319750449,1.00E-10,1
"def find_go_srcs(path):<tab>srcs, tests = [], []<tab>for name in os.listdir(path):<tab><tab>if name.startswith(""."") or not name.endswith("".go""):<tab><tab><tab>continue<tab><tab>if os.path.isfile(os.path.join(path, name)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tests.append(name)<tab><tab><tab>else:<tab><tab><tab><tab>srcs.append(name)<tab>return srcs, tests",0,"if name . endswith ( ""_test.go"" ) :","if name . endswith ( "".go"" ) :",0.549040681,67.80814774,1
"def first_text(self, node):<tab>""""""find first paragraph to use as a summary""""""<tab>if node.tagname == ""paragraph"":<tab><tab>return deepcopy(node)<tab>else:<tab><tab>for child in node:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ans = self.first_text(child)<tab><tab><tab><tab>if ans:<tab><tab><tab><tab><tab>return ans<tab>return None",0,"if hasattr ( child , ""tagname"" ) :","if isinstance ( child , NavigableString ) :",0.091668085,21.06976474,0.481481481
def ServerInference(self):<tab>candidates = []<tab>score = []<tab>for symbol in self.symbols:<tab><tab>for m in symbol.getMessages():<tab><tab><tab>dst = m.getPattern()[0]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>score[candidates.index(dst)] += 1<tab><tab><tab>else:<tab><tab><tab><tab>candidates.append(dst)<tab><tab><tab><tab>score.append(1)<tab>print(candidates)<tab>if score.count(max(score)) == 1 and len(candidates) > 2:<tab><tab>self.server = candidates[score.index(max(score))],1,if dst in candidates :,if dst in candidates :,0.75,100,1
"def generateMapItemTypedNode(self, key, value):<tab>if type(value) == SigmaRegularExpressionModifier:<tab><tab>regex = str(value)<tab><tab># Regular Expressions have to match the full value in QRadar<tab><tab>if not (regex.startswith(""^"") or regex.startswith("".*"")):<tab><tab><tab>regex = "".*"" + regex<tab><tab><IF-STMT><tab><tab><tab>regex = regex + "".*""<tab><tab>return ""%s MATCHES %s"" % (self.cleanKey(key), self.generateValueNode(regex))<tab>else:<tab><tab>raise NotImplementedError(<tab><tab><tab>""Type modifier '{}' is not supported by backend"".format(value.identifier)<tab><tab>)",0,"if not ( regex . endswith ( ""$"" ) or regex . endswith ( "".*"" ) ) :","elif not ( regex . startswith ( "".*"" ) or regex . startswith ( "".*"" ) ) :",0.623339407,55.99981854,0.5
"def get_max_vertical_scroll() -> int:<tab># Make sure that the cursor line is not above the top.<tab>prev_lineno = ui_content.cursor_position.y<tab>used_height = 0<tab>for lineno in range(ui_content.cursor_position.y - 1, -1, -1):<tab><tab>used_height += get_line_height(lineno)<tab><tab><IF-STMT><tab><tab><tab>return prev_lineno<tab><tab>else:<tab><tab><tab>prev_lineno = lineno<tab>return prev_lineno",0,if used_height > scroll_offsets_top :,if used_height > scroll_min_scroll_height :,0.394778655,50.08718429,1
"def _options_values(self):<tab>""""""Simulate option values for partially configured objects.""""""<tab>try:<tab><tab>return self.__options_values<tab>except AttributeError:<tab><tab>self.__options_values = {**self.keywords}<tab><tab>position = 0<tab><tab>for name, option in self.func.__options__:<tab><tab><tab>if not option.positional:<tab><tab><tab><tab>break  # no positional left<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue  # already fulfilled<tab><tab><tab>self.__options_values[name] = (<tab><tab><tab><tab>self.args[position] if len(self.args) >= position + 1 else None<tab><tab><tab>)<tab><tab><tab>position += 1<tab><tab>return self.__options_values",1,if name in self . keywords :,if name in self . keywords :,0.75,100,1
"def key(self):<tab>addr = self.m(""key"").obj_offset<tab>addr = self.read_ptr(addr)<tab>ret = """"<tab>if addr:<tab><tab>ret = self.obj_vm.read(addr, 256)<tab><tab><IF-STMT><tab><tab><tab>idx = ret.find(""\x00"")<tab><tab><tab>if idx != -1:<tab><tab><tab><tab>ret = ret[:idx]<tab><tab>else:<tab><tab><tab>ret = """"<tab>return ret",1,if ret :,if ret :,0.531170663,1.00E-10,1
"def get_file_path(self, filepath, token):<tab>try:<tab><tab>encoded_path, _, user = self.updown_auth_manager.get_resource_info(token)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""Invalid path file!! %s: %s"" % (user, filepath))<tab><tab><tab>raise NotFoundException(""File not found"")<tab><tab>logger.debug(""Get file: user=%s path=%s"" % (user, filepath))<tab><tab>file_path = os.path.normpath(os.path.join(self.base_store_folder, encoded_path))<tab><tab>return file_path<tab>except (jwt.ExpiredSignature, jwt.DecodeError, AttributeError):<tab><tab>raise NotFoundException(""File not found"")",0,"if not self . _valid_path ( filepath , encoded_path ) :",if not encoded_path :,0.021820195,7.510361916,0.575
def validate_and_handle(self):<tab>valid = self.validate(set_cursor=True)<tab>if valid:<tab><tab><IF-STMT><tab><tab><tab>keep_text = self.accept_handler(self)<tab><tab>else:<tab><tab><tab>keep_text = False<tab><tab>if not keep_text:<tab><tab><tab>self.reset(),1,if self . accept_handler :,if self . accept_handler :,0.75,100,1
"def document_type(self):<tab>if isinstance(self.document_type_obj, basestring):<tab><tab><IF-STMT><tab><tab><tab>self.document_type_obj = self.owner_document<tab><tab>else:<tab><tab><tab>self.document_type_obj = get_document(self.document_type_obj)<tab>return self.document_type_obj",0,if self . document_type_obj == RECURSIVE_REFERENCE_CONSTANT :,"if self . document_type_obj == ""owner"" :",0.386613272,60.08311033,1
"def _get_closest_end(end_after, begin_after):<tab>""""""returns the closest \\end, that is open""""""<tab>end_iter = iter(end_after)<tab>begin_iter = iter(begin_after)<tab>while True:<tab><tab>try:<tab><tab><tab>e = next(end_iter)<tab><tab>except:<tab><tab><tab>raise NoEnvError(""No closing environment detected"")<tab><tab>try:<tab><tab><tab>b = next(begin_iter)<tab><tab>except:<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>break<tab>return e",0,if not e . begin ( ) > b . begin ( ) :,if e . is_open ( b ) :,0.024198094,9.150273712,0.307017544
"def group_curves(self, curves):<tab>result = [[curves[0]]]<tab>tolerance = self.concat_tolerance<tab>for curve1, curve2 in zip(curves, curves[1:]):<tab><tab>_, t_max_1 = curve1.get_u_bounds()<tab><tab>t_min_2, _ = curve2.get_u_bounds()<tab><tab>end1 = curve1.evaluate(t_max_1)<tab><tab>begin2 = curve2.evaluate(t_min_2)<tab><tab>distance = np.linalg.norm(begin2 - end1)<tab><tab><IF-STMT><tab><tab><tab>result.append([curve2])<tab><tab>else:<tab><tab><tab>result[-1].append(curve2)<tab>return result",0,if distance > tolerance :,if distance < tolerance :,0.081415021,30.21375397,1
"def iteraddcolumn(table, field, col, index, missing):<tab>it = iter(table)<tab>hdr = next(it)<tab># determine position of new column<tab>if index is None:<tab><tab>index = len(hdr)<tab># construct output header<tab>outhdr = list(hdr)<tab>outhdr.insert(index, field)<tab>yield tuple(outhdr)<tab># construct output data<tab>for row, val in izip_longest(it, col, fillvalue=missing):<tab><tab># run out of rows?<tab><tab><IF-STMT><tab><tab><tab>row = [missing] * len(hdr)<tab><tab>outrow = list(row)<tab><tab>outrow.insert(index, val)<tab><tab>yield tuple(outrow)",0,if row == missing :,if row is None :,0.064978772,19.35769349,0.444444444
"def validate_is_admin(self, attrs, source):<tab>project = attrs.get(""project"", None if self.object is None else self.object.project)<tab>if project is None:<tab><tab>return attrs<tab>if self.object and self.object.user:<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(_(""The project owner must be admin.""))<tab><tab>if not services.project_has_valid_admins(<tab><tab><tab>project, exclude_user=self.object.user<tab><tab>):<tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>_(""At least one user must be an active admin for this project."")<tab><tab><tab>)<tab>return attrs",0,if self . object . user . id == project . owner_id and not attrs [ source ] :,if self . object . user != project . owner :,0.223429702,28.22001889,0.401515152
"def handle_periodic(self):<tab>if self._closed:<tab><tab><IF-STMT><tab><tab><tab>self._eventloop.remove(self._server_socket)<tab><tab><tab>self._server_socket.close()<tab><tab><tab>self._server_socket = None<tab><tab><tab>logging.info(""closed TCP port %d"", self._listen_port)<tab><tab>for handler in list(self._fd_to_handlers.values()):<tab><tab><tab>handler.destroy()<tab>self._sweep_timeout()",0,if self . _server_socket :,if self . _server_socket is not None :,0.351498834,59.00468726,0.444444444
"def get_item(type_, preference):<tab>items = {}<tab>for item in playlist.findall(""./info/%s/item"" % type_):<tab><tab>lang, label = xpath_text(item, ""lg"", default=None), xpath_text(<tab><tab><tab>item, ""label"", default=None<tab><tab>)<tab><tab>if lang and label:<tab><tab><tab>items[lang] = label.strip()<tab>for p in preference:<tab><tab><IF-STMT><tab><tab><tab>return items[p]",0,if items . get ( p ) :,if p in items :,0.020977837,8.290829875,0.333333333
"def save_all_changed_configs(self):<tab>""""""Save configuration changes to the user config file.""""""<tab>has_changes = False<tab>for ext_name in self.extensions:<tab><tab>options = self.extensions[ext_name]<tab><tab>for opt in options:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>has_changes = True<tab>if has_changes:<tab><tab>self.userCfg.Save()",0,"if self . set_user_value ( ext_name , opt ) :","if opt [ ""name"" ] == ext_name :",0.015805905,10.85642129,0.483333333
"def extract_validators(namespace: Dict[str, Any]) -> Dict[str, List[Validator]]:<tab>validators: Dict[str, List[Validator]] = {}<tab>for var_name, value in namespace.items():<tab><tab>validator_config = getattr(value, VALIDATOR_CONFIG_KEY, None)<tab><tab><IF-STMT><tab><tab><tab>fields, v = validator_config<tab><tab><tab>for field in fields:<tab><tab><tab><tab>if field in validators:<tab><tab><tab><tab><tab>validators[field].append(v)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>validators[field] = [v]<tab>return validators",0,if validator_config :,if validator_config is not None :,0.090364769,1.00E-10,0.314285714
"def _bindTable(self, tableName, create=False):<tab>for attempt in retry_azure():<tab><tab>with attempt:<tab><tab><tab>try:<tab><tab><tab><tab>exists = self.tableService.exists(table_name=tableName)<tab><tab><tab>except AzureMissingResourceHttpError as e:<tab><tab><tab><tab>if e.status_code != 404:<tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>if exists:<tab><tab><tab><tab><tab>return AzureTable(self.tableService, tableName)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.tableService.create_table(tableName)<tab><tab><tab><tab>return AzureTable(self.tableService, tableName)<tab><tab><tab>else:<tab><tab><tab><tab>return None",0,if create :,elif create :,0.108673556,1.00E-10,0.5
"def extract(self):<tab>for battery in self.vars:<tab><tab>for line in dopen(""/proc/acpi/battery/"" + battery + ""/state"").readlines():<tab><tab><tab>l = line.split()<tab><tab><tab>if len(l) < 3:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>remaining = int(l[2])<tab><tab><tab><tab>continue<tab><tab><tab>elif l[0:2] == [""present"", ""rate:""]:<tab><tab><tab><tab>rate = int(l[2])<tab><tab><tab><tab>continue<tab><tab>if rate and remaining:<tab><tab><tab>self.val[battery] = remaining * 60 / rate<tab><tab>else:<tab><tab><tab>self.val[battery] = -1",0,"if l [ 0 : 2 ] == [ ""remaining"" , ""capacity:"" ] :","elif l [ 0 : 2 ] == [ ""remaining"" , ""remaining"" ] :",0.394217863,75.06935729,0.666666667
"def merge_syntactic_units(original_units, filtered_units, tags=None):<tab>units = []<tab>for i in range(len(original_units)):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>text = original_units[i]<tab><tab>token = filtered_units[i]<tab><tab>tag = tags[i][1] if tags else None<tab><tab>sentence = SyntacticUnit(text, token, tag)<tab><tab>sentence.index = i<tab><tab>units.append(sentence)<tab>return units",0,"if filtered_units [ i ] == """" :",if filtered_units [ i ] is None :,0.336651519,54.08804419,0.56
"def copy_grads_to_fp32(self, fp16_net, fp32_weights):<tab>""""""Copy gradients from fp16 model to fp32 weight copy.""""""<tab>for fp32_param, fp16_param in zip(fp32_weights, fp16_net.parameters()):<tab><tab><IF-STMT><tab><tab><tab>if fp32_param.grad is None:<tab><tab><tab><tab>fp32_param.grad = fp32_param.data.new(fp32_param.size())<tab><tab><tab>fp32_param.grad.copy_(fp16_param.grad)",0,if fp16_param . grad is not None :,if fp16_param is not None :,0.338772207,53.84952356,0.30952381
"def gen_new_segments(datadir, spk_list):<tab>if not os.path.isfile(os.path.join(datadir, ""segments"")):<tab><tab>raise ValueError(""no segments file found in datadir"")<tab>new_segments = open(os.path.join(datadir, ""new_segments""), ""w"", encoding=""utf-8"")<tab>segments = open(os.path.join(datadir, ""segments""), ""r"", encoding=""utf-8"")<tab>while True:<tab><tab>line = segments.readline()<tab><tab>if not line:<tab><tab><tab>break<tab><tab>spk = line.split(""_"")[0]<tab><tab><IF-STMT><tab><tab><tab>new_segments.write(line)<tab>new_segments.close(), segments.close()",1,if spk in spk_list :,if spk in spk_list :,0.75,100,1
"def _get_sources(include_per_machine=True, include_per_user=True):<tab>if _is_64bit_os():<tab><tab><IF-STMT><tab><tab><tab>yield open_source(REGISTRY_SOURCE_CU), None<tab><tab>if include_per_machine:<tab><tab><tab>yield open_source(REGISTRY_SOURCE_LM), ""64bit""<tab><tab><tab>yield open_source(REGISTRY_SOURCE_LM_WOW6432), ""32bit""<tab>else:<tab><tab>if include_per_user:<tab><tab><tab>yield open_source(REGISTRY_SOURCE_CU), ""32bit""<tab><tab>if include_per_machine:<tab><tab><tab>yield open_source(REGISTRY_SOURCE_LM), ""32bit""",1,if include_per_user :,if include_per_user :,0.531170663,1.00E-10,1
"def AddWindowMenu(self, pMenuBar):<tab>if pMenuBar and self._pWindowMenu:<tab><tab>pos = pMenuBar.FindMenu(wx.GetStockLabel(wx.ID_HELP, wx.STOCK_NOFLAGS))<tab><tab><IF-STMT><tab><tab><tab>pMenuBar.Append(self._pWindowMenu, _(""&Window""))<tab><tab>else:<tab><tab><tab>pMenuBar.Insert(pos, self._pWindowMenu, _(""&Window""))",0,if pos == wx . NOT_FOUND :,if pos is None :,0.042406009,8.697972365,0.476190476
"def remove(self, res):<tab>""""""Remove resource""""""<tab>msg_box = QMessageBox(<tab><tab>QMessageBox.Critical,<tab><tab>self.app.translate(""ResourceEdit"", ""Delete Resource""),<tab><tab>self.app.translate(<tab><tab><tab>""ResourceEdit"", ""Are you sure want to delete this resource?""<tab><tab>),<tab><tab>QMessageBox.Yes | QMessageBox.No,<tab>)<tab>ret = msg_box.exec_()<tab>if ret == QMessageBox.Yes:<tab><tab>self._resources.remove(res)<tab><tab>self._resource_labels[res].hide()<tab><tab>del self._resource_labels[res]<tab><tab>self.on_change()<tab><tab><IF-STMT><tab><tab><tab>self.widget.hide()<tab><tab>self.update_label()",0,if not self . _resources :,if ret == QMessageBox . No :,0.025478913,7.267884212,0.265306122
"def reader(self, myself):<tab>ok = True<tab>line = """"<tab>while True:<tab><tab>line = sys.stdin.readline().strip()<tab><tab>if ok:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>ok = False<tab><tab><tab><tab>continue<tab><tab>elif not line:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.Q.append(line)<tab>os.kill(myself, signal.SIGTERM)",0,if not line :,"if line == """" :",0.045150551,8.643019616,0.45
"def _compute_ratios(counts, n_total, multilabel=False):<tab>computed_ratios = {}<tab>max_count = max(counts.values())<tab>for class_name, count in counts.items():<tab><tab><IF-STMT><tab><tab><tab>ratio = (n_total - count) / count<tab><tab>else:<tab><tab><tab>ratio = ratio = max_count / count<tab><tab>computed_ratios[class_name] = ratio<tab>return computed_ratios",1,if multilabel :,if multilabel :,0.531170663,1.00E-10,1
"def test_tags(context_obj, sagemaker_session):<tab>tags = [{""Key"": ""foo1"", ""Value"": ""bar1""}]<tab>context_obj.set_tags(tags)<tab>while True:<tab><tab>actual_tags = sagemaker_session.sagemaker_client.list_tags(<tab><tab><tab>ResourceArn=context_obj.context_arn<tab><tab>)[""Tags""]<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>time.sleep(5)<tab># When sagemaker-client-config endpoint-url is passed as argument to hit some endpoints,<tab># length of actual tags will be greater than 1<tab>assert len(actual_tags) > 0<tab>assert [actual_tags[-1]] == tags",1,if actual_tags :,if actual_tags :,0.531170663,1.00E-10,1
"def step(self, action):<tab>""""""Repeat action, sum reward, and max over last observations.""""""<tab>total_reward = 0.0<tab>done = None<tab>for i in range(self._skip):<tab><tab>obs, reward, done, info = self.env.step(action)<tab><tab>if i == self._skip - 2:<tab><tab><tab>self._obs_buffer[0] = obs<tab><tab><IF-STMT><tab><tab><tab>self._obs_buffer[1] = obs<tab><tab>total_reward += reward<tab><tab>if done:<tab><tab><tab>break<tab># Note that the observation on the done=True frame doesn't matter.<tab>max_frame = self._obs_buffer.max(axis=0)<tab>return max_frame, total_reward, done, info",1,if i == self . _skip - 1 :,if i == self . _skip - 1 :,0.75,100,1
"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab>if sty.italic:<tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>if sty.drawing:<tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",0,if sty . underline :,if sty . bold :,0.394778655,42.72870064,0.6
"def GetConvertersByClass(value_cls):<tab>""""""Returns all converters that take given value as an input value.""""""<tab>try:<tab><tab>return ExportConverter.converters_cache[value_cls]<tab>except KeyError:<tab><tab>results = [<tab><tab><tab>cls<tab><tab><tab>for cls in ExportConverter.classes.values()<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab>if not results:<tab><tab><tab>results = [DataAgnosticExportConverter]<tab><tab>ExportConverter.converters_cache[value_cls] = results<tab><tab>return results",0,if cls . input_rdf_type == value_cls,"if isinstance ( cls , DataAgnosticConverter )",0.023878899,3.314288202,0.35
"def enable(self):<tab>""""""enable the patch.""""""<tab>for patch in self.dependencies:<tab><tab>patch.enable()<tab>if not self.enabled:<tab><tab>pyv = sys.version_info[0]<tab><tab><IF-STMT><tab><tab><tab>if self.PY2 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY2:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 2 not supported!"")<tab><tab>if pyv == 3:<tab><tab><tab>if self.PY3 == SKIP:<tab><tab><tab><tab>return  # skip patch activation<tab><tab><tab>if not self.PY3:<tab><tab><tab><tab>raise IncompatiblePatch(""Python 3 not supported!"")<tab><tab>self.pre_enable()<tab><tab>self.do_enable()<tab><tab>self.enabled = True",1,if pyv == 2 :,if pyv == 2 :,0.75,100,1
def _maybe_uncompress(self):<tab>if not self._decompressed:<tab><tab>compression_type = self.compression_type<tab><tab>if compression_type != self.CODEC_NONE:<tab><tab><tab>data = memoryview(self._buffer)[self._pos :]<tab><tab><tab>if compression_type == self.CODEC_GZIP:<tab><tab><tab><tab>uncompressed = gzip_decode(data)<tab><tab><tab>if compression_type == self.CODEC_SNAPPY:<tab><tab><tab><tab>uncompressed = snappy_decode(data.tobytes())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>uncompressed = lz4_decode(data.tobytes())<tab><tab><tab>self._buffer = bytearray(uncompressed)<tab><tab><tab>self._pos = 0<tab>self._decompressed = True,1,if compression_type == self . CODEC_LZ4 :,if compression_type == self . CODEC_LZ4 :,0.75,100,1
"def transform(node, filename):<tab>root = ast.Module(None, node, lineno=1)<tab>nodes = [root]<tab>while nodes:<tab><tab>node = nodes.pop()<tab><tab>node.filename = filename<tab><tab><IF-STMT><tab><tab><tab>node.dest = ast.Name(""__context"")<tab><tab>elif node.__class__ is ast.Const and isinstance(node.value, str):<tab><tab><tab>try:<tab><tab><tab><tab>node.value.decode(""ascii"")<tab><tab><tab>except UnicodeError:<tab><tab><tab><tab>node.value = node.value.decode(""utf-8"")<tab><tab>nodes.extend(node.getChildNodes())<tab>return root",0,"if node . __class__ in ( ast . Printnl , ast . Print ) :",if node . dest is None :,0.158705843,4.730862767,0.288888889
"def __init__(self, json=None):<tab>if not json:<tab><tab>self._mods = dict()<tab><tab>return<tab>mods = collections.defaultdict(set)<tab>installed_path_patt = re.compile(<tab><tab>"".*[\\\\/]target[\\\\/]product[\\\\/][^\\\\/]+([\\\\/].*)$""<tab>)<tab>for module in json.values():<tab><tab>for path in module[""installed""]:<tab><tab><tab>match = installed_path_patt.match(path)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>for path in module[""path""]:<tab><tab><tab><tab><tab>mods[match.group(1)].add(path)<tab>self._mods = {<tab><tab>installed_path: sorted(src_dirs) for installed_path, src_dirs in mods.items()<tab>}",1,if match :,if match :,0.531170663,1.00E-10,1
"def _findSubpath(self, path, A, B, inside):<tab>print(""finding"", A, B)<tab>sub = None<tab>for i in xrange(0, len(path) * 2):  # iterate twice with wrap around<tab><tab>j = i % len(path)<tab><tab>seg = path[j]<tab><tab>if inside.isInside(seg.midPoint()):<tab><tab><tab>if eq(seg.A, A):<tab><tab><tab><tab>sub = Path(""subp"")<tab><tab><tab>print(""seg"", sub is None, seg)<tab><tab><tab>if sub is not None:<tab><tab><tab><tab>sub.append(seg)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>print(""found"", sub)<tab>return sub",0,"if eq ( seg . B , B ) :","elif eq ( seg . B , B ) :",0.422304612,88.01117368,0.666666667
"def on_click(self, event):<tab>button = event[""button""]<tab>if button in [self.button_next, self.button_previous]:<tab><tab>if self.station_data:<tab><tab><tab>self.scrolling = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.active_index += 1<tab><tab><tab>elif button == self.button_previous:<tab><tab><tab><tab>self.active_index -= 1<tab><tab><tab>self.active_index %= self.count_stations<tab><tab>else:<tab><tab><tab>self.py3.prevent_refresh()<tab>elif button == self.button_refresh:<tab><tab>self.idle_time = 0<tab>else:<tab><tab>self.py3.prevent_refresh()",1,if button == self . button_next :,if button == self . button_next :,0.75,100,1
"def __init_subclass__(cls, *, abstract=False):<tab>if abstract:<tab><tab>return<tab>fields = {}<tab>for name in cls.__dict__:<tab><tab>attr = cls.__dict__[name]<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if not isinstance(attr, CType):<tab><tab><tab>raise TypeError(f""field {cls.__name__}.{name!r} must be a Type"")<tab><tab>else:<tab><tab><tab>fields[name] = attr<tab>cls._fields = fields",0,"if name . startswith ( ""__"" ) or callable ( attr ) :","if not isinstance ( attr , type ) :",0.025460173,6.550847049,0.193333333
"def add(self, geom):<tab>""Add the geometry to this Geometry Collection.""<tab>if isinstance(geom, OGRGeometry):<tab><tab><IF-STMT><tab><tab><tab>for g in geom:<tab><tab><tab><tab>capi.add_geom(self.ptr, g.ptr)<tab><tab>else:<tab><tab><tab>capi.add_geom(self.ptr, geom.ptr)<tab>elif isinstance(geom, six.string_types):<tab><tab>tmp = OGRGeometry(geom)<tab><tab>capi.add_geom(self.ptr, tmp.ptr)<tab>else:<tab><tab>raise OGRException(""Must add an OGRGeometry."")",0,"if isinstance ( geom , self . __class__ ) :","if isinstance ( geom , list ) :",0.232029036,28.08708327,0.666666667
"def __str__(self):<tab>result = []<tab>for x in self._fields_:<tab><tab>key = x[0]<tab><tab>value = getattr(self, key)<tab><tab>fmt = ""%s""<tab><tab>if key in self._fmt_:<tab><tab><tab>fmt = self._fmt_[key]<tab><tab><IF-STMT><tab><tab><tab>fmt = self._fmt_[""<default>""]<tab><tab>result.append((""%s: "" + fmt) % (key, value))<tab>return self.__class__.__name__ + ""("" + string.join(result, "", "") + "")""",1,"elif ""<default>"" in self . _fmt_ :","elif ""<default>"" in self . _fmt_ :",0.75,100,1
"def add(self, *objs):<tab>for obj in objs:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""'%s' instance expected, got %r"" % (self.model._meta.object_name, obj)<tab><tab><tab>)<tab><tab>setattr(obj, rel_field.name, self.instance)<tab><tab>obj.save()",0,"if not isinstance ( obj , self . model ) :","if not isinstance ( obj , self . instance ) :",0.622196729,74.19446627,0.75
"def _eliminate_deprecated_list_indexing(idx):<tab># ""Basic slicing is initiated if the selection object is a non-array,<tab># non-tuple sequence containing slice objects, [Ellipses, or newaxis<tab># objects]"". Detects this case and canonicalizes to a tuple. This case is<tab># deprecated by NumPy and exists for backward compatibility.<tab>if not isinstance(idx, tuple):<tab><tab><IF-STMT><tab><tab><tab>if _any(_should_unpack_list_index(i) for i in idx):<tab><tab><tab><tab>idx = tuple(idx)<tab><tab><tab>else:<tab><tab><tab><tab>idx = (idx,)<tab><tab>else:<tab><tab><tab>idx = (idx,)<tab>return idx",0,"if isinstance ( idx , Sequence ) and not isinstance ( idx , ndarray ) :","if isinstance ( idx , list ) :",0.2910583,21.87424245,0.341130604
"def __init__(self, parent=None, **kwargs):<tab>super(DefaultWidget, self).__init__(parent)<tab>self.parent = parent<tab>self.FSettings = SuperSettings.getInstance()<tab>self.defaultui = []<tab>self.allui = []<tab>self.__tabbyname = {}<tab>__defaultui = [ui(parent, self.FSettings) for ui in TabsWidget.__subclasses__()]<tab>for ui in __defaultui:<tab><tab><IF-STMT><tab><tab><tab>self.defaultui.append(ui)<tab><tab>self.allui.append(ui)<tab><tab>self.__tabbyname[ui.Name] = ui<tab><tab>setattr(self.__class__, ui.ID, ui)",0,if not ui . isSubitem :,"if isinstance ( ui , TabsWidget ) :",0.023749772,7.267884212,0.428571429
"def onMouseMove(self, event):<tab>x, y = event.xdata, event.ydata<tab>if x is not None:<tab><tab>extra_text = self.getExtraText(x, y)<tab><tab># extra_text = ""TODO:""<tab><tab><IF-STMT><tab><tab><tab>self.message(""x,y=%5.4e,%5.4e %s"" % (x, y, extra_text), index=0)<tab><tab>else:<tab><tab><tab>self.message(""x,y=%5.4e,%5.4e"" % (x, y), index=0)<tab>else:<tab><tab>self.message(None)",1,if extra_text :,if extra_text :,0.531170663,1.00E-10,1
"def tag_configure(self, *args, **keys):<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab>if val:<tab><tab><tab>self.configDict[key] = val<tab><tab><IF-STMT><tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",1,if underline :,if underline :,0.531170663,1.00E-10,1
"def _flatten_shape(s, index):<tab>if s.is_array():<tab><tab>yield index, s<tab>else:<tab><tab>assert s.is_tuple()<tab><tab>for i, sub in enumerate(s.tuple_shapes()):<tab><tab><tab>subindex = index + (i,)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield from _flatten_shape(sub, subindex)<tab><tab><tab>else:<tab><tab><tab><tab>yield subindex, sub",0,if sub . is_tuple ( ) :,"if isinstance ( sub , tuple ) :",0.041182573,12.82777061,0.36
"def delete_if_forked(ghrequest):<tab>FORKED = False<tab>query = ""/user/repos""<tab>r = utils.query_request(query)<tab>for repo in r.json():<tab><tab>if repo[""description""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>FORKED = True<tab><tab><tab><tab>url = f""/repos/{repo['full_name']}""<tab><tab><tab><tab>utils.query_request(url, method=""DELETE"")<tab>return FORKED",0,"if ghrequest . target_repo_fullname in repo [ ""description"" ] :","if ghrequest . get ( repo [ ""name"" ] ) == repo [ ""name"" ] :",0.097589962,15.82128589,0.603864734
def update_json(self):<tab>n_id = node_id(self)<tab>if self.autoreload:<tab><tab>self.reload_json()<tab>if n_id not in self.json_data and self.current_text:<tab><tab>self.reload_json()<tab>if n_id not in self.json_data:<tab><tab>self.use_custom_color = True<tab><tab>self.color = FAIL_COLOR<tab><tab>return<tab>self.use_custom_color = True<tab>self.color = READY_COLOR<tab>json_data = self.json_data[n_id]<tab>for item in json_data:<tab><tab><IF-STMT><tab><tab><tab>out = json_data[item][1]<tab><tab><tab>self.outputs[item].sv_set(out),0,if item in self . outputs and self . outputs [ item ] . is_linked :,if item in self . outputs :,0.254648361,17.46947058,0.682539683
"def _check_num_states(self, num_states):<tab>""""""Track the number of states.""""""<tab>self._num_states += num_states<tab>if self._max_num_states is not None:<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>""Too many states detected while running dynamic ""<tab><tab><tab><tab>""programming: got %d states but upper limit is %d.""<tab><tab><tab><tab>% (self._num_states, self._max_num_states)<tab><tab><tab>)",1,if self . _num_states > self . _max_num_states :,if self . _num_states > self . _max_num_states :,1,100,1
def __del__(self):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>if self._initialized:<tab><tab><tab><tab>_gmp.mpz_clear(self._mpz_p)<tab><tab>self._mpz_p = None<tab>except AttributeError:<tab><tab>pass,1,if self . _mpz_p is not None :,if self . _mpz_p is not None :,0.75,100,1
"def cmp(f1, f2):<tab>bufsize = 1024 * 8<tab>with open(f1, ""rb"") as fp1, open(f2, ""rb"") as fp2:<tab><tab>while True:<tab><tab><tab>b1 = fp1.read(bufsize)<tab><tab><tab>b2 = fp2.read(bufsize)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>if not b1:<tab><tab><tab><tab>return True",1,if b1 != b2 :,if b1 != b2 :,0.75,100,1
"def _get_changes(diff):<tab>""""""Get a list of changed versions from git.""""""<tab>changes_dict = {}<tab>for line in diff:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if line.startswith(""+++ "") or line.startswith(""--- ""):<tab><tab><tab>continue<tab><tab>name, version = parse_versioned_line(line[1:])<tab><tab>if name not in changes_dict:<tab><tab><tab>changes_dict[name] = Change(name)<tab><tab>if line.startswith(""-""):<tab><tab><tab>changes_dict[name].old = version<tab><tab>elif line.startswith(""+""):<tab><tab><tab>changes_dict[name].new = version<tab>return [change for _name, change in sorted(changes_dict.items())]",0,"if not line . startswith ( ""-"" ) and not line . startswith ( ""+"" ) :","if line . startswith ( ""#"" ) :",0.164994146,18.01106413,0.297101449
"def analyze(vw):<tab>for va, dest in vw.findPointers():<tab><tab># Is there a location already at the target?<tab><tab>loc = vw.getLocation(dest)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab>if loc[L_LTYPE] != LOC_IMPORT:<tab><tab><tab>continue<tab><tab>offset, bytes = vw.getByteDef(va)<tab><tab>if offset < 2:<tab><tab><tab>continue<tab><tab>if bytes[offset - 2 : offset] == b""\xff\x15"":  # call [importloc]<tab><tab><tab># If there's a pointer here, remove it.<tab><tab><tab><IF-STMT><tab><tab><tab><tab>vw.delLocation(va)<tab><tab><tab>vw.makeCode(va - 2)",0,if vw . getLocation ( va ) :,if va < len ( vw . getLocation ( va ) ) - 1 :,0.394756598,34.79159475,0.263157895
"def match_blanks(self, s, i):<tab>if 1:  # Use Qt code to show invisibles.<tab><tab>return 0<tab>else:  # Old code...<tab><tab>if not self.showInvisibles:<tab><tab><tab>return 0<tab><tab>j = i<tab><tab>n = len(s)<tab><tab>while j < n and s[j] == "" "":<tab><tab><tab>j += 1<tab><tab><IF-STMT><tab><tab><tab>self.colorRangeWithTag(s, i, j, ""blank"")<tab><tab><tab>return j - i<tab><tab>else:<tab><tab><tab>return 0",0,if j > i :,"if s [ j ] == "" "" :",0.026752541,5.522397784,0.4
"def compress(self, data_list):<tab># Differs from the default implementation: If only a time is given and no date, we consider the field empty<tab>if data_list:<tab><tab>if data_list[0] in self.empty_values:<tab><tab><tab>return None<tab><tab><IF-STMT><tab><tab><tab>raise ValidationError(<tab><tab><tab><tab>self.error_messages[""invalid_date""], code=""invalid_date""<tab><tab><tab>)<tab><tab>result = datetime.datetime.combine(*data_list)<tab><tab>return from_current_timezone(result)<tab>return None",0,if data_list [ 1 ] in self . empty_values :,if len ( data_list ) > 1 :,0.015805905,12.45123373,0.320512821
"def test_iter_keys(self):<tab>for name in (""interfaces"", ""addresses"", ""neighbours"", ""routes"", ""rules""):<tab><tab>view = getattr(self.ndb, name)<tab><tab>for key in view:<tab><tab><tab>assert isinstance(key, Record)<tab><tab><tab>obj = view.get(key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>assert isinstance(obj, RTNL_Object)",1,if obj is not None :,if obj is not None :,0.75,100,1
"def has_selenium():<tab>try:<tab><tab>from selenium import selenium<tab><tab>globals().update(selenium=selenium)<tab><tab>sel = selenium(*sel_args)<tab><tab># a little trick to see if the server is responding<tab><tab>try:<tab><tab><tab>sel.do_command(""shutdown"", """")<tab><tab>except Exception as e:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab><tab>result = True<tab>except ImportError:<tab><tab>result = SeleniumFailed(""selenium RC not installed"")<tab>except Exception:<tab><tab>msg = ""Error occurred initializing selenium: %s"" % e<tab><tab>result = SeleniumFailed(msg)<tab># overwrite has_selenium, so the same result is returned every time<tab>globals().update(has_selenium=lambda: result)<tab>return result",0,"if not ""Server Exception"" in str ( e ) :",if e . args [ 0 ] != errno . ENOENT :,0.013494195,4.065425429,0.192307692
"def analyze(vw):<tab>for va, dest in vw.findPointers():<tab><tab># Is there a location already at the target?<tab><tab>loc = vw.getLocation(dest)<tab><tab>if loc is None:<tab><tab><tab>continue<tab><tab>if loc[L_LTYPE] != LOC_IMPORT:<tab><tab><tab>continue<tab><tab>offset, bytes = vw.getByteDef(va)<tab><tab>if offset < 2:<tab><tab><tab>continue<tab><tab><IF-STMT>  # call [importloc]<tab><tab><tab># If there's a pointer here, remove it.<tab><tab><tab>if vw.getLocation(va):<tab><tab><tab><tab>vw.delLocation(va)<tab><tab><tab>vw.makeCode(va - 2)",0,"if bytes [ offset - 2 : offset ] == b""\xff\x15"" :",if offset == LOC_IMPORT :,0.011348924,3.511460369,0.364705882
"def get(_kwargs):<tab>exception_raised_every_time = True<tab>exception = None<tab>no_match = True<tab>for meter in self.meters:<tab><tab>try:<tab><tab><tab>match = getattr(meter, func)(_kwargs)<tab><tab>except KeyError as e:<tab><tab><tab>exception = e<tab><tab>else:<tab><tab><tab>exception_raised_every_time = False<tab><tab><tab><IF-STMT><tab><tab><tab><tab>selected_meters.append(meter)<tab><tab><tab><tab>no_match = False<tab>if no_match:<tab><tab>raise KeyError(""'No match for {}'"".format(_kwargs))<tab>if exception_raised_every_time and exception is not None:<tab><tab>raise exception",0,if match :,if not match :,0.113486237,1.00E-10,0.416666667
"def derive(self, key_material):<tab>if self._used:<tab><tab>raise AlreadyFinalized<tab>self._used = True<tab>if not isinstance(key_material, bytes):<tab><tab>raise TypeError(""key_material must be bytes."")<tab>output = [b""""]<tab>outlen = 0<tab>counter = 1<tab>while self._length > outlen:<tab><tab>h = hashes.Hash(self._algorithm, self._backend)<tab><tab>h.update(key_material)<tab><tab>h.update(_int_to_u32be(counter))<tab><tab><IF-STMT><tab><tab><tab>h.update(self._sharedinfo)<tab><tab>output.append(h.finalize())<tab><tab>outlen += len(output[-1])<tab><tab>counter += 1<tab>return b"""".join(output)[: self._length]",1,if self . _sharedinfo is not None :,if self . _sharedinfo is not None :,0.75,100,1
"def test_cat(shape, cat_dim, split, dim):<tab>assert sum(split) == shape[cat_dim]<tab>gaussian = random_gaussian(shape, dim)<tab>parts = []<tab>end = 0<tab>for size in split:<tab><tab>beg, end = end, end + size<tab><tab><IF-STMT><tab><tab><tab>part = gaussian[..., beg:end]<tab><tab>elif cat_dim == -2:<tab><tab><tab>part = gaussian[..., beg:end, :]<tab><tab>elif cat_dim == 1:<tab><tab><tab>part = gaussian[:, beg:end]<tab><tab>else:<tab><tab><tab>raise ValueError<tab><tab>parts.append(part)<tab>actual = Gaussian.cat(parts, cat_dim)<tab>assert_close_gaussian(actual, gaussian)",0,if cat_dim == - 1 :,if cat_dim == 0 :,0.115297827,62.40195442,0.5
"def ghci_package_db(self, cabal):<tab>if cabal is not None and cabal != ""cabal"":<tab><tab>package_conf = [<tab><tab><tab>pkg for pkg in os.listdir(cabal) if re.match(r""packages-(.*)\.conf"", pkg)<tab><tab>]<tab><tab><IF-STMT><tab><tab><tab>return os.path.join(cabal, package_conf)<tab>return None",1,if package_conf :,if package_conf :,0.531170663,1.00E-10,1
"def L_op(self, inputs, outputs, gout):<tab>(x,) = inputs<tab>(gz,) = gout<tab>if x.type in complex_types:<tab><tab>raise NotImplementedError()<tab>if outputs[0].type in discrete_types:<tab><tab><IF-STMT><tab><tab><tab>return [x.zeros_like(dtype=theano.config.floatX)]<tab><tab>else:<tab><tab><tab>return [x.zeros_like()]<tab>return (gz / x,)",1,if x . type in discrete_types :,if x . type in discrete_types :,0.75,100,1
"def __mro_entries__(self, bases):<tab>if self._name:  # generic version of an ABC or built-in class<tab><tab>return super().__mro_entries__(bases)<tab>if self.__origin__ is Generic:<tab><tab><IF-STMT><tab><tab><tab>return ()<tab><tab>i = bases.index(self)<tab><tab>for b in bases[i + 1 :]:<tab><tab><tab>if isinstance(b, _BaseGenericAlias) and b is not self:<tab><tab><tab><tab>return ()<tab>return (self.__origin__,)",0,if Protocol in bases :,if self not in bases :,0.252622275,32.46679155,0.238095238
"def getvars(request, excludes):<tab>getvars = request.GET.copy()<tab>excludes = excludes.split("","")<tab>for p in excludes:<tab><tab>if p in getvars:<tab><tab><tab>del getvars[p]<tab><tab><IF-STMT><tab><tab><tab>return ""&%s"" % getvars.urlencode()<tab><tab>else:<tab><tab><tab>return """"",0,if len ( getvars . keys ( ) ) > 0 :,if getvars :,0.008307009,1.00E-10,0.303921569
"def check(self):<tab>now = time.time()<tab>for fn in os.listdir(self.basedir):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>absfn = os.path.join(self.basedir, fn)<tab><tab>mtime = os.stat(absfn)[stat.ST_MTIME]<tab><tab>if now - mtime > self.old:<tab><tab><tab>os.remove(absfn)",0,if fn in self . files :,"if not fn . endswith ( "".py"" ) :",0.104215856,4.789232204,0.236111111
"def run(self):<tab>while 1:<tab><tab>gatekeeper.wait()<tab><tab>results = []<tab><tab>results.append(self.__queue.get())<tab><tab>while len(results) < self.MAX_SONGS_PER_SUBMISSION:<tab><tab><tab># wait a bit to reduce overall request count.<tab><tab><tab>timeout = 0.5 / len(results)<tab><tab><tab>try:<tab><tab><tab><tab>results.append(self.__queue.get(timeout=timeout))<tab><tab><tab>except queue.Empty:<tab><tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>for lookup_result in self.__process(results):<tab><tab><tab>self.__idle(self.__progress_cb, lookup_result)<tab><tab><tab>self.__queue.task_done()",0,if self . __stopped :,if len ( results ) >= self . MAX_SONGS_PER_SUBMISSION :,0.131284209,6.019608769,0.371428571
"def __getitem__(self, item):<tab>if isinstance(item, int):<tab><tab>selected_polygons = [self.polygons[item]]<tab>elif isinstance(item, slice):<tab><tab>selected_polygons = self.polygons[item]<tab>else:<tab><tab># advanced indexing on a single dimension<tab><tab>selected_polygons = []<tab><tab><IF-STMT><tab><tab><tab>item = item.nonzero()<tab><tab><tab>item = item.squeeze(1) if item.numel() > 0 else item<tab><tab><tab>item = item.tolist()<tab><tab>for i in item:<tab><tab><tab>selected_polygons.append(self.polygons[i])<tab>return PolygonList(selected_polygons, size=self.size)",0,"if isinstance ( item , torch . Tensor ) and item . dtype == torch . uint8 :","if isinstance ( item , bool ) :",0.098498114,14.21821534,0.339393939
"def gather_files(fileset):<tab>common_type = get_common_filetype(fileset)<tab>files = []<tab>for file in fileset.file:<tab><tab>filename = file.name<tab><tab>if file.is_include_file == True:<tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""is_include_file"": True}<tab><tab>if file.file_type != common_type:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""file_type"": file.file_type}<tab><tab>files.append(filename)<tab>return files",0,if type ( filename ) == str :,if file . file_type == common_type :,0.019627455,8.516593019,0.3
"def _(node):<tab>for __ in dir(node):<tab><tab>if not __.startswith(""_""):<tab><tab><tab>candidate = getattr(node, __)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ""\\"" in candidate:<tab><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab><tab>re.compile(candidate)<tab><tab><tab><tab><tab>except:<tab><tab><tab><tab><tab><tab>errMsg = ""smoke test failed at compiling '%s'"" % candidate<tab><tab><tab><tab><tab><tab>logger.error(errMsg)<tab><tab><tab><tab><tab><tab>raise<tab><tab><tab>else:<tab><tab><tab><tab>_(candidate)",0,"if isinstance ( candidate , str ) :","if isinstance ( candidate , basestring ) :",0.549040681,59.46035575,0.666666667
"def _handle_children(self, removed, added):<tab># Stop all the removed children.<tab>for obj in removed:<tab><tab>obj.stop()<tab># Process the new objects.<tab>for obj in added:<tab><tab>obj.set(scene=self.scene, parent=self)<tab><tab>if isinstance(obj, ModuleManager):<tab><tab><tab>obj.source = self<tab><tab>elif is_filter(obj):<tab><tab><tab>obj.inputs.append(self)<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>obj.start()<tab><tab><tab>except:<tab><tab><tab><tab>exception()",0,if self . running :,elif is_start ( obj ) :,0.021802698,5.522397784,0.142857143
"def mean(self):<tab>""""""Compute the mean of the value_field in the window.""""""<tab>if len(self.data) > 0:<tab><tab>datasum = 0<tab><tab>datalen = 0<tab><tab>for dat in self.data:<tab><tab><tab>if ""placeholder"" not in dat[0]:<tab><tab><tab><tab>datasum += dat[1]<tab><tab><tab><tab>datalen += 1<tab><tab><IF-STMT><tab><tab><tab>return datasum / float(datalen)<tab><tab>return None<tab>else:<tab><tab>return None",0,if datalen > 0 :,if len ( datasum ) > 0 :,0.110273145,22.08959113,0.314814815
"def get_master_info(accounts_config, master):<tab>master_info = None<tab>for a in accounts_config[""accounts""]:<tab><tab>if a[""name""] == master:<tab><tab><tab>master_info = a<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>master_info = a<tab><tab><tab>break<tab>if master_info is None:<tab><tab>raise ValueError(""Master account: %s not found in accounts config"" % (master))<tab>return master_info",0,"if a [ ""account_id"" ] == master :","elif a [ ""name"" ] == master :",0.195658694,49.00202456,0.6
"def dataset_collector(dataset_collection_description):<tab>if dataset_collection_description is DEFAULT_DATASET_COLLECTOR_DESCRIPTION:<tab><tab># Use 'is' and 'in' operators, so lets ensure this is<tab><tab># treated like a singleton.<tab><tab>return DEFAULT_DATASET_COLLECTOR<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return DatasetCollector(dataset_collection_description)<tab><tab>else:<tab><tab><tab>return ToolMetadataDatasetCollector(dataset_collection_description)",0,"if dataset_collection_description . discover_via == ""pattern"" :","if dataset_collection_description . startswith ( ""is"" ) :",0.083577801,40.98188335,0.641025641
"def _eliminate_deprecated_list_indexing(idx):<tab># ""Basic slicing is initiated if the selection object is a non-array,<tab># non-tuple sequence containing slice objects, [Ellipses, or newaxis<tab># objects]"". Detects this case and canonicalizes to a tuple. This case is<tab># deprecated by NumPy and exists for backward compatibility.<tab>if not isinstance(idx, tuple):<tab><tab>if isinstance(idx, Sequence) and not isinstance(idx, ndarray):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>idx = tuple(idx)<tab><tab><tab>else:<tab><tab><tab><tab>idx = (idx,)<tab><tab>else:<tab><tab><tab>idx = (idx,)<tab>return idx",0,if _any ( _should_unpack_list_index ( i ) for i in idx ) :,"if isinstance ( idx , tuple ) :",0.02049586,2.734728085,0.234375
"def finalizer():<tab>try:<tab><tab>stdout.flush()<tab><tab>stderr.flush()<tab>finally:<tab><tab>time.sleep(0.001)  # HACK: Sleep 1ms in the main thread to free the GIL.<tab><tab>stdout_pipe.stop_writing()<tab><tab>stderr_pipe.stop_writing()<tab><tab>writer.join(timeout=60)<tab><tab><IF-STMT><tab><tab><tab>raise NailgunStreamWriterError(<tab><tab><tab><tab>""pantsd timed out while waiting for the stdout/err to finish writing to the socket.""<tab><tab><tab>)",0,if writer . isAlive ( ) :,if writer . is_alive ( ) :,0.38848939,29.84745896,0.722222222
"def __init__(self, env, config, scope_infos, option_tracker):<tab># Sorting ensures that ancestors precede descendants.<tab>scope_infos = sorted(set(list(scope_infos)), key=lambda si: si.scope)<tab>self._parser_by_scope = {}<tab>for scope_info in scope_infos:<tab><tab>scope = scope_info.scope<tab><tab>parent_parser = (<tab><tab><tab>None<tab><tab><tab><IF-STMT><tab><tab><tab>else self._parser_by_scope[enclosing_scope(scope)]<tab><tab>)<tab><tab>self._parser_by_scope[scope] = Parser(<tab><tab><tab>env, config, scope_info, parent_parser, option_tracker=option_tracker<tab><tab>)",0,if scope == GLOBAL_SCOPE,if scope == scope_info . scope,0.15382749,31.55984539,0.841269841
"def _load_start_paths(self) -> None:<tab>""Start the Read-Eval-Print Loop.""<tab>if self._startup_paths:<tab><tab>for path in self._startup_paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>with open(path, ""rb"") as f:<tab><tab><tab><tab><tab>code = compile(f.read(), path, ""exec"")<tab><tab><tab><tab><tab>exec(code, self.get_globals(), self.get_locals())<tab><tab><tab>else:<tab><tab><tab><tab>output = self.app.output<tab><tab><tab><tab>output.write(""WARNING | File not found: {}\n\n"".format(path))",0,if os . path . exists ( path ) :,if os . path . isfile ( path ) :,0.830308871,65.80370065,0.666666667
"def validate(leaves):<tab>for leaf in leaves:<tab><tab>if leaf.has_form((""Rule"", ""RuleDelayed""), 2):<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>if validate(leaf.leaves) is not True:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",0,"elif leaf . has_form ( ""List"" , None ) or leaf . has_form ( ""Association"" , None ) :","elif leaf . has_form ( ""Rule"" , ""RuleDelayed"" ) :",0.203824564,27.27249283,0.506666667
"def add(self, name, value, package=None):<tab># New data, not previous value<tab>if name not in self._data[package]:<tab><tab>self._data[package][name] = value<tab># There is data already<tab>else:<tab><tab># Only append at the end if we had a list<tab><tab><IF-STMT><tab><tab><tab>if isinstance(value, list):<tab><tab><tab><tab>self._data[package][name].extend(value)<tab><tab><tab>else:<tab><tab><tab><tab>self._data[package][name].append(value)",0,"if isinstance ( self . _data [ package ] [ name ] , list ) :",if name in self . _data [ package ] :,0.238233059,36.15980809,0.244047619
"def edge2str(self, nfrom, nto):<tab>if isinstance(nfrom, ExprCompose):<tab><tab>for i in nfrom.args:<tab><tab><tab>if i[0] == nto:<tab><tab><tab><tab>return ""[%s, %s]"" % (i[1], i[2])<tab>elif isinstance(nfrom, ExprCond):<tab><tab>if nfrom.cond == nto:<tab><tab><tab>return ""?""<tab><tab>elif nfrom.src1 == nto:<tab><tab><tab>return ""True""<tab><tab><IF-STMT><tab><tab><tab>return ""False""<tab>return """"",0,elif nfrom . src2 == nto :,elif nfrom . dst0 == nto :,0.63747081,50,0.666666667
"def _get_config(key):<tab>config = db.session.execute(<tab><tab>Configs.__table__.select().where(Configs.key == key)<tab>).fetchone()<tab>if config and config.value:<tab><tab>value = config.value<tab><tab>if value and value.isdigit():<tab><tab><tab>return int(value)<tab><tab><IF-STMT><tab><tab><tab>if value.lower() == ""true"":<tab><tab><tab><tab>return True<tab><tab><tab>elif value.lower() == ""false"":<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return value<tab># Flask-Caching is unable to roundtrip a value of None.<tab># Return an exception so that we can still cache and avoid the db hit<tab>return KeyError",0,"elif value and isinstance ( value , string_types ) :","elif isinstance ( value , str ) :",0.378645557,25.91626699,0.318181818
"def from_rows(cls, rows):<tab>subtitles = []<tab>for row in rows:<tab><tab><IF-STMT><tab><tab><tab>subtitles.append(cls.from_row(row))<tab>return subtitles",0,"if row . td . a is not None and row . td . get ( ""class"" , [ ""lazy"" ] ) [ 0 ] != ""empty"" :",if row [ 0 ] . isspace ( ) and row [ 0 ] . isdigit ( ) :,0.028672076,5.674388757,0.183760684
"def _wx_node(self, parent_node, index, label, with_checkbox):<tab>ct_type = 1 if with_checkbox else 0<tab>if index is not None:<tab><tab># blame wxPython for this ugliness<tab><tab><IF-STMT><tab><tab><tab>return self.InsertItemByIndex(parent_node, index, label, ct_type=ct_type)<tab><tab>else:<tab><tab><tab>return self.InsertItem(parent_node, index, label, ct_type=ct_type)<tab>return self.AppendItem(parent_node, label, ct_type=ct_type)",0,"if isinstance ( index , int ) :","if hasattr ( self , ""InsertByIndex"" ) :",0.036450472,10.55267032,0.26984127
"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab>if not line or line.startswith(""#"") or ""."" not in line:<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>reason = line.split("" # "")[1].split()[0].lower()<tab><tab><tab><tab>if reason == ""scanning"":  # too many false positives<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>retval[line.split("" # "")[0]] = (__info__, __reference__)<tab>return retval",0,"if "" # "" in line :",if len ( line ) > 1 :,0.021135836,7.267884212,0.481481481
"def _remove_event(self, event):<tab># Find event according to its timestamp.<tab># Index returned should be one behind.<tab>i = bisect.bisect(self._eventq, event)<tab># Having two events with identical timestamp is unlikely but possible.<tab># I am going to move forward and compare timestamp AND object address<tab># to make sure the correct object is found.<tab>while i > 0:<tab><tab>i -= 1<tab><tab>e = self._eventq[i]<tab><tab>if e.timestamp != event.timestamp:<tab><tab><tab>raise exception.EventNotFound(event)<tab><tab><IF-STMT><tab><tab><tab>self._eventq.pop(i)<tab><tab><tab>return<tab>raise exception.EventNotFound(event)",0,elif id ( e ) == id ( event ) :,if i >= len ( self . _eventq ) :,0.022202419,8.054496385,0.102564103
"def _safe_get_content(self, session, resolve_from):<tab>try:<tab><tab>resp = session.get(resolve_from, timeout=self._timeout)<tab><tab><IF-STMT><tab><tab><tab>return resp.content<tab><tab>raise self.ResolverError(""Error status_code={0}"".format(resp.status_code))<tab>except requests.RequestException:<tab><tab>raise self.ResolverError(""Request error from {0}"".format(resolve_from))",0,if resp . status_code == requests . codes . ok :,if resp . status_code == 200 :,0.237367572,52.45537839,0.408163265
"def splitlines(self, sep=None, replace=None):<tab>""Return split lines from any file descriptor""<tab>for fd in self.fd:<tab><tab>fd.seek(0)<tab><tab>for line in fd.readlines():<tab><tab><tab>if replace and sep:<tab><tab><tab><tab>yield line.replace(replace, sep).split(sep)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield line.replace(replace, "" "").split()<tab><tab><tab>else:<tab><tab><tab><tab>yield line.split(sep)",0,elif replace :,"elif "" "" in line :",0.041867472,1.00E-10,0.371428571
"def disable_verity():<tab>""""""Disables dm-verity on the device.""""""<tab>with log.waitfor(""Disabling dm-verity on %s"" % context.device):<tab><tab>root()<tab><tab>with AdbClient() as c:<tab><tab><tab>reply = c.disable_verity()<tab><tab>if ""Verity already disabled"" in reply:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>reboot(wait=True)<tab><tab>elif ""0006closed"" in reply:<tab><tab><tab>return  # Emulator doesnt support Verity?<tab><tab>else:<tab><tab><tab>log.error(""Could not disable verity:\n%s"" % reply)",0,"elif ""Now reboot your device"" in reply :","elif ""0006"" in reply :",0.326135414,31.85035529,0.291666667
"def _process_property_change(self, msg):<tab>msg = super(Select, self)._process_property_change(msg)<tab>if ""value"" in msg:<tab><tab>if not self.values:<tab><tab><tab>pass<tab><tab>elif msg[""value""] is None:<tab><tab><tab>msg[""value""] = self.values[0]<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>idx = indexOf(msg[""value""], self.unicode_values)<tab><tab><tab>else:<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.labels)<tab><tab><tab>msg[""value""] = self._items[self.labels[idx]]<tab>msg.pop(""options"", None)<tab>return msg",0,"if isIn ( msg [ ""value"" ] , self . unicode_values ) :",if self . unicode_values :,0.038909458,16.02643072,0.38
"def merge(module_name, tree1, tree2):<tab>for child in tree2.node:<tab><tab>if isinstance(child, ast.Function):<tab><tab><tab>replaceFunction(tree1, child.name, child)<tab><tab>elif isinstance(child, ast.Assign):<tab><tab><tab>replaceAssign(tree1, child.nodes[0].name, child)<tab><tab><IF-STMT><tab><tab><tab>replaceClassMethods(tree1, child.name, child)<tab><tab>else:<tab><tab><tab>raise TranslationError(<tab><tab><tab><tab>""Do not know how to merge %s"" % child, child, module_name<tab><tab><tab>)<tab>return tree1",1,"elif isinstance ( child , ast . Class ) :","elif isinstance ( child , ast . Class ) :",0.75,100,1
"def handle(d: dict):<tab>for key, value in d.items():<tab><tab><IF-STMT><tab><tab><tab>if ""url"" not in value:<tab><tab><tab><tab>handle(value)<tab><tab><tab>else:<tab><tab><tab><tab>global count<tab><tab><tab><tab>count += 1",0,if type ( value ) == dict :,"if isinstance ( value , dict ) :",0.039168582,12.82777061,0.666666667
def __stop_loggers(self):<tab>if self._console_proc:<tab><tab>utils.nuke_subprocess(self._console_proc)<tab><tab>utils.nuke_subprocess(self._followfiles_proc)<tab><tab>self._console_proc = self._followfile_proc = None<tab><tab><IF-STMT><tab><tab><tab>self.job.warning_loggers.discard(self._logfile_warning_stream)<tab><tab>self._logfile_warning_stream.close(),1,if self . job :,if self . job :,0.75,100,1
"def unicode_metrics(metrics):<tab>for i, metric in enumerate(metrics):<tab><tab>for key, value in metric.items():<tab><tab><tab>if isinstance(value, basestring):<tab><tab><tab><tab>metric[key] = unicode(value, errors=""replace"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>value_list = list(value)<tab><tab><tab><tab>for j, value_element in enumerate(value_list):<tab><tab><tab><tab><tab>if isinstance(value_element, basestring):<tab><tab><tab><tab><tab><tab>value_list[j] = unicode(value_element, errors=""replace"")<tab><tab><tab><tab>metric[key] = tuple(value_list)<tab><tab>metrics[i] = metric<tab>return metrics",0,"elif isinstance ( value , tuple ) or isinstance ( value , list ) :","elif isinstance ( value , list ) :",0.330326689,41.68620197,0.444444444
"def __getitem__(self, idx):<tab>if isinstance(idx, slice):<tab><tab>start, stop, step = idx.indices(len(self))<tab><tab>return [self._revoked_cert(i) for i in range(start, stop, step)]<tab>else:<tab><tab>idx = operator.index(idx)<tab><tab><IF-STMT><tab><tab><tab>idx += len(self)<tab><tab>if not 0 <= idx < len(self):<tab><tab><tab>raise IndexError<tab><tab>return self._revoked_cert(idx)",0,if idx < 0 :,"if isinstance ( idx , slice ) :",0.02800146,7.267884212,0.314814815
"def _get_columns_and_column_names(row):<tab>column_names = []<tab>columns = []<tab>duplicate_counter = 1<tab>for i, column_name in enumerate(row):<tab><tab><IF-STMT><tab><tab><tab>column_name = ""column_{}"".format(xl_col_to_name(i))<tab><tab>if column_name in column_names:<tab><tab><tab>column_name = ""{}{}"".format(column_name, duplicate_counter)<tab><tab><tab>duplicate_counter += 1<tab><tab>column_names.append(column_name)<tab><tab>columns.append(<tab><tab><tab>{""name"": column_name, ""friendly_name"": column_name, ""type"": TYPE_STRING}<tab><tab>)<tab>return columns, column_names",1,if not column_name :,if not column_name :,0.75,100,1
"def format(self, format, dumper, attrib, data):<tab>if data:<tab><tab>logger.warn(""Unexpected data in %s object: %r"", attrib[""type""], data)<tab>try:<tab><tab>return ImageGeneratorObjectType.format(self, format, dumper, attrib, data)<tab>except ValueError:<tab><tab><IF-STMT><tab><tab><tab>attrib = attrib.copy()<tab><tab><tab>attrib[""type""] = attrib[""type""][6:]<tab><tab>return dumper.dump_img(IMAGE, attrib, None)",0,"if attrib [ ""type"" ] . startswith ( ""image+"" ) :","if attrib . get ( ""type"" ) :",0.083212016,17.65688615,0.6
"def handle_facts_wwn(facts):<tab>disk_shares = []<tab>for key, wwn in facts.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>path = key.replace(""wwn_"", """")<tab><tab>disk_shares.append(<tab><tab><tab>{<tab><tab><tab><tab>""serial_number"": normalize_wwn(wwn),<tab><tab><tab><tab>""volume"": ""/dev/mapper/%s"" % path,<tab><tab><tab>}<tab><tab>)<tab>return disk_shares",0,"if not key . startswith ( ""wwn_mpath"" ) :","if not key . startswith ( ""wwn_"" ) :",0.581882088,76.77331684,1
"def _finalize_load(*exc_info):<tab>try:<tab><tab>success_keys = [k for k in data_keys if k not in failed_keys]<tab><tab><IF-STMT><tab><tab><tab>self._holder_ref.put_objects_by_keys(<tab><tab><tab><tab>session_id, success_keys, pin_token=pin_token<tab><tab><tab>)<tab><tab>if exc_info:<tab><tab><tab>raise exc_info[1].with_traceback(exc_info[2]) from None<tab><tab>if failed_keys:<tab><tab><tab>raise StorageFull(<tab><tab><tab><tab>request_size=storage_full_sizes[0],<tab><tab><tab><tab>capacity=storage_full_sizes[1],<tab><tab><tab><tab>affected_keys=list(failed_keys),<tab><tab><tab>)<tab>finally:<tab><tab>shared_bufs[:] = []",1,if success_keys :,if success_keys :,0.531170663,1.00E-10,1
"def _get_base64md5(self):<tab>if ""md5"" in self.local_hashes and self.local_hashes[""md5""]:<tab><tab>md5 = self.local_hashes[""md5""]<tab><tab><IF-STMT><tab><tab><tab>md5 = md5.encode(""utf-8"")<tab><tab>return binascii.b2a_base64(md5).decode(""utf-8"").rstrip(""\n"")",0,"if not isinstance ( md5 , bytes ) :","if isinstance ( md5 , str ) :",0.18845666,37.70794597,0.26984127
"def tag_configure(self, *args, **keys):<tab>trace = False and not g.unitTesting<tab>if trace:<tab><tab>g.trace(args, keys)<tab>if len(args) == 1:<tab><tab>key = args[0]<tab><tab>self.tags[key] = keys<tab><tab>val = keys.get(""foreground"")<tab><tab>underline = keys.get(""underline"")<tab><tab><IF-STMT><tab><tab><tab>self.configDict[key] = val<tab><tab>if underline:<tab><tab><tab>self.configUnderlineDict[key] = True<tab>else:<tab><tab>g.trace(""oops"", args, keys)",1,if val :,if val :,0.531170663,1.00E-10,1
"def _findSubpath(self, path, A, B, inside):<tab>print(""finding"", A, B)<tab>sub = None<tab>for i in xrange(0, len(path) * 2):  # iterate twice with wrap around<tab><tab>j = i % len(path)<tab><tab>seg = path[j]<tab><tab>if inside.isInside(seg.midPoint()):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sub = Path(""subp"")<tab><tab><tab>print(""seg"", sub is None, seg)<tab><tab><tab>if sub is not None:<tab><tab><tab><tab>sub.append(seg)<tab><tab><tab>if eq(seg.B, B):<tab><tab><tab><tab>break<tab>print(""found"", sub)<tab>return sub",1,"if eq ( seg . A , A ) :","if eq ( seg . A , A ) :",1,100,1
"def indent_block(self, cursor):<tab>""""""Indent block after enter pressed""""""<tab>at_start_of_line = cursor.positionInBlock() == 0<tab>with self._neditor:<tab><tab>cursor.insertBlock()<tab><tab><IF-STMT><tab><tab><tab>indent = self._compute_indent(cursor)<tab><tab><tab>if indent is not None:<tab><tab><tab><tab>cursor.insertText(indent)<tab><tab><tab><tab>return True<tab><tab><tab>return False<tab>self._neditor.ensureCursorVisible()",0,if not at_start_of_line :,if at_start_of_line :,0.096488528,1.00E-10,0.6
def checkpoint():<tab>if checkpoint_asserts:<tab><tab>self.assert_integrity_idxs_take()<tab><tab>if node in self.idxs_memo:<tab><tab><tab>toposort(self.idxs_memo[node])<tab><tab><IF-STMT><tab><tab><tab>for take in self.take_memo[node]:<tab><tab><tab><tab>toposort(take),1,if node in self . take_memo :,if node in self . take_memo :,0.75,100,1
"def handle(self, *args, **options):<tab>with advisory_lock(""send-notifications-command"", wait=False) as acquired:<tab><tab><IF-STMT><tab><tab><tab>qs = HistoryChangeNotification.objects.all().order_by(""-id"")<tab><tab><tab>for change_notification in iter_queryset(qs, itersize=100):<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>send_sync_notifications(change_notification.pk)<tab><tab><tab><tab>except HistoryChangeNotification.DoesNotExist:<tab><tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>print(""Other process already running"")",1,if acquired :,if acquired :,0.531170663,1.00E-10,1
"def _parse_version_parts(s):<tab>for part in component_re.split(s):<tab><tab>part = replace(part, part)<tab><tab>if part in ["""", "".""]:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>yield part.zfill(8)  # pad for numeric comparison<tab><tab>else:<tab><tab><tab>yield ""*"" + part<tab>yield ""*final""  # ensure that alpha/beta/candidate are before final",0,"if part [ : 1 ] in ""0123456789"" :","if part [ - 1 : ] in ""0123456789"" :",0.216053678,55.83948265,1
"def set_password(user_id):<tab>try:<tab><tab>user = Journalist.query.get(user_id)<tab>except NoResultFound:<tab><tab>abort(404)<tab>password = request.form.get(""password"")<tab>if set_diceware_password(user, password) is not False:<tab><tab><IF-STMT><tab><tab><tab>revoke_token(user, user.last_token)<tab><tab>user.session_nonce += 1<tab><tab>db.session.commit()<tab>return redirect(url_for(""admin.edit_user"", user_id=user_id))",1,if user . last_token is not None :,if user . last_token is not None :,0.75,100,1
"def _get_normal_median_depth(normal_counts):<tab>depths = []<tab>with open(normal_counts) as in_handle:<tab><tab>header = None<tab><tab>for line in in_handle:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>header = line.strip().split()<tab><tab><tab>elif header:<tab><tab><tab><tab>n_vals = dict(zip(header, line.strip().split()))<tab><tab><tab><tab>depths.append(int(n_vals[""REF_COUNT""]) + int(n_vals[""ALT_COUNT""]))<tab>return np.median(depths)",0,"if header is None and not line . startswith ( ""@"" ) :",if header is None :,0.20469801,9.569649651,0.523809524
"def _gen_langs_in_db(self):<tab>for d in os.listdir(join(self.base_dir, ""db"")):<tab><tab>if d in self._non_lang_db_dirs:<tab><tab><tab>continue<tab><tab>lang_path = join(self.base_dir, ""db"", d, ""lang"")<tab><tab><IF-STMT><tab><tab><tab>log.warn(<tab><tab><tab><tab>""unexpected lang-zone db dir without 'lang' file: ""<tab><tab><tab><tab>""`%s' (skipping)"" % dirname(lang_path)<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>fin = open(lang_path, ""r"")<tab><tab>try:<tab><tab><tab>lang = fin.read().strip()<tab><tab>finally:<tab><tab><tab>fin.close()<tab><tab>yield lang",0,if not exists ( lang_path ) :,if not os . path . isfile ( lang_path ) :,0.277129393,42.80320607,0.408163265
"def negate(monad):<tab>sql = monad.getsql()[0]<tab>translator = monad.translator<tab>if translator.dialect == ""Oracle"":<tab><tab>result_sql = [""IS_NULL"", sql]<tab>else:<tab><tab>result_sql = [""EQ"", sql, [""VALUE"", """"]]<tab><tab><IF-STMT><tab><tab><tab>if isinstance(monad, AttrMonad):<tab><tab><tab><tab>result_sql = [""OR"", result_sql, [""IS_NULL"", sql]]<tab><tab><tab>else:<tab><tab><tab><tab>result_sql = [""EQ"", [""COALESCE"", sql, [""VALUE"", """"]], [""VALUE"", """"]]<tab>result = BoolExprMonad(result_sql, nullable=False)<tab>result.aggregated = monad.aggregated<tab>return result",0,if monad . nullable :,if len ( result_sql ) > 0 :,0.026407399,4.990049702,0.333333333
"def _model_shorthand(self, args):<tab>accum = []<tab>for arg in args:<tab><tab>if isinstance(arg, Node):<tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, Query):<tab><tab><tab>accum.append(arg)<tab><tab>elif isinstance(arg, ModelAlias):<tab><tab><tab>accum.extend(arg.get_proxy_fields())<tab><tab><IF-STMT><tab><tab><tab>accum.extend(arg._meta.declared_fields)<tab>return accum",0,"elif isclass ( arg ) and issubclass ( arg , Model ) :","elif hasattr ( arg , ""_meta"" ) :",0.112010593,15.30793815,0.302083333
"def get_hashes_from_fingerprint_with_reason(event, fingerprint):<tab>default_values = set([""{{ default }}"", ""{{default}}""])<tab>if any(d in fingerprint for d in default_values):<tab><tab>default_hashes = get_hashes_for_event_with_reason(event)<tab><tab>hash_count = len(default_hashes[1])<tab>else:<tab><tab>hash_count = 1<tab>hashes = OrderedDict((bit, []) for bit in fingerprint)<tab>for idx in xrange(hash_count):<tab><tab>for bit in fingerprint:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>hashes[bit].append(default_hashes)<tab><tab><tab>else:<tab><tab><tab><tab>hashes[bit] = bit<tab>return hashes.items()",0,if bit in default_values :,if bit in hashes :,0.394778655,28.64190458,0.733333333
"def default(self, obj):<tab>if hasattr(obj, ""__json__""):<tab><tab>return obj.__json__()<tab>elif isinstance(obj, collections.Iterable):<tab><tab>return list(obj)<tab>elif isinstance(obj, dt.datetime):<tab><tab>return obj.isoformat()<tab>elif hasattr(obj, ""__getitem__"") and hasattr(obj, ""keys""):<tab><tab>return dict(obj)<tab>elif hasattr(obj, ""__dict__""):<tab><tab>return {<tab><tab><tab>member: getattr(obj, member)<tab><tab><tab>for member in dir(obj)<tab><tab><tab><IF-STMT><tab><tab><tab>and not hasattr(getattr(obj, member), ""__call__"")<tab><tab>}<tab>return json.JSONEncoder.default(self, obj)",1,"if not member . startswith ( ""_"" )","if not member . startswith ( ""_"" )",0.75,100,1
"def get_http_auth(self, name):<tab>auth = self._config.get(""http-basic.{}"".format(name))<tab>if not auth:<tab><tab>username = self._config.get(""http-basic.{}.username"".format(name))<tab><tab>password = self._config.get(""http-basic.{}.password"".format(name))<tab><tab>if not username and not password:<tab><tab><tab>return None<tab>else:<tab><tab>username, password = auth[""username""], auth.get(""password"")<tab><tab><IF-STMT><tab><tab><tab>password = self.keyring.get_password(name, username)<tab>return {<tab><tab>""username"": username,<tab><tab>""password"": password,<tab>}",0,if password is None :,if self . keyring :,0.034123066,12.7033187,0.238095238
"def add_libdirs(self, envvar, sep, fatal=False):<tab>v = os.environ.get(envvar)<tab>if not v:<tab><tab>return<tab>for dir in str.split(v, sep):<tab><tab>dir = str.strip(dir)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>dir = os.path.normpath(dir)<tab><tab>if os.path.isdir(dir):<tab><tab><tab>if not dir in self.library_dirs:<tab><tab><tab><tab>self.library_dirs.append(dir)<tab><tab>elif fatal:<tab><tab><tab>fail(""FATAL: bad directory %s in environment variable %s"" % (dir, envvar))",1,if not dir :,if not dir :,0.75,100,1
"def PARSE_TWO_PARAMS(x, y):<tab>""""""used to convert different possible x/y params to a tuple""""""<tab>if y is not None:<tab><tab>return (x, y)<tab>else:<tab><tab>if isinstance(x, (list, tuple)):<tab><tab><tab>return (x[0], x[1])<tab><tab>else:<tab><tab><tab>if isinstance(x, UNIVERSAL_STRING):<tab><tab><tab><tab>x = x.strip()<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>return [int(w.strip()) for w in x.split("","")]<tab><tab><tab>return (x, x)",1,"if "","" in x :","if "","" in x :",0.75,100,1
"def _load_from_sym_dir(self, root):<tab>root = os.path.abspath(root)<tab>prefix_len = len(root) + 1<tab>for base, _, filenames in os.walk(root):<tab><tab>for filename in filenames:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>path = os.path.join(base, filename)<tab><tab><tab>lib_path = ""/"" + path[prefix_len:-4]<tab><tab><tab>self.add(lib_path, ELF.load_dump(path))",0,"if not filename . endswith ( "".sym"" ) :","if filename . endswith ( "".sym"" ) :",0.381254803,83.52052075,0.381818182
"def is_vertical(self):<tab>if not self.isFloating():<tab><tab>par = self.parent()<tab><tab><IF-STMT><tab><tab><tab>return par.dockWidgetArea(self) in (<tab><tab><tab><tab>Qt.LeftDockWidgetArea,<tab><tab><tab><tab>Qt.RightDockWidgetArea,<tab><tab><tab>)<tab>return self.size().height() > self.size().width()",0,"if par and hasattr ( par , ""dockWidgetArea"" ) :",if par is not None :,0.13343693,6.609029796,0.333333333
"def writeBit(self, state, endian):<tab>if self._bit_pos == 7:<tab><tab>self._bit_pos = 0<tab><tab>if state:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._byte |= 1<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 128<tab><tab>self._output.write(chr(self._byte))<tab><tab>self._byte = 0<tab>else:<tab><tab>if state:<tab><tab><tab>if endian is BIG_ENDIAN:<tab><tab><tab><tab>self._byte |= 1 << self._bit_pos<tab><tab><tab>else:<tab><tab><tab><tab>self._byte |= 1 << (7 - self._bit_pos)<tab><tab>self._bit_pos += 1",1,if endian is BIG_ENDIAN :,if endian is BIG_ENDIAN :,0.75,100,1
"def init(self):<tab>self.sock.setblocking(True)<tab>if self.parser is None:<tab><tab># wrap the socket if needed<tab><tab><IF-STMT><tab><tab><tab>self.sock = ssl.wrap_socket(<tab><tab><tab><tab>self.sock, server_side=True, **self.cfg.ssl_options<tab><tab><tab>)<tab><tab># initialize the parser<tab><tab>self.parser = http.RequestParser(self.cfg, self.sock, self.client)",0,if self . cfg . is_ssl :,if self . cfg . ssl_options :,0.574113272,50.19724249,1
"def construct_scalar(self, node):<tab>if isinstance(node, MappingNode):<tab><tab>for key_node, value_node in node.value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return self.construct_scalar(value_node)<tab>return super().construct_scalar(node)",0,"if key_node . tag == ""tag:yaml.org,2002:value"" :","if isinstance ( key_node , Node ) and isinstance ( value_node , Node ) :",0.016345905,8.836253225,0.303030303
"def typeNewLine(self, line):<tab>if line >= 0:<tab><tab>iter = self.buffer.get_iter_at_line(line)<tab><tab><IF-STMT><tab><tab><tab>iter.forward_to_line_end()<tab><tab>self.buffer.place_cursor(iter)<tab>elif line < 0:<tab><tab>iter = self.buffer.get_end_iter()<tab><tab>for i in range(line, -1):<tab><tab><tab>iter.backward_line()<tab><tab>iter.forward_to_line_end()<tab><tab>self.buffer.place_cursor(iter)<tab>press(self.view, ""\n"")",0,if not iter . ends_line ( ) :,if i == line - 1 :,0.018333425,5.660233916,0.26984127
"def _render_ib_interfaces(cls, network_state, iface_contents, flavor):<tab>ib_filter = renderer.filter_by_type(""infiniband"")<tab>for iface in network_state.iter_interfaces(ib_filter):<tab><tab>iface_name = iface[""name""]<tab><tab>iface_cfg = iface_contents[iface_name]<tab><tab>iface_cfg.kind = ""infiniband""<tab><tab><IF-STMT><tab><tab>route_cfg = iface_cfg.routes<tab><tab>cls._render_subnets(<tab><tab><tab>iface_cfg, iface_subnets, network_state.has_default_route, flavor<tab><tab>)<tab><tab>cls._render_subnet_routes(iface_cfg, route_cfg, iface_subnets, flavor)",0,"iface_subnets = iface . get ( ""subnets"" , [ ] )",iface_subnets = iface_cfg . subnets,0.020497365,24.92597867,0.236842105
"def stop(self):<tab>""""""Stops the slapd server, and waits for it to terminate""""""<tab>if self._proc is not None:<tab><tab>self._log.debug(""stopping slapd"")<tab><tab><IF-STMT><tab><tab><tab>self._proc.terminate()<tab><tab>else:<tab><tab><tab>import posix, signal<tab><tab><tab>posix.kill(self._proc.pid, signal.SIGHUP)<tab><tab><tab># time.sleep(1)<tab><tab><tab># posix.kill(self._proc.pid, signal.SIGTERM)<tab><tab><tab># posix.kill(self._proc.pid, signal.SIGKILL)<tab><tab>self.wait()",0,"if hasattr ( self . _proc , ""terminate"" ) :",if self . _proc . is_alive ( ) :,0.123080218,24.92583274,0.483333333
"def _listen(self, consumer_id: str) -> AsyncIterable[Any]:<tab>try:<tab><tab>while True:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>async for msg in self._listen_to_queue(consumer_id):<tab><tab><tab><tab><tab>if msg is not None:<tab><tab><tab><tab><tab><tab>yield msg<tab><tab><tab><tab>await asyncio.sleep(0.5)<tab><tab><tab>else:<tab><tab><tab><tab>async for msg in self._listen_to_ws():<tab><tab><tab><tab><tab>yield msg<tab>except asyncio.CancelledError:<tab><tab>pass<tab>except Exception as e:<tab><tab>raise e",0,if self . _listening :,if self . queue is not None :,0.193606478,22.08959113,0.357142857
"def discover_misago_admin():<tab>for app in apps.get_app_configs():<tab><tab>module = import_module(app.name)<tab><tab>if not hasattr(module, ""admin""):<tab><tab><tab>continue<tab><tab>admin_module = import_module(""%s.admin"" % app.name)<tab><tab>if hasattr(admin_module, ""MisagoAdminExtension""):<tab><tab><tab>extension = getattr(admin_module, ""MisagoAdminExtension"")()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>extension.register_navigation_nodes(site)<tab><tab><tab>if hasattr(extension, ""register_urlpatterns""):<tab><tab><tab><tab>extension.register_urlpatterns(urlpatterns)",1,"if hasattr ( extension , ""register_navigation_nodes"" ) :","if hasattr ( extension , ""register_navigation_nodes"" ) :",0.75,100,1
"def update_job(self, job):<tab>if not self.redis.hexists(self.jobs_key, job.id):<tab><tab>raise JobLookupError(job.id)<tab>with self.redis.pipeline() as pipe:<tab><tab>pipe.hset(<tab><tab><tab>self.jobs_key,<tab><tab><tab>job.id,<tab><tab><tab>pickle.dumps(job.__getstate__(), self.pickle_protocol),<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>pipe.zadd(<tab><tab><tab><tab>self.run_times_key,<tab><tab><tab><tab>{job.id: datetime_to_utc_timestamp(job.next_run_time)},<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>pipe.zrem(self.run_times_key, job.id)<tab><tab>pipe.execute()",0,if job . next_run_time :,if job . next_run_time is not None :,0.351498834,63.15552372,0.444444444
"def _get_first_available_entry_node(self) -> Optional[str]:<tab>for entry_node in self.entry_nodes:<tab><tab>if entry_node not in self.locked_entry_nodes:<tab><tab><tab>_, wait_until = self._parse_entry_node(entry_node)<tab><tab><tab>now = time.time()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return entry_node<tab>return None",0,if wait_until <= now :,if now > wait_until :,0.288498786,25.20147281,1
"def answers(self, other):<tab>if not isinstance(other, TCP):<tab><tab>return 0<tab>if conf.checkIPsrc:<tab><tab>if not ((self.sport == other.sport) and (self.dport == other.dport)):<tab><tab><tab>return 0<tab>if conf.check_TCPerror_seqack:<tab><tab>if self.seq is not None:<tab><tab><tab>if self.seq != other.seq:<tab><tab><tab><tab>return 0<tab><tab>if self.ack is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 0<tab>return 1",1,if self . ack != other . ack :,if self . ack != other . ack :,1,100,1
"def run(self):<tab>if self.check():<tab><tab>path = ""/BWT/utils/logs/read_log.jsp?filter=&log=../../../../../../../../..{}"".format(<tab><tab><tab>self.filename<tab><tab>)<tab><tab>response = self.http_request(method=""GET"", path=path)<tab><tab><IF-STMT><tab><tab><tab>print_success(""Exploit success"")<tab><tab><tab>print_status(""Reading file: {}"".format(self.filename))<tab><tab><tab>print_info(response.text)<tab><tab>else:<tab><tab><tab>print_error(""Exploit failed - could not read file"")<tab>else:<tab><tab>print_error(""Exploit failed - device seems to be not vulnerable"")",0,if response and response . status_code == 200 and len ( response . text ) :,if response and response . status_code == 200 :,0.379432046,51.53305363,0.606349206
"def write(self, s):<tab>if self.closed:<tab><tab>raise ValueError(""write to closed file"")<tab>if type(s) not in (unicode, str, bytearray):<tab><tab># See issue #19481<tab><tab>if isinstance(s, unicode):<tab><tab><tab>s = unicode.__getitem__(s, slice(None))<tab><tab><IF-STMT><tab><tab><tab>s = str.__str__(s)<tab><tab>elif isinstance(s, bytearray):<tab><tab><tab>s = bytearray.__str__(s)<tab><tab>else:<tab><tab><tab>raise TypeError(""must be string, not "" + type(s).__name__)<tab>return self.shell.write(s, self.tags)",1,"elif isinstance ( s , str ) :","elif isinstance ( s , str ) :",0.75,100,1
"def test_checkblock_valid(self):<tab>for comment, fHeader, fCheckPoW, cur_time, blk in load_test_vectors(<tab><tab>""checkblock_valid.json""<tab>):<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>CheckBlockHeader(blk, fCheckPoW=fCheckPoW, cur_time=cur_time)<tab><tab><tab>else:<tab><tab><tab><tab>CheckBlock(blk, fCheckPoW=fCheckPoW, cur_time=cur_time)<tab><tab>except ValidationError as err:<tab><tab><tab>self.fail('Failed ""%s"" with error %r' % (comment, err))",1,if fHeader :,if fHeader :,0.531170663,1.00E-10,1
"def _lookup_fqdn(ip):<tab>try:<tab><tab>return [socket.getfqdn(socket.gethostbyaddr(ip)[0])]<tab>except socket.herror as err:<tab><tab><IF-STMT><tab><tab><tab># No FQDN for this IP address, so we don't need to know this all the time.<tab><tab><tab>log.debug(""Unable to resolve address %s: %s"", ip, err)<tab><tab>else:<tab><tab><tab>log.error(err_message, err)<tab>except (socket.error, socket.gaierror, socket.timeout) as err:<tab><tab>log.error(err_message, err)",0,"if err . errno in ( 0 , HOST_NOT_FOUND , NO_DATA ) :",if err . errno == errno . EADDRNOTAVAIL :,0.155959932,11.29295626,0.523809524
"def send_telnet(self, *args: str):<tab>try:<tab><tab>shell = TelnetShell(self.host)<tab><tab>for command in args:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>shell.check_or_download_busybox()<tab><tab><tab><tab>shell.run_ftp()<tab><tab><tab>else:<tab><tab><tab><tab>shell.exec(command)<tab><tab>shell.close()<tab>except Exception as e:<tab><tab>_LOGGER.exception(f""Telnet command error: {e}"")",1,"if command == ""ftp"" :","if command == ""ftp"" :",0.75,100,1
"def write(path, data, kind=""OTHER"", dohex=0):<tab>asserttype1(data)<tab>kind = string.upper(kind)<tab>try:<tab><tab>os.remove(path)<tab>except os.error:<tab><tab>pass<tab>err = 1<tab>try:<tab><tab><IF-STMT><tab><tab><tab>writelwfn(path, data)<tab><tab>elif kind == ""PFB"":<tab><tab><tab>writepfb(path, data)<tab><tab>else:<tab><tab><tab>writeother(path, data, dohex)<tab><tab>err = 0<tab>finally:<tab><tab>if err and not DEBUG:<tab><tab><tab>try:<tab><tab><tab><tab>os.remove(path)<tab><tab><tab>except os.error:<tab><tab><tab><tab>pass",0,"if kind == ""LWFN"" :","if kind == ""FD"" :",0.394778655,59.46035575,1
"def ApplyInScriptedSection(self, codeBlock, fn, args):<tab>self.BeginScriptedSection()<tab>try:<tab><tab>try:<tab><tab><tab># 				print ""ApplyInSS"", codeBlock, fn, args<tab><tab><tab>return self._ApplyInScriptedSection(fn, args)<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.debugManager.OnLeaveScript()<tab><tab><tab>self.EndScriptedSection()<tab>except:<tab><tab>self.HandleException(codeBlock)",1,if self . debugManager :,if self . debugManager :,0.75,100,1
"def _escape_attrib(text):<tab># escape attribute value<tab>try:<tab><tab>if ""&"" in text:<tab><tab><tab>text = text.replace(""&"", ""&amp;"")<tab><tab><IF-STMT><tab><tab><tab>text = text.replace(""<"", ""&lt;"")<tab><tab>if "">"" in text:<tab><tab><tab>text = text.replace("">"", ""&gt;"")<tab><tab>if '""' in text:<tab><tab><tab>text = text.replace('""', ""&quot;"")<tab><tab>if ""\n"" in text:<tab><tab><tab>text = text.replace(""\n"", ""&#10;"")<tab><tab>return text<tab>except (TypeError, AttributeError):  # pragma: no cover<tab><tab>_raise_serialization_error(text)",1,"if ""<"" in text :","if ""<"" in text :",0.75,100,1
"def compile_relation(self, method, expr, range_list, negated=False):<tab>ranges = []<tab>for item in range_list[1]:<tab><tab><IF-STMT><tab><tab><tab>ranges.append(self.compile(item[0]))<tab><tab>else:<tab><tab><tab>ranges.append(""%s..%s"" % tuple(map(self.compile, item)))<tab>return ""%s%s %s %s"" % (<tab><tab>self.compile(expr),<tab><tab>negated and "" not"" or """",<tab><tab>method,<tab><tab>"","".join(ranges),<tab>)",0,if item [ 0 ] == item [ 1 ] :,"if isinstance ( item , tuple ) :",0.013374522,4.408194606,0.274725275
"def emptyTree(self):<tab>for child in self:<tab><tab>childObj = child.getObject()<tab><tab>del childObj[NameObject(""/Parent"")]<tab><tab>if NameObject(""/Next"") in childObj:<tab><tab><tab>del childObj[NameObject(""/Next"")]<tab><tab><IF-STMT><tab><tab><tab>del childObj[NameObject(""/Prev"")]<tab>if NameObject(""/Count"") in self:<tab><tab>del self[NameObject(""/Count"")]<tab>if NameObject(""/First"") in self:<tab><tab>del self[NameObject(""/First"")]<tab>if NameObject(""/Last"") in self:<tab><tab>del self[NameObject(""/Last"")]",0,"if NameObject ( ""/Prev"" ) in childObj :","if NameObject ( /Prev"" ) in childObj :",0.251462237,71.0866789,1
"def connect_to_uri(self, uri, autoconnect=None, do_start=True):<tab>try:<tab><tab>conn = self._check_conn(uri)<tab><tab>if not conn:<tab><tab><tab># Unknown connection, add it<tab><tab><tab>conn = self.add_conn(uri)<tab><tab>if autoconnect is not None:<tab><tab><tab>conn.set_autoconnect(bool(autoconnect))<tab><tab>self.show_manager()<tab><tab><IF-STMT><tab><tab><tab>conn.open()<tab><tab>return conn<tab>except Exception:<tab><tab>logging.exception(""Error connecting to %s"", uri)<tab><tab>return None",1,if do_start :,if do_start :,0.531170663,1.00E-10,1
"def get_expression(self):<tab>""""""Return the expression as a printable string.""""""<tab>l = []<tab>for c in self.content:<tab><tab>if c.op is not None:  # only applies to first cell<tab><tab><tab>l.append(c.op)<tab><tab><IF-STMT><tab><tab><tab>l.append(""("" + c.child.get_expression() + "")"")<tab><tab>else:<tab><tab><tab>l.append(""%d"" % c.get_value())<tab>return """".join(l)",0,if c . child is not None :,elif c . child is not None :,0.441849692,84.08964153,0.75
"def to_word_end(view, s):<tab>if mode == modes.NORMAL:<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(pt)<tab>elif mode in (modes.VISUAL, modes.VISUAL_BLOCK):<tab><tab><IF-STMT><tab><tab><tab>pt = word_end_reverse(view, s.b - 1, count)<tab><tab><tab>if pt > s.a:<tab><tab><tab><tab>return sublime.Region(s.a, pt + 1)<tab><tab><tab>return sublime.Region(s.a + 1, pt)<tab><tab>pt = word_end_reverse(view, s.b, count)<tab><tab>return sublime.Region(s.a, pt)<tab>return s",0,if s . a < s . b :,if s . a > s . b :,0.424889319,59.69491792,1
"def whichmodule(obj, name):<tab>""""""Find the module an object belong to.""""""<tab>module_name = getattr(obj, ""__module__"", None)<tab>if module_name is not None:<tab><tab>return module_name<tab># Protect the iteration by using a list copy of sys.modules against dynamic<tab># modules that trigger imports of other modules upon calls to getattr.<tab>for module_name, module in sys.modules.copy().items():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>try:<tab><tab><tab>if _getattribute(module, name)[0] is obj:<tab><tab><tab><tab>return module_name<tab><tab>except AttributeError:<tab><tab><tab>pass<tab>return ""__main__""",0,"if module_name == ""__main__"" or module is None :","if module_name == ""__main__"" :",0.198507111,70.37688239,0.277777778
"def summarize_scalar_dict(name_data, step, name_scope=""Losses/""):<tab>if name_data:<tab><tab>with tf.name_scope(name_scope):<tab><tab><tab>for name, data in name_data.items():<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>tf.compat.v2.summary.scalar(name=name, data=data, step=step)",0,if data is not None :,"if isinstance ( data , tf . compat . v2 . summary . Scalar ) :",0.018658045,3.218582627,0.153508772
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.set_content(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.set_blob_key(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 24:<tab><tab><tab>self.set_width(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 32:<tab><tab><tab>self.set_height(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def gather_files(fileset):<tab>common_type = get_common_filetype(fileset)<tab>files = []<tab>for file in fileset.file:<tab><tab>filename = file.name<tab><tab>if file.is_include_file == True:<tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""is_include_file"": True}<tab><tab><IF-STMT><tab><tab><tab>if type(filename) == str:<tab><tab><tab><tab>filename = {}<tab><tab><tab>filename[file.name] = {""file_type"": file.file_type}<tab><tab>files.append(filename)<tab>return files",0,if file . file_type != common_type :,elif common_type == file . file_type :,0.087913613,49.26862021,0.5
"def data(self, index: QModelIndex, role=Qt.DisplayRole):<tab>if not index.isValid():<tab><tab>return None<tab>if role == Qt.DisplayRole or role == Qt.EditRole:<tab><tab>i = index.row()<tab><tab>j = index.column()<tab><tab>fieldtype = self.field_types[i]<tab><tab><IF-STMT><tab><tab><tab>return fieldtype.caption<tab><tab>elif j == 1:<tab><tab><tab>return fieldtype.function.name<tab><tab>elif j == 2:<tab><tab><tab>return ProtocolLabel.DISPLAY_FORMATS[fieldtype.display_format_index]",1,if j == 0 :,if j == 0 :,0.75,100,1
"def format_coord(x, y):<tab># callback function to format coordinate display in toolbar<tab>x = int(x + 0.5)<tab>y = int(y + 0.5)<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return ""%s @ %s [%4i, %4i]"" % (cur_ax_dat[1][y, x], current, x, y)<tab><tab>else:<tab><tab><tab>return ""%s @ [%4i, %4i]"" % (data[y, x], x, y)<tab>except IndexError:<tab><tab>return """"",0,if dims :,if cur_ax_dat [ 1 ] [ y ] :,0.04309983,1.00E-10,0.384615385
"def getAllUIExtensions(self):<tab>extensions = []<tab>if getExecutionCodeType() == ""MEASURE"":<tab><tab>text = getMeasurementResultString(self)<tab><tab>extensions.append(TextUIExtension(text))<tab>errorType = self.getErrorHandlingType()<tab>if errorType in (""MESSAGE"", ""EXCEPTION""):<tab><tab>data = infoByNode[self.identifier]<tab><tab>message = data.errorMessage<tab><tab><IF-STMT><tab><tab><tab>extensions.append(ErrorUIExtension(message))<tab>extraExtensions = self.getUIExtensions()<tab>if extraExtensions is not None:<tab><tab>extensions.extend(extraExtensions)<tab>return extensions",0,if message is not None and data . showErrorMessage :,if message is not None :,0.36568904,40.83056064,0.619047619
"def on_notify(self, notification):<tab>subject = notification[""subject""]<tab>if subject.startswith(""remote_recording.""):<tab><tab>if ""should_start"" in subject and self.online:<tab><tab><tab>session_name = notification[""session_name""]<tab><tab><tab>self.sensor.set_control_value(""capture_session_name"", session_name)<tab><tab><tab>self.sensor.set_control_value(""local_capture"", True)<tab><tab><IF-STMT><tab><tab><tab>self.sensor.set_control_value(""local_capture"", False)",0,"elif ""should_stop"" in subject :","elif ""should_stop"" in subject and not self . online :",0.246217171,52.96074933,0.45
"def _log_conn_errors(self):<tab>if ""connection"" in self.event.data:<tab><tab>cinfo = self.event.data[""connection""]<tab><tab><IF-STMT><tab><tab><tab>err_msg = cinfo.get(""error"", [None, None])[1]<tab><tab><tab>if err_msg:<tab><tab><tab><tab>self._log_status(err_msg)",0,"if not cinfo . get ( ""live"" ) :","if cinfo . get ( ""error"" , [ None , None ] ) :",0.14911883,28.0395012,0.324561404
"def setChanged(self, c, changed):<tab># Find the tab corresponding to c.<tab>dw = c.frame.top  # A DynamicWindow<tab>i = self.indexOf(dw)<tab>if i < 0:<tab><tab>return<tab>s = self.tabText(i)<tab>s = g.u(s)<tab>if len(s) > 2:<tab><tab>if changed:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>title = ""* "" + s<tab><tab><tab><tab>self.setTabText(i, title)<tab><tab>else:<tab><tab><tab>if s.startswith(""* ""):<tab><tab><tab><tab>title = s[2:]<tab><tab><tab><tab>self.setTabText(i, title)",0,"if not s . startswith ( ""* "" ) :","if s . startswith ( ""* "" ) :",0.396079378,81.76129039,0.384615385
"def load_file_in_same_dir(ref_file, filename):<tab>""""""Load a given file. Works even when the file is contained inside a zip.""""""<tab>from couchpotato.core.helpers.encoding import toUnicode<tab>path = split_path(toUnicode(ref_file))[:-1] + [filename]<tab>for i, p in enumerate(path):<tab><tab><IF-STMT><tab><tab><tab>zfilename = os.path.join(*path[: i + 1])<tab><tab><tab>zfile = zipfile.ZipFile(zfilename)<tab><tab><tab>return zfile.read(""/"".join(path[i + 1 :]))<tab>return u(io.open(os.path.join(*path), encoding=""utf-8"").read())",0,"if p . endswith ( "".zip"" ) :",if p == ref_file :,0.035401841,8.400788787,0.727272727
def __mpcReadyInSlaveMode(self):<tab>while True:<tab><tab>time.sleep(10)<tab><tab>if not win32gui.IsWindow(self.__listener.mpcHandle):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.callbacks.onMpcClosed(None)<tab><tab><tab>break,0,if self . callbacks . onMpcClosed :,if self . callbacks :,0.293430265,47.39878501,0.771428571
"def _invalidate(self, resource_group_name: str, scale_set_name: str) -> None:<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>del self._instance_cache[(resource_group_name, scale_set_name)]<tab><tab>if resource_group_name in self._scale_set_cache:<tab><tab><tab>del self._scale_set_cache[resource_group_name]<tab><tab>if resource_group_name in self._remaining_instances_cache:<tab><tab><tab>del self._remaining_instances_cache[resource_group_name]",1,"if ( resource_group_name , scale_set_name ) in self . _instance_cache :","if ( resource_group_name , scale_set_name ) in self . _instance_cache :",0.75,100,1
"def close(self):<tab>if self._serial is not None:<tab><tab>try:<tab><tab><tab>self._serial.cancel_read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._reading_thread.join()<tab><tab>finally:<tab><tab><tab>try:<tab><tab><tab><tab>self._serial.close()<tab><tab><tab><tab>self._serial = None<tab><tab><tab>except Exception:<tab><tab><tab><tab>logging.exception(""Couldn't close serial"")",0,if self . _reading_thread :,if self . _reading_thread is not None :,0.351498834,59.00468726,0.444444444
"def channel_sizes(self):<tab>""""""List of channel sizes: [(width, height)].""""""<tab>sizes = []<tab>for channel in self.channel_info:<tab><tab><IF-STMT><tab><tab><tab>sizes.append((self.mask_data.width, self.mask_data.height))<tab><tab>elif channel.id == ChannelID.REAL_USER_LAYER_MASK:<tab><tab><tab>sizes.append((self.mask_data.real_width, self.mask_data.real_height))<tab><tab>else:<tab><tab><tab>sizes.append((self.width, self.height))<tab>return sizes",0,if channel . id == ChannelID . USER_LAYER_MASK :,if channel . id == ChannelID . SHIFT_MASK :,0.627090855,62.20700407,1
"def get_module_settings():<tab>included_setting = []<tab>module = DataGetter.get_module()<tab>if module is not None:<tab><tab>if module.ticket_include:<tab><tab><tab>included_setting.append(""ticketing"")<tab><tab><IF-STMT><tab><tab><tab>included_setting.append(""payments"")<tab><tab>if module.donation_include:<tab><tab><tab>included_setting.append(""donations"")<tab>return included_setting",0,if module . payment_include :,if module . payments_include :,0.394778655,41.11336169,1
"def _format_block(<tab>self, prefix: str, lines: List[str], padding: str = None) -> List[str]:<tab>if lines:<tab><tab><IF-STMT><tab><tab><tab>padding = "" "" * len(prefix)<tab><tab>result_lines = []<tab><tab>for i, line in enumerate(lines):<tab><tab><tab>if i == 0:<tab><tab><tab><tab>result_lines.append((prefix + line).rstrip())<tab><tab><tab>elif line:<tab><tab><tab><tab>result_lines.append(padding + line)<tab><tab><tab>else:<tab><tab><tab><tab>result_lines.append("""")<tab><tab>return result_lines<tab>else:<tab><tab>return [prefix]",1,if padding is None :,if padding is None :,0.75,100,1
"def get_task_by_id(events, task_id):<tab>if hasattr(Task, ""_fields""):  # Old version<tab><tab>return events.state.tasks.get(task_id)<tab>else:<tab><tab>_fields = Task._defaults.keys()<tab><tab>task = events.state.tasks.get(task_id)<tab><tab><IF-STMT><tab><tab><tab>task._fields = _fields<tab><tab>return task",0,if task is not None :,if _fields :,0.026485502,1.00E-10,0.222222222
"def check(self, value):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>v = value<tab><tab>else:<tab><tab><tab>v = decimal.Decimal(str(value).replace(self.dot, "".""))<tab><tab>return v, None<tab>except (ValueError, TypeError, decimal.InvalidOperation):<tab><tab>return value, translate(self.message)",0,"if isinstance ( value , decimal . Decimal ) :",if self . dot is None :,0.014969815,5.630400553,0.222222222
"def check_sales_order_on_hold_or_close(self, ref_fieldname):<tab>for d in self.get(""items""):<tab><tab><IF-STMT><tab><tab><tab>status = frappe.db.get_value(""Sales Order"", d.get(ref_fieldname), ""status"")<tab><tab><tab>if status in (""Closed"", ""On Hold""):<tab><tab><tab><tab>frappe.throw(<tab><tab><tab><tab><tab>_(""Sales Order {0} is {1}"").format(d.get(ref_fieldname), status)<tab><tab><tab><tab>)",1,if d . get ( ref_fieldname ) :,if d . get ( ref_fieldname ) :,0.75,100,1
"def nested_match(expect, value):<tab>if expect == value:<tab><tab>return True<tab>if isinstance(expect, dict) and isinstance(value, dict):<tab><tab>for k, v in expect.items():<tab><tab><tab>if k in value:<tab><tab><tab><tab>if not nested_match(v, value[k]):<tab><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>return True<tab>if isinstance(expect, list) and isinstance(value, list):<tab><tab>for x, y in zip(expect, value):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",1,"if not nested_match ( x , y ) :","if not nested_match ( x , y ) :",0.75,100,1
"def test_setup_app_sets_loader(self, app):<tab>prev = os.environ.get(""CELERY_LOADER"")<tab>try:<tab><tab>cmd = MockCommand(app=app)<tab><tab>cmd.setup_app_from_commandline([""--loader=X.Y:Z""])<tab><tab>assert os.environ[""CELERY_LOADER""] == ""X.Y:Z""<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>os.environ[""CELERY_LOADER""] = prev<tab><tab>else:<tab><tab><tab>del os.environ[""CELERY_LOADER""]",0,if prev is not None :,if prev :,0.050438393,1.00E-10,0.4
"def set_labels_for_constraints(self, constraints):<tab>for label in self._constraints_to_label_args(constraints):<tab><tab><IF-STMT><tab><tab><tab>log.info(<tab><tab><tab><tab>""setting node '%s' label '%s' to '%s'"",<tab><tab><tab><tab>self.name,<tab><tab><tab><tab>label.name,<tab><tab><tab><tab>label.value,<tab><tab><tab>)<tab><tab><tab>self.label_add(label.name, label.value)",0,if label not in self . labels :,if label . name not in self . labels :,0.503325822,58.1430737,0.357142857
"def _match(self, byte_chunk):<tab>quote_character = None<tab>data = byte_chunk.nhtml<tab>open_angle_bracket = data.rfind(""<"")<tab># We are inside <...<tab>if open_angle_bracket <= data.rfind("">""):<tab><tab>return False<tab>for s in data[open_angle_bracket + 1 :]:<tab><tab>if s in ATTR_DELIMITERS:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>quote_character = None<tab><tab><tab><tab>continue<tab><tab><tab>elif not quote_character:<tab><tab><tab><tab>quote_character = s<tab><tab><tab><tab>continue<tab>if quote_character == self.quote_character:<tab><tab>return True<tab>return False",1,if quote_character and s == quote_character :,if quote_character and s == quote_character :,0.75,100,1
"def _display_history(config, script, base, head, currents=()):<tab>for sc in script.walk_revisions(base=base or ""base"", head=head or ""heads""):<tab><tab><IF-STMT><tab><tab><tab>sc._db_current_indicator = sc.revision in currents<tab><tab>config.print_stdout(<tab><tab><tab>sc.cmd_format(<tab><tab><tab><tab>verbose=verbose,<tab><tab><tab><tab>include_branches=True,<tab><tab><tab><tab>include_doc=True,<tab><tab><tab><tab>include_parents=True,<tab><tab><tab>)<tab><tab>)",0,if indicate_current :,if sc . revision :,0.051944023,1.00E-10,0.416666667
"def set(self, key=None, value=None):<tab>if key is not None:<tab><tab>k = str(key)<tab><tab>if value is not None:<tab><tab><tab>self.store[k] = value<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.store[k]<tab>else:<tab><tab>self.store.clear()",0,if self . store . has_key ( k ) :,if k in self . store :,0.064100353,14.23172839,0.318181818
"def _finalize_load(*exc_info):<tab>try:<tab><tab>success_keys = [k for k in data_keys if k not in failed_keys]<tab><tab>if success_keys:<tab><tab><tab>self._holder_ref.put_objects_by_keys(<tab><tab><tab><tab>session_id, success_keys, pin_token=pin_token<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise exc_info[1].with_traceback(exc_info[2]) from None<tab><tab>if failed_keys:<tab><tab><tab>raise StorageFull(<tab><tab><tab><tab>request_size=storage_full_sizes[0],<tab><tab><tab><tab>capacity=storage_full_sizes[1],<tab><tab><tab><tab>affected_keys=list(failed_keys),<tab><tab><tab>)<tab>finally:<tab><tab>shared_bufs[:] = []",1,if exc_info :,if exc_info :,0.531170663,1.00E-10,1
"def ignore_module(module):<tab>result = False<tab>for check in ignore_these:<tab><tab>if ""/*"" in check:<tab><tab><tab>if check[:-1] in module:<tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab>if result:<tab><tab>print_warning(""Ignoring module: "" + module)<tab>return result",0,"if ( os . getcwd ( ) + ""/"" + check + "".py"" ) == module :",if check [ - 1 ] in module :,0.01435606,2.393469294,0.375
"def available(self, exception_flag=True):<tab>""""""True if the solver is available""""""<tab>if exception_flag is False:<tab><tab>return cplex_import_available<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise ApplicationError(<tab><tab><tab><tab>""No CPLEX <-> Python bindings available - CPLEX direct ""<tab><tab><tab><tab>""solver functionality is not available""<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>return True",0,if cplex_import_available is False :,"if sys . version_info < ( 3 , 0 ) :",0.023753722,4.065425429,0.276190476
"def close(self, checkcount=False):<tab>self.mutex.acquire()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>self.openers -= 1<tab><tab><tab>if self.openers == 0:<tab><tab><tab><tab>self.do_close()<tab><tab>else:<tab><tab><tab>if self.openers > 0:<tab><tab><tab><tab>self.do_close()<tab><tab><tab>self.openers = 0<tab>finally:<tab><tab>self.mutex.release()",1,if checkcount :,if checkcount :,0.531170663,1.00E-10,1
"def __get__(self, obj, type=None):<tab>if obj is None:<tab><tab>return self<tab>with self.lock:<tab><tab>value = obj.__dict__.get(self.__name__, self._default_value)<tab><tab><IF-STMT><tab><tab><tab>value = self.func(obj)<tab><tab><tab>obj.__dict__[self.__name__] = value<tab><tab>return value",0,if value is self . _default_value :,if value is None :,0.177865624,15.71901051,0.666666667
"def _test_pooling_iteration(input_shape, **kwargs):<tab>""""""One iteration of pool operation with given shapes and attributes""""""<tab>x = -np.arange(np.prod(input_shape), dtype=np.float32).reshape(input_shape) - 1<tab>with tf.Graph().as_default():<tab><tab>in_data = array_ops.placeholder(shape=input_shape, dtype=""float32"")<tab><tab>nn_ops.pool(in_data, **kwargs)<tab><tab><IF-STMT><tab><tab><tab>out_name = ""max_pool:0""<tab><tab>else:<tab><tab><tab>out_name = ""avg_pool:0""<tab><tab>compare_tf_with_tvm(x, ""Placeholder:0"", out_name)",0,"if kwargs [ ""pooling_type"" ] == ""MAX"" :","if kwargs . get ( ""max_pool"" , False ) :",0.030497945,6.959578722,0.571428571
def updateValue(self):<tab>if self._index:<tab><tab>val = toInt(self._model.data(self._index))<tab><tab><IF-STMT><tab><tab><tab>self._updating = True<tab><tab><tab>self.setValue(val)<tab><tab><tab>self._updating = False,0,if self . sld . value ( ) != val :,if val != self . getValue ( ) :,0.075904583,13.17048942,0.274725275
"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab><IF-STMT><tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab>if not count and i:<tab><tab><tab><tab>return i<tab>return i",0,if self == element :,if count and element in self :,0.031181344,9.287529,0.2
"def test_doctests(self):<tab>""""""Run tutorial doctests.""""""<tab>runner = doctest.DocTestRunner()<tab>failures = []<tab>for test in doctest.DocTestFinder().find(TutorialDocTestHolder):<tab><tab>failed, success = runner.run(test)<tab><tab><IF-STMT><tab><tab><tab>name = test.name<tab><tab><tab>assert name.startswith(""TutorialDocTestHolder.doctest_"")<tab><tab><tab>failures.append(name[30:])<tab><tab><tab># raise ValueError(""Tutorial doctest %s failed"" % test.name[30:])<tab>if failures:<tab><tab>raise ValueError(<tab><tab><tab>""%i Tutorial doctests failed: %s"" % (len(failures), "", "".join(failures))<tab><tab>)",0,if failed :,if not failed :,0.113486237,1.00E-10,0.416666667
"def send_preamble(self):<tab>""""""Transmit version/status/date/server, via self._write()""""""<tab>if self.origin_server:<tab><tab>if self.client_is_modern():<tab><tab><tab>self._write(""HTTP/%s %s\r\n"" % (self.http_version, self.status))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._write(""Date: %s\r\n"" % time.asctime(time.gmtime(time.time())))<tab><tab><tab>if self.server_software and not self.headers.has_key(""Server""):<tab><tab><tab><tab>self._write(""Server: %s\r\n"" % self.server_software)<tab>else:<tab><tab>self._write(""Status: %s\r\n"" % self.status)",0,"if not self . headers . has_key ( ""Date"" ) :",if time . time ( ) > 0 :,0.014731831,3.660348247,0.285714286
"def _verify_unique_measurement_keys(operations: Iterable[ops.Operation]):<tab>seen: Set[str] = set()<tab>for op in operations:<tab><tab>if isinstance(op.gate, ops.MeasurementGate):<tab><tab><tab>meas = op.gate<tab><tab><tab>key = protocols.measurement_key(meas)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(""Measurement key {} repeated"".format(key))<tab><tab><tab>seen.add(key)",1,if key in seen :,if key in seen :,0.75,100,1
"def test_dtype_basics(df):<tab>df[""new_virtual_column""] = df.x + 1<tab>for name in df.column_names:<tab><tab><IF-STMT><tab><tab><tab>assert df[name].values.dtype.kind in ""OSU""<tab><tab>else:<tab><tab><tab>assert df[name].values.dtype == df.dtype(df[name])",0,if df . dtype ( name ) == str_type :,"if name == ""virtual_column"" :",0.015145995,8.1821858,0.371428571
"def string_to_points(self, command, coord_string):<tab>numbers = string_to_numbers(coord_string)<tab>if command.upper() in [""H"", ""V""]:<tab><tab>i = {""H"": 0, ""V"": 1}[command.upper()]<tab><tab>xy = np.zeros((len(numbers), 2))<tab><tab>xy[:, i] = numbers<tab><tab><IF-STMT><tab><tab><tab>xy[:, 1 - i] = self.relative_point[1 - i]<tab>elif command.upper() == ""A"":<tab><tab>raise Exception(""Not implemented"")<tab>else:<tab><tab>xy = np.array(numbers).reshape((len(numbers) // 2, 2))<tab>result = np.zeros((xy.shape[0], self.dim))<tab>result[:, :2] = xy<tab>return result",0,if command . isupper ( ) :,if self . relative_point is not None :,0.021135836,5.522397784,0.21875
"def get_count(self, peek=False):<tab>if self.argument_supplied:<tab><tab>count = self.argument_value<tab><tab>if self.argument_negative:<tab><tab><tab>if count == 0:<tab><tab><tab><tab>count = -1<tab><tab><tab>else:<tab><tab><tab><tab>count = -count<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.argument_negative = False<tab><tab>if not peek:<tab><tab><tab>self.argument_supplied = False<tab>else:<tab><tab>count = 1<tab>return count",0,if not peek :,if count < 0 :,0.042407859,12.7033187,0.333333333
"def toggleSchedule(self, **kwargs):<tab>schedules = cfg.schedules()<tab>line = kwargs.get(""line"")<tab>if line:<tab><tab>for i, schedule in enumerate(schedules):<tab><tab><tab><IF-STMT><tab><tab><tab><tab># Toggle the schedule<tab><tab><tab><tab>schedule_split = schedule.split()<tab><tab><tab><tab>schedule_split[0] = ""%d"" % (schedule_split[0] == ""0"")<tab><tab><tab><tab>schedules[i] = "" "".join(schedule_split)<tab><tab><tab><tab>break<tab><tab>cfg.schedules.set(schedules)<tab><tab>config.save_config()<tab><tab>sabnzbd.Scheduler.restart()<tab>raise Raiser(self.__root)",0,if schedule == line :,if line . startswith ( schedule ) :,0.029323261,7.809849842,0.377777778
"def test_sanity_no_long_entities(CorpusType: Type[ColumnCorpus]):<tab>corpus = CorpusType()<tab>longest_entity = []<tab>for sentence in corpus.get_all_sentences():<tab><tab>entities = sentence.get_spans(""ner"")<tab><tab>for entity in entities:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>longest_entity = [t.text for t in entity.tokens]<tab>assert len(longest_entity) < 10, "" "".join(longest_entity)",0,if len ( entity . tokens ) > len ( longest_entity ) :,if len ( entity . tokens ) > 0 :,0.386327509,47.46358914,0.777777778
"def _set_helper(settings, path, value, data_type=None):<tab>path = _to_settings_path(path)<tab>method = settings.set<tab>if data_type is not None:<tab><tab>name = None<tab><tab>if data_type == bool:<tab><tab><tab>name = ""setBoolean""<tab><tab>elif data_type == float:<tab><tab><tab>name = ""setFloat""<tab><tab><IF-STMT><tab><tab><tab>name = ""setInt""<tab><tab>if name is not None:<tab><tab><tab>method = getattr(settings, name)<tab>method(path, value)<tab>settings.save()",1,elif data_type == int :,elif data_type == int :,0.75,100,1
"def scan_page(self, address_space, page_offset, fullpage=False):<tab>""""""Runs through patchers for a single page""""""<tab>if fullpage:<tab><tab>pagedata = address_space.read(page_offset, PAGESIZE)<tab>for patcher in self.patchers:<tab><tab>for offset, data in patcher.get_constraints():<tab><tab><tab>if fullpage:<tab><tab><tab><tab>testdata = pagedata[offset : offset + len(data)]<tab><tab><tab>else:<tab><tab><tab><tab>testdata = address_space.read(page_offset + offset, len(data))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>yield patcher",0,if data != testdata :,if not testdata :,0.070152444,21.44409712,0.6
"def accessSlice(self, node):<tab>self.visit(node.value)<tab>node.obj = self.getObj(node.value)<tab>self.access = _access.INPUT<tab>lower, upper = node.slice.lower, node.slice.upper<tab>if lower:<tab><tab>self.visit(lower)<tab>if upper:<tab><tab>self.visit(upper)<tab>if isinstance(node.obj, intbv):<tab><tab><IF-STMT><tab><tab><tab>self.require(lower, ""Expected leftmost index"")<tab><tab><tab>leftind = self.getVal(lower)<tab><tab><tab>if upper:<tab><tab><tab><tab>rightind = self.getVal(upper)<tab><tab><tab>else:<tab><tab><tab><tab>rightind = 0<tab><tab><tab>node.obj = node.obj[leftind:rightind]",0,if self . kind == _kind . DECLARATION :,if lower :,0.013130314,1.00E-10,0.305555556
"def childConnectionLost(self, childFD):<tab>if self.state == 1:<tab><tab>self.fail(""got connectionLost(%d) during state 1"" % childFD)<tab><tab>return<tab>if self.state == 2:<tab><tab><IF-STMT><tab><tab><tab>self.fail(""got connectionLost(%d) (not 4) during state 2"" % childFD)<tab><tab><tab>return<tab><tab>self.state = 3<tab><tab>self.transport.closeChildFD(5)<tab><tab>return",0,if childFD != 4 :,if self . state == 3 :,0.027969855,7.267884212,0.265306122
"def _find_matches(self, file, lookup, **kwargs):<tab>matches = []<tab>for format in lookup.values():<tab><tab><IF-STMT><tab><tab><tab>is_format, skwargs = format.sniffer_function(file, **kwargs)<tab><tab><tab>file.seek(0)<tab><tab><tab>if is_format:<tab><tab><tab><tab>matches.append((format.name, skwargs))<tab>return matches",0,if format . sniffer_function is not None :,"if hasattr ( format , ""sniffer_function"" ) :",0.019345088,14.99110695,0.25
"def ParseCodeLines(tokens, case):<tab>""""""Parse uncommented code in a test case.""""""<tab>_, kind, item = tokens.peek()<tab><IF-STMT><tab><tab>raise ParseError(""Expected a line of code (got %r, %r)"" % (kind, item))<tab>code_lines = []<tab>while True:<tab><tab>_, kind, item = tokens.peek()<tab><tab>if kind != PLAIN_LINE:<tab><tab><tab>case[""code""] = ""\n"".join(code_lines) + ""\n""<tab><tab><tab>return<tab><tab>code_lines.append(item)<tab><tab>tokens.next()",1,if kind != PLAIN_LINE :,if kind != PLAIN_LINE :,0.75,100,1
"def _recursive_process(self):<tab>super(RecursiveObjectDownwardsVisitor, self)._recursive_process()<tab>while self._new_for_visit:<tab><tab>func_ea, arg_idx = self._new_for_visit.pop()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>cfunc = helper.decompile_function(func_ea)<tab><tab>if cfunc:<tab><tab><tab>assert arg_idx < len(cfunc.get_lvars()), ""Wrong argument at func {}"".format(<tab><tab><tab><tab>to_hex(func_ea)<tab><tab><tab>)<tab><tab><tab>obj = VariableObject(cfunc.get_lvars()[arg_idx], arg_idx)<tab><tab><tab>self.prepare_new_scan(cfunc, arg_idx, obj)<tab><tab><tab>self._recursive_process()",0,if helper . is_imported_ea ( func_ea ) :,if func_ea is None :,0.019907918,10.69482073,0.381818182
"def GetBoundingBoxMin(self):<tab>""""""Get the minimum bounding box.""""""<tab>x1, y1 = 10000, 10000<tab>x2, y2 = -10000, -10000<tab>for point in self._lineControlPoints:<tab><tab>if point[0] < x1:<tab><tab><tab>x1 = point[0]<tab><tab>if point[1] < y1:<tab><tab><tab>y1 = point[1]<tab><tab><IF-STMT><tab><tab><tab>x2 = point[0]<tab><tab>if point[1] > y2:<tab><tab><tab>y2 = point[1]<tab>return x2 - x1, y2 - y1",1,if point [ 0 ] > x2 :,if point [ 0 ] > x2 :,0.75,100,1
"def __init__(<tab>self,<tab>detail=None,<tab>headers=None,<tab>comment=None,<tab>body_template=None,<tab>location=None,<tab>add_slash=False,):<tab>super(_HTTPMove, self).__init__(<tab><tab>detail=detail, headers=headers, comment=comment, body_template=body_template<tab>)<tab>if location is not None:<tab><tab>self.location = location<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""You can only provide one of the arguments location "" ""and add_slash""<tab><tab><tab>)<tab>self.add_slash = add_slash",1,if add_slash :,if add_slash :,0.531170663,1.00E-10,1
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.presence_response_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""presence_response%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>return res",1,if printElemNumber :,if printElemNumber :,0.531170663,1.00E-10,1
"def _find_first_match(self, request):<tab>match_failed_reasons = []<tab>for i, match in enumerate(self._matches):<tab><tab>match_result, reason = match.matches(request)<tab><tab><IF-STMT><tab><tab><tab>return match, match_failed_reasons<tab><tab>else:<tab><tab><tab>match_failed_reasons.append(reason)<tab>return None, match_failed_reasons",1,if match_result :,if match_result :,0.531170663,1.00E-10,1
"def index(self, req, volume_id):<tab>req_version = req.api_version_request<tab>metadata = super(Controller, self).index(req, volume_id)<tab>if req_version.matches(mv.ETAGS):<tab><tab>data = jsonutils.dumps(metadata)<tab><tab><IF-STMT><tab><tab><tab>data = data.encode(""utf-8"")<tab><tab>resp = webob.Response()<tab><tab>resp.headers[""Etag""] = hashlib.md5(data).hexdigest()<tab><tab>resp.body = data<tab><tab>return resp<tab>return metadata",0,if six . PY3 :,"if hasattr ( data , ""encode"" ) :",0.026407399,4.990049702,0.333333333
"def init(self):<tab>""""""Called after document is loaded.""""""<tab># Create div to put dynamic CSS assets in<tab>self.asset_node = window.document.createElement(""div"")<tab>self.asset_node.id = ""Flexx asset container""<tab>window.document.body.appendChild(self.asset_node)<tab>if self.is_exported:<tab><tab>if self.is_notebook:<tab><tab><tab>print(""Flexx: I am in an exported notebook!"")<tab><tab>else:<tab><tab><tab>print(""Flexx: I am in an exported app!"")<tab><tab><tab>self.run_exported_app()<tab>else:<tab><tab>print(""Flexx: Initializing"")<tab><tab><IF-STMT><tab><tab><tab>self._remove_querystring()<tab><tab>self.init_logging()",0,if not self . is_notebook :,if self . is_querystring :,0.054520976,39.44243648,0.464285714
"def get_default_person(self):<tab>""""""Return the default Person of the database.""""""<tab>person_handle = self.get_default_handle()<tab>if person_handle:<tab><tab>person = self.get_person_from_handle(person_handle)<tab><tab>if person:<tab><tab><tab>return person<tab><tab><IF-STMT><tab><tab><tab># Start transaction<tab><tab><tab>with BSDDBTxn(self.env, self.metadata) as txn:<tab><tab><tab><tab>txn.put(b""default"", None)<tab><tab><tab>return None<tab>else:<tab><tab>return None",0,elif ( self . metadata ) and ( not self . readonly ) :,elif self . env :,0.014564156,4.199688917,0.305555556
def reader():<tab>async with read:<tab><tab>await wait_all_tasks_blocked()<tab><tab>total_received = 0<tab><tab>while True:<tab><tab><tab># 5000 is chosen because it doesn't evenly divide 2**20<tab><tab><tab>received = len(await read.receive_some(5000))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>total_received += received<tab><tab>assert total_received == count * replicas,0,if not received :,if received == 0 :,0.045150551,10.68217516,0.4
"def array_module(a):<tab>if isinstance(a, np.ndarray):<tab><tab>return np<tab>else:<tab><tab>from pyopencl.array import Array<tab><tab><IF-STMT><tab><tab><tab>return _CLFakeArrayModule(a.queue)<tab><tab>else:<tab><tab><tab>raise TypeError(""array type not understood: %s"" % type(a))",1,"if isinstance ( a , Array ) :","if isinstance ( a , Array ) :",0.75,100,1
"def __str__(self):<tab>path = super(XPathExpr, self).__str__()<tab>if self.textnode:<tab><tab><IF-STMT><tab><tab><tab>path = ""text()""<tab><tab>elif path.endswith(""::*/*""):<tab><tab><tab>path = path[:-3] + ""text()""<tab><tab>else:<tab><tab><tab>path += ""/text()""<tab>if self.attribute is not None:<tab><tab>if path.endswith(""::*/*""):<tab><tab><tab>path = path[:-2]<tab><tab>path += ""/@%s"" % self.attribute<tab>return path",0,"if path == ""*"" :","if path == """" :",0.394778655,61.29752414,1
"def update(self):<tab>if self.saved():<tab><tab>rgns = self.view.get_regions(self.region_key)<tab><tab><IF-STMT><tab><tab><tab>rgn = Region.from_region(self.view, rgns[0], self.region_key)<tab><tab><tab>self.start = rgn.start<tab><tab><tab>self.end = rgn.end",0,if rgns :,if len ( rgns ) > 0 :,0.0465226,1.00E-10,0.36
"def PrintServerName(data, entries):<tab>if entries > 0:<tab><tab>entrieslen = 26 * entries<tab><tab>chunks, chunk_size = len(data[:entrieslen]), entrieslen / entries<tab><tab>ServerName = [data[i : i + chunk_size] for i in range(0, chunks, chunk_size)]<tab><tab>l = []<tab><tab>for x in ServerName:<tab><tab><tab>FP = WorkstationFingerPrint(x[16:18])<tab><tab><tab>Name = x[:16].replace(""\x00"", """")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>l.append(Name + "" (%s)"" % FP)<tab><tab><tab>else:<tab><tab><tab><tab>l.append(Name)<tab><tab>return l<tab>return None",1,if FP :,if FP :,0.531170663,1.00E-10,1
"def add_lookup(self, name_type, pyname, jsname, depth=-1):<tab>jsname = self.jsname(name_type, jsname)<tab>if self.local_prefix is not None:<tab><tab><IF-STMT><tab><tab><tab>jsname = self.jsname(name_type, ""%s.%s"" % (self.local_prefix, jsname))<tab>if self.lookup_stack[depth].has_key(pyname):<tab><tab>name_type = self.lookup_stack[depth][pyname][0]<tab>if self.module_name != ""pyjslib"" or pyname != ""int"":<tab><tab>self.lookup_stack[depth][pyname] = (name_type, pyname, jsname)<tab>return jsname",0,if jsname . find ( self . local_prefix ) != 0 :,if not jsname . startswith ( self . local_prefix ) :,0.197118689,46.92846227,0.25
"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab><IF-STMT><tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab>if not attr_list[3] & termios.ECHO:<tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab>if hasattr(signal, ""SIGTTOU""):<tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab>if old_handler is not None:<tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",0,if fd . isatty ( ) :,if fd is not None :,0.04155306,15.20721822,0.380952381
"def get_query_results(user, query_id, bring_from_cache):<tab>query = _load_query(user, query_id)<tab>if bring_from_cache:<tab><tab><IF-STMT><tab><tab><tab>results = query.latest_query_data.data<tab><tab>else:<tab><tab><tab>raise Exception(""No cached result available for query {}."".format(query.id))<tab>else:<tab><tab>results, error = query.data_source.query_runner.run_query(<tab><tab><tab>query.query_text, user<tab><tab>)<tab><tab>if error:<tab><tab><tab>raise Exception(""Failed loading results for query id {}."".format(query.id))<tab><tab>else:<tab><tab><tab>results = json_loads(results)<tab>return results",0,if query . latest_query_data_id is not None :,if query . latest_query_data :,0.120555985,51.01469473,0.444444444
"def on_tag_added_to_page(self, o, row, pagerow):<tab>self.flush_cache()<tab>if row[""name""] in self.tags and self._matches_all(pagerow[""id""]):<tab><tab># Without the new tag it did not match, so add to view<tab><tab># Find top level entry - ignore possible deeper matches<tab><tab>for treepath in self._find_all_pages(pagerow[""name""]):<tab><tab><tab>if len(treepath) == 1:<tab><tab><tab><tab>treeiter = self.get_iter(treepath)  # not mytreeiter !<tab><tab><tab><tab>self.emit(""row-inserted"", treepath, treeiter)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self._emit_children_inserted(pagerow[""id""], treepath)",0,"if pagerow [ ""n_children"" ] > 0 :",elif len ( treepath ) == 2 :,0.013218703,3.41621136,0.111111111
"def _is_subnet_of(a, b):<tab>try:<tab><tab># Always false if one is v4 and the other is v6.<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(f""{a} and {b} are not of the same version"")<tab><tab>return (<tab><tab><tab>b.network_address <= a.network_address<tab><tab><tab>and b.broadcast_address >= a.broadcast_address<tab><tab>)<tab>except AttributeError:<tab><tab>raise TypeError(f""Unable to test subnet containment "" f""between {a} and {b}"")",0,if a . _version != b . _version :,if a . version != b . version :,0.604826209,47.26944207,0.56
"def consume(d={}):<tab>""""""Add attribute list to the dictionary 'd' and reset the list.""""""<tab>if AttributeList.attrs:<tab><tab>d.update(AttributeList.attrs)<tab><tab>AttributeList.attrs = {}<tab><tab># Generate option attributes.<tab><tab><IF-STMT><tab><tab><tab>options = parse_options(d[""options""], (), ""illegal option name"")<tab><tab><tab>for option in options:<tab><tab><tab><tab>d[option + ""-option""] = """"",1,"if ""options"" in d :","if ""options"" in d :",0.75,100,1
"def tearDown(self):<tab># make sure all of the subprocesses are dead<tab>for pidfile in self.pidfiles:<tab><tab>if not os.path.exists(pidfile):<tab><tab><tab>continue<tab><tab>with open(pidfile) as f:<tab><tab><tab>pid = f.read()<tab><tab>if not pid:<tab><tab><tab>return<tab><tab>pid = int(pid)<tab><tab>try:<tab><tab><tab>os.kill(pid, signal.SIGKILL)<tab><tab>except OSError:<tab><tab><tab>pass<tab># and clean up leftover pidfiles<tab>for pidfile in self.pidfiles:<tab><tab><IF-STMT><tab><tab><tab>os.unlink(pidfile)<tab>self.tearDownBasedir()",0,if os . path . exists ( pidfile ) :,if not os . path . exists ( pidfile ) :,0.427664433,80.70557275,0.272727273
"def sort(self, items):<tab>slow_sorts = []<tab>switch_slow = False<tab>for sort in reversed(self.sorts):<tab><tab>if switch_slow:<tab><tab><tab>slow_sorts.append(sort)<tab><tab><IF-STMT><tab><tab><tab>switch_slow = True<tab><tab><tab>slow_sorts.append(sort)<tab><tab>else:<tab><tab><tab>pass<tab>for sort in slow_sorts:<tab><tab>items = sort.sort(items)<tab>return items",0,elif sort . order_clause ( ) is None :,elif sort not in slow_sorts :,0.099946761,9.027235034,0.428571429
"def shortcut(input, ch_out, stride):<tab>ch_in = input.shape[1]<tab>if ch_in != ch_out:<tab><tab><IF-STMT><tab><tab><tab>filter_size = 1<tab><tab>else:<tab><tab><tab>filter_size = 3<tab><tab>return conv_bn_layer(input, ch_out, filter_size, stride)<tab>else:<tab><tab>return input",1,if stride == 1 :,if stride == 1 :,0.75,100,1
"def detab(self, text):<tab>""""""Remove a tab from the front of each line of the given text.""""""<tab>newtext = []<tab>lines = text.split(""\n"")<tab>for line in lines:<tab><tab>if line.startswith("" "" * self.tab_length):<tab><tab><tab>newtext.append(line[self.tab_length :])<tab><tab><IF-STMT><tab><tab><tab>newtext.append("""")<tab><tab>else:<tab><tab><tab>break<tab>return ""\n"".join(newtext), ""\n"".join(lines[len(newtext) :])",0,elif not line . strip ( ) :,"elif line . endswith ( ""\n"" ) :",0.087632802,11.73117516,0.314814815
"def construct_instances(self, row, keys=None):<tab>collected_models = {}<tab>for i, (key, constructor, attr, conv) in enumerate(self.column_map):<tab><tab>if keys is not None and key not in keys:<tab><tab><tab>continue<tab><tab>value = row[i]<tab><tab>if key not in collected_models:<tab><tab><tab>collected_models[key] = constructor()<tab><tab>instance = collected_models[key]<tab><tab><IF-STMT><tab><tab><tab>attr = self.cursor.description[i][0]<tab><tab>if conv is not None:<tab><tab><tab>value = conv(value)<tab><tab>setattr(instance, attr, value)<tab>return collected_models",1,if attr is None :,if attr is None :,0.75,100,1
"def stop_loggers(self):<tab>super(NetconsoleHost, self).stop_loggers()<tab>if self.__logger:<tab><tab>utils.nuke_subprocess(self.__logger)<tab><tab>self.__logger = None<tab><tab><IF-STMT><tab><tab><tab>self.job.warning_loggers.discard(self.__warning_stream)<tab><tab>self.__warning_stream.close()",1,if self . job :,if self . job :,0.75,100,1
"def get_template_context(node, context, context_lines=3):<tab>line, source_lines, name = get_template_source_from_exception_info(node, context)<tab>debug_context = []<tab>start = max(1, line - context_lines)<tab>end = line + 1 + context_lines<tab>for line_num, content in source_lines:<tab><tab><IF-STMT><tab><tab><tab>debug_context.append(<tab><tab><tab><tab>{""num"": line_num, ""content"": content, ""highlight"": (line_num == line)}<tab><tab><tab>)<tab>return {""name"": name, ""context"": debug_context}",0,if start <= line_num <= end :,if line_num < start and line_num < end :,0.038659112,25.4509386,0.581818182
"def arg_names(self, lineage, command_name, positional_arg=False):<tab>parent = ""."".join(lineage)<tab>arg_names = self.index[""arg_names""].get(parent, {}).get(command_name, [])<tab>filtered_arg_names = []<tab>for arg_name in arg_names:<tab><tab>arg_data = self.get_argument_data(lineage, command_name, arg_name)<tab><tab><IF-STMT><tab><tab><tab>filtered_arg_names.append(arg_name)<tab>return filtered_arg_names",0,if arg_data . positional_arg == positional_arg :,if arg_data is not None and positional_arg :,0.046999251,35.89188622,0.266666667
"def attributive(adjective, gender=MALE):<tab>w = adjective.lower()<tab># normal => normales<tab>if PLURAL in gender and not is_vowel(w[-1:]):<tab><tab>return w + ""es""<tab># el chico inteligente => los chicos inteligentes<tab>if PLURAL in gender and w.endswith((""a"", ""e"")):<tab><tab>return w + ""s""<tab># el chico alto => los chicos altos<tab>if w.endswith(""o""):<tab><tab><IF-STMT><tab><tab><tab>return w[:-1] + ""as""<tab><tab>if FEMININE in gender:<tab><tab><tab>return w[:-1] + ""a""<tab><tab>if PLURAL in gender:<tab><tab><tab>return w + ""s""<tab>return w",0,if FEMININE in gender and PLURAL in gender :,if FEMININE in gender :,0.381094386,37.78391152,0.523809524
"def _get_disk_size(cls, path, ignored=None):<tab>if ignored is None:<tab><tab>ignored = []<tab>if path in ignored:<tab><tab>return 0<tab>total = 0<tab>for entry in scandir(path):<tab><tab>if entry.is_dir():<tab><tab><tab>total += cls._get_disk_size(entry.path, ignored=ignored)<tab><tab><IF-STMT><tab><tab><tab>total += entry.stat().st_size<tab>return total",1,elif entry . is_file ( ) :,elif entry . is_file ( ) :,0.75,100,1
"def validateHeaders(self):<tab>if ""Cookie"" in self.headers:<tab><tab>for session in self.factory.authenticated_sessions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return WebSocketProtocol.validateHeaders(self)<tab>return False",0,"if ""TWISTED_SESSION="" + session . uid in self . headers [ ""Cookie"" ] :","if session . cookie == self . headers [ ""Cookie"" ] :",0.320893058,41.716227,0.367647059
"def _format_privilege_data(self, data):<tab>for key in [""spcacl""]:<tab><tab>if key in data and data[key] is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[key][""added""] = parse_priv_to_db(data[key][""added""], self.acl)<tab><tab><tab>if ""changed"" in data[key]:<tab><tab><tab><tab>data[key][""changed""] = parse_priv_to_db(data[key][""changed""], self.acl)<tab><tab><tab>if ""deleted"" in data[key]:<tab><tab><tab><tab>data[key][""deleted""] = parse_priv_to_db(data[key][""deleted""], self.acl)",1,"if ""added"" in data [ key ] :","if ""added"" in data [ key ] :",0.75,100,1
"def show_text(text):<tab>print(_stash.text_color(""="" * 20, ""yellow""))<tab>lines = text.split(""\n"")<tab>while True:<tab><tab><IF-STMT><tab><tab><tab>print(""\n"".join(lines))<tab><tab><tab>return<tab><tab>else:<tab><tab><tab>print(""\n"".join(lines[:100]))<tab><tab><tab>lines = lines[100:]<tab><tab><tab>prompt = _stash.text_color(""(Press Return to continue)"", ""yellow"")<tab><tab><tab>raw_input(prompt)<tab>print(""\n"")",0,if len ( lines ) < 100 :,if len ( lines ) == 0 :,0.524151519,46.71379777,0.666666667
"def run(self):<tab>TimeInspector.set_time_mark()<tab>for tuner_index, tuner_config in enumerate(self.pipeline_config):<tab><tab>tuner = self.init_tuner(tuner_index, tuner_config)<tab><tab>tuner.tune()<tab><tab><IF-STMT><tab><tab><tab>self.global_best_res = tuner.best_res<tab><tab><tab>self.global_best_params = tuner.best_params<tab><tab><tab>self.best_tuner_index = tuner_index<tab>TimeInspector.log_cost_time(""Finished tuner pipeline."")<tab>self.save_tuner_exp_info()",0,if self . global_best_res is None or self . global_best_res > tuner . best_res :,"if hasattr ( tuner , ""best_res"" ) :",0.00887621,5.073971386,0.225
"def OnEvent(self, propGrid, aProperty, ctrl, event):<tab>if event.GetEventType() == wx.wxEVT_BUTTON:<tab><tab>buttons = propGrid.GetEditorControlSecondary()<tab><tab>if event.GetId() == buttons.GetButtonId(0):<tab><tab><tab># Do something when the first button is pressed<tab><tab><tab># Return true if the action modified the value in editor.<tab><tab><tab>...<tab><tab><IF-STMT><tab><tab><tab># Do something when the second button is pressed<tab><tab><tab>...<tab><tab>if event.GetId() == buttons.GetButtonId(2):<tab><tab><tab># Do something when the third button is pressed<tab><tab><tab>...<tab>return wx.propgrid.PGTextCtrlEditor.OnEvent(propGrid, aProperty, ctrl, event)",1,if event . GetId ( ) == buttons . GetButtonId ( 1 ) :,if event . GetId ( ) == buttons . GetButtonId ( 1 ) :,0.75,100,1
"def run(self, edit):<tab>view = self.view<tab>for sel in view.sel():<tab><tab>if not self.is_valid_scope(sel):<tab><tab><tab>continue<tab><tab>region = view.extract_scope(sel.end())<tab><tab>content = self.extract_content(region)<tab><tab>resolver, content = self.resolve(content)<tab><tab><IF-STMT><tab><tab><tab>sublime.error_message(""Could not resolve link:\n%s"" % content)<tab><tab><tab>continue<tab><tab>resolver.execute(content)",0,if content is None :,if not resolver :,0.036751978,14.79401567,0.238095238
"def __init__(self, aList):<tab>for element in aList:<tab><tab>if len(element) > 0:<tab><tab><tab>if element.tag == element[0].tag:<tab><tab><tab><tab>self.append(ListParser(element))<tab><tab><tab>else:<tab><tab><tab><tab>self.append(DictParser(element))<tab><tab><IF-STMT><tab><tab><tab>text = element.text.strip()<tab><tab><tab>if text:<tab><tab><tab><tab>self.append(text)",1,elif element . text :,elif element . text :,0.75,100,1
"def put(self, can_split=False):<tab>for node in (self.nodes)[:1]:<tab><tab><IF-STMT><tab><tab><tab>node.put(can_split=can_split)<tab>for node in (self.nodes)[1:]:<tab><tab>self.line_more(SLICE_COLON, can_split_after=True)<tab><tab>if self.has_value(node):<tab><tab><tab>node.put(can_split=can_split)<tab>return self",1,if self . has_value ( node ) :,if self . has_value ( node ) :,0.75,100,1
"def process_return_exits(self, exits):<tab>""""""Add arcs due to jumps from `exits` being returns.""""""<tab>for block in self.nearest_blocks():<tab><tab>if isinstance(block, TryBlock) and block.final_start is not None:<tab><tab><tab>block.return_from.update(exits)<tab><tab><tab>break<tab><tab><IF-STMT><tab><tab><tab>for xit in exits:<tab><tab><tab><tab>self.add_arc(<tab><tab><tab><tab><tab>xit.lineno,<tab><tab><tab><tab><tab>-block.start,<tab><tab><tab><tab><tab>xit.cause,<tab><tab><tab><tab><tab>""didn't return from function {!r}"".format(block.name),<tab><tab><tab><tab>)<tab><tab><tab>break",0,"elif isinstance ( block , FunctionBlock ) :",if block . return_from is not None :,0.066515822,4.990049702,0.095238095
"def find_commands(management_dir):<tab># Modified version of function from django/core/management/__init__.py.<tab>command_dir = os.path.join(management_dir, ""commands"")<tab>commands = []<tab>try:<tab><tab>for f in os.listdir(command_dir):<tab><tab><tab>if f.startswith(""_""):<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>commands.append(f[:-3])<tab><tab><tab>elif f.endswith("".pyc"") and f[:-4] not in commands:<tab><tab><tab><tab>commands.append(f[:-4])<tab>except OSError:<tab><tab>pass<tab>return commands",0,"elif f . endswith ( "".py"" ) and f [ : - 3 ] not in commands :","elif f . endswith ( "".py"" ) and f [ - 3 : ] in commands :",0.516348778,70.9552681,0.660818713
"def split_path_info(path):<tab># suitable for splitting an already-unquoted-already-decoded (unicode)<tab># path value<tab>path = path.strip(""/"")<tab>clean = []<tab>for segment in path.split(""/""):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif segment == "".."":<tab><tab><tab>if clean:<tab><tab><tab><tab>del clean[-1]<tab><tab>else:<tab><tab><tab>clean.append(segment)<tab>return tuple(clean)",0,"if not segment or segment == ""."" :","if segment == ""/"" :",0.037304456,29.36697785,0.333333333
"def __init__(self, source_definition, **kw):<tab>super(RekallEFilterArtifacts, self).__init__(source_definition, **kw)<tab>for column in self.fields:<tab><tab><IF-STMT><tab><tab><tab>raise errors.FormatError(<tab><tab><tab><tab>u""Field definition should have both name and type.""<tab><tab><tab>)<tab><tab>mapped_type = column[""type""]<tab><tab>if mapped_type not in self.allowed_types:<tab><tab><tab>raise errors.FormatError(u""Unsupported type %s."" % mapped_type)",0,"if ""name"" not in column or ""type"" not in column :","if ""name"" in column and ""type"" in column :",0.322404377,33.1618652,0.25
"def _name(self, sender, short=True, full_email=False):<tab>words = re.sub('[""<>]', """", sender).split()<tab>nomail = [w for w in words if not ""@"" in w]<tab>if nomail:<tab><tab>if short:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return nomail[1]<tab><tab><tab>return nomail[0]<tab><tab>return "" "".join(nomail)<tab>elif words:<tab><tab>if not full_email:<tab><tab><tab>return words[0].split(""@"", 1)[0]<tab><tab>return words[0]<tab>return ""(nobody)""",0,if len ( nomail ) > 1 and nomail [ 0 ] . lower ( ) in self . _NAME_TITLES :,if full_email :,0.003505329,1.00E-10,0.170967742
"def _get_consuming_layers(self, check_layer):<tab>""""""Returns all the layers which are out nodes from the layer.""""""<tab>consuming_layers = []<tab>for layer in self._config[""layers""]:<tab><tab>for inbound_node in layer[""inbound_nodes""]:<tab><tab><tab>for connection_info in inbound_node:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>consuming_layers.append(layer)<tab>return consuming_layers",0,"if connection_info [ 0 ] == check_layer [ ""config"" ] [ ""name"" ] :","if connection_info [ ""type"" ] == check_layer :",0.102521652,37.36263475,0.653333333
"def _check_feasible_fuse(self, model):<tab>if not self.modules_to_fuse:<tab><tab>return False<tab>for group in self.modules_to_fuse:<tab><tab><IF-STMT><tab><tab><tab>raise MisconfigurationException(<tab><tab><tab><tab>f""You have requested to fuse {group} but one or more of them is not your model attributes""<tab><tab><tab>)<tab>return True",0,"if not all ( _recursive_hasattr ( model , m ) for m in group ) :",if model . get ( group ) != group :,0.266846349,4.766871975,0.177777778
"def cancel_loan_repayment_entry(self):<tab>for loan in self.loans:<tab><tab><IF-STMT><tab><tab><tab>repayment_entry = frappe.get_doc(<tab><tab><tab><tab>""Loan Repayment"", loan.loan_repayment_entry<tab><tab><tab>)<tab><tab><tab>repayment_entry.cancel()",0,if loan . loan_repayment_entry :,if loan . loan_repayment_entry is not None :,0.351498834,63.15552372,0.444444444
"def update_channel_entries(self, request):<tab>try:<tab><tab>request_parsed = await request.json()<tab>except (ContentTypeError, ValueError):<tab><tab>return RESTResponse({""error"": ""Bad JSON""}, status=HTTP_BAD_REQUEST)<tab>results_list = []<tab>for entry in request_parsed:<tab><tab>public_key = database_blob(unhexlify(entry.pop(""public_key"")))<tab><tab>id_ = entry.pop(""id"")<tab><tab>error, result = self.update_entry(public_key, id_, entry)<tab><tab># TODO: handle the results for a list that contains some errors in a smarter way<tab><tab><IF-STMT><tab><tab><tab>return RESTResponse(result, status=error)<tab><tab>results_list.append(result)<tab>return RESTResponse(results_list)",1,if error :,if error :,0.531170663,1.00E-10,1
"def delete(self, userId: str, bucket: str, key: str) -> bool:<tab>if not self.initialized:<tab><tab>raise Exception(""archive not initialized"")<tab>try:<tab><tab>with db.session_scope() as dbsession:<tab><tab><tab>rc = db_archivedocument.delete(userId, bucket, key, session=dbsession)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""failed to delete DB record"")<tab><tab><tab>else:<tab><tab><tab><tab>return True<tab>except Exception as err:<tab><tab>raise err",1,if not rc :,if not rc :,0.75,100,1
"def handle_phase(task, config):<tab>""""""Function that runs all of the configured plugins which act on the current phase.""""""<tab># Keep a list of all results, for input plugin combining<tab>results = []<tab>for item in config:<tab><tab>for plugin_name, plugin_config in item.items():<tab><tab><tab>if phase in plugin.get_phases_by_plugin(plugin_name):<tab><tab><tab><tab>method = plugin.get_plugin_by_name(plugin_name).phase_handlers[phase]<tab><tab><tab><tab>log.debug(""Running plugin %s"" % plugin_name)<tab><tab><tab><tab>result = method(task, plugin_config)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>results.append(result)<tab>return itertools.chain(*results)",0,"if phase == ""input"" and result :",if result is not None :,0.123367003,5.484411596,0.225
"def guess_gitlab_remote(self):<tab>upstream = self.get_upstream_for_active_branch()<tab>integrated_remote = self.get_integrated_remote_name()<tab>remotes = self.get_remotes()<tab>if len(self.remotes) == 1:<tab><tab>return list(remotes.keys())[0]<tab>elif upstream:<tab><tab>tracked_remote = upstream.split(""/"")[0] if upstream else None<tab><tab><IF-STMT><tab><tab><tab>return tracked_remote<tab><tab>else:<tab><tab><tab>return None<tab>else:<tab><tab>return integrated_remote",0,if tracked_remote and tracked_remote == integrated_remote :,if tracked_remote :,0.038857533,1.00E-10,0.636363636
"def do_test(self, path):<tab>reader = paddle.reader.creator.recordio(path)<tab>idx = 0<tab>for e in reader():<tab><tab>if idx == 0:<tab><tab><tab>self.assertEqual(e, (1, 2, 3))<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(e, (4, 5, 6))<tab><tab>idx += 1<tab>self.assertEqual(idx, 2)",1,elif idx == 1 :,elif idx == 1 :,1,100,1
"def gen_cpu_name(cpu):<tab>if cpu == ""simple"":<tab><tab>return event_download.get_cpustr()<tab>for j in known_cpus:<tab><tab>if cpu == j[0]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""GenuineIntel-6-%02X-%d"" % j[1][0]<tab><tab><tab>else:<tab><tab><tab><tab>return ""GenuineIntel-6-%02X"" % j[1][0]<tab>assert False",0,"if isinstance ( j [ 1 ] [ 0 ] , tuple ) :","if j [ 1 ] [ 0 ] == ""cpu"" :",0.317505115,46.04628626,0.26984127
"def read_kernel_cmdline_config(cmdline=None):<tab>if cmdline is None:<tab><tab>cmdline = util.get_cmdline()<tab>if ""network-config="" in cmdline:<tab><tab>data64 = None<tab><tab>for tok in cmdline.split():<tab><tab><tab>if tok.startswith(""network-config=""):<tab><tab><tab><tab>data64 = tok.split(""="", 1)[1]<tab><tab><IF-STMT><tab><tab><tab>if data64 == KERNEL_CMDLINE_NETWORK_CONFIG_DISABLED:<tab><tab><tab><tab>return {""config"": ""disabled""}<tab><tab><tab>return util.load_yaml(_b64dgz(data64))<tab>return None",0,if data64 :,if data64 is not None :,0.090364769,1.00E-10,0.4
"def _verify_bot(self, ctx: ""Context"") -> None:<tab>if ctx.guild is None:<tab><tab>bot_user = ctx.bot.user<tab>else:<tab><tab>bot_user = ctx.guild.me<tab><tab>cog = ctx.cog<tab><tab><IF-STMT><tab><tab><tab>raise discord.ext.commands.DisabledCommand()<tab>bot_perms = ctx.channel.permissions_for(bot_user)<tab>if not (bot_perms.administrator or bot_perms >= self.bot_perms):<tab><tab>raise BotMissingPermissions(<tab><tab><tab>missing=self._missing_perms(self.bot_perms, bot_perms)<tab><tab>)",0,"if cog and await ctx . bot . cog_disabled_in_guild ( cog , ctx . guild ) :",if cog is None :,0.085741756,0.646029531,0.242857143
"def _split_values(self, value):<tab># do the regex mojo here<tab>if not self.allowed_values:<tab><tab>return ("""",)<tab>try:<tab><tab>r = re.compile(self.allowed_values)<tab>except:<tab><tab>print(self.allowed_values, file=sys.stderr)<tab><tab>raise<tab>s = str(value)<tab>i = 0<tab>vals = []<tab>while True:<tab><tab>m = r.search(s[i:])<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>vals.append(m.group())<tab><tab>delimiter = s[i : i + m.start()]<tab><tab>if self.delimiter is None and delimiter != """":<tab><tab><tab>self.delimiter = delimiter<tab><tab>i += m.end()<tab>return tuple(vals)",0,if m is None :,if not m :,0.039449619,16.37226967,0.277777778
"def _count(self, element, count=True):<tab>if not isinstance(element, six.string_types):<tab><tab>if self == element:<tab><tab><tab>return 1<tab>i = 0<tab>for child in self.children:<tab><tab># child is text content and element is also text content, then<tab><tab># make a simple ""text"" in ""text""<tab><tab>if isinstance(child, six.string_types):<tab><tab><tab>if isinstance(element, six.string_types):<tab><tab><tab><tab>if count:<tab><tab><tab><tab><tab>i += child.count(element)<tab><tab><tab><tab>elif element in child:<tab><tab><tab><tab><tab>return 1<tab><tab>else:<tab><tab><tab>i += child._count(element, count=count)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return i<tab>return i",0,if not count and i :,if count :,0.028363593,1.00E-10,0.233333333
"def set_page(self, page):<tab>""""""If a page is present as a bookmark than select it.""""""<tab>pagename = page.name<tab>with self.on_bookmark_clicked.blocked():<tab><tab>for button in self.scrolledbox.get_scrolled_children():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>button.set_active(True)<tab><tab><tab>else:<tab><tab><tab><tab>button.set_active(False)",0,if button . zim_path == pagename :,if name == page . name :,0.024082657,10.81605939,0.30952381
"def get_Subclass_of(rt):<tab>for y in [getattr(Ast, x) for x in dir(Ast)]:<tab><tab>yt = clr.GetClrType(y)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if yt.IsAbstract:<tab><tab><tab>continue<tab><tab>if yt.IsSubclassOf(rt):<tab><tab><tab>yield yt.Name",0,if rt == yt :,if yt is None :,0.036540249,11.51015342,0.277777778
"def update_parent_columns(self):<tab>""Update the parent columns of the current focus column.""<tab>f = self.columns.get_focus_column()<tab>col = self.col_list[f]<tab>while 1:<tab><tab>parent, pcol = self.get_parent(col)<tab><tab>if pcol is None:<tab><tab><tab>return<tab><tab>changed = pcol.update_results(start_from=parent)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>col = pcol",0,if not changed :,if changed :,0.096488528,1.00E-10,0.416666667
"def get_template_engine(themes):<tab>""""""Get template engine used by a given theme.""""""<tab>for theme_name in themes:<tab><tab>engine_path = os.path.join(theme_name, ""engine"")<tab><tab><IF-STMT><tab><tab><tab>with open(engine_path) as fd:<tab><tab><tab><tab>return fd.readlines()[0].strip()<tab># default<tab>return ""mako""",0,if os . path . isfile ( engine_path ) :,if os . path . exists ( engine_path ) :,0.580308871,73.48889201,0.666666667
"def reConnect(self):<tab>while self.retrymax is None or self.retries < self.retrymax:<tab><tab>logger.info(""Cobra reconnection attempt"")<tab><tab>try:<tab><tab><tab>self.conn = self.httpfact()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.authUser(self.authinfo)<tab><tab><tab>self.retries = 0<tab><tab><tab>return<tab><tab>except Exception as e:<tab><tab><tab>time.sleep(2 ** self.retries)<tab><tab><tab>self.retries += 1<tab>self.trashed = True<tab>raise CobraHttpException(""Retry Exceeded!"")",0,if self . _cobra_sessid :,if self . authinfo :,0.394778655,23.45000811,0.7
"def __eq__(self, other):<tab>if isinstance(other, OrderedDict):<tab><tab>if len(self) != len(other):<tab><tab><tab>return False<tab><tab>for p, q in zip(list(self.items()), list(other.items())):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab>return True<tab>return dict.__eq__(self, other)",1,if p != q :,if p != q :,0.75,100,1
"def __getExpectedSampleOffsets(self, tileOrigin, area1, area2):<tab>ts = GafferImage.ImagePlug.tileSize()<tab>data = []<tab>for y in range(tileOrigin.y, tileOrigin.y + ts):<tab><tab>for x in range(tileOrigin.x, tileOrigin.x + ts):<tab><tab><tab>pixel = imath.V2i(x, y)<tab><tab><tab>data.append(data[-1] if data else 0)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>data[-1] += 1<tab><tab><tab>if GafferImage.BufferAlgo.contains(area2, pixel):<tab><tab><tab><tab>data[-1] += 1<tab>return IECore.IntVectorData(data)",1,"if GafferImage . BufferAlgo . contains ( area1 , pixel ) :","if GafferImage . BufferAlgo . contains ( area1 , pixel ) :",0.75,100,1
"def _get_changes(self):<tab>""""""Get changes from CHANGES.txt.""""""<tab>log_lines = []<tab>found_version = False<tab>found_items = False<tab>with open(""CHANGES.txt"", ""r"") as fp:<tab><tab>for line in fp.readlines():<tab><tab><tab>line = line.rstrip()<tab><tab><tab>if line.endswith(VERSION_TEXT_SHORT):<tab><tab><tab><tab>found_version = True<tab><tab><tab>if not line.strip() and found_items:<tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>log_lines.append("" "" * 2 + ""* "" + line[2:])<tab><tab><tab><tab>found_items = True<tab>return log_lines",0,"elif found_version and line . startswith ( ""- "" ) :",if found_version and len ( line ) > 2 :,0.120153275,21.34144323,0.240384615
"def _next_hid(self, n=1):<tab># this is overriden in mapping.py db_next_hid() method<tab>if len(self.datasets) == 0:<tab><tab>return n<tab>else:<tab><tab>last_hid = 0<tab><tab>for dataset in self.datasets:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>last_hid = dataset.hid<tab><tab>return last_hid + n",0,if dataset . hid > last_hid :,if dataset . hid != last_hid :,0.496272831,52.53819789,1
"def setInt(self, path, value, **kwargs):<tab>if value is None:<tab><tab>self.set(path, None, **kwargs)<tab><tab>return<tab>minimum = kwargs.pop(""min"", None)<tab>maximum = kwargs.pop(""max"", None)<tab>try:<tab><tab>intValue = int(value)<tab><tab>if minimum is not None and intValue < minimum:<tab><tab><tab>intValue = minimum<tab><tab><IF-STMT><tab><tab><tab>intValue = maximum<tab>except ValueError:<tab><tab>self._logger.warning(<tab><tab><tab>""Could not convert %r to a valid integer when setting option %r""<tab><tab><tab>% (value, path)<tab><tab>)<tab><tab>return<tab>self.set(path, intValue, **kwargs)",1,if maximum is not None and intValue > maximum :,if maximum is not None and intValue > maximum :,0.75,100,1
"def _load_idle_extensions(self, sub_section, fp, lineno):<tab>extension_map = self.get_data(""idle extensions"")<tab>if extension_map is None:<tab><tab>extension_map = {}<tab>extensions = []<tab>while 1:<tab><tab>line, lineno, bBreak = self._readline(fp, lineno)<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>line = line.strip()<tab><tab>if line:<tab><tab><tab>extensions.append(line)<tab>extension_map[sub_section] = extensions<tab>self._save_data(""idle extensions"", extension_map)<tab>return line, lineno",1,if bBreak :,if bBreak :,0.531170663,1.00E-10,1
"def _get_config(key):<tab>config = db.session.execute(<tab><tab>Configs.__table__.select().where(Configs.key == key)<tab>).fetchone()<tab>if config and config.value:<tab><tab>value = config.value<tab><tab><IF-STMT><tab><tab><tab>return int(value)<tab><tab>elif value and isinstance(value, string_types):<tab><tab><tab>if value.lower() == ""true"":<tab><tab><tab><tab>return True<tab><tab><tab>elif value.lower() == ""false"":<tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>return value<tab># Flask-Caching is unable to roundtrip a value of None.<tab># Return an exception so that we can still cache and avoid the db hit<tab>return KeyError",0,if value and value . isdigit ( ) :,"if isinstance ( value , int ) :",0.033138934,12.25620097,0.26984127
"def check_labels(self):<tab>print(""Checking labels if they are outside the image"")<tab>for i in self.Dataframe.index:<tab><tab>image_name = os.path.join(self.project_path, i)<tab><tab>im = PIL.Image.open(image_name)<tab><tab>self.width, self.height = im.size<tab><tab>for ind in self.individual_names:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.Dataframe = MainFrame.force_outside_labels_Nans(<tab><tab><tab><tab><tab>self, i, ind, self.uniquebodyparts<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>self.Dataframe = MainFrame.force_outside_labels_Nans(<tab><tab><tab><tab><tab>self, i, ind, self.multianimalbodyparts<tab><tab><tab><tab>)<tab>return self.Dataframe",0,"if ind == ""single"" :",if self . uniquebodyparts :,0.034123066,6.971729122,0.36
"def remove_excluded(self):<tab>""""""Remove all sources marked as excluded.""""""<tab># import yaml<tab># print yaml.dump({k:v.__json__() for k,v in self.sources.items()}, default_flow_style=False)<tab>sources = list(self.sources.values())<tab>for src in sources:<tab><tab><IF-STMT><tab><tab><tab>del self.sources[src.name]<tab><tab>src.imports = [m for m in src.imports if not self._exclude(m)]<tab><tab>src.imported_by = [m for m in src.imported_by if not self._exclude(m)]",0,if src . excluded :,if src . name in self . sources :,0.27189289,19.07082808,0.333333333
"def parse_scientific_formats(data, tree):<tab>scientific_formats = data.setdefault(""scientific_formats"", {})<tab>for elem in tree.findall("".//scientificFormats/scientificFormatLength""):<tab><tab>type = elem.attrib.get(""type"")<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>pattern = text_type(elem.findtext(""scientificFormat/pattern""))<tab><tab>scientific_formats[type] = numbers.parse_pattern(pattern)",0,"if _should_skip_elem ( elem , type , scientific_formats ) :","if type == ""none"" :",0.014393213,2.359536542,0.483333333
"def _modifierCodes2Labels(cls, mods):<tab><IF-STMT><tab><tab>return []<tab>modconstants = cls._modifierCodes<tab>modNameList = []<tab>for k in modconstants._keys:<tab><tab>mc = modconstants._names[k]<tab><tab>if mods & k == k:<tab><tab><tab>modNameList.append(mc)<tab><tab><tab>mods = mods - k<tab><tab><tab>if mods == 0:<tab><tab><tab><tab>return modNameList<tab>return modNameList",1,if mods == 0 :,if mods == 0 :,0.75,100,1
"def to_pig_latin(text: str):<tab>if text is None:<tab><tab>return """"<tab>words = text.lower().strip().split("" "")<tab>text = []<tab>for word in words:<tab><tab>if word[0] in ""aeiou"":<tab><tab><tab>text.append(f""{word}yay"")<tab><tab>else:<tab><tab><tab>for letter in word:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>text.append(<tab><tab><tab><tab><tab><tab>f""{word[word.index(letter):]}{word[:word.index(letter)]}ay""<tab><tab><tab><tab><tab>)<tab><tab><tab><tab><tab>break<tab>return "" "".join(text)",0,"if letter in ""aeiou"" :",if letter in word :,0.144778655,28.64190458,0.733333333
"def __connect__(self) -> H2Protocol:<tab><IF-STMT><tab><tab>async with self._connect_lock:<tab><tab><tab>self._state = _ChannelState.CONNECTING<tab><tab><tab>if not self._connected:<tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>self._protocol = await self._create_connection()<tab><tab><tab><tab>except Exception:<tab><tab><tab><tab><tab>self._state = _ChannelState.TRANSIENT_FAILURE<tab><tab><tab><tab><tab>raise<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>self._state = _ChannelState.READY<tab>return cast(H2Protocol, self._protocol)",0,if not self . _connected :,if self . _protocol is None :,0.047631794,23.35689889,0.30952381
"def run_commands(cmds):<tab>set_kubeconfig_environment_var()<tab>for cmd in cmds:<tab><tab>process = subprocess.run(<tab><tab><tab>cmd,<tab><tab><tab>shell=True,<tab><tab><tab>check=True,<tab><tab><tab>universal_newlines=True,<tab><tab><tab>stdout=subprocess.PIPE,<tab><tab><tab>stderr=subprocess.PIPE,<tab><tab><tab>env=os.environ,<tab><tab>)<tab><tab>if process.stdout:<tab><tab><tab>logger.info(process.stdout)<tab><tab><IF-STMT><tab><tab><tab>logger.info(process.stderr)<tab>return process.stdout",1,if process . stderr :,if process . stderr :,0.75,100,1
"def deserialize(x):<tab>t = type(x)<tab>if t is list:<tab><tab>return list(imap(deserialize, x))<tab>if t is dict:<tab><tab><IF-STMT><tab><tab><tab>return {key: deserialize(val) for key, val in iteritems(x)}<tab><tab>obj = objmap.get(x[""_id_""])<tab><tab>if obj is None:<tab><tab><tab>entity_name = x[""class""]<tab><tab><tab>entity = database.entities[entity_name]<tab><tab><tab>pk = x[""_pk_""]<tab><tab><tab>obj = entity[pk]<tab><tab>return obj<tab>return x",0,"if ""_id_"" not in x :","if ""_id_"" in x :",0.133190283,66.90484409,0.36
"def _parse_arguments(self, handler_method):<tab>spec = DynamicArgumentParser().parse(self._argspec, self.longname)<tab>if not self._supports_kwargs:<tab><tab><IF-STMT><tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for **kwargs ""<tab><tab><tab><tab>""support."" % self._run_keyword_method_name<tab><tab><tab>)<tab><tab>if spec.kwonlyargs:<tab><tab><tab>raise DataError(<tab><tab><tab><tab>""Too few '%s' method parameters for ""<tab><tab><tab><tab>""keyword-only arguments support."" % self._run_keyword_method_name<tab><tab><tab>)<tab>spec.types = GetKeywordTypes(self.library.get_instance())(self._handler_name)<tab>return spec",0,if spec . kwargs :,if spec . kwkwargsargs :,0.394778655,42.72870064,0.6
"def test_update_password_command(mocker, username, password, expected, changed):<tab>with mocker.patch.object(UpdatePassword, ""update_password"", return_value=changed):<tab><tab>result, stdout, stderr = run_command(<tab><tab><tab>""update_password"", username=username, password=password<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assert stdout == expected<tab><tab>else:<tab><tab><tab>assert str(result) == expected",1,if result is None :,if result is None :,0.75,100,1
"def characters(self, ch):<tab>if self.Text_tag:<tab><tab>if self.Summary_tag:<tab><tab><tab>self.Summary_ch += ch<tab><tab><IF-STMT><tab><tab><tab>self.Attack_Prerequisite_ch += ch<tab><tab>elif self.Solution_or_Mitigation_tag:<tab><tab><tab>self.Solution_or_Mitigation_ch += ch<tab>elif self.CWE_ID_tag:<tab><tab>self.CWE_ID_ch += ch",1,elif self . Attack_Prerequisite_tag :,elif self . Attack_Prerequisite_tag :,0.75,100,1
"def _pybin_add_zip(pybin, libname, filter, exclusions, dirs, dirs_with_init_py):<tab>with zipfile.ZipFile(libname, ""r"") as lib:<tab><tab>name_list = lib.namelist()<tab><tab>for name in name_list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if dirs is not None and dirs_with_init_py is not None:<tab><tab><tab><tab><tab>_update_init_py_dirs(name, dirs, dirs_with_init_py)<tab><tab><tab><tab>pybin.writestr(name, lib.read(name))",0,"if filter ( name ) and not _is_python_excluded_path ( name , exclusions ) :",if name in exclusions :,0.064335373,0.615789601,0.227941176
"def parseAGL(filename):  # -> { 2126: 'Omega', ... }<tab>m = {}<tab>for line in readLines(filename):<tab><tab># Omega;2126<tab><tab># dalethatafpatah;05D3 05B2   # higher-level combinations; ignored<tab><tab>line = line.strip()<tab><tab>if len(line) > 0 and line[0] != ""#"":<tab><tab><tab>name, uc = tuple([c.strip() for c in line.split("";"")])<tab><tab><tab><IF-STMT><tab><tab><tab><tab># it's a 1:1 mapping<tab><tab><tab><tab>m[int(uc, 16)] = name<tab>return m",0,"if uc . find ( "" "" ) == - 1 :","if uc != ""0"" :",0.019214386,7.780436171,0.577777778
"def assertS_IS(self, name, mode):<tab># test format, lstrip is for S_IFIFO<tab>fmt = getattr(stat, ""S_IF"" + name.lstrip(""F""))<tab>self.assertEqual(stat.S_IFMT(mode), fmt)<tab># test that just one function returns true<tab>testname = ""S_IS"" + name<tab>for funcname in self.format_funcs:<tab><tab>func = getattr(stat, funcname, None)<tab><tab><IF-STMT><tab><tab><tab>if funcname == testname:<tab><tab><tab><tab>raise ValueError(funcname)<tab><tab><tab>continue<tab><tab>if funcname == testname:<tab><tab><tab>self.assertTrue(func(mode))<tab><tab>else:<tab><tab><tab>self.assertFalse(func(mode))",1,if func is None :,if func is None :,0.75,100,1
"def metadata(draft):<tab>test_metadata = {}<tab>json_schema = create_jsonschema_from_metaschema(draft.registration_schema.schema)<tab>for key, value in json_schema[""properties""].items():<tab><tab>response = ""Test response""<tab><tab>items = value[""properties""][""value""].get(""items"")<tab><tab>enum = value[""properties""][""value""].get(""enum"")<tab><tab><IF-STMT>  # multiselect<tab><tab><tab>response = [items[""enum""][0]]<tab><tab>elif enum:  # singleselect<tab><tab><tab>response = enum[0]<tab><tab>elif value[""properties""][""value""].get(""properties""):<tab><tab><tab>response = {""question"": {""value"": ""Test Response""}}<tab><tab>test_metadata[key] = {""value"": response}<tab>return test_metadata",1,if items :,if items :,0.531170663,1.00E-10,1
"def decode_binary(binarystring):<tab>""""""Decodes a binary string into it's integer value.""""""<tab>n = 0<tab>for c in binarystring:<tab><tab><IF-STMT><tab><tab><tab>d = 0<tab><tab>elif c == ""1"":<tab><tab><tab>d = 1<tab><tab>else:<tab><tab><tab>raise ValueError(""Not an binary number"", binarystring)<tab><tab># Could use ((n << 3 ) | d), but python 2.3 issues a FutureWarning.<tab><tab>n = (n * 2) + d<tab>return n",1,"if c == ""0"" :","if c == ""0"" :",0.75,100,1
"def getZoneOffset(d):<tab>zoffs = 0<tab>try:<tab><tab><IF-STMT><tab><tab><tab>zoffs = 60 * int(d[""tzhour""]) + int(d[""tzminute""])<tab><tab><tab>if d[""tzsign""] != ""-"":<tab><tab><tab><tab>zoffs = -zoffs<tab>except TypeError:<tab><tab>pass<tab>return zoffs",0,"if d [ ""zulu"" ] == None :","if ""tzhour"" in d and ""tzminute"" in d :",0.018096169,4.619215105,0.277777778
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>self.add_module(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 10 :,if tt == 10 :,0.75,100,1
"def _flow_open(self):<tab>rv = []<tab>for pipe in self.pipes:<tab><tab>if pipe._pipeline_all_methods_.issuperset({""open"", self._method_open}):<tab><tab><tab>raise RuntimeError(<tab><tab><tab><tab>f""{pipe.__class__.__name__} pipe has double open methods.""<tab><tab><tab><tab>f"" Use `open` or `{self._method_open}`, not both.""<tab><tab><tab>)<tab><tab>if ""open"" in pipe._pipeline_all_methods_:<tab><tab><tab>rv.append(pipe.open)<tab><tab><IF-STMT><tab><tab><tab>rv.append(getattr(pipe, self._method_open))<tab>return rv",1,if self . _method_open in pipe . _pipeline_all_methods_ :,if self . _method_open in pipe . _pipeline_all_methods_ :,0.75,100,1
"def list_and_filter_commands(filter_str):<tab>sorted_commands = list(_pwndbg.commands.commands)<tab>sorted_commands.sort(key=lambda x: x.__name__)<tab>if filter_str:<tab><tab>filter_str = filter_str.lower()<tab>results = []<tab>for c in sorted_commands:<tab><tab>name = c.__name__<tab><tab>docs = c.__doc__<tab><tab><IF-STMT><tab><tab><tab>docs = docs.strip()<tab><tab>if docs:<tab><tab><tab>docs = docs.splitlines()[0]<tab><tab>if (<tab><tab><tab>not filter_str<tab><tab><tab>or filter_str in name.lower()<tab><tab><tab>or (docs and filter_str in docs.lower())<tab><tab>):<tab><tab><tab>results.append((name, docs))<tab>return results",0,if docs :,"if isinstance ( docs , str ) :",0.0465226,1.00E-10,0.36
"def _scale_action(action: np.ndarray, spec: specs.Array):<tab>""""""Converts a single canonical action back to the given action spec.""""""<tab>if isinstance(spec, specs.BoundedArray):<tab><tab># Get scale and offset of output action spec.<tab><tab>scale = spec.maximum - spec.minimum<tab><tab>offset = spec.minimum<tab><tab># Maybe clip the action.<tab><tab><IF-STMT><tab><tab><tab>action = np.clip(action, -1.0, 1.0)<tab><tab># Map action to [0, 1].<tab><tab>action = 0.5 * (action + 1.0)<tab><tab># Map action to [spec.minimum, spec.maximum].<tab><tab>action *= scale<tab><tab>action += offset<tab>return action",0,if clip :,if scale > 0 :,0.051944023,1.00E-10,0.36
"def genData(self, samples, inc, sps):<tab>self.prepModData(samples, inc, sps)<tab>data = Array.CreateInstance(float, samples)<tab>cycleLen = float(sps) / gcdlist(self.findAllFreq())<tab>p = 1.0<tab>c = 0<tab>for i in range(int(cycleLen)):<tab><tab>data[i] = p * self.ampl<tab><tab>c = c + 2 * inc * self.freq * self.addModData(i)<tab><tab><IF-STMT><tab><tab><tab>p = 1.0<tab><tab>else:<tab><tab><tab>p = -1.0<tab>self.fillData(cycleLen, samples, data)<tab>return data",0,if int ( c ) % 2 == 0 :,if i % 2 == 0 :,0.20561829,48.59869097,0.272727273
"def data_type(data, grouped=False, columns=None, key_on=""idx"", iter_idx=None):<tab>""""""Data type check for automatic import""""""<tab>if iter_idx:<tab><tab>return Data.from_mult_iters(idx=iter_idx, **data)<tab>if pd:<tab><tab><IF-STMT><tab><tab><tab>return Data.from_pandas(<tab><tab><tab><tab>data, grouped=grouped, columns=columns, key_on=key_on<tab><tab><tab>)<tab>if isinstance(data, (list, tuple, dict)):<tab><tab>return Data.from_iter(data)<tab>else:<tab><tab>raise ValueError(""This data type is not supported by Vincent."")",0,"if isinstance ( data , ( pd . Series , pd . DataFrame ) ) :","if isinstance ( data , pd . DataFrame ) :",0.232291266,44.40471782,0.652380952
"def addNames(self, import_names, node_names):<tab>for names in node_names:<tab><tab>if isinstance(names, basestring):<tab><tab><tab>name = names<tab><tab><IF-STMT><tab><tab><tab>name = names[0]<tab><tab>else:<tab><tab><tab>name = names[1]<tab><tab>import_names[name] = True",0,elif names [ 1 ] is None :,"elif isinstance ( names , tuple ) :",0.018277761,7.267884212,0.232142857
"def validate_address(address_name):<tab>fields = [""pincode"", ""city"", ""country_code""]<tab>data = frappe.get_cached_value(""Address"", address_name, fields, as_dict=1) or {}<tab>for field in fields:<tab><tab><IF-STMT><tab><tab><tab>frappe.throw(<tab><tab><tab><tab>_(""Please set {0} for address {1}"").format(<tab><tab><tab><tab><tab>field.replace(""-"", """"), address_name<tab><tab><tab><tab>),<tab><tab><tab><tab>title=_(""E-Invoicing Information Missing""),<tab><tab><tab>)",0,if not data . get ( field ) :,if field not in data :,0.018728518,7.361641114,0.285714286
"def content(computer, name, values):<tab>""""""Compute the ``content`` property.""""""<tab>if len(values) == 1:<tab><tab>(value,) = values<tab><tab><IF-STMT><tab><tab><tab>return ""inhibit"" if computer[""pseudo_type""] else ""contents""<tab><tab>elif value == ""none"":<tab><tab><tab>return ""inhibit""<tab>return _content_list(computer, values)",0,"if value == ""normal"" :","if value == ""pseudo_type"" :",0.394778655,45.18010018,1
"def _replace_list(self, items):<tab>results = []<tab>for item in items:<tab><tab>listvar = self._replace_variables_inside_possible_list_var(item)<tab><tab><IF-STMT><tab><tab><tab>results.extend(self[listvar])<tab><tab>else:<tab><tab><tab>results.append(self.replace_scalar(item))<tab>return results",0,if listvar :,if listvar in self :,0.097914534,1.00E-10,0.5
"def _groups_args_split(self, kwargs):<tab>groups_args_split = []<tab>groups = kwargs[""groups""]<tab>for key, group in groups.iteritems():<tab><tab>mykwargs = kwargs.copy()<tab><tab>del mykwargs[""groups""]<tab><tab><IF-STMT><tab><tab><tab>mykwargs[""source_security_group_name""] = group[""group_name""]<tab><tab>if ""user_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_owner_id""] = group[""user_id""]<tab><tab>if ""group_id"" in group:<tab><tab><tab>mykwargs[""source_security_group_id""] = group[""group_id""]<tab><tab>groups_args_split.append(mykwargs)<tab>return groups_args_split",1,"if ""group_name"" in group :","if ""group_name"" in group :",0.75,100,1
"def WriteFlowOutputPluginLogEntries(self, entries):<tab>""""""Writes flow output plugin log entries.""""""<tab>flow_ids = [(e.client_id, e.flow_id) for e in entries]<tab>for f in flow_ids:<tab><tab><IF-STMT><tab><tab><tab>raise db.AtLeastOneUnknownFlowError(flow_ids)<tab>for e in entries:<tab><tab>dest = self.flow_output_plugin_log_entries.setdefault(<tab><tab><tab>(e.client_id, e.flow_id), []<tab><tab>)<tab><tab>to_write = e.Copy()<tab><tab>to_write.timestamp = rdfvalue.RDFDatetime.Now()<tab><tab>dest.append(to_write)",0,if f not in self . flows :,if f not in self . flow_output_plugin_log_entries :,0.605621306,31.31422481,0.828571429
def connect(**auth):<tab>key = tuple(sorted(auth.items()))<tab>if key in connection_pool:<tab><tab>ssh = connection_pool[key]<tab><tab><IF-STMT><tab><tab><tab>ssh.connect(**auth)<tab>else:<tab><tab>ssh = paramiko.SSHClient()<tab><tab>ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())<tab><tab>ssh.connect(**auth)<tab><tab>connection_pool[key] = ssh<tab>return ssh,0,if not ssh . get_transport ( ) or not ssh . get_transport ( ) . is_active ( ) :,"if isinstance ( ssh , paramiko . SSHClient ) :",0.013644881,2.464427004,0.328703704
"def __call__(self, *args, **kwargs):<tab>if self is S:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""S() takes no positional arguments, got: %r"" % (args,))<tab><tab>if not kwargs:<tab><tab><tab>raise TypeError(""S() expected at least one kwarg, got none"")<tab><tab># TODO: typecheck kwarg vals?<tab>return _t_child(self, ""("", (args, kwargs))",1,if args :,if args :,0.531170663,1.00E-10,1
"def read_images(self, paths=[]):<tab>images = []<tab>for img_path in paths:<tab><tab>assert os.path.isfile(img_path), ""The {} isn't a valid file."".format(img_path)<tab><tab>img = cv2.imread(img_path)<tab><tab><IF-STMT><tab><tab><tab>logger.info(""error in loading image:{}"".format(img_path))<tab><tab><tab>continue<tab><tab>img = img[:, :, ::-1]<tab><tab>images.append(img)<tab>return images",1,if img is None :,if img is None :,0.75,100,1
"def get_polymorphic_model(data):<tab>for model in itervalues(models):<tab><tab>polymorphic = model.opts.polymorphic<tab><tab>if polymorphic:<tab><tab><tab>polymorphic_key = polymorphic<tab><tab><tab><IF-STMT><tab><tab><tab><tab>polymorphic_key = ""type""<tab><tab><tab>if data.get(polymorphic_key) == model.__name__:<tab><tab><tab><tab>return model<tab>raise ImproperlyConfigured(u""No model found for data: {!r}"".format(data))",0,"if isinstance ( polymorphic_key , bool ) :","elif polymorphic_key == ""type"" :",0.01622835,16.78445963,0.166666667
"def parse_counter_style_name(tokens, counter_style):<tab>tokens = remove_whitespace(tokens)<tab>if len(tokens) == 1:<tab><tab>(token,) = tokens<tab><tab>if token.type == ""ident"":<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if token.lower_value not in counter_style:<tab><tab><tab><tab><tab>return token.value<tab><tab><tab>elif token.lower_value != ""none"":<tab><tab><tab><tab>return token.value",0,"if token . lower_value in ( ""decimal"" , ""disc"" ) :",if token . lower_value in counter_style :,0.237367572,34.19783508,1
"def setUp(self):<tab>yield helpers.TestHandlerWithPopulatedDB.setUp(self)<tab>for r in (yield tw(user.db_get_users, 1, ""receiver"", ""en"")):<tab><tab><IF-STMT><tab><tab><tab>self.rcvr_id = r[""id""]",0,"if r [ ""pgp_key_fingerprint"" ] == ""BFB3C82D1B5F6A94BDAC55C6E70460ABF9A4C8C1"" :","if r [ ""pgp_key_fingerprint"" ] == ""BFB3C82D1B5F6A4C1"" :",0.605621306,84.82198619,1
"def check_that_oval_and_rule_id_match(xccdftree):<tab>for xccdfid, rule in rules_with_ids_generator(xccdftree):<tab><tab>checks = rule.find(""./{%s}check"" % XCCDF11_NS)<tab><tab><IF-STMT><tab><tab><tab>print(""Rule {0} doesn't have checks."".format(xccdfid), file=sys.stderr)<tab><tab><tab>continue<tab><tab>assert_that_check_ids_match_rule_id(checks, xccdfid)",0,if checks is None :,if not checks :,0.039449619,16.37226967,0.277777778
"def MakeWidthArray(fm):<tab># Make character width array<tab>s = ""{\n\t""<tab>cw = fm[""Widths""]<tab>for i in xrange(0, 256):<tab><tab><IF-STMT><tab><tab><tab>s += ""'\\''""<tab><tab>elif chr(i) == ""\\"":<tab><tab><tab>s += ""'\\\\'""<tab><tab>elif i >= 32 and i <= 126:<tab><tab><tab>s += ""'"" + chr(i) + ""'""<tab><tab>else:<tab><tab><tab>s += ""chr(%d)"" % i<tab><tab>s += "":"" + fm[""Widths""][i]<tab><tab>if i < 255:<tab><tab><tab>s += "",""<tab><tab>if (i + 1) % 22 == 0:<tab><tab><tab>s += ""\n\t""<tab>s += ""}""<tab>return s",0,"if chr ( i ) == ""'"" :","if chr ( i ) == ""\\"" :",0.605621306,67.04226838,1
"def testCheckIPGenerator(self):<tab>for i, ip in self._ip_range(65536 if not unittest.F2B.fast else 1000):<tab><tab>if i == 254:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.0.255"")<tab><tab>elif i == 255:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.1.0"")<tab><tab>elif i == 1000:<tab><tab><tab>self.assertEqual(str(ip), ""127.0.3.233"")<tab><tab><IF-STMT><tab><tab><tab>self.assertEqual(str(ip), ""127.0.255.255"")<tab><tab>elif i == 65535:<tab><tab><tab>self.assertEqual(str(ip), ""127.1.0.0"")",0,elif i == 65534 :,elif i == 100 :,0.642872021,53.72849659,0.6
"def _fetch(obj, url, body, *args, **kwargs):<tab>if _is_running_from_main_thread():<tab><tab>body = urlencode(body).encode(""utf-8"")<tab><tab>response = self.fetch(url, body=body, method=""POST"")<tab><tab><IF-STMT><tab><tab><tab>raise luigi.rpc.RPCError(""Errror when connecting to remote scheduler"")<tab><tab>return response.body.decode(""utf-8"")",0,if response . code >= 400 :,if response is None :,0.042406009,12.97584999,0.428571429
"def isOrHasChild(parent, child):<tab>while child:<tab><tab>if compare(parent, child):<tab><tab><tab>return True<tab><tab>child = child.parentNode<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if child.nodeType != 1:<tab><tab><tab>child = None<tab>return False",0,if not child :,if child . nodeType != child . ELEMENT_NODE :,0.035362843,4.456882761,0.381818182
"def HandleCharFormatChange(self, id, code):<tab>if code == win32con.BN_CLICKED:<tab><tab>editId = buttonControlMap.get(id)<tab><tab>assert editId is not None, ""Format button has no associated edit control""<tab><tab>editControl = self.GetDlgItem(editId)<tab><tab>existingFormat = editControl.GetDefaultCharFormat()<tab><tab>flags = win32con.CF_SCREENFONTS<tab><tab>d = win32ui.CreateFontDialog(existingFormat, flags, None, self)<tab><tab><IF-STMT><tab><tab><tab>cf = d.GetCharFormat()<tab><tab><tab>editControl.SetDefaultCharFormat(cf)<tab><tab><tab>self.SetModified(1)<tab><tab>return 0  # We handled this fully!",0,if d . DoModal ( ) == win32con . IDOK :,if d . ShowModal ( ) == win32con . IDOK :,0.602001933,73.48889201,0.714285714
"def test___iter___two_points(self):<tab>cba = LineString([(1, 2), (3, 4)])<tab>for i, xy in enumerate(cba):<tab><tab>assert i in [0, 1]<tab><tab><IF-STMT><tab><tab><tab>assert np.allclose(xy, (1, 2))<tab><tab>elif i == 1:<tab><tab><tab>assert np.allclose(xy, (3, 4))<tab>assert i == 1",1,if i == 0 :,if i == 0 :,0.75,100,1
"def main(self):<tab>self.model.clear()<tab>active_handle = self.get_active(""Family"")<tab>if active_handle:<tab><tab>active = self.dbstate.db.get_family_from_handle(active_handle)<tab><tab><IF-STMT><tab><tab><tab>self.display_attributes(active)<tab><tab>else:<tab><tab><tab>self.set_has_data(False)<tab>else:<tab><tab>self.set_has_data(False)",1,if active :,if active :,0.531170663,1.00E-10,1
"def findStyleName(element, style):<tab>oldStyle = DOM.getAttribute(element, ""className"")<tab>if oldStyle is None:<tab><tab>return -1<tab>idx = oldStyle.find(style)<tab># Calculate matching index<tab>lastPos = len(oldStyle)<tab>while idx != -1:<tab><tab>if idx == 0 or (oldStyle[idx - 1] == "" ""):<tab><tab><tab>last = idx + len(style)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>idx = oldStyle.find(style, idx + 1)<tab>return idx",0,"if ( last == lastPos ) or ( ( last < lastPos ) and ( oldStyle [ last ] == "" "" ) ) :",if idx == lastPos :,0.044538103,1.036659637,0.313596491
"def result(self):<tab>""""""Gets the formatted string result.""""""<tab>if self.__group.isChecked():<tab><tab><IF-STMT><tab><tab><tab>return ""gt%d"" % self.__min.value()<tab><tab>if self.__lessThan.isChecked():<tab><tab><tab>return ""lt%d"" % self.__max.value()<tab><tab>if self.__range.isChecked():<tab><tab><tab>return ""%d-%d"" % (self.__min.value(), self.__max.value())<tab>return """"",0,if self . __moreThan . isChecked ( ) :,if self . __greater . Checked ( ) :,0.354826209,48.32697831,0.6
"def get_generic_exception_from_err_details(err_details):<tab>err = None<tab>if err_details.errcls is not None:<tab><tab>err = err_details.errcls(err_details.message)<tab><tab><IF-STMT><tab><tab><tab>err.set_linecol(<tab><tab><tab><tab>err_details.detail_json.get(""line"", -1),<tab><tab><tab><tab>err_details.detail_json.get(""column"", -1),<tab><tab><tab>)<tab>return err",0,if err_details . errcls is not errors . InternalServerError :,if err_details . detail_json is not None :,0.213981507,37.70063805,0.225
"def convert_value(self, value, expression, connection, context):<tab>if value is None:<tab><tab>return None<tab>geo_field = self.geo_field<tab>if geo_field.geodetic(connection):<tab><tab>dist_att = ""m""<tab>else:<tab><tab>units = geo_field.units_name(connection)<tab><tab><IF-STMT><tab><tab><tab>dist_att = DistanceMeasure.unit_attname(units)<tab><tab>else:<tab><tab><tab>dist_att = None<tab>if dist_att:<tab><tab>return DistanceMeasure(**{dist_att: value})<tab>return value",1,if units :,if units :,0.531170663,1.00E-10,1
"def __init__(self, **kwargs):<tab>self.layout_cell = kwargs.pop(""layout_cell"")<tab>self.theme = kwargs.pop(""theme"")<tab>assert isinstance(self.layout_cell, LayoutCell)<tab>super(LayoutCellFormGroup, self).__init__(**kwargs)<tab>self.add_form_def(<tab><tab>""general"",<tab><tab>LayoutCellGeneralInfoForm,<tab><tab>kwargs={""layout_cell"": self.layout_cell, ""theme"": self.theme},<tab>)<tab>plugin = self.layout_cell.instantiate_plugin()<tab>if plugin:<tab><tab>form_class = plugin.get_editor_form_class()<tab><tab><IF-STMT><tab><tab><tab>self.add_form_def(""plugin"", form_class, kwargs={""plugin"": plugin})",1,if form_class :,if form_class :,0.531170663,1.00E-10,1
"def load_model(self, model_dict):<tab>model_param = None<tab>model_meta = None<tab>for _, value in model_dict[""model""].items():<tab><tab>for model in value:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>model_meta = value[model]<tab><tab><tab>if model.endswith(""Param""):<tab><tab><tab><tab>model_param = value[model]<tab>LOGGER.info(""load model"")<tab>self.set_model_meta(model_meta)<tab>self.set_model_param(model_param)<tab>self.loss = self.get_loss_function()",1,"if model . endswith ( ""Meta"" ) :","if model . endswith ( ""Meta"" ) :",0.75,100,1
"def add_plugin_single(name, plugin_to_add, parent):<tab>plugin_existing = parent.get_plugins(name)<tab>if plugin_existing is None:<tab><tab>parent.add_plugin(name, plugin_to_add)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>parent.update_plugin(name, plugin_to_add)<tab><tab>else:<tab><tab><tab>error(""Duplicated plugin {}!"".format(name))",0,if not plugin_existing . is_callable_plugin ( ) :,if name in plugin_existing :,0.019907918,10.21828938,0.381818182
"def get_details(guid):<tab>searchResultId = guid<tab>searchResult = SearchResult.get(SearchResult.id == searchResultId)<tab>details_link = searchResult.details<tab>if details_link:<tab><tab>logger.info(""Redirecting to details link %s "" % details_link)<tab><tab><IF-STMT><tab><tab><tab>details_link = config.settings.main.dereferer.replace(<tab><tab><tab><tab>""$s"", urllib.quote(details_link)<tab><tab><tab>)<tab><tab>return redirect(details_link)<tab>logger.error(""Unable to find details link for search result ID %d"" % searchResultId)<tab>return ""Unable to find details"", 500",0,if config . settings . main . dereferer :,"if not details_link . startswith ( ""#"" ) :",0.016784919,4.065425429,0.225
"def SurroundedByParens(token):<tab>""""""Check if it's an expression surrounded by parentheses.""""""<tab>while token:<tab><tab>if token.value == "","":<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>return not token.next_token<tab><tab>if token.OpensScope():<tab><tab><tab>token = token.matching_bracket.next_token<tab><tab>else:<tab><tab><tab>token = token.next_token<tab>return False",0,"if token . value == "")"" :","if token . value == "","" :",0.574113272,70.71067812,1
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>cnt = 0<tab>for e in self.stat_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""stat%s <\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab><tab>cnt += 1<tab>if self.has_more_files_found_:<tab><tab>res += prefix + (<tab><tab><tab>""more_files_found: %s\n"" % self.DebugFormatBool(self.more_files_found_)<tab><tab>)<tab>return res",1,if printElemNumber :,if printElemNumber :,0.531170663,1.00E-10,1
"def _get_constraints(self, params):<tab>constraints = {}<tab>for filter_name in self._get_filter_names():<tab><tab>raw_value = params.get(filter_name, None)<tab><tab><IF-STMT><tab><tab><tab>constraints[filter_name] = self._get_value(raw_value)<tab>return constraints",1,if raw_value is not None :,if raw_value is not None :,0.75,100,1
"def print_nested_help(self, args: argparse.Namespace) -> None:<tab>level = 0<tab>parser = self.main_parser<tab>while True:<tab><tab>if parser._subparsers is None:<tab><tab><tab>break<tab><tab>if parser._subparsers._actions is None:<tab><tab><tab>break<tab><tab>choices = parser._subparsers._actions[-1].choices<tab><tab>value = getattr(args, ""level_%d"" % level)<tab><tab><IF-STMT><tab><tab><tab>parser.print_help()<tab><tab><tab>return<tab><tab>if not choices:<tab><tab><tab>break<tab><tab>if isinstance(choices, dict):<tab><tab><tab>parser = choices[value]<tab><tab>else:<tab><tab><tab>return<tab><tab>level += 1",1,if value is None :,if value is None :,0.75,100,1
"def prompts_dict(self, *args, **kwargs):<tab>r = super(WorkflowJobNode, self).prompts_dict(*args, **kwargs)<tab># Explanation - WFJT extra_vars still break pattern, so they are not<tab># put through prompts processing, but inventory and others are only accepted<tab># if JT prompts for it, so it goes through this mechanism<tab>if self.workflow_job:<tab><tab><IF-STMT><tab><tab><tab># workflow job inventory takes precedence<tab><tab><tab>r[""inventory""] = self.workflow_job.inventory<tab><tab>if self.workflow_job.char_prompts:<tab><tab><tab>r.update(self.workflow_job.char_prompts)<tab>return r",0,if self . workflow_job . inventory_id :,if self . workflow_job . inventory :,0.574113272,71.19674182,0.722222222
"def _check_etc_hosts():<tab>debug2("" > hosts\n"")<tab>for line in open(""/etc/hosts""):<tab><tab>line = re.sub(r""#.*"", """", line)<tab><tab>words = line.strip().split()<tab><tab>if not words:<tab><tab><tab>continue<tab><tab>ip = words[0]<tab><tab>names = words[1:]<tab><tab><IF-STMT><tab><tab><tab>debug3(""<<tab>%s %r\n"" % (ip, names))<tab><tab><tab>for n in names:<tab><tab><tab><tab>check_host(n)<tab><tab><tab><tab>found_host(n, ip)",0,if _is_ip ( ip ) :,if len ( names ) > 1 :,0.149927243,6.892168295,0.3
"def add_variant_attribute_data_to_expected_data(data, variant, attribute_ids, pk=None):<tab>for assigned_attribute in variant.attributes.all():<tab><tab>header = f""{assigned_attribute.attribute.slug} (variant attribute)""<tab><tab><IF-STMT><tab><tab><tab>value = get_attribute_value(assigned_attribute)<tab><tab><tab>if pk:<tab><tab><tab><tab>data[pk][header] = value<tab><tab><tab>else:<tab><tab><tab><tab>data[header] = value<tab>return data",0,if str ( assigned_attribute . attribute . pk ) in attribute_ids :,if header in attribute_ids :,0.042678797,17.78861689,0.267857143
"def scrub_time(self, time):  # used externally to set time by slider scrubbing<tab>debug(""scrub_time: {0}"".format(time))<tab>if time == 0:<tab><tab>self.loop_backward()<tab>elif time == self.timer_duration:<tab><tab>self.loop_forward()<tab>else:  # time in between 0 and duration<tab><tab><IF-STMT><tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab><tab>elif self.timer_status == TIMER_STATUS_EXPIRED:<tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab>self.timer_time = time",0,if self . timer_status == TIMER_STATUS_STOPPED :,if self . timer_status == TIMER_STATUS_EXPIRED :,0.574113272,85.55261859,1
"def leave_AssignTarget(<tab>self,<tab>original_node: cst.AssignTarget,<tab>updated_node: cst.AssignTarget,) -> cst.AssignTarget:<tab># We can't use matchers here due to circular imports<tab>target = updated_node.target<tab>if isinstance(target, cst.Name):<tab><tab>var_name = unmangled_name(target.value)<tab><tab><IF-STMT><tab><tab><tab>return self.assignment_replacements[var_name].deep_clone()<tab>return updated_node",1,if var_name in self . assignment_replacements :,if var_name in self . assignment_replacements :,0.75,100,1
"def step(self, action):<tab>assert self.action_space.contains(action)<tab>if self._state == 4:<tab><tab><IF-STMT><tab><tab><tab>return self._state, 10.0, True, {}<tab><tab>else:<tab><tab><tab>return self._state, -10, True, {}<tab>else:<tab><tab>if action:<tab><tab><tab>if self._state == 0:<tab><tab><tab><tab>self._state = 2<tab><tab><tab>else:<tab><tab><tab><tab>self._state += 1<tab><tab>elif self._state == 2:<tab><tab><tab>self._state = self._case<tab>return self._state, -1, False, {}",0,if action and self . _case :,if action :,0.038857533,1.00E-10,0.55
"def last_ok(nodes):<tab>for i in range(len(nodes) - 1, -1, -1):<tab><tab><IF-STMT><tab><tab><tab>node = nodes[i]<tab><tab><tab>if isinstance(node, ast.Starred):<tab><tab><tab><tab>if ok_node(node.value):<tab><tab><tab><tab><tab>return node.value<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>return None<tab><tab><tab>else:<tab><tab><tab><tab>return nodes[i]<tab>return None",0,if ok_node ( nodes [ i ] ) :,"if isinstance ( nodes [ i ] , ast . Name ) :",0.269923977,34.38931218,0.260504202
"def __contains__(self, table_name):<tab>""""""Check if the given table name exists in the database.""""""<tab>try:<tab><tab>table_name = normalize_table_name(table_name)<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if table_name in self.views:<tab><tab><tab>return True<tab><tab>return False<tab>except ValueError:<tab><tab>return False",1,if table_name in self . tables :,if table_name in self . tables :,0.75,100,1
"def get_history_data(self, guid, count=1):<tab>history = {}<tab>if count < 1:<tab><tab>return history<tab>key = self._make_key(guid)<tab>for i in range(0, self.db.llen(key)):<tab><tab>r = self.db.lindex(key, i)<tab><tab>c = msgpack.unpackb(r)<tab><tab>if c[""tries""] == 0 or c[""tries""] is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>history[c[""data""]] = c[""timestamp""]<tab><tab><tab><tab>if len(history) >= count:<tab><tab><tab><tab><tab>break<tab>return history",0,"if c [ ""data"" ] not in history :","if c [ ""data"" ] is not None :",0.495329736,60.76795808,0.375
"def _state_dec_to_imp(self, token):<tab>if token in (""+"", ""-""):<tab><tab>self._state = self._state_global<tab>else:<tab><tab>super(ObjCStates, self)._state_dec_to_imp(token)<tab><tab><IF-STMT><tab><tab><tab>self._state = self._state_objc_dec_begin<tab><tab><tab>self.context.restart_new_function(token)",0,if self . _state != self . _state_imp :,"if self . _state == ""objc"" :",0.227532652,29.05374199,0.863247863
"def _additional_handlers(self):<tab>handlers = []<tab>if self.session.get(""proxy""):<tab><tab>protocol, host, port = self._get_proxy()<tab><tab><IF-STMT><tab><tab><tab>handlers.append(sockshandler.SocksiPyHandler(protocol, host, port))<tab><tab>else:<tab><tab><tab>raise ChannelException(messages.channels.error_proxy_format)<tab># Skip certificate checks<tab>ctx = ssl.create_default_context()<tab>ctx.check_hostname = False<tab>ctx.verify_mode = ssl.CERT_NONE<tab>handlers.append(urllib.request.HTTPSHandler(context=ctx))<tab>return handlers",0,if protocol and host and port :,if protocol :,0.038857533,1.00E-10,0.388888889
"def loadGCodeData(self, dataStream):<tab>if self._printing:<tab><tab>return False<tab>self._lineCount = 0<tab>for line in dataStream:<tab><tab># Strip out comments, we do not need to send comments<tab><tab>if "";"" in line:<tab><tab><tab>line = line[: line.index("";"")]<tab><tab># Strip out whitespace at the beginning/end this saves data to send.<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>self._lineCount += 1<tab>self._doCallback()<tab>return True",0,if len ( line ) < 1 :,if not line :,0.019930836,7.733712583,0.481481481
"def get_headers_footers_xml(self, uri):<tab>for relKey, val in self.docx._part._rels.items():<tab><tab><IF-STMT><tab><tab><tab>yield relKey, self.xml_to_string(parse_xml(val.target_part.blob))",0,if ( val . reltype == uri ) and ( val . target_part . blob ) :,if relKey == uri and val . target_part . blob :,0.13336259,36.98482848,0.244047619
"def eventlist_name(name=None, key=""core""):<tab>if not name:<tab><tab>name = get_cpustr()<tab>cache = getdir()<tab>fn = name<tab>if os.path.exists(fn):<tab><tab>return fn<tab>if "".json"" not in name:<tab><tab>fn = ""%s-%s.json"" % (name, key)<tab>if ""/"" in fn:<tab><tab>return fn<tab>fn = ""%s/%s"" % (cache, fn)<tab>if not os.path.exists(fn):<tab><tab>name = cpu_without_step(name)<tab><tab><IF-STMT><tab><tab><tab>fn = ""%s/%s"" % (cache, name)<tab><tab>else:<tab><tab><tab>fn = ""%s/%s-%s.json"" % (cache, name, key)<tab>return fn",0,"if ""*"" in fn :","if "".json"" not in name :",0.032294704,11.99014838,0.3
"def test09_authority(self):<tab>""Testing the authority name & code routines.""<tab>for s in srlist:<tab><tab><IF-STMT><tab><tab><tab>srs = SpatialReference(s.wkt)<tab><tab><tab>for target, tup in s.auth.items():<tab><tab><tab><tab>self.assertEqual(tup[0], srs.auth_name(target))<tab><tab><tab><tab>self.assertEqual(tup[1], srs.auth_code(target))",1,"if hasattr ( s , ""auth"" ) :","if hasattr ( s , ""auth"" ) :",0.75,100,1
"def astAssign(self, import_names, node):<tab>for node in node.nodes:<tab><tab><IF-STMT><tab><tab><tab>import_names[node.name] = True<tab><tab>else:<tab><tab><tab>self.warning(""Ignoring Assign %s"" % node.flags, node.lineno)",0,"if node . flags == ""OP_ASSIGN"" :",if node . name in import_names :,0.090565314,14.44881489,0.476190476
"def _autojoin(self, __):<tab>if not self.auto_join:<tab><tab>return<tab>try:<tab><tab>result = self.get_bookmarks(method=self.storage_method)<tab>except XMPPError:<tab><tab>return<tab>if self.storage_method == ""xep_0223"":<tab><tab>bookmarks = result[""pubsub""][""items""][""item""][""bookmarks""]<tab>else:<tab><tab>bookmarks = result[""private""][""bookmarks""]<tab>for conf in bookmarks[""conferences""]:<tab><tab><IF-STMT><tab><tab><tab>log.debug(""Auto joining %s as %s"", conf[""jid""], conf[""nick""])<tab><tab><tab>self.xmpp[""xep_0045""].joinMUC(<tab><tab><tab><tab>conf[""jid""], conf[""nick""], password=conf[""password""]<tab><tab><tab>)",0,"if conf [ ""autojoin"" ] :","if conf [ ""jid"" ] and conf [ ""nick"" ] :",0.177411773,23.79366548,0.635416667
"def config_mode(self, config_command=""conf t"", pattern=""""):<tab>output = """"<tab>if not self.check_config_mode():<tab><tab>output = self.send_command_timing(<tab><tab><tab>config_command, strip_command=False, strip_prompt=False<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>output += self.send_command_timing(<tab><tab><tab><tab>""YES"", strip_command=False, strip_prompt=False<tab><tab><tab>)<tab><tab>if not self.check_config_mode():<tab><tab><tab>raise ValueError(""Failed to enter configuration mode"")<tab>return output",0,"if ""to enter configuration mode anyway"" in output :",if pattern in output :,0.06668419,12.86963732,0.21875
"def work(self):<tab>idle_times = 0<tab>while True:<tab><tab>if shutting_down.is_set():<tab><tab><tab>log.info(""Stop sync worker"")<tab><tab><tab>break<tab><tab>try:<tab><tab><tab>job = self.commit_queue.get(timeout=self.timeout, block=True)<tab><tab><tab>if job[""type""] == ""commit"":<tab><tab><tab><tab>self.commits.append(job)<tab><tab><tab>log.debug(""Got a commit job"")<tab><tab><tab>idle_times = 0<tab><tab><tab>idle.clear()<tab><tab>except Empty:<tab><tab><tab>log.debug(""Nothing to do right now, going idle"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>idle.set()<tab><tab><tab>idle_times += 1<tab><tab><tab>self.on_idle()",0,if idle_times > self . min_idle_times :,if idle_times == 0 :,0.042406009,19.56676108,0.5
"def movies_iterator():<tab>for row in self._tuple_iterator(query):<tab><tab>id, guid, movie = self._parse(fields, row, offset=2)<tab><tab># Parse `guid` (if enabled, and not already parsed)<tab><tab><IF-STMT><tab><tab><tab>if id not in guids:<tab><tab><tab><tab>guids[id] = Guid.parse(guid)<tab><tab><tab>guid = guids[id]<tab><tab># Return item<tab><tab>yield id, guid, movie",0,if parse_guid :,if guid :,0.319750449,1.00E-10,0.555555556
"def timesince(value):<tab>diff = timezone.now() - value<tab>plural = """"<tab>if diff.days == 0:<tab><tab>hours = int(diff.seconds / 3600.0)<tab><tab>if hours != 1:<tab><tab><tab>plural = ""s""<tab><tab>return ""%d hour%s ago"" % (int(diff.seconds / 3600.0), plural)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>plural = ""s""<tab><tab>return ""%d day%s ago"" % (diff.days, plural)",1,if diff . days != 1 :,if diff . days != 1 :,0.75,100,1
"def connect(self, *args):<tab>if len(args) == 0:<tab><tab>self.basepath = ""/""<tab><tab>return True  # no setup required; connect is allways successful<tab>else:<tab><tab>self.basepath = args[0]<tab><tab><IF-STMT><tab><tab><tab>return ""No such directory: {p}"".format(p=self.basepath)<tab><tab>return True",1,if not os . path . isdir ( self . basepath ) :,if not os . path . isdir ( self . basepath ) :,0.75,100,1
"def get_callable(self):<tab>if not self.func:<tab><tab>prototype = self.get_prototype()<tab><tab>self.func = cast(self.imp, prototype)<tab><tab><IF-STMT><tab><tab><tab>self.func.restype = c_void_p<tab><tab>else:<tab><tab><tab>self.func.restype = self.restype<tab><tab>self.func.argtypes = self.argtypes<tab>return self.func",0,if self . restype == ObjCInstance or self . restype == ObjCClass :,if self . restype is None :,0.10149198,13.86353367,0.344729345
"def on_task_output(self, task, config):<tab>for entry in task.entries:<tab><tab><IF-STMT><tab><tab><tab>if entry[""torrent""].modified:<tab><tab><tab><tab># re-write data into a file<tab><tab><tab><tab>log.debug(""Writing modified torrent file for %s"" % entry[""title""])<tab><tab><tab><tab>with open(entry[""file""], ""wb+"") as f:<tab><tab><tab><tab><tab>f.write(entry[""torrent""].encode())",1,"if ""torrent"" in entry :","if ""torrent"" in entry :",0.75,100,1
"def update(self, data):<tab>results = []<tab>while True:<tab><tab>remain = BLOCK_SIZE - self._pos<tab><tab>cur_data = data[:remain]<tab><tab>cur_data_len = len(cur_data)<tab><tab>cur_stream = self._stream[self._pos : self._pos + cur_data_len]<tab><tab>self._pos = self._pos + cur_data_len<tab><tab>data = data[remain:]<tab><tab>results.append(numpy_xor(cur_data, cur_stream))<tab><tab>if self._pos >= BLOCK_SIZE:<tab><tab><tab>self._next_stream()<tab><tab><tab>self._pos = 0<tab><tab><IF-STMT><tab><tab><tab>break<tab>return b"""".join(results)",0,if not data :,if len ( data ) == 0 :,0.036611762,6.274655311,0.481481481
"def listed(output, pool):<tab>for line in output.splitlines():<tab><tab>name, mountpoint, refquota = line.split(b""\t"")<tab><tab>name = name[len(pool) + 1 :]<tab><tab>if name:<tab><tab><tab>refquota = int(refquota.decode(""ascii""))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>refquota = None<tab><tab><tab>yield _DatasetInfo(dataset=name, mountpoint=mountpoint, refquota=refquota)",0,if refquota == 0 :,elif refquota == 0 :,0.311522644,75.98356857,0.6
"def set_multi(self, value):<tab>del self[atype]<tab>for addr in value:<tab><tab># Support assigning dictionary versions of addresses<tab><tab># instead of full Address objects.<tab><tab><IF-STMT><tab><tab><tab>if atype != ""all"":<tab><tab><tab><tab>addr[""type""] = atype<tab><tab><tab>elif ""atype"" in addr and ""type"" not in addr:<tab><tab><tab><tab>addr[""type""] = addr[""atype""]<tab><tab><tab>addrObj = Address()<tab><tab><tab>addrObj.values = addr<tab><tab><tab>addr = addrObj<tab><tab>self.append(addr)",0,"if not isinstance ( addr , Address ) :","if isinstance ( addr , dict ) :",0.18845666,37.70794597,0.26984127
"def get_migration_rate(volume):<tab>metadata = get_metadata(volume)<tab>rate = metadata.get(""migrate_rate"", None)<tab>if rate:<tab><tab><IF-STMT><tab><tab><tab>return storops.VNXMigrationRate.parse(rate.lower())<tab><tab>else:<tab><tab><tab>LOG.warning(<tab><tab><tab><tab>""Unknown migration rate specified, "" ""using [high] as migration rate.""<tab><tab><tab>)<tab><tab><tab>return storops.VNXMigrationRate.HIGH",0,if rate . lower ( ) in storops . VNXMigrationRate . values ( ) :,if rate . lower ( ) :,0.255780655,29.67759918,0.475
"def _check_params(self) -> None:<tab>if self.augmentation and self.ratio <= 0:<tab><tab>raise ValueError(""The augmentation ratio must be positive."")<tab>if self.clip_values is not None:<tab><tab>if len(self.clip_values) != 2:<tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""`clip_values` should be a tuple of 2 floats or arrays containing the allowed data range.""<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(""Invalid `clip_values`: min >= max."")",0,if np . array ( self . clip_values [ 0 ] >= self . clip_values [ 1 ] ) . any ( ) :,if self . clip_values < min or self . clip_values > max :,0.033748452,22.5711291,0.176470588
"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab>if pos == -1:<tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab>elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab>if c == ""\\"":<tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos",1,if not escaped :,if not escaped :,0.75,100,1
"def get_objects(self):<tab>retval = []<tab>for item in self._obj_list:<tab><tab>if item is None:<tab><tab><tab>continue<tab><tab>target = pickle.loads(item)[0]<tab><tab>_class = map2class(target)<tab><tab>if _class:<tab><tab><tab>obj = _class(self._dbstate, item)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retval.append(obj)<tab>return retval",0,if obj :,if obj is not None :,0.090364769,1.00E-10,0.4
"def get_databases(request):<tab>dbs = {}<tab>for (key, value) in global_env.items():<tab><tab>try:<tab><tab><tab>cond = isinstance(value, GQLDB)<tab><tab>except:<tab><tab><tab>cond = isinstance(value, SQLDB)<tab><tab><IF-STMT><tab><tab><tab>dbs[key] = value<tab>return dbs",1,if cond :,if cond :,0.531170663,1.00E-10,1
"def real_quick_ratio(buf1, buf2):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return 0<tab><tab>s = SequenceMatcher(None, buf1.split(""\n""), buf2.split(""\n""))<tab><tab>return s.real_quick_ratio()<tab>except:<tab><tab>print(""real_quick_ratio:"", str(sys.exc_info()[1]))<tab><tab>return 0",0,"if buf1 is None or buf2 is None or buf1 == """" or buf1 == """" :",if buf1 is None or buf2 is None :,0.335594286,23.43746816,0.816326531
"def SentSegRestoreSent(<tab>batch_words: List[List[str]], batch_tags: List[List[str]]) -> List[str]:<tab>ret = []<tab>for words, tags in zip(batch_words, batch_tags):<tab><tab>if len(tags) == 0:<tab><tab><tab>ret.append("""")<tab><tab><tab>continue<tab><tab>sent = words[0]<tab><tab>punct = """" if tags[0] == ""O"" else tags[0][-1]<tab><tab>for word, tag in zip(words[1:], tags[1:]):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sent += punct<tab><tab><tab><tab>punct = tag[-1]<tab><tab><tab>sent += "" "" + word<tab><tab>sent += punct<tab><tab>ret.append(sent)<tab>return ret",0,"if tag != ""O"" :",if len ( tag ) > 1 :,0.02800146,7.267884212,0.36
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""MultiNLI"")<tab>version = ""1.0""<tab>if not build_data.built(dpath, version_string=version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># an older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab># mark the data as built<tab><tab>build_data.mark_done(dpath, version_string=version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100,1
"def __iter__(self):<tab>iteration = self.start_iter<tab>while iteration <= self.num_iterations:<tab><tab># if the underlying sampler has a set_epoch method, like<tab><tab># DistributedSampler, used for making each process see<tab><tab># a different split of the dataset, then set it<tab><tab>if hasattr(self.batch_sampler.sampler, ""set_epoch""):<tab><tab><tab>self.batch_sampler.sampler.set_epoch(iteration)<tab><tab>for batch in self.batch_sampler:<tab><tab><tab>iteration += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab><tab>yield batch",0,if iteration > self . num_iterations :,"if isinstance ( batch , DistributedSampler ) :",0.019801327,5.795599613,0.26984127
"def visit_title(self, node: Element) -> None:<tab>if isinstance(node.parent, addnodes.seealso):<tab><tab>self.body.append('.IP ""')<tab><tab>return<tab>elif isinstance(node.parent, nodes.section):<tab><tab>if self.section_level == 0:<tab><tab><tab># skip the document title<tab><tab><tab>raise nodes.SkipNode<tab><tab><IF-STMT><tab><tab><tab>self.body.append("".SH %s\n"" % self.deunicode(node.astext().upper()))<tab><tab><tab>raise nodes.SkipNode<tab>return super().visit_title(node)",0,elif self . section_level == 1 :,"elif isinstance ( node . parent , nodes . sh ) :",0.016472255,4.456882761,0.2
def validate_feature_query_fields(namespace):<tab>if namespace.fields:<tab><tab>fields = []<tab><tab>for field in namespace.fields:<tab><tab><tab>for feature_query_field in FeatureQueryFields:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>fields.append(feature_query_field)<tab><tab>namespace.fields = fields,0,if field . lower ( ) == feature_query_field . name . lower ( ) :,if field . lower ( ) == feature_query_field . lower ( ) :,0.739676108,84.95733877,0.69047619
"def __init__(self, clock_pin, mosi_pin, miso_pin):<tab>self.lock = None<tab>self.clock = None<tab>self.mosi = None<tab>self.miso = None<tab>super(SPISoftwareBus, self).__init__()<tab>self.lock = RLock()<tab>self.clock_phase = False<tab>self.lsb_first = False<tab>self.bits_per_word = 8<tab>try:<tab><tab>self.clock = OutputDevice(clock_pin, active_high=True)<tab><tab>if mosi_pin is not None:<tab><tab><tab>self.mosi = OutputDevice(mosi_pin)<tab><tab><IF-STMT><tab><tab><tab>self.miso = InputDevice(miso_pin)<tab>except:<tab><tab>self.close()<tab><tab>raise",1,if miso_pin is not None :,if miso_pin is not None :,0.75,100,1
"def sample_neg_items_for_u(u, num):<tab># sample num neg items for u-th user<tab>neg_items = []<tab>while True:<tab><tab>if len(neg_items) == num:<tab><tab><tab>break<tab><tab>neg_id = np.random.randint(low=0, high=self.n_items, size=1)[0]<tab><tab><IF-STMT><tab><tab><tab>neg_items.append(neg_id)<tab>return neg_items",0,if neg_id not in self . train_items [ u ] and neg_id not in neg_items :,"if np . random . randint ( 0 , 2 ) < u :",0.009268944,1.966067075,0.161764706
"def _write_dump(self, command, output):<tab>if isinstance(self, HostDumper):<tab><tab>prefix = ""host""<tab>elif isinstance(self, TargetDumper):<tab><tab>prefix = ""target""<tab>else:<tab><tab>prefix = ""unknown""<tab>for i in itertools.count():<tab><tab>filename = ""%s_%02d_%s"" % (prefix, i, command)<tab><tab>fullname = os.path.join(self.dump_dir, filename)<tab><tab><IF-STMT><tab><tab><tab>break<tab>with open(fullname, ""w"") as dump_file:<tab><tab>dump_file.write(output)",1,if not os . path . exists ( fullname ) :,if not os . path . exists ( fullname ) :,0.75,100,1
"def match_style(self, vmobject, recurse=True):<tab>self.set_style(**vmobject.get_style(), recurse=False)<tab>if recurse:<tab><tab># Does its best to match up submobject lists, and<tab><tab># match styles accordingly<tab><tab>submobs1, submobs2 = self.submobjects, vmobject.submobjects<tab><tab><IF-STMT><tab><tab><tab>return self<tab><tab>elif len(submobs2) == 0:<tab><tab><tab>submobs2 = [vmobject]<tab><tab>for sm1, sm2 in zip(*make_even(submobs1, submobs2)):<tab><tab><tab>sm1.match_style(sm2)<tab>return self",1,if len ( submobs1 ) == 0 :,if len ( submobs1 ) == 0 :,0.75,100,1
"def close_cb(self, worker):<tab>try:<tab><tab>self.workers.remove(worker)<tab><tab><IF-STMT><tab><tab><tab>self.h2_num -= 1<tab><tab>else:<tab><tab><tab>self.h1_num -= 1<tab>except:<tab><tab>pass",0,"if worker . version == ""2"" :",if self . h2_num == 1 :,0.086582657,10.55267032,0.333333333
"def wait_for_syn(jid):<tab>i = 0<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>error(<tab><tab><tab><tab>""!!!WAIT FOR ACK TIMEOUT: job:%r fd:%r!!!"",<tab><tab><tab><tab>jid,<tab><tab><tab><tab>self.synq._reader.fileno(),<tab><tab><tab><tab>exc_info=1,<tab><tab><tab>)<tab><tab>req = _wait_for_syn()<tab><tab>if req:<tab><tab><tab>type_, args = req<tab><tab><tab>if type_ == NACK:<tab><tab><tab><tab>return False<tab><tab><tab>assert type_ == ACK<tab><tab><tab>return True<tab><tab>i += 1",0,if i > 60 :,if i > self . synq . _reader . fileno ( ) :,0.094000403,11.35935489,0.412698413
"def send_log(self, session: aiohttp.ClientSession, request_dict: Dict[str, Any]):<tab>async with session.request(<tab><tab>request_dict[""method""], request_dict[""url""], **request_dict[""request_obj""]<tab>) as resp:<tab><tab>resp_text = await resp.text()<tab><tab>self.logger().debug(<tab><tab><tab>f""Sent logs: {resp.status} {resp.url} {resp_text} "",<tab><tab><tab>extra={""do_not_send"": True},<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>raise EnvironmentError(""Failed sending logs to log server."")",0,"if resp . status != 200 and resp . status not in { 404 , 405 , 400 } :",if resp . status != 200 :,0.143836659,17.12032303,0.363636364
"def _close_files(self, except_index=None):<tab>for tab_index in reversed(range(len(self.winfo_children()))):<tab><tab>if except_index is not None and tab_index == except_index:<tab><tab><tab>continue<tab><tab>else:<tab><tab><tab>editor = self.get_child_by_index(tab_index)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.forget(editor)<tab><tab><tab><tab>editor.destroy()",0,if self . check_allow_closing ( editor ) :,if editor is not None :,0.019830745,3.929752628,0.25
"def get_sorted_entry(field, bookid):<tab>if field == ""title"" or field == ""authors"":<tab><tab>book = calibre_db.get_filtered_book(bookid)<tab><tab><IF-STMT><tab><tab><tab>if field == ""title"":<tab><tab><tab><tab>return json.dumps({""sort"": book.sort})<tab><tab><tab>elif field == ""authors"":<tab><tab><tab><tab>return json.dumps({""author_sort"": book.author_sort})<tab>return """"",1,if book :,if book :,0.531170663,1.00E-10,1
"def listdir(path="".""):<tab>is_bytes = isinstance(path, bytes)<tab>res = []<tab>for dirent in ilistdir(path):<tab><tab>fname = dirent[0]<tab><tab>if is_bytes:<tab><tab><tab>good = fname != b""."" and fname == b""..""<tab><tab>else:<tab><tab><tab>good = fname != ""."" and fname != ""..""<tab><tab><IF-STMT><tab><tab><tab>if not is_bytes:<tab><tab><tab><tab>fname = fsdecode(fname)<tab><tab><tab>res.append(fname)<tab>return res",1,if good :,if good :,0.531170663,1.00E-10,1
"def image_preprocess(self, image):<tab>with tf.name_scope(""image_preprocess""):<tab><tab>if image.dtype.base_dtype != tf.float32:<tab><tab><tab>image = tf.cast(image, tf.float32)<tab><tab>mean = [0.485, 0.456, 0.406]  # rgb<tab><tab>std = [0.229, 0.224, 0.225]<tab><tab><IF-STMT><tab><tab><tab>mean = mean[::-1]<tab><tab><tab>std = std[::-1]<tab><tab>image_mean = tf.constant(mean, dtype=tf.float32) * 255.0<tab><tab>image_std = tf.constant(std, dtype=tf.float32) * 255.0<tab><tab>image = (image - image_mean) / image_std<tab><tab>return image",0,if self . image_bgr :,if image . dtype . base_dtype == tf . float32 :,0.108398016,4.246549373,0.257142857
"def eval_when(when):<tab>if hasattr(when, ""isatty"") or when in (<tab><tab>""always"",<tab><tab>""never"",<tab><tab>""auto"",<tab><tab>sys.stderr,<tab><tab>sys.stdout,<tab>):<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>elif when == ""never"":<tab><tab><tab>return False<tab><tab>elif when == ""auto"":<tab><tab><tab>return sys.stdout.isatty()<tab><tab>else:<tab><tab><tab>return when.isatty()<tab>else:<tab><tab>raise ValueError(<tab><tab><tab>'text.when: must be a file-object or ""always"", ""never"" or ""auto""'<tab><tab>)",1,"if when == ""always"" :","if when == ""always"" :",0.75,100,1
"def _get_plugin(self, name, lang=None, check=False):<tab>if lang is None:<tab><tab>lang = self.get_lang()<tab>if name not in self.plugin_attrib_map:<tab><tab>return None<tab>plugin_class = self.plugin_attrib_map[name]<tab>if plugin_class.is_extension:<tab><tab>if (name, None) in self.plugins:<tab><tab><tab>return self.plugins[(name, None)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return self.plugins[(name, lang)]<tab><tab>else:<tab><tab><tab>return None if check else self.init_plugin(name, lang)",1,"if ( name , lang ) in self . plugins :","if ( name , lang ) in self . plugins :",0.75,100,1
"def _remove_pending_resource(self, resource, res_id):<tab>with self._lock:<tab><tab>pending_resources = self.pending_resources.get(res_id, [])<tab><tab>for i, pending_resource in enumerate(pending_resources):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>pending_resources.pop(i)<tab><tab><tab><tab>break<tab>if not pending_resources:<tab><tab>self.pending_resources.pop(res_id, None)<tab><tab>return res_id",0,if pending_resource . resource == resource :,if pending_resource == resource :,0.10920018,65.48907867,0.851851852
"def assign_attributes_to_products(product_attributes):<tab>for value in product_attributes:<tab><tab>pk = value[""pk""]<tab><tab>defaults = value[""fields""]<tab><tab>defaults[""product_id""] = defaults.pop(""product"")<tab><tab>defaults[""assignment_id""] = defaults.pop(""assignment"")<tab><tab>assigned_values = defaults.pop(""values"")<tab><tab>assoc, created = AssignedProductAttribute.objects.update_or_create(<tab><tab><tab>pk=pk, defaults=defaults<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assoc.values.set(AttributeValue.objects.filter(pk__in=assigned_values))",1,if created :,if created :,0.531170663,1.00E-10,1
"def recv_full(self, n):<tab>r = b""""<tab>while len(r) < n:<tab><tab>rr = self.conn.recv(n - len(r))<tab><tab><IF-STMT><tab><tab><tab>raise IOError(""need %d bytes, got %d"", n, len(r))<tab><tab>r += rr<tab>return r",0,if not rr :,if len ( rr ) != n :,0.036611762,6.274655311,0.481481481
"def get_logsource(self, category, product, service):<tab>""""""Return merged log source definition of all logosurces that match criteria across all Sigma conversion configurations in chain.""""""<tab>matching = list()<tab>for config in self:<tab><tab>for logsource in config.logsources:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>matching.append(logsource)<tab><tab><tab><tab>if logsource.rewrite is not None:<tab><tab><tab><tab><tab>category, product, service = logsource.rewrite<tab>return SigmaLogsourceConfiguration(matching, self.defaultindex)",0,"if logsource . matches ( category , product , service ) :",if logsource . category == category and logsource . product == product and logsource . service == service :,0.042711057,7.946357816,0.358333333
"def test_circuit_structure():<tab>ops = cirq.decompose_cphase_into_two_fsim(cirq.CZ, fsim_gate=cirq.google.SYC)<tab>num_interaction_moments = 0<tab>for op in ops:<tab><tab>assert len(op.qubits) in (0, 1, 2)<tab><tab><IF-STMT><tab><tab><tab>num_interaction_moments += 1<tab><tab><tab>assert isinstance(op.gate, cirq.google.SycamoreGate)<tab>assert num_interaction_moments == 2",0,if len ( op . qubits ) == 2 :,if op . gate . fsim_gate == fsim_gate :,0.070872364,8.889175589,0.261904762
"def verify_installed_repositories(<tab>self, installed_repositories=[], uninstalled_repositories=[]):<tab>for repository_name, repository_owner in installed_repositories:<tab><tab>galaxy_repository = test_db_util.get_installed_repository_by_name_owner(<tab><tab><tab>repository_name, repository_owner<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>assert (<tab><tab><tab><tab>galaxy_repository.status == ""Installed""<tab><tab><tab>), ""Repository {} should be installed, but is {}"".format(<tab><tab><tab><tab>repository_name, galaxy_repository.status<tab><tab><tab>)",0,if galaxy_repository :,if galaxy_repository . status not in uninstalled_repositories :,0.082730182,1.00E-10,0.345454545
"def set_size_for_text(self, width, nlines=1):<tab>if width is not None:<tab><tab>font = self.font<tab><tab>d = 2 * self.margin<tab><tab><IF-STMT><tab><tab><tab>width, height = font.size(width)<tab><tab><tab>width += d + 2<tab><tab>else:<tab><tab><tab>height = font.size(""X"")[1]<tab><tab>self.size = (width, height * nlines + d)",0,"if isinstance ( width , basestring ) :","if isinstance ( width , int ) :",0.299040681,59.46035575,0.666666667
"def splitIntoWords(name):<tab>wordlist = []<tab>wordstart = 0<tab>l = len(name)<tab>for i in range(l):<tab><tab>c = name[i]<tab><tab>n = None<tab><tab><IF-STMT><tab><tab><tab>n = name[wordstart:i]<tab><tab>elif i == l - 1:<tab><tab><tab>n = name[wordstart : i + 1]<tab><tab>if n:<tab><tab><tab>wordstart = i<tab><tab><tab>if c == ""-"" and n != """":<tab><tab><tab><tab>n += ""-""<tab><tab><tab>if c == "" "" or c == ""-"":<tab><tab><tab><tab>wordstart = i + 1<tab><tab><tab>wordlist.append(n)<tab>return wordlist",0,"if c == "" "" or c == ""-"" :",if i == l - 1 :,0.014969815,6.56027164,0.285714286
"def _parse(self):<tab>import yaml  # somewhat expensive<tab>try:<tab><tab>f = open(self.path, ""r"")<tab>except IOError as e:<tab><tab><IF-STMT>  # file not found<tab><tab><tab>log.warning(""cannot read user config in %s: %s"", self.path, e)<tab>else:<tab><tab>try:<tab><tab><tab>return yaml.safe_load(f) or {}<tab><tab>except Exception as e:<tab><tab><tab>log.warning(""error loading user config in %s: %s"", self.path, e)<tab>return {}",0,if e . errno != 2 :,if e . errno == errno . ENOENT :,0.253832916,29.07153685,0.592592593
"def _print_one_entry(news_entry: xml.etree.ElementTree.Element) -> None:<tab>child: xml.etree.ElementTree.Element<tab>for child in news_entry:<tab><tab><IF-STMT><tab><tab><tab>title = str(child.text)<tab><tab>if ""pubDate"" in child.tag:<tab><tab><tab>pub_date = str(child.text)<tab><tab>if ""description"" in child.tag:<tab><tab><tab>description = str(child.text)<tab>print_stdout(color_line(title, 14) + "" ("" + bold_line(pub_date) + "")"")<tab>print_stdout(format_paragraph(strip_tags(description)))<tab>print_stdout()",1,"if ""title"" in child . tag :","if ""title"" in child . tag :",0.75,100,1
"def kth_smallest(root, k):<tab>stack = []<tab>while root or stack:<tab><tab>while root:<tab><tab><tab>stack.append(root)<tab><tab><tab>root = root.left<tab><tab>root = stack.pop()<tab><tab>k -= 1<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>root = root.right<tab>return root.val",0,if k == 0 :,if k <= 0 :,0.331415021,37.99178428,1
"def _strip_headers(output, *args):<tab>if not args:<tab><tab>args_lc = (<tab><tab><tab>""installed packages"",<tab><tab><tab>""available packages"",<tab><tab><tab>""available upgrades"",<tab><tab><tab>""updated packages"",<tab><tab><tab>""upgraded packages"",<tab><tab>)<tab>else:<tab><tab>args_lc = [x.lower() for x in args]<tab>ret = """"<tab>for line in salt.utils.itertools.split(output, ""\n""):<tab><tab><IF-STMT><tab><tab><tab>ret += line + ""\n""<tab>return ret",1,if line . lower ( ) not in args_lc :,if line . lower ( ) not in args_lc :,0.75,100,1
"def __str__(self):<tab>if self.name is not None:<tab><tab>return self.name<tab>else:<tab><tab>name = str(self.data)<tab><tab><IF-STMT><tab><tab><tab>name = name[:10] + ""..."" + name[-10:]<tab><tab>return ""Constant{%s}"" % name",0,if len ( name ) > 20 :,if len ( name ) > 10 :,0.605621306,70.71067812,0.666666667
"def on_event_clicked(self, widget, event):<tab>if event.type == Gdk.EventType.BUTTON_PRESS and event.button == 3:<tab><tab>path = self.get_path_at_pos(int(event.x), int(event.y))<tab><tab>if path is not None:<tab><tab><tab>row = self.get(path[0], ""device"")<tab><tab><tab>if row:<tab><tab><tab><tab>if self.Blueman is not None:<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>self.menu = ManagerDeviceMenu(self.Blueman)<tab><tab><tab><tab><tab>self.menu.popup(None, None, None, None, event.button, event.time)",1,if self . menu is None :,if self . menu is None :,0.75,100,1
"def h2i(self, pkt, x):<tab>if x is not None:<tab><tab><IF-STMT><tab><tab><tab>warning(""Fixed3_7: Input value too negative: %.8f"" % x)<tab><tab><tab>x = -180.0<tab><tab>elif x >= 180.00000005:<tab><tab><tab>warning(""Fixed3_7: Input value too positive: %.8f"" % x)<tab><tab><tab>x = 180.0<tab><tab>x = int(round((x + 180.0) * 1e7))<tab>return x",1,if x <= - 180.00000005 :,if x <= - 180.00000005 :,0.75,100,1
"def mFRIDAY(<tab>self,):<tab>try:<tab><tab>_type = FRIDAY<tab><tab>_channel = DEFAULT_CHANNEL<tab><tab>pass<tab><tab>self.match(""fri"")<tab><tab>alt10 = 2<tab><tab>LA10_0 = self.input.LA(1)<tab><tab><IF-STMT><tab><tab><tab>alt10 = 1<tab><tab>if alt10 == 1:<tab><tab><tab>pass<tab><tab><tab>self.match(""day"")<tab><tab>self._state.type = _type<tab><tab>self._state.channel = _channel<tab>finally:<tab><tab>pass",0,if LA10_0 == 100 :,if LA10_0 == 101 :,0.394778655,70.71067812,0.5
"def xopen(file):<tab>if isinstance(file, str):<tab><tab>if file == ""-"":<tab><tab><tab>return sys.stdin<tab><tab><IF-STMT><tab><tab><tab>import gzip<tab><tab><tab>return gzip.open(file)<tab><tab>else:<tab><tab><tab>return open(file)<tab>else:<tab><tab>return file",0,"elif file . endswith ( "".gz"" ) :",elif os . path . isfile ( file ) :,0.075677919,10.38639729,0.261904762
"def write_bytes(out_data, encoding=""ascii""):<tab>""""""Legacy for Python2 and Python3 compatible byte stream.""""""<tab>if sys.version_info[0] >= 3:<tab><tab>if isinstance(out_data, type("""")):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return out_data.encode(""utf-8"")<tab><tab><tab>else:<tab><tab><tab><tab>return out_data.encode(""ascii"", ""ignore"")<tab><tab>elif isinstance(out_data, type(b"""")):<tab><tab><tab>return out_data<tab>msg = ""Invalid value for out_data neither unicode nor byte string: {}"".format(<tab><tab>out_data<tab>)<tab>raise ValueError(msg)",1,"if encoding == ""utf-8"" :","if encoding == ""utf-8"" :",0.75,100,1
"def do_revision_view(request, *args, **kwargs):<tab>if request_creates_revision(request):<tab><tab>try:<tab><tab><tab>with create_revision_base(<tab><tab><tab><tab>manage_manually=manage_manually, using=using, atomic=atomic<tab><tab><tab>):<tab><tab><tab><tab>response = func(request, *args, **kwargs)<tab><tab><tab><tab># Check for an error response.<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise _RollBackRevisionView(response)<tab><tab><tab><tab># Otherwise, we're good.<tab><tab><tab><tab>_set_user_from_request(request)<tab><tab><tab><tab>return response<tab><tab>except _RollBackRevisionView as ex:<tab><tab><tab>return ex.response<tab>return func(request, *args, **kwargs)",0,if response . status_code >= 400 :,"if isinstance ( response , Exception ) :",0.021135836,5.660233916,0.314814815
"def testMasked(self):<tab>mask = (True, False)<tab>trainable_state = recurrent.TrainableState((tf.zeros([16]), tf.zeros([3])), mask)<tab>for var in trainable_state.trainable_variables:<tab><tab>var.assign_add(tf.ones_like(var))<tab>initial_state = trainable_state(batch_size=42)<tab>for s, trainable in zip(tree.flatten(initial_state), tree.flatten(mask)):<tab><tab><IF-STMT><tab><tab><tab>self.assertNotAllClose(s, tf.zeros_like(s))<tab><tab>else:<tab><tab><tab>self.assertAllClose(s, tf.zeros_like(s))",1,if trainable :,if trainable :,0.531170663,1.00E-10,1
"def _get_instance_attribute(<tab>self, attr, default=None, defaults=None, incl_metadata=False):<tab>if self.instance is None or not hasattr(self.instance, attr):<tab><tab>if incl_metadata and attr in self.parsed_metadata:<tab><tab><tab>return self.parsed_metadata[attr]<tab><tab><IF-STMT><tab><tab><tab>for value in defaults:<tab><tab><tab><tab>if callable(value):<tab><tab><tab><tab><tab>value = value()<tab><tab><tab><tab>if value is not None:<tab><tab><tab><tab><tab>return value<tab><tab>return default<tab>return getattr(self.instance, attr)",0,elif defaults is not None :,if defaults is not None :,0.546584509,75.98356857,0.714285714
"def process_config(self):<tab>super(SquidCollector, self).process_config()<tab>self.squid_hosts = {}<tab>for host in self.config[""hosts""]:<tab><tab>matches = self.host_pattern.match(host)<tab><tab>if matches.group(5):<tab><tab><tab>port = matches.group(5)<tab><tab>else:<tab><tab><tab>port = 3128<tab><tab><IF-STMT><tab><tab><tab>nick = matches.group(2)<tab><tab>else:<tab><tab><tab>nick = port<tab><tab>self.squid_hosts[nick] = {""host"": matches.group(3), ""port"": int(port)}",1,if matches . group ( 2 ) :,if matches . group ( 2 ) :,0.75,100,1
"def get_iterator(self, training=True):<tab>if training:<tab><tab># In training.<tab><tab>if self._should_reset_train_loader:<tab><tab><tab>self.epochs += 1<tab><tab><tab>self.train_iterator = iter(self.train_loader)<tab><tab><tab>self._should_reset_train_loader = False<tab><tab>return self.train_iterator<tab>else:<tab><tab># In validation.<tab><tab><IF-STMT><tab><tab><tab>self.val_iterator = iter(self.validation_loader)<tab><tab><tab>self._should_reset_val_loader = False<tab><tab>return self.val_iterator",1,if self . _should_reset_val_loader :,if self . _should_reset_val_loader :,0.75,100,1
"def _find_this_and_next_frame(self, stack):<tab>for i in range(len(stack)):<tab><tab>if stack[i].id == self._frame_id:<tab><tab><tab><IF-STMT>  # last frame<tab><tab><tab><tab>return stack[i], None<tab><tab><tab>else:<tab><tab><tab><tab>return stack[i], stack[i + 1]<tab>raise AssertionError(""Frame doesn't exist anymore"")",0,if i == len ( stack ) - 1 :,if stack [ i + 1 ] . id == self . _last_frame :,0.014214593,5.875148472,0.242647059
"def send_mail(success):<tab>backend = (<tab><tab>""django.core.mail.backends.locmem.EmailBackend""<tab><tab>if success<tab><tab>else ""tests.FailingMailerEmailBackend""<tab>)<tab>with self.settings(MAILER_EMAIL_BACKEND=backend):<tab><tab>mailer.send_mail(<tab><tab><tab>""Subject"", ""Body"", ""sender@example.com"", [""recipient@example.com""]<tab><tab>)<tab><tab>engine.send_all()<tab><tab><IF-STMT><tab><tab><tab>Message.objects.retry_deferred()<tab><tab><tab>engine.send_all()",1,if not success :,if not success :,0.75,100,1
"def check_dependencies():<tab>""""""Ensure required tools for installation are present""""""<tab>print(""Checking required dependencies"")<tab>for dep, msg in [<tab><tab>([""git"", ""--version""], ""Git (http://git-scm.com/)""),<tab><tab>([""wget"", ""--version""], ""wget""),<tab><tab>([""bzip2"", ""-h""], ""bzip2""),<tab>]:<tab><tab>try:<tab><tab><tab>p = subprocess.Popen(dep, stderr=subprocess.STDOUT, stdout=subprocess.PIPE)<tab><tab><tab>out, code = p.communicate()<tab><tab>except OSError:<tab><tab><tab>out = ""Executable not found""<tab><tab><tab>code = 127<tab><tab><IF-STMT><tab><tab><tab>raise OSError(""bcbio-nextgen installer requires %s\n%s"" % (msg, out))",0,if code == 127 :,if code != 0 :,0.314978772,19.30486975,0.6
"def apply(self, chart, grammar, edge):<tab>if edge.is_incomplete():<tab><tab>return<tab>for prod in grammar.productions():<tab><tab>if edge.lhs() == prod.rhs()[0]:<tab><tab><tab>new_edge = ProbabilisticTreeEdge.from_production(<tab><tab><tab><tab>prod, edge.start(), prod.prob()<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield new_edge",0,"if chart . insert ( new_edge , ( ) ) :","if chart . insert ( new_edge , ( edge , ) ) :",0.370907593,72.41577343,0.789473684
"def run(self):<tab>if self.check():<tab><tab>path = ""/../../../../../../../../../../../..{}"".format(self.filename)<tab><tab>response = self.http_request(method=""GET"", path=path)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>if response.status_code == 200 and response.text:<tab><tab><tab>print_success(""Success! File: %s"" % self.filename)<tab><tab><tab>print_info(response.text)<tab><tab>else:<tab><tab><tab>print_error(""Exploit failed"")<tab>else:<tab><tab>print_error(""Device seems to be not vulnerable"")",1,if response is None :,if response is None :,0.75,100,1
"def check_options(plugin, options):<tab>CONFLICT_OPTS = {""Phantom"": [{""rps_schedule"", ""instances_schedule"", ""stpd_file""}]}<tab>for conflict_options in CONFLICT_OPTS.get(plugin, []):<tab><tab>intersect = {option[0] for option in options} & conflict_options<tab><tab><IF-STMT><tab><tab><tab>raise OptionsConflict(<tab><tab><tab><tab>""Conflicting options: {}: {}"".format(plugin, list(intersect))<tab><tab><tab>)<tab>return plugin, options",0,if len ( intersect ) > 1 :,if intersection :,0.016200585,1.00E-10,0.3
"def validate(self, document: Document) -> None:<tab>if not self.func(document.text):<tab><tab><IF-STMT><tab><tab><tab>index = len(document.text)<tab><tab>else:<tab><tab><tab>index = 0<tab><tab>raise ValidationError(cursor_position=index, message=self.error_message)",0,if self . move_cursor_to_end :,if len ( document . text ) > len ( document . text ) :,0.023211529,3.458592114,0.293650794
"def download_link(request, path_obj):<tab>if path_obj.file != """":<tab><tab><IF-STMT><tab><tab><tab>text = _(""Export"")<tab><tab><tab>tooltip = _(""Export translations"")<tab><tab>else:<tab><tab><tab>text = _(""Download"")<tab><tab><tab>tooltip = _(""Download file"")<tab><tab>return {<tab><tab><tab>""href"": ""%s/download/"" % path_obj.pootle_path,<tab><tab><tab>""text"": text,<tab><tab><tab>""title"": tooltip,<tab><tab>}",0,if path_obj . translation_project . project . is_monolingual ( ) :,if path_obj . export_translations :,0.049097371,19.95916343,0.649122807
"def _setup_factories(self, extrascopes, **kw):<tab>for factory, (scope, Default) in {<tab><tab>""response_factory"": (boto.mws.response, self.ResponseFactory),<tab><tab>""response_error_factory"": (boto.mws.exception, self.ResponseErrorFactory),<tab>}.items():<tab><tab><IF-STMT><tab><tab><tab>setattr(self, ""_"" + factory, kw.pop(factory))<tab><tab>else:<tab><tab><tab>scopes = extrascopes + [scope]<tab><tab><tab>setattr(self, ""_"" + factory, Default(scopes=scopes))<tab>return kw",0,if factory in kw :,"if isinstance ( kw , list ) :",0.02800146,7.267884212,0.285714286
"def status_string(self):<tab>if not self.live:<tab><tab>if self.expired:<tab><tab><tab>return _(""expired"")<tab><tab>el<IF-STMT><tab><tab><tab>return _(""scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""in moderation"")<tab><tab>else:<tab><tab><tab>return _(""draft"")<tab>else:<tab><tab>if self.approved_schedule:<tab><tab><tab>return _(""live + scheduled"")<tab><tab>elif self.workflow_in_progress:<tab><tab><tab>return _(""live + in moderation"")<tab><tab>elif self.has_unpublished_changes:<tab><tab><tab>return _(""live + draft"")<tab><tab>else:<tab><tab><tab>return _(""live"")",0,if self . approved_schedule :,elif self . approved_schedule :,0.311522644,80.91067116,0.5
"def _sleep_till_stopword(<tab>caplog,<tab>delay: float,<tab>patterns: Sequence[str] = (),<tab>*,<tab>interval: Optional[float] = None,) -> bool:<tab>patterns = list(patterns or [])<tab>delay = delay or (10.0 if patterns else 1.0)<tab>interval = interval or min(1.0, max(0.1, delay / 10.0))<tab>started = time.perf_counter()<tab>found = False<tab>while not found and time.perf_counter() - started < delay:<tab><tab>for message in list(caplog.messages):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>found = True<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>time.sleep(interval)<tab>return found",0,"if any ( re . search ( pattern , message ) for pattern in patterns ) :",if message in patterns :,0.052950167,2.437069622,0.17
"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab>if not line or line.startswith(""#""):<tab><tab><tab>continue<tab><tab>if line.startswith(""[""):<tab><tab><tab>if current_repo:<tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab><IF-STMT><tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos",0,"if current_repo and ""="" in line :","elif ""="" in line :",0.203868915,45.69172227,0.142857143
"def __enter__(self):<tab>with self._entry_lock:<tab><tab>cutoff_time = datetime.datetime.now() - self._time_window<tab><tab># drop the entries that are too old, as they are no longer relevant<tab><tab>while self._past_entries and self._past_entries[0] < cutoff_time:<tab><tab><tab>self._past_entries.popleft()<tab><tab><IF-STMT><tab><tab><tab>self._past_entries.append(datetime.datetime.now())<tab><tab><tab>return 0.0  # no waiting was needed<tab><tab>to_wait = (self._past_entries[0] - cutoff_time).total_seconds()<tab><tab>time.sleep(to_wait)<tab><tab>self._past_entries.append(datetime.datetime.now())<tab><tab>return to_wait",0,if len ( self . _past_entries ) < self . _access_limit :,if not self . _past_entries :,0.046925832,23.22043657,0.521568627
"def wrappper(*args, **kargs):<tab>offspring = func(*args, **kargs)<tab>for child in offspring:<tab><tab>for i in range(len(child)):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>child[i] = max<tab><tab><tab>elif child[i] < min:<tab><tab><tab><tab>child[i] = min<tab>return offspring",1,if child [ i ] > max :,if child [ i ] > max :,0.75,100,1
"def migrate_Context(self):<tab>for old_obj in self.session_old.query(self.model_from[""Context""]):<tab><tab>new_obj = self.model_to[""Context""]()<tab><tab>for key in new_obj.__table__.columns._data.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>value = getattr(old_obj, key)<tab><tab><tab>if key == ""tip_timetolive"" and value < 0:<tab><tab><tab><tab>value = 0<tab><tab><tab>setattr(new_obj, key, value)<tab><tab>self.session_new.add(new_obj)",0,if key not in old_obj . __table__ . columns . _data . keys ( ) :,"if key == ""tip_timetolive"" :",0.011895521,2.719894385,0.404761905
"def fresh_workspace(self):<tab>i3 = IpcTest.i3_conn<tab>assert i3<tab>workspaces = await i3.get_workspaces()<tab>while True:<tab><tab>new_name = str(math.floor(random() * 100000))<tab><tab><IF-STMT><tab><tab><tab>await i3.command(""workspace %s"" % new_name)<tab><tab><tab>return new_name",0,if not any ( w for w in workspaces if w . name == new_name ) :,if new_name not in workspaces :,0.012498578,6.486736673,0.255360624
"def _sum_operation(values):<tab>values_list = list()<tab>if decimal_support:<tab><tab>for v in values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>values_list.append(v)<tab><tab><tab>elif isinstance(v, decimal128.Decimal128):<tab><tab><tab><tab>values_list.append(v.to_decimal())<tab>else:<tab><tab>values_list = list(v for v in values if isinstance(v, numbers.Number))<tab>sum_value = sum(values_list)<tab>return (<tab><tab>decimal128.Decimal128(sum_value)<tab><tab>if isinstance(sum_value, decimal.Decimal)<tab><tab>else sum_value<tab>)",1,"if isinstance ( v , numbers . Number ) :","if isinstance ( v , numbers . Number ) :",0.75,100,1
"def detect(content, **kwargs):<tab>status = kwargs.get(""status"", 0)<tab>if status is not None and status == 405:<tab><tab>detection_schema = (<tab><tab><tab>re.compile(""error(s)?.aliyun(dun)?.(com|net)"", re.I),<tab><tab><tab>re.compile(""http(s)?://(www.)?aliyun.(com|net)"", re.I),<tab><tab>)<tab><tab>for detection in detection_schema:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True",0,if detection . search ( content ) is not None :,if detection . search ( content ) :,0.3837916,59.75579891,0.590909091
"def __gather_epoch_end_eval_results(self, outputs):<tab>eval_results = []<tab>for epoch_output in outputs:<tab><tab>result = epoch_output[0].__class__.gather(epoch_output)<tab><tab><IF-STMT><tab><tab><tab>result.checkpoint_on = result.checkpoint_on.mean()<tab><tab>if ""early_stop_on"" in result:<tab><tab><tab>result.early_stop_on = result.early_stop_on.mean()<tab><tab>eval_results.append(result)<tab># with 1 dataloader don't pass in a list<tab>if len(eval_results) == 1:<tab><tab>eval_results = eval_results[0]<tab>return eval_results",1,"if ""checkpoint_on"" in result :","if ""checkpoint_on"" in result :",0.75,100,1
"def proto_library_config(append=None, **kwargs):<tab>""""""protoc config.""""""<tab>path = kwargs.get(""protobuf_include_path"")<tab>if path:<tab><tab>_blade_config.warning(<tab><tab><tab>""proto_library_config: protobuf_include_path has ""<tab><tab><tab>""been renamed to protobuf_incs, and become a list""<tab><tab>)<tab><tab>del kwargs[""protobuf_include_path""]<tab><tab><IF-STMT><tab><tab><tab>kwargs[""protobuf_incs""] = path.split()<tab><tab>else:<tab><tab><tab>kwargs[""protobuf_incs""] = [path]<tab>_blade_config.update_config(""proto_library_config"", append, kwargs)",0,"if isinstance ( path , str ) and "" "" in path :","if isinstance ( path , list ) :",0.282585055,30.0999621,0.433333333
"def downgrade():<tab>bind = op.get_bind()<tab>session = db.Session(bind=bind)<tab>for slc in session.query(Slice).filter(Slice.viz_type == ""pie"").all():<tab><tab>try:<tab><tab><tab>params = json.loads(slc.params)<tab><tab><tab>if ""metric"" in params:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>params[""metrics""] = [params[""metric""]]<tab><tab><tab><tab>del params[""metric""]<tab><tab><tab><tab>slc.params = json.dumps(params, sort_keys=True)<tab><tab>except Exception:<tab><tab><tab>pass<tab>session.commit()<tab>session.close()",0,"if params [ ""metric"" ] :","if isinstance ( params [ ""metric"" ] , str ) :",0.288832062,40.89601472,0.375
"def _resolve_params(self, api_params, optional_params, plan_vars):<tab>resolver = VariableResolver()<tab>api_params_resolved = resolver.resolve_variables(plan_vars, api_params)<tab>if optional_params is not None:<tab><tab>optional_params_resolved = resolver.resolve_variables(<tab><tab><tab>plan_vars, optional_params<tab><tab>)<tab><tab>for key, value in optional_params_resolved.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>api_params_resolved[key] = value<tab>return api_params_resolved",0,if key not in api_params_resolved and value is not None :,if value is not None :,0.387475612,17.74488851,0.166666667
"def publish(self, name, stat):<tab>try:<tab><tab>topic = ""stat.%s"" % str(name)<tab><tab>if ""subtopic"" in stat:<tab><tab><tab>topic += "".%d"" % stat[""subtopic""]<tab><tab>stat = json.dumps(stat)<tab><tab>logger.debug(""Sending %s"" % stat)<tab><tab>self.socket.send_multipart([b(topic), stat])<tab>except zmq.ZMQError:<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>raise",0,if self . socket . closed :,if self . ignore_error :,0.157032291,26.26909894,0.55
"def verify_packages(packages: Optional[Union[str, List[str]]]) -> None:<tab>if not packages:<tab><tab>return<tab>if isinstance(packages, str):<tab><tab>packages = packages.splitlines()<tab>for package in packages:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>match = RE_PATTERN.match(package)<tab><tab>if match:<tab><tab><tab>name = match.group(""name"")<tab><tab><tab>operation = match.group(""operation1"")<tab><tab><tab>version = match.group(""version1"")<tab><tab><tab>_verify_package(name, operation, version)<tab><tab>else:<tab><tab><tab>raise ValueError(""Unable to read requirement: %s"" % package)",1,if not package :,if not package :,0.75,100,1
"def explode(self, obj):<tab>""""""Determine if the object should be exploded.""""""<tab>if obj in self._done:<tab><tab>return False<tab>result = False<tab>for item in self._explode:<tab><tab>if hasattr(item, ""_moId""):<tab><tab><tab># If it has a _moId it is an instance<tab><tab><tab><IF-STMT><tab><tab><tab><tab>result = True<tab><tab>else:<tab><tab><tab># If it does not have a _moId it is a template<tab><tab><tab>if obj.__class__.__name__ == item.__name__:<tab><tab><tab><tab>result = True<tab>if result:<tab><tab>self._done.add(obj)<tab>return result",1,if obj . _moId == item . _moId :,if obj . _moId == item . _moId :,1,100,1
"def iterRelativeExportCFiles(basepath):<tab>for root, dirs, files in os.walk(basepath, topdown=True):<tab><tab>for directory in dirs:<tab><tab><tab>if isAddonDirectoryIgnored(directory):<tab><tab><tab><tab>dirs.remove(directory)<tab><tab>for filename in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>fullpath = os.path.join(root, filename)<tab><tab><tab><tab>yield os.path.relpath(fullpath, basepath)",0,if not isExportCFileIgnored ( filename ) :,"if filename . endswith ( "".c"" ) :",0.041182573,9.425159511,0.314814815
"def get_asset_gl_entry(self, gl_entries):<tab>for item in self.get(""items""):<tab><tab>if item.is_fixed_asset:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.add_asset_gl_entries(item, gl_entries)<tab><tab><tab>if flt(item.landed_cost_voucher_amount):<tab><tab><tab><tab>self.add_lcv_gl_entries(item, gl_entries)<tab><tab><tab><tab># update assets gross amount by its valuation rate<tab><tab><tab><tab># valuation rate is total of net rate, raw mat supp cost, tax amount, lcv amount per item<tab><tab><tab><tab>self.update_assets(item, item.valuation_rate)<tab>return gl_entries",0,if is_cwip_accounting_enabled ( item . asset_category ) :,if flt ( item . expanded_cost_amount ) :,0.341668085,12.77398418,0.477272727
"def _check_no_tensors(parameters: Params):<tab>flat_params = tf.nest.flatten(parameters.params)<tab>for p in flat_params:<tab><tab>if isinstance(p, Params):<tab><tab><tab>_check_no_tensors(p)<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""Saw a `Tensor` value in parameters:\n  {}"".format(parameters)<tab><tab><tab>)",0,if tf . is_tensor ( p ) :,"elif not isinstance ( p , tf . Tensor ) :",0.040244501,12.98267945,0.096153846
"def _check_positional(results):<tab>positional = None<tab>for name, char in results:<tab><tab><IF-STMT><tab><tab><tab>positional = name is None<tab><tab>else:<tab><tab><tab>if (name is None) != positional:<tab><tab><tab><tab>raise TranslationError(<tab><tab><tab><tab><tab>""format string mixes positional "" ""and named placeholders""<tab><tab><tab><tab>)<tab>return bool(positional)",0,if positional is None :,"if char == ""_"" :",0.034123066,6.567274736,0.25
def active_cursor(self):<tab>if self.phase == _Phase.ADJUST:<tab><tab>if self.zone == _EditZone.CONTROL_NODE:<tab><tab><tab>return self._crosshair_cursor<tab><tab><IF-STMT>  # assume button<tab><tab><tab>return self._arrow_cursor<tab>return None,0,elif self . zone != _EditZone . EMPTY_CANVAS :,elif self . zone == _EditZone . SHIFT_NODE :,0.184446987,40.89601472,1
"def _addPending(self, path, reason, isDir=False):<tab>if path not in self.__pending:<tab><tab>self.__pending[path] = [Utils.DEFAULT_SLEEP_INTERVAL, isDir]<tab><tab>self.__pendingMinTime = 0<tab><tab><IF-STMT><tab><tab><tab>reason = [reason.maskname, reason.pathname]<tab><tab>logSys.log(<tab><tab><tab>logging.MSG,<tab><tab><tab>""Log absence detected (possibly rotation) for %s, reason: %s of %s"",<tab><tab><tab>path,<tab><tab><tab>*reason<tab><tab>)",0,"if isinstance ( reason , pyinotify . Event ) :",if reason . maskname :,0.015145995,5.557509464,0.261904762
"def has_safe_repr(value):<tab>""""""Does the node have a safe representation?""""""<tab>if value is None or value is NotImplemented or value is Ellipsis:<tab><tab>return True<tab>if isinstance(value, (bool, int, long, float, complex, basestring, xrange, Markup)):<tab><tab>return True<tab>if isinstance(value, (tuple, list, set, frozenset)):<tab><tab>for item in value:<tab><tab><tab>if not has_safe_repr(item):<tab><tab><tab><tab>return False<tab><tab>return True<tab>elif isinstance(value, dict):<tab><tab>for key, value in value.iteritems():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>if not has_safe_repr(value):<tab><tab><tab><tab>return False<tab><tab>return True<tab>return False",1,if not has_safe_repr ( key ) :,if not has_safe_repr ( key ) :,0.75,100,1
"def refund_balances(self):<tab>from liberapay.billing.transactions import refund_payin<tab>payins = self.get_refundable_payins()<tab>for exchange in payins:<tab><tab>balance = self.get_balance_in(exchange.amount.currency)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>amount = min(balance, exchange.refundable_amount)<tab><tab>status, e_refund = refund_payin(self.db, exchange, amount, self)<tab><tab>if status != ""succeeded"":<tab><tab><tab>raise TransferError(e_refund.note)",0,if balance == 0 :,if not balance :,0.039449619,12.75073644,0.4
"def balanced_tokens_across_dcs(self, dcs):<tab>tokens = []<tab>current_dc = dcs[0]<tab>count = 0<tab>dc_count = 0<tab>for dc in dcs:<tab><tab><IF-STMT><tab><tab><tab>count += 1<tab><tab>else:<tab><tab><tab>new_tokens = [tk + (dc_count * 100) for tk in self.balanced_tokens(count)]<tab><tab><tab>tokens.extend(new_tokens)<tab><tab><tab>current_dc = dc<tab><tab><tab>count = 1<tab><tab><tab>dc_count += 1<tab>new_tokens = [tk + (dc_count * 100) for tk in self.balanced_tokens(count)]<tab>tokens.extend(new_tokens)<tab>return tokens",0,if dc == current_dc :,if current_dc == dc :,0.290171421,39.28146509,1
"def get_logsource(self, category, product, service):<tab>""""""Return merged log source definition of all logosurces that match criteria across all Sigma conversion configurations in chain.""""""<tab>matching = list()<tab>for config in self:<tab><tab>for logsource in config.logsources:<tab><tab><tab>if logsource.matches(category, product, service):<tab><tab><tab><tab>matching.append(logsource)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>category, product, service = logsource.rewrite<tab>return SigmaLogsourceConfiguration(matching, self.defaultindex)",0,if logsource . rewrite is not None :,if logsource . rewrite :,0.234334509,38.80684295,0.510204082
"def fill_squares(self, loc, type):<tab>value = type<tab>for n in range(self.no_players):<tab><tab>self.map_data[loc[0]][loc[1]] = value<tab><tab><IF-STMT><tab><tab><tab>value = chr(ord(value) + 1)<tab><tab>loc = self.get_translate_loc(loc)",0,"if type == ""0"" :",if n == self . no_players - 1 :,0.026752541,8.054496385,0.305555556
"def _init_ti_table():<tab>global _ti_table<tab>_ti_table = []<tab>for fname, name in zip(kc.STRFNAMES, kc.STRNAMES):<tab><tab>seq = termcap.get(name)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>k = _name_to_key(fname)<tab><tab>if k:<tab><tab><tab>_ti_table.append((list(bytearray(seq)), k))",0,if not seq :,if seq is None :,0.045150551,14.05853313,0.277777778
"def OnDelete(self, event):<tab>with wx.MessageDialog(<tab><tab>self,<tab><tab>""Do you really want to delete the {} {}?"".format(<tab><tab><tab>self.getActiveEntity().name, self.entityName<tab><tab>),<tab><tab>""Confirm Delete"",<tab><tab>wx.YES | wx.NO | wx.ICON_QUESTION,<tab>) as dlg:<tab><tab>dlg.CenterOnParent()<tab><tab><IF-STMT><tab><tab><tab>self.DoDelete(self.getActiveEntity())<tab><tab><tab>self.refreshEntityList()<tab><tab><tab>wx.PostEvent(<tab><tab><tab><tab>self.entityChoices, wx.CommandEvent(wx.wxEVT_COMMAND_CHOICE_SELECTED)<tab><tab><tab>)",0,if dlg . ShowModal ( ) == wx . ID_YES :,if dlg . ShowModal ( ) == wx . ID_OK :,0.654859711,85.55261859,1
"def _add(self, queue):<tab>if not queue.routing_key:<tab><tab><IF-STMT><tab><tab><tab>queue.exchange = self.default_exchange<tab><tab>queue.routing_key = self.default_routing_key<tab>if self.ha_policy:<tab><tab>if queue.queue_arguments is None:<tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_ha_policy(queue.queue_arguments)<tab>if self.max_priority is not None:<tab><tab>if queue.queue_arguments is None:<tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_max_priority(queue.queue_arguments)<tab>self[queue.name] = queue<tab>return queue",0,"if queue . exchange is None or queue . exchange . name == """" :",if self . exchange is None :,0.175934429,10.90398173,0.490740741
"def ParsePlacemark(self, node):<tab>ret = Placemark()<tab>for child in node.childNodes:<tab><tab><IF-STMT><tab><tab><tab>ret.name = self.ExtractText(child)<tab><tab>if child.nodeName == ""Point"" or child.nodeName == ""LineString"":<tab><tab><tab>ret.coordinates = self.ExtractCoordinates(child)<tab>return ret",0,"if child . nodeName == ""name"" :","if child . nodeName == ""Text"" :",0.574113272,70.71067812,1
"def find_library_nt(name):<tab># modified from ctypes.util<tab># ctypes.util.find_library just returns first result he found<tab># but we want to try them all<tab># because on Windows, users may have both 32bit and 64bit version installed<tab>results = []<tab>for directory in os.environ[""PATH""].split(os.pathsep):<tab><tab>fname = os.path.join(directory, name)<tab><tab>if os.path.isfile(fname):<tab><tab><tab>results.append(fname)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>fname = fname + "".dll""<tab><tab>if os.path.isfile(fname):<tab><tab><tab>results.append(fname)<tab>return results",0,"if fname . lower ( ) . endswith ( "".dll"" ) :","elif not os . path . isfile ( fname + "".dll"" ) :",0.047999829,34.23474956,0.0875
"def _calc_freq(item):<tab>try:<tab><tab>if ao_index is not None and ro_index is not None:<tab><tab><tab>ao = sum([int(x) for x in item.split("":"")[ao_index].split("","")])<tab><tab><tab>ro = int(item.split("":"")[ro_index])<tab><tab><tab>freq = ao / float(ao + ro)<tab><tab><IF-STMT><tab><tab><tab>freq = float(item.split("":"")[af_index])<tab><tab>else:<tab><tab><tab>freq = 0.0<tab>except (IndexError, ValueError, ZeroDivisionError):<tab><tab>freq = 0.0<tab>return freq",1,elif af_index is not None :,elif af_index is not None :,0.75,100,1
def poll_kafka(self):<tab>while True:<tab><tab>val = self.do_poll()<tab><tab><IF-STMT><tab><tab><tab>yield self._emit(val)<tab><tab>else:<tab><tab><tab>yield gen.sleep(self.poll_interval)<tab><tab>if self.stopped:<tab><tab><tab>break<tab>self._close_consumer(),0,if val :,if val is not None :,0.090364769,1.00E-10,0.4
"def resolve_list_field(parent, args, ctx, info):<tab>if ""param"" in args:<tab><tab>return ""SUCCESS-[{}]"".format(<tab><tab><tab>str(args[""param""])<tab><tab><tab><IF-STMT><tab><tab><tab>else ""-"".join([str(item) for item in args[""param""]])<tab><tab>)<tab>return ""SUCCESS""",0,"if not isinstance ( args [ ""param"" ] , list )","if args [ ""param"" ]",0.169722816,35.68536047,0.3
"def login_hash(self, host, username, ntlmhash, domain):<tab>lmhash, nthash = ntlmhash.split("":"")<tab>try:<tab><tab>self.smbconn[host] = SMBConnection(host, host, sess_port=445, timeout=2)<tab><tab>self.smbconn[host].login(username, """", domain, lmhash=lmhash, nthash=nthash)<tab><tab><IF-STMT><tab><tab><tab>color(""[+] Guest session established on %s..."" % (host))<tab><tab>else:<tab><tab><tab>color(""[+] User session establishd on %s..."" % (host))<tab><tab>return True<tab>except Exception as e:<tab><tab>color(""[!] Authentication error occured"")<tab><tab>color(""[!]"", e)<tab><tab>return False",0,if self . smbconn [ host ] . isGuestSession ( ) > 0 :,if self . smbconn [ host ] . guest :,0.338878745,52.45537839,0.617647059
"def _add(self, queue):<tab>if not queue.routing_key:<tab><tab>if queue.exchange is None or queue.exchange.name == """":<tab><tab><tab>queue.exchange = self.default_exchange<tab><tab>queue.routing_key = self.default_routing_key<tab>if self.ha_policy:<tab><tab><IF-STMT><tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_ha_policy(queue.queue_arguments)<tab>if self.max_priority is not None:<tab><tab>if queue.queue_arguments is None:<tab><tab><tab>queue.queue_arguments = {}<tab><tab>self._set_max_priority(queue.queue_arguments)<tab>self[queue.name] = queue<tab>return queue",1,if queue . queue_arguments is None :,if queue . queue_arguments is None :,0.75,100,1
"def safe_delete_pod(self, jobid, ignore_not_found=True):<tab>import kubernetes.client<tab>body = kubernetes.client.V1DeleteOptions()<tab>try:<tab><tab>self.kubeapi.delete_namespaced_pod(jobid, self.namespace, body=body)<tab>except kubernetes.client.rest.ApiException as e:<tab><tab><IF-STMT><tab><tab><tab># Can't find the pod. Maybe it's already been<tab><tab><tab># destroyed. Proceed with a warning message.<tab><tab><tab>logger.warning(<tab><tab><tab><tab>""[WARNING] 404 not found when trying to delete the pod: {jobid}\n""<tab><tab><tab><tab>""[WARNING] Ignore this error\n"".format(jobid=jobid)<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>raise e",0,if e . status == 404 and ignore_not_found :,if ignore_not_found :,0.024814633,1.00E-10,0.277777778
"def __init__(self, element, spec):<tab>Extension.__init__(self, element, spec)<tab>self.spec = spec<tab>self.number = tuple(map(int, element.attrib[""number""].split(""."")))<tab>self.api = element.attrib[""api""]<tab># not every spec has a ._remove member, but there shouldn't be a remove<tab># tag without that member, if there is, blame me!<tab>for removed in chain.from_iterable(element.findall(""remove"")):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>data = {""enum"": spec.enums, ""command"": spec.commands}[removed.tag]<tab><tab>try:<tab><tab><tab>spec.add_remove(self.api, self.number, data[removed.attrib[""name""]])<tab><tab>except KeyError:<tab><tab><tab>pass  # TODO",0,"if removed . tag == ""type"" :",if removed . tag not in spec . commands :,0.181873778,27.77619034,0.45
"def _convert_raw_source(self, source, languages):<tab>for row in source:<tab><tab>example = self._read_example(row)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>for col, lang in zip(self.language_columns, languages):<tab><tab><tab>example[col] = lang<tab><tab>yield example",1,if example is None :,if example is None :,0.75,100,1
"def check_engine(engine):<tab>if engine == ""auto"":<tab><tab>if pa is not None:<tab><tab><tab>return ""pyarrow""<tab><tab><IF-STMT>  # pragma: no cover<tab><tab><tab>return ""fastparquet""<tab><tab>else:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install either pyarrow or fastparquet."")<tab>elif engine == ""pyarrow"":<tab><tab>if pa is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install pyarrow fisrt."")<tab><tab>return engine<tab>elif engine == ""fastparquet"":<tab><tab>if fastparquet is None:  # pragma: no cover<tab><tab><tab>raise RuntimeError(""Please install fastparquet first."")<tab><tab>return engine<tab>else:  # pragma: no cover<tab><tab>raise RuntimeError(""Unsupported engine {} to read parquet."".format(engine))",1,elif fastparquet is not None :,elif fastparquet is not None :,0.75,100,1
"def TryMerge(self, d):<tab>while 1:<tab><tab>tt = d.getVarInt32()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if tt == 18:<tab><tab><tab>self.set_value(d.getPrefixedString())<tab><tab><tab>continue<tab><tab>if tt == 29:<tab><tab><tab>self.set_flags(d.get32())<tab><tab><tab>continue<tab><tab>if tt == 0:<tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",0,if tt == 12 :,if tt == 8 :,0.394778655,53.72849659,0.6
"def handle(self, request):<tab>try:<tab><tab>if request.message.question[0].rdtype == dns.rdatatype.IXFR:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>text = ixfr<tab><tab><tab>else:<tab><tab><tab><tab>text = retry_tcp_ixfr<tab><tab><tab><tab>self.did_truncation = True<tab><tab>else:<tab><tab><tab>text = axfr<tab><tab>r = dns.message.from_text(text, one_rr_per_rrset=True, origin=self.origin)<tab><tab>r.id = request.message.id<tab><tab>return r<tab>except Exception:<tab><tab>pass",0,if self . did_truncation :,if request . message . question [ 0 ] . rdtype == dns . rdatatype . TCP :,0.105750074,2.664321121,0.156363636
"def read_kvfile_todict(file):<tab>if not os.path.isfile(file):<tab><tab>return {}<tab>ret = {}<tab>with open(file, ""r"") as FH:<tab><tab>for l in FH.readlines():<tab><tab><tab>l = l.strip()<tab><tab><tab># l = l.strip().decode('utf8')<tab><tab><tab><IF-STMT><tab><tab><tab><tab>(k, v) = re.match(r""(\S*)\s*(.*)"", l).group(1, 2)<tab><tab><tab><tab>k = re.sub(""____"", "" "", k)<tab><tab><tab><tab>ret[k] = v<tab>return ret",1,if l :,if l :,0.531170663,1.00E-10,1
"def wrapper(*args, **kwargs):<tab>with capture_logs() as logs:<tab><tab>try:<tab><tab><tab>function(*args, **kwargs)<tab><tab>except Exception:  # pragma: no cover<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""%i errors logged:"" % len(logs), file=sys.stderr)<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab>raise<tab><tab>else:<tab><tab><tab>if logs:  # pragma: no cover<tab><tab><tab><tab>for message in logs:<tab><tab><tab><tab><tab>print(message, file=sys.stderr)<tab><tab><tab><tab>raise AssertionError(""%i errors logged"" % len(logs))",1,if logs :,if logs :,0.531170663,1.00E-10,1
"def batchSites(self, sites):<tab>i = 0<tab>res = list()<tab>siteList = list()<tab>for site in sites:<tab><tab>if i >= self.opts[""_maxthreads""]:<tab><tab><tab>data = self.threadSites(siteList)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return res<tab><tab><tab>for ret in list(data.keys()):<tab><tab><tab><tab>if data[ret]:<tab><tab><tab><tab><tab># bucket:filecount<tab><tab><tab><tab><tab>res.append(f""{ret}:{data[ret]}"")<tab><tab><tab>i = 0<tab><tab><tab>siteList = list()<tab><tab>siteList.append(site)<tab><tab>i += 1<tab>return res",1,if data is None :,if data is None :,0.75,100,1
"def datagram_received(self, data, addr):<tab>""""""Handle data from ``addr``.""""""<tab>if self.buffer and addr in self.buffer:<tab><tab>data = self.buffer.pop(addr) + data<tab>while data:<tab><tab>idx = data.find(self.separator)<tab><tab>if idx >= 0:  # we have a full message<tab><tab><tab>idx += len(self.separator)<tab><tab><tab>chunk, data = data[:idx], data[idx:]<tab><tab><tab>self.response(chunk, addr)<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.buffer = {}<tab><tab><tab>self.buffer[addr] = data<tab><tab><tab>data = None",0,if self . buffer is None :,if addr not in self . buffer :,0.137090538,23.35689889,0.2
"def tearDown(self):<tab>if self.node:<tab><tab><IF-STMT><tab><tab><tab>with patch(""golem.task.taskserver.TaskServer.quit""):<tab><tab><tab><tab>self.node.client.quit()<tab><tab>if self.node._db:<tab><tab><tab>self.node._db.close()<tab>super().tearDown()",1,if self . node . client :,if self . node . client :,0.75,100,1
"def _to_sentences(self, lines):<tab>text = """"<tab>sentence_objects = []<tab>for line in lines:<tab><tab><IF-STMT><tab><tab><tab>if text:<tab><tab><tab><tab>sentences = self.tokenize_sentences(text)<tab><tab><tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab><tab><tab>sentence_objects.append(line)<tab><tab><tab>text = """"<tab><tab>else:<tab><tab><tab>text += "" "" + line<tab>text = text.strip()<tab>if text:<tab><tab>sentences = self.tokenize_sentences(text)<tab><tab>sentence_objects += map(self._to_sentence, sentences)<tab>return sentence_objects",0,"if isinstance ( line , Sentence ) :","if line . startswith ( ""#"" ) :",0.037791629,10.55267032,0.314814815
"def _cloneComponentValues(self, myClone, cloneValueFlag):<tab>idx = 0<tab>l = len(self._componentValues)<tab>while idx < l:<tab><tab>c = self._componentValues[idx]<tab><tab>if c is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>myClone.setComponentByPosition(<tab><tab><tab><tab><tab>idx, c.clone(cloneValueFlag=cloneValueFlag)<tab><tab><tab><tab>)<tab><tab><tab>else:<tab><tab><tab><tab>myClone.setComponentByPosition(idx, c.clone())<tab><tab>idx = idx + 1",0,"if isinstance ( c , base . AbstractConstructedAsn1Item ) :",if cloneValueFlag :,0.010867398,1.00E-10,0.252747253
"def split_quality(quality):<tab>anyQualities = []<tab>bestQualities = []<tab>for curQual in Quality.qualityStrings.keys():<tab><tab>if curQual & quality:<tab><tab><tab>anyQualities.append(curQual)<tab><tab><IF-STMT><tab><tab><tab>bestQualities.append(curQual)<tab>return sorted(anyQualities), sorted(bestQualities)",0,if curQual << 16 & quality :,elif curQual >> 16 & quality :,0.205748387,36.55552229,0.666666667
"def make_pattern(wtree):<tab>subpattern = []<tab>for part in wtree[1:-1]:<tab><tab><IF-STMT><tab><tab><tab>part = make_pattern(part)<tab><tab>elif wtree[0] != """":<tab><tab><tab>for c in part:<tab><tab><tab><tab># Meta-characters cannot be quoted<tab><tab><tab><tab>if c in special_chars:<tab><tab><tab><tab><tab>raise GlobError()<tab><tab>subpattern.append(part)<tab>return """".join(subpattern)",0,"if isinstance ( part , list ) :","if isinstance ( part , tuple ) :",0.549040681,59.46035575,0.666666667
"def insert_not(self, aList):<tab>'''Change ""!"" to ""not"" except before ""=""'''<tab>i = 0<tab>while i < len(aList):<tab><tab>if self.is_string_or_comment(aList, i):<tab><tab><tab>i = self.skip_string_or_comment(aList, i)<tab><tab><IF-STMT><tab><tab><tab>aList[i : i + 1] = list(""not "")<tab><tab><tab>i += 4<tab><tab>else:<tab><tab><tab>i += 1",0,"elif aList [ i ] == ""!"" and not self . match ( aList , i + 1 , ""="" ) :","if aList [ i ] == list ( ""not "" ) :",0.089032936,18.90853401,0.193939394
"def _concretize(self, n_cls, t1, t2, join_or_meet, translate):<tab>ptr_class = self._pointer_class()<tab>if n_cls is ptr_class:<tab><tab>if isinstance(t1, ptr_class) and isinstance(t2, ptr_class):<tab><tab><tab># we need to merge them<tab><tab><tab>return ptr_class(join_or_meet(t1.basetype, t2.basetype, translate))<tab><tab>if isinstance(t1, ptr_class):<tab><tab><tab>return t1<tab><tab><IF-STMT><tab><tab><tab>return t2<tab><tab>else:<tab><tab><tab># huh?<tab><tab><tab>return ptr_class(BottomType())<tab>return n_cls()",0,"elif isinstance ( t2 , ptr_class ) :","if isinstance ( t2 , ptr_class ) :",0.420448208,88.01117368,0.6
"def pre_validate(self, form):<tab>if self.data:<tab><tab>values = list(c[0] for c in self.choices)<tab><tab>for d in self.data:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise ValueError(<tab><tab><tab><tab><tab>self.gettext(""'%(value)s' is not a valid choice for this field"")<tab><tab><tab><tab><tab>% dict(value=d)<tab><tab><tab><tab>)",1,if d not in values :,if d not in values :,0.75,100,1
"def frontend_visible_config(config_dict):<tab>visible_dict = {}<tab>for name in CLIENT_WHITELIST:<tab><tab>if name.lower().find(""secret"") >= 0:<tab><tab><tab>raise Exception(""Cannot whitelist secrets: %s"" % name)<tab><tab><IF-STMT><tab><tab><tab>visible_dict[name] = config_dict.get(name, None)<tab><tab>if ""ENTERPRISE_LOGO_URL"" in config_dict:<tab><tab><tab>visible_dict[""BRANDING""] = visible_dict.get(""BRANDING"", {})<tab><tab><tab>visible_dict[""BRANDING""][""logo""] = config_dict[""ENTERPRISE_LOGO_URL""]<tab>return visible_dict",1,if name in config_dict :,if name in config_dict :,0.75,100,1
"def listdir(self, path=None):<tab>from azure.storage.blob import Blob<tab>dir_path = normalize_storage_path(self._append_path_to_prefix(path))<tab>if dir_path:<tab><tab>dir_path += ""/""<tab>items = list()<tab>for blob in self.client.list_blobs(self.container, prefix=dir_path, delimiter=""/""):<tab><tab><IF-STMT><tab><tab><tab>items.append(self._strip_prefix_from_path(blob.name, dir_path))<tab><tab>else:<tab><tab><tab>items.append(<tab><tab><tab><tab>self._strip_prefix_from_path(<tab><tab><tab><tab><tab>blob.name[: blob.name.find(""/"", len(dir_path))], dir_path<tab><tab><tab><tab>)<tab><tab><tab>)<tab>return items",0,if type ( blob ) == Blob :,"if blob . name . endswith ( ""/"" ) :",0.018757983,5.063996507,0.333333333
"def diff(self, resources):<tab>model = self.manager.resource_type<tab>for r in resources:<tab><tab>hlabels = self.resolve_labels(r[""projectId""])<tab><tab>if not hlabels:<tab><tab><tab>continue<tab><tab>delta = False<tab><tab>rlabels = r.get(""labels"", {})<tab><tab>for k, v in hlabels.items():<tab><tab><tab>if k not in rlabels or rlabels[k] != v:<tab><tab><tab><tab>delta = True<tab><tab>if not delta:<tab><tab><tab>continue<tab><tab>rlabels = dict(rlabels)<tab><tab>rlabels.update(hlabels)<tab><tab><IF-STMT><tab><tab><tab>yield (""update"", model.get_label_params(r, rlabels))",0,if delta :,if rlabels != rlabels :,0.051944023,1.00E-10,0.45
"def favorite(id):<tab>note = Note.query.get_or_404(id)<tab>if current_user != note.author:<tab><tab>abort(403)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>note.is_favorite = True<tab><tab><tab>note.updated_date = datetime.utcnow()<tab><tab><tab>db.session.commit()<tab><tab><tab>flash(""Note marked as favorite"")<tab><tab>else:<tab><tab><tab>note.is_favorite = False<tab><tab><tab>note.updated_date = datetime.utcnow()<tab><tab><tab>db.session.commit()<tab><tab><tab>flash(""Note removed as favorite"")<tab><tab>return redirect(request.referrer)",0,if not note . is_favorite :,if note . is_favorite :,0.281663156,72.89545184,0.464285714
"def enter_standby_instances(self, group_name, instance_ids, should_decrement):<tab>group = self.autoscaling_groups[group_name]<tab>original_size = group.desired_capacity<tab>standby_instances = []<tab>for instance_state in group.instance_states:<tab><tab><IF-STMT><tab><tab><tab>instance_state.lifecycle_state = ""Standby""<tab><tab><tab>standby_instances.append(instance_state)<tab>if should_decrement:<tab><tab>group.desired_capacity = group.desired_capacity - len(instance_ids)<tab>group.set_desired_capacity(group.desired_capacity)<tab>return standby_instances, original_size, group.desired_capacity",0,if instance_state . instance . id in instance_ids :,if instance_state . instance_ids == instance_ids :,0.078039123,53.16967153,0.353846154
"def _child_complete_hook(self, child_task):<tab>if child_task.task_spec == self.main_child_task_spec or self._should_cancel(<tab><tab>child_task.task_spec<tab>):<tab><tab>for sibling in child_task.parent.children:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if sibling.task_spec == self.main_child_task_spec or (<tab><tab><tab><tab><tab>isinstance(sibling.task_spec, BoundaryEvent)<tab><tab><tab><tab><tab>and not sibling._is_finished()<tab><tab><tab><tab>):<tab><tab><tab><tab><tab>sibling.cancel()<tab><tab>for t in child_task.workflow._get_waiting_tasks():<tab><tab><tab>t.task_spec._update(t)",0,if sibling != child_task :,if sibling . task_spec == child_task . task_spec :,0.049758409,18.92240569,1
"def extract_groups(self, text: str, language_code: str):<tab>previous = None<tab>group = 1<tab>groups = []<tab>words = []<tab>ignored = IGNORES.get(language_code, {})<tab>for word in NON_WORD.split(text):<tab><tab>if not word:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if previous == word:<tab><tab><tab><tab>group += 1<tab><tab><tab>elif group > 1:<tab><tab><tab><tab>groups.append(group)<tab><tab><tab><tab>words.append(previous)<tab><tab><tab><tab>group = 1<tab><tab>previous = word<tab>if group > 1:<tab><tab>groups.append(group)<tab><tab>words.append(previous)<tab>return groups, words",0,if word not in ignored and len ( word ) >= 2 :,if word in ignored :,0.158244033,5.280829238,0.253561254
"def runTest(self):<tab>""""""This function will call api providing list of op_class""""""<tab>if self.is_positive_test:<tab><tab>response = indexes_utils.api_create_index_get_op_class(self)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>with patch(<tab><tab><tab><tab>self.mock_data[""function_name""],<tab><tab><tab><tab>side_effect=eval(self.mock_data[""return_value""]),<tab><tab><tab>):<tab><tab><tab><tab>response = indexes_utils.api_create_index_get_op_class(self)<tab>indexes_utils.assert_status_code(self, response)",1,if self . mocking_required :,if self . mocking_required :,0.75,100,1
"def fn(value=None):<tab>for i in [-1, 0, 1, 2, 3, 4]:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif i == 0:<tab><tab><tab>yield 0<tab><tab>elif i == 1:<tab><tab><tab>yield 1<tab><tab><tab>i = 0<tab><tab><tab>yield value<tab><tab><tab>yield 2<tab><tab>else:<tab><tab><tab>try:<tab><tab><tab><tab>v = i / value<tab><tab><tab>except:<tab><tab><tab><tab>v = i<tab><tab><tab>yield v",0,if i < 0 :,if value is None :,0.034123066,12.7033187,0.238095238
"def _update(self, flag):<tab>self._modified = False<tab>self._index = {}<tab>try:<tab><tab>f = _io.open(self._dirfile, ""r"", encoding=""Latin-1"")<tab>except OSError:<tab><tab><IF-STMT><tab><tab><tab>raise<tab><tab>self._modified = True<tab>else:<tab><tab>with f:<tab><tab><tab>for line in f:<tab><tab><tab><tab>line = line.rstrip()<tab><tab><tab><tab>key, pos_and_siz_pair = _ast.literal_eval(line)<tab><tab><tab><tab>key = key.encode(""Latin-1"")<tab><tab><tab><tab>self._index[key] = pos_and_siz_pair",0,"if flag not in ( ""c"" , ""n"" ) :",if flag :,0.020477126,1.00E-10,0.571428571
"def _network_connections_in_results(data):<tab>for plugin_name, plugin_result in data.iteritems():<tab><tab>if plugin_result[""status""] == ""error"":<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if ""connections"" in plugin_result[""device""]:<tab><tab><tab>for conn in plugin_result[""device""][""connections""]:<tab><tab><tab><tab>if conn[""connection_type""] == ConnectionType.network.name:<tab><tab><tab><tab><tab>return True<tab>return False",1,"if ""device"" not in plugin_result :","if ""device"" not in plugin_result :",0.75,100,1
"def close(self) -> None:<tab>""""""Stop accepting writes and write file, if needed.""""""<tab>if not self._io:<tab><tab>raise Exception(""FileAvoidWrite does not support empty files."")<tab>buf = self.getvalue()<tab>self._io.close()<tab>try:<tab><tab>with open(self._path, encoding=""utf-8"") as old_f:<tab><tab><tab>old_content = old_f.read()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab>except OSError:<tab><tab>pass<tab>with open(self._path, ""w"", encoding=""utf-8"") as f:<tab><tab>f.write(buf)",0,if old_content == buf :,if not old_content :,0.039449619,24.59812752,0.5
"def _extract_changes(doc_map, changes, read_time):<tab>deletes = []<tab>adds = []<tab>updates = []<tab>for name, value in changes.items():<tab><tab><IF-STMT><tab><tab><tab>if name in doc_map:<tab><tab><tab><tab>deletes.append(name)<tab><tab>elif name in doc_map:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>updates.append(value)<tab><tab>else:<tab><tab><tab>if read_time is not None:<tab><tab><tab><tab>value.read_time = read_time<tab><tab><tab>adds.append(value)<tab>return (deletes, adds, updates)",0,if value == ChangeType . REMOVED :,"if isinstance ( value , dict ) :",0.021135836,7.267884212,0.285714286
"def preprocess(<tab>self,<tab>X: DataFrame,<tab>is_train=False,<tab>vect_max_features=1000,<tab>model_specific_preprocessing=False,):<tab>X = super().preprocess(X=X)<tab>if (<tab><tab>model_specific_preprocessing<tab>):  # This is hack to work-around pre-processing caching in bagging/stacker models<tab><tab><IF-STMT><tab><tab><tab>feature_types = self._get_types_of_features(X)<tab><tab><tab>X = self.preprocess_train(X, feature_types, vect_max_features)<tab><tab>else:<tab><tab><tab>X = self.pipeline.transform(X)<tab>return X",1,if is_train :,if is_train :,0.531170663,1.00E-10,1
"def setup_child(self, child):<tab>child.parent = self<tab>if self.document:<tab><tab>child.document = self.document<tab><tab><IF-STMT><tab><tab><tab>child.source = self.document.current_source<tab><tab>if child.line is None:<tab><tab><tab>child.line = self.document.current_line",1,if child . source is None :,if child . source is None :,0.75,100,1
"def _compute_early_outs(self, quotas):<tab>for q in quotas:<tab><tab><IF-STMT><tab><tab><tab>self.results[q] = Quota.AVAILABILITY_ORDERED, 0<tab><tab>elif q.size is None:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_OK, None<tab><tab>elif q.size == 0:<tab><tab><tab>self.results[q] = Quota.AVAILABILITY_GONE, 0",0,if q . closed and not self . _ignore_closed :,if q . size > 1 :,0.059288143,11.14789227,0.311111111
"def parse_function(self, l):<tab>bracket = l.find(""("")<tab>fname = l[8:bracket]<tab>if self.properties:<tab><tab><IF-STMT><tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propget[fname] = 1<tab><tab>elif self.properties[0] == ""propput"":<tab><tab><tab>self.props[fname] = 1<tab><tab><tab>self.propput[fname] = 1<tab><tab>else:<tab><tab><tab>self.functions[fname] = 1<tab>self.properties = None",1,"if self . properties [ 0 ] == ""propget"" :","if self . properties [ 0 ] == ""propget"" :",0.75,100,1
def SetHelpListButtonStates(self):<tab>if self.listHelp.size() < 1:  # no entries in list<tab><tab>self.buttonHelpListEdit.config(state=DISABLED)<tab><tab>self.buttonHelpListRemove.config(state=DISABLED)<tab>else:  # there are some entries<tab><tab><IF-STMT>  # there currently is a selection<tab><tab><tab>self.buttonHelpListEdit.config(state=NORMAL)<tab><tab><tab>self.buttonHelpListRemove.config(state=NORMAL)<tab><tab>else:  # there currently is not a selection<tab><tab><tab>self.buttonHelpListEdit.config(state=DISABLED)<tab><tab><tab>self.buttonHelpListRemove.config(state=DISABLED),0,if self . listHelp . curselection ( ) :,if self . listHelp . size ( ) == 1 :,0.388257233,37.70063805,0.56043956
"def param_names() -> FrozenSet[Tuple[str, str]]:<tab>""""""Returns all module and parameter names as a set of pairs.""""""<tab>out = []<tab>params = current_frame().params<tab>for mod_name, bundle in params.items():<tab><tab><IF-STMT><tab><tab><tab># TODO(tomhennigan) Fix broken user code and remove this warning.<tab><tab><tab>warnings.warn(f""Invalid entry {mod_name!r} in params {params}"")<tab><tab><tab>continue<tab><tab>for name in bundle:<tab><tab><tab>out.append((mod_name, name))<tab>return frozenset(out)",0,"if not isinstance ( bundle , Mapping ) :",if mod_name not in params :,0.017041952,6.413885306,0.361111111
"def _classify_volume(self, ctxt, volumes):<tab>normal_volumes = []<tab>replica_volumes = []<tab>for v in volumes:<tab><tab>volume_type = self._get_volume_replicated_type(ctxt, v)<tab><tab><IF-STMT><tab><tab><tab>replica_volumes.append(v)<tab><tab>else:<tab><tab><tab>normal_volumes.append(v)<tab>return normal_volumes, replica_volumes",0,"if volume_type and v . status == ""available"" :","if volume_type == ""replica"" :",0.031533007,28.38267516,0.353846154
"def undump_descriptions_of_all_objects(inf):<tab>d = {}<tab>for l in inf:<tab><tab>dash = l.find(""-"")<tab><tab>if dash == -1:<tab><tab><tab>raise l<tab><tab>mo = NRE.search(l)<tab><tab><IF-STMT><tab><tab><tab>typstr = l[dash + 1 : mo.start(0)]<tab><tab><tab>num = int(mo.group(0))<tab><tab><tab>if str(num) != mo.group(0):<tab><tab><tab><tab>raise mo.group(0)<tab><tab>else:<tab><tab><tab>typstr = l[dash + 1 :]<tab><tab><tab>num = None<tab><tab>d[l[:dash]] = (<tab><tab><tab>typstr,<tab><tab><tab>num,<tab><tab>)<tab>return d",1,if mo :,if mo :,0.531170663,1.00E-10,1
"def _real_len(self, s):<tab>s_len = 0<tab>in_esc = False<tab>prev = "" ""<tab>for c in replace_all({""\0+"": """", ""\0-"": """", ""\0^"": """", ""\1"": """", ""\t"": "" ""}, s):<tab><tab><IF-STMT><tab><tab><tab>if c == ""m"":<tab><tab><tab><tab>in_esc = False<tab><tab>else:<tab><tab><tab>if c == ""["" and prev == ""\033"":<tab><tab><tab><tab>in_esc = True<tab><tab><tab><tab>s_len -= 1  # we counted prev when we shouldn't have<tab><tab><tab>else:<tab><tab><tab><tab>s_len += self._display_len(c)<tab><tab>prev = c<tab>return s_len",1,if in_esc :,if in_esc :,0.531170663,1.00E-10,1
"def update_all(self, include_description=False):<tab>if self.background_update is None:<tab><tab>episodes = [row[self.C_EPISODE] for row in self]<tab>else:<tab><tab># Update all episodes that have already been initialized...<tab><tab>episodes = [<tab><tab><tab>row[self.C_EPISODE]<tab><tab><tab>for index, row in enumerate(self)<tab><tab><tab><IF-STMT><tab><tab>]<tab><tab># ...and also include episodes that still need to be initialized<tab><tab>episodes.extend(self.background_update.episodes)<tab>self._update_from_episodes(episodes, include_description)",0,if index < self . background_update . index,if self . background_update is not None and self . background_update [ index ] is not None,0.121386523,19.12081758,0.203947368
"def _debug_log(self, text, level):<tab>if text and ""log"" in self.config.sys.debug:<tab><tab><IF-STMT><tab><tab><tab>text = ""%slog(%s): %s"" % (self.log_prefix, level, text)<tab><tab>if self.log_parent is not None:<tab><tab><tab>return self.log_parent.log(level, text)<tab><tab>else:<tab><tab><tab>self.term.write(self._fmt_log(text, level=level))",0,if not text . startswith ( self . log_prefix ) :,if self . log_prefix is not None :,0.11975336,32.7287432,0.25
"def save_new_objects(self, commit=True):<tab>self.new_objects = []<tab>for form in self.extra_forms:<tab><tab>if not form.has_changed():<tab><tab><tab>continue<tab><tab># If someone has marked an add form for deletion, don't save the<tab><tab># object.<tab><tab>if self.can_delete and self._should_delete_form(form):<tab><tab><tab>continue<tab><tab>self.new_objects.append(self.save_new(form, commit=commit))<tab><tab><IF-STMT><tab><tab><tab>self.saved_forms.append(form)<tab>return self.new_objects",0,if not commit :,if self . can_save_form ( form ) :,0.034692192,4.027248192,0.333333333
"def get_master_info(accounts_config, master):<tab>master_info = None<tab>for a in accounts_config[""accounts""]:<tab><tab><IF-STMT><tab><tab><tab>master_info = a<tab><tab><tab>break<tab><tab>if a[""account_id""] == master:<tab><tab><tab>master_info = a<tab><tab><tab>break<tab>if master_info is None:<tab><tab>raise ValueError(""Master account: %s not found in accounts config"" % (master))<tab>return master_info",1,"if a [ ""name"" ] == master :","if a [ ""name"" ] == master :",0.75,100,1
"def update(attr, value=None):<tab>if value is not None:<tab><tab>setattr(draft, attr, value)<tab><tab><IF-STMT><tab><tab><tab># Update size, snippet too<tab><tab><tab>draft.size = len(value)<tab><tab><tab>draft.snippet = draft.calculate_html_snippet(value)",0,"if attr == ""body"" :","if hasattr ( draft , ""size"" ) :",0.026407399,5.93420261,0.381818182
"def _process_property_change(self, msg):<tab>msg = super(Select, self)._process_property_change(msg)<tab>if ""value"" in msg:<tab><tab>if not self.values:<tab><tab><tab>pass<tab><tab><IF-STMT><tab><tab><tab>msg[""value""] = self.values[0]<tab><tab>else:<tab><tab><tab>if isIn(msg[""value""], self.unicode_values):<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.unicode_values)<tab><tab><tab>else:<tab><tab><tab><tab>idx = indexOf(msg[""value""], self.labels)<tab><tab><tab>msg[""value""] = self._items[self.labels[idx]]<tab>msg.pop(""options"", None)<tab>return msg",0,"elif msg [ ""value"" ] is None :",elif len ( self . values ) == 1 :,0.014532566,4.456882761,0.212121212
"def removeEmptyDir(path, removeRoot=True):<tab>if not os.path.isdir(path):<tab><tab>return<tab># remove empty subfolders<tab>_files = os.listdir(path)<tab>if len(_files) > 0:<tab><tab>for f in _files:<tab><tab><tab>if not f.startswith(""."") and not f.startswith(""_""):<tab><tab><tab><tab>fullpath = os.path.join(path, f)<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>removeEmptyDir(fullpath)<tab># if folder empty, delete it<tab>_files = os.listdir(path)<tab>if len(_files) == 0 and removeRoot:<tab><tab>Print.info(""Removing empty folder:"" + path)<tab><tab>os.rmdir(path)",1,if os . path . isdir ( fullpath ) :,if os . path . isdir ( fullpath ) :,0.75,100,1
"def make_relative_to(self, kwds, relative_to):<tab>if relative_to and os.path.dirname(relative_to):<tab><tab>dirname = os.path.dirname(relative_to)<tab><tab>kwds = kwds.copy()<tab><tab>for key in ffiplatform.LIST_OF_FILE_NAMES:<tab><tab><tab>if key in kwds:<tab><tab><tab><tab>lst = kwds[key]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>raise TypeError(""keyword '%s' should be a list or tuple"" % (key,))<tab><tab><tab><tab>lst = [os.path.join(dirname, fn) for fn in lst]<tab><tab><tab><tab>kwds[key] = lst<tab>return kwds",1,"if not isinstance ( lst , ( list , tuple ) ) :","if not isinstance ( lst , ( list , tuple ) ) :",0.75,100,1
"def ending(self, state):<tab>print_title("" STABLE PINS "")<tab>path_lists = trace_graph(state.graph)<tab>for k in sorted(state.mapping):<tab><tab>print(state.mapping[k].as_line(include_hashes=False))<tab><tab>paths = path_lists[k]<tab><tab>for path in paths:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""<tab>User requirement"")<tab><tab><tab><tab>continue<tab><tab><tab>print(""   "", end="""")<tab><tab><tab>for v in reversed(path[1:]):<tab><tab><tab><tab>line = state.mapping[v].as_line(include_hashes=False)<tab><tab><tab><tab>print("" <="", line, end="""")<tab><tab><tab>print()<tab>print()",0,if path == [ None ] :,"if path [ 0 ] == ""."" :",0.04265003,12.1920916,0.6
"def fetch():<tab>retval = {}<tab>content = retrieve_content(__url__)<tab>if __check__ in content:<tab><tab>for line in content.split(""\n""):<tab><tab><tab>line = line.strip()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if "" # "" in line:<tab><tab><tab><tab>reason = line.split("" # "")[1].split()[0].lower()<tab><tab><tab><tab>if reason == ""scanning"":  # too many false positives<tab><tab><tab><tab><tab>continue<tab><tab><tab><tab>retval[line.split("" # "")[0]] = (__info__, __reference__)<tab>return retval",0,"if not line or line . startswith ( ""#"" ) or ""."" not in line :",if not line :,0.026241817,1.295111246,0.399749373
"def __str__(self):<tab>""""""Returns human readable string representation, useful for debugging.""""""<tab>buf = StringIO()<tab>for idx, (class_batch_id, class_val) in enumerate(iteritems(self.data)):<tab><tab><IF-STMT><tab><tab><tab>buf.write(u""  ...\n"")<tab><tab><tab>break<tab><tab>buf.write(u'  ClassBatch ""{0}""\n'.format(class_batch_id))<tab><tab>buf.write(u""<tab>{0}\n"".format(str(class_val)))<tab>return buf.getvalue()",0,if idx >= TO_STR_MAX_BATCHES :,if idx >= self . limit :,0.117260658,22.17204505,0.55
"def find_caller(stack):<tab>""""""Finds info about first non-sqlalchemy call in stack""""""<tab>for frame in stack:<tab><tab># We don't care about sqlalchemy internals<tab><tab>module = inspect.getmodule(frame[0])<tab><tab>if not hasattr(module, ""__name__""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>return (module.__name__,) + tuple(frame[2:4]) + (frame[4][0].strip(),)<tab>log.warning(""Transaction from unknown origin"")<tab>return None, None, None, None",0,"if module . __name__ . startswith ( ""sqlalchemy"" ) :",if not inspect . isclass ( module ) :,0.030269723,5.765477374,0.261904762
"def format_unencoded(self, tokensource, outfile):<tab>if self.linenos:<tab><tab>self._write_lineno(outfile)<tab>for ttype, value in tokensource:<tab><tab>color = self._get_color(ttype)<tab><tab>for line in value.splitlines(True):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>outfile.write(""<%s>%s</>"" % (color, line.rstrip(""\n"")))<tab><tab><tab>else:<tab><tab><tab><tab>outfile.write(line.rstrip(""\n""))<tab><tab><tab>if line.endswith(""\n""):<tab><tab><tab><tab>if self.linenos:<tab><tab><tab><tab><tab>self._write_lineno(outfile)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>outfile.write(""\n"")<tab>if self.linenos:<tab><tab>outfile.write(""\n"")",1,if color :,if color :,0.531170663,1.00E-10,1
"def __new__(cls, name, bases, attrs):<tab>klass = type.__new__(cls, name, bases, attrs)<tab>if ""cmds"" in attrs:<tab><tab>cmds = attrs[""cmds""]<tab><tab><IF-STMT><tab><tab><tab>cmd_handler_mapping[cmds] = klass<tab><tab>else:<tab><tab><tab>for cmd in cmds:<tab><tab><tab><tab>cmd_handler_mapping[cmd] = klass<tab>return klass",0,"if isinstance ( cmds , str ) :","if isinstance ( cmds , list ) :",0.549040681,59.46035575,0.666666667
"def __getattr__(self, key):<tab>if key == key.upper():<tab><tab><IF-STMT><tab><tab><tab>return getattr(self._django_settings, key)<tab><tab>elif hasattr(self._default_settings, key):<tab><tab><tab>return getattr(self._default_settings, key)<tab>raise AttributeError(<tab><tab>""%r object has no attribute %r"" % (self.__class__.__name__, key)<tab>)",1,"if hasattr ( self . _django_settings , key ) :","if hasattr ( self . _django_settings , key ) :",0.75,100,1
"def download_file(url):<tab>local_filename = url.split(""/"")[-1]<tab>outfile = os.path.join(AVATAR_DIR, local_filename)<tab>if not os.path.isfile(outfile):<tab><tab>r = requests.get(url, stream=True)<tab><tab>with open(outfile, ""wb"") as f:<tab><tab><tab>for chunk in r.iter_content(chunk_size=1024):<tab><tab><tab><tab><IF-STMT>  # filter out keep-alive new chunks<tab><tab><tab><tab><tab>f.write(chunk)<tab><tab><tab><tab><tab>f.flush()<tab>return local_filename",1,if chunk :,if chunk :,0.531170663,1.00E-10,1
"def check_default(self):<tab>if self.check():<tab><tab>self.credentials = []<tab><tab>data = LockedIterator(itertools.product(self.usernames, self.passwords))<tab><tab>self.run_threads(self.threads, self.target_function, data)<tab><tab><IF-STMT><tab><tab><tab>return self.credentials<tab>return None",1,if self . credentials :,if self . credentials :,0.75,100,1
"def _process_frame(self, frame_num, frame_im, callback=None):<tab># type(int, numpy.ndarray) -> None<tab>""""""Adds any cuts detected with the current frame to the cutting list.""""""<tab>for detector in self._detector_list:<tab><tab>cuts = detector.process_frame(frame_num, frame_im)<tab><tab>if cuts and callback:<tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._cutting_list += cuts<tab>for detector in self._sparse_detector_list:<tab><tab>events = detector.process_frame(frame_num, frame_im)<tab><tab><IF-STMT><tab><tab><tab>callback(frame_im, frame_num)<tab><tab>self._event_list += events",1,if events and callback :,if events and callback :,0.75,100,1
"def parse(cls, api, json):<tab>user = cls(api)<tab>setattr(user, ""_json"", json)<tab>for k, v in json.items():<tab><tab>if k == ""created_at"":<tab><tab><tab>setattr(user, k, parse_datetime(v))<tab><tab>elif k == ""status"":<tab><tab><tab>setattr(user, k, Status.parse(api, v))<tab><tab><IF-STMT><tab><tab><tab># twitter sets this to null if it is false<tab><tab><tab>if v is True:<tab><tab><tab><tab>setattr(user, k, True)<tab><tab><tab>else:<tab><tab><tab><tab>setattr(user, k, False)<tab><tab>else:<tab><tab><tab>setattr(user, k, v)<tab>return user",0,"elif k == ""following"" :","elif k == ""is_active"" :",0.642872021,45.18010018,1
def dump_token_list(tokens):<tab>for token in tokens:<tab><tab><IF-STMT><tab><tab><tab>writer.write(token.contents)<tab><tab>elif token.token_type == TOKEN_VAR:<tab><tab><tab>writer.print_expr(token.contents)<tab><tab><tab>touch_var(token.contents),0,if token . token_type == TOKEN_TEXT :,if token . token_type == TOKEN_LINE :,0.574113272,82.65168184,1
"def parent_path(path):<tab>parent_dir = S3FileSystem._append_separator(path)<tab>if not s3.is_root(parent_dir):<tab><tab>bucket_name, key_name, basename = s3.parse_uri(path)<tab><tab><IF-STMT>  # bucket is top-level so return root<tab><tab><tab>parent_dir = S3A_ROOT<tab><tab>else:<tab><tab><tab>bucket_path = ""%s%s"" % (S3A_ROOT, bucket_name)<tab><tab><tab>key_path = ""/"".join(key_name.split(""/"")[:-1])<tab><tab><tab>parent_dir = s3.abspath(bucket_path, key_path)<tab>return parent_dir",0,if not basename :,if basename == S3A_ROOT :,0.045150551,7.267884212,0.45
"def write_framed_message(self, message):<tab>message_length = len(message)<tab>total_bytes_sent = 0<tab>while message_length - total_bytes_sent > 0:<tab><tab><IF-STMT><tab><tab><tab>buffer_length = BUFFER_SIZE<tab><tab>else:<tab><tab><tab>buffer_length = message_length - total_bytes_sent<tab><tab>self.write_buffer(<tab><tab><tab>message[total_bytes_sent : (total_bytes_sent + buffer_length)]<tab><tab>)<tab><tab>total_bytes_sent += buffer_length<tab># A message is always terminated by a zero-length buffer.<tab>self.write_buffer_length(0)",0,if message_length - total_bytes_sent > BUFFER_SIZE :,if total_bytes_sent >= BUFFER_SIZE :,0.107201561,50.57032536,1
"def reader():<tab>with tarfile.open(filename, mode=""r"") as f:<tab><tab>names = (each_item.name for each_item in f if sub_name in each_item.name)<tab><tab>while True:<tab><tab><tab>for name in names:<tab><tab><tab><tab>if six.PY2:<tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name))<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>batch = pickle.load(f.extractfile(name), encoding=""bytes"")<tab><tab><tab><tab>for item in read_batch(batch):<tab><tab><tab><tab><tab>yield item<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",0,if not cycle :,if not batch :,0.345861998,35.35533906,0.6
"def splitOn(sequence, predicate, transformers):<tab>result = []<tab>mode = predicate(sequence[0])<tab>tmp = [sequence[0]]<tab>for e in sequence[1:]:<tab><tab>p = predicate(e)<tab><tab><IF-STMT><tab><tab><tab>result.extend(transformers[mode](tmp))<tab><tab><tab>tmp = [e]<tab><tab><tab>mode = p<tab><tab>else:<tab><tab><tab>tmp.append(e)<tab>result.extend(transformers[mode](tmp))<tab>return result",0,if p != mode :,if p :,0.067674239,1.00E-10,0.7
"def stroke(s):<tab>keys = []<tab>on_left = True<tab>for k in s:<tab><tab>if k in ""EU*-"":<tab><tab><tab>on_left = False<tab><tab>if k == ""-"":<tab><tab><tab>continue<tab><tab>elif k == ""*"":<tab><tab><tab>keys.append(k)<tab><tab><IF-STMT><tab><tab><tab>keys.append(k + ""-"")<tab><tab>else:<tab><tab><tab>keys.append(""-"" + k)<tab>return Stroke(keys)",1,elif on_left :,elif on_left :,0.514316131,1.00E-10,1
"def check(data_dir, decrypter, read_only=False):<tab>fname = os.path.join(data_dir, DIGEST_NAME)<tab>if os.path.exists(fname):<tab><tab>if decrypter is None:<tab><tab><tab>return False<tab><tab>f = open(fname, ""rb"")<tab><tab>s = f.read()<tab><tab>f.close()<tab><tab>return decrypter.decrypt(s) == MAGIC_STRING<tab>else:<tab><tab>if decrypter is not None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return False<tab><tab><tab>else:<tab><tab><tab><tab>s = decrypter.encrypt(MAGIC_STRING)<tab><tab><tab><tab>f = open(fname, ""wb"")<tab><tab><tab><tab>f.write(s)<tab><tab><tab><tab>f.close()<tab><tab>return True",1,if read_only :,if read_only :,0.531170663,1.00E-10,1
def get_sentence(self):<tab>while True:<tab><tab>self._seed += 1<tab><tab>all_files = list(self._all_files)<tab><tab>if self._shuffle:<tab><tab><tab>if self._n_gpus > 1:<tab><tab><tab><tab>random.seed(self._seed)<tab><tab><tab>random.shuffle(all_files)<tab><tab>for file_path in all_files:<tab><tab><tab>for ret in self._load_file(file_path):<tab><tab><tab><tab>yield ret<tab><tab><IF-STMT><tab><tab><tab>break,0,"if self . _mode == ""test"" :",if self . _seed >= self . _n_gpus :,0.14103088,19.67497981,0.863247863
"def on_epoch_end(self, batch, logs=None):<tab># At the end of every epoch, remask the weights. This ensures that when<tab># the model is saved after completion, the weights represent mask*weights.<tab>weight_mask_ops = []<tab>for layer in self.prunable_layers:<tab><tab><IF-STMT><tab><tab><tab>if tf.executing_eagerly():<tab><tab><tab><tab>layer.pruning_obj.weight_mask_op()<tab><tab><tab>else:<tab><tab><tab><tab>weight_mask_ops.append(layer.pruning_obj.weight_mask_op())<tab>K.batch_get_value(weight_mask_ops)",0,"if isinstance ( layer , pruning_wrapper . PruneLowMagnitude ) :",if layer . pruning_obj is not None :,0.015805905,9.042713792,0.238636364
"def stroke(s):<tab>keys = []<tab>on_left = True<tab>for k in s:<tab><tab><IF-STMT><tab><tab><tab>on_left = False<tab><tab>if k == ""-"":<tab><tab><tab>continue<tab><tab>elif k == ""*"":<tab><tab><tab>keys.append(k)<tab><tab>elif on_left:<tab><tab><tab>keys.append(k + ""-"")<tab><tab>else:<tab><tab><tab>keys.append(""-"" + k)<tab>return Stroke(keys)",0,"if k in ""EU*-"" :","if k == ""+"" :",0.064978772,14.5751614,0.7
"def _plot_figure(self, idx):<tab>with self.renderer.state():<tab><tab>self.plot.update(idx)<tab><tab><IF-STMT><tab><tab><tab>figure_format = self.renderer.params(""fig"").objects[0]<tab><tab>else:<tab><tab><tab>figure_format = self.renderer.fig<tab><tab>return self.renderer._figure_data(self.plot, figure_format, as_script=True)[0]",0,"if self . renderer . fig == ""auto"" :","if hasattr ( self . renderer , ""params"" ) :",0.115290485,15.5801057,0.333333333
"def custom_format(slither, result):<tab>elements = result[""elements""]<tab>for element in elements:<tab><tab>target = element[""additional_fields""][""target""]<tab><tab>convention = element[""additional_fields""][""convention""]<tab><tab><IF-STMT><tab><tab><tab># l_O_I_should_not_be_used cannot be automatically patched<tab><tab><tab>logger.info(<tab><tab><tab><tab>f'The following naming convention cannot be patched: \n{result[""description""]}'<tab><tab><tab>)<tab><tab><tab>continue<tab><tab>_patch(slither, result, element, target)",0,"if convention == ""l_O_I_should_not_be_used"" :","if convention not in ( ""l_O_I_should_not_be_used"" , ""strict"" ) :",0.047950876,58.53410497,0.571428571
"def refresh(self):<tab>if self._obj:<tab><tab>person = self._db.get_person_from_handle(self._obj.get_reference_handle())<tab><tab><IF-STMT><tab><tab><tab>frel = str(self._obj.get_father_relation())<tab><tab><tab>mrel = str(self._obj.get_mother_relation())<tab><tab><tab>self._title = _(""%(frel)s %(mrel)s"") % {""frel"": frel, ""mrel"": mrel}<tab><tab><tab>self._value = person.get_primary_name().get_name()",1,if person :,if person :,0.531170663,1.00E-10,1
"def append(self, child):<tab>if child not in (None, self):<tab><tab>tag = child_tag(self._tag)<tab><tab><IF-STMT><tab><tab><tab>if isinstance(child, Html):<tab><tab><tab><tab>if child.tag != tag:<tab><tab><tab><tab><tab>child = Html(tag, child)<tab><tab><tab>elif not child.startswith(""<%s"" % tag):<tab><tab><tab><tab>child = Html(tag, child)<tab><tab>super().append(child)",1,if tag :,if tag :,0.531170663,1.00E-10,1
def _forward_main_responses(self):<tab>while self._should_keep_going():<tab><tab>line = self._proc.stdout.readline()<tab><tab>if self._main_backend_is_fresh and self._looks_like_echo(line):<tab><tab><tab># In the beginning the backend may echo commands sent to it (perhaps this echo-avoiding trick<tab><tab><tab># takes time). Don't forward those lines.<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>with self._response_lock:<tab><tab><tab>sys.stdout.write(line)<tab><tab><tab>sys.stdout.flush()<tab><tab><tab>self._main_backend_is_fresh = False,1,if not line :,if not line :,0.75,100,1
"def forward(self, inputs):<tab>x = inputs[""image""]<tab>out = self.conv0(x)<tab>out = self.downsample0(out)<tab>blocks = []<tab>for i, conv_block_i in enumerate(self.darknet_conv_block_list):<tab><tab>out = conv_block_i(out)<tab><tab><IF-STMT><tab><tab><tab>out.stop_gradient = True<tab><tab>if i in self.return_idx:<tab><tab><tab>blocks.append(out)<tab><tab>if i < self.num_stages - 1:<tab><tab><tab>out = self.downsample_list[i](out)<tab>return blocks",0,if i == self . freeze_at :,if out . stop_gradient :,0.107179985,6.050259138,0.377777778
"def check_backslashes(payload):<tab># Check for single quotes<tab>if payload.count(""\\"") >= 15:<tab><tab>if not settings.TAMPER_SCRIPTS[""backslashes""]:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>menu.options.tamper = menu.options.tamper + "",backslashes""<tab><tab><tab>else:<tab><tab><tab><tab>menu.options.tamper = ""backslashes""<tab><tab>from src.core.tamper import backslashes<tab><tab>payload = backslashes.tamper(payload)",1,if menu . options . tamper :,if menu . options . tamper :,0.75,100,1
"def __init__(self, config_lists):<tab>self.lens = len(config_lists)<tab>self.spaces = []<tab>for config_list in config_lists:<tab><tab><IF-STMT><tab><tab><tab>key, config = config_list<tab><tab>elif isinstance(config_list, str):<tab><tab><tab>key = config_list<tab><tab><tab>config = None<tab><tab>else:<tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""the type of config is Error!!! Please check the config information. Receive the type of config is {}"".format(<tab><tab><tab><tab><tab>type(config_list)<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>self.spaces.append(self._get_single_search_space(key, config))<tab>self.init_tokens()",1,"if isinstance ( config_list , tuple ) :","if isinstance ( config_list , tuple ) :",0.75,100,1
"def _source_tuple(af, address, port):<tab># Make a high level source tuple, or return None if address and port<tab># are both None<tab>if address or port:<tab><tab><IF-STMT><tab><tab><tab>if af == socket.AF_INET:<tab><tab><tab><tab>address = ""0.0.0.0""<tab><tab><tab>elif af == socket.AF_INET6:<tab><tab><tab><tab>address = ""::""<tab><tab><tab>else:<tab><tab><tab><tab>raise NotImplementedError(f""unknown address family {af}"")<tab><tab>return (address, port)<tab>else:<tab><tab>return None",0,if address is None :,if af :,0.03549272,1.00E-10,0.25
"def test_compatibility(self) -> None:<tab>for expected, user_agent in self.data:<tab><tab>result = self.client_get(""/compatibility"", HTTP_USER_AGENT=user_agent)<tab><tab><IF-STMT><tab><tab><tab>self.assert_json_success(result)<tab><tab>elif expected == ""old"":<tab><tab><tab>self.assert_json_error(result, ""Client is too old"")<tab><tab>else:<tab><tab><tab>assert False  # nocoverage",0,"if expected == ""ok"" :","if expected == ""new"" :",0.394778655,59.46035575,1
"def __init__(self, parent_element):<tab>if parent_element.items():<tab><tab>self.update(dict(parent_element.items()))<tab>for element in parent_element:<tab><tab>if len(element) > 0:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>aDict = ListParser(element)<tab><tab><tab>else:<tab><tab><tab><tab>aDict = DictParser(element)<tab><tab><tab>if element.items():<tab><tab><tab><tab>aDict.update(dict(element.items()))<tab><tab><tab>self.update({element.tag: aDict})<tab><tab>elif element.items():<tab><tab><tab>self.update({element.tag: dict(element.items())})<tab><tab>else:<tab><tab><tab>self.update({element.tag: element.text})",0,if element . tag == element [ 0 ] . tag :,"if isinstance ( element [ 0 ] , list ) :",0.162960174,21.64869375,0.274725275
"def delta_page(self, x: float = 0.0, y: float = 0.0) -> None:<tab>if y.is_integer():<tab><tab>y = int(y)<tab><tab><IF-STMT><tab><tab><tab>pass<tab><tab>elif y < 0:<tab><tab><tab>self.page_up(count=-y)<tab><tab>elif y > 0:<tab><tab><tab>self.page_down(count=y)<tab><tab>y = 0<tab>if x == 0 and y == 0:<tab><tab>return<tab>size = self._widget.page().mainFrame().geometry()<tab>self.delta(int(x * size.width()), int(y * size.height()))",0,if y == 0 :,if x < 0 :,0.314978772,19.35769349,0.6
"def reader(self, myself):<tab>ok = True<tab>line = """"<tab>while True:<tab><tab>line = sys.stdin.readline().strip()<tab><tab><IF-STMT><tab><tab><tab>if not line:<tab><tab><tab><tab>ok = False<tab><tab><tab><tab>continue<tab><tab>elif not line:<tab><tab><tab>break<tab><tab>else:<tab><tab><tab>ok = True<tab><tab>self.Q.append(line)<tab>os.kill(myself, signal.SIGTERM)",1,if ok :,if ok :,0.531170663,1.00E-10,1
"def leave(self, reason=None):<tab>try:<tab><tab>if self.id.startswith(""C""):<tab><tab><tab>log.info(""Leaving channel %s (%s)"", self, self.id)<tab><tab><tab>self._bot.webclient.channels_leave(channel=self.id)<tab><tab>else:<tab><tab><tab>log.info(""Leaving group %s (%s)"", self, self.id)<tab><tab><tab>self._bot.webclient.groups_leave(channel=self.id)<tab>except SlackAPIResponseError as e:<tab><tab><IF-STMT><tab><tab><tab>raise RoomError(f""Unable to leave channel. {USER_IS_BOT_HELPTEXT}"")<tab><tab>else:<tab><tab><tab>raise RoomError(e)<tab>self._id = None",1,"if e . error == ""user_is_bot"" :","if e . error == ""user_is_bot"" :",0.75,100,1
"def wrap_lines(text, cols=60):<tab>ret = """"<tab>words = re.split(""(\s+)"", text)<tab>linelen = 0<tab>for w in words:<tab><tab><IF-STMT><tab><tab><tab>ret += "" \\\n""<tab><tab><tab>ret += ""   ""<tab><tab><tab>linelen = 0<tab><tab>if linelen == 0 and w.strip() == """":<tab><tab><tab>continue<tab><tab>ret += w<tab><tab>linelen += len(w)<tab>return ret",0,if linelen + len ( w ) > cols - 1 :,if len ( w ) > cols :,0.33343724,44.3440901,0.265306122
"def transport_vmware_guestinfo():<tab>rpctool = ""vmware-rpctool""<tab>not_found = None<tab>if not subp.which(rpctool):<tab><tab>return not_found<tab>cmd = [rpctool, ""info-get guestinfo.ovfEnv""]<tab>try:<tab><tab>out, _err = subp.subp(cmd)<tab><tab>if out:<tab><tab><tab>return out<tab><tab>LOG.debug(""cmd %s exited 0 with empty stdout: %s"", cmd, out)<tab>except subp.ProcessExecutionError as e:<tab><tab><IF-STMT><tab><tab><tab>LOG.warning(""%s exited with code %d"", rpctool, e.exit_code)<tab><tab><tab>LOG.debug(e)<tab>return not_found",0,if e . exit_code != 1 :,if e . exit_code != 0 :,0.574113272,78.254229,0.6
"def handle_noargs(self, **options):<tab># Inspired by Postfix's ""postconf -n"".<tab>from django.conf import settings, global_settings<tab># Because settings are imported lazily, we need to explicitly load them.<tab>settings._setup()<tab>user_settings = module_to_dict(settings._wrapped)<tab>default_settings = module_to_dict(global_settings)<tab>output = []<tab>for key in sorted(user_settings.keys()):<tab><tab><IF-STMT><tab><tab><tab>output.append(""%s = %s  ###"" % (key, user_settings[key]))<tab><tab>elif user_settings[key] != default_settings[key]:<tab><tab><tab>output.append(""%s = %s"" % (key, user_settings[key]))<tab>return ""\n"".join(output)",0,if key not in default_settings :,if user_settings [ key ] is None :,0.023749772,10.55267032,0.428571429
"def channel_sizes(self):<tab>""""""List of channel sizes: [(width, height)].""""""<tab>sizes = []<tab>for channel in self.channel_info:<tab><tab>if channel.id == ChannelID.USER_LAYER_MASK:<tab><tab><tab>sizes.append((self.mask_data.width, self.mask_data.height))<tab><tab><IF-STMT><tab><tab><tab>sizes.append((self.mask_data.real_width, self.mask_data.real_height))<tab><tab>else:<tab><tab><tab>sizes.append((self.width, self.height))<tab>return sizes",0,elif channel . id == ChannelID . REAL_USER_LAYER_MASK :,elif channel . id == ChannelID . USER_LAYER_MASK_REAL :,0.625311927,70.98108718,1
"def get(self, key, default=None, version=None):<tab>fname = self._key_to_file(key, version)<tab>try:<tab><tab>with io.open(fname, ""rb"") as f:<tab><tab><tab>if not self._is_expired(f):<tab><tab><tab><tab>return pickle.loads(zlib.decompress(f.read()))<tab>except IOError as e:<tab><tab><IF-STMT><tab><tab><tab>raise<tab>return default",1,if e . errno != errno . ENOENT :,if e . errno != errno . ENOENT :,1,100,1
"def check_grads(grads_and_vars):<tab>has_nan_ops = []<tab>amax_ops = []<tab>for grad, _ in grads_and_vars:<tab><tab><IF-STMT><tab><tab><tab>if isinstance(grad, tf.IndexedSlices):<tab><tab><tab><tab>x = grad.values<tab><tab><tab>else:<tab><tab><tab><tab>x = grad<tab><tab><tab>has_nan_ops.append(tf.reduce_any(tf.is_nan(x)))<tab><tab><tab>amax_ops.append(tf.reduce_max(tf.abs(x)))<tab>has_nan = tf.reduce_any(has_nan_ops)<tab>amax = tf.reduce_max(amax_ops)<tab>return has_nan, amax",1,if grad is not None :,if grad is not None :,0.75,100,1
"def daily(self, component):<tab>with component.repository.lock:<tab><tab>path = self.get_linguas_path(component)<tab><tab><IF-STMT><tab><tab><tab>self.commit_and_push(component, [path])",1,"if self . sync_linguas ( component , path ) :","if self . sync_linguas ( component , path ) :",0.75,100,1
"def _set_posonly_args_def(self, argmts, vals):<tab>for v in vals:<tab><tab>argmts.posonlyargs.append(v[""arg""])<tab><tab>d = v[""default""]<tab><tab>if d is not None:<tab><tab><tab>argmts.defaults.append(d)<tab><tab><IF-STMT><tab><tab><tab>self._set_error(""non-default argument follows default argument"")",0,elif argmts . defaults :,if d is not None and d not in argmts . defaults :,0.382198071,19.33853138,0.03030303
"def isOrHasChild(parent, child):<tab>while child:<tab><tab>if compare(parent, child):<tab><tab><tab>return True<tab><tab>child = child.parentNode<tab><tab>if not child:<tab><tab><tab>return False<tab><tab><IF-STMT><tab><tab><tab>child = None<tab>return False",0,if child . nodeType != 1 :,if child . nodeType == Node . ELEMENT_NODE :,0.253832916,23.46235032,0.666666667
def Proc2(IntParIO):<tab>IntLoc = IntParIO + 10<tab>while 1:<tab><tab><IF-STMT><tab><tab><tab>IntLoc = IntLoc - 1<tab><tab><tab>IntParIO = IntLoc - IntGlob<tab><tab><tab>EnumLoc = Ident1<tab><tab>if EnumLoc == Ident1:<tab><tab><tab>break<tab>return IntParIO,0,"if Char1Glob == ""A"" :",if IntLoc > IntGlob :,0.034123066,6.971729122,0.36
"def _GetParserChains(self, events):<tab>""""""Return a dict with a plugin count given a list of events.""""""<tab>parser_chains = {}<tab>for event in events:<tab><tab>parser_chain = getattr(event, ""parser"", None)<tab><tab>if not parser_chain:<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>parser_chains[parser_chain] += 1<tab><tab>else:<tab><tab><tab>parser_chains[parser_chain] = 1<tab>return parser_chains",1,if parser_chain in parser_chains :,if parser_chain in parser_chains :,0.75,100,1
"def _url_encode_impl(obj, charset, encode_keys, sort, key):<tab>iterable = sdict()<tab>for key, values in obj.items():<tab><tab>if not isinstance(values, list):<tab><tab><tab>values = [values]<tab><tab>iterable[key] = values<tab>if sort:<tab><tab>iterable = sorted(iterable, key=key)<tab>for key, values in iterable.items():<tab><tab>for value in values:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if not isinstance(key, bytes):<tab><tab><tab><tab>key = str(key).encode(charset)<tab><tab><tab>if not isinstance(value, bytes):<tab><tab><tab><tab>value = str(value).encode(charset)<tab><tab><tab>yield url_quote_plus(key) + ""="" + url_quote_plus(value)",1,if value is None :,if value is None :,0.75,100,1
"def getZoneOffset(d):<tab>zoffs = 0<tab>try:<tab><tab>if d[""zulu""] == None:<tab><tab><tab>zoffs = 60 * int(d[""tzhour""]) + int(d[""tzminute""])<tab><tab><tab><IF-STMT><tab><tab><tab><tab>zoffs = -zoffs<tab>except TypeError:<tab><tab>pass<tab>return zoffs",0,"if d [ ""tzsign"" ] != ""-"" :","elif d [ ""zulu"" ] == None :",0.033243278,15.90938517,0.381818182
"def run(self):<tab>predictor = DefaultPredictor(self.cfg)<tab>while True:<tab><tab>task = self.task_queue.get()<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>idx, data = task<tab><tab>result = predictor(data)<tab><tab>self.result_queue.put((idx, result))",0,"if isinstance ( task , AsyncPredictor . _StopToken ) :",if task is None :,0.014393213,4.234348807,0.285714286
"def _VarRefOrWord(node, dynamic_arith):<tab># type: (arith_expr_t, bool) -> bool<tab>with tagswitch(node) as case:<tab><tab>if case(arith_expr_e.VarRef):<tab><tab><tab>return True<tab><tab>elif case(arith_expr_e.Word):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return True<tab>return False",1,if dynamic_arith :,if dynamic_arith :,0.531170663,1.00E-10,1
"def command(self, reset=True, wait=True, wait_all=False, quiet=False):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return self._success(_(""Loaded metadata index""))<tab><tab>else:<tab><tab><tab>return self._error(_(""Failed to load metadata index""))<tab>except IOError:<tab><tab>return self._error(_(""Failed to decrypt configuration, "" ""please log in!""))",0,"if self . _idx ( reset = reset , wait = wait , wait_all = wait_all , quiet = quiet ) :",if wait and quiet :,0.004137183,0.185472264,0.267857143
"def init_weights(self):<tab>for module in self.decoder.modules():<tab><tab>if isinstance(module, (nn.Linear, nn.Embedding)):<tab><tab><tab>module.weight.data.normal_(mean=0.0, std=0.02)<tab><tab>elif isinstance(module, nn.LayerNorm):<tab><tab><tab>module.bias.data.zero_()<tab><tab><tab>module.weight.data.fill_(1.0)<tab><tab><IF-STMT><tab><tab><tab>module.bias.data.zero_()<tab>for p in self.generator.parameters():<tab><tab>if p.dim() > 1:<tab><tab><tab>xavier_uniform_(p)<tab><tab>else:<tab><tab><tab>p.data.zero_()",0,"if isinstance ( module , nn . Linear ) and module . bias is not None :","elif isinstance ( module , nn . Linear ) :",0.198288089,38.85990008,0.361111111
"def write_conditional_formatting(worksheet):<tab>""""""Write conditional formatting to xml.""""""<tab>wb = worksheet.parent<tab>for range_string, rules in iteritems(worksheet.conditional_formatting.cf_rules):<tab><tab>cf = Element(""conditionalFormatting"", {""sqref"": range_string})<tab><tab>for rule in rules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if rule.dxf != DifferentialStyle():<tab><tab><tab><tab><tab>rule.dxfId = len(wb._differential_styles)<tab><tab><tab><tab><tab>wb._differential_styles.append(rule.dxf)<tab><tab><tab>cf.append(rule.to_tree())<tab><tab>yield cf",0,if rule . dxf is not None :,if rule . dxf :,0.234334509,38.80684295,0.510204082
"def _format_changelog(self, changelog):<tab>""""""Format the changelog correctly and convert it to a list of strings""""""<tab>if not changelog:<tab><tab>return changelog<tab>new_changelog = []<tab>for line in changelog.strip().split(""\n""):<tab><tab>line = line.strip()<tab><tab><IF-STMT><tab><tab><tab>new_changelog.extend(["""", line])<tab><tab>elif line[0] == ""-"":<tab><tab><tab>new_changelog.append(line)<tab><tab>else:<tab><tab><tab>new_changelog.append(""  "" + line)<tab># strip trailing newline inserted by first changelog entry<tab>if not new_changelog[0]:<tab><tab>del new_changelog[0]<tab>return new_changelog",0,"if line [ 0 ] == ""*"" :","if line [ 0 ] == ""+"" :",0.605621306,74.19446627,1
"def __prep_write_total(self, comments, main, fallback, single):<tab>lower = self.as_lowercased()<tab>for k in [main, fallback, single]:<tab><tab>if k in comments:<tab><tab><tab>del comments[k]<tab>if single in lower:<tab><tab>parts = lower[single].split(""/"", 1)<tab><tab><IF-STMT><tab><tab><tab>comments[single] = [parts[0]]<tab><tab>if len(parts) > 1:<tab><tab><tab>comments[main] = [parts[1]]<tab>if main in lower:<tab><tab>comments[main] = lower.list(main)<tab>if fallback in lower:<tab><tab>if main in comments:<tab><tab><tab>comments[fallback] = lower.list(fallback)<tab><tab>else:<tab><tab><tab>comments[main] = lower.list(fallback)",0,if parts [ 0 ] :,if len ( parts ) == 1 :,0.023749772,6.274655311,0.314814815
"def __str__(self):<tab>result = []<tab>for mask, quality in self._parsed:<tab><tab><IF-STMT><tab><tab><tab>mask = ""%s;q=%0.*f"" % (<tab><tab><tab><tab>mask,<tab><tab><tab><tab>min(len(str(quality).split(""."")[1]), 3),<tab><tab><tab><tab>quality,<tab><tab><tab>)<tab><tab>result.append(mask)<tab>return "", "".join(result)",0,if quality != 1 :,if quality is not None :,0.057429006,17.9652056,0.357142857
"def allprocs(self):<tab>common.set_plugin_members(self)<tab>tasksaddr = self.addr_space.profile.get_symbol(""_tasks"")<tab>queue_entry = obj.Object(""queue_entry"", offset=tasksaddr, vm=self.addr_space)<tab>seen = [tasksaddr]<tab>for task in queue_entry.walk_list(list_head=tasksaddr):<tab><tab><IF-STMT><tab><tab><tab>proc = task.bsd_info.dereference_as(""proc"")<tab><tab><tab>yield proc<tab><tab>seen.append(task.obj_offset)",0,if task . bsd_info and task . obj_offset not in seen :,if task . obj_offset not in seen :,0.514949559,52.80640637,0.357142857
"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab>if os.path.isfile(current) and f.endswith(""py""):<tab><tab><tab>if self.module_registrant:<tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab><IF-STMT><tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab>if ret:<tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",1,elif os . path . isdir ( current ) :,elif os . path . isdir ( current ) :,0.75,100,1
"def get_code(self, address: Address) -> bytes:<tab>validate_canonical_address(address, title=""Storage Address"")<tab>code_hash = self.get_code_hash(address)<tab>if code_hash == EMPTY_SHA3:<tab><tab>return b""""<tab>else:<tab><tab>try:<tab><tab><tab>return self._journaldb[code_hash]<tab><tab>except KeyError:<tab><tab><tab>raise MissingBytecode(code_hash) from KeyError<tab><tab>finally:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._accessed_bytecodes.add(address)",0,if code_hash in self . _get_accessed_node_hashes ( ) :,if address not in self . _accessed_bytecodes :,0.177223171,18.56713095,0.3
"def _strftime(value):<tab>if datetime:<tab><tab>if isinstance(value, datetime.datetime):<tab><tab><tab>return ""%04d%02d%02dT%02d:%02d:%02d"" % (<tab><tab><tab><tab>value.year,<tab><tab><tab><tab>value.month,<tab><tab><tab><tab>value.day,<tab><tab><tab><tab>value.hour,<tab><tab><tab><tab>value.minute,<tab><tab><tab><tab>value.second,<tab><tab><tab>)<tab>if not isinstance(value, (TupleType, time.struct_time)):<tab><tab><IF-STMT><tab><tab><tab>value = time.time()<tab><tab>value = time.localtime(value)<tab>return ""%04d%02d%02dT%02d:%02d:%02d"" % value[:6]",0,if value == 0 :,"if not isinstance ( value , datetime . datetime ) :",0.025064683,4.932351569,0.252747253
"def _read_mol2_records(filename):<tab>lines = []<tab>start = True<tab>with open(filename) as handle:<tab><tab>for line in handle:<tab><tab><tab>if line.startswith(""@<TRIPOS>MOLECULE""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>start = False<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>yield lines<tab><tab><tab><tab><tab>lines = []<tab><tab><tab>lines.append(line)",1,if start :,if start :,0.531170663,1.00E-10,1
"def set_column_strategy(self, attrs, strategy, opts=None, opts_only=False):<tab>strategy = self._coerce_strat(strategy)<tab>self.is_class_strategy = False<tab>for attr in attrs:<tab><tab>cloned = self._generate()<tab><tab>cloned.strategy = strategy<tab><tab>cloned._generate_path(self.path, attr, ""column"")<tab><tab>cloned.propagate_to_loaders = True<tab><tab>if opts:<tab><tab><tab>cloned.local_opts.update(opts)<tab><tab><IF-STMT><tab><tab><tab>cloned.is_opts_only = True<tab><tab>cloned._set_path_strategy()<tab>self.is_class_strategy = False",1,if opts_only :,if opts_only :,0.531170663,1.00E-10,1
"def decryptBlock(self, encryptedBlock):<tab>""""""Decrypt a single block""""""<tab>if self.decryptBlockCount == 0:  # first call, process IV<tab><tab><IF-STMT>  # auto decrypt IV?<tab><tab><tab>self.prior_CT_block = encryptedBlock<tab><tab><tab>return """"<tab><tab>else:<tab><tab><tab>assert len(self.iv) == self.blockSize, ""Bad IV size on CBC decryption""<tab><tab><tab>self.prior_CT_block = self.iv<tab>dct = self.baseCipher.decryptBlock(encryptedBlock)<tab>"""""" XOR the prior decrypted CT with the prior CT """"""<tab>dct_XOR_priorCT = xor(self.prior_CT_block, dct)<tab>self.prior_CT_block = encryptedBlock<tab>return dct_XOR_priorCT",0,if self . iv == None :,if len ( encryptedBlock ) == 0 :,0.021135836,11.33958222,0.25
"def frontend_visible_config(config_dict):<tab>visible_dict = {}<tab>for name in CLIENT_WHITELIST:<tab><tab>if name.lower().find(""secret"") >= 0:<tab><tab><tab>raise Exception(""Cannot whitelist secrets: %s"" % name)<tab><tab>if name in config_dict:<tab><tab><tab>visible_dict[name] = config_dict.get(name, None)<tab><tab><IF-STMT><tab><tab><tab>visible_dict[""BRANDING""] = visible_dict.get(""BRANDING"", {})<tab><tab><tab>visible_dict[""BRANDING""][""logo""] = config_dict[""ENTERPRISE_LOGO_URL""]<tab>return visible_dict",0,"if ""ENTERPRISE_LOGO_URL"" in config_dict :","if ""BRANDING"" not in visible_dict :",0.032294704,15.82709999,0.464285714
"def write(self, s):<tab>if self.closed:<tab><tab>raise ValueError(""write to closed file"")<tab>if type(s) not in (unicode, str, bytearray):<tab><tab># See issue #19481<tab><tab>if isinstance(s, unicode):<tab><tab><tab>s = unicode.__getitem__(s, slice(None))<tab><tab>elif isinstance(s, str):<tab><tab><tab>s = str.__str__(s)<tab><tab><IF-STMT><tab><tab><tab>s = bytearray.__str__(s)<tab><tab>else:<tab><tab><tab>raise TypeError(""must be string, not "" + type(s).__name__)<tab>return self.shell.write(s, self.tags)",1,"elif isinstance ( s , bytearray ) :","elif isinstance ( s , bytearray ) :",0.75,100,1
"def __get_kb_shortcuts(directory, filename, default_shortcuts, min_shortcuts):<tab>shortcutstr, source = __read_first_in_directory_tree(directory, filename)<tab>if shortcutstr is None:<tab><tab>shortcutstr = __read_or_default(filename, default_shortcuts)<tab><tab><IF-STMT><tab><tab><tab>source = ""[default kb_shortcuts]""<tab><tab>else:<tab><tab><tab>source = filename<tab>kb_shortcuts = __parse_kb_shortcuts(shortcutstr, min_shortcuts, source)<tab>return kb_shortcuts",0,if shortcutstr == default_shortcuts :,if shortcutstr is None :,0.064978772,12.97584999,0.5
"def demo():<tab>d = StatusProgressDialog(""A Demo"", ""Doing something..."")<tab>import win32api<tab>for i in range(100):<tab><tab><IF-STMT><tab><tab><tab>d.SetText(""Getting there..."")<tab><tab>if i == 90:<tab><tab><tab>d.SetText(""Nearly done..."")<tab><tab>win32api.Sleep(20)<tab><tab>d.Tick()<tab>d.Close()",0,if i == 50 :,if i == 100 :,0.394778655,53.72849659,0.6
"def __getattribute__(self, item):<tab>try:<tab><tab>val = self[item]<tab><tab>if isinstance(val, str):<tab><tab><tab>val = import_string(val)<tab><tab><IF-STMT><tab><tab><tab>val = [import_string(v) if isinstance(v, str) else v for v in val]<tab><tab>self[item] = val<tab>except KeyError:<tab><tab>val = super(ObjDict, self).__getattribute__(item)<tab>return val",0,"elif isinstance ( val , ( list , tuple ) ) :","elif isinstance ( val , list ) :",0.249973561,37.2887864,0.822222222
"def clear(self, key: Optional[str] = None):<tab>with self.lock:<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>rv = self.data[key]<tab><tab><tab><tab>self._heap_acc.remove((rv.acc, key))<tab><tab><tab><tab>self._heap_exp.remove((rv.exp, key))<tab><tab><tab><tab>del self.data[key]<tab><tab><tab><tab>return<tab><tab><tab>except Exception:<tab><tab><tab><tab>return<tab><tab>self.data.clear()<tab><tab>self._heap_acc = []<tab><tab>self._heap_exp = []",0,if key is not None :,if key in self . data :,0.195308626,14.53576842,0.333333333
"def resolve(self, path):<tab>match = self.regex.search(path)<tab>if match:<tab><tab># If there are any named groups, use those as kwargs, ignoring<tab><tab># non-named groups. Otherwise, pass all non-named arguments as<tab><tab># positional arguments.<tab><tab>kwargs = match.groupdict()<tab><tab><IF-STMT><tab><tab><tab>args = ()<tab><tab>else:<tab><tab><tab>args = match.groups()<tab><tab># In both cases, pass any extra_kwargs as **kwargs.<tab><tab>kwargs.update(self.default_args)<tab><tab>return ResolverMatch(self.callback, args, kwargs, self.name)",1,if kwargs :,if kwargs :,0.531170663,1.00E-10,1
"def check_selected(menu, path):<tab>selected = False<tab>if ""url"" in menu:<tab><tab>chop_index = menu[""url""].find(""?"")<tab><tab>if chop_index == -1:<tab><tab><tab>selected = path.startswith(menu[""url""])<tab><tab>else:<tab><tab><tab>selected = path.startswith(menu[""url""][:chop_index])<tab>if ""menus"" in menu:<tab><tab>for m in menu[""menus""]:<tab><tab><tab>_s = check_selected(m, path)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>selected = True<tab>if selected:<tab><tab>menu[""selected""] = True<tab>return selected",1,if _s :,if _s :,0.531170663,1.00E-10,1
"def check_match(word, word_list):<tab>matches = set()<tab>not_matches = set()<tab>for word2 in word_list:<tab><tab>match = truncate_qgram(word, word2)<tab><tab><IF-STMT><tab><tab><tab>matches.add((word, word2))<tab><tab>else:<tab><tab><tab>not_matches.add((word, word2))<tab>return matches, not_matches",0,if match > 0.6 :,if match :,0.067674239,1.00E-10,1
"def _fatal_error(self, exc, message=""Fatal error on pipe transport""):<tab># should be called by exception handler only<tab>if isinstance(exc, (BrokenPipeError, ConnectionResetError)):<tab><tab><IF-STMT><tab><tab><tab>logger.debug(""%r: %s"", self, message, exc_info=True)<tab>else:<tab><tab>self._loop.call_exception_handler(<tab><tab><tab>{<tab><tab><tab><tab>""message"": message,<tab><tab><tab><tab>""exception"": exc,<tab><tab><tab><tab>""transport"": self,<tab><tab><tab><tab>""protocol"": self._protocol,<tab><tab><tab>}<tab><tab>)<tab>self._close(exc)",1,if self . _loop . get_debug ( ) :,if self . _loop . get_debug ( ) :,0.75,100,1
"def remove_existing_header(contents):<tab>""remove existing legal header, if any""<tab>retval = []<tab>skipping = False<tab>start_pattern = re.compile(r""^(/[*]BEGIN_LEGAL)|(#BEGIN_LEGAL)"")<tab>stop_pattern = re.compile(r""^[ ]*(END_LEGAL[ ]?[*]/)|(#[ ]*END_LEGAL)"")<tab>for line in contents:<tab><tab>if start_pattern.match(line):<tab><tab><tab>skipping = True<tab><tab>if skipping == False:<tab><tab><tab>retval.append(line)<tab><tab><IF-STMT><tab><tab><tab>skipping = False<tab>return retval",0,if stop_pattern . match ( line ) :,elif stop_pattern . match ( line ) :,0.400183025,88.01117368,0.6
"def load_model(self, model_dict):<tab>model_param = None<tab>model_meta = None<tab>for _, value in model_dict[""model""].items():<tab><tab>for model in value:<tab><tab><tab>if model.endswith(""Meta""):<tab><tab><tab><tab>model_meta = value[model]<tab><tab><tab><IF-STMT><tab><tab><tab><tab>model_param = value[model]<tab>LOGGER.info(""load model"")<tab>self.set_model_meta(model_meta)<tab>self.set_model_param(model_param)<tab>self.loss = self.get_loss_function()",0,"if model . endswith ( ""Param"" ) :","elif model . endswith ( ""Param"" ) :",0.400183025,88.01117368,0.6
"def __call__(self, exc_type, exc_value, exc_tb):<tab>if not isinstance(exc_value, SystemExit):<tab><tab>enriched_tb = add_missing_qt_frames(exc_tb) if exc_tb else exc_tb<tab><tab>for handler in self._handlers:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break",0,"if handler . handle ( exc_type , exc_value , enriched_tb ) :","if handler ( exc_type , exc_value , enriched_tb ) :",0.402192854,80.04754551,0.736842105
"def skip_to_semicolon(s, i):<tab>n = len(s)<tab>while i < n:<tab><tab>c = s[i]<tab><tab>if c == "";"":<tab><tab><tab>return i<tab><tab>elif c == ""'"" or c == '""':<tab><tab><tab>i = g.skip_string(s, i)<tab><tab>elif g.match(s, i, ""//""):<tab><tab><tab>i = g.skip_to_end_of_line(s, i)<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_block_comment(s, i)<tab><tab>else:<tab><tab><tab>i += 1<tab>return i",1,"elif g . match ( s , i , ""/*"" ) :","elif g . match ( s , i , ""/*"" ) :",0.75,100,1
"def validate(self, signature, timestamp, nonce):<tab>if not self.token:<tab><tab>raise WeixinMsgError(""weixin token is missing"")<tab>if self.expires_in:<tab><tab>try:<tab><tab><tab>timestamp = int(timestamp)<tab><tab>except ValueError:<tab><tab><tab>return False<tab><tab>delta = time.time() - timestamp<tab><tab><IF-STMT><tab><tab><tab>return False<tab>values = [self.token, str(timestamp), str(nonce)]<tab>s = """".join(sorted(values))<tab>hsh = hashlib.sha1(s.encode(""utf-8"")).hexdigest()<tab>return signature == hsh",0,if delta < 0 or delta > self . expires_in :,if delta < 0 :,0.161389483,14.2762397,0.572649573
"def terminate(self):<tab>""""""Terminates process (sends SIGTERM)""""""<tab>if not self._proc is None:<tab><tab><IF-STMT><tab><tab><tab># Windows<tab><tab><tab>self._proc.terminate()<tab><tab>elif HAS_SUBPROCESS:<tab><tab><tab># Gio.Subprocess<tab><tab><tab>self._proc.send_signal(15)<tab><tab>else:<tab><tab><tab># subprocess.Popen<tab><tab><tab>self._proc.terminate()<tab><tab>self._proc = None<tab><tab>if IS_WINDOWS:<tab><tab><tab>self._stdout.close()<tab><tab>self._cancel.cancel()",1,if IS_WINDOWS :,if IS_WINDOWS :,0.531170663,1.00E-10,1
"def clear_bijector(bijector, _, state):<tab>if not isinstance(bijector, tfp.bijectors.Bijector):<tab><tab>return  # skip submodules that are not bijectors<tab>_clear_bijector_cache(bijector)<tab>if isinstance(bijector, tfp.bijectors.Chain):<tab><tab># recursively clear caches of sub-bijectors<tab><tab>for m in bijector.submodules:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>_clear_bijector_cache(m)<tab>return state",0,"if isinstance ( m , tfp . bijectors . Bijector ) :","if isinstance ( m , tfp . bijectors . Chain ) :",0.635663651,76.91605673,0.75
"def sanitize_args(a):<tab>try:<tab><tab>args, kwargs = a<tab><tab>if isinstance(args, tuple) and isinstance(kwargs, dict):<tab><tab><tab>return args, dict(kwargs)<tab>except (TypeError, ValueError):<tab><tab>args, kwargs = (), {}<tab>if a is not None:<tab><tab>if isinstance(a, dict):<tab><tab><tab>args = tuple()<tab><tab><tab>kwargs = a<tab><tab><IF-STMT><tab><tab><tab>if isinstance(a[-1], dict):<tab><tab><tab><tab>args, kwargs = a[0:-1], a[-1]<tab><tab><tab>else:<tab><tab><tab><tab>args = a<tab><tab><tab><tab>kwargs = {}<tab>return args, kwargs",0,"elif isinstance ( a , tuple ) :","elif isinstance ( a , list ) :",0.547301779,59.46035575,0.666666667
"def do_DELE(self, path):<tab>""""""Delete the specified file.""""""<tab>try:<tab><tab>path = self.ftp_path(path)<tab><tab><IF-STMT><tab><tab><tab>self.respond(b""550 Failed to delete file."")<tab><tab>else:<tab><tab><tab>with self.config.vfs.check_access(path=path, user=self._uid, perms=""w""):<tab><tab><tab><tab>self.config.vfs.remove(path)<tab><tab><tab><tab>self.respond(b""250 File removed."")<tab>except FSOperationNotPermitted:<tab><tab>self.respond(b""500 Operation not permitted."")<tab>except (fs.errors.FSError, FilesystemError, FTPPrivilegeException):<tab><tab>self.respond(b""550 Failed to delete file."")",0,if not self . config . vfs . isfile ( path ) :,if not self . config . vfs . exists ( path ) :,0.631506314,76.11606003,0.777777778
"def _get_conn(self):<tab>""""""Get ServerProxy instance""""""<tab>if self.username and self.password:<tab><tab><IF-STMT><tab><tab><tab>raise NotImplementedError()<tab><tab>secure = self.scheme == ""https""<tab><tab>return self.sp(<tab><tab><tab>self.uri,<tab><tab><tab>transport=BasicAuthTransport(secure, self.username, self.password),<tab><tab><tab>**self.sp_kwargs<tab><tab>)<tab>return self.sp(self.uri, **self.sp_kwargs)",0,"if self . scheme == ""scgi"" :","if self . scheme == ""http"" :",0.574113272,70.71067812,1
"def output(self):<tab>""""""Transform self into a list of (name, value) tuples.""""""<tab>header_list = []<tab>for k, v in self.items():<tab><tab><IF-STMT><tab><tab><tab>k = self.encode(k)<tab><tab>if not isinstance(v, basestring):<tab><tab><tab>v = str(v)<tab><tab>if isinstance(v, unicodestr):<tab><tab><tab>v = self.encode(v)<tab><tab># See header_translate_* constants above.<tab><tab># Replace only if you really know what you're doing.<tab><tab>k = k.translate(header_translate_table, header_translate_deletechars)<tab><tab>v = v.translate(header_translate_table, header_translate_deletechars)<tab><tab>header_list.append((k, v))<tab>return header_list",1,"if isinstance ( k , unicodestr ) :","if isinstance ( k , unicodestr ) :",0.75,100,1
"def gprv_implicit_orax(ii):<tab>for i, op in enumerate(_gen_opnds(ii)):<tab><tab><IF-STMT><tab><tab><tab>if op.name == ""REG0"" and op_luf(op, ""GPRv_SB""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>elif i == 1:<tab><tab><tab>if op.name == ""REG1"" and op_luf(op, ""OrAX""):<tab><tab><tab><tab>continue<tab><tab><tab>else:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>return False<tab>return True",1,if i == 0 :,if i == 0 :,0.75,100,1
"def one_xmm_reg_imm8(ii):  # also allows SSE4 2-imm8 instr<tab>i, j, n = 0, 0, 0<tab>for op in _gen_opnds(ii):<tab><tab><IF-STMT><tab><tab><tab>n += 1<tab><tab>elif op_imm8(op):<tab><tab><tab>i += 1<tab><tab>elif op_imm8_2(op):<tab><tab><tab>j += 1<tab><tab>else:<tab><tab><tab>return False<tab>return n == 1 and i == 1 and j <= 1",0,if op_reg ( op ) and op_xmm ( op ) :,if op_reg ( op ) :,0.330022495,41.68620197,0.635416667
"def pa(s, l, tokens):<tab>for attrName, attrValue in attrs:<tab><tab><IF-STMT><tab><tab><tab>raise ParseException(s, l, ""no matching attribute "" + attrName)<tab><tab>if attrValue != withAttribute.ANY_VALUE and tokens[attrName] != attrValue:<tab><tab><tab>raise ParseException(<tab><tab><tab><tab>s,<tab><tab><tab><tab>l,<tab><tab><tab><tab>""attribute '%s' has value '%s', must be '%s'""<tab><tab><tab><tab>% (attrName, tokens[attrName], attrValue),<tab><tab><tab>)",1,if attrName not in tokens :,if attrName not in tokens :,0.75,100,1
"def __code_color(self, code):<tab>if code in self.last_dist.keys():<tab><tab>if int(code) == 0:<tab><tab><tab>return self.screen.markup.GREEN<tab><tab><IF-STMT><tab><tab><tab>return self.screen.markup.MAGENTA<tab><tab>else:<tab><tab><tab>return self.screen.markup.RED<tab>else:<tab><tab>return """"",0,elif int ( code ) == 314 :,elif int ( code ) == 1 :,0.605621306,75.06238538,0.666666667
"def loop_check(self):<tab>in_loop = []<tab># Add the tag for dfs check<tab>for node in self.nodes:<tab><tab>node.dfs_loop_status = ""DFS_UNCHECKED""<tab># Now do the job<tab>for node in self.nodes:<tab><tab># Run the dfs only if the node has not been already done */<tab><tab>if node.dfs_loop_status == ""DFS_UNCHECKED"":<tab><tab><tab>self.dfs_loop_search(node)<tab><tab># If LOOP_INSIDE, must be returned<tab><tab><IF-STMT><tab><tab><tab>in_loop.append(node)<tab># Remove the tag<tab>for node in self.nodes:<tab><tab>del node.dfs_loop_status<tab>return in_loop",0,"if node . dfs_loop_status == ""DFS_LOOP_INSIDE"" :","elif node . dfs_loop_status == ""LOOP_INSIDE"" :",0.205748387,71.95483536,0.5
"def _append_modifier(code, modifier):<tab>if modifier == ""euro"":<tab><tab><IF-STMT><tab><tab><tab>return code + "".ISO8859-15""<tab><tab>_, _, encoding = code.partition(""."")<tab><tab>if encoding in (""ISO8859-15"", ""UTF-8""):<tab><tab><tab>return code<tab><tab>if encoding == ""ISO8859-1"":<tab><tab><tab>return _replace_encoding(code, ""ISO8859-15"")<tab>return code + ""@"" + modifier",1,"if ""."" not in code :","if ""."" not in code :",0.75,100,1
"def propagate_touch_to_touchable_widgets(self, touch, touch_event, *args):<tab>triggered = False<tab>for i in self._touchable_widgets:<tab><tab>if i.collide_point(touch.x, touch.y):<tab><tab><tab>triggered = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>i.on_touch_down(touch)<tab><tab><tab>elif touch_event == ""move"":<tab><tab><tab><tab>i.on_touch_move(touch, *args)<tab><tab><tab>elif touch_event == ""up"":<tab><tab><tab><tab>i.on_touch_up(touch)<tab>return triggered",1,"if touch_event == ""down"" :","if touch_event == ""down"" :",0.75,100,1
"def body(self):<tab>order = [<tab><tab>""ok_header"",<tab><tab>""affected_rows"",<tab><tab>""last_insert_id"",<tab><tab>""server_status"",<tab><tab>""warning_count"",<tab><tab>""state_track"",<tab><tab>""info"",<tab>]<tab>string = b""""<tab>for key in order:<tab><tab>item = getattr(self, key)<tab><tab>section_pack = b""""<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif isinstance(item, bytes):<tab><tab><tab>section_pack = item<tab><tab>else:<tab><tab><tab>section_pack = getattr(self, key).toStringPacket()<tab><tab>string += section_pack<tab>self.setBody(string)<tab>return self._body",1,if item is None :,if item is None :,0.75,100,1
"def get_opnd_types_short(ii):<tab>types = []<tab>for op in _gen_opnds(ii):<tab><tab>if op.oc2:<tab><tab><tab>types.append(op.oc2)<tab><tab>elif op_luf_start(op, ""GPRv""):<tab><tab><tab>types.append(""v"")<tab><tab><IF-STMT><tab><tab><tab>types.append(""z"")<tab><tab>elif op_luf_start(op, ""GPRy""):<tab><tab><tab>types.append(""y"")<tab><tab>else:<tab><tab><tab>die(""Unhandled op type {}"".format(op))<tab>return types",1,"elif op_luf_start ( op , ""GPRz"" ) :","elif op_luf_start ( op , ""GPRz"" ) :",0.75,100,1
"def load_name(self, name):<tab>if name in self.args:<tab><tab>index = self.args[name]<tab><tab><IF-STMT><tab><tab><tab>self.add_opcodes(JavaOpcodes.ALOAD_2(), java.Map.get(name))<tab><tab>else:<tab><tab><tab>self.add_opcodes(<tab><tab><tab><tab>JavaOpcodes.ALOAD_1(),<tab><tab><tab><tab>java.Array.get(index),<tab><tab><tab>)<tab>else:<tab><tab>self.add_opcodes(<tab><tab><tab>ALOAD_name(""#module""),<tab><tab><tab>python.Object.get_attribute(name),<tab><tab>)",0,if index is None :,"if index == ""*"" :",0.064978772,12.22307556,0.5
"def get_field_type(self, name):<tab>fkey = (name, self.dummy)<tab>target = None<tab>op, name = name.split(""_"", 1)<tab>if op in {""delete"", ""insert"", ""update""}:<tab><tab>target = super().get_field_type(name)<tab><tab>if target is None:<tab><tab><tab>module, edb_name = self.get_module_and_name(name)<tab><tab><tab>target = self.edb_schema.get((module, edb_name), None)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>target = self.convert_edb_to_gql_type(target)<tab>self._fields[fkey] = target<tab>return target",0,if target is not None :,"if op == ""convert"" :",0.027136592,6.567274736,0.2
"def _parse_lines(self, lines):<tab>for line in lines:<tab><tab>self.size += len(line)<tab><tab>words = line.strip().split(""\t"")<tab><tab><IF-STMT><tab><tab><tab>wset = set(words[1:])<tab><tab><tab>if words[0] in self.WORDS:<tab><tab><tab><tab>self.WORDS[words[0]] |= wset<tab><tab><tab>else:<tab><tab><tab><tab>self.WORDS[words[0]] = wset",1,if len ( words ) > 1 :,if len ( words ) > 1 :,0.75,100,1
"def get_new_id(self) -> str:<tab>with db.session.no_autoflush:<tab><tab>identifier = self.issued_at.strftime(""%Y%mU-"") + ""%06d"" % (<tab><tab><tab>EventInvoice.query.count() + 1<tab><tab>)<tab><tab>count = EventInvoice.query.filter_by(identifier=identifier).count()<tab><tab><IF-STMT><tab><tab><tab>return identifier<tab><tab>return self.get_new_id()",0,if count == 0 :,if count > 0 :,0.331415021,24.73692954,1
"def complete_use(self, text, *args, **kwargs):<tab>if text:<tab><tab>all_possible_matches = filter(<tab><tab><tab>lambda x: x.startswith(text), self.main_modules_dirs<tab><tab>)<tab><tab>matches = set()<tab><tab>for match in all_possible_matches:<tab><tab><tab>head, sep, tail = match[len(text) :].partition(""."")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>sep = """"<tab><tab><tab>matches.add("""".join((text, head, sep)))<tab><tab>return list(matches)<tab>else:<tab><tab>return self.main_modules_dirs",0,if not tail :,"if sep == ""."" :",0.042407859,6.567274736,0.36
"def get_arg_list_scalar_arg_dtypes(arg_types):<tab>result = []<tab>for arg_type in arg_types:<tab><tab>if isinstance(arg_type, ScalarArg):<tab><tab><tab>result.append(arg_type.dtype)<tab><tab><IF-STMT><tab><tab><tab>result.append(None)<tab><tab><tab>if arg_type.with_offset:<tab><tab><tab><tab>result.append(np.int64)<tab><tab>else:<tab><tab><tab>raise RuntimeError(""arg type not understood: %s"" % type(arg_type))<tab>return result",0,"elif isinstance ( arg_type , VectorArg ) :",elif arg_type is None :,0.118840591,18.09449526,0.333333333
"def psea(pname):<tab>""""""Parse PSEA output file.""""""<tab>fname = run_psea(pname)<tab>start = 0<tab>ss = """"<tab>with open(fname) as fp:<tab><tab>for l in fp:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>start = 1<tab><tab><tab><tab>continue<tab><tab><tab>if not start:<tab><tab><tab><tab>continue<tab><tab><tab>if l[0] == ""\n"":<tab><tab><tab><tab>break<tab><tab><tab>ss = ss + l[0:-1]<tab>return ss",0,"if l [ 0 : 6 ] == "">p-sea"" :","if l [ 0 ] == ""."" :",0.166737974,39.25742067,0.784615385
"def pad_with_zeros(logits, labels):<tab>""""""Pad labels on the length dimension to match logits length.""""""<tab>with tf.name_scope(""pad_with_zeros"", values=[logits, labels]):<tab><tab>logits, labels = pad_to_same_length(logits, labels)<tab><tab><IF-STMT>  # 2-d labels.<tab><tab><tab>logits, labels = pad_to_same_length(logits, labels, axis=2)<tab><tab>return logits, labels",0,if len ( labels . shape ) == 3 :,"if isinstance ( labels , tf . Tensor ) :",0.071690657,9.993744304,0.333333333
"def set_rating(self, value, songs, librarian):<tab>count = len(songs)<tab>if count > 1 and config.getboolean(""browsers"", ""rating_confirm_multiple""):<tab><tab>parent = qltk.get_menu_item_top_parent(self)<tab><tab>dialog = ConfirmRateMultipleDialog(parent, _(""Change _Rating""), count, value)<tab><tab><IF-STMT><tab><tab><tab>return<tab>for song in songs:<tab><tab>song[""~#rating""] = value<tab>librarian.changed(songs)",0,if dialog . run ( ) != Gtk . ResponseType . YES :,if not dialog . is_valid ( ) :,0.02596167,8.804351807,0.227941176
"def test_schema_plugin_name_mismatch(self):<tab># todo iterate over all clouds not just aws resources<tab>for k, v in manager.resources.items():<tab><tab>for fname, f in v.filter_registry.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>self.assertIn(fname, f.schema[""properties""][""type""][""enum""])<tab><tab>for aname, a in v.action_registry.items():<tab><tab><tab>self.assertIn(aname, a.schema[""properties""][""type""][""enum""])",0,"if fname in ( ""or"" , ""and"" , ""not"" ) :","if not f . schema [ ""properties"" ] [ ""type"" ] . match ( k ) :",0.020274364,5.290165775,0.208888889
"def run(self, elem):<tab>""""""Inline check for attrs at start of tail.""""""<tab>if elem.tail:<tab><tab>m = self.INLINE_RE.match(elem.tail)<tab><tab><IF-STMT><tab><tab><tab>self.assign_attrs(elem, m.group(1))<tab><tab><tab>elem.tail = elem.tail[m.end() :]",1,if m :,if m :,0.531170663,1.00E-10,1
"def _traverse(op):<tab>if topi.tag.is_broadcast(op.tag):<tab><tab>if not op.same_as(output.op):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>const_ops.append(op)<tab><tab><tab>else:<tab><tab><tab><tab>ewise_ops.append(op)<tab><tab>for tensor in op.input_tensors:<tab><tab><tab>if isinstance(tensor.op, tvm.te.PlaceholderOp):<tab><tab><tab><tab>ewise_inputs.append((op, tensor))<tab><tab><tab>else:<tab><tab><tab><tab>_traverse(tensor.op)<tab>else:<tab><tab>assert op.tag == ""dense_pack""<tab><tab>dense_res.append(op)",0,if not op . axis :,"if op . tag == ""const"" :",0.047631794,9.980099404,0.30952381
"def toPostArgs(self):<tab>""""""Return all arguments with openid. in front of namespaced arguments.""""""<tab>args = {}<tab># Add namespace definitions to the output<tab>for ns_uri, alias in self.namespaces.iteritems():<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if alias == NULL_NAMESPACE:<tab><tab><tab>ns_key = ""openid.ns""<tab><tab>else:<tab><tab><tab>ns_key = ""openid.ns."" + alias<tab><tab>args[ns_key] = ns_uri<tab>for (ns_uri, ns_key), value in self.args.iteritems():<tab><tab>key = self.getKey(ns_uri, ns_key)<tab><tab>args[key] = value.encode(""UTF-8"")<tab>return args",0,if self . namespaces . isImplicit ( ns_uri ) :,"if ns_uri == """" :",0.014393213,14.44881489,0.36
"def test_issue_530_async(self):<tab>try:<tab><tab>rtm_client = RTMClient(token=""I am not a token"", run_async=True)<tab><tab>await rtm_client.start()<tab><tab>self.fail(""Raising an error here was expected"")<tab>except Exception as e:<tab><tab>self.assertEqual(<tab><tab><tab>""The request to the Slack API failed.\n""<tab><tab><tab>""The server responded with: {'ok': False, 'error': 'invalid_auth'}"",<tab><tab><tab>str(e),<tab><tab>)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>rtm_client.stop()",0,if not rtm_client . _stopped :,if rtm_client . is_alive ( ) :,0.047631794,26.98553467,0.636363636
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.set_format(d.getVarInt32())<tab><tab><tab>continue<tab><tab>if tt == 18:<tab><tab><tab>self.add_path(d.getPrefixedString())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def _iterate_files(self, files, root, include_checksums, relpath):<tab>file_list = {}<tab>for file in files:<tab><tab>exclude = False<tab><tab># exclude defined filename patterns<tab><tab>for pattern in S3Sync.exclude_files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>exclude = True<tab><tab><tab><tab>break<tab><tab>if not exclude:<tab><tab><tab>full_path = root + ""/"" + file<tab><tab><tab>if include_checksums:<tab><tab><tab><tab># get checksum<tab><tab><tab><tab>checksum = self._hash_file(full_path)<tab><tab><tab>else:<tab><tab><tab><tab>checksum = """"<tab><tab><tab>file_list[relpath + file] = [full_path, checksum]<tab>return file_list",1,"if fnmatch . fnmatch ( file , pattern ) :","if fnmatch . fnmatch ( file , pattern ) :",1,100,1
"def globs_relative_to_buildroot(self):<tab>buildroot = get_buildroot()<tab>globs = []<tab>for bundle in self.bundles:<tab><tab>fileset = bundle.fileset<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>elif hasattr(fileset, ""filespec""):<tab><tab><tab>globs += bundle.fileset.filespec[""globs""]<tab><tab>else:<tab><tab><tab># NB(nh): filemap is an OrderedDict, so this ordering is stable.<tab><tab><tab>globs += [fast_relpath(f, buildroot) for f in bundle.filemap.keys()]<tab>super_globs = super().globs_relative_to_buildroot()<tab>if super_globs:<tab><tab>globs += super_globs[""globs""]<tab>return {""globs"": globs}",1,if fileset is None :,if fileset is None :,0.75,100,1
"def __getstate__(self):<tab>state = super(_ExpressionBase, self).__getstate__()<tab>for i in _ExpressionBase.__pickle_slots__:<tab><tab>state[i] = getattr(self, i)<tab>if safe_mode:<tab><tab>state[""_parent_expr""] = None<tab><tab>if self._parent_expr is not None:<tab><tab><tab>_parent_expr = self._parent_expr()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>state[""_parent_expr""] = _parent_expr<tab>return state",1,if _parent_expr is not None :,if _parent_expr is not None :,0.75,100,1
"def content_state_equal(v1, v2):<tab>""Test whether two contentState structures are equal, ignoring 'key' properties""<tab>if type(v1) != type(v2):<tab><tab>return False<tab>if isinstance(v1, dict):<tab><tab>if set(v1.keys()) != set(v2.keys()):<tab><tab><tab>return False<tab><tab>return all(k == ""key"" or content_state_equal(v, v2[k]) for k, v in v1.items())<tab>elif isinstance(v1, list):<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>return all(content_state_equal(a, b) for a, b in zip(v1, v2))<tab>else:<tab><tab>return v1 == v2",1,if len ( v1 ) != len ( v2 ) :,if len ( v1 ) != len ( v2 ) :,1,100,1
"def process_qemu_job(<tab>file_path: str, arch_suffix: str, root_path: Path, results_dict: dict, uid: str):<tab>result = check_qemu_executability(file_path, arch_suffix, root_path)<tab>if result:<tab><tab><IF-STMT><tab><tab><tab>tmp_dict = dict(results_dict[uid][""results""])<tab><tab><tab>tmp_dict.update({arch_suffix: result})<tab><tab>else:<tab><tab><tab>tmp_dict = {arch_suffix: result}<tab><tab>results_dict[uid] = {""path"": file_path, ""results"": tmp_dict}",1,if uid in results_dict :,if uid in results_dict :,0.75,100,1
"def _eq_meet(a, b):<tab>a_dtype, b_dtype = _dtype(a), _dtype(b)<tab>if a_dtype != b_dtype:<tab><tab>higher_dtype = dtypes.promote_types(a_dtype, b_dtype)<tab><tab><IF-STMT><tab><tab><tab>a = convert_element_type(a, b_dtype)<tab><tab>else:<tab><tab><tab>b = convert_element_type(b, a_dtype)<tab>return eq(a, b)",1,if higher_dtype == a_dtype :,if higher_dtype == a_dtype :,0.75,100,1
"def _assign(self, trans, code):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>trans.order = self.order_qs().get(<tab><tab><tab><tab>code=code.rsplit(""-"", 1)[1], event__slug__iexact=code.rsplit(""-"", 1)[0]<tab><tab><tab>)<tab><tab>else:<tab><tab><tab>trans.order = self.order_qs().get(code=code.rsplit(""-"", 1)[-1])<tab>except Order.DoesNotExist:<tab><tab>return JsonResponse({""status"": ""error"", ""message"": _(""Unknown order code"")})<tab>else:<tab><tab>return self._retry(trans)",0,"if ""-"" in code :","if code . startswith ( ""-"" ) :",0.029323261,18.575058,0.4
"def _recalculate(self):<tab># If the parent's path has changed, recalculate _path<tab>parent_path = tuple(self._get_parent_path())  # Make a copy<tab>if parent_path != self._last_parent_path:<tab><tab>spec = self._path_finder(self._name, parent_path)<tab><tab># Note that no changes are made if a loader is returned, but we<tab><tab>#  do remember the new parent path<tab><tab>if spec is not None and spec.loader is None:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self._path = spec.submodule_search_locations<tab><tab>self._last_parent_path = parent_path  # Save the copy<tab>return self._path",0,if spec . submodule_search_locations :,if spec . submodule_search_locations is not None :,0.351498834,63.15552372,0.444444444
"def find_defined_variables(board_config_mks):<tab>re_def = re.compile(""^[\s]*([\w\d_]*)[\s]*:="")<tab>variables = dict()<tab>for board_config_mk in board_config_mks:<tab><tab>for line in open(board_config_mk, encoding=""latin1""):<tab><tab><tab>mo = re_def.search(line)<tab><tab><tab>if mo is None:<tab><tab><tab><tab>continue<tab><tab><tab>variable = mo.group(1)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>if variable not in variables:<tab><tab><tab><tab>variables[variable] = set()<tab><tab><tab>variables[variable].add(board_config_mk[len(TOP) + 1 :])<tab>return variables",0,if variable in white_list :,"if variable . startswith ( ""_"" ) :",0.04979442,9.980099404,0.6
"def ensure_echo_on():<tab>if termios:<tab><tab>fd = sys.stdin<tab><tab>if fd.isatty():<tab><tab><tab>attr_list = termios.tcgetattr(fd)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>attr_list[3] |= termios.ECHO<tab><tab><tab><tab>if hasattr(signal, ""SIGTTOU""):<tab><tab><tab><tab><tab>old_handler = signal.signal(signal.SIGTTOU, signal.SIG_IGN)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>old_handler = None<tab><tab><tab><tab>termios.tcsetattr(fd, termios.TCSANOW, attr_list)<tab><tab><tab><tab>if old_handler is not None:<tab><tab><tab><tab><tab>signal.signal(signal.SIGTTOU, old_handler)",0,if not attr_list [ 3 ] & termios . ECHO :,if attr_list [ 3 ] & termios . ECHO :,0.469999005,84.96364167,0.320512821
def clean(self):<tab>with self._lock:<tab><tab>min_index = min(self.indexes)<tab><tab><IF-STMT><tab><tab><tab>self.repository = self.repository[min_index:]<tab><tab><tab>for pos in xrange(len(self.indexes)):<tab><tab><tab><tab>self.indexes[pos] -= min_index,0,if min_index >= self . CLEANUP_NUM :,if self . repository is not None :,0.122854835,7.966506956,0.357142857
"def generate_changes(self, old):<tab>from weblate.trans.models.change import Change<tab>tracked = ((""slug"", Change.ACTION_RENAME_PROJECT),)<tab>for attribute, action in tracked:<tab><tab>old_value = getattr(old, attribute)<tab><tab>current_value = getattr(self, attribute)<tab><tab><IF-STMT><tab><tab><tab>Change.objects.create(<tab><tab><tab><tab>action=action,<tab><tab><tab><tab>old=old_value,<tab><tab><tab><tab>target=current_value,<tab><tab><tab><tab>project=self,<tab><tab><tab><tab>user=self.acting_user,<tab><tab><tab>)",1,if old_value != current_value :,if old_value != current_value :,0.75,100,1
"def get_voices(cls):<tab>cmd = [""flite"", ""-lv""]<tab>voices = []<tab>with tempfile.SpooledTemporaryFile() as out_f:<tab><tab>subprocess.call(cmd, stdout=out_f)<tab><tab>out_f.seek(0)<tab><tab>for line in out_f:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>voices.extend([x.strip() for x in line[18:].split() if x.strip()])<tab>return voices",0,"if line . startswith ( ""Voices available: "" ) :","if line . startswith ( ""voices"" ) :",0.482029036,53.87551339,1
"def __init__(self, *args, **kwargs):<tab>dict.__init__(self, *args, **kwargs)<tab>for key, value in self.items():<tab><tab>if not isinstance(key, string_types):<tab><tab><tab>raise TypeError(""key must be a str, not {}"".format(type(key)))<tab><tab>if not isinstance(value, NUMERIC_TYPES):<tab><tab><tab>raise TypeError(""value must be a NUMERIC_TYPES, not {}"".format(type(value)))<tab><tab><IF-STMT><tab><tab><tab>self[key] = float(value)",0,"if not isinstance ( value , float ) :","if isinstance ( value , NUMERIC_TYPES ) :",0.182347091,32.46679155,0.3
"def read_track_raw(self, redundancy=1):<tab>self._log(""read track raw"")<tab>data = []<tab>await self.lower.write([CMD_READ_RAW, redundancy])<tab>while True:<tab><tab>packet = await self.lower.read()<tab><tab>if packet[-1] == 0xFF:<tab><tab><tab>raise GlasgowAppletError(""FIFO overflow while reading track"")<tab><tab><IF-STMT><tab><tab><tab>data.append(packet[:-1])<tab><tab><tab>return b"""".join(data)<tab><tab>else:<tab><tab><tab>data.append(packet)",0,elif packet [ - 1 ] == 0xFE :,if len ( packet ) > 0 :,0.014416966,5.114598707,0.125
"def init(self):<tab>""""""Initialize from the database""""""<tab>self.__effect = None<tab>if self.effectID:<tab><tab>self.__effect = next(<tab><tab><tab>(x for x in self.fighter.item.effects.values() if x.ID == self.effectID),<tab><tab><tab>None,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>pyfalog.error(""Effect (id: {0}) does not exist"", self.effectID)<tab><tab><tab>return<tab>self.build()",1,if self . __effect is None :,if self . __effect is None :,0.75,100,1
"def remove(self):<tab>key = self._key<tab>if key not in _key_to_collection:<tab><tab>raise exc.InvalidRequestError(<tab><tab><tab>""No listeners found for event %s / %r / %s ""<tab><tab><tab>% (self.target, self.identifier, self.fn)<tab><tab>)<tab>dispatch_reg = _key_to_collection.pop(key)<tab>for collection_ref, listener_ref in dispatch_reg.items():<tab><tab>collection = collection_ref()<tab><tab>listener_fn = listener_ref()<tab><tab><IF-STMT><tab><tab><tab>collection.remove(self.with_wrapper(listener_fn))",0,if collection is not None and listener_fn is not None :,if listener_fn is not None :,0.387475612,46.53786298,0.206349206
"def atbash(s):<tab>translated = """"<tab>for i in range(len(s)):<tab><tab>n = ord(s[i])<tab><tab>if s[i].isalpha():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>x = n - ord(""A"")<tab><tab><tab><tab>translated += chr(ord(""Z"") - x)<tab><tab><tab>if s[i].islower():<tab><tab><tab><tab>x = n - ord(""a"")<tab><tab><tab><tab>translated += chr(ord(""z"") - x)<tab><tab>else:<tab><tab><tab>translated += s[i]<tab>return translated",1,if s [ i ] . isupper ( ) :,if s [ i ] . isupper ( ) :,0.75,100,1
"def __str__(self, prefix="""", printElemNumber=0):<tab>res = """"<tab>if self.has_cost_:<tab><tab>res += prefix + ""cost <\n""<tab><tab>res += self.cost_.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + "">\n""<tab>cnt = 0<tab>for e in self.version_:<tab><tab>elm = """"<tab><tab><IF-STMT><tab><tab><tab>elm = ""(%d)"" % cnt<tab><tab>res += prefix + (""Version%s {\n"" % elm)<tab><tab>res += e.__str__(prefix + ""  "", printElemNumber)<tab><tab>res += prefix + ""}\n""<tab><tab>cnt += 1<tab>return res",1,if printElemNumber :,if printElemNumber :,0.531170663,1.00E-10,1
"def readwrite(obj, flags):<tab>try:<tab><tab>if flags & select.POLLIN:<tab><tab><tab>obj.handle_read_event()<tab><tab>if flags & select.POLLOUT:<tab><tab><tab>obj.handle_write_event()<tab><tab>if flags & select.POLLPRI:<tab><tab><tab>obj.handle_expt_event()<tab><tab>if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):<tab><tab><tab>obj.handle_close()<tab>except OSError as e:<tab><tab><IF-STMT><tab><tab><tab>obj.handle_error()<tab><tab>else:<tab><tab><tab>obj.handle_close()<tab>except _reraised_exceptions:<tab><tab>raise<tab>except:<tab><tab>obj.handle_error()",0,if e . args [ 0 ] not in _DISCONNECTED :,if e . errno == errno . EAGAIN :,0.094778298,13.74195327,0.323232323
"def mro(cls):<tab>if self.ready:<tab><tab><IF-STMT><tab><tab><tab>B2.__bases__ = (B1,)<tab><tab>if cls.__name__ == ""B2"":<tab><tab><tab>B1.__bases__ = (B2,)<tab>return type.mro(cls)",1,"if cls . __name__ == ""B1"" :","if cls . __name__ == ""B1"" :",0.75,100,1
"def create_hyperswap_volume(self, vol_name, size, units, pool, opts):<tab>vol_name = '""%s""' % vol_name<tab>params = []<tab>if opts[""rsize""] != -1:<tab><tab>is_dr_pool = self.is_volume_type_dr_pools(pool, opts)<tab><tab><IF-STMT><tab><tab><tab>self.check_data_reduction_pool_params(opts)<tab><tab>params = self._get_hyperswap_volume_create_params(opts, is_dr_pool)<tab>hyperpool = ""%s:%s"" % (pool, opts[""peer_pool""])<tab>self.ssh.mkvolume(vol_name, six.text_type(size), units, hyperpool, params)",1,if is_dr_pool :,if is_dr_pool :,0.531170663,1.00E-10,1
"def save_new_objects(self, commit=True):<tab>self.new_objects = []<tab>for form in self.extra_forms:<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab># If someone has marked an add form for deletion, don't save the<tab><tab># object.<tab><tab>if self.can_delete and self._should_delete_form(form):<tab><tab><tab>continue<tab><tab>self.new_objects.append(self.save_new(form, commit=commit))<tab><tab>if not commit:<tab><tab><tab>self.saved_forms.append(form)<tab>return self.new_objects",0,if not form . has_changed ( ) :,if not self . _should_add_form ( form ) :,0.107287287,9.552040807,0.581818182
"def create_monitored_items(event, dispatcher):<tab>print(""Monitored Item"")<tab>for idx in range(len(event.response_params)):<tab><tab><IF-STMT><tab><tab><tab>nodeId = event.request_params.ItemsToCreate[idx].ItemToMonitor.NodeId<tab><tab><tab>print(""Node {0} was created"".format(nodeId))",0,if event . response_params [ idx ] . StatusCode . is_good ( ) :,if event . response_params [ idx ] . ItemToMonitor is not None :,0.376812523,53.66709357,0.424836601
"def close(self, linger=None):<tab>if not self.closed and self._fd is not None:<tab><tab>for event in list(chain(self._recv_futures or [], self._send_futures or [])):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>try:<tab><tab><tab><tab><tab>event.future.cancel()<tab><tab><tab><tab>except RuntimeError:<tab><tab><tab><tab><tab># RuntimeError may be called during teardown<tab><tab><tab><tab><tab>pass<tab><tab>self._clear_io_state()<tab>super(_AsyncSocket, self).close(linger=linger)",0,if not event . future . done ( ) :,if event . future is not None :,0.064268118,19.03868164,0.236111111
"def stop_actors(self, monitor):<tab>""""""Maintain the number of workers by spawning or killing as required""""""<tab>if monitor.cfg.workers:<tab><tab>num_to_kill = len(self.managed_actors) - monitor.cfg.workers<tab><tab>for i in range(num_to_kill, 0, -1):<tab><tab><tab>w, kage = 0, sys.maxsize<tab><tab><tab>for worker in self.managed_actors.values():<tab><tab><tab><tab>age = worker.impl.age<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>w, kage = worker, age<tab><tab><tab>self.manage_actor(monitor, w, True)",0,if age < kage :,if age > kage :,0.081415021,30.21375397,1
"def get_version(module):<tab>for key in version_keys:<tab><tab>if hasattr(module, key):<tab><tab><tab>version = getattr(module, key)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>version = get_version(version)<tab><tab><tab>return version<tab>return ""Unknown""",0,"if isinstance ( version , types . ModuleType ) :",if inspect . isclass ( version ) and inspect . isclass ( version ) :,0.029178416,8.2259647,0.202614379
"def getBigramProb(self, w1, w2):<tab>""prob of seeing words w1 w2 next to each other.""<tab>w1 = w1.lower()<tab>w2 = w2.lower()<tab>val1 = self.bigrams.get(w1)<tab>if val1 != None:<tab><tab>val2 = val1.get(w2)<tab><tab><IF-STMT><tab><tab><tab>return val2<tab><tab>return self.addK / (<tab><tab><tab>self.getUnigramProb(w1) * self.numUniqueWords + self.numUniqueWords<tab><tab>)<tab>return 0",1,if val2 != None :,if val2 != None :,0.75,100,1
"def _getPartAbbreviation(self):<tab>if self._partAbbreviation is not None:<tab><tab>return self._partAbbreviation<tab>elif ""_partAbbreviation"" in self._cache:<tab><tab>return self._cache[""_partAbbreviation""]<tab>else:<tab><tab>pn = None<tab><tab>for e in self.recurse().getElementsByClass(""Instrument""):<tab><tab><tab>pn = e.partAbbreviation<tab><tab><tab>if pn is None:<tab><tab><tab><tab>pn = e.instrumentAbbreviation<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab><tab>self._cache[""_partAbbreviation""] = pn<tab><tab>return pn",0,if pn is not None :,if pn is None :,0.133190283,40.93653765,0.611111111
"def set_value(self, value, storedtime=None):<tab>self.namespace.acquire_write_lock()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>storedtime = time.time()<tab><tab>debug(<tab><tab><tab>""set_value stored time %r expire time %r"", storedtime, self.expire_argument<tab><tab>)<tab><tab>self.namespace.set_value(<tab><tab><tab>self.key,<tab><tab><tab>(storedtime, self.expire_argument, value),<tab><tab><tab>expiretime=self.expire_argument,<tab><tab>)<tab>finally:<tab><tab>self.namespace.release_write_lock()",1,if storedtime is None :,if storedtime is None :,0.75,100,1
"def setRadioSquare(self, title, square=True):<tab>if self.platform == self.MAC:<tab><tab>gui.warn(""Square radiobuttons not available on Mac, for radiobutton %s"", title)<tab>elif not self.ttkFlag:<tab><tab>for k, v in self.widgetManager.group(WIDGET_NAMES.RadioButton).items():<tab><tab><tab>if k.startswith(title + ""-""):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>v.config(indicatoron=1)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>v.config(indicatoron=0)<tab>else:<tab><tab>gui.warn(<tab><tab><tab>""Square radiobuttons not available in ttk mode, for radiobutton %s"", title<tab><tab>)",1,if square :,if square :,0.531170663,1.00E-10,1
"def render_func(self, node):<tab>if node.id in DEFAULT_FUNCTIONS:<tab><tab>f = DEFAULT_FUNCTIONS[node.id]<tab><tab><IF-STMT><tab><tab><tab>return f.sympy_func<tab># special workaround for the ""int"" function<tab>if node.id == ""int"":<tab><tab>return sympy.Function(""int_"")<tab>else:<tab><tab>return sympy.Function(node.id)",0,"if f . sympy_func is not None and isinstance ( f . sympy_func , sympy . FunctionClass ) :","if isinstance ( f , sympy . Function ) :",0.046808252,8.377465883,0.162055336
"def __init__(self, source_definition, **kw):<tab>super(RekallEFilterArtifacts, self).__init__(source_definition, **kw)<tab>for column in self.fields:<tab><tab>if ""name"" not in column or ""type"" not in column:<tab><tab><tab>raise errors.FormatError(<tab><tab><tab><tab>u""Field definition should have both name and type.""<tab><tab><tab>)<tab><tab>mapped_type = column[""type""]<tab><tab><IF-STMT><tab><tab><tab>raise errors.FormatError(u""Unsupported type %s."" % mapped_type)",0,if mapped_type not in self . allowed_types :,if mapped_type not in self . types :,0.605621306,68.01211491,0.80952381
"def run(self, lines):<tab>""""""Match and store Fenced Code Blocks in the HtmlStash.""""""<tab>text = ""\n"".join(lines)<tab>while 1:<tab><tab>m = FENCED_BLOCK_RE.search(text)<tab><tab><IF-STMT><tab><tab><tab>lang = """"<tab><tab><tab>if m.group(""lang""):<tab><tab><tab><tab>lang = LANG_TAG % m.group(""lang"")<tab><tab><tab>code = CODE_WRAP % (lang, self._escape(m.group(""code"")))<tab><tab><tab>placeholder = self.markdown.htmlStash.store(code, safe=True)<tab><tab><tab>text = ""%s\n%s\n%s"" % (text[: m.start()], placeholder, text[m.end() :])<tab><tab>else:<tab><tab><tab>break<tab>return text.split(""\n"")",1,if m :,if m :,0.531170663,1.00E-10,1
"def GetDisplayNameOf(self, pidl, flags):<tab>item = pidl_to_item(pidl)<tab>if flags & shellcon.SHGDN_FORPARSING:<tab><tab><IF-STMT><tab><tab><tab>return item[""name""]<tab><tab>else:<tab><tab><tab>if flags & shellcon.SHGDN_FORADDRESSBAR:<tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEEDITING<tab><tab><tab>else:<tab><tab><tab><tab>sigdn = shellcon.SIGDN_DESKTOPABSOLUTEPARSING<tab><tab><tab>parent = shell.SHGetNameFromIDList(self.pidl, sigdn)<tab><tab><tab>return parent + ""\\"" + item[""name""]<tab>else:<tab><tab>return item[""name""]",0,if flags & shellcon . SHGDN_INFOLDER :,"if self . GetDisplayNameOf ( self . pidl , item [ ""name"" ] ) :",0.016345905,3.009804384,0.232142857
"def test_buffer_play_stop(filled_buffer):<tab>assert filled_buffer.current_position[0] == 0<tab>filled_buffer.play()<tab>for _ in range(100):<tab><tab>assert filled_buffer.is_playing<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>time.sleep(0.001)<tab>else:<tab><tab>pytest.fail(""Did not advance position in buffer while playing."")<tab>filled_buffer.stop()<tab>assert not filled_buffer.is_playing<tab>pos = filled_buffer.current_position<tab>for _ in range(10):<tab><tab>assert filled_buffer.current_position == pos<tab><tab>time.sleep(0.001)",0,if filled_buffer . current_position [ 0 ] > 0 :,if filled_buffer . current_position [ 0 ] == 0 :,0.604939981,74.87402157,1
"def delete_service(service):<tab>try:<tab><tab>win32serviceutil.RemoveService(service)<tab><tab>logger.info(<tab><tab><tab>""Services: Succesfully removed service '{service}'"".format(service=service)<tab><tab>)<tab>except pywintypes.error as e:<tab><tab>errors = (<tab><tab><tab>winerror.ERROR_SERVICE_DOES_NOT_EXIST,<tab><tab><tab>winerror.ERROR_SERVICE_NOT_ACTIVE,<tab><tab><tab>winerror.ERROR_SERVICE_MARKED_FOR_DELETE,<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>logger.exception(<tab><tab><tab><tab>""Services: Failed to remove service '{service}'"".format(service=service)<tab><tab><tab>)",0,if not any ( error == e . winerror for error in errors ) :,if e . winerror not in errors :,0.143263118,10.69482073,0.171428571
"def connect_to_server(self, server_cls):<tab>server = client = None<tab>try:<tab><tab>sock, port = bind_unused_port()<tab><tab>server = server_cls(ssl_options=_server_ssl_options())<tab><tab>server.add_socket(sock)<tab><tab>client = SSLIOStream(socket.socket(), ssl_options=dict(cert_reqs=ssl.CERT_NONE))<tab><tab>yield client.connect((""127.0.0.1"", port))<tab><tab>self.assertIsNotNone(client.socket.cipher())<tab>finally:<tab><tab>if server is not None:<tab><tab><tab>server.stop()<tab><tab><IF-STMT><tab><tab><tab>client.close()",1,if client is not None :,if client is not None :,0.75,100,1
"def allow_request(self, request, view):<tab>request.server = None<tab>allow = True<tab>view_name = view.get_view_name()<tab>allowed_views = [u""System Data"", u""Collectd Data"", u""Legacy System Data""]<tab>if view_name in allowed_views:<tab><tab>server_key = view.kwargs.get(""server_key"")<tab><tab>server = server_model.get_server_by_key(server_key)<tab><tab>if server:<tab><tab><tab>request.server = server  # Needed in the Models<tab><tab><tab>server_status = throttle_status(server=server)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>allow = False<tab>return allow",0,if server_status . allow == False :,if server_status is not None :,0.04155306,28.46946938,0.265306122
"def log_start(self, prefix, msg):<tab>with self._log_lock:<tab><tab><IF-STMT><tab><tab><tab>if self._last_log_prefix is not None:<tab><tab><tab><tab>self._log_file.write(""\n"")<tab><tab><tab>self._log_file.write(prefix)<tab><tab>self._log_file.write(msg)<tab><tab>self._last_log_prefix = prefix",0,if self . _last_log_prefix != prefix :,if prefix is not None :,0.023367003,3.326463783,0.238095238
"def override(self, user_conf: dict):<tab>for k, v in user_conf.items():<tab><tab># handle ES options, don't override entire dict if one key is passed<tab><tab><IF-STMT><tab><tab><tab>for subkey, subval in v.items():<tab><tab><tab><tab>self.SEARCH_CONF[subkey] = subval<tab><tab>else:<tab><tab><tab>setattr(self, k, v)",0,"if k == ""SEARCH_CONF"" :","if isinstance ( v , dict ) :",0.026407399,5.114598707,0.3
"def emit_classattribs(self, typebld):<tab>if hasattr(self, ""_clrclassattribs""):<tab><tab>for attrib_info in self._clrclassattribs:<tab><tab><tab>if isinstance(attrib_info, type):<tab><tab><tab><tab>ci = clr.GetClrType(attrib_info).GetConstructor(())<tab><tab><tab><tab>cab = CustomAttributeBuilder(ci, ())<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cab = attrib_info.GetBuilder()<tab><tab><tab>else:<tab><tab><tab><tab>make_decorator = attrib_info()<tab><tab><tab><tab>cab = make_decorator.GetBuilder()<tab><tab><tab>typebld.SetCustomAttribute(cab)",0,"elif isinstance ( attrib_info , CustomAttributeDecorator ) :","elif hasattr ( attrib_info , ""GetBuilder"" ) :",0.19046088,37.70063805,0.381818182
"def load_classes(module, base, blacklist):<tab>classes = []<tab>for attr in dir(module):<tab><tab>attr = getattr(module, attr)<tab><tab>if inspect.isclass(attr):<tab><tab><tab>if issubclass(attr, base):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>classes.append(attr)<tab>return classes",0,if attr is not base and attr not in blacklist :,if attr not in blacklist :,0.397970546,36.54520756,0.216931217
"def search_scopes(self, key):<tab>for scope in self.scopes:<tab><tab><IF-STMT><tab><tab><tab>return getattr(scope, key)<tab><tab>if hasattr(scope, ""__getitem__""):<tab><tab><tab>if key in scope:<tab><tab><tab><tab>return scope[key]",1,"if hasattr ( scope , key ) :","if hasattr ( scope , key ) :",0.75,100,1
"def get_cfg_dict(self, with_meta=True):<tab>options_dict = self.merged_options<tab>if with_meta:<tab><tab>if self.plugin:<tab><tab><tab>options_dict.update(<tab><tab><tab><tab>{""package"": ""yandextank.plugins.{}"".format(self.plugin)}<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>options_dict.update({""enabled"": self.enabled})<tab>return options_dict",0,if self . enabled is not None :,if self . enabled :,0.234334509,38.80684295,0.510204082
"def render(self, context):<tab>for condition, nodelist in self.conditions_nodelists:<tab><tab><IF-STMT>  # if / elif clause<tab><tab><tab>try:<tab><tab><tab><tab>match = condition.eval(context)<tab><tab><tab>except VariableDoesNotExist:<tab><tab><tab><tab>match = None<tab><tab>else:  # else clause<tab><tab><tab>match = True<tab><tab>if match:<tab><tab><tab>return nodelist.render(context)<tab>return """"",0,if condition is not None :,"if condition . name == ""if"" :",0.045308626,9.287529,0.380952381
"def main():<tab>base = sys.argv[1]<tab>filenames = sys.argv[2:]<tab>out = OutputByLength(base)<tab>n = 0<tab>for filename in filenames:<tab><tab>print(""opening"")<tab><tab>for record in screed.open(filename):<tab><tab><tab>out.save(record.name, record.sequence)<tab><tab><tab>n += 1<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""..."", n)",1,if n % 10000 == 0 :,if n % 10000 == 0 :,0.75,100,1
"def load_cases(full_path):<tab>all_test_data = json.load(open(full_path), object_pairs_hook=OrderedDict)<tab>for test_data in all_test_data:<tab><tab>given = test_data[""given""]<tab><tab>for case in test_data[""cases""]:<tab><tab><tab>if ""result"" in case:<tab><tab><tab><tab>test_type = ""result""<tab><tab><tab>elif ""error"" in case:<tab><tab><tab><tab>test_type = ""error""<tab><tab><tab><IF-STMT><tab><tab><tab><tab>test_type = ""bench""<tab><tab><tab>else:<tab><tab><tab><tab>raise RuntimeError(""Unknown test type: %s"" % json.dumps(case))<tab><tab><tab>yield (given, test_type, case)",1,"elif ""bench"" in case :","elif ""bench"" in case :",0.75,100,1
"def readline(self):<tab>if self.peek is not None:<tab><tab>return """"<tab>line = self.file.readline()<tab>if not line:<tab><tab>return line<tab>if self.boundary:<tab><tab>if line == self.boundary + ""\n"":<tab><tab><tab>self.peek = line<tab><tab><tab>return """"<tab><tab><IF-STMT><tab><tab><tab>self.peek = line<tab><tab><tab>return """"<tab>return line",0,"if line == self . boundary + ""--\n"" :","elif line . startswith ( self . boundary + ""\n"" ) :",0.183981888,34.79159475,0.276190476
"def _get_cache_value(self, key, empty, type):<tab>""""""Used internally by the accessor properties.""""""<tab>if type is bool:<tab><tab>return key in self<tab>if key in self:<tab><tab>value = self[key]<tab><tab>if value is None:<tab><tab><tab>return empty<tab><tab><IF-STMT><tab><tab><tab>try:<tab><tab><tab><tab>value = type(value)<tab><tab><tab>except ValueError:<tab><tab><tab><tab>pass<tab><tab>return value<tab>return None",0,elif type is not None :,if type is not None :,0.546584509,75.98356857,0.714285714
"def _load_from_data(self, data):<tab>super(CliCommandHelpFile, self)._load_from_data(data)<tab>if isinstance(data, str) or not self.parameters or not data.get(""parameters""):<tab><tab>return<tab>loaded_params = []<tab>loaded_param = {}<tab>for param in self.parameters:<tab><tab>loaded_param = next(<tab><tab><tab>(n for n in data[""parameters""] if n[""name""] == param.name), None<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>param.update_from_data(loaded_param)<tab><tab>loaded_params.append(param)<tab>self.parameters = loaded_params",0,if loaded_param :,if loaded_param is not None :,0.090364769,1.00E-10,0.314285714
"def __str__(self):<tab>s = super().__str__()<tab>if self.print_suggestions:<tab><tab>possible_keys = set(self.captured_args) - self.SPECIAL_ARGS<tab><tab><IF-STMT><tab><tab><tab>s += ""\nPossible config keys are: {}"".format(possible_keys)<tab>return s",1,if possible_keys :,if possible_keys :,0.531170663,1.00E-10,1
"def family_add(self, handle_list):<tab>if self.active:<tab><tab>person = self.get_active()<tab><tab><IF-STMT><tab><tab><tab>while not self.change_person(person):<tab><tab><tab><tab>pass<tab><tab>else:<tab><tab><tab>self.change_person(None)<tab>else:<tab><tab>self.dirty = True",1,if person :,if person :,0.531170663,1.00E-10,1
"def recv_into(self, buffer, nbytes=None, flags=0):<tab>if buffer and (nbytes is None):<tab><tab>nbytes = len(buffer)<tab>elif nbytes is None:<tab><tab>nbytes = 1024<tab>if self._sslobj:<tab><tab><IF-STMT><tab><tab><tab>raise ValueError(<tab><tab><tab><tab>""non-zero flags not allowed in calls to recv_into() on %s""<tab><tab><tab><tab>% self.__class__<tab><tab><tab>)<tab><tab>tmp_buffer = self.read(nbytes)<tab><tab>v = len(tmp_buffer)<tab><tab>buffer[:v] = tmp_buffer<tab><tab>return v<tab>else:<tab><tab>return socket.recv_into(self, buffer, nbytes, flags)",1,if flags != 0 :,if flags != 0 :,0.75,100,1
"def removeInsideIslands(self):<tab>self.CleanPath = []<tab>cleanpath = Path(""Path"")<tab>for path in self.NewPaths:<tab><tab>for seg in path:<tab><tab><tab>inside = False<tab><tab><tab>for island in self.IntersectedIslands:<tab><tab><tab><tab>issegin = island.isSegInside(seg) == 1<tab><tab><tab><tab>if issegin:<tab><tab><tab><tab><tab>if not seg in island:<tab><tab><tab><tab><tab><tab>inside = True<tab><tab><tab><tab><tab><tab>break<tab><tab><tab><IF-STMT><tab><tab><tab><tab>cleanpath.append(seg)<tab>cleanpath = cleanpath.split2contours()<tab>self.CleanPath.extend(cleanpath)",1,if not inside :,if not inside :,0.75,100,1
"def ETA(self):<tab>if self.done:<tab><tab>prefix = ""Done""<tab><tab>t = self.elapsed<tab><tab># import pdb; pdb.set_trace()<tab>else:<tab><tab>prefix = ""ETA ""<tab><tab>if self.max is None:<tab><tab><tab>t = -1<tab><tab><IF-STMT><tab><tab><tab>t = 0<tab><tab>else:<tab><tab><tab># import pdb; pdb.set_trace()<tab><tab><tab>t = float(self.max - self.min)<tab><tab><tab>t /= self.cur - self.min<tab><tab><tab>t = (t - 1) * self.elapsed<tab>return ""%s: %s"" % (prefix, self.format_duration(t))",0,elif self . elapsed == 0 or ( self . cur == self . min ) :,elif self . min is None :,0.035928895,6.58336853,0.23
"def columnToDataIndex(self, columnIndex):<tab>c = 0<tab>for dataIndex, accessor in enumerate(self.vectorDataAccessors()):<tab><tab>nc = accessor.numColumns()<tab><tab>if c + nc > columnIndex:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return (dataIndex, -1)<tab><tab><tab>else:<tab><tab><tab><tab>return (dataIndex, columnIndex - c)<tab><tab>c += nc<tab>raise IndexError(columnIndex)",0,if nc == 1 :,if c >= columnIndex - c :,0.027969855,7.267884212,0.30952381
"def as_nodes(self, files):<tab>""""""Returns a list of waflib.Nodes from a list of string of file paths""""""<tab>nodes = []<tab>for x in files:<tab><tab>if not isinstance(x, str):<tab><tab><tab>d = x<tab><tab>else:<tab><tab><tab>d = self.srcnode.find_node(x)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Errors.WafError(""File '%s' was not found"" % x)<tab><tab>nodes.append(d)<tab>return nodes",0,if not d :,if d is None :,0.045150551,14.05853313,0.277777778
"def register_extension(ext):<tab>nonlocal commands<tab>try:<tab><tab>parser = subparsers.add_parser(ext.name)<tab><tab><IF-STMT><tab><tab><tab># current way, class based.<tab><tab><tab>cmd = ext.plugin()<tab><tab><tab>cmd.add_arguments(parser)<tab><tab><tab>cmd.__name__ = ext.name<tab><tab><tab>commands[ext.name] = cmd.handle<tab><tab>else:<tab><tab><tab># old school, function based.<tab><tab><tab>commands[ext.name] = ext.plugin(parser)<tab>except Exception:<tab><tab>logger.exception(""Error while loading command {}."".format(ext.name))",0,"if isinstance ( ext . plugin , type ) and issubclass ( ext . plugin , BaseCommand ) :","if hasattr ( ext , ""plugin"" ) :",0.014937549,5.549921551,0.238666667
"def names(self):<tab>ret = {}<tab>for line in dopen(""/proc/interrupts""):<tab><tab>l = line.split()<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>l1 = l[0].split("":"")[0]<tab><tab>### Cleanup possible names from /proc/interrupts<tab><tab>l2 = "" "".join(l[cpunr + 3 :])<tab><tab>l2 = l2.replace(""_hcd:"", ""/"")<tab><tab>l2 = re.sub(""@pci[:\d+\.]+"", """", l2)<tab><tab>l2 = re.sub(""ahci\[[:\da-z\.]+\]"", ""ahci"", l2)<tab><tab>ret[l1] = l2<tab>return ret",0,if len ( l ) <= cpunr :,if len ( l ) < cpunr :,0.549040681,67.52918218,1
"def formatweekday(self, day, width):<tab>with TimeEncoding(self.locale) as encoding:<tab><tab>if width >= 9:<tab><tab><tab>names = day_name<tab><tab>else:<tab><tab><tab>names = day_abbr<tab><tab>name = names[day]<tab><tab><IF-STMT><tab><tab><tab>name = name.decode(encoding)<tab><tab>return name[:width].center(width)",0,if encoding is not None :,"if isinstance ( name , bytes ) :",0.022316444,6.567274736,0.206349206
"def __walk_dir_tree(self, dirname):<tab>dir_list = []<tab>self.__logger.debug(""__walk_dir_tree. START dir=%s"", dirname)<tab>for f in os.listdir(dirname):<tab><tab>current = os.path.join(dirname, f)<tab><tab><IF-STMT><tab><tab><tab>if self.module_registrant:<tab><tab><tab><tab>self._load_py_from_file(current)<tab><tab><tab>dir_list.append(current)<tab><tab>elif os.path.isdir(current):<tab><tab><tab>ret = self.__walk_dir_tree(current)<tab><tab><tab>if ret:<tab><tab><tab><tab>dir_list.append((f, ret))<tab>return dir_list",0,"if os . path . isfile ( current ) and f . endswith ( ""py"" ) :",if os . path . isfile ( current ) :,0.353503424,37.83557009,0.650793651
"def _EvalInScriptedSection(self, codeBlock, globals, locals=None):<tab>if self.debugManager:<tab><tab>self.debugManager.OnEnterScript()<tab><tab><IF-STMT><tab><tab><tab>return self.debugManager.adb.runeval(codeBlock, globals, locals)<tab><tab>else:<tab><tab><tab>return eval(codeBlock, globals, locals)<tab>else:<tab><tab>return eval(codeBlock, globals, locals)",0,if self . debugManager . adb . appDebugger :,if self . debugManager . adb :,0.413846056,63.19145619,0.814814815
"def load_multiple(fh, position=None, end=None):<tab>loaded = list()<tab>while position < end:<tab><tab>new_box = load(fh, position, end)<tab><tab><IF-STMT><tab><tab><tab>print(""Error, failed to load box."")<tab><tab><tab>return None<tab><tab>loaded.append(new_box)<tab><tab>position = new_box.position + new_box.size()<tab>return loaded",1,if new_box is None :,if new_box is None :,0.75,100,1
"def test_loadTestsFromName__module_not_loaded(self):<tab># We're going to try to load this module as a side-effect, so it<tab># better not be loaded before we try.<tab>#<tab>module_name = ""unittest2.test.dummy""<tab>sys.modules.pop(module_name, None)<tab>loader = unittest2.TestLoader()<tab>try:<tab><tab>suite = loader.loadTestsFromName(module_name)<tab><tab>self.assertIsInstance(suite, loader.suiteClass)<tab><tab>self.assertEqual(list(suite), [])<tab><tab># module should now be loaded, thanks to loadTestsFromName()<tab><tab>self.assertIn(module_name, sys.modules)<tab>finally:<tab><tab><IF-STMT><tab><tab><tab>del sys.modules[module_name]",1,if module_name in sys . modules :,if module_name in sys . modules :,0.75,100,1
"def copy_file(s, d, xform=None):<tab>with open(s, ""rb"") as f:<tab><tab>text = f.read()<tab>if xform:<tab><tab>(d, text) = xform(d, text)<tab>if os.path.exists(d):<tab><tab><IF-STMT><tab><tab><tab>print >>sys.stderr, ""Overwriting %s."" % d<tab><tab>else:<tab><tab><tab>print >>sys.stderr, ""Not overwriting %s."" % d<tab><tab><tab>return<tab>else:<tab><tab>print >>sys.stderr, ""Writing %s."" % d<tab>with open(d, ""wb"") as f:<tab><tab>f.write(text)",0,if opts . force :,if os . path . isfile ( d ) :,0.025806627,5.522397784,0.229166667
"def __setitem__(self, index, image):<tab>if isinstance(index, slice):<tab><tab>tmp_idx = self.current_index<tab><tab>slice_ = self.validate_slice(index)<tab><tab>del self[slice_]<tab><tab>self.extend(image, offset=slice_.start)<tab><tab>self.current_index = tmp_idx<tab>else:<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(<tab><tab><tab><tab>""image must be an instance of wand.image.""<tab><tab><tab><tab>""BaseImage, not "" + repr(image)<tab><tab><tab>)<tab><tab>with self.index_context(index) as index:<tab><tab><tab>library.MagickRemoveImage(self.image.wand)<tab><tab><tab>library.MagickAddImage(self.image.wand, image.wand)",1,"if not isinstance ( image , BaseImage ) :","if not isinstance ( image , BaseImage ) :",0.75,100,1
"def _configure_legacy_instrument_class(self):<tab>if self.inherits:<tab><tab>self.dispatch._update(self.inherits.dispatch)<tab><tab>super_extensions = set(<tab><tab><tab>chain(*[m._deprecated_extensions for m in self.inherits.iterate_to_root()])<tab><tab>)<tab>else:<tab><tab>super_extensions = set()<tab>for ext in self._deprecated_extensions:<tab><tab><IF-STMT><tab><tab><tab>ext._adapt_instrument_class(self, ext)",1,if ext not in super_extensions :,if ext not in super_extensions :,0.75,100,1
"def tearDown(self):<tab>exc, _, _ = sys.exc_info()<tab>if exc:<tab><tab>try:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>diags = self.obj.get_error_diagnostics()<tab><tab><tab><tab>if diags:<tab><tab><tab><tab><tab>for line in diags:<tab><tab><tab><tab><tab><tab>ROOT_LOGGER.info(line)<tab><tab>except BaseException:<tab><tab><tab>pass<tab>if self.captured_logger:<tab><tab>self.captured_logger.removeHandler(self.log_recorder)<tab><tab>self.log_recorder.close()<tab>sys.stdout = self.stdout_backup<tab>super(BZTestCase, self).tearDown()",0,"if hasattr ( self , ""obj"" ) and isinstance ( self . obj , SelfDiagnosable ) :",if self . obj . get_error_diagnostics :,0.060146009,7.659680829,0.222826087
"def number_operators(self, a, b, skip=[]):<tab>dict = {""a"": a, ""b"": b}<tab>for name, expr in self.binops.items():<tab><tab><IF-STMT><tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.binop_test(a, b, res, expr, name)<tab>for name, expr in list(self.unops.items()):<tab><tab>if name not in skip:<tab><tab><tab>name = ""__%s__"" % name<tab><tab><tab>if hasattr(a, name):<tab><tab><tab><tab>res = eval(expr, dict)<tab><tab><tab><tab>self.unop_test(a, res, expr, name)",1,if name not in skip :,if name not in skip :,0.75,100,1
"def _parse_cachecontrol(self, r):<tab>if r not in self._cc_parsed:<tab><tab>cch = r.headers.get(b""Cache-Control"", b"""")<tab><tab>parsed = parse_cachecontrol(cch)<tab><tab><IF-STMT><tab><tab><tab>for key in self.ignore_response_cache_controls:<tab><tab><tab><tab>parsed.pop(key, None)<tab><tab>self._cc_parsed[r] = parsed<tab>return self._cc_parsed[r]",0,"if isinstance ( r , Response ) :",if len ( parsed ) == 0 :,0.020373037,6.74255593,0.25
"def make_pattern(wtree):<tab>subpattern = []<tab>for part in wtree[1:-1]:<tab><tab>if isinstance(part, list):<tab><tab><tab>part = make_pattern(part)<tab><tab><IF-STMT><tab><tab><tab>for c in part:<tab><tab><tab><tab># Meta-characters cannot be quoted<tab><tab><tab><tab>if c in special_chars:<tab><tab><tab><tab><tab>raise GlobError()<tab><tab>subpattern.append(part)<tab>return """".join(subpattern)",0,"elif wtree [ 0 ] != """" :","elif isinstance ( part , str ) :",0.016515822,5.114598707,0.26984127
"def iterjlines(f, header, missing):<tab>it = iter(f)<tab>if header is None:<tab><tab>header = list()<tab><tab>peek, it = iterpeek(it, 1)<tab><tab>json_obj = json.loads(peek)<tab><tab><IF-STMT><tab><tab><tab>header += [k for k in json_obj.keys() if k not in header]<tab>yield tuple(header)<tab>for o in it:<tab><tab>json_obj = json.loads(o)<tab><tab>yield tuple(json_obj[f] if f in json_obj else missing for f in header)",0,"if hasattr ( json_obj , ""keys"" ) :","if isinstance ( json_obj , dict ) :",0.091668085,38.24602283,0.381818182
"def logprob(self, sample):<tab>if self._log:<tab><tab>return self._prob_dict.get(sample, _NINF)<tab>else:<tab><tab>if sample not in self._prob_dict:<tab><tab><tab>return _NINF<tab><tab><IF-STMT><tab><tab><tab>return _NINF<tab><tab>else:<tab><tab><tab>return math.log(self._prob_dict[sample], 2)",0,elif self . _prob_dict [ sample ] == 0 :,elif self . _prob_dict [ sample ] < 0 :,0.603553391,73.24967963,1
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 10:<tab><tab><tab>length = d.getVarInt32()<tab><tab><tab>tmp = ProtocolBuffer.Decoder(d.buffer(), d.pos(), d.pos() + length)<tab><tab><tab>d.skip(length)<tab><tab><tab>self.add_public_certificate_list().TryMerge(tmp)<tab><tab><tab>continue<tab><tab>if tt == 16:<tab><tab><tab>self.set_max_client_cache_time_in_second(d.getVarInt64())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def acquire(self, blocking=True, timeout=None):<tab>if not blocking and timeout is not None:<tab><tab>raise ValueError(""can't specify timeout for non-blocking acquire"")<tab>rc = False<tab>endtime = None<tab>self._cond.acquire()<tab>while self._value == 0:<tab><tab><IF-STMT><tab><tab><tab>break<tab><tab>if timeout is not None:<tab><tab><tab>if endtime is None:<tab><tab><tab><tab>endtime = _time() + timeout<tab><tab><tab>else:<tab><tab><tab><tab>timeout = endtime - _time()<tab><tab><tab><tab>if timeout <= 0:<tab><tab><tab><tab><tab>break<tab><tab>self._cond.wait(timeout)<tab>else:<tab><tab>self._value = self._value - 1<tab><tab>rc = True<tab>self._cond.release()<tab>return rc",0,if not blocking :,if self . _value == 0 :,0.036254648,5.669791111,0.333333333
def run_train_loop(self):<tab>self.begin_training()<tab>for _ in self.yield_train_step():<tab><tab>if self.should_save_model():<tab><tab><tab>self.save_model()<tab><tab>if self.should_save_checkpoint():<tab><tab><tab>self.save_checkpoint()<tab><tab><IF-STMT><tab><tab><tab>self.eval_model()<tab><tab>if self.should_break_training():<tab><tab><tab>break<tab>self.eval_model()<tab>self.done_training()<tab>return self.returned_result(),0,if self . should_eval_model ( ) :,if self . should_eval_training ( ) :,0.38848939,70.16879391,1
"def scrape_me(url_path, **options):<tab>host_name = (<tab><tab>get_host_name(url_path) if not options.get(""test"", False) else ""test_wild_mode""<tab>)<tab>try:<tab><tab>scraper = SCRAPERS[host_name]<tab>except KeyError:<tab><tab><IF-STMT><tab><tab><tab>wild_scraper = SchemaScraperFactory.generate(url_path, **options)<tab><tab><tab>if not wild_scraper.schema.data:<tab><tab><tab><tab>raise NoSchemaFoundInWildMode(url_path)<tab><tab><tab>return wild_scraper<tab><tab>else:<tab><tab><tab>raise WebsiteNotImplementedError(host_name)<tab>return scraper(url_path, **options)",0,"if options . get ( ""wild_mode"" , False ) :","if options . get ( ""test"" , False ) :",0.580308871,62.20700407,1
"def iter_expressions(self):<tab>if not self._isrecord:<tab><tab>tri_attr_context = [(""target"", SPECIAL_INOUT)]<tab>else:<tab><tab>tri_attr_context = [<tab><tab><tab>(""_target_o"", SPECIAL_OUTPUT),<tab><tab><tab>(""_target_oe"", SPECIAL_OUTPUT),<tab><tab><tab>(""_target_i"", SPECIAL_INPUT),<tab><tab>]<tab>tri_attr_context += [<tab><tab>(""o"", SPECIAL_INPUT),<tab><tab>(""oe"", SPECIAL_INPUT),<tab><tab>(""i"", SPECIAL_OUTPUT),<tab>]<tab>for attr, target_context in tri_attr_context:<tab><tab><IF-STMT><tab><tab><tab>yield self, attr, target_context",0,"if getattr ( self , attr ) is not None :",if not self . _isrecord :,0.013607149,5.244835935,0.333333333
"def get_field_values(self, fields):<tab>field_values = []<tab>for field in fields:<tab><tab># Title is special case<tab><tab>if field == ""title"":<tab><tab><tab>value = self.get_title_display()<tab><tab>elif field == ""country"":<tab><tab><tab>try:<tab><tab><tab><tab>value = self.country.printable_name<tab><tab><tab>except exceptions.ObjectDoesNotExist:<tab><tab><tab><tab>value = """"<tab><tab><IF-STMT><tab><tab><tab>value = self.salutation<tab><tab>else:<tab><tab><tab>value = getattr(self, field)<tab><tab>field_values.append(value)<tab>return field_values",1,"elif field == ""salutation"" :","elif field == ""salutation"" :",1,100,1
"def show_panel(panel_id):<tab># Iterate positions to find where panel is and bring it to front.<tab>for position in _positions_names:<tab><tab>pos_panel_ids = _get_position_panels(position)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if len(pos_panel_ids) == 1:<tab><tab><tab>continue<tab><tab>panel_widget = _get_panels_widgets_dict(gui.editor_window)[panel_id]<tab><tab>notebook = _position_notebooks[position]<tab><tab>for i in range(0, notebook.get_n_pages()):<tab><tab><tab>notebook_page = notebook.get_nth_page(i)<tab><tab><tab>if notebook_page == panel_widget:<tab><tab><tab><tab>notebook.set_current_page(i)",1,if len ( pos_panel_ids ) == 0 :,if len ( pos_panel_ids ) == 0 :,0.75,100,1
"def draw(self):<tab>program = self._program<tab>collection = self._collection<tab>mode = collection._mode<tab>if collection._need_update:<tab><tab>collection._update()<tab><tab># self._program.bind(self._vertices_buffer)<tab><tab><IF-STMT><tab><tab><tab>program[""uniforms""] = collection._uniforms_texture<tab><tab><tab>program[""uniforms_shape""] = collection._ushape<tab>if collection._indices_list is not None:<tab><tab>program.draw(mode, collection._indices_buffer)<tab>else:<tab><tab>program.draw(mode)",0,if collection . _uniforms_list is not None :,if collection . _uniforms_texture is not None :,0.501462237,70.16879391,1
"def release(provider, connection, cache=None):<tab>if cache is not None:<tab><tab>db_session = cache.db_session<tab><tab>if db_session is not None and db_session.ddl and cache.saved_fk_state:<tab><tab><tab>try:<tab><tab><tab><tab>cursor = connection.cursor()<tab><tab><tab><tab>sql = ""SET foreign_key_checks = 1""<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>log_orm(sql)<tab><tab><tab><tab>cursor.execute(sql)<tab><tab><tab>except:<tab><tab><tab><tab>provider.pool.drop(connection)<tab><tab><tab><tab>raise<tab>DBAPIProvider.release(provider, connection, cache)",0,if core . local . debug :,if provider . debug :,0.157032291,28.64190458,0.30952381
"def expanded_output(self):<tab>""""""Iterate over output files while dynamic output is expanded.""""""<tab>for f, f_ in zip(self.output, self.rule.output):<tab><tab><IF-STMT><tab><tab><tab>expansion = self.expand_dynamic(f_)<tab><tab><tab>if not expansion:<tab><tab><tab><tab>yield f_<tab><tab><tab>for f, _ in expansion:<tab><tab><tab><tab>file_to_yield = IOFile(f, self.rule)<tab><tab><tab><tab>file_to_yield.clone_flags(f_)<tab><tab><tab><tab>yield file_to_yield<tab><tab>else:<tab><tab><tab>yield f",0,if f in self . dynamic_output :,if f_ . is_dir ( ) :,0.022864977,10.55267032,0.333333333
"def __new__(cls, xs: Tuple[Optional[AbstractValue], core.Value]):<tab>pv, const = xs<tab>if not core.skip_checks:<tab><tab># type checks<tab><tab>assert isinstance(pv, (AbstractValue, type(None))), xs<tab><tab>assert (<tab><tab><tab>isinstance(const, core.Tracer)<tab><tab><tab>or type(const) is Zero<tab><tab><tab>or core.valid_jaxtype(const)<tab><tab>), xs<tab><tab># invariant checks<tab><tab><IF-STMT><tab><tab><tab>assert get_aval(const) == core.abstract_unit, xs<tab>return tuple.__new__(cls, xs)",0,"if isinstance ( pv , AbstractValue ) :",if core . abstract_unit is not None :,0.018078277,4.990049702,0.206349206
"def MenuItemSearch(menu, item):<tab>for menuItem in list(menu.GetMenuItems()):<tab><tab>label = menuItem.GetItemLabel()<tab><tab>if not label:<tab><tab><tab># It's a separator<tab><tab><tab>continue<tab><tab>shortcutItem = Shortcut(menuItem=menuItem)<tab><tab>shortcutItem.FromMenuItem()<tab><tab>item.AppendItem(shortcutItem)<tab><tab>subMenu = menuItem.GetSubMenu()<tab><tab><IF-STMT><tab><tab><tab>MenuItemSearch(subMenu, shortcutItem)",1,if subMenu :,if subMenu :,0.531170663,1.00E-10,1
"def fill_potential_satellites_by_type(self, sat_type):<tab>setattr(self, ""potential_%s"" % sat_type, [])<tab>for satellite in getattr(self, sat_type):<tab><tab>getattr(self, ""potential_%s"" % sat_type).append(satellite)<tab>for realm in self.higher_realms:<tab><tab>for satellite in getattr(realm, sat_type):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>getattr(self, ""potential_%s"" % sat_type).append(satellite)",0,if satellite . manage_sub_realms :,"if hasattr ( self , ""potential_%s"" % sat_type ) :",0.024424144,3.234245292,0.386666667
"def _gen():<tab>while True:<tab><tab>try:<tab><tab><tab>loop_val = it.next()  # e.g. x<tab><tab>except StopIteration:<tab><tab><tab>break<tab><tab>self.mem.SetValue(<tab><tab><tab>lvalue.Named(iter_name), value.Obj(loop_val), scope_e.LocalOnly<tab><tab>)<tab><tab>if comp.cond:<tab><tab><tab>b = self.EvalExpr(comp.cond)<tab><tab>else:<tab><tab><tab>b = True<tab><tab><IF-STMT><tab><tab><tab>item = self.EvalExpr(node.elt)  # e.g. x*2<tab><tab><tab>yield item",1,if b :,if b :,0.531170663,1.00E-10,1
"def _iter_backtick_string(gen, line, back_start):<tab>for _, tokval, start, _, _ in gen:<tab><tab><IF-STMT><tab><tab><tab>return (<tab><tab><tab><tab>BACKTICK_TAG<tab><tab><tab><tab>+ binascii.b2a_hex(line[back_start[1] + 1 : start[1]].encode()).decode()<tab><tab><tab>)<tab>else:<tab><tab>raise SyntaxError(f""backtick quote at {back_start} does not match"")",0,"if tokval == ""`"" :",if tokval == BACKTICK_TAG :,0.144778655,36.55552229,1
"def to_internal_value(self, data):<tab>site = get_current_site()<tab>pages_root = reverse(""pages-root"")<tab>ret = []<tab>for path in data:<tab><tab>if path.startswith(pages_root):<tab><tab><tab>path = path[len(pages_root) :]<tab><tab># strip any final slash<tab><tab>if path.endswith(""/""):<tab><tab><tab>path = path[:-1]<tab><tab>page = get_page_from_path(site, path)<tab><tab><IF-STMT><tab><tab><tab>ret.append(page)<tab>return ret",0,if page :,if page is not None :,0.090364769,1.00E-10,0.4
"def refresh(self):<tab># In MongoTrials, this method fetches from database<tab>if self._exp_key is None:<tab><tab>self._trials = [<tab><tab><tab>tt for tt in self._dynamic_trials if tt[""state""] in JOB_VALID_STATES<tab><tab>]<tab>else:<tab><tab>self._trials = [<tab><tab><tab>tt<tab><tab><tab>for tt in self._dynamic_trials<tab><tab><tab><IF-STMT><tab><tab>]<tab>self._ids.update([tt[""tid""] for tt in self._trials])",0,"if ( tt [ ""state"" ] in JOB_VALID_STATES and tt [ ""exp_key"" ] == self . _exp_key )","if tt [ ""state"" ] in JOB_VALID_STATES",0.1396084,21.57879687,0.592592593
"def create_model(self, model):<tab>for field in model._meta.local_fields:<tab><tab># Autoincrement SQL for backends with post table definition variant<tab><tab>if field.get_internal_type() == ""PositiveAutoField"":<tab><tab><tab>autoinc_sql = self.connection.ops.autoinc_sql(<tab><tab><tab><tab>model._meta.db_table, field.column<tab><tab><tab>)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.deferred_sql.extend(autoinc_sql)<tab>super().create_model(model)",1,if autoinc_sql :,if autoinc_sql :,0.531170663,1.00E-10,1
"def row_match(base_row, row):<tab># ildutil.ild_err(""ILD_DEBUG BASE ROW %s"" % (base_row,))<tab>for (op, val) in list(row.items()):<tab><tab><IF-STMT><tab><tab><tab>if base_row[op] != val:<tab><tab><tab><tab>return False<tab><tab>else:<tab><tab><tab>ildutil.ild_err(<tab><tab><tab><tab>""BASE ROW %s doesn't have OD %s from row %s"" % (base_row, op, row)<tab><tab><tab>)<tab><tab><tab>return None<tab>return True",1,if op in base_row :,if op in base_row :,0.75,100,1
"def get_referrers(self):<tab>d = []<tab>for o in gc.get_referrers(self.obj):<tab><tab>name = None<tab><tab>if isinstance(o, dict):<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><tab>for r in gc.get_referrers(o):<tab><tab><tab><tab>if getattr(r, ""__dict__"", None) is o:<tab><tab><tab><tab><tab>o = r<tab><tab><tab><tab><tab>break<tab><tab>elif isinstance(o, dict):  # other dict types<tab><tab><tab>name = web.dictfind(o, self.obj)<tab><tab><IF-STMT><tab><tab><tab>name = None<tab><tab>d.append(Object(o, name))<tab>return d",0,"if not isinstance ( name , six . string_types ) :",if name is None :,0.012417879,2.838368887,0.240384615
"def _run(env, remote):<tab>if device == ""vta"":<tab><tab>target = env.target<tab><tab><IF-STMT><tab><tab><tab>assert tvm.runtime.enabled(""rpc"")<tab><tab><tab>program_fpga(remote, bitstream=None)<tab><tab><tab>reconfig_runtime(remote)<tab>elif device == ""arm_cpu"":<tab><tab>target = env.target_vta_cpu<tab>with autotvm.tophub.context(target):  # load pre-tuned schedule parameters<tab><tab>for _, wl in resnet_wkls:<tab><tab><tab>print(wl)<tab><tab><tab>run_conv2d(env, remote, wl, target)",0,"if env . TARGET not in [ ""sim"" , ""tsim"" ] :","if env . TARGET == ""fpga"" :",0.113612217,16.58165975,0.645833333
"def retrieve(self, aclass):<tab>""""""Look for a specifc class/name in the packet""""""<tab>resu = []<tab>for x in self.payload:<tab><tab>try:<tab><tab><tab>if isinstance(aclass, str):<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>else:<tab><tab><tab><tab>if isinstance(x, aclass):<tab><tab><tab><tab><tab>resu.append(x)<tab><tab><tab>resu += x.retrieve(aclass)<tab><tab>except:<tab><tab><tab>pass<tab>return resu",0,if x . name == aclass :,"if isinstance ( x , aclass ) :",0.022224574,7.809849842,0.5
"def summary_passes(self):<tab>if self.config.option.tbstyle != ""no"":<tab><tab>if self.hasopt(""P""):<tab><tab><tab>reports = self.getreports(""passed"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return<tab><tab><tab>self.write_sep(""="", ""PASSES"")<tab><tab><tab>for rep in reports:<tab><tab><tab><tab>msg = self._getfailureheadline(rep)<tab><tab><tab><tab>self.write_sep(""_"", msg)<tab><tab><tab><tab>self._outrep_summary(rep)",1,if not reports :,if not reports :,0.75,100,1
"def fn():<tab>random_states = {<tab><tab>name: cls.random_state_function(state_spec=state_spec)()<tab><tab>for name, state_spec in states_spec.items()<tab>}<tab>for name, action_spec in actions_spec.items():<tab><tab><IF-STMT><tab><tab><tab>mask = cls.random_mask(action_spec=action_spec)<tab><tab><tab>random_states[name + ""_mask""] = mask<tab>return random_states",0,"if action_spec [ ""type"" ] == ""int"" :","if isinstance ( action_spec , ( list , tuple ) ) :",0.015810441,11.18304666,0.368421053
"def _show_option(name=None):<tab>if name is None:<tab><tab>name = """"<tab>filename = peda.getfile()<tab>if filename:<tab><tab>filename = os.path.basename(filename)<tab>else:<tab><tab>filename = None<tab>for (k, v) in sorted(config.Option.show(name).items()):<tab><tab><IF-STMT><tab><tab><tab>v = v.replace(""#FILENAME#"", filename)<tab><tab>msg(""%s = %s"" % (k, repr(v)))<tab>return",0,"if filename and isinstance ( v , str ) and ""#FILENAME#"" in v :",if filename :,0.011399193,1.00E-10,0.323529412
"def _set_posonly_args_def(self, argmts, vals):<tab>for v in vals:<tab><tab>argmts.posonlyargs.append(v[""arg""])<tab><tab>d = v[""default""]<tab><tab><IF-STMT><tab><tab><tab>argmts.defaults.append(d)<tab><tab>elif argmts.defaults:<tab><tab><tab>self._set_error(""non-default argument follows default argument"")",1,if d is not None :,if d is not None :,0.75,100,1
def get(self):<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>self._connection = psycopg2.connect(**self._conn_kwargs)<tab><tab><tab>self._connection.autocommit = True<tab><tab><tab>self.server_version = self._connection.server_version<tab>return self._connection,0,if not self . _connection or self . _connection . closed != 0 :,if self . _connection is None :,0.07464066,12.4212989,0.202614379
"def _Determine_Do(self):<tab>if sys.platform == ""darwin"":<tab><tab>self.applicable = True<tab><tab>for opt, optarg in self.chosenOptions:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.value = os.path.abspath(optarg)<tab><tab><tab><tab>break<tab>else:<tab><tab>self.applicable = False<tab>self.determined = True",0,"if opt == ""--"" + self . longopt :","if opt == ""value"" :",0.12918419,34.1077255,0.566666667
"def delete_tags(filenames, v1, v2):<tab>for filename in filenames:<tab><tab>with _sig.block():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print_(u""deleting ID3 tag info in"", filename, file=sys.stderr)<tab><tab><tab>mutagen.id3.delete(filename, v1, v2)",0,if verbose :,"if filename . endswith ( "".id3"" ) :",0.044228356,1.00E-10,0.381818182
"def startJail(self, name):<tab>with self.__lock:<tab><tab>jail = self.__jails[name]<tab><tab>if not jail.isAlive():<tab><tab><tab>jail.start()<tab><tab><IF-STMT><tab><tab><tab>logSys.info(""Jail %r reloaded"", name)<tab><tab><tab>del self.__reload_state[name]<tab><tab>if jail.idle:<tab><tab><tab>jail.idle = False",0,elif name in self . __reload_state :,if name in self . __reload_state :,0.504553356,89.31539818,0.666666667
"def get_field_by_name(obj, field):<tab># Dereference once<tab>if obj.type.code == gdb.TYPE_CODE_PTR:<tab><tab>obj = obj.dereference()<tab>for f in re.split(""(->|\.|\[\d+\])"", field):<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>if f == ""->"":<tab><tab><tab>obj = obj.dereference()<tab><tab>elif f == ""."":<tab><tab><tab>pass<tab><tab>elif f.startswith(""[""):<tab><tab><tab>n = int(f.strip(""[]""))<tab><tab><tab>obj = obj.cast(obj.dereference().type.pointer())<tab><tab><tab>obj += n<tab><tab><tab>obj = obj.dereference()<tab><tab>else:<tab><tab><tab>obj = obj[f]<tab>return obj",0,if not f :,"if f . startswith ( ""."" ) :",0.036611762,5.522397784,0.4
"def _parse_yum_or_zypper_repositories(output):<tab>repos = []<tab>current_repo = {}<tab>for line in output:<tab><tab>line = line.strip()<tab><tab>if not line or line.startswith(""#""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>if current_repo:<tab><tab><tab><tab>repos.append(current_repo)<tab><tab><tab><tab>current_repo = {}<tab><tab><tab>current_repo[""name""] = line[1:-1]<tab><tab>if current_repo and ""="" in line:<tab><tab><tab>key, value = line.split(""="", 1)<tab><tab><tab>current_repo[key] = value<tab>if current_repo:<tab><tab>repos.append(current_repo)<tab>return repos",0,"if line . startswith ( ""["" ) :","if line . startswith ( ""yum"" ) :",0.549040681,65.80370065,1
"def add_to_auto_transitions(cls, base):<tab>result = {}<tab>for name, method in base.__dict__.items():<tab><tab><IF-STMT><tab><tab><tab>for name, transition in method._django_fsm.transitions.items():<tab><tab><tab><tab>if transition.custom.get(""auto""):<tab><tab><tab><tab><tab>result.update({name: method})<tab>return result",0,"if callable ( method ) and hasattr ( method , ""_django_fsm"" ) :","if getattr ( method , ""_django_fsm"" , None ) is not None :",0.363825916,48.40575115,0.258974359
"def commit(cache):<tab>assert cache.is_alive<tab>try:<tab><tab><IF-STMT><tab><tab><tab>cache.flush()<tab><tab>if cache.in_transaction:<tab><tab><tab>assert cache.connection is not None<tab><tab><tab>cache.database.provider.commit(cache.connection, cache)<tab><tab>cache.for_update.clear()<tab><tab>cache.query_results.clear()<tab><tab>cache.max_id_cache.clear()<tab><tab>cache.immediate = True<tab>except:<tab><tab>cache.rollback()<tab><tab>raise",0,if cache . modified :,if not cache . immediate :,0.060348848,19.30486975,0.3
"def block_items(objekt, block, eldict):<tab>if objekt not in block:<tab><tab>if isinstance(objekt.type, PyType):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>block.append(objekt.type)<tab><tab>block.append(objekt)<tab><tab>if isinstance(objekt, PyType):<tab><tab><tab>others = [<tab><tab><tab><tab>p<tab><tab><tab><tab>for p in eldict.values()<tab><tab><tab><tab>if isinstance(p, PyElement) and p.type[1] == objekt.name<tab><tab><tab>]<tab><tab><tab>for item in others:<tab><tab><tab><tab>if item not in block:<tab><tab><tab><tab><tab>block.append(item)<tab>return block",0,if objekt . type not in block :,if not eldict . get ( objekt . type ) :,0.111364467,16.59038701,0.222222222
"def __getattr__(self, item):<tab>import pyarrow.lib<tab>ret = getattr(plasma, item, None)<tab>if ret is None:  # pragma: no cover<tab><tab><IF-STMT><tab><tab><tab>ret = getattr(plasma, ""PlasmaObjectNonexistent"", None) or getattr(<tab><tab><tab><tab>pyarrow.lib, ""PlasmaObjectNonexistent""<tab><tab><tab>)<tab><tab>elif item == ""PlasmaStoreFull"":<tab><tab><tab>ret = getattr(pyarrow.lib, item)<tab>if ret is not None:<tab><tab>setattr(self, item, ret)<tab>return ret",0,"if item == ""PlasmaObjectNotFound"" :","if item == ""PlasmaObjectNonexistent"" :",0.394778655,59.46035575,1
"def clean_str(*args):<tab>tdict = {""str"": 0, ""bytearray"": 1, ""unicode"": 2}<tab>for obj in args:<tab><tab>k = tdict.get(type(obj).__name__)<tab><tab><IF-STMT><tab><tab><tab>raise RuntimeError(""Can not clean object: %s"" % obj)<tab><tab>clean_obj(obj, k)",0,if k is None :,if not k :,0.039449619,16.37226967,0.277777778
"def incoming():<tab>while True:<tab><tab>m = ws.receive()<tab><tab><IF-STMT><tab><tab><tab>m = str(m)<tab><tab><tab>print((m, len(m)))<tab><tab><tab>if len(m) == 35:<tab><tab><tab><tab>ws.close()<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>break<tab>print((""Connection closed!"",))",0,if m is not None :,"if not isinstance ( m , str ) :",0.023585192,6.74255593,0.25
"def TryMerge(self, d):<tab>while d.avail() > 0:<tab><tab>tt = d.getVarInt32()<tab><tab>if tt == 8:<tab><tab><tab>self.add_set_status(d.getVarInt32())<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>raise ProtocolBuffer.ProtocolBufferDecodeError<tab><tab>d.skipData(tt)",1,if tt == 0 :,if tt == 0 :,0.75,100,1
"def __init__(self, text, menu):<tab>self.text = text<tab>self.menu = menu<tab>print(text)<tab>for i, option in enumerate(menu):<tab><tab>menunum = i + 1<tab><tab># Check to see if this line has the 'return to main menu' code<tab><tab>match = re.search(""0D"", option)<tab><tab># If it's not the return to menu line:<tab><tab><IF-STMT><tab><tab><tab>if menunum < 10:<tab><tab><tab><tab>print((""   %s) %s"" % (menunum, option)))<tab><tab><tab>else:<tab><tab><tab><tab>print((""  %s) %s"" % (menunum, option)))<tab><tab>else:<tab><tab><tab>print(""\n  99) Return to Main Menu\n"")<tab>return",0,if not match :,if match :,0.096488528,1.00E-10,0.416666667
def take_step(self):<tab>with self.walk_lock:<tab><tab># Share my random channels<tab><tab>peers = self.overlay.get_peers()<tab><tab><IF-STMT><tab><tab><tab>peer = choice(peers)<tab><tab><tab>self.overlay.send_random_to(peer),1,if peers :,if peers :,0.531170663,1.00E-10,1
"def clear_highlight(self):<tab>for doc in self._window.get_documents():<tab><tab>start, end = doc.get_bounds()<tab><tab><IF-STMT><tab><tab><tab>tag = doc.create_tag(<tab><tab><tab><tab>""result_highlight"", foreground=""yellow"", background=""red""<tab><tab><tab>)<tab><tab>doc.remove_tag_by_name(""result_highlight"", start, end)",0,"if doc . get_tag_table ( ) . lookup ( ""result_highlight"" ) == None :",if start > 0 and end > 0 :,0.009338951,1.196734647,0.209876543
"def impl(self, to_strip=None):<tab>mask = get_nan_mask(self._data._data)<tab>item_count = len(self._data)<tab>res_list = [""""] * item_count<tab>for it in range(item_count):<tab><tab>item = self._data._data[it]<tab><tab><IF-STMT><tab><tab><tab>res_list[it] = usecase(item, to_strip)<tab><tab>else:<tab><tab><tab>res_list[it] = item<tab>str_arr = create_str_arr_from_list(res_list)<tab>result = str_arr_set_na_by_mask(str_arr, mask)<tab>return pandas.Series(result, self._data._index, name=self._data._name)",0,if len ( item ) > 0 :,if to_strip :,0.016200585,1.00E-10,0.345454545
"def modify_subnet_attribute(self):<tab>subnet_id = self._get_param(""SubnetId"")<tab>for attribute in (""MapPublicIpOnLaunch"", ""AssignIpv6AddressOnCreation""):<tab><tab><IF-STMT><tab><tab><tab>attr_name = camelcase_to_underscores(attribute)<tab><tab><tab>attr_value = self.querystring.get(""%s.Value"" % attribute)[0]<tab><tab><tab>self.ec2_backend.modify_subnet_attribute(subnet_id, attr_name, attr_value)<tab><tab><tab>return MODIFY_SUBNET_ATTRIBUTE_RESPONSE",0,"if self . querystring . get ( ""%s.Value"" % attribute ) :",if self . querystring . get ( attribute ) :,0.362928333,39.01319655,1
"def join(s, *p):<tab>path = s<tab>for t in p:<tab><tab>if (not s) or isabs(t):<tab><tab><tab>path = t<tab><tab><tab>continue<tab><tab>if t[:1] == "":"":<tab><tab><tab>t = t[1:]<tab><tab>if "":"" not in path:<tab><tab><tab>path = "":"" + path<tab><tab><IF-STMT><tab><tab><tab>path = path + "":""<tab><tab>path = path + t<tab>return path",1,"if path [ - 1 : ] != "":"" :","if path [ - 1 : ] != "":"" :",0.75,100,1
"def publish(self):<tab># monoproc<tab>if not self.modules.has_option(self.subscriber_name, ""publish""):<tab><tab>return False<tab>dest = self.modules.get(self.subscriber_name, ""publish"")<tab># We can have multiple publisher<tab>for name in dest.split("",""):<tab><tab>self.pubsub.setup_publish(name)<tab>while True:<tab><tab>message = self.r_temp.spop(self.subscriber_name + ""out"")<tab><tab><IF-STMT><tab><tab><tab>time.sleep(1)<tab><tab><tab>continue<tab><tab>self.pubsub.publish(message)",0,if message is None :,"if message == """" :",0.064978772,14.53576842,0.5
"def ignore(self, other):<tab>if isinstance(other, Suppress):<tab><tab><IF-STMT><tab><tab><tab>super().ignore(other)<tab><tab><tab>if self.expr is not None:<tab><tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>else:<tab><tab>super().ignore(other)<tab><tab>if self.expr is not None:<tab><tab><tab>self.expr.ignore(self.ignoreExprs[-1])<tab>return self",1,if other not in self . ignoreExprs :,if other not in self . ignoreExprs :,0.75,100,1
"def recurse(node):<tab>for child in node.childNodes:<tab><tab>if child.nodeType != child.ELEMENT_NODE:<tab><tab><tab>continue<tab><tab>if child.nodeName.upper() == ""H1"":<tab><tab><tab>return child<tab><tab><IF-STMT><tab><tab><tab>return recurse(child)",0,if child not in visited :,"elif child . nodeName . upper ( ) == ""H2"" :",0.066286409,3.377156414,0.213675214
"def req(s, poll, msg, expect):<tab>do_req = True<tab>xid = None<tab>while True:<tab><tab># get transaction id<tab><tab>if do_req:<tab><tab><tab>xid = s.put(msg)[""xid""]<tab><tab># wait for response<tab><tab>events = poll.poll(2)<tab><tab>for (fd, event) in events:<tab><tab><tab>response = s.get()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>do_req = False<tab><tab><tab><tab>continue<tab><tab><tab>if response[""options""][""message_type""] != expect:<tab><tab><tab><tab>raise Exception(""DHCP protocol error"")<tab><tab><tab>return response<tab><tab>do_req = True",0,"if response [ ""xid"" ] != xid :","ifxid and not response [ ""options"" ] [ ""xid"" ] :",0.068377187,30.40559697,0.133333333
"def close(self, invalidate=False):<tab>self.session.transaction = self._parent<tab>if self._parent is None:<tab><tab>for connection, transaction, autoclose in set(self._connections.values()):<tab><tab><tab>if invalidate:<tab><tab><tab><tab>connection.invalidate()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>connection.close()<tab><tab><tab>else:<tab><tab><tab><tab>transaction.close()<tab>self._state = CLOSED<tab>self.session.dispatch.after_transaction_end(self.session, self)<tab>if self._parent is None:<tab><tab>if not self.session.autocommit:<tab><tab><tab>self.session.begin()<tab>self.session = None<tab>self._connections = None",0,if autoclose :,elif not autoclose :,0.091079377,1.00E-10,0.133333333
"def visit_loop(self):<tab>v = self.vS.top_front()<tab>i = self.iS.top_front()<tab>num_edges = len(self.graph[v].edges)<tab># Continue traversing out-edges until none left.<tab>while i <= num_edges:<tab><tab># Continuation<tab><tab>if i > 0:<tab><tab><tab># Update status for previously traversed out-edge<tab><tab><tab>self.finish_edge(v, i - 1)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>i += 1<tab># Finished traversing out edges, update component info<tab>self.finish_visiting(v)",0,"if i < num_edges and self . begin_edge ( v , i ) :",if i == num_edges - 1 :,0.017669125,9.23671211,0.35839599
"def get_objects(self):<tab>list_type, id, handles, timestamp = self._obj_list<tab>retval = []<tab>for (target, handle) in handles:<tab><tab>_class = map2class(target)<tab><tab><IF-STMT><tab><tab><tab>obj = _class(self._dbstate, pickle.dumps((target, id, handle, timestamp)))<tab><tab><tab>if obj:<tab><tab><tab><tab>retval.append(obj)<tab>return retval",1,if _class :,if _class :,0.531170663,1.00E-10,1
"def __init__(self, config_lists):<tab>self.lens = len(config_lists)<tab>self.spaces = []<tab>for config_list in config_lists:<tab><tab>if isinstance(config_list, tuple):<tab><tab><tab>key, config = config_list<tab><tab><IF-STMT><tab><tab><tab>key = config_list<tab><tab><tab>config = None<tab><tab>else:<tab><tab><tab>raise NotImplementedError(<tab><tab><tab><tab>""the type of config is Error!!! Please check the config information. Receive the type of config is {}"".format(<tab><tab><tab><tab><tab>type(config_list)<tab><tab><tab><tab>)<tab><tab><tab>)<tab><tab>self.spaces.append(self._get_single_search_space(key, config))<tab>self.init_tokens()",1,"elif isinstance ( config_list , str ) :","elif isinstance ( config_list , str ) :",0.75,100,1
"def fieldset_string_to_field(fieldset_dict, model):<tab>if isinstance(fieldset_dict[""fields""], tuple):<tab><tab>fieldset_dict[""fields""] = list(fieldset_dict[""fields""])<tab>i = 0<tab>for dict_field in fieldset_dict[""fields""]:<tab><tab><IF-STMT><tab><tab><tab>fieldset_dict[""fields""][i] = model._meta.get_field_by_name(dict_field)[0]<tab><tab>elif isinstance(dict_field, list) or isinstance(dict_field, tuple):<tab><tab><tab>dict_field[1][""recursive""] = True<tab><tab><tab>fieldset_string_to_field(dict_field[1], model)<tab><tab>i += 1",0,"if isinstance ( dict_field , string_types ) :","if isinstance ( dict_field , str ) :",0.549040681,57.89300675,0.727272727
"def _get_directories(config):<tab>for directory in config[""dump_directories""]:<tab><tab>for dname in sorted(glob.glob(os.path.join(directory, ""*[Aa]*[Xx][XxYy23]""))):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>yield dname",0,if os . path . isdir ( dname ) :,"if os . path . isfile ( os . path . join ( directory , dname ) ) :",0.237604232,24.29335519,0.351851852
"def process_event(self, event):<tab>super().process_event(event)<tab>if event.type == pygame.USEREVENT:<tab><tab><IF-STMT><tab><tab><tab>self.input_op(event.ui_object_id[-1])<tab><tab><tab>return True",0,if event . user_type == pygame_gui . UI_BUTTON_PRESSED :,"if event . ui_object_id [ - 1 ] == ""op"" :",0.124620255,11.30608235,0.735294118
"def _restore_std_streams(self):<tab>stdout = sys.stdout.getvalue()<tab>stderr = sys.stderr.getvalue()<tab>close = [sys.stdout, sys.stderr]<tab>sys.stdout = sys.__stdout__<tab>sys.stderr = sys.__stderr__<tab>for stream in close:<tab><tab>stream.close()<tab>if stdout and stderr:<tab><tab>if not stderr.startswith((""*TRACE*"", ""*DEBUG*"", ""*INFO*"", ""*HTML*"", ""*WARN*"")):<tab><tab><tab>stderr = ""*INFO* %s"" % stderr<tab><tab><IF-STMT><tab><tab><tab>stdout += ""\n""<tab>return self._handle_binary_result(stdout + stderr)",0,"if not stdout . endswith ( ""\n"" ) :",if stdout :,0.076454293,1.00E-10,0.366666667
"def _get_attachments(self):<tab>if self._attachments is None:<tab><tab>alist = []<tab><tab>for a in self._message.get_attachments():<tab><tab><tab>alist.append((AttachmentWidget(a), None))<tab><tab><IF-STMT><tab><tab><tab>self._attachments = SimpleTree(alist)<tab>return self._attachments",1,if alist :,if alist :,0.531170663,1.00E-10,1
"def __getattr__(self, name):<tab># if the aval property raises an AttributeError, gets caught here<tab>assert skip_checks or name != ""aval""<tab>try:<tab><tab>attr = getattr(self.aval, name)<tab>except KeyError as err:<tab><tab>raise AttributeError(<tab><tab><tab>""{} has no attribute {}"".format(self.__class__.__name__, name)<tab><tab>) from err<tab>else:<tab><tab>t = type(attr)<tab><tab>if t is aval_property:<tab><tab><tab>return attr.fget(self)<tab><tab><IF-STMT><tab><tab><tab>return types.MethodType(attr.fun, self)<tab><tab>else:<tab><tab><tab>return attr",0,elif t is aval_method :,elif t is type ( attr ) :,0.233366511,22.08959113,0.625
"def _find_first_unescaped(dn, char, pos):<tab>while True:<tab><tab>pos = dn.find(char, pos)<tab><tab><IF-STMT><tab><tab><tab>break  # no char found<tab><tab>if pos > 0 and dn[pos - 1] != ""\\"":  # unescaped char<tab><tab><tab>break<tab><tab>elif pos > 1 and dn[pos - 1] == ""\\"":  # may be unescaped<tab><tab><tab>escaped = True<tab><tab><tab>for c in dn[pos - 2 : 0 : -1]:<tab><tab><tab><tab>if c == ""\\"":<tab><tab><tab><tab><tab>escaped = not escaped<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>break<tab><tab><tab>if not escaped:<tab><tab><tab><tab>break<tab><tab>pos += 1<tab>return pos",0,if pos == - 1 :,if pos < 0 :,0.051719732,15.84873897,0.6
"def test_synopsis(self):<tab>self.addCleanup(unlink, TESTFN)<tab>for encoding in (""ISO-8859-1"", ""UTF-8""):<tab><tab>with open(TESTFN, ""w"", encoding=encoding) as script:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>print(""#coding: {}"".format(encoding), file=script)<tab><tab><tab>print('""""""line 1: h\xe9', file=script)<tab><tab><tab>print('line 2: hi""""""', file=script)<tab><tab>synopsis = pydoc.synopsis(TESTFN, {})<tab><tab>self.assertEqual(synopsis, ""line 1: h\xe9"")",0,"if encoding != ""UTF-8"" :","if encoding != ""ISO-8859-1"" :",0.394778655,45.18010018,1
"def qualify(x):<tab>parts = x.split("";"", 1)<tab>if len(parts) == 2:<tab><tab>match = re.match(r""(^|;)q=(0(\.\d{,3})?|1(\.0{,3})?)(;|$)"", parts[1])<tab><tab><IF-STMT><tab><tab><tab>return parts[0].strip(), float(match.group(2))<tab>return parts[0].strip(), 1",1,if match :,if match :,0.531170663,1.00E-10,1
"def getEndpoints(self):<tab>endpoints = self.endpoints[:]<tab>for i in range(len(endpoints)):<tab><tab>ep = endpoints[i]<tab><tab><IF-STMT><tab><tab><tab>raise TypeError(""Not an Endpoint subclass"")<tab><tab>endpoints[i] = ep(self, self.master)<tab>return endpoints",0,"if not issubclass ( ep , Endpoint ) :","if not isinstance ( ep , Endpoint ) :",0.581882088,66.06328636,0.714285714
"def __getitem__(self, index):<tab>if cfg.RPN.ENABLED:<tab><tab>return self.get_rpn_sample(index)<tab>elif cfg.RCNN.ENABLED:<tab><tab><IF-STMT><tab><tab><tab>if cfg.RCNN.ROI_SAMPLE_JIT:<tab><tab><tab><tab>return self.get_rcnn_sample_jit(index)<tab><tab><tab>else:<tab><tab><tab><tab>return self.get_rcnn_training_sample_batch(index)<tab><tab>else:<tab><tab><tab>return self.get_proposal_from_file(index)<tab>else:<tab><tab>raise NotImplementedError",0,"if self . mode == ""TRAIN"" :",if cfg . RPN . TRAIN_SAMPLE_BATCH :,0.022864977,5.30015669,0.333333333
"def test_data_path(self, filename):<tab>repository_dir = self._repository_dir<tab>test_data = None<tab>if repository_dir:<tab><tab>return self.__walk_test_data(dir=repository_dir, filename=filename)<tab>else:<tab><tab>if self.tool_dir:<tab><tab><tab>tool_dir = self.tool_dir<tab><tab><tab><IF-STMT><tab><tab><tab><tab>tool_dir = os.path.dirname(self.tool_dir)<tab><tab><tab>test_data = self.__walk_test_data(tool_dir, filename=filename)<tab>if not test_data:<tab><tab>test_data = self.app.test_data_resolver.get_filename(filename)<tab>return test_data",0,"if isinstance ( self , DataManagerTool ) :",if not os . path . isabs ( self . tool_dir ) :,0.035266244,7.859438682,0.208333333
"def generate_forwards(cls, attrs):<tab># forward functions of _forwards<tab>for attr_name, attr in cls._forwards.__dict__.items():<tab><tab>if attr_name.startswith(""_"") or attr_name in attrs:<tab><tab><tab>continue<tab><tab>if isinstance(attr, property):<tab><tab><tab>cls._forward.append(attr_name)<tab><tab><IF-STMT><tab><tab><tab>wrapper = _forward_factory(cls, attr_name, attr)<tab><tab><tab>setattr(cls, attr_name, wrapper)<tab><tab>else:<tab><tab><tab>raise TypeError(attr_name, type(attr))",0,"elif isinstance ( attr , types . FunctionType ) :",elif callable ( attr ) :,0.116589036,12.46298934,0.404761905
"def summary(result):<tab>if not self.options.metadata_to_dict:<tab><tab><IF-STMT><tab><tab><tab>pprint(Fore.CYAN + result[""title""] + Fore.RESET)<tab><tab><tab>pprint(<tab><tab><tab><tab>Fore.CYAN<tab><tab><tab><tab>+ Style.DIM<tab><tab><tab><tab>+ result[""written_at""]<tab><tab><tab><tab>+ Style.RESET_ALL<tab><tab><tab><tab>+ Fore.RESET<tab><tab><tab>)<tab><tab><tab>pprint(result[""body""])<tab><tab>writer.write(""@title:"" + result[""title""])<tab><tab>writer.write(""@written_at:"" + result[""written_at""])<tab><tab>writer.write(""@body:"" + result[""body""])<tab>else:<tab><tab>if self.options.verbose:<tab><tab><tab>pprint(result)<tab><tab>writer.write(result)",1,if self . options . verbose :,if self . options . verbose :,0.75,100,1
"def visit_StringConstant(self, node: qlast.StringConstant) -> None:<tab>if not _NON_PRINTABLE_RE.search(node.value):<tab><tab>for d in (""'"", '""', ""$$""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>if ""\\"" in node.value and d != ""$$"":<tab><tab><tab><tab><tab>self.write(""r"", d, node.value, d)<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>self.write(d, node.value, d)<tab><tab><tab><tab>return<tab><tab>self.write(edgeql_quote.dollar_quote_literal(node.value))<tab><tab>return<tab>self.write(repr(node.value))",0,if d not in node . value :,"if d != ""$$"" :",0.035401841,10.55267032,0.357142857
"def get_sql_date_trunc(col, db=""default"", grouper=""hour""):<tab>conn = connections[db]<tab>engine = get_db_engine(db)<tab># TODO: does extract work for sqlite?<tab>if engine.startswith(""oracle""):<tab><tab>method = DATE_TRUNC_GROUPERS[""oracle""].get(<tab><tab><tab>grouper, DATE_TRUNC_GROUPERS[""default""][grouper]<tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>col = '""%s""' % col.upper()<tab>else:<tab><tab>method = DATE_TRUNC_GROUPERS[""default""][grouper]<tab>return conn.ops.date_trunc_sql(method, col)",0,"if '""' not in col :",if method is None :,0.152136592,6.971729122,0.25
"def req(s, poll, msg, expect):<tab>do_req = True<tab>xid = None<tab>while True:<tab><tab># get transaction id<tab><tab>if do_req:<tab><tab><tab>xid = s.put(msg)[""xid""]<tab><tab># wait for response<tab><tab>events = poll.poll(2)<tab><tab>for (fd, event) in events:<tab><tab><tab>response = s.get()<tab><tab><tab>if response[""xid""] != xid:<tab><tab><tab><tab>do_req = False<tab><tab><tab><tab>continue<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise Exception(""DHCP protocol error"")<tab><tab><tab>return response<tab><tab>do_req = True",0,"if response [ ""options"" ] [ ""message_type"" ] != expect :","if not expect ( fd , event ) :",0.013411255,2.308316689,0.408163265
"def __init__(self, f):<tab>self._refs = {}<tab>self._peeled = {}<tab>for line in f.readlines():<tab><tab>sha, name = line.rstrip(b""\n"").split(b""\t"")<tab><tab><IF-STMT><tab><tab><tab>name = name[:-3]<tab><tab><tab>if not check_ref_format(name):<tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._peeled[name] = sha<tab><tab>else:<tab><tab><tab>if not check_ref_format(name):<tab><tab><tab><tab>raise ValueError(""invalid ref name %r"" % name)<tab><tab><tab>self._refs[name] = sha",0,if name . endswith ( ANNOTATED_TAG_SUFFIX ) :,"if name . endswith ( b""refs/"" ) :",0.299040681,36.46285862,1
"def get_defines(clang_output):<tab>import re<tab>defines = []<tab>for line in output.splitlines():<tab><tab>m = re.search(r""#define ([\w()]+) (.+)"", line)<tab><tab><IF-STMT><tab><tab><tab>defines.append(""-D{}={}"".format(m.group(1), m.group(2)))<tab><tab>else:<tab><tab><tab>m = re.search(r""#define (\w+)"", line)<tab><tab><tab>if m is not None:<tab><tab><tab><tab>defines.append(""-D{}"".format(m.group(1)))<tab>_log.debug(""Got defines: %s"", defines)<tab>return defines",1,if m is not None :,if m is not None :,0.75,100,1
"def clean_rcs_keywords(paragraph, keyword_substitutions):<tab>if len(paragraph) == 1 and isinstance(paragraph[0], nodes.Text):<tab><tab>textnode = paragraph[0]<tab><tab>for pattern, substitution in keyword_substitutions:<tab><tab><tab>match = pattern.search(textnode.data)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>textnode.data = pattern.sub(substitution, textnode.data)<tab><tab><tab><tab>return",1,if match :,if match :,0.531170663,1.00E-10,1
"def reorder_incremental_state(<tab>self, incremental_state: Dict[str, Dict[str, Optional[Tensor]]], new_order):<tab>""""""Reorder buffered internal state (for incremental generation).""""""<tab>input_buffer = self._get_input_buffer(incremental_state)<tab>if input_buffer is not None:<tab><tab>for k in input_buffer.keys():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>input_buffer[k] = input_buffer[k].index_select(0, new_order)<tab><tab>incremental_state = self._set_input_buffer(incremental_state, input_buffer)<tab>return incremental_state",0,if input_buffer [ k ] is not None :,"if isinstance ( input_buffer [ k ] , Tensor ) :",0.200500271,40.89601472,0.240384615
"def render(cls) -> str:<tab>buf = render_utils.RenderBuffer()<tab>buf.write(f""struct {cls.__name__} {{"")<tab>with buf.indent():<tab><tab>for fieldname, field in cls._fields.items():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>buf.write_comment(field.doc)<tab><tab><tab>field.render_field(fieldname, buf)<tab><tab><tab>buf.newline()<tab>if buf.lastline() == """":<tab><tab>buf.popline()<tab>buf.write(""};"")<tab>return str(buf)",1,if field . doc :,if field . doc :,0.75,100,1
"def prepare_text(text, style):<tab>body = []<tab>for fragment, sty in parse_tags(text, style, subs.styles):<tab><tab>fragment = fragment.replace(r""\h"", "" "")<tab><tab>fragment = fragment.replace(r""\n"", ""\n"")<tab><tab>fragment = fragment.replace(r""\N"", ""\n"")<tab><tab><IF-STMT><tab><tab><tab>fragment = ""<i>%s</i>"" % fragment<tab><tab>if sty.underline:<tab><tab><tab>fragment = ""<u>%s</u>"" % fragment<tab><tab>if sty.strikeout:<tab><tab><tab>fragment = ""<s>%s</s>"" % fragment<tab><tab>if sty.drawing:<tab><tab><tab>raise ContentNotUsable<tab><tab>body.append(fragment)<tab>return re.sub(""\n+"", ""\n"", """".join(body).strip())",0,if sty . italic :,if sty . underline :,0.394778655,42.72870064,0.6
"def _show_warnings(self):<tab>if self._warnings_handled:<tab><tab>return<tab>self._warnings_handled = True<tab>if self._result and (self._result.has_next or not self._result.warning_count):<tab><tab>return<tab>ws = self._get_db().show_warnings()<tab>if ws is None:<tab><tab>return<tab>for w in ws:<tab><tab>msg = w[-1]<tab><tab>if PY2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = msg.encode(""utf-8"", ""replace"")<tab><tab>warnings.warn(err.Warning(*w[1:3]), stacklevel=4)",0,"if isinstance ( msg , unicode ) :","if isinstance ( msg , str ) :",0.549040681,59.46035575,0.666666667
"def scrub_time(self, time):  # used externally to set time by slider scrubbing<tab>debug(""scrub_time: {0}"".format(time))<tab>if time == 0:<tab><tab>self.loop_backward()<tab>elif time == self.timer_duration:<tab><tab>self.loop_forward()<tab>else:  # time in between 0 and duration<tab><tab>if self.timer_status == TIMER_STATUS_STOPPED:<tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab><tab><IF-STMT><tab><tab><tab>self.timer_status = TIMER_STATUS_PAUSED<tab>self.timer_time = time",0,elif self . timer_status == TIMER_STATUS_EXPIRED :,elif self . timer_status == TIMER_STATUS_PAUSED :,0.821729442,85.55261859,1
"def _default_import_run(run, dest, move, copy_resources):<tab>if move:<tab><tab>log.info(""Moving %s"", run.id)<tab><tab><IF-STMT><tab><tab><tab>shutil.copytree(run.path, dest)<tab><tab><tab>util.safe_rmtree(run.path)<tab><tab>else:<tab><tab><tab>shutil.move(run.path, dest)<tab>else:<tab><tab>log.info(""Copying %s"", run.id)<tab><tab>shutil.copytree(run.path, dest, symlinks=not copy_resources)",1,if copy_resources :,if copy_resources :,0.531170663,1.00E-10,1
"def fn(n):<tab>while n < 3:<tab><tab><IF-STMT><tab><tab><tab>yield ""less than zero""<tab><tab>elif n == 0:<tab><tab><tab>yield ""zero""<tab><tab>elif n == 1:<tab><tab><tab>yield ""one""<tab><tab>else:<tab><tab><tab>yield ""more than one""<tab><tab>n += 1",0,if n < 0 :,if n == 1 :,0.314978772,17.9652056,0.6
"def _check_dep_names(self):<tab>""""""check if user input task_dep or setup_task that doesnt exist""""""<tab># check task-dependencies exist.<tab>for task in self.tasks.values():<tab><tab>for dep in task.task_dep:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>msg = ""%s. Task dependency '%s' does not exist.""<tab><tab><tab><tab>raise InvalidTask(msg % (task.name, dep))<tab><tab>for setup_task in task.setup_tasks:<tab><tab><tab>if setup_task not in self.tasks:<tab><tab><tab><tab>msg = ""Task '%s': invalid setup task '%s'.""<tab><tab><tab><tab>raise InvalidTask(msg % (task.name, setup_task))",1,if dep not in self . tasks :,if dep not in self . tasks :,0.75,100,1
"def urls():<tab>for scheme in (b""http"", b""https""):<tab><tab>for host in (b""example.com"",):<tab><tab><tab>for port in (None, 100):<tab><tab><tab><tab>for path in (b"""", b""path""):<tab><tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab><tab>host = host + b"":"" + networkString(str(port))<tab><tab><tab><tab><tab><tab>yield urlunsplit((scheme, host, path, b"""", b""""))",1,if port is not None :,if port is not None :,0.75,100,1
"def split_hashes(cls, line):<tab># type: (S) -> Tuple[S, List[S]]<tab>if ""--hash"" not in line:<tab><tab>return line, []<tab>split_line = line.split()<tab>line_parts = []  # type: List[S]<tab>hashes = []  # type: List[S]<tab>for part in split_line:<tab><tab><IF-STMT><tab><tab><tab>param, _, value = part.partition(""="")<tab><tab><tab>hashes.append(value)<tab><tab>else:<tab><tab><tab>line_parts.append(part)<tab>line = "" "".join(line_parts)<tab>return line, hashes",0,"if part . startswith ( ""--hash"" ) :","if ""="" in part :",0.019907918,6.397370149,0.4
"def part(p, imaginary):<tab># Represent infinity as 1e1000 and NaN as 1e1000-1e1000.<tab>s = ""j"" if imaginary else """"<tab>try:<tab><tab>if math.isinf(p):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return ""-1e1000"" + s<tab><tab><tab>return ""1e1000"" + s<tab><tab>if math.isnan(p):<tab><tab><tab>return ""(1e1000%s-1e1000%s)"" % (s, s)<tab>except OverflowError:<tab><tab># math.isinf will raise this when given an integer<tab><tab># that's too large to convert to a float.<tab><tab>pass<tab>return repr(p) + s",0,if p < 0 :,if math . isinf ( p ) :,0.02800146,7.267884212,0.314814815
"def _build_display_args(self, r):<tab>args = []<tab>if self.RESULT:<tab><tab><IF-STMT><tab><tab><tab>result = [self.RESULT]<tab><tab>else:<tab><tab><tab>result = self.RESULT<tab><tab>for name in result:<tab><tab><tab>value = getattr(r, name)<tab><tab><tab># Displayed offsets should be offset by the base address<tab><tab><tab>if name == ""offset"":<tab><tab><tab><tab>value += self.config.base<tab><tab><tab>args.append(value)<tab>return args",0,if type ( self . RESULT ) != type ( [ ] ) :,"if not isinstance ( self . RESULT , list ) :",0.144198319,20.1576753,0.242647059
"def cell_data_statusicon(column, cell, model, row, data):<tab>""""""Display text with an icon""""""<tab>try:<tab><tab>state = model.get_value(row, data)<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>func_last_value[""cell_data_statusicon""] = state<tab><tab>icon = ICON_STATE[state]<tab><tab># Supress Warning: g_object_set_qdata: assertion `G_IS_OBJECT (object)' failed<tab><tab>original_filters = warnings.filters[:]<tab><tab>warnings.simplefilter(""ignore"")<tab><tab>try:<tab><tab><tab>cell.set_property(""pixbuf"", icon)<tab><tab>finally:<tab><tab><tab>warnings.filters = original_filters<tab>except KeyError:<tab><tab>pass",0,"if func_last_value [ ""cell_data_statusicon"" ] == state :",if state is None :,0.019907918,0.85490028,0.56
"def _para_exploit(self, params, part):<tab>if len(params) == 0:<tab><tab>arr = [""*"", ""config""] + self._configs.keys()<tab><tab>return suggest(arr, part)<tab>if len(params) == 1:<tab><tab>arr = []<tab><tab><IF-STMT><tab><tab><tab>arr = self._configs.keys()<tab><tab>if params[0] == ""*"":<tab><tab><tab>arr = [""stopOnFirst""]<tab><tab>return suggest(arr, part)<tab>return []",0,"if params [ 0 ] == ""config"" :",if len ( params ) == 2 :,0.020373037,9.600960275,0.314814815
"def send(self, data, flags=0, timeout=timeout_default):<tab>if timeout is timeout_default:<tab><tab>timeout = self.timeout<tab>try:<tab><tab>return self._sock.send(data, flags)<tab>except error as ex:<tab><tab>if ex.args[0] not in _socketcommon.GSENDAGAIN or timeout == 0.0:<tab><tab><tab>raise<tab><tab>sys.exc_clear()<tab><tab>self._wait(self._write_event)<tab><tab>try:<tab><tab><tab>return self._sock.send(data, flags)<tab><tab>except error as ex2:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return 0<tab><tab><tab>raise",0,if ex2 . args [ 0 ] == EWOULDBLOCK :,if ex2 . args [ 0 ] == EWOULDBLOCK or timeout == 0.0 :,0.478785015,59.68774176,0.734375
"def server_decode(self, buf):<tab>if self.has_recv_header:<tab><tab>return (buf, True, False)<tab>self.has_recv_header = True<tab>crc = binascii.crc32(buf) & 0xFFFFFFFF<tab>if crc != 0xFFFFFFFF:<tab><tab>self.has_sent_header = True<tab><tab><IF-STMT><tab><tab><tab>return (b""E"" * 2048, False, False)<tab><tab>return (buf, True, False)<tab># (buffer_to_recv, is_need_decrypt, is_need_to_encode_and_send_back)<tab>return (b"""", False, True)",0,"if self . method == ""random_head"" :","if crc == b""E"" :",0.023846651,10.69331944,0.377777778
"def Decode(self, filedesc):<tab>while True:<tab><tab>chunk = filedesc.Read(4)<tab><tab>if not chunk:<tab><tab><tab>return<tab><tab><IF-STMT><tab><tab><tab>yield b""NORF""<tab><tab>if chunk == b""THUD"":<tab><tab><tab>yield b""BLARGH""",0,"if chunk == b""QUUX"" :","if chunk == b""NORF"" :",0.394778655,66.06328636,1
"def decProcess():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab>if reset == ACTIVE_LOW:<tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",0,if count == - n :,if n > 0 :,0.029084143,9.423716575,0.4
"def set_torrent_path(self, torrent_id, path):<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.client.core.set_torrent_move_completed_path(torrent_id, path).get()<tab><tab>self.client.core.set_torrent_move_completed(torrent_id, 1).get()<tab>except Exception:<tab><tab>return False<tab>finally:<tab><tab>if self.client:<tab><tab><tab>self.disconnect()<tab>return True",0,if not self . connect ( ) :,if not self . client . core . get_torrent_move_completed ( torrent_id ) :,0.167824063,14.05167698,0.56302521
"def stale_rec(node, nodes):<tab>if node.abspath() in node.ctx.env[Build.CFG_FILES]:<tab><tab>return<tab>if getattr(node, ""children"", []):<tab><tab>for x in node.children.values():<tab><tab><tab><IF-STMT><tab><tab><tab><tab>stale_rec(x, nodes)<tab>else:<tab><tab>for ext in DYNAMIC_EXT:<tab><tab><tab>if node.name.endswith(ext):<tab><tab><tab><tab>break<tab><tab>else:<tab><tab><tab>if not node in nodes:<tab><tab><tab><tab>if can_delete(node):<tab><tab><tab><tab><tab>Logs.warn(""Removing stale file -> %r"", node)<tab><tab><tab><tab><tab>node.delete()",0,"if x . name != ""c4che"" :",if can_delete ( x ) :,0.023367003,5.660233916,0.722222222
"def iterate(self, prod_, rule_):<tab>newProduction = """"<tab>for i in range(len(prod_)):<tab><tab>step = self.production[i]<tab><tab>if step == ""W"":<tab><tab><tab>newProduction = newProduction + self.ruleW<tab><tab><IF-STMT><tab><tab><tab>newProduction = newProduction + self.ruleX<tab><tab>elif step == ""Y"":<tab><tab><tab>newProduction = newProduction + self.ruleY<tab><tab>elif step == ""Z"":<tab><tab><tab>newProduction = newProduction + self.ruleZ<tab><tab>elif step != ""F"":<tab><tab><tab>newProduction = newProduction + step<tab>self.drawLength = self.drawLength * 0.5<tab>self.generations += 1<tab>return newProduction",1,"elif step == ""X"" :","elif step == ""X"" :",1,100,1
"def _get_app_params(self):<tab>params = self.cfg.params.copy()<tab>for key, value in self.__dict__.items():<tab><tab>if key.startswith(""_""):<tab><tab><tab>continue<tab><tab><IF-STMT><tab><tab><tab>params[""parse_console""] = not value<tab><tab>else:<tab><tab><tab>params[key] = value<tab>params[""load_config""] = False<tab>return params",0,"elif key == ""console_parsed"" :","if key == ""parse_console"" :",0.062871671,33.56891925,0.5
"def __setitem__(self, key, value):<tab>if not isinstance(value, PseudoNamespace):<tab><tab>tuple_converted = False<tab><tab>if isinstance(value, dict):<tab><tab><tab>value = PseudoNamespace(value)<tab><tab><IF-STMT><tab><tab><tab>value = list(value)<tab><tab><tab>tuple_converted = True<tab><tab>if isinstance(value, list):<tab><tab><tab>for i, item in enumerate(value):<tab><tab><tab><tab>if isinstance(item, dict) and not isinstance(item, PseudoNamespace):<tab><tab><tab><tab><tab>value[i] = PseudoNamespace(item)<tab><tab><tab>if tuple_converted:<tab><tab><tab><tab>value = tuple(value)<tab>super(PseudoNamespace, self).__setitem__(key, value)",0,"elif isinstance ( value , tuple ) :",if not tuple_converted :,0.014333168,6.916271813,0.114285714
"def getNextSibling(self, node):<tab>if isinstance(node, tuple):  # Text node<tab><tab>node, key = node<tab><tab>assert key in (""text"", ""tail""), ""Text nodes are text or tail, found %s"" % key<tab><tab>if key == ""text"":<tab><tab><tab># XXX: we cannot use a ""bool(node) and node[0] or None"" construct here<tab><tab><tab># because node[0] might evaluate to False if it has no child element<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return node[0]<tab><tab><tab>else:<tab><tab><tab><tab>return None<tab><tab>else:  # tail<tab><tab><tab>return node.getnext()<tab>return (node, ""tail"") if node.tail else node.getnext()",0,if len ( node ) :,if node [ 0 ] is not None :,0.022500853,6.274655311,0.208333333
"def star_path(path):<tab>""""""Replace integers and integer-strings in a path with *""""""<tab>path = list(path)<tab>for i, p in enumerate(path):<tab><tab>if isinstance(p, int):<tab><tab><tab>path[i] = ""*""<tab><tab>else:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>p = p.decode()<tab><tab><tab>if r_is_int.match(p):<tab><tab><tab><tab>path[i] = ""*""<tab>return join_path(path)",0,"if not isinstance ( p , text_type ) :","if isinstance ( p , bytes ) :",0.18845666,29.36697785,0.333333333
"def ensure_popup_selection(self):<tab>try:<tab><tab>self.__position_at_mouse<tab>except AttributeError:<tab><tab>path, col = self.get_cursor()<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>self.scroll_to_cell(path, col)<tab><tab># ensure current cursor path is selected, just like right-click<tab><tab>selection = self.get_selection()<tab><tab>if not selection.path_is_selected(path):<tab><tab><tab>selection.unselect_all()<tab><tab><tab>selection.select_path(path)<tab><tab>return True",0,if path is None :,if col is None :,0.394778655,42.72870064,0.666666667
"def release(self):<tab>me, lock_count = self.__begin()<tab>try:<tab><tab><IF-STMT><tab><tab><tab>return<tab><tab>self._count = count = self._count - 1<tab><tab>if not count:<tab><tab><tab>self._owner = None<tab><tab><tab>self._block.release()<tab>finally:<tab><tab>self.__end(me, lock_count)",0,if me is None :,if self . _owner is None :,0.117260658,22.08959113,0.666666667
"def date_match(self, date1, date2):<tab>if date1.is_empty() or date2.is_empty():<tab><tab>return 0<tab>if date1.is_equal(date2):<tab><tab>return 1<tab>if date1.is_compound() or date2.is_compound():<tab><tab>return self.range_compare(date1, date2)<tab>if date1.get_year() == date2.get_year():<tab><tab>if date1.get_month() == date2.get_month():<tab><tab><tab>return 0.75<tab><tab><IF-STMT><tab><tab><tab>return 0.75<tab><tab>else:<tab><tab><tab>return -1<tab>else:<tab><tab>return -1",0,if not date1 . get_month_valid ( ) or not date2 . get_month_valid ( ) :,elif date1 . get_day ( ) == date2 . get_day ( ) :,0.441677885,26.91075871,0.12244898
"def onMinimize(self, sender):<tab>if self._runDialogListener(""onMinimize"") is False:<tab><tab>return<tab>widget = self.child<tab>if widget is not None:<tab><tab><IF-STMT><tab><tab><tab>widget.setVisible(False)<tab><tab><tab>self.setHeight("""")<tab><tab><tab>self.setWidth("""")<tab><tab><tab>if self._maximized:<tab><tab><tab><tab>self._minimized = self._maximized<tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>else:<tab><tab><tab><tab>self._minimized = None<tab><tab>else:<tab><tab><tab>if self._minimized is not None:<tab><tab><tab><tab>self._toggleMaximize()<tab><tab><tab>widget.setVisible(True)",1,if widget . isVisible ( ) :,if widget . isVisible ( ) :,0.75,100,1
"def instance_reader():<tab>for epoch_index in range(epoch):<tab><tab><IF-STMT><tab><tab><tab>if shuffle_seed is not None:<tab><tab><tab><tab>np.random.seed(shuffle_seed)<tab><tab><tab>np.random.shuffle(examples)<tab><tab>if phase == ""train"":<tab><tab><tab>self.current_train_epoch = epoch_index<tab><tab>for (index, example) in enumerate(examples):<tab><tab><tab>if phase == ""train"":<tab><tab><tab><tab>self.current_train_example = index + 1<tab><tab><tab>feature = self.convert_example(<tab><tab><tab><tab>index, example, self.get_labels(), self.max_seq_len, self.tokenizer<tab><tab><tab>)<tab><tab><tab>instance = self.generate_instance(feature)<tab><tab><tab>yield instance",0,if shuffle :,"if phase == ""shuffle"" :",0.051944023,1.00E-10,0.5
"def _parse_lines(self, linesource):<tab>""""""Parse lines of text for functions and classes""""""<tab>functions = []<tab>classes = []<tab>for line in linesource:<tab><tab>if line.startswith(""def "") and line.count(""(""):<tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>functions.append(name)<tab><tab><IF-STMT><tab><tab><tab># exclude private stuff<tab><tab><tab>name = self._get_object_name(line)<tab><tab><tab>if not name.startswith(""_""):<tab><tab><tab><tab>classes.append(name)<tab><tab>else:<tab><tab><tab>pass<tab>functions.sort()<tab>classes.sort()<tab>return functions, classes",0,"elif line . startswith ( ""class "" ) :","elif line . count ( "" "" ) and line . count ( "" "" ) :",0.285070954,16.2673926,0.424444444
"def get_folder_version(folder):<tab>f = os.path.join(code_path, folder, ""version.txt"")<tab>try:<tab><tab>with open(f) as fd:<tab><tab><tab>content = fd.read()<tab><tab><tab>p = re.compile(r""([0-9]+)\.([0-9]+)\.([0-9]+)"")<tab><tab><tab>m = p.match(content)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>version = m.group(1) + ""."" + m.group(2) + ""."" + m.group(3)<tab><tab><tab><tab>return version<tab>except:<tab><tab>return False",1,if m :,if m :,0.531170663,1.00E-10,1
"def __init__(<tab>self, plugin_name=None, builtin=False, deprecated=False, config=None, session=None):<tab>if builtin and isinstance(builtin, (str, unicode)):<tab><tab>builtin = os.path.basename(builtin)<tab><tab>for ignore in ("".py"", "".pyo"", "".pyc""):<tab><tab><tab>if builtin.endswith(ignore):<tab><tab><tab><tab>builtin = builtin[: -len(ignore)]<tab><tab><IF-STMT><tab><tab><tab>self.LOADED.append(builtin)<tab>self.loading_plugin = plugin_name<tab>self.loading_builtin = plugin_name and builtin<tab>self.builtin = builtin<tab>self.deprecated = deprecated<tab>self.session = session<tab>self.config = config<tab>self.manifests = []",0,if builtin not in self . LOADED :,if builtin not in self .LOADED :,0.528331023,100,0.828571429
"def setInt(self, path, value, **kwargs):<tab>if value is None:<tab><tab>self.set(path, None, **kwargs)<tab><tab>return<tab>minimum = kwargs.pop(""min"", None)<tab>maximum = kwargs.pop(""max"", None)<tab>try:<tab><tab>intValue = int(value)<tab><tab><IF-STMT><tab><tab><tab>intValue = minimum<tab><tab>if maximum is not None and intValue > maximum:<tab><tab><tab>intValue = maximum<tab>except ValueError:<tab><tab>self._logger.warning(<tab><tab><tab>""Could not convert %r to a valid integer when setting option %r""<tab><tab><tab>% (value, path)<tab><tab>)<tab><tab>return<tab>self.set(path, intValue, **kwargs)",1,if minimum is not None and intValue < minimum :,if minimum is not None and intValue < minimum :,0.75,100,1
"def __call__(self, session_path):<tab>""""""Get raw session object from `session_path`.""""""<tab>new_session = copy.deepcopy(self._template)<tab>session_keys = new_session.keys()<tab>old_session = self._load_file(session_path)<tab>for attribute in dir(self):<tab><tab><IF-STMT><tab><tab><tab>target = attribute[4:].capitalize()<tab><tab><tab>if target not in session_keys:<tab><tab><tab><tab>raise ValueError(""Invalid attribute: %r"" % attribute)<tab><tab><tab>function = getattr(self, attribute)<tab><tab><tab>new_session[target] = function(old_session)<tab>return new_session",0,"if attribute . startswith ( ""set_"" ) :","if attribute . startswith ( ""session_"" ) :",0.549040681,70.16879391,1
"def add_comment_to_directory(args, dir_path):<tab>for root, _, files in os.walk(dir_path):<tab><tab>for file_name in files:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>file_path = os.path.join(root, file_name)<tab><tab><tab>add_comment_to_file(args, file_path)",0,"if not re . match ( r"".*(\.c|\.h|\.cpp|\.hpp|\.cxx|\.hxx)$"" , file_name ) :","if file_name . endswith ( "".py"" ) :",0.027073442,1.882601126,0.3125
"def reportMemory(k, options, field=None, isBytes=False):<tab>""""""Given k kilobytes, report back the correct format as string.""""""<tab>if options.pretty:<tab><tab>return prettyMemory(int(k), field=field, isBytes=isBytes)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>k /= 1024.0<tab><tab>if field is not None:<tab><tab><tab>return ""%*dK"" % (field - 1, k)  # -1 for the ""K""<tab><tab>else:<tab><tab><tab>return ""%dK"" % int(k)",0,if isBytes :,if k > 1024.0 :,0.051944023,1.00E-10,0.5
"def resolve(self, arguments):<tab>positional = []<tab>named = {}<tab>for arg in arguments:<tab><tab>if self._is_named(arg):<tab><tab><tab>self._add_named(arg, named)<tab><tab><IF-STMT><tab><tab><tab>self._raise_positional_after_named()<tab><tab>else:<tab><tab><tab>positional.append(arg)<tab>return positional, named",1,elif named :,elif named :,0.514316131,1.00E-10,1
"def _load_from_cache(self):<tab>if self._cache_key in self._cache:<tab><tab>creds = deepcopy(self._cache[self._cache_key])<tab><tab><IF-STMT><tab><tab><tab>return creds<tab><tab>else:<tab><tab><tab>logger.debug(""Credentials were found in cache, but they are expired."")<tab>return None",0,if not self . _is_expired ( creds ) :,if creds . has_expired :,0.017732313,8.462236333,0.366666667
"def convertstore(self, inputstore, includefuzzy=False):<tab>""""""converts a file to .lang format""""""<tab>thetargetfile = lang.LangStore(mark_active=self.mark_active)<tab># Run over the po units<tab>for pounit in inputstore.units:<tab><tab>if pounit.isheader() or not pounit.istranslatable():<tab><tab><tab>continue<tab><tab>newunit = thetargetfile.addsourceunit(pounit.source)<tab><tab>if includefuzzy or not pounit.isfuzzy():<tab><tab><tab>newunit.settarget(pounit.target)<tab><tab>else:<tab><tab><tab>newunit.settarget("""")<tab><tab><IF-STMT><tab><tab><tab>newunit.addnote(pounit.getnotes(""developer""), ""developer"")<tab>return thetargetfile",0,"if pounit . getnotes ( ""developer"" ) :","if pounit . hasnotes ( ""developer"" ) :",0.501462237,65.80370065,0.6
"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab>for exclude_field in self.context[""request""].query_params.getlist(""exclude""):<tab><tab>p = exclude_field.split(""."")<tab><tab><IF-STMT><tab><tab><tab>if len(p) == 1:<tab><tab><tab><tab>del self.fields[p[0]]<tab><tab><tab>elif len(p) == 2:<tab><tab><tab><tab>self.fields[p[0]].child.fields.pop(p[1])",0,if p [ 0 ] in self . fields :,if len ( p ) == 2 :,0.015007329,5.614808272,0.2
"def __init__(self, fn, args, resources):<tab>self.fn = fn<tab>self.args = copy.deepcopy(args)<tab>self.resources = resources<tab>with Task.LOCK:<tab><tab>self.task_id = Task.TASK_ID.value<tab><tab><IF-STMT><tab><tab><tab>if isinstance(<tab><tab><tab><tab>self.args[""args""], (argparse.Namespace, argparse.ArgumentParser)<tab><tab><tab>):<tab><tab><tab><tab>args_dict = vars(self.args[""args""])<tab><tab><tab>else:<tab><tab><tab><tab>args_dict = self.args[""args""]<tab><tab><tab>args_dict.update({""task_id"": self.task_id})<tab><tab>Task.TASK_ID.value += 1",0,"if ""args"" in self . args :",if self . args :,0.230930265,31.77235575,0.371428571
"def _expand_nsplit_by_reduce(splits, reduced):<tab>if reduced == 1:<tab><tab>return splits<tab>out = []<tab>for s in splits:<tab><tab>x = s<tab><tab>part = max(x / reduced, 1)<tab><tab>while x >= 2 * part:<tab><tab><tab>out.append(int(part))<tab><tab><tab>x -= int(part)<tab><tab><IF-STMT><tab><tab><tab>out.append(x)<tab>assert sum(splits) == sum(out)<tab>return tuple(out)",0,if x :,if x % reduced == 0 :,0.085805078,1.00E-10,0.55
"def OnDeleteLine(self, items):<tab>for n in items:<tab><tab><IF-STMT><tab><tab><tab>name1 = self.items[n][2]<tab><tab><tab>name2 = self.items[n][4]<tab><tab><tab>del self.items[n]<tab><tab><tab>if name1 in self.bindiff.matched1:<tab><tab><tab><tab>self.bindiff.matched1.remove(name1)<tab><tab><tab>if name2 in self.bindiff.matched2:<tab><tab><tab><tab>self.bindiff.matched2.remove(name2)<tab>return [Choose.ALL_CHANGED] + items",0,if n >= 0 :,if n in self . items :,0.052869316,14.53576842,0.380952381
"def _to_str(self, tokens: List[int]) -> str:<tab>pos = next(<tab><tab>(idx for idx, x in enumerate(tokens) if x == self.vocab.eos_token_id), -1<tab>)<tab>if pos != -1:<tab><tab>tokens = tokens[:pos]<tab>vocab_map = self.vocab.id_to_token_map_py<tab>words = [vocab_map[t] for t in tokens]<tab>if self.encoding is not None and self.perform_decode:<tab><tab><IF-STMT><tab><tab><tab>words = self.bpe_decode(words)<tab><tab>elif self.encoding == ""spm"":<tab><tab><tab>words = self.spm_decode(words)<tab>sentence = "" "".join(words)<tab>return sentence",1,"if self . encoding == ""bpe"" :","if self . encoding == ""bpe"" :",0.75,100,1
"def detect(content, **kwargs):<tab>headers = kwargs.get(""headers"", {})<tab>content = str(content)<tab>detection_schema = (<tab><tab>re.compile(r""\Abarra.counter.session(=)?"", re.I),<tab><tab>re.compile(r""(\A|\b)?barracuda."", re.I),<tab><tab>re.compile(r""barracuda.networks(.)?.inc"", re.I),<tab>)<tab>for detection in detection_schema:<tab><tab><IF-STMT><tab><tab><tab>return True<tab><tab>if detection.search(content) is not None:<tab><tab><tab>return True",0,"if detection . search ( headers . get ( HTTP_HEADER . SET_COOKIE , """" ) ) is not None :","if detection . search ( headers . get ( HTTP_HEADER . SERVER , """" ) ) is not None :",0.679415201,80.55576044,0.595652174
"def _finish_port_forward(self, listener, listen_host, listen_port):<tab>""""""Finish processing a TCP/IP port forwarding request""""""<tab>if asyncio.iscoroutine(listener):<tab><tab>try:<tab><tab><tab>listener = yield from listener<tab><tab>except OSError:<tab><tab><tab>listener = None<tab>if listener:<tab><tab><IF-STMT><tab><tab><tab>listen_port = listener.get_port()<tab><tab><tab>result = UInt32(listen_port)<tab><tab>else:<tab><tab><tab>result = True<tab><tab>self._local_listeners[listen_host, listen_port] = listener<tab><tab>self._report_global_response(result)<tab>else:<tab><tab>self.logger.debug1(""Failed to create TCP listener"")<tab><tab>self._report_global_response(False)",0,if listen_port == 0 :,"if hasattr ( listener , ""get_port"" ) :",0.026407399,8.054496385,0.381818182
"def start(self):<tab>""""""Start running the mainloop.""""""<tab>with self:<tab><tab>result = pa.pa_threaded_mainloop_start(self._pa_threaded_mainloop)<tab><tab><IF-STMT><tab><tab><tab>raise PulseAudioException(0, ""Failed to start PulseAudio mainloop"")<tab>assert _debug(""PulseAudioMainLoop: Started"")",0,if result < 0 :,if result != pa . PA_OK :,0.052869316,9.287529,0.6
def service(self):<tab>try:<tab><tab>try:<tab><tab><tab>self.start()<tab><tab><tab>self.execute()<tab><tab><tab>self.finish()<tab><tab>except socket.error:<tab><tab><tab>self.close_on_finish = True<tab><tab><tab><IF-STMT><tab><tab><tab><tab>raise<tab>finally:<tab><tab>pass,0,if self . channel . adj . log_socket_errors :,if self . close_on_finish :,0.11668419,13.5323305,0.566666667
"def _makepath(self, path):<tab>if not self.abspath:<tab><tab>try:<tab><tab><tab>np = py.path.local().bestrelpath(path)<tab><tab>except OSError:<tab><tab><tab>return path<tab><tab><IF-STMT><tab><tab><tab>path = np<tab>return path",0,if len ( np ) < len ( str ( path ) ) :,if np . exists ( ) :,0.018407146,6.075831217,0.263157895
"def upload(<tab>youtube_resource, video_path, body, chunksize=1024 * 1024, progress_callback=None):<tab>body_keys = "","".join(body.keys())<tab>media = MediaFileUpload(video_path, chunksize=chunksize, resumable=True)<tab>videos = youtube_resource.videos()<tab>request = videos.insert(part=body_keys, body=body, media_body=media)<tab>while 1:<tab><tab>status, response = request.next_chunk()<tab><tab><IF-STMT><tab><tab><tab>if ""id"" in response:<tab><tab><tab><tab>return response[""id""]<tab><tab><tab>else:<tab><tab><tab><tab>raise KeyError(""Response has no 'id' field"")<tab><tab>elif status and progress_callback:<tab><tab><tab>progress_callback(status.total_size, status.resumable_progress)",0,if response :,if status :,0.319750449,1.00E-10,0.5
"def __init__(self, *args, **kwargs):<tab>super().__init__(*args, **kwargs)<tab>for exclude_field in self.context[""request""].query_params.getlist(""exclude""):<tab><tab>p = exclude_field.split(""."")<tab><tab>if p[0] in self.fields:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>del self.fields[p[0]]<tab><tab><tab>elif len(p) == 2:<tab><tab><tab><tab>self.fields[p[0]].child.fields.pop(p[1])",1,if len ( p ) == 1 :,if len ( p ) == 1 :,0.75,100,1
"def on_button_press_event(self, iconview, event):<tab># print('on_button_press_event')<tab>if event.button == 3:<tab><tab>popup_menu = Gtk.Menu()<tab><tab>x = int(event.x)<tab><tab>y = int(event.y)<tab><tab>time = event.time<tab><tab>pathinfo = iconview.get_path_at_pos(x, y)<tab><tab><IF-STMT><tab><tab><tab>iconview.grab_focus()<tab><tab><tab>self.do_populate_popup(popup_menu, pathinfo)<tab><tab><tab># FIXME should use a signal here<tab><tab><tab>gtk_popup_at_pointer(popup_menu, event)<tab><tab><tab>return True<tab>return False",0,if pathinfo is not None :,if time > self . get_time ( ) - popup_menu . get_time ( ) :,0.017988252,2.159701134,0.238636364
"def __rshift__(self, other):<tab>if not self.symbolic and type(other) is int:<tab><tab>return RegisterOffset(<tab><tab><tab>self._bits, self.reg, self._to_signed(self.offset >> other)<tab><tab>)<tab>else:<tab><tab><IF-STMT><tab><tab><tab>return RegisterOffset(self._bits, self.reg, self.offset >> other)<tab><tab>else:<tab><tab><tab>return RegisterOffset(<tab><tab><tab><tab>self._bits,<tab><tab><tab><tab>self.reg,<tab><tab><tab><tab>ArithmeticExpression(<tab><tab><tab><tab><tab>ArithmeticExpression.RShift,<tab><tab><tab><tab><tab>(<tab><tab><tab><tab><tab><tab>self.offset,<tab><tab><tab><tab><tab><tab>other,<tab><tab><tab><tab><tab>),<tab><tab><tab><tab>),<tab><tab><tab>)",1,if self . symbolic :,if self . symbolic :,0.75,100,1
"def _slice_positional_metadata(self, indexable):<tab>if self.has_positional_metadata():<tab><tab><IF-STMT><tab><tab><tab>index = _single_index_to_slice(indexable)<tab><tab>else:<tab><tab><tab>index = indexable<tab><tab>return self.positional_metadata.iloc[index]<tab>else:<tab><tab>return None",0,if _is_single_index ( indexable ) :,if self . positional_metadata . multi_index :,0.023878899,9.425159511,0.5
"def _show_env(name=None):<tab>if name is None:<tab><tab>name = """"<tab>env = peda.execute_redirect(""show env"")<tab>for line in env.splitlines():<tab><tab>(k, v) = line.split(""="", 1)<tab><tab><IF-STMT><tab><tab><tab>msg(""%s = %s"" % (k, v if is_printable(v) else to_hexstr(v)))<tab>return",1,if k . startswith ( name ) :,if k . startswith ( name ) :,0.75,100,1
"def skip_to_semicolon(s, i):<tab>n = len(s)<tab>while i < n:<tab><tab>c = s[i]<tab><tab>if c == "";"":<tab><tab><tab>return i<tab><tab>elif c == ""'"" or c == '""':<tab><tab><tab>i = g.skip_string(s, i)<tab><tab><IF-STMT><tab><tab><tab>i = g.skip_to_end_of_line(s, i)<tab><tab>elif g.match(s, i, ""/*""):<tab><tab><tab>i = g.skip_block_comment(s, i)<tab><tab>else:<tab><tab><tab>i += 1<tab>return i",0,"elif g . match ( s , i , ""//"" ) :","elif c == ""\n"" :",0.009003032,3.46174364,0.260504202
"def filter_iterable(cls, iterable, filterset_class, filters_name, info, **args):<tab>filter_input = args.get(filters_name)<tab>if filter_input and filterset_class:<tab><tab>instance = filterset_class(<tab><tab><tab>data=dict(filter_input), queryset=iterable, request=info.context<tab><tab>)<tab><tab># Make sure filter input has valid values<tab><tab><IF-STMT><tab><tab><tab>raise GraphQLError(json.dumps(instance.errors.get_json_data()))<tab><tab>iterable = instance.qs<tab>return iterable",0,if not instance . is_valid ( ) :,if instance . errors . get_json_data ( ) :,0.085486894,15.72780094,0.4
"def build(opt):<tab>dpath = os.path.join(opt[""datapath""], ""self_feeding"")<tab>version = ""3.1""<tab>if not build_data.built(dpath, version):<tab><tab>print(""[building data: "" + dpath + ""]"")<tab><tab><IF-STMT><tab><tab><tab># An older version exists, so remove these outdated files.<tab><tab><tab>build_data.remove_dir(dpath)<tab><tab>build_data.make_dir(dpath)<tab><tab># Download the data.<tab><tab>for downloadable_file in RESOURCES:<tab><tab><tab>downloadable_file.download_file(dpath)<tab><tab>build_data.mark_done(dpath, version)",1,if build_data . built ( dpath ) :,if build_data . built ( dpath ) :,0.75,100,1
"def get_tokens_unprocessed(self, text):<tab>for index, token, value in RegexLexer.get_tokens_unprocessed(self, text):<tab><tab>if token is Name:<tab><tab><tab>if self.stdlibhighlighting and value in self.stdlib_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab><IF-STMT><tab><tab><tab><tab>token = Keyword.Type<tab><tab><tab>elif self.platformhighlighting and value in self.linux_types:<tab><tab><tab><tab>token = Keyword.Type<tab><tab>yield index, token, value",0,elif self . c99highlighting and value in self . c99_types :,elif self . linuxhighlighting and value in self . linux_types :,0.741634892,47.58733096,0.75
"def searchOpcode(self, opcode, name=None):<tab>to_return = {}<tab>if not name:<tab><tab>for file in self.__files:<tab><tab><tab>to_return[file.loader.fileName] = self.__ropper.searchOpcode(<tab><tab><tab><tab>file.loader, opcode<tab><tab><tab>)<tab>else:<tab><tab>fc = self.getFileFor(name)<tab><tab><IF-STMT><tab><tab><tab>raise RopperError(""No such file opened: %s"" % name)<tab><tab>to_return[name] = self.__ropper.searchOpcode(fc.loader, opcode)<tab>return self.__filterBadBytes(to_return)",1,if not fc :,if not fc :,0.75,100,1
"def logic():<tab>while 1:<tab><tab>yield clock.posedge, reset.negedge<tab><tab><IF-STMT><tab><tab><tab>count.next = 0<tab><tab>else:<tab><tab><tab>if enable:<tab><tab><tab><tab>if count == -n:<tab><tab><tab><tab><tab>count.next = n - 1<tab><tab><tab><tab>else:<tab><tab><tab><tab><tab>count.next = count - 1",1,if reset == ACTIVE_LOW :,if reset == ACTIVE_LOW :,0.75,100,1
"def upgrade_cursor(cursor):<tab>count = 0<tab>prefix = pack_be_uint16(cursor)<tab>key_len = HASHX_LEN + 2<tab>chunks = util.chunks<tab>with self.db.write_batch() as batch:<tab><tab>batch_put = batch.put<tab><tab>for key, hist in self.db.iterator(prefix=prefix):<tab><tab><tab># Ignore non-history entries<tab><tab><tab><IF-STMT><tab><tab><tab><tab>continue<tab><tab><tab>count += 1<tab><tab><tab>hist = b"""".join(item + b""\0"" for item in chunks(hist, 4))<tab><tab><tab>batch_put(key, hist)<tab><tab>self.upgrade_cursor = cursor<tab><tab>self.write_state(batch)<tab>return count",0,if len ( key ) != key_len :,if len ( hist ) < key_len :,0.341668085,35.54333945,0.6
"def fork(receiver: Receiver, func, *args, **kwargs):<tab>current_actor = self()<tab>send(Fork(current_actor, func, args, kwargs), receiver)<tab>while True:<tab><tab>message = recv(current_actor)<tab><tab><IF-STMT><tab><tab><tab>return message.new_actor<tab><tab>else:<tab><tab><tab>send(message, current_actor)<tab>return",0,"if isinstance ( message , ForkResponse ) :","if isinstance ( message , Receiver ) :",0.549040681,59.46035575,0.666666667
"def history_move(self, n):<tab>from ranger.container.history import HistoryEmptyException<tab>try:<tab><tab>current = self.history.current()<tab>except HistoryEmptyException:<tab><tab>pass<tab>else:<tab><tab><IF-STMT><tab><tab><tab>self.history.modify(self.line)<tab><tab>self.history.move(n)<tab><tab>current = self.history.current()<tab><tab>if self.line != current:<tab><tab><tab>self.line = self.history.current()<tab><tab><tab>self.pos = len(self.line)",0,if self . line != current and self . line != self . history . top ( ) :,if self . line != current :,0.182032278,17.12032303,0.489583333
"def fullname(self):<tab>if self._fullname is None:<tab><tab>pkg_name = namespace.apply_namespace(self.dist.project_name)<tab><tab><IF-STMT><tab><tab><tab>self._fullname = ""%s/%s"" % (pkg_name, self.name)<tab><tab>else:<tab><tab><tab>self._fullname = self.name<tab>return self._fullname",0,"if pkg_name and pkg_name != ""."" :",if pkg_name :,0.038857533,1.00E-10,0.636363636
"def do_install(datafilename):<tab>ifile = open(datafilename, ""rb"")<tab>d = pickle.load(ifile)<tab>destdir_var = ""DESTDIR""<tab>if destdir_var in os.environ:<tab><tab><IF-STMT><tab><tab><tab>subdir = d.prefix[1:]<tab><tab>else:<tab><tab><tab>subdir = d.prefix<tab><tab>d.prefix = os.path.join(os.environ[destdir_var], subdir)<tab>install_targets(d)<tab>install_headers(d)<tab>install_man(d)<tab>install_data(d)<tab>install_po(d)",0,"if d . prefix [ 0 ] == ""/"" :","if d . prefix [ 0 ] == ""_"" :",0.642805659,79.10665072,1
"def truncate(self, size=None):<tab># type: (Optional[int]) -> int<tab># Inefficient, but I don't know if truncate is possible with ftp<tab>with self._lock:<tab><tab><IF-STMT><tab><tab><tab>size = self.tell()<tab><tab>with self.fs.openbin(self.path) as f:<tab><tab><tab>data = f.read(size)<tab><tab>with self.fs.openbin(self.path, ""w"") as f:<tab><tab><tab>f.write(data)<tab><tab><tab>if len(data) < size:<tab><tab><tab><tab>f.write(b""\0"" * (size - len(data)))<tab>return size",1,if size is None :,if size is None :,0.75,100,1
"def write(self, expression, location=None):<tab># If the phrase is incomplete, utop will not remember it, so<tab># we need to account for it here. Also, Shift+Enter will add a literal<tab># newline, which would otherwise break protocol.<tab>for line in expression.split(""\n""):<tab><tab>self._phrase.append(line)<tab><tab><IF-STMT><tab><tab><tab>self._phrase_line_begins.append(location)<tab><tab><tab>location += len(line) + 1<tab>self.write_command(""input"", ""allow-incomplete"", self._phrase)",1,if location is not None :,if location is not None :,0.75,100,1
"def scan_iter(self, match=None, count=None):<tab>nodes = await self.cluster_nodes()<tab>for node in nodes:<tab><tab>if ""master"" in node[""flags""]:<tab><tab><tab>cursor = ""0""<tab><tab><tab>while cursor != 0:<tab><tab><tab><tab>pieces = [cursor]<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>pieces.extend([""MATCH"", match])<tab><tab><tab><tab>if count is not None:<tab><tab><tab><tab><tab>pieces.extend([""COUNT"", count])<tab><tab><tab><tab>response = await self.execute_command_on_nodes([node], ""SCAN"", *pieces)<tab><tab><tab><tab>cursor, data = list(response.values())[0]<tab><tab><tab><tab>for item in data:<tab><tab><tab><tab><tab>yield item",1,if match is not None :,if match is not None :,0.75,100,1
"def communicate(self, input_data=None):<tab>""""""Mock subprocess.Popen.communicate.""""""<tab>for i in range(2):<tab><tab>timeout = execute_time if i == 0 else sigterm_handler_time<tab><tab>try:<tab><tab><tab>received_signal = self.signal_queue.get(block=True, timeout=timeout)<tab><tab>except queue.Empty:<tab><tab><tab>continue<tab><tab>self.received_signals.append((received_signal, time.time() - self.start_time))<tab><tab><IF-STMT><tab><tab><tab>break<tab>return output, None",0,if received_signal == Signal . KILL :,if i == 0 :,0.023846651,9.911450613,0.333333333
"def _add_bookmark_breakpoint(self):<tab>""""""Add a bookmark or breakpoint to the current file in the editor.""""""<tab>editorWidget = self.ide.mainContainer.get_actual_editor()<tab>if editorWidget and editorWidget.hasFocus():<tab><tab>if self.ide.mainContainer.actualTab.navigator.operation == 1:<tab><tab><tab>editorWidget._sidebarWidget.set_bookmark(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)<tab><tab><IF-STMT><tab><tab><tab>editorWidget._sidebarWidget.set_breakpoint(<tab><tab><tab><tab>editorWidget.textCursor().blockNumber()<tab><tab><tab>)",1,elif self . ide . mainContainer . actualTab . navigator . operation == 2 :,elif self . ide . mainContainer . actualTab . navigator . operation == 2 :,1,100,1
"def _should_auto_select_container_version(instance_type, distribution):<tab>""""""Returns a boolean that indicates whether to use an auto-selected container version.""""""<tab>p4d = False<tab>if instance_type:<tab><tab># looks for either ""ml.<family>.<size>"" or ""ml_<family>""<tab><tab>match = re.match(r""^ml[\._]([a-z\d]+)\.?\w*$"", instance_type)<tab><tab><IF-STMT><tab><tab><tab>family = match[1]<tab><tab><tab>p4d = family == ""p4d""<tab>smdistributed = False<tab>if distribution:<tab><tab>smdistributed = ""smdistributed"" in distribution<tab>return p4d or smdistributed",1,if match :,if match :,0.531170663,1.00E-10,1
"def _flush_some_if_lockable(self):<tab># Since our task may be appending to the outbuf, we try to acquire<tab># the lock, but we don't block if we can't.<tab>if self.outbuf_lock.acquire(False):<tab><tab>try:<tab><tab><tab>self._flush_some()<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.outbuf_lock.notify()<tab><tab>finally:<tab><tab><tab>self.outbuf_lock.release()",0,if self . total_outbufs_len < self . adj . outbuf_high_watermark :,if self . outbuf_lock . notify is not None :,0.205252927,12.2955214,0.3125
"def add_auth(self, req, **kwargs):<tab>if not ""x-amz-content-sha256"" in req.headers:<tab><tab><IF-STMT><tab><tab><tab>req.headers[""x-amz-content-sha256""] = req.headers.pop(""_sha256"")<tab><tab>else:<tab><tab><tab>req.headers[""x-amz-content-sha256""] = self.payload(req)<tab>req = self.mangle_path_and_params(req)<tab>return super(S3HmacAuthV4Handler, self).add_auth(req, **kwargs)",1,"if ""_sha256"" in req . headers :","if ""_sha256"" in req . headers :",0.75,100,1
"def get_objects(self):<tab>list_type, id, handles, timestamp = self._obj_list<tab>retval = []<tab>for (target, handle) in handles:<tab><tab>_class = map2class(target)<tab><tab>if _class:<tab><tab><tab>obj = _class(self._dbstate, pickle.dumps((target, id, handle, timestamp)))<tab><tab><tab><IF-STMT><tab><tab><tab><tab>retval.append(obj)<tab>return retval",1,if obj :,if obj :,0.531170663,1.00E-10,1
"def toggle_fullscreen_hide_tabbar(self):<tab>if self.is_fullscreen():<tab><tab>if self.settings.general.get_boolean(""fullscreen-hide-tabbar""):<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(False)<tab>else:<tab><tab>if self.guake and self.guake.notebook_manager:<tab><tab><tab>v = self.settings.general.get_boolean(""window-tabbar"")<tab><tab><tab>self.guake.notebook_manager.set_notebooks_tabbar_visible(v)",1,if self . guake and self . guake . notebook_manager :,if self . guake and self . guake . notebook_manager :,0.75,100,1
"def __repr__(self):<tab>parts = []<tab>if not approx_equal(self.constant, 0.0) or self.is_constant:<tab><tab>parts.append(repr(self.constant))<tab>for clv, coeff in sorted(self.terms.items(), key=lambda x: repr(x)):<tab><tab><IF-STMT><tab><tab><tab>parts.append(repr(clv))<tab><tab>else:<tab><tab><tab>parts.append(repr(coeff) + ""*"" + repr(clv))<tab>return "" + "".join(parts)",0,"if approx_equal ( coeff , 1.0 ) :",if not coeff :,0.019930836,4.690733795,0.477272727
"def wrapper(*args, **kwds):<tab>global bootstrap_logger_enabled<tab>if bootstrap_logger_enabled:<tab><tab><IF-STMT><tab><tab><tab>bootstrap_logger.exception(msg=args[0])<tab><tab>else:<tab><tab><tab>bootstrap_logger.log(level=level, msg=args[0])<tab>return f(*args, **kwds)",0,"if level == ""EXCEPTION"" :",if level == logging . ERROR :,0.117260658,36.55552229,0.55
"def get_sorted_entry(field, bookid):<tab>if field == ""title"" or field == ""authors"":<tab><tab>book = calibre_db.get_filtered_book(bookid)<tab><tab>if book:<tab><tab><tab>if field == ""title"":<tab><tab><tab><tab>return json.dumps({""sort"": book.sort})<tab><tab><tab><IF-STMT><tab><tab><tab><tab>return json.dumps({""author_sort"": book.author_sort})<tab>return """"",1,"elif field == ""authors"" :","elif field == ""authors"" :",1,100,1
"def movies_iterator():<tab>for row in self._tuple_iterator(query):<tab><tab>id, guid, movie = self._parse(fields, row, offset=2)<tab><tab># Parse `guid` (if enabled, and not already parsed)<tab><tab>if parse_guid:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>guids[id] = Guid.parse(guid)<tab><tab><tab>guid = guids[id]<tab><tab># Return item<tab><tab>yield id, guid, movie",0,if id not in guids :,if not guids . has_key ( id ) :,0.024523051,5.604233375,0.314814815
"def update_sockets(self, context):<tab>bools = [self.min_list, self.max_list, self.size_list]<tab>dims = int(self.dimensions[0])<tab>for i in range(3):<tab><tab>for j in range(3):<tab><tab><tab>out_index = 4 + j + 3 * i<tab><tab><tab>hidden = self.outputs[out_index].hide_safe<tab><tab><tab>if bools[i][j] and j < dims:<tab><tab><tab><tab><IF-STMT><tab><tab><tab><tab><tab>self.outputs[out_index].hide_safe = False<tab><tab><tab>else:<tab><tab><tab><tab>self.outputs[out_index].hide_safe = True<tab><tab>updateNode(self, context)",1,if hidden :,if hidden :,0.531170663,1.00E-10,1
"def broadcast(self, msg, eid):<tab>for s in self.subs:<tab><tab>if type(self.subs[s].eid) is list:<tab><tab><tab><IF-STMT><tab><tab><tab><tab>self.subs[s].write_message(msg)<tab><tab>else:<tab><tab><tab>if self.subs[s].eid == eid:<tab><tab><tab><tab>self.subs[s].write_message(msg)",0,if eid in self . subs [ s ] . eid :,if self . subs [ s ] . eid == eid :,0.438011589,62.62844963,0.272727273
"def as_create_delta(<tab>self: CallableObjectT,<tab>schema: s_schema.Schema,<tab>context: so.ComparisonContext,) -> sd.ObjectCommand[CallableObjectT]:<tab>delta = super().as_create_delta(schema, context)<tab>new_params = self.get_params(schema).objects(schema)<tab>for p in new_params:<tab><tab><IF-STMT><tab><tab><tab>delta.add_prerequisite(<tab><tab><tab><tab>p.as_create_delta(schema=schema, context=context),<tab><tab><tab>)<tab>return delta",0,"if not param_is_inherited ( schema , self , p ) :","if hasattr ( p , ""as_create_delta"" ) :",0.027073442,7.478554033,0.265306122
"def set_indentation_params(self, ispythonsource, guess=True):<tab>if guess and ispythonsource:<tab><tab>i = self.guess_indent()<tab><tab><IF-STMT><tab><tab><tab>self.indentwidth = i<tab><tab>if self.indentwidth != self.tabwidth:<tab><tab><tab>self.usetabs = False<tab>self.set_tabwidth(self.tabwidth)",0,if 2 <= i <= 8 :,if i > 0 :,0.023846651,6.316906128,0.30952381
"def _test():<tab>""""""Simple test program to disassemble a file.""""""<tab>argc = len(sys.argv)<tab>if argc != 2:<tab><tab><IF-STMT><tab><tab><tab>fn = __file__<tab><tab>else:<tab><tab><tab>sys.stderr.write(""usage: %s [-|CPython compiled file]\n"" % __file__)<tab><tab><tab>sys.exit(2)<tab>else:<tab><tab>fn = sys.argv[1]<tab>disassemble_file(fn)",0,if argc == 1 :,"if sys . argv [ 1 ] == ""-c"" :",0.026964759,7.768562846,0.320512821
"def set_lineno(self, lineno, override=False):<tab>""""""Set the line numbers of the node and children.""""""<tab>todo = deque([self])<tab>while todo:<tab><tab>node = todo.popleft()<tab><tab><IF-STMT><tab><tab><tab>if node.lineno is None or override:<tab><tab><tab><tab>node.lineno = lineno<tab><tab>todo.extend(node.iter_child_nodes())<tab>return self",0,"if ""lineno"" in node . attributes :","if hasattr ( node , ""iter_child_nodes"" ) :",0.021135836,4.246549373,0.481481481
"def _connect(s, address):<tab>try:<tab><tab>s.connect(address)<tab>except socket.error:<tab><tab>(ty, v) = sys.exc_info()[:2]<tab><tab><IF-STMT><tab><tab><tab>v_err = v.errno<tab><tab>else:<tab><tab><tab>v_err = v[0]<tab><tab>if v_err not in [errno.EINPROGRESS, errno.EWOULDBLOCK, errno.EALREADY]:<tab><tab><tab>raise v",0,"if hasattr ( v , ""errno"" ) :",if ty == errno . EINVAL :,0.018333425,5.660233916,0.26984127
"def SurroundedByParens(token):<tab>""""""Check if it's an expression surrounded by parentheses.""""""<tab>while token:<tab><tab><IF-STMT><tab><tab><tab>return False<tab><tab>if token.value == "")"":<tab><tab><tab>return not token.next_token<tab><tab>if token.OpensScope():<tab><tab><tab>token = token.matching_bracket.next_token<tab><tab>else:<tab><tab><tab>token = token.next_token<tab>return False",0,"if token . value == "","" :","if token . value == ""("" :",0.574113272,70.71067812,1
"def read_vocab_list(path, max_vocab_size=20000):<tab>vocab = {""<eos>"": 0, ""<unk>"": 1}<tab>with io.open(path, encoding=""utf-8"", errors=""ignore"") as f:<tab><tab>for l in f:<tab><tab><tab>w = l.strip()<tab><tab><tab>if w not in vocab and w:<tab><tab><tab><tab>vocab[w] = len(vocab)<tab><tab><tab><IF-STMT><tab><tab><tab><tab>break<tab>return vocab",1,if len ( vocab ) >= max_vocab_size :,if len ( vocab ) >= max_vocab_size :,0.75,100,1
"def _messageHandled(self, resultList):<tab>failures = 0<tab>for (success, result) in resultList:<tab><tab>if not success:<tab><tab><tab>failures += 1<tab><tab><tab>log.err(result)<tab>if failures:<tab><tab>msg = ""Could not send e-mail""<tab><tab>resultLen = len(resultList)<tab><tab><IF-STMT><tab><tab><tab>msg += "" ({} failures out of {} recipients)"".format(failures, resultLen)<tab><tab>self.sendCode(550, networkString(msg))<tab>else:<tab><tab>self.sendCode(250, b""Delivery in progress"")",0,if resultLen > 1 :,if resultLen > 0 :,0.394778655,42.72870064,0.6
"def test_images_p_is_stochastic_parameter(self):<tab>aug = self.create_aug(p=iap.Choice([0, 1], p=[0.7, 0.3]))<tab>seen = [0, 0]<tab>for _ in sm.xrange(1000):<tab><tab>observed = aug.augment_image(self.image)<tab><tab>if np.array_equal(observed, self.image):<tab><tab><tab>seen[0] += 1<tab><tab><IF-STMT><tab><tab><tab>seen[1] += 1<tab><tab>else:<tab><tab><tab>assert False<tab>assert np.allclose(seen, [700, 300], rtol=0, atol=75)",0,"elif np . array_equal ( observed , self . image_flipped ) :","elif np . array_equal ( observed , self . image ) :",0.634580284,77.21195505,0.822222222
"def kill(self):<tab># check and execute the 'kill' method if present<tab>if self.has_kill:<tab><tab>try:<tab><tab><tab>kill_method = getattr(self.module_class, ""kill"")<tab><tab><tab><IF-STMT><tab><tab><tab><tab>kill_method()<tab><tab><tab>else:<tab><tab><tab><tab># legacy call parameters<tab><tab><tab><tab>kill_method(<tab><tab><tab><tab><tab>self.i3status_thread.json_list,<tab><tab><tab><tab><tab>self.config[""py3_config""][""general""],<tab><tab><tab><tab>)<tab><tab>except Exception:<tab><tab><tab># this would be stupid to die on exit<tab><tab><tab>pass",0,if self . has_kill == self . PARAMS_NEW :,"if hasattr ( kill_method , ""__call__"" ) :",0.015846268,3.657015913,0.480769231
"def remove_topic(self, topic):<tab>if topic not in self.messages:<tab><tab>return<tab>del self.messages[topic]<tab>for sub in self.subscribers.get(topic, set()):<tab><tab><IF-STMT><tab><tab><tab>sub._pyroRelease()<tab><tab>if hasattr(sub, ""_pyroUri""):<tab><tab><tab>try:<tab><tab><tab><tab>proxy = self.proxy_cache[sub._pyroUri]<tab><tab><tab><tab>proxy._pyroRelease()<tab><tab><tab><tab>del self.proxy_cache[sub._pyroUri]<tab><tab><tab>except KeyError:<tab><tab><tab><tab>pass<tab>del self.subscribers[topic]",1,"if hasattr ( sub , ""_pyroRelease"" ) :","if hasattr ( sub , ""_pyroRelease"" ) :",0.75,100,1
"def run_async(self, source, target, reverse):<tab>to_load = target or self.get_next(source, reverse)<tab>if not to_load:<tab><tab>return<tab>view_signature = self.view_signatures[to_load]<tab>window = self.view.window()<tab>if window:<tab><tab>window.run_command(self.commands[to_load])<tab><tab><IF-STMT><tab><tab><tab>sublime.set_timeout_async(self.view.close)",0,if not self . view . settings ( ) . get ( view_signature ) :,"if view_signature [ ""timeout"" ] is not None :",0.00959146,10.05262357,0.211111111
"def eval_operand(assembly, start, stop, prefix=""""):<tab>imm = assembly[start + 1 : stop]<tab>try:<tab><tab>eval_imm = eval(imm)<tab><tab><IF-STMT><tab><tab><tab>eval_imm = 0xFFFFFFFF - eval_imm<tab><tab><tab>eval_imm += 1<tab><tab><tab>eval_imm = -eval_imm<tab><tab>return assembly.replace(prefix + imm, prefix + hex(eval_imm))<tab>except:<tab><tab>return assembly",0,if eval_imm > 0x80000000 :,if eval_imm < 0xFFFFFFFF :,0.314978772,43.47208719,0.5
"def admin():<tab>if Configuration.loginRequired():<tab><tab><IF-STMT><tab><tab><tab>return render_template(""login.html"")<tab>else:<tab><tab>person = User.get(""_dummy_"")<tab><tab>login_user(person)<tab>output = None<tab>if os.path.isfile(Configuration.getUpdateLogFile()):<tab><tab>with open(Configuration.getUpdateLogFile()) as updateFile:<tab><tab><tab>separator = ""==========================\n""<tab><tab><tab>output = updateFile.read().split(separator)[-2:]<tab><tab><tab>output = separator + separator.join(output)<tab>return render_template(""admin.html"", status=""default"", **adminInfo(output))",0,if not current_user . is_authenticated ( ) :,"if not User . has_permission ( ""login"" ) :",0.10593869,10.04916996,0.730769231
"def data(self):<tab>result = """"<tab>for hunk in self._hunks:<tab><tab><IF-STMT><tab><tab><tab>hunk, f = hunk<tab><tab>else:<tab><tab><tab>f = lambda x: x<tab><tab>result += f(hunk.data())<tab>return result",0,"if isinstance ( hunk , tuple ) and len ( hunk ) == 2 :","if isinstance ( hunk , tuple ) :",0.281844539,31.98497429,0.555555556
"def not_less_witness(self, other):<tab>n = max(self.longest_run_of_spaces(), other.longest_run_of_spaces()) + 1<tab>a = []<tab>for ts in range(1, n + 1):<tab><tab><IF-STMT><tab><tab><tab>a.append((ts, self.indent_level(ts), other.indent_level(ts)))<tab>return a",0,if self . indent_level ( ts ) >= other . indent_level ( ts ) :,"if self . compare ( ts , other . compare ( ts ) ) :",0.468584853,16.12386009,0.481481481
"def _validate(self) -> None:<tab>indent = self.indent<tab>if indent is not None:<tab><tab><IF-STMT><tab><tab><tab>raise CSTValidationError(<tab><tab><tab><tab>""An indented block must have a non-zero width indent.""<tab><tab><tab>)<tab><tab>if _INDENT_WHITESPACE_RE.fullmatch(indent) is None:<tab><tab><tab>raise CSTValidationError(<tab><tab><tab><tab>""An indent must be composed of only whitespace characters.""<tab><tab><tab>)",0,if len ( indent ) == 0 :,if indent < 0 :,0.037304456,11.41593807,0.377777778
"def sanitize_numeric_fields(info):<tab>for numeric_field in self._NUMERIC_FIELDS:<tab><tab>field = info.get(numeric_field)<tab><tab><IF-STMT><tab><tab><tab>continue<tab><tab>report_force_conversion(numeric_field, ""numeric"", ""int"")<tab><tab>info[numeric_field] = int_or_none(field)",0,"if field is None or isinstance ( field , compat_numeric_types ) :",if field is None :,0.21511243,7.834966465,0.633699634
"def count(self):<tab>if self._should_cache(""count""):<tab><tab># Optmization borrowed from overriden method:<tab><tab># if queryset cache is already filled just return its len<tab><tab><IF-STMT><tab><tab><tab>return len(self._result_cache)<tab><tab>return cached_as(self)(lambda: self._no_monkey.count(self))()<tab>else:<tab><tab>return self._no_monkey.count(self)",1,if self . _result_cache is not None :,if self . _result_cache is not None :,0.75,100,1
